{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQRlenvaPMSzFBuUM81JEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hliuson/gh-pr-discussions/blob/feature%2Fgithub-data-pipeline/GitHubDataPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "01SBJSOpmHzE"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import files, userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "eRY41CJOp7Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "HEADERS = {\n",
        "    'Authorization': f'token {GITHUB_TOKEN}',\n",
        "    'Accept': 'application/vnd.github+json'\n",
        "}\n",
        "\n",
        "REQUEST_DELAY = 2\n",
        "MAX_REPOS = 100\n",
        "MAX_PRS_PER_REPO = 10"
      ],
      "metadata": {
        "id": "jN3dWJ3vo9Vz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discover the Repositories"
      ],
      "metadata": {
        "id": "U18CBoPnqGQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Searches python Repos for at least 1000 stars, 100 forks, and not older than Jan 1st 2024\n",
        "def searchRepos(language='python', min_stars=1000, min_forks=100):\n",
        "\n",
        "  search_url = \"https://api.github.com/search/repositories\"\n",
        "\n",
        "  queries = [\n",
        "      f\"stars:>{min_stars}\",\n",
        "      f\"forks:>{min_forks}\",\n",
        "      f\"language:{language}\",\n",
        "      \"pushed:>2024-01-01\",\n",
        "      \"archived:false\"\n",
        "  ]\n",
        "\n",
        "  params = {\n",
        "      'q': ' '.join(queries),\n",
        "      'sort': 'stars',\n",
        "      'order': 'desc',\n",
        "      'per_page': MAX_REPOS\n",
        "  }\n",
        "\n",
        "  print(f\"Repo query: {params['q']}\")\n",
        "\n",
        "  response = requests.get(search_url, headers=HEADERS, params=params)\n",
        "\n",
        "  if response.status_code != 200:\n",
        "    print(f\"Error: {response.status_code} -  {response.text}\") ################################################## For Debugging\n",
        "    return []\n",
        "\n",
        "  return response.json().get('items', [])"
      ],
      "metadata": {
        "id": "BMqYZy4CqKmN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter repositories with conditions below and create and return a dictionary with important imfo about the repository\n",
        "def filterRepos(repos):\n",
        "\n",
        "  quality_repos = []\n",
        "\n",
        "  for repo in repos:\n",
        "    if (repo['stargazers_count'] >= 1000 and # Greater than 1000 stars\n",
        "        repo['forks_count'] >= 100 and       # More than 100 forks\n",
        "        repo['open_issues_count'] > 5 and    # Look for Repos that have open issues, tackling real challenges developers face\n",
        "        repo['open_issues_count'] < 500 and  # But not more than 500 then there might be issues with the repo and code base itself\n",
        "        repo['size'] > 100 and               # Look for a Repo greater than 100KB in size\n",
        "        repo.get('license') and              # Allows us to use this repo legally\n",
        "        repo.get('description') and          # Has a description\n",
        "        len(repo['description']) > 20 and    # Description is at least 20 characters\n",
        "        not repo['archived'] and             # Look for active Repo\n",
        "        not repo['disabled']):               # Look for active Repo part 2\n",
        "\n",
        "      quality_repo = {\n",
        "          'id': repo['id'],\n",
        "          'name': repo['name'],\n",
        "          'full_name': repo['full_name'],\n",
        "          'description': repo['description'][:200],\n",
        "          'stars': repo['stargazers_count'],\n",
        "          'forks': repo['forks_count'],\n",
        "          'language': repo['language'],\n",
        "          'open_issues': repo['open_issues_count'],\n",
        "          'updated_at': repo['updated_at'],\n",
        "          'pushed_at': repo['pushed_at'],\n",
        "          'license': repo['license']['name'] if repo['license'] else 'Unknown',\n",
        "          'size': repo['size'],\n",
        "          'has_wiki': repo['has_wiki'],\n",
        "          'has_pages': repo['has_pages'],\n",
        "          'url': repo['html_url']\n",
        "      }\n",
        "\n",
        "      quality_repos.append(quality_repo)\n",
        "\n",
        "  return quality_repos"
      ],
      "metadata": {
        "id": "wLqRUe6EvdkS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Pull Request Discussions"
      ],
      "metadata": {
        "id": "sLO5EvFjwrhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Look for Pull Requests that specifically have comments, this is a pivot from the original idea of just taking the most recent prs and filtering them\n",
        "since many of the new prs(up to 100, when I tested) had no comments'''\n",
        "def searchPRsWithComments(repo_fullName, max_prs=50):\n",
        "\n",
        "    search_url = \"https://api.github.com/search/issues\"\n",
        "\n",
        "    # Search for PRs with comments in this specific repo\n",
        "    query = f\"repo:{repo_fullName} type:pr comments:>0\"\n",
        "\n",
        "    params = {\n",
        "        'q': query,\n",
        "        'sort': 'comments',     # Sort by number of comments\n",
        "        'order': 'desc',        # Most comments first\n",
        "        'per_page': max_prs\n",
        "    }\n",
        "\n",
        "    #print(f\"Searching for PRs with comments in {repo_fullName}\") ################################################## For Debugging\n",
        "    time.sleep(REQUEST_DELAY)\n",
        "\n",
        "    response = requests.get(search_url, headers=HEADERS, params=params)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error searching PRs: {response.status_code}\") ################################################## For Debugging\n",
        "        return []\n",
        "\n",
        "    prs = response.json().get('items', [])\n",
        "\n",
        "    for pr in prs:\n",
        "        pr['repository_full_name'] = repo_fullName\n",
        "\n",
        "    return response.json().get('items', [])"
      ],
      "metadata": {
        "id": "UKwbKaH6roTv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for quality PRS with the conditions specified below\n",
        "def filterPRs(prs):\n",
        "  print(f\"    Filtering {len(prs)} PRs...\")\n",
        "  quality_prs = []\n",
        "  no_comments_count = 0\n",
        "\n",
        "  for pr in prs:\n",
        "    has_quality_title = len(pr.get('title', '')) > 10\n",
        "    has_description = pr.get('body') and len(pr['body']) > 30\n",
        "    has_comments = pr.get('comments', 0) > 0\n",
        "    not_draft = not pr.get('draft', False)\n",
        "\n",
        "    if (has_quality_title or has_description) and has_comments and not_draft:\n",
        "      quality_prs.append(pr)\n",
        "      ################################################## The proceeding logic is all for debugging\n",
        "    elif pr.get('comments', 0) == 0:\n",
        "      no_comments_count += 1\n",
        "      # Only print first few to avoid spam\n",
        "      if no_comments_count <= 3:\n",
        "          print(f\"    Filtered out PR #{pr.get('number', '?')}: No comments\")\n",
        "    elif pr.get('draft', False):\n",
        "      print(f\"    Filtered out PR #{pr.get('number', '?')}: Draft PR\")\n",
        "\n",
        "    #print(f\"    Summary: {no_comments_count} PRs with no comments\") ################################################## For Debugging\n",
        "    #print(f\"    Found {len(quality_prs)} quality PRs\") ################################################## For Debugging\n",
        "\n",
        "  return quality_prs"
      ],
      "metadata": {
        "id": "pMT9wKJzw122"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the comments from the chosen quality PRs\n",
        "def getComments(repo_fullName, pr_number):\n",
        "\n",
        "  url = f\"https://api.github.com/repos/{repo_fullName}/issues/{pr_number}/comments\"\n",
        "\n",
        "  #print(f\"      Fetching comments from: {url}\") ################################################## For Debugging\n",
        "  time.sleep(REQUEST_DELAY)\n",
        "\n",
        "  response = requests.get(url, headers=HEADERS)\n",
        "\n",
        "  #print(f\"      Response status: {response.status_code}\") ################################################## For Debugging\n",
        "\n",
        "  if response.status_code != 200:\n",
        "    print(f\"Error getting comments for PR #{pr_number}: {response.status_code}\")\n",
        "    print(f\"      Error details: {response.text}\")\n",
        "    return []\n",
        "\n",
        "  comments = response.json()\n",
        "  #print(f\"      API returned {len(comments)} comments for PR #{pr_number}\") ################################################## For Debugging\n",
        "\n",
        "  return comments"
      ],
      "metadata": {
        "id": "wUvpkJyCzOuV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter out comments with patterns of botting and non-substantial info\n",
        "def processComments(comments, pr_data):\n",
        "\n",
        "  bot_patterns = [\n",
        "      'bot', 'Bot', '[bot]', 'github-actions', 'dependabot',\n",
        "      'codecov', 'travis', 'circleci', 'sonarcloud'\n",
        "  ]\n",
        "\n",
        "  unwanted_patterns = [\n",
        "      r'^lgtm$',\n",
        "      r'^ðŸ‘$',\n",
        "      r'^thanks$',\n",
        "      r'^ping @',\n",
        "      r'^cc @',\n",
        "      r'^\\+1$',\n",
        "      r'^approved$',\n",
        "      r'^merge$'\n",
        "  ]\n",
        "\n",
        "  quality_comments = []\n",
        "\n",
        "  for comment in comments:\n",
        "    username = comment['user']['login']\n",
        "    body = comment['body']\n",
        "\n",
        "    is_bot = (any(pattern in username for pattern in bot_patterns) or\n",
        "              comment['user']['type'] == 'Bot')\n",
        "\n",
        "    is_too_short = len(body) < 30\n",
        "\n",
        "    is_unwanted = any(re.match(pattern, body.strip(), re.IGNORECASE)\n",
        "                      for pattern in unwanted_patterns)\n",
        "\n",
        "    is_minor_fix = re.match(r'^(fix:|type:|lint:|format:)', body, re.IGNORECASE)\n",
        "\n",
        "    if not (is_bot or is_too_short or is_unwanted or is_minor_fix):\n",
        "            cleaned_comment = {\n",
        "                'pr_title': pr_data.get('title', 'Unknown'),\n",
        "                'pr_body': pr_data.get('body', '')[:500] if pr_data.get('body') else '',\n",
        "                'pr_number': pr_data.get('number', 0),\n",
        "                'comment_id': comment['id'],\n",
        "                'author': username,\n",
        "                'body': body,\n",
        "                'created_at': comment['created_at'],\n",
        "                'updated_at': comment['updated_at'],\n",
        "                'repository': pr_data.get('repository_full_name', 'Unknown'),\n",
        "                'comment_length': len(body)\n",
        "            } # Returns a dictionary of important comment information\n",
        "\n",
        "            quality_comments.append(cleaned_comment)\n",
        "\n",
        "    return quality_comments"
      ],
      "metadata": {
        "id": "VE6n27Z50Rbb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Management"
      ],
      "metadata": {
        "id": "uqFbp-mBBKOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the gathered information in a JSON format\n",
        "def saveJSON(data, filename):\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"Data saved to {filename}\")\n",
        "    return filename\n",
        "\n",
        "# Display the info gathered, used for visual of progress or debugging\n",
        "def summaryDisplay(data, data_type=\"data\"):\n",
        "    print(f\"\\n=== {data_type.upper()} SUMMARY ===\")\n",
        "    print(f\"Total items: {len(data)}\")\n",
        "\n",
        "    if data and isinstance(data[0], dict):\n",
        "        print(\"Sample item keys:\", list(data[0].keys()))\n",
        "        if len(data) > 0:\n",
        "            print(\"First item preview:\")\n",
        "            for k, v in list(data[0].items())[:3]:\n",
        "                preview = str(v)[:100] + \"...\" if len(str(v)) > 100 else str(v)\n",
        "                print(f\"  {k}: {preview}\")\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "xoO5ioAGBM71"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Pipeline"
      ],
      "metadata": {
        "id": "sbmono3ZKDPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def repositoryDiscovery():\n",
        "    print(\"=== STAGE 1: REPOSITORY DISCOVERY ===\")\n",
        "\n",
        "    # Search for repositories\n",
        "    repos = searchRepos(language='python', min_stars=1000)\n",
        "    print(f\"Found {len(repos)} repositories from search\") ################################################## For Debugging\n",
        "\n",
        "    # Filter for quality\n",
        "    quality_repos = filterRepos(repos)\n",
        "    print(f\"Filtered to {len(quality_repos)} high-quality repositories\") ################################################## For Debugging\n",
        "\n",
        "    # Save to JSON\n",
        "    filename = saveJSON(quality_repos, 'high_quality_repos.json')\n",
        "    summaryDisplay(quality_repos, \"repositories\")\n",
        "\n",
        "    return quality_repos"
      ],
      "metadata": {
        "id": "RnFGpKhfKCnl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prDiscussionExtraction(repos):\n",
        "\n",
        "    print(\"=== STAGE 2: PR DISCUSSION EXTRACTION ===\")\n",
        "\n",
        "    all_discussions = []\n",
        "\n",
        "    for i, repo in enumerate(repos[:10]):  # !!!!!IMPORTANT!!!!! Limit to first 10 repo for testing\n",
        "        #print(f\"\\nProcessing repository {i+1}/{min(len(repos), 10)}: {repo['full_name']}\")\n",
        "\n",
        "        # Get pull requests\n",
        "        prs = searchPRsWithComments(repo['full_name'], max_prs=100)\n",
        "        print(f\"  Total PRs found: {len(prs)}\")\n",
        "\n",
        "        # Filter substantial PRs\n",
        "        substantial_prs = filterPRs(prs)\n",
        "        print(f\"Found {len(substantial_prs)} substantial PRs\")\n",
        "\n",
        "        # Process each PR\n",
        "        for pr in substantial_prs[:10]:  # !!!!!IMPORTANT!!!!! Limit PRs per repo\n",
        "            #print(f\"  Processing PR #{pr['number']}: {pr['title'][:50]}...\")\n",
        "\n",
        "            # Get comments\n",
        "            comments = getComments(repo['full_name'], pr['number'])\n",
        "            print(f\"  Raw comments retrieved: {len(comments)}\")\n",
        "\n",
        "            # Clean and filter comments\n",
        "            quality_comments = processComments(comments, pr)\n",
        "            print(f\"  Quality comments after filtering: {len(quality_comments)}\")\n",
        "\n",
        "            all_discussions.extend(quality_comments)\n",
        "\n",
        "    print(f\"\\nTotal quality discussions collected: {len(all_discussions)}\")\n",
        "\n",
        "    # Save to JSON\n",
        "    if all_discussions:\n",
        "        filename = saveJSON(all_discussions, 'pr_discussions_cleaned.json')\n",
        "        summaryDisplay(all_discussions, \"discussions\")\n",
        "\n",
        "    return all_discussions"
      ],
      "metadata": {
        "id": "txmKtxtzMTal"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline Execution"
      ],
      "metadata": {
        "id": "rIojcstxNUDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_repo = {\n",
        "    'full_name': 'microsoft/vscode',  # Very active with lots of discussions\n",
        "    'name': 'vscode'\n",
        "} # Debugging step cus my first iteration returned 0 comments, tested a repo with for sure high quality PRs with many comments"
      ],
      "metadata": {
        "id": "JG8DBNxKePRn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Start of GitHub Pipeline\")\n",
        "\n",
        "repos = repositoryDiscovery()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMseoTUHNTW_",
        "outputId": "7c2d66a3-7484-4028-a205-57857fc396be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of GitHub Pipeline\n",
            "=== STAGE 1: REPOSITORY DISCOVERY ===\n",
            "Repo query: stars:>1000 forks:>100 language:python pushed:>2024-01-01 archived:false\n",
            "Found 100 repositories from search\n",
            "Filtered to 55 high-quality repositories\n",
            "Data saved to high_quality_repos.json\n",
            "\n",
            "=== REPOSITORIES SUMMARY ===\n",
            "Total items: 55\n",
            "Sample item keys: ['id', 'name', 'full_name', 'description', 'stars', 'forks', 'language', 'open_issues', 'updated_at', 'pushed_at', 'license', 'size', 'has_wiki', 'has_pages', 'url']\n",
            "First item preview:\n",
            "  id: 13491895\n",
            "  name: free-programming-books\n",
            "  full_name: EbookFoundation/free-programming-books\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discussions = prDiscussionExtraction(repos)\n",
        "\n",
        "print(\"\\n Pipeline completed!\")\n",
        "print(f\" Collected {len(repos)} repositories and {len(discussions)} discussions\")\n",
        "print(\"\\n Output files:\")\n",
        "print(\"  - high_quality_repos.json\")\n",
        "print(\"  - pr_discussions_cleaned.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaxyeSyFQ8km",
        "outputId": "f197412a-2c95-4cd9-d795-583928b710a6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== STAGE 2: PR DISCUSSION EXTRACTION ===\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #2235: No comments\n",
            "    Filtered out PR #6799: No comments\n",
            "    Filtered out PR #6878: No comments\n",
            "Found 94 substantial PRs\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 19\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 10\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 18\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 2\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 3\n",
            "  Quality comments after filtering: 1\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #2497: Draft PR\n",
            "Found 98 substantial PRs\n",
            "  Raw comments retrieved: 24\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 11\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 4\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 16\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 4\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 16\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 14\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 10\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 1\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #7364: No comments\n",
            "    Filtered out PR #4518: No comments\n",
            "    Filtered out PR #4669: No comments\n",
            "    Filtered out PR #2459: Draft PR\n",
            "Found 83 substantial PRs\n",
            "  Raw comments retrieved: 3\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 13\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 1\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 7\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 1\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 2\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 1\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 2\n",
            "  Quality comments after filtering: 0\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #9621: Draft PR\n",
            "    Filtered out PR #9543: Draft PR\n",
            "    Filtered out PR #8306: Draft PR\n",
            "    Filtered out PR #3316: Draft PR\n",
            "    Filtered out PR #7142: Draft PR\n",
            "    Filtered out PR #4547: Draft PR\n",
            "    Filtered out PR #4299: Draft PR\n",
            "Found 93 substantial PRs\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 10\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 25\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 17\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #1063: Draft PR\n",
            "    Filtered out PR #1082: No comments\n",
            "    Filtered out PR #1210: No comments\n",
            "    Filtered out PR #1243: No comments\n",
            "Found 96 substantial PRs\n",
            "  Raw comments retrieved: 9\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 23\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 15\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 11\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 18\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 9\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 17\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 20\n",
            "  Quality comments after filtering: 1\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "Found 100 substantial PRs\n",
            "  Raw comments retrieved: 10\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 7\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 18\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 11\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 23\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 15\n",
            "  Quality comments after filtering: 1\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #1483: No comments\n",
            "    Filtered out PR #991: Draft PR\n",
            "Found 98 substantial PRs\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 15\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 27\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 15\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 15\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 14\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 10\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 1\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "Found 100 substantial PRs\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 17\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 16\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #241: No comments\n",
            "    Filtered out PR #242: No comments\n",
            "    Filtered out PR #183: No comments\n",
            "Found 95 substantial PRs\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 27\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 17\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 20\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 20\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 19\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 19\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 16\n",
            "  Quality comments after filtering: 0\n",
            "  Raw comments retrieved: 3\n",
            "  Quality comments after filtering: 1\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #343: No comments\n",
            "    Filtered out PR #124: No comments\n",
            "    Filtered out PR #106: No comments\n",
            "Found 78 substantial PRs\n",
            "  Raw comments retrieved: 4\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 5\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 4\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 5\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 3\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 1\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 4\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 7\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "\n",
            "Total quality discussions collected: 74\n",
            "Data saved to pr_discussions_cleaned.json\n",
            "\n",
            "=== DISCUSSIONS SUMMARY ===\n",
            "Total items: 74\n",
            "Sample item keys: ['pr_title', 'pr_body', 'pr_number', 'comment_id', 'author', 'body', 'created_at', 'updated_at', 'repository', 'comment_length']\n",
            "First item preview:\n",
            "  pr_title: move the translated documentation files to a docs folder\n",
            "  pr_body: - add translation section in Readme\n",
            "- replace multilinks with a  single link to translation section...\n",
            "  pr_number: 6614\n",
            "\n",
            " Pipeline completed!\n",
            " Collected 55 repositories and 74 discussions\n",
            "\n",
            " Output files:\n",
            "  - high_quality_repos.json\n",
            "  - pr_discussions_cleaned.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('high_quality_repos.json')"
      ],
      "metadata": {
        "id": "s2DiaTe4dVOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('pr_discussions_cleaned.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oVc3-9fhjsbt",
        "outputId": "8f20cdc4-a036-4931-93e8-a071200a073e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_db80cabc-6be8-4f6b-9694-0d8f41fc563b\", \"pr_discussions_cleaned.json\", 73376)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}