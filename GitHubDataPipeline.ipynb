{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNe9H4TAuE5CNnXE0oWOOT4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hliuson/gh-pr-discussions/blob/feature%2Fgithub-data-pipeline/GitHubDataPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01SBJSOpmHzE"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "eRY41CJOp7Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GITHUB_TOKEN = \"\"\n",
        "HEADERS = {\n",
        "    'Authorization': f'token {GITHUB_TOKEN}',\n",
        "    'Accept': 'application/vnd.github+json'\n",
        "}\n",
        "\n",
        "REQUEST_DELAY = 2\n",
        "MAX_REPOS = 100\n",
        "MAX_PRS_PER_REPO = 10"
      ],
      "metadata": {
        "id": "jN3dWJ3vo9Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discover the Repositories"
      ],
      "metadata": {
        "id": "U18CBoPnqGQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def searchRepos(language='python', min_stars=1000, min_forks=100):\n",
        "\n",
        "  search_url = \"https://api.github.com/search/repositories\"\n",
        "\n",
        "  queries = [\n",
        "      f\"stars:>{min_stars}\",\n",
        "      f\"forks:>{min_forks}\",\n",
        "      f\"language:{language}\",\n",
        "      \"pushed:>2024-01-01\",\n",
        "      \"archived:false\"\n",
        "  ]\n",
        "\n",
        "  params = {\n",
        "      'q': ' '.join(queries),\n",
        "      'sort': 'stars',\n",
        "      'order': 'desc',\n",
        "      'per_page': MAX_REPOS\n",
        "  }\n",
        "\n",
        "  print(f\"Repo query: {params['q']}\")\n",
        "\n",
        "  response = requests.get(search_url, headers=HEADERS, params=params)\n",
        "\n",
        "  if response.status_code != 200:\n",
        "    print(f\"Error: {response.status_code} -  {response.text}\")\n",
        "    return []\n",
        "\n",
        "  return response.json().get('items', [])"
      ],
      "metadata": {
        "id": "BMqYZy4CqKmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filterRepos(repos):\n",
        "\n",
        "  quality_repos = []\n",
        "\n",
        "  for repo in repos:\n",
        "    if (repo['stargazers_count'] >= 1000 and\n",
        "        repo['forks_count'] >= 100 and\n",
        "        repo['open_issues_count'] > 5 and\n",
        "        repo['open_issues_count'] < 500 and\n",
        "        repo['size'] > 100 and\n",
        "        repo.get('license') and\n",
        "        repo.get('description') and\n",
        "        len(repo['description']) > 20 and\n",
        "        not repo['archived'] and\n",
        "        not repo['disabled']):\n",
        "\n",
        "      quality_repo = {\n",
        "          'id': repo['id'],\n",
        "          'name': repo['name'],\n",
        "          'full_name': repo['full_name'],\n",
        "          'description': repo['description'][:200],\n",
        "          'stars': repo['stargazers_count'],\n",
        "          'forks': repo['forks_count'],\n",
        "          'language': repo['language'],\n",
        "          'open_issues': repo['open_issues_count'],\n",
        "          'updated_at': repo['updated_at'],\n",
        "          'pushed_at': repo['pushed_at'],\n",
        "          'license': repo['license']['name'] if repo['license'] else 'Unknown',\n",
        "          'size': repo['size'],\n",
        "          'has_wiki': repo['has_wiki'],\n",
        "          'has_pages': repo['has_pages'],\n",
        "          'url': repo['html_url']\n",
        "      }\n",
        "\n",
        "      quality_repos.append(quality_repo)\n",
        "\n",
        "  return quality_repos"
      ],
      "metadata": {
        "id": "wLqRUe6EvdkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Pull Request Discussions"
      ],
      "metadata": {
        "id": "sLO5EvFjwrhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def searchPRsWithComments(repo_fullName, max_prs=50):\n",
        "\n",
        "    search_url = \"https://api.github.com/search/issues\"\n",
        "\n",
        "    # Search for PRs with comments in this specific repo\n",
        "    query = f\"repo:{repo_fullName} type:pr comments:>0\"\n",
        "\n",
        "    params = {\n",
        "        'q': query,\n",
        "        'sort': 'comments',     # Sort by number of comments\n",
        "        'order': 'desc',        # Most comments first\n",
        "        'per_page': max_prs\n",
        "    }\n",
        "\n",
        "    print(f\"Searching for PRs with comments in {repo_fullName}\")\n",
        "    time.sleep(REQUEST_DELAY)\n",
        "\n",
        "    response = requests.get(search_url, headers=HEADERS, params=params)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error searching PRs: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "    prs = response.json().get('items', [])\n",
        "\n",
        "    for pr in prs:\n",
        "        pr['repository_full_name'] = repo_fullName\n",
        "\n",
        "    return response.json().get('items', [])"
      ],
      "metadata": {
        "id": "UKwbKaH6roTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filterPRs(prs):\n",
        "  print(f\"    Filtering {len(prs)} PRs...\")\n",
        "  quality_prs = []\n",
        "  no_comments_count = 0\n",
        "\n",
        "  for pr in prs:\n",
        "    has_quality_title = len(pr.get('title', '')) > 10\n",
        "    has_description = pr.get('body') and len(pr['body']) > 30\n",
        "    has_comments = pr.get('comments', 0) > 0\n",
        "    not_draft = not pr.get('draft', False)\n",
        "\n",
        "    if (has_quality_title or has_description) and has_comments and not_draft:\n",
        "      quality_prs.append(pr)\n",
        "    elif pr.get('comments', 0) == 0:\n",
        "      no_comments_count += 1\n",
        "      # Only print first few to avoid spam\n",
        "      if no_comments_count <= 3:\n",
        "          print(f\"    Filtered out PR #{pr.get('number', '?')}: No comments\")\n",
        "    elif pr.get('draft', False):\n",
        "      print(f\"    Filtered out PR #{pr.get('number', '?')}: Draft PR\")\n",
        "\n",
        "    #print(f\"    Summary: {no_comments_count} PRs with no comments\")\n",
        "    #print(f\"    Found {len(quality_prs)} quality PRs\")\n",
        "\n",
        "  return quality_prs"
      ],
      "metadata": {
        "id": "pMT9wKJzw122"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getComments(repo_fullName, pr_number):\n",
        "\n",
        "  url = f\"https://api.github.com/repos/{repo_fullName}/issues/{pr_number}/comments\"\n",
        "\n",
        "  #print(f\"      Fetching comments from: {url}\")\n",
        "  time.sleep(REQUEST_DELAY)\n",
        "\n",
        "  response = requests.get(url, headers=HEADERS)\n",
        "\n",
        "  #print(f\"      Response status: {response.status_code}\")\n",
        "\n",
        "  if response.status_code != 200:\n",
        "    print(f\"Error getting comments for PR #{pr_number}: {response.status_code}\")\n",
        "    print(f\"      Error details: {response.text}\")\n",
        "    return []\n",
        "\n",
        "  comments = response.json()\n",
        "  #print(f\"      API returned {len(comments)} comments for PR #{pr_number}\")\n",
        "\n",
        "  return comments"
      ],
      "metadata": {
        "id": "wUvpkJyCzOuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processComments(comments, pr_data):\n",
        "\n",
        "  bot_patterns = [\n",
        "      'bot', 'Bot', '[bot]', 'github-actions', 'dependabot',\n",
        "      'codecov', 'travis', 'circleci', 'sonarcloud'\n",
        "  ]\n",
        "\n",
        "  unwanted_patterns = [\n",
        "      r'^lgtm$',\n",
        "      r'^👍$',\n",
        "      r'^thanks$',\n",
        "      r'^ping @',\n",
        "      r'^cc @',\n",
        "      r'^\\+1$',\n",
        "      r'^approved$',\n",
        "      r'^merge$'\n",
        "  ]\n",
        "\n",
        "  quality_comments = []\n",
        "\n",
        "  for comment in comments:\n",
        "    username = comment['user']['login']\n",
        "    body = comment['body']\n",
        "\n",
        "    is_bot = (any(pattern in username for pattern in bot_patterns) or\n",
        "              comment['user']['type'] == 'Bot')\n",
        "\n",
        "    is_too_short = len(body) < 30\n",
        "\n",
        "    is_unwanted = any(re.match(pattern, body.strip(), re.IGNORECASE)\n",
        "                      for pattern in unwanted_patterns)\n",
        "\n",
        "    is_minor_fix = re.match(r'^(fix:|type:|lint:|format:)', body, re.IGNORECASE)\n",
        "\n",
        "    if not (is_bot or is_too_short or is_unwanted or is_minor_fix):\n",
        "            cleaned_comment = {\n",
        "                'pr_title': pr_data.get('title', 'Unknown'),\n",
        "                'pr_body': pr_data.get('body', '')[:500] if pr_data.get('body') else '',\n",
        "                'pr_number': pr_data.get('number', 0),\n",
        "                'comment_id': comment['id'],\n",
        "                'author': username,\n",
        "                'body': body,\n",
        "                'created_at': comment['created_at'],\n",
        "                'updated_at': comment['updated_at'],\n",
        "                'repository': pr_data.get('repository_full_name', 'Unknown'),\n",
        "                'comment_length': len(body)\n",
        "            }\n",
        "\n",
        "            quality_comments.append(cleaned_comment)\n",
        "\n",
        "    return quality_comments"
      ],
      "metadata": {
        "id": "VE6n27Z50Rbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Management"
      ],
      "metadata": {
        "id": "uqFbp-mBBKOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def saveJSON(data, filename):\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"Data saved to {filename}\")\n",
        "    return filename\n",
        "\n",
        "def summaryDisplay(data, data_type=\"data\"):\n",
        "    print(f\"\\n=== {data_type.upper()} SUMMARY ===\")\n",
        "    print(f\"Total items: {len(data)}\")\n",
        "\n",
        "    if data and isinstance(data[0], dict):\n",
        "        print(\"Sample item keys:\", list(data[0].keys()))\n",
        "        if len(data) > 0:\n",
        "            print(\"First item preview:\")\n",
        "            for k, v in list(data[0].items())[:3]:\n",
        "                preview = str(v)[:100] + \"...\" if len(str(v)) > 100 else str(v)\n",
        "                print(f\"  {k}: {preview}\")\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "xoO5ioAGBM71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Pipeline"
      ],
      "metadata": {
        "id": "sbmono3ZKDPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def repositoryDiscovery():\n",
        "    print(\"=== STAGE 1: REPOSITORY DISCOVERY ===\")\n",
        "\n",
        "    # Search for repositories\n",
        "    repos = searchRepos(language='python', min_stars=1000)\n",
        "    print(f\"Found {len(repos)} repositories from search\")\n",
        "\n",
        "    # Filter for quality\n",
        "    quality_repos = filterRepos(repos)\n",
        "    print(f\"Filtered to {len(quality_repos)} high-quality repositories\")\n",
        "\n",
        "    # Save to JSON\n",
        "    filename = saveJSON(quality_repos, 'high_quality_repos.json')\n",
        "    summaryDisplay(quality_repos, \"repositories\")\n",
        "\n",
        "    return quality_repos"
      ],
      "metadata": {
        "id": "RnFGpKhfKCnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prDiscussionExtraction(repos):\n",
        "\n",
        "    print(\"=== STAGE 2: PR DISCUSSION EXTRACTION ===\")\n",
        "\n",
        "    all_discussions = []\n",
        "\n",
        "    for i, repo in enumerate(repos[:10]):  # Limit to first repo for testing\n",
        "        #print(f\"\\nProcessing repository {i+1}/{min(len(repos), 10)}: {repo['full_name']}\")\n",
        "\n",
        "        # Get pull requests\n",
        "        prs = searchPRsWithComments(repo['full_name'], max_prs=100)\n",
        "        print(f\"  Total PRs found: {len(prs)}\")\n",
        "\n",
        "        # Filter substantial PRs\n",
        "        substantial_prs = filterPRs(prs)\n",
        "        print(f\"Found {len(substantial_prs)} substantial PRs\")\n",
        "\n",
        "        # Process each PR\n",
        "        for pr in substantial_prs[:10]:  # Limit PRs per repo\n",
        "            print(f\"  Processing PR #{pr['number']}: {pr['title'][:50]}...\")\n",
        "\n",
        "            # Get comments\n",
        "            comments = getComments(repo['full_name'], pr['number'])\n",
        "            print(f\"  Raw comments retrieved: {len(comments)}\")\n",
        "\n",
        "            # Clean and filter comments\n",
        "            quality_comments = processComments(comments, pr)\n",
        "            print(f\"  Quality comments after filtering: {len(quality_comments)}\")\n",
        "\n",
        "            all_discussions.extend(quality_comments)\n",
        "\n",
        "    print(f\"\\nTotal quality discussions collected: {len(all_discussions)}\")\n",
        "\n",
        "    # Save to JSON\n",
        "    if all_discussions:\n",
        "        filename = saveJSON(all_discussions, 'pr_discussions_cleaned.json')\n",
        "        summaryDisplay(all_discussions, \"discussions\")\n",
        "\n",
        "    return all_discussions"
      ],
      "metadata": {
        "id": "txmKtxtzMTal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline Execution"
      ],
      "metadata": {
        "id": "rIojcstxNUDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_repo = {\n",
        "    'full_name': 'microsoft/vscode',  # Very active with lots of discussions\n",
        "    'name': 'vscode'\n",
        "}"
      ],
      "metadata": {
        "id": "JG8DBNxKePRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Start of GitHub Pipeline\")\n",
        "\n",
        "repos = repositoryDiscovery()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMseoTUHNTW_",
        "outputId": "4f3bfadc-e378-445e-f6ee-36f89380b4eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of GitHub Pipeline\n",
            "=== STAGE 1: REPOSITORY DISCOVERY ===\n",
            "Repo query: stars:>1000 forks:>100 language:python pushed:>2024-01-01 archived:false\n",
            "Found 100 repositories from search\n",
            "Filtered to 55 high-quality repositories\n",
            "Data saved to high_quality_repos.json\n",
            "\n",
            "=== REPOSITORIES SUMMARY ===\n",
            "Total items: 55\n",
            "Sample item keys: ['id', 'name', 'full_name', 'description', 'stars', 'forks', 'language', 'open_issues', 'updated_at', 'pushed_at', 'license', 'size', 'has_wiki', 'has_pages', 'url']\n",
            "First item preview:\n",
            "  id: 13491895\n",
            "  name: free-programming-books\n",
            "  full_name: EbookFoundation/free-programming-books\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discussions = prDiscussionExtraction(repos)\n",
        "\n",
        "print(\"\\n Pipeline completed!\")\n",
        "print(f\" Collected {len(repos)} repositories and {len(discussions)} discussions\")\n",
        "print(\"\\n Output files:\")\n",
        "print(\"  - high_quality_repos.json\")\n",
        "print(\"  - pr_discussions_cleaned.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaxyeSyFQ8km",
        "outputId": "fb8851ad-02cf-46d3-fa2a-6fd70c08cdc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== STAGE 2: PR DISCUSSION EXTRACTION ===\n",
            "Searching for PRs with comments in EbookFoundation/free-programming-books\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #2235: No comments\n",
            "    Filtered out PR #6799: No comments\n",
            "    Filtered out PR #6878: No comments\n",
            "Found 94 substantial PRs\n",
            "  Processing PR #6614: move the translated documentation files to a docs ...\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #7818: Telugu courses added...\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #10030: Translating ZH for Contributing document (zh revie...\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #3166: Format desc base on CONTRIBUTING-zh and Optimize z...\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #3050: 8 books...\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #11781: Added Playground for different languages...\n",
            "  Raw comments retrieved: 19\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #6724: docs(howto): Homogenize HowTo's format across tran...\n",
            "  Raw comments retrieved: 10\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #3026: issues:add in list #3009,#3010, correction blank i...\n",
            "  Raw comments retrieved: 18\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #6471: docs(free-programming-books-subjects): fixed broke...\n",
            "  Raw comments retrieved: 2\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #7034: fix: homogenize authoring format and place...\n",
            "  Raw comments retrieved: 3\n",
            "  Quality comments after filtering: 1\n",
            "Searching for PRs with comments in vinta/awesome-python\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #2497: Draft PR\n",
            "Found 98 substantial PRs\n",
            "  Processing PR #2292: add ruff ...\n",
            "  Raw comments retrieved: 24\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1753: Add Beanie...\n",
            "  Raw comments retrieved: 11\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #2611: :triangular_flag_on_post: an extra accuracy README...\n",
            "  Raw comments retrieved: 4\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1723: add pydantic...\n",
            "  Raw comments retrieved: 16\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #441: Add \"Continuous Integration services\" section...\n",
            "  Raw comments retrieved: 4\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #607: Add hug to REST frameworks list...\n",
            "  Raw comments retrieved: 16\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #1350: Add copier...\n",
            "  Raw comments retrieved: 14\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #723: Added \"church\" to Testing...\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #427: Added the Hitch integration testing framework....\n",
            "  Raw comments retrieved: 10\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #471: Added marshmellow...\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 1\n",
            "Searching for PRs with comments in TheAlgorithms/Python\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #7364: No comments\n",
            "    Filtered out PR #4518: No comments\n",
            "    Filtered out PR #4669: No comments\n",
            "    Filtered out PR #2459: Draft PR\n",
            "Found 83 substantial PRs\n",
            "  Processing PR #7092: add basic blockchain and detection of tempering...\n",
            "  Raw comments retrieved: 3\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #7106: XGBoost Classifier...\n",
            "  Raw comments retrieved: 13\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #11859: Chore: Game Theory algorithms are missing #11804...\n",
            "  Raw comments retrieved: 1\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #11036: Add FuzzySet Class for Triangular Fuzzy Sets...\n",
            "  Raw comments retrieved: 7\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #12082: Adding LSTM algorithm from scratch in neural netwo...\n",
            "  Raw comments retrieved: 1\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #5232: Python Kinematics...\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #4298: Add algorithm for N-body simulation - retry...\n",
            "  Raw comments retrieved: 2\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #7572: added file in graph...\n",
            "  Raw comments retrieved: 1\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #8730: Improved Graph Implementations...\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #11611: Create function_optimization.py...\n",
            "  Raw comments retrieved: 2\n",
            "  Quality comments after filtering: 0\n",
            "Searching for PRs with comments in Significant-Gravitas/AutoGPT\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #9621: Draft PR\n",
            "    Filtered out PR #9543: Draft PR\n",
            "    Filtered out PR #8306: Draft PR\n",
            "    Filtered out PR #3316: Draft PR\n",
            "    Filtered out PR #7142: Draft PR\n",
            "    Filtered out PR #4547: Draft PR\n",
            "    Filtered out PR #4299: Draft PR\n",
            "Found 93 substantial PRs\n",
            "  Processing PR #4208: Vector memory revamp (part 1: refactoring)...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #9956: feat(frontend,backend): Redesign block menu on bui...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #9946: feat(block): Add Ayrshare integration for social m...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #7054: feat(agent): Component-based Agents...\n",
            "  Raw comments retrieved: 10\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #10074: feat(platform): Add Block Development SDK with aut...\n",
            "  Raw comments retrieved: 25\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #7170: feat(forge): Component-specific configuration...\n",
            "  Raw comments retrieved: 17\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #8358: feat(platform, blocks): Webhook-triggered blocks...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #4799: Agent loop v2: Planning & Task Management (part 1:...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #3969: Re-arch hello world...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #4683: OpenAI Functions Support...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 0\n",
            "Searching for PRs with comments in nvbn/thefuck\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #1063: Draft PR\n",
            "    Filtered out PR #1082: No comments\n",
            "    Filtered out PR #1210: No comments\n",
            "    Filtered out PR #1243: No comments\n",
            "Found 96 substantial PRs\n",
            "  Processing PR #1302: New rule: fix missing `git clone` when given a URL...\n",
            "  Raw comments retrieved: 9\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #563: Run flake8 in Travis, fix some errors...\n",
            "  Raw comments retrieved: 23\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1184: Adding devcontainer for easy Python development...\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1292: #1282 git misspelled...\n",
            "  Raw comments retrieved: 15\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1100: Globalize pyenv rule ...\n",
            "  Raw comments retrieved: 11\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #130: config.fish: improve documentation on creating Fis...\n",
            "  Raw comments retrieved: 18\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #942: Rule for branch dash 0...\n",
            "  Raw comments retrieved: 9\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1007: Fix Issue #959: breaks after composer require with...\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1393: feat: new rule for `nix-shell`...\n",
            "  Raw comments retrieved: 17\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #532: start work on -y...\n",
            "  Raw comments retrieved: 20\n",
            "  Quality comments after filtering: 1\n",
            "Searching for PRs with comments in fastapi/fastapi\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "Found 100 substantial PRs\n",
            "  Processing PR #5178: 🌐 Add Ukrainian translation for `docs/uk/docs/inde...\n",
            "  Raw comments retrieved: 10\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #4203: 🌐 Add French translation for `docs/fr/docs/index.m...\n",
            "  Raw comments retrieved: 7\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #10502: :globe_with_meridians: Add Turkish translation for...\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #12025: 🌐 Add Spanish translation for `docs/es/docs/contri...\n",
            "  Raw comments retrieved: 18\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #2058: 🌐 Add Japanese translation for Concurrency and asy...\n",
            "  Raw comments retrieved: 11\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #10445: 🌐 Update Turkish translation for `docs/tr/docs/pyt...\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #9675: 🌐 Add Russian translation for `docs/ru/docs/tutori...\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #12489: 🌐 Add Traditional Chinese translation for `docs/zh...\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #10505: 🌐 Initialize translations for Traditional Chinese...\n",
            "  Raw comments retrieved: 23\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #10599: 🌐 Add Russian translation for `docs/ru/docs/tutori...\n",
            "  Raw comments retrieved: 15\n",
            "  Quality comments after filtering: 1\n",
            "Searching for PRs with comments in openai/whisper\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #1483: No comments\n",
            "    Filtered out PR #991: Draft PR\n",
            "Found 98 substantial PRs\n",
            "  Processing PR #382: Uses MPS (Mac acceleration) by default when availa...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #869: word-level timestamps in `transcribe()`...\n",
            "  Raw comments retrieved: 15\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1838: Skip silence around hallucinations...\n",
            "  Raw comments retrieved: 27\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #43: [Do not land] [RFC] 1.375x speedup - Remove contro...\n",
            "  Raw comments retrieved: 15\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1052: attempt to fix the repetition/hallucination issue ...\n",
            "  Raw comments retrieved: 15\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1119: Per Token Confidence + Color terminal example...\n",
            "  Raw comments retrieved: 14\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1040: add always_use_initial_prompt...\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1250: Replaced 'no' langauge code with 'nb' and use full...\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1473: Add support for AMD GPU (ROCm Platform)...\n",
            "  Raw comments retrieved: 10\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #228: Add CSV formatted output in transcript, using inte...\n",
            "  Raw comments retrieved: 8\n",
            "  Quality comments after filtering: 1\n",
            "Searching for PRs with comments in django/django\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "Found 100 substantial PRs\n",
            "  Processing PR #2692: #22667 replaced occurrences of master/slave termin...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #18056: Fixed #373 -- Added CompositePrimaryKey....\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #3114: [Soc2014] Official meta API...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #6385: Fixed #14370 -- Added select2 widget for related o...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #376: Schema alteration...\n",
            "  Raw comments retrieved: 17\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #11452: Fixed #12990 -- Added JSONField model field....\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1364: Checking framework...\n",
            "  Raw comments retrieved: 16\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #9622: Refs #28643 -- Added math database functions....\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #15687: Fixed #33308 -- Added support for psycopg version ...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #14437: Fixed #33012 -- Added Redis cache backend....\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "Searching for PRs with comments in 3b1b/manim\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #241: No comments\n",
            "    Filtered out PR #242: No comments\n",
            "    Filtered out PR #183: No comments\n",
            "Found 95 substantial PRs\n",
            "  Processing PR #1018: Code() in file Code_mobject.py to display code wit...\n",
            "  Raw comments retrieved: 30\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1071: Fixed Some bugs of code_mobject.py and Text_mobjec...\n",
            "  Raw comments retrieved: 27\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1035: Fix space characters problem of Text...\n",
            "  Raw comments retrieved: 17\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #7: Docker Support...\n",
            "  Raw comments retrieved: 20\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #1366: Refactor the structure of the package and add conf...\n",
            "  Raw comments retrieved: 20\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1036: Code() in file Code_mobject.py to display code wit...\n",
            "  Raw comments retrieved: 19\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1336: Package manimlib and automatically publish to pypi...\n",
            "  Raw comments retrieved: 19\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #1326: Interactive Mobjects Performance Improvements...\n",
            "  Raw comments retrieved: 12\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #680: New Text Mobject...\n",
            "  Raw comments retrieved: 16\n",
            "  Quality comments after filtering: 0\n",
            "  Processing PR #580: Update learning_by_example.rst...\n",
            "  Raw comments retrieved: 3\n",
            "  Quality comments after filtering: 1\n",
            "Searching for PRs with comments in bregman-arie/devops-exercises\n",
            "  Total PRs found: 100\n",
            "    Filtering 100 PRs...\n",
            "    Filtered out PR #343: No comments\n",
            "    Filtered out PR #124: No comments\n",
            "    Filtered out PR #106: No comments\n",
            "Found 78 substantial PRs\n",
            "  Processing PR #229: Added security answers and questions...\n",
            "  Raw comments retrieved: 4\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #104: Adding Anthos on GCP and K8s questions...\n",
            "  Raw comments retrieved: 5\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #45: Updated the Beginners Section of Terraform...\n",
            "  Raw comments retrieved: 4\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #195: Added the answer for the question: 'How Web Server...\n",
            "  Raw comments retrieved: 5\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #244: Added Grafana questions and answers...\n",
            "  Raw comments retrieved: 3\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #115: Added Cloud answers...\n",
            "  Raw comments retrieved: 1\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #358: added more exercises and solutions for shell scrip...\n",
            "  Raw comments retrieved: 4\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #337: Ali...\n",
            "  Raw comments retrieved: 7\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #36: Fix spelling errors...\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "  Processing PR #186: Feature/new perl regex questions and answers...\n",
            "  Raw comments retrieved: 6\n",
            "  Quality comments after filtering: 1\n",
            "\n",
            "Total quality discussions collected: 74\n",
            "Data saved to pr_discussions_cleaned.json\n",
            "\n",
            "=== DISCUSSIONS SUMMARY ===\n",
            "Total items: 74\n",
            "Sample item keys: ['pr_title', 'pr_body', 'pr_number', 'comment_id', 'author', 'body', 'created_at', 'updated_at', 'repository', 'comment_length']\n",
            "First item preview:\n",
            "  pr_title: move the translated documentation files to a docs folder\n",
            "  pr_body: - add translation section in Readme\n",
            "- replace multilinks with a  single link to translation section...\n",
            "  pr_number: 6614\n",
            "\n",
            " Pipeline completed!\n",
            " Collected 55 repositories and 74 discussions\n",
            "\n",
            " Output files:\n",
            "  - high_quality_repos.json\n",
            "  - pr_discussions_cleaned.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('high_quality_repos.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "NTVQdrAdQDHl",
        "outputId": "f56a0705-cc92-43b3-f111-133bcb7c76b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'id': 13491895, 'name': 'free-programming-books', 'full_name': 'EbookFoundation/free-programming-books', 'description': ':books: Freely available programming books', 'stars': 363434, 'forks': 63796, 'language': 'Python', 'open_issues': 37, 'updated_at': '2025-07-22T03:23:53Z', 'pushed_at': '2025-06-28T02:59:36Z', 'license': 'Creative Commons Attribution 4.0 International', 'size': 19604, 'has_wiki': False, 'has_pages': True, 'url': 'https://github.com/EbookFoundation/free-programming-books'}, {'id': 21289110, 'name': 'awesome-python', 'full_name': 'vinta/awesome-python', 'description': 'An opinionated list of awesome Python frameworks, libraries, software and resources.', 'stars': 251296, 'forks': 26012, 'language': 'Python', 'open_issues': 479, 'updated_at': '2025-07-22T03:38:59Z', 'pushed_at': '2025-07-17T16:35:51Z', 'license': 'Other', 'size': 6839, 'has_wiki': False, 'has_pages': True, 'url': 'https://github.com/vinta/awesome-python'}, {'id': 63476337, 'name': 'Python', 'full_name': 'TheAlgorithms/Python', 'description': 'All Algorithms implemented in Python', 'stars': 203110, 'forks': 47084, 'language': 'Python', 'open_issues': 414, 'updated_at': '2025-07-22T03:01:20Z', 'pushed_at': '2025-07-21T19:29:29Z', 'license': 'MIT License', 'size': 15436, 'has_wiki': True, 'has_pages': True, 'url': 'https://github.com/TheAlgorithms/Python'}, {'id': 614765452, 'name': 'AutoGPT', 'full_name': 'Significant-Gravitas/AutoGPT', 'description': 'AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.', 'stars': 177098, 'forks': 45897, 'language': 'Python', 'open_issues': 204, 'updated_at': '2025-07-22T03:30:16Z', 'pushed_at': '2025-07-22T03:25:40Z', 'license': 'Other', 'size': 266197, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/Significant-Gravitas/AutoGPT'}, {'id': 33614304, 'name': 'thefuck', 'full_name': 'nvbn/thefuck', 'description': 'Magnificent app which corrects your previous console command.', 'stars': 92959, 'forks': 3736, 'language': 'Python', 'open_issues': 386, 'updated_at': '2025-07-22T03:03:56Z', 'pushed_at': '2024-07-19T14:56:13Z', 'license': 'MIT License', 'size': 4043, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/nvbn/thefuck'}, {'id': 160919119, 'name': 'fastapi', 'full_name': 'fastapi/fastapi', 'description': 'FastAPI framework, high performance, easy to learn, fast to code, ready for production', 'stars': 87510, 'forks': 7621, 'language': 'Python', 'open_issues': 317, 'updated_at': '2025-07-22T03:00:28Z', 'pushed_at': '2025-07-21T17:30:43Z', 'license': 'MIT License', 'size': 26965, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/fastapi/fastapi'}, {'id': 537603333, 'name': 'whisper', 'full_name': 'openai/whisper', 'description': 'Robust Speech Recognition via Large-Scale Weak Supervision', 'stars': 85267, 'forks': 10433, 'language': 'Python', 'open_issues': 89, 'updated_at': '2025-07-22T03:29:57Z', 'pushed_at': '2025-06-26T01:05:52Z', 'license': 'MIT License', 'size': 12789, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/openai/whisper'}, {'id': 4164482, 'name': 'django', 'full_name': 'django/django', 'description': 'The Web framework for perfectionists with deadlines.', 'stars': 84305, 'forks': 32731, 'language': 'Python', 'open_issues': 360, 'updated_at': '2025-07-22T01:24:01Z', 'pushed_at': '2025-07-22T01:23:29Z', 'license': 'BSD 3-Clause \"New\" or \"Revised\" License', 'size': 268441, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/django/django'}, {'id': 32689863, 'name': 'manim', 'full_name': '3b1b/manim', 'description': 'Animation engine for explanatory math videos', 'stars': 79020, 'forks': 6797, 'language': 'Python', 'open_issues': 456, 'updated_at': '2025-07-22T02:57:26Z', 'pushed_at': '2025-06-14T15:50:43Z', 'license': 'MIT License', 'size': 76584, 'has_wiki': True, 'has_pages': True, 'url': 'https://github.com/3b1b/manim'}, {'id': 212639071, 'name': 'devops-exercises', 'full_name': 'bregman-arie/devops-exercises', 'description': 'Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions', 'stars': 77671, 'forks': 17417, 'language': 'Python', 'open_issues': 44, 'updated_at': '2025-07-21T22:29:23Z', 'pushed_at': '2025-04-24T19:36:05Z', 'license': 'Other', 'size': 7771, 'has_wiki': True, 'has_pages': True, 'url': 'https://github.com/bregman-arie/devops-exercises'}, {'id': 695864515, 'name': 'Deep-Live-Cam', 'full_name': 'hacksider/Deep-Live-Cam', 'description': 'real time face swap and one-click video deepfake with only a single image', 'stars': 71952, 'forks': 10328, 'language': 'Python', 'open_issues': 94, 'updated_at': '2025-07-22T02:49:48Z', 'pushed_at': '2025-07-09T09:19:26Z', 'license': 'GNU Affero General Public License v3.0', 'size': 155836, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/hacksider/Deep-Live-Cam'}, {'id': 101138315, 'name': 'd2l-zh', 'full_name': 'd2l-ai/d2l-zh', 'description': '《动手学深度学习》：面向中文读者、能运行、可讨论。中英文版被70多个国家的500多所大学用于教学。', 'stars': 70954, 'forks': 11758, 'language': 'Python', 'open_issues': 109, 'updated_at': '2025-07-22T03:22:06Z', 'pushed_at': '2024-07-30T09:32:19Z', 'license': 'Apache License 2.0', 'size': 316965, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/d2l-ai/d2l-zh'}, {'id': 718741813, 'name': 'screenshot-to-code', 'full_name': 'abi/screenshot-to-code', 'description': 'Drop in a screenshot and convert it to clean code (HTML/Tailwind/React/Vue)', 'stars': 70416, 'forks': 8696, 'language': 'Python', 'open_issues': 122, 'updated_at': '2025-07-22T03:07:29Z', 'pushed_at': '2025-07-03T21:04:54Z', 'license': 'MIT License', 'size': 3624, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/abi/screenshot-to-code'}, {'id': 596892, 'name': 'flask', 'full_name': 'pallets/flask', 'description': 'The Python micro framework for building web applications.', 'stars': 70009, 'forks': 16504, 'language': 'Python', 'open_issues': 14, 'updated_at': '2025-07-22T02:54:14Z', 'pushed_at': '2025-06-12T20:48:14Z', 'license': 'BSD 3-Clause \"New\" or \"Revised\" License', 'size': 11028, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/pallets/flask'}, {'id': 616372661, 'name': 'gpt_academic', 'full_name': 'binary-husky/gpt_academic', 'description': '为GPT/GLM等LLM大语言模型提供实用化交互接口，特别优化论文阅读/润色/写作体验，模块化设计，支持自定义快捷按钮&函数插件，支持Python和C++等项目剖析&自译解功能，PDF/LaTex论文翻译&总结功能，支持并行问询多种LLM模型，支持chatglm3等本地模型。接入通义千问, deepseekcoder, 讯飞星火, 文心一言, llama2, rwkv, claude2, moss', 'stars': 68984, 'forks': 8365, 'language': 'Python', 'open_issues': 285, 'updated_at': '2025-07-22T02:44:17Z', 'pushed_at': '2025-07-20T18:18:51Z', 'license': 'GNU General Public License v3.0', 'size': 72488, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/binary-husky/gpt_academic'}, {'id': 888092115, 'name': 'markitdown', 'full_name': 'microsoft/markitdown', 'description': 'Python tool for converting files and office documents to Markdown.', 'stars': 68831, 'forks': 3669, 'language': 'Python', 'open_issues': 333, 'updated_at': '2025-07-22T03:33:45Z', 'pushed_at': '2025-06-04T04:09:25Z', 'license': 'MIT License', 'size': 3240, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/microsoft/markitdown'}, {'id': 71220757, 'name': 'PayloadsAllTheThings', 'full_name': 'swisskyrepo/PayloadsAllTheThings', 'description': 'A list of useful payloads and bypass for Web Application Security and Pentest/CTF', 'stars': 68586, 'forks': 15708, 'language': 'Python', 'open_issues': 25, 'updated_at': '2025-07-22T02:22:42Z', 'pushed_at': '2025-07-19T09:06:54Z', 'license': 'MIT License', 'size': 23287, 'has_wiki': False, 'has_pages': True, 'url': 'https://github.com/swisskyrepo/PayloadsAllTheThings'}, {'id': 162998479, 'name': 'sherlock', 'full_name': 'sherlock-project/sherlock', 'description': 'Hunt down social media accounts by username across social networks', 'stars': 67107, 'forks': 7708, 'language': 'Python', 'open_issues': 233, 'updated_at': '2025-07-22T02:11:18Z', 'pushed_at': '2025-05-06T09:55:10Z', 'license': 'MIT License', 'size': 17823, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/sherlock-project/sherlock'}, {'id': 620936652, 'name': 'gpt4free', 'full_name': 'xtekky/gpt4free', 'description': 'The official gpt4free repository | various collection of powerful language models | o4, o3 and deepseek r1, gpt-4.1, gemini 2.5', 'stars': 64705, 'forks': 13671, 'language': 'Python', 'open_issues': 10, 'updated_at': '2025-07-21T22:49:20Z', 'pushed_at': '2025-07-21T15:36:03Z', 'license': 'GNU General Public License v3.0', 'size': 168277, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/xtekky/gpt4free'}, {'id': 33015583, 'name': 'keras', 'full_name': 'keras-team/keras', 'description': 'Deep Learning for humans', 'stars': 63225, 'forks': 19589, 'language': 'Python', 'open_issues': 297, 'updated_at': '2025-07-22T03:43:22Z', 'pushed_at': '2025-07-21T15:27:19Z', 'license': 'Apache License 2.0', 'size': 47019, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/keras-team/keras'}, {'id': 290091948, 'name': 'annotated_deep_learning_paper_implementations', 'full_name': 'labmlai/annotated_deep_learning_paper_implementations', 'description': '🧑\\u200d🏫 60+ Implementations/tutorials of deep learning papers with side-by-side notes 📝; including transformers (original, xl, switch, feedback, vit, ...), optimizers (adam, adabelief, sophia, ...), gans(', 'stars': 62056, 'forks': 6280, 'language': 'Python', 'open_issues': 27, 'updated_at': '2025-07-22T03:13:07Z', 'pushed_at': '2025-07-20T05:10:58Z', 'license': 'MIT License', 'size': 153370, 'has_wiki': True, 'has_pages': True, 'url': 'https://github.com/labmlai/annotated_deep_learning_paper_implementations'}, {'id': 771302083, 'name': 'OpenHands', 'full_name': 'All-Hands-AI/OpenHands', 'description': '🙌 OpenHands: Code Less, Make More', 'stars': 60890, 'forks': 7189, 'language': 'Python', 'open_issues': 402, 'updated_at': '2025-07-22T03:34:12Z', 'pushed_at': '2025-07-22T02:00:11Z', 'license': 'MIT License', 'size': 216852, 'has_wiki': True, 'has_pages': True, 'url': 'https://github.com/All-Hands-AI/OpenHands'}, {'id': 666299222, 'name': 'open-interpreter', 'full_name': 'openinterpreter/open-interpreter', 'description': 'A natural language interface for computers', 'stars': 60017, 'forks': 5114, 'language': 'Python', 'open_issues': 272, 'updated_at': '2025-07-22T02:58:26Z', 'pushed_at': '2025-04-23T07:18:30Z', 'license': 'GNU Affero General Public License v3.0', 'size': 100324, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/openinterpreter/open-interpreter'}, {'id': 71948498, 'name': 'localstack', 'full_name': 'localstack/localstack', 'description': '💻 A fully functional local AWS cloud stack. Develop and test your cloud & Serverless apps offline', 'stars': 59757, 'forks': 4196, 'language': 'Python', 'open_issues': 308, 'updated_at': '2025-07-22T03:17:41Z', 'pushed_at': '2025-07-21T19:54:30Z', 'license': 'Other', 'size': 53102, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/localstack/localstack'}, {'id': 601538369, 'name': 'llama', 'full_name': 'meta-llama/llama', 'description': 'Inference code for Llama models', 'stars': 58539, 'forks': 9786, 'language': 'Python', 'open_issues': 493, 'updated_at': '2025-07-22T02:58:54Z', 'pushed_at': '2025-01-26T21:42:26Z', 'license': 'Other', 'size': 1150, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/meta-llama/llama'}, {'id': 660551251, 'name': 'MetaGPT', 'full_name': 'FoundationAgents/MetaGPT', 'description': '🌟 The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming', 'stars': 57373, 'forks': 6896, 'language': 'Python', 'open_issues': 61, 'updated_at': '2025-07-22T03:39:52Z', 'pushed_at': '2025-06-30T11:45:55Z', 'license': 'MIT License', 'size': 184056, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/FoundationAgents/MetaGPT'}, {'id': 635240594, 'name': 'private-gpt', 'full_name': 'zylon-ai/private-gpt', 'description': 'Interact with your documents using the power of GPT, 100% privately, no data leaks', 'stars': 56318, 'forks': 7552, 'language': 'Python', 'open_issues': 275, 'updated_at': '2025-07-22T01:08:18Z', 'pushed_at': '2024-11-13T19:30:32Z', 'license': 'Apache License 2.0', 'size': 2778, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/zylon-ai/private-gpt'}, {'id': 5483330, 'name': 'you-get', 'full_name': 'soimort/you-get', 'description': ':arrow_double_down: Dumb downloader that scrapes the web', 'stars': 56038, 'forks': 9780, 'language': 'Python', 'open_issues': 382, 'updated_at': '2025-07-22T03:43:46Z', 'pushed_at': '2025-04-27T15:33:25Z', 'license': 'Other', 'size': 3533, 'has_wiki': True, 'has_pages': True, 'url': 'https://github.com/soimort/you-get'}, {'id': 74627617, 'name': 'openpilot', 'full_name': 'commaai/openpilot', 'description': 'openpilot is an operating system for robotics. Currently, it upgrades the driver assistance system on 300+ supported cars.', 'stars': 55496, 'forks': 9959, 'language': 'Python', 'open_issues': 162, 'updated_at': '2025-07-22T03:30:26Z', 'pushed_at': '2025-07-22T03:41:40Z', 'license': 'MIT License', 'size': 1025490, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/commaai/openpilot'}, {'id': 188660663, 'name': 'Real-Time-Voice-Cloning', 'full_name': 'CorentinJ/Real-Time-Voice-Cloning', 'description': 'Clone a voice in 5 seconds to generate arbitrary speech in real-time', 'stars': 54738, 'forks': 9038, 'language': 'Python', 'open_issues': 223, 'updated_at': '2025-07-22T02:48:14Z', 'pushed_at': '2025-05-30T11:41:05Z', 'license': 'Other', 'size': 369678, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/CorentinJ/Real-Time-Voice-Cloning'}, {'id': 264818686, 'name': 'yolov5', 'full_name': 'ultralytics/yolov5', 'description': 'YOLOv5 🚀 in PyTorch > ONNX > CoreML > TFLite', 'stars': 54714, 'forks': 17072, 'language': 'Python', 'open_issues': 283, 'updated_at': '2025-07-22T03:41:55Z', 'pushed_at': '2025-07-14T04:50:34Z', 'license': 'GNU Affero General Public License v3.0', 'size': 16998, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/ultralytics/yolov5'}, {'id': 634224458, 'name': 'gpt-engineer', 'full_name': 'AntonOsika/gpt-engineer', 'description': 'CLI platform to experiment with codegen. Precursor to: https://lovable.dev', 'stars': 54551, 'forks': 7208, 'language': 'Python', 'open_issues': 45, 'updated_at': '2025-07-22T03:06:33Z', 'pushed_at': '2025-05-14T10:15:10Z', 'license': 'MIT License', 'size': 20474, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/AntonOsika/gpt-engineer'}, {'id': 114747226, 'name': 'faceswap', 'full_name': 'deepfakes/faceswap', 'description': 'Deepfakes Software For All', 'stars': 54277, 'forks': 13425, 'language': 'Python', 'open_issues': 39, 'updated_at': '2025-07-22T02:31:47Z', 'pushed_at': '2025-07-11T17:20:12Z', 'license': 'GNU General Public License v3.0', 'size': 203600, 'has_wiki': False, 'has_pages': True, 'url': 'https://github.com/deepfakes/faceswap'}, {'id': 1362490, 'name': 'requests', 'full_name': 'psf/requests', 'description': 'A simple, yet elegant, HTTP library.', 'stars': 53072, 'forks': 9506, 'language': 'Python', 'open_issues': 269, 'updated_at': '2025-07-22T02:54:47Z', 'pushed_at': '2025-07-18T16:24:31Z', 'license': 'Apache License 2.0', 'size': 13200, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/psf/requests'}, {'id': 254832799, 'name': 'hackingtool', 'full_name': 'Z4nzu/hackingtool', 'description': 'ALL IN ONE Hacking Tool For Hackers', 'stars': 53031, 'forks': 5724, 'language': 'Python', 'open_issues': 64, 'updated_at': '2025-07-22T01:28:59Z', 'pushed_at': '2025-03-03T15:17:19Z', 'license': 'MIT License', 'size': 1367, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/Z4nzu/hackingtool'}, {'id': 220809393, 'name': 'rich', 'full_name': 'Textualize/rich', 'description': 'Rich is a Python library for rich text and beautiful formatting in the terminal.', 'stars': 52942, 'forks': 1858, 'language': 'Python', 'open_issues': 280, 'updated_at': '2025-07-22T01:39:08Z', 'pushed_at': '2025-06-24T13:02:12Z', 'license': 'MIT License', 'size': 50248, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/Textualize/rich'}, {'id': 262296122, 'name': 'PaddleOCR', 'full_name': 'PaddlePaddle/PaddleOCR', 'description': 'Awesome multilingual OCR and Document Parsing toolkits based on PaddlePaddle (practical ultra lightweight OCR system, support 80+ languages recognition, provide data annotation and synthesis tools, su', 'stars': 51804, 'forks': 8441, 'language': 'Python', 'open_issues': 216, 'updated_at': '2025-07-22T03:28:07Z', 'pushed_at': '2025-07-17T03:18:42Z', 'license': 'Apache License 2.0', 'size': 1474225, 'has_wiki': False, 'has_pages': True, 'url': 'https://github.com/PaddlePaddle/PaddleOCR'}, {'id': 793375104, 'name': 'awesome-llm-apps', 'full_name': 'Shubhamsaboo/awesome-llm-apps', 'description': 'Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.', 'stars': 50834, 'forks': 5934, 'language': 'Python', 'open_issues': 8, 'updated_at': '2025-07-22T03:19:24Z', 'pushed_at': '2025-07-19T15:37:39Z', 'license': 'Apache License 2.0', 'size': 172444, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/Shubhamsaboo/awesome-llm-apps'}, {'id': 798201435, 'name': 'crawl4ai', 'full_name': 'unclecode/crawl4ai', 'description': \"🚀🤖 Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN\", 'stars': 48861, 'forks': 4739, 'language': 'Python', 'open_issues': 244, 'updated_at': '2025-07-22T03:42:59Z', 'pushed_at': '2025-07-21T13:19:41Z', 'license': 'Apache License 2.0', 'size': 145194, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/unclecode/crawl4ai'}, {'id': 680120071, 'name': 'autogen', 'full_name': 'microsoft/autogen', 'description': 'A programming framework for agentic AI 🤖 PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour', 'stars': 47672, 'forks': 7256, 'language': 'Python', 'open_issues': 460, 'updated_at': '2025-07-22T03:39:56Z', 'pushed_at': '2025-07-21T17:09:44Z', 'license': 'Creative Commons Attribution 4.0 International', 'size': 147133, 'has_wiki': False, 'has_pages': True, 'url': 'https://github.com/microsoft/autogen'}, {'id': 40416236, 'name': 'big-list-of-naughty-strings', 'full_name': 'minimaxir/big-list-of-naughty-strings', 'description': 'The Big List of Naughty Strings is a list of strings which have a high probability of causing issues when used as user-input data.', 'stars': 47322, 'forks': 2157, 'language': 'Python', 'open_issues': 108, 'updated_at': '2025-07-21T22:46:04Z', 'pushed_at': '2024-04-18T03:26:59Z', 'license': 'MIT License', 'size': 330, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/minimaxir/big-list-of-naughty-strings'}, {'id': 676676006, 'name': 'Fooocus', 'full_name': 'lllyasviel/Fooocus', 'description': 'Focus on prompting and generating', 'stars': 45814, 'forks': 7289, 'language': 'Python', 'open_issues': 266, 'updated_at': '2025-07-22T03:22:14Z', 'pushed_at': '2025-01-24T10:55:35Z', 'license': 'GNU General Public License v3.0', 'size': 34059, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/lllyasviel/Fooocus'}, {'id': 323048702, 'name': 'OpenBB', 'full_name': 'OpenBB-finance/OpenBB', 'description': 'Investment Research for Everyone, Everywhere.', 'stars': 43715, 'forks': 3943, 'language': 'Python', 'open_issues': 55, 'updated_at': '2025-07-22T03:43:23Z', 'pushed_at': '2025-07-21T15:36:07Z', 'license': 'Other', 'size': 2357795, 'has_wiki': False, 'has_pages': True, 'url': 'https://github.com/OpenBB-finance/OpenBB'}, {'id': 560704231, 'name': 'llama_index', 'full_name': 'run-llama/llama_index', 'description': 'LlamaIndex is the leading framework for building LLM-powered agents over your data.', 'stars': 43247, 'forks': 6211, 'language': 'Python', 'open_issues': 277, 'updated_at': '2025-07-22T03:31:31Z', 'pushed_at': '2025-07-21T22:29:35Z', 'license': 'MIT License', 'size': 315921, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/run-llama/llama_index'}, {'id': 582822129, 'name': 'nanoGPT', 'full_name': 'karpathy/nanoGPT', 'description': 'The simplest, fastest repository for training/finetuning medium-sized GPTs.', 'stars': 43046, 'forks': 7220, 'language': 'Python', 'open_issues': 299, 'updated_at': '2025-07-22T02:15:55Z', 'pushed_at': '2024-12-09T23:53:04Z', 'license': 'MIT License', 'size': 953, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/karpathy/nanoGPT'}, {'id': 265612440, 'name': 'TTS', 'full_name': 'coqui-ai/TTS', 'description': '🐸💬 - a deep learning toolkit for Text-to-Speech, battle-tested in research and production', 'stars': 41538, 'forks': 5405, 'language': 'Python', 'open_issues': 9, 'updated_at': '2025-07-22T03:40:24Z', 'pushed_at': '2024-08-16T12:07:14Z', 'license': 'Mozilla Public License 2.0', 'size': 170196, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/coqui-ai/TTS'}, {'id': 569927055, 'name': 'stablediffusion', 'full_name': 'Stability-AI/stablediffusion', 'description': 'High-Resolution Image Synthesis with Latent Diffusion Models', 'stars': 41399, 'forks': 5284, 'language': 'Python', 'open_issues': 297, 'updated_at': '2025-07-22T02:30:33Z', 'pushed_at': '2025-06-25T14:18:37Z', 'license': 'MIT License', 'size': 75202, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/Stability-AI/stablediffusion'}, {'id': 237791077, 'name': 'diagrams', 'full_name': 'mingrammer/diagrams', 'description': ':art: Diagram as Code for prototyping cloud system architectures', 'stars': 41198, 'forks': 2650, 'language': 'Python', 'open_issues': 379, 'updated_at': '2025-07-21T22:29:23Z', 'pushed_at': '2025-07-20T11:07:56Z', 'license': 'MIT License', 'size': 61553, 'has_wiki': True, 'has_pages': True, 'url': 'https://github.com/mingrammer/diagrams'}, {'id': 422274596, 'name': 'ColossalAI', 'full_name': 'hpcaitech/ColossalAI', 'description': 'Making large AI models cheaper, faster and more accessible', 'stars': 41044, 'forks': 4524, 'language': 'Python', 'open_issues': 474, 'updated_at': '2025-07-21T20:09:42Z', 'pushed_at': '2025-07-22T02:02:05Z', 'license': 'Apache License 2.0', 'size': 66256, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/hpcaitech/ColossalAI'}, {'id': 125266328, 'name': 'black', 'full_name': 'psf/black', 'description': 'The uncompromising Python code formatter', 'stars': 40707, 'forks': 2617, 'language': 'Python', 'open_issues': 368, 'updated_at': '2025-07-22T02:28:07Z', 'pushed_at': '2025-07-21T07:54:11Z', 'license': 'MIT License', 'size': 7269, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/psf/black'}, {'id': 91629816, 'name': 'freqtrade', 'full_name': 'freqtrade/freqtrade', 'description': 'Free, open source crypto trading bot', 'stars': 40674, 'forks': 8162, 'language': 'Python', 'open_issues': 37, 'updated_at': '2025-07-22T01:03:47Z', 'pushed_at': '2025-07-22T03:30:49Z', 'license': 'GNU General Public License v3.0', 'size': 600025, 'has_wiki': True, 'has_pages': True, 'url': 'https://github.com/freqtrade/freqtrade'}, {'id': 765083837, 'name': 'MinerU', 'full_name': 'opendatalab/MinerU', 'description': 'A high-quality tool for convert PDF to Markdown and JSON.一站式开源高质量数据提取工具，将PDF转换成Markdown和JSON格式。', 'stars': 40331, 'forks': 3307, 'language': 'Python', 'open_issues': 121, 'updated_at': '2025-07-22T03:34:39Z', 'pushed_at': '2025-07-21T09:32:41Z', 'license': 'GNU Affero General Public License v3.0', 'size': 135484, 'has_wiki': False, 'has_pages': True, 'url': 'https://github.com/opendatalab/MinerU'}, {'id': 519832, 'name': 'mitmproxy', 'full_name': 'mitmproxy/mitmproxy', 'description': 'An interactive TLS-capable intercepting HTTP proxy for penetration testers and software developers.', 'stars': 39868, 'forks': 4257, 'language': 'Python', 'open_issues': 365, 'updated_at': '2025-07-22T03:02:01Z', 'pushed_at': '2025-07-14T07:32:19Z', 'license': 'MIT License', 'size': 66656, 'has_wiki': False, 'has_pages': False, 'url': 'https://github.com/mitmproxy/mitmproxy'}, {'id': 90563585, 'name': 'cheat.sh', 'full_name': 'chubin/cheat.sh', 'description': 'the only cheat sheet you need', 'stars': 39646, 'forks': 1831, 'language': 'Python', 'open_issues': 139, 'updated_at': '2025-07-22T03:01:55Z', 'pushed_at': '2025-02-01T13:32:00Z', 'license': 'MIT License', 'size': 4538, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/chubin/cheat.sh'}, {'id': 162405963, 'name': 'gradio', 'full_name': 'gradio-app/gradio', 'description': 'Build and share delightful machine learning apps, all in Python. 🌟 Star to support our work!', 'stars': 39123, 'forks': 2987, 'language': 'Python', 'open_issues': 452, 'updated_at': '2025-07-22T00:27:56Z', 'pushed_at': '2025-07-21T14:38:00Z', 'license': 'Apache License 2.0', 'size': 298942, 'has_wiki': True, 'has_pages': False, 'url': 'https://github.com/gradio-app/gradio'}]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d9e7fec1-ad9e-4080-b2a6-836763509bba\", \"high_quality_repos.json\", 29387)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('pr_discussions_cleaned.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oVc3-9fhjsbt",
        "outputId": "8f20cdc4-a036-4931-93e8-a071200a073e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_db80cabc-6be8-4f6b-9694-0d8f41fc563b\", \"pr_discussions_cleaned.json\", 73376)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}