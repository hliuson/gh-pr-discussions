[
  {
    "index": 1,
    "filtered_comments": [
      "The PR fails to meet some basic requirements but shows a good effort. Issues:\n1. The PR template is not properly filled out - missing test plan and checklist items\n2. While the scope is clear (frontend) and shown in the title correctly, documentation of changes could be clearer\n3. No clear explanation in PR body about 'why' these changes were needed\n4. No test plan or testing notes provided for such a large UI change\n\nHowever, the code itself looks well-structured with clear component organization and documentation. The TODO comments also show good forward planning.",
      "## Feedback for PR Improvement\n\n### Missing PR Template & Checklist\nPlease fill out the complete PR template, including the checklist section. This is required for all PRs and helps reviewers understand what's being changed and how it's been tested.\n\n### Scope Mismatch\nYour PR title mentions only frontend changes (`feat(frontend)`), but the diff shows significant backend additions including:\n- New API routes in `/api/builder/`\n- New DB functions and models\n- Changes to store routes\n\nPlease update your title to reflect both frontend and backend changes, or better explain in the description why backend changes were needed for this frontend redesign.\n\n### User ID Validation\nSome of the new backend functions in `backend/server/v2/builder/db.py` don't appear to validate user permissions via user_id. Please review these functions to ensure proper authorization is in place or provide an explanation for why user_id checks aren't needed.\n\n### Merge Conflicts\nThis PR has merge conflicts that need to be resolved before it can be merged.\n\n### Testing\nPlease include information about how you've tested these changes, particularly since they span both frontend and backend components.\n\nOnce you've addressed these issues, the PR should be ready for re-review.",
      "Thank you for your work on redesigning the block menu. This looks like a substantial change that will improve the builder page experience. \n\nHowever, there are a few things that need to be addressed before this PR can be merged:\n\n1. **Missing checklist**: Please complete the PR template checklist. For code changes like these, we need to know that you've tested your changes with a clear test plan.\n\n2. **Scope discrepancy**: Your PR title mentions only frontend changes, but the diff includes significant backend changes - new routes, endpoints, and database access functions. Please update your PR title to reflect that this is both a frontend and backend feature, perhaps something like `feat(frontend,backend): Redesign block menu on builder page`.\n\n3. **Implementation details**: Your PR description lists the components you've added but doesn't explain how they work together or what specific improvements they bring. Please enhance the description with more details about the implementation and how it improves upon the previous design.\n\n4. **Test plan**: Please add a test plan to your PR description explaining how you've tested these changes.\n\nThe code itself looks well-structured with proper authentication handling and user_id checks. I particularly like how you've organized the new components and the backend routes to support them. Once you address the above points, this PR should be ready for another review.",
      "Thank you for your work on redesigning the block menu! I have a few comments before this can be merged:\n\n## Description and Checklist\n- Please update your PR description to include a more detailed explanation of the changes you've made\n- The required PR checklist is missing. Please add the checklist from the PR template and check off the appropriate items\n\n## Scope Mismatch\nYour PR title indicates this is a frontend feature (`feat(frontend)`), but the changes include substantial backend code, including:\n- New backend routes in `/api/builder`\n- New database functions in `backend/server/v2/builder/db.py`\n- New models in `backend/server/v2/builder/model.py`\n\nConsider updating your PR title to reflect that this involves both frontend and backend changes, perhaps something like `feat(platform): Redesign block menu on builder page with backend support`\n\n## Test Plan\nPlease include a test plan in your PR description to explain how you've tested these changes.\n\nOnce these items are addressed, we can proceed with reviewing the technical aspects of the implementation. The component list and structure looks well-organized!",
      "Thank you for your work on redesigning the block menu! I have a few concerns about this PR that need to be addressed before it can be merged:\n\n1. **PR Description:** While you've listed the components you've added, the PR description should explain why these changes are needed and provide more context about the redesign goals.\n\n2. **Missing Checklist:** Your PR description is missing the required checklist section that outlines your test plan and confirms you've tested the changes appropriately. Please update your PR description to include the complete checklist.\n\n3. **Scope Mismatch:** The PR title indicates this is a frontend change, but the diff shows substantial backend changes including:\n   - New backend routes in `/api/builder`\n   - New database functions and models\n   - Changes to the store API\n\n   Please update either the PR title to reflect the full scope of changes (e.g., `feat(frontend,backend): Redesign block menu and add builder API endpoints`) or separate the backend changes into a different PR.\n\n4. **Dependencies:** You've added several new dependencies (`react-timeago`, `tailwind-scrollbar`, `tailwind-scrollbar-hide`). Please ensure these are necessary and document their purpose in the PR description.\n\n5. **Testing:** Please describe how you've tested these changes, especially the new backend routes and functionality.\n\nAdditionally, I see there's a conflicts label on this PR. Please resolve any merge conflicts before this can be approved.\n\nOnce you've addressed these issues, I'll be happy to review the PR again.",
      "Thank you for your PR to redesign the block menu! The component list you provided is helpful for understanding what's been added. I have some feedback to help get this PR ready for merging:\n\n1. **Missing checklist**: This PR contains significant code changes but is missing the required checklist. Please add the checklist from the PR template and ensure you've tested all changes appropriately.\n\n2. **Scope mismatch**: While your title mentions frontend changes, a significant portion of this PR adds backend functionality (new routes, models, and database operations for the builder). Please update your PR title to reflect both frontend and backend changes, e.g., `feat(frontend,backend): Redesign block menu and add builder API endpoints`.\n\n3. **PR description improvements**: Consider expanding your description to mention the backend API endpoints you've added to support the block menu functionality.\n\nOnce you've addressed these items, we'll be able to review your PR again. The code changes themselves look good - I like the organized approach with the reusable components and the proper handling of user_id in the backend routes.",
      "Thanks for the PR to redesign the block menu! The implementation looks comprehensive with both frontend components and backend support.\n\n### Feedback\n\n1. **PR Description Improvements**:\n   - The PR description is missing the required checklist from the template. Please add the checklist sections for code changes and make sure all items are checked off.\n   - While you've described the frontend components well, please also mention the significant backend changes (new API routes in `/api/builder`, pagination model extensions, etc.) that support this feature.\n\n2. **Implementation Notes**:\n   - The changes include backend routes and models to support the block menu functionality, which is good but should be mentioned in the PR description.\n   - I notice you've added several new npm packages (`react-timeago`, `tailwind-scrollbar`, etc.) - please include these in your description of changes.\n\n3. **Code Quality**:\n   - The backend implementation looks solid with well-structured endpoints and models.\n   - Good job on the TODO markers for future work.\n\nPlease update the PR description to include the missing checklist and mention the backend changes that support this feature. Once these items are addressed, the PR will be ready for another review.",
      "Thank you for your PR to redesign the block menu! I've identified a few issues that need to be addressed before this can be merged:\n\n1. **Scope mismatch**: While your PR title indicates this is a frontend change, approximately half of the changes are backend-related (new API endpoints, models, database functions). The PR title and description should accurately reflect all major components being changed.\n\n2. **Missing checklist**: For substantial code changes like this, the PR template checklist needs to be completed to ensure proper testing and quality checks. Please add the checklist and check off the appropriate items.\n\n3. **Backend changes documentation**: The PR description doesn't mention any of the backend changes. Please update the description to include details about the new backend/server/v2/builder files and endpoints you're adding.\n\nAdditionally, I notice you've marked some items with \"BLOCK MENU TODO:\" for future work. If these are part of this redesign effort but will be addressed in separate PRs, that's fine, but please make that clear in the description.\n\nOnce you've updated the PR title to accurately reflect both frontend and backend changes, completed the required checklist, and expanded the description to cover all major components being changed, we can proceed with the review process.",
      "Thanks for your PR on redesigning the block menu. I noticed a few things that need to be addressed before this can be merged:\n\n1. **Missing Checklist**: Please include the complete PR checklist in your description. Since your changes include significant code modifications, you'll need to add the checklist with appropriate test plans.\n\n2. **Scope Mismatch**: Your PR title only mentions frontend changes (`feat(frontend)`), but the diff shows substantial backend additions including:\n   - New API routes in `/api/builder`\n   - New database functionality\n   - New models and response types\n\n   Please update your PR title to reflect both the frontend and backend changes, perhaps something like `feat(frontend,backend): Redesign block menu on builder page`.\n\n3. **PR Description**: Consider enhancing your description to explain more about the purpose of the backend changes and how they relate to the frontend block menu redesign.\n\nThe changes themselves look promising, but we need to ensure the PR follows our submission guidelines before proceeding with the review of the actual implementation. Please make these updates so we can move forward with the review.",
      "Thank you for your work on redesigning the block menu! I have a few concerns that need to be addressed before this PR can be merged:\n\n1. **Missing Checklist**: The PR description is missing the required checklist. Please update your description to include the standard checklist and fill it out completely.\n\n2. **Scope Mismatch**: The PR title mentions only frontend changes (`feat(frontend)`), but the diff shows significant backend changes as well. Please update the PR title to accurately reflect the scope of your changes. Something like `feat(platform): Redesign block menu on builder page` or `feat(platform/frontend,platform/backend): Redesign block menu on builder page` would be more appropriate.\n\n3. **Backend Changes**: The PR includes substantial backend additions:\n   - New builder routes and endpoints\n   - New database functions and models\n   - Changes to the store API\n\nPlease make sure to include these backend changes in your test plan when you add the checklist.\n\nOnce these items are addressed, we can proceed with the review of the code itself. The overall direction of the redesign looks promising!",
      "Thank you for working on redesigning the block menu. I see you've created several reusable components for this feature.\n\nI have two main concerns with this PR:\n\n1. **Missing Checklist**: Your PR description is missing the required checklist that should cover testing plan and other verification steps. Please update your description to include the standard checklist and fill it out appropriately.\n\n2. **Scope Mismatch**: Your PR title mentions only a frontend redesign, but the changes include significant backend work. I see new backend files for a builder API, including routes, models, and database functionality. The PR title should reflect both frontend and backend changes, something like: `feat(frontend,backend): Redesign block menu and add builder API`\n\nPlease update your PR to address these issues so we can proceed with the review. The code changes themselves look well-structured, but we need to ensure the PR follows our process requirements.\n\nAlso, I noticed you've marked some items with `BLOCK MENU TODO:` for future work. That's a good approach for tracking remaining tasks.",
      "Hi @Abhi1992002, thanks for your work on redesigning the block menu. I have some feedback to help get this PR ready for merging:\n\n## Required Changes\n\n1. **PR Description & Checklist**\n   - Please include the complete PR checklist from our template, including your test plan\n   - The description should explain both the frontend and backend changes\n\n2. **PR Scope**\n   - Your PR title mentions only frontend changes, but there are significant backend changes\n   - Please update the title to reflect both (e.g., `feat(frontend,backend): Redesign block menu on builder page`)\n\n3. **Backend Testing**\n   - The new API endpoints should have proper testing documentation\n   - Please describe how you've tested the new endpoints\n\n4. **User ID Security**\n   - For the new backend routes, please confirm that user_id checks are properly implemented\n\n## Questions\n\n1. What testing have you done for both the frontend components and backend endpoints?\n2. Are there any configuration changes needed for these new components?\n3. How do the new endpoints interact with the redesigned block menu?\n\nOnce these items are addressed, I'd be happy to re-review the PR. Thanks!",
      "Thanks for working on redesigning the block menu for the builder page! This is an important improvement that will enhance the user experience. However, there are a couple of issues that need to be addressed before we can merge this PR:\n\n1. **Missing Checklist**: The PR template requires a filled-out checklist for all code changes. Please update your PR description to include the checklist from the template with all applicable items checked.\n\n2. **Scope Mismatch**: Your PR title indicates this is a frontend change, but the diff contains significant backend changes including:\n   - Adding new backend routes under `/api/builder`\n   - Creating new backend models and database functions\n   - Modifying the store API\n\n   Please either:\n   - Update the PR title to something like `feat(platform): Redesign block menu with backend support` to accurately reflect both frontend and backend changes, or\n   - Split this into separate PRs for frontend and backend changes\n\nAdditionally, while your PR description lists the components you've added, it would be helpful to include a brief explanation of the backend changes as well.\n\nOnce these items are addressed, we can proceed with the review of the implementation details. The component organization looks good, and I appreciate your marking future tasks with the `BLOCK MENU TODO:` tag for easy reference.",
      "Thanks for working on the block menu redesign! This PR adds important components and functionality for the builder page.\n\n### Key Issues to Address\n\n1. **Missing Checklist:** Please add the required checklist to your PR description. This is mandatory for code changes and should include details about your test plan.\n\n2. **Scope Clarification:** Your PR title focuses on frontend changes, but includes significant backend changes (new endpoints, models, DB functions). While these backend changes appear necessary to support the frontend redesign, consider either:\n   - Updating the PR title to reflect both frontend and backend changes (e.g., `feat(platform): Redesign block menu on builder page with supporting API`)  \n   - OR splitting the PR into separate frontend and backend PRs if that makes sense\n\n3. **PR Conflicts:** There's a conflicts label on your PR - please resolve these merge conflicts.\n\n### Additional Notes\n\n- The TODO comments you've marked with `BLOCK MENU TODO:` are fine as placeholders for future work.\n- Good job properly implementing auth middleware on the new API routes.\n- Consider adding more details about what the redesigned block menu includes and what improvements it brings.\n\nOnce you've addressed these issues, particularly adding the required checklist, the PR should be ready for another review.",
      "Thank you for your PR to redesign the block menu! The implementation looks thorough with many new components created for the builder page.\n\nHowever, I've noticed a couple of issues that need to be addressed before this can be merged:\n\n1. **Missing checklist**: The PR description is missing the required checklist from our PR template. Since this is a significant code change, please update your PR description to include a completed checklist with items like:\n   - Confirmation that you've tested your changes\n   - A test plan outlining how you verified your implementation works correctly\n\n2. **Scope mismatch**: Your PR title mentions only frontend changes, but the PR includes substantial backend implementations including:\n   - A new backend/server/v2/builder module with model, db, and routes files\n   - New API endpoints\n   - Modifications to existing store functionality\n\n   Please update your PR title to reflect both frontend and backend changes, perhaps something like: `feat(frontend,backend): Redesign block menu and add builder API endpoints`\n\nOnce these issues are addressed, we can proceed with the review of your implementation. The code itself looks well-structured with appropriate user_id handling in the backend functions.",
      "Thanks for your PR on redesigning the block menu! There are a few items that need to be addressed before this can be merged:\n\n## Missing Required Information\n\n1. **Checklist**: Your PR is missing the required checklist section. Since this PR involves significant code changes, we need to ensure all necessary checks have been completed.\n\n2. **Test Plan**: Please include details on how you've tested these changes.\n\n## Scope Clarification\n\nYour PR title mentions frontend redesign, but includes significant backend changes (new API endpoints, models, etc.). While these backend changes appear to support the frontend redesign, it would be helpful to:\n\n- Update your PR title to reflect both frontend and backend changes, e.g., `feat(platform): Redesign block menu with supporting backend APIs`\n- OR clarify in your description how the backend changes are necessary for the frontend redesign\n\n## Documentation\n\nPlease add some brief documentation on the new backend endpoints you've created to help other developers understand their purpose and how they relate to the block menu redesign.\n\nThe code itself looks good - I see you've properly protected all routes with auth middleware and correctly handle user_id passing where needed. Once you've addressed these items, we can proceed with the review.",
      "Thank you for working on redesigning the block menu! This is an important improvement for the builder page UI. I've identified a couple of issues that need to be addressed before this PR can be merged:\n\n1. The PR description is missing the required checklist. Please update your description to include the checklist from our template, with all applicable items checked off.\n\n2. The PR title mentions only frontend changes (`feat(frontend)`), but the PR includes significant backend additions (new routes, models, and DB functions in `/backend/server/v2/builder/`). Either:\n   - Update the PR title to reflect both frontend and backend changes (e.g., `feat(platform): Redesign block menu with backend support`)\n   - Or split this into separate PRs for frontend and backend changes\n\nYour implementation looks good overall - I can see you've built reusable components and made sure the backend functions properly handle user_id for authentication. Please address the issues above so we can proceed with the review.\n\nNote: There's also a conflict label on this PR that will need to be resolved before merging.",
      "Thank you for your PR to redesign the block menu on the builder page! This looks like a substantial piece of work that adds many components and backend support.  \n\nHowever, I've noticed a few issues that need to be addressed before this can be merged:\n\n1. **Missing Checklist**: Your PR is missing the required checklist. Please add the complete checklist from the PR template and check off the items you've completed. Given the scope of your changes, the checklist is necessary to ensure everything has been properly tested.\n\n2. **PR Title/Scope Mismatch**: Your PR title only mentions frontend changes, but there are significant backend changes as well (new API routes, database functions, models). Please update your PR title to reflect both aspects, perhaps something like: `feat(frontend,backend): Redesign block menu on builder page with API support`\n\n3. **Test Plan**: Please provide a test plan detailing how you've verified that both the frontend components and backend API routes work correctly.\n\n4. **PR Description**: Consider expanding your description to briefly explain the purpose of the backend changes and how they support the frontend redesign.\n\nYour component organization looks good, and I appreciate that you've marked future tasks with `BLOCK MENU TODO:`. Once you address these items, we'll be able to move forward with the review process.",
      "Thanks for your contribution to redesign the block menu! This is a substantial PR with changes across both frontend and backend.\n\n### Missing Required Checklist\n\nPlease add the standard PR checklist to your description and complete it. This is required for all PRs with material code changes. The checklist helps ensure you've tested your changes appropriately and considered all necessary factors.\n\n### Scope Consideration\n\nYour PR title mentions frontend changes, but there are significant backend changes as well (new API endpoints, database functions, models). Consider either:\n1. Updating the PR title to reflect both frontend and backend changes, or\n2. Splitting this into two PRs if the changes are separable (one for backend support, one for frontend implementation)\n\n### TODOs in Code\n\nYou mentioned \"Some tasks are planned for the near future. I've marked them with `BLOCK MENU TODO:` so they can be found easily.\" Please ensure that these TODOs are addressed before the PR is merged, or create follow-up issues to track them.\n\n### Other Notes\n\n- The new backend endpoints look well-structured with appropriate auth middleware\n- The implementation seems comprehensive with search functionality, filtering, and pagination\n- Good job on adding new dependencies in package.json for the enhanced UI components\n\nPlease update your PR description with the required checklist and consider the scope recommendation.",
      "Thank you for your PR! I noticed a few issues that need to be addressed before this can be merged:\n\n## Missing Checklist\nYour PR contains significant code changes but doesn't include the required checklist. Please add the standard checklist to your PR description and ensure all items are checked off.\n\n## Scope Mismatch\nYour PR title mentions only frontend changes (`feat(frontend): Redesign block menu on builder page`), but the actual changes include extensive backend work:\n- New backend routes in `/api/builder/`\n- New database functions and models for builder functionality\n- Changes to store and library endpoints\n\nPlease update your PR title to reflect both frontend and backend changes, for example: `feat(frontend,backend): Redesign block menu and add builder API endpoints`\n\n## PR Description Needs Expansion\nPlease provide more details in your PR description:\n- What problem does this redesign solve?\n- What are the key changes in both frontend and backend?\n- How should reviewers test these changes?\n\nThe current description lists small components but doesn't explain the overall architecture or the backend additions.\n\nOnce these issues are addressed, I'll be happy to review this PR again. Let me know if you need any clarification!",
      "Thanks for your PR on redesigning the block menu! I have a couple of important issues that need to be addressed before this can be merged:\n\n## Required Changes\n\n1. **Missing Checklist**: The PR template requires a checklist to be completed for code changes. Please update your PR description to include the standard checklist and complete it.\n\n2. **PR Title/Scope Mismatch**: Your PR title indicates this is a frontend change (`feat(frontend)`), but the vast majority of changes are actually backend-related. The PR adds several new backend files (db.py, model.py, routes.py) and modifies existing backend code.\n\n   Please update your PR title to accurately reflect the scope of changes, such as `feat(platform): Redesign block menu with backend support` or similar that reflects both the frontend and backend work.\n\n3. **PR Description**: Consider expanding your PR description to explain why this redesign was needed and how it improves the current implementation. \n\n## Additional Notes\n\n- Your backend code changes look good from a security perspective - the functions properly use user_id for access control.\n- I noticed you've added a TODO comment \"BLOCK MENU TODO:\" for future work. Make sure these are tracked separately if they won't be addressed in this PR.\n- You've added some new dependencies in package.json (tailwind-scrollbar, react-timeago, etc.) - it would be helpful to mention these in the PR description.\n\nPlease update your PR with these changes so we can proceed with the review process. Let me know if you need any clarification!",
      "Thanks for your work on redesigning the block menu! I noticed a few issues that need to be addressed before this PR can be merged:\n\n## Description and Scope\n\n- Your PR title indicates only frontend changes, but there are significant backend changes (new API routes, models, etc.). The scope in the title should reflect all areas being modified, such as `feat(platform)` or both frontend and backend.\n- The PR description focuses on frontend components but doesn't mention the backend API work. Please update your description to include details about all changes made.\n\n## Missing Required Checklist\n\n- The PR is missing the required checklist that should be filled out completely. Since this includes substantial code changes, please add the checklist and check off all applicable items.\n- Please include a test plan detailing how you've verified the changes work correctly.\n\n## Suggested Changes\n\n1. Update the PR title to correctly represent the scope of changes (e.g., `feat(platform): Redesign block menu on builder page`)\n2. Expand the PR description to include details about the backend API changes\n3. Add the required checklist template and fill it out completely\n4. Include a test plan that describes how you've tested these changes\n\nOnce these issues are addressed, we can proceed with reviewing the code changes in detail.",
      "Thank you for your PR to redesign the block menu! I've reviewed your changes and have a few concerns that need to be addressed before this can be merged:\n\n## Missing Checklist\nThe PR description is missing the required checklist for code changes. Please update your description to include the standard checklist that confirms you've tested your changes properly.\n\n## Scope Mismatch\nYour PR title indicates this is a frontend change (`feat(frontend): Redesign block menu on builder page`), but the changes include significant backend additions:\n- New builder API endpoints\n- New database functions\n- New models and data structures\n\nThese backend changes appear to be more than 20% of the total changes, which exceeds our scope guidelines. You have two options:\n\n1. Split this into two PRs: one for frontend and one for backend changes\n2. Update the PR title to reflect both areas (e.g., `feat(frontend,backend): Redesign block menu with supporting API endpoints`)\n\nThe new backend code looks good in terms of security and user_id handling, but we need to ensure the PR accurately represents the work being done.\n\nPlease update your PR accordingly, and let me know if you need any help or clarification!",
      "Thanks for the PR to redesign the block menu! The components structure you've listed looks well organized.\n\nI noticed a couple of issues that need to be addressed before this can be merged:\n\n1. **Missing checklist**: The PR template requires a checklist section to be completed for code changes. Please add the checklist from the template and fill it out appropriately, especially including your test plan.\n\n2. **Scope mismatch**: Your PR title indicates this is purely a frontend change (`feat(frontend)`), but the PR contains substantial backend changes including:\n   - New backend API routes in `/api/builder`\n   - New backend models and database methods\n   - Changes to existing backend services\n\nPlease update either:\n   - The PR title to reflect both frontend and backend changes (e.g., `feat(platform): Redesign block menu and add builder API endpoints`)\n   - OR split this into separate PRs for frontend and backend changes\n\nAlso, I notice you've marked some tasks with \"BLOCK MENU TODO\" for future work. It would be helpful to clarify in the PR description which parts are complete in this PR and which parts are planned for future PRs.\n\nLet me know if you need any help with these changes!",
      "Thank you for your work on redesigning the block menu for the builder page. However, there are a couple of issues that need to be addressed before this PR can be merged:\n\n1. **Missing Checklist**: Your PR is missing the required checklist section. Please update your PR description to include the standard checklist and fill it out completely. This helps ensure all necessary steps have been completed before merging.\n\n2. **Scope Mismatch**: Your PR title mentions only frontend changes (`feat(frontend): Redesign block menu on builder page`), but the PR includes extensive backend changes as well. I see new backend routes, models, and database functions being added in:\n   - `backend/server/v2/builder/db.py`\n   - `backend/server/v2/builder/model.py`\n   - `backend/server/v2/builder/routes.py`\n   - And modifications to several other backend files\n\nYou have two options to address this:\n   - Update your PR title to reflect both frontend and backend changes, such as `feat(platform): Redesign block menu with supporting backend APIs`\n   - Or split this into separate PRs - one for frontend and one for backend changes\n\nPlease make these adjustments so we can proceed with the review. The changes themselves look valuable, but we need to ensure the PR follows our standards."
    ],
    "code_diff": "diff --git a/autogpt_platform/backend/backend/blocks/agent.py b/autogpt_platform/backend/backend/blocks/agent.py\nindex c25d99458d6d..406bff9e06bf 100644\n--- a/autogpt_platform/backend/backend/blocks/agent.py\n+++ b/autogpt_platform/backend/backend/blocks/agent.py\n@@ -23,6 +23,9 @@ class Input(BlockSchema):\n         user_id: str = SchemaField(description=\"User ID\")\n         graph_id: str = SchemaField(description=\"Graph ID\")\n         graph_version: int = SchemaField(description=\"Graph Version\")\n+        agent_name: Optional[str] = SchemaField(\n+            default=None, description=\"Name to display in the Builder UI\"\n+        )\n \n         inputs: BlockInput = SchemaField(description=\"Input data for the graph\")\n         input_schema: dict = SchemaField(description=\"Input schema for the graph\")\ndiff --git a/autogpt_platform/backend/backend/server/model.py b/autogpt_platform/backend/backend/server/model.py\nindex 8b7293b65ae7..c7b63634729f 100644\n--- a/autogpt_platform/backend/backend/server/model.py\n+++ b/autogpt_platform/backend/backend/server/model.py\n@@ -74,6 +74,15 @@ class Pagination(pydantic.BaseModel):\n         description=\"Number of items per page.\", examples=[25]\n     )\n \n+    @staticmethod\n+    def empty() -> \"Pagination\":\n+        return Pagination(\n+            total_items=0,\n+            total_pages=0,\n+            current_page=0,\n+            page_size=0,\n+        )\n+\n \n class RequestTopUp(pydantic.BaseModel):\n     credit_amount: int\ndiff --git a/autogpt_platform/backend/backend/server/rest_api.py b/autogpt_platform/backend/backend/server/rest_api.py\nindex 7ebbab9c4a38..5a885b9606a1 100644\n--- a/autogpt_platform/backend/backend/server/rest_api.py\n+++ b/autogpt_platform/backend/backend/server/rest_api.py\n@@ -23,6 +23,8 @@\n import backend.server.routers.v1\n import backend.server.v2.admin.credit_admin_routes\n import backend.server.v2.admin.store_admin_routes\n+import backend.server.v2.builder\n+import backend.server.v2.builder.routes\n import backend.server.v2.library.db\n import backend.server.v2.library.model\n import backend.server.v2.library.routes\n@@ -144,6 +146,9 @@ async def validation_error_handler(\n app.include_router(\n     backend.server.v2.store.routes.router, tags=[\"v2\"], prefix=\"/api/store\"\n )\n+app.include_router(\n+    backend.server.v2.builder.routes.router, tags=[\"v2\"], prefix=\"/api/builder\"\n+)\n app.include_router(\n     backend.server.v2.admin.store_admin_routes.router,\n     tags=[\"v2\", \"admin\"],\ndiff --git a/autogpt_platform/backend/backend/server/v2/builder/db.py b/autogpt_platform/backend/backend/server/v2/builder/db.py\nnew file mode 100644\nindex 000000000000..8cdbf9d9d4c7\n--- /dev/null\n+++ b/autogpt_platform/backend/backend/server/v2/builder/db.py\n@@ -0,0 +1,370 @@\n+import functools\n+import logging\n+\n+import prisma\n+\n+import backend.data.block\n+import backend.server.model as server_model\n+from backend.blocks import load_all_blocks\n+from backend.blocks.llm import LlmModel\n+from backend.data.block import Block, BlockCategory, BlockSchema\n+from backend.data.credit import get_block_costs\n+from backend.integrations.providers import ProviderName\n+from backend.server.v2.builder.model import (\n+    BlockCategoryResponse,\n+    BlockData,\n+    BlockResponse,\n+    BlockType,\n+    CountResponse,\n+    Provider,\n+    ProviderResponse,\n+    SearchBlocksResponse,\n+)\n+\n+logger = logging.getLogger(__name__)\n+llm_models = [name.name.lower().replace(\"_\", \" \") for name in LlmModel]\n+_static_counts_cache: dict | None = None\n+_suggested_blocks: list[BlockData] | None = None\n+\n+\n+def get_block_categories(category_blocks: int = 3) -> list[BlockCategoryResponse]:\n+    categories: dict[BlockCategory, BlockCategoryResponse] = {}\n+\n+    for block_type in load_all_blocks().values():\n+        block: Block[BlockSchema, BlockSchema] = block_type()\n+        # Skip disabled blocks\n+        if block.disabled:\n+            continue\n+        # Skip blocks that don't have categories (all should have at least one)\n+        if not block.categories:\n+            continue\n+\n+        # Add block to the categories\n+        for category in block.categories:\n+            if category not in categories:\n+                categories[category] = BlockCategoryResponse(\n+                    name=category.name.lower(),\n+                    total_blocks=0,\n+                    blocks=[],\n+                )\n+\n+            categories[category].total_blocks += 1\n+\n+            # Append if the category has less than the specified number of blocks\n+            if len(categories[category].blocks) < category_blocks:\n+                categories[category].blocks.append(block.to_dict())\n+\n+    # Sort categories by name\n+    return sorted(categories.values(), key=lambda x: x.name)\n+\n+\n+def get_blocks(\n+    *,\n+    category: str | None = None,\n+    type: BlockType | None = None,\n+    provider: ProviderName | None = None,\n+    page: int = 1,\n+    page_size: int = 50,\n+) -> BlockResponse:\n+    \"\"\"\n+    Get blocks based on either category, type or provider.\n+    Providing nothing fetches all block types.\n+    \"\"\"\n+    # Only one of category, type, or provider can be specified\n+    if (category and type) or (category and provider) or (type and provider):\n+        raise ValueError(\"Only one of category, type, or provider can be specified\")\n+\n+    blocks: list[Block[BlockSchema, BlockSchema]] = []\n+    skip = (page - 1) * page_size\n+    take = page_size\n+    total = 0\n+\n+    for block_type in load_all_blocks().values():\n+        block: Block[BlockSchema, BlockSchema] = block_type()\n+        # Skip disabled blocks\n+        if block.disabled:\n+            continue\n+        # Skip blocks that don't match the category\n+        if category and category not in {c.name.lower() for c in block.categories}:\n+            continue\n+        # Skip blocks that don't match the type\n+        if (\n+            (type == \"input\" and block.block_type.value != \"Input\")\n+            or (type == \"output\" and block.block_type.value != \"Output\")\n+            or (type == \"action\" and block.block_type.value in (\"Input\", \"Output\"))\n+        ):\n+            continue\n+        # Skip blocks that don't match the provider\n+        if provider:\n+            credentials_info = block.input_schema.get_credentials_fields_info().values()\n+            if not any(provider in info.provider for info in credentials_info):\n+                continue\n+\n+        total += 1\n+        if skip > 0:\n+            skip -= 1\n+            continue\n+        if take > 0:\n+            take -= 1\n+            blocks.append(block)\n+\n+    costs = get_block_costs()\n+\n+    return BlockResponse(\n+        blocks=[{**b.to_dict(), \"costs\": costs.get(b.id, [])} for b in blocks],\n+        pagination=server_model.Pagination(\n+            total_items=total,\n+            total_pages=total // page_size + (1 if total % page_size > 0 else 0),\n+            current_page=page,\n+            page_size=page_size,\n+        ),\n+    )\n+\n+\n+def search_blocks(\n+    include_blocks: bool = True,\n+    include_integrations: bool = True,\n+    query: str = \"\",\n+    page: int = 1,\n+    page_size: int = 50,\n+) -> SearchBlocksResponse:\n+    \"\"\"\n+    Get blocks based on the filter and query.\n+    `providers` only applies for `integrations` filter.\n+    \"\"\"\n+    blocks: list[Block[BlockSchema, BlockSchema]] = []\n+    query = query.lower()\n+\n+    total = 0\n+    skip = (page - 1) * page_size\n+    take = page_size\n+    block_count = 0\n+    integration_count = 0\n+\n+    for block_type in load_all_blocks().values():\n+        block: Block[BlockSchema, BlockSchema] = block_type()\n+        # Skip disabled blocks\n+        if block.disabled:\n+            continue\n+        # Skip blocks that don't match the query\n+        if (\n+            query not in block.name.lower()\n+            and query not in block.description.lower()\n+            and not _matches_llm_model(block.input_schema, query)\n+        ):\n+            continue\n+        keep = False\n+        credentials = list(block.input_schema.get_credentials_fields().values())\n+        if include_integrations and len(credentials) > 0:\n+            keep = True\n+            integration_count += 1\n+        if include_blocks and len(credentials) == 0:\n+            keep = True\n+            block_count += 1\n+\n+        if not keep:\n+            continue\n+\n+        total += 1\n+        if skip > 0:\n+            skip -= 1\n+            continue\n+        if take > 0:\n+            take -= 1\n+            blocks.append(block)\n+\n+    costs = get_block_costs()\n+\n+    return SearchBlocksResponse(\n+        blocks=BlockResponse(\n+            blocks=[{**b.to_dict(), \"costs\": costs.get(b.id, [])} for b in blocks],\n+            pagination=server_model.Pagination(\n+                total_items=total,\n+                total_pages=total // page_size + (1 if total % page_size > 0 else 0),\n+                current_page=page,\n+                page_size=page_size,\n+            ),\n+        ),\n+        total_block_count=block_count,\n+        total_integration_count=integration_count,\n+    )\n+\n+\n+def get_providers(\n+    query: str = \"\",\n+    page: int = 1,\n+    page_size: int = 50,\n+) -> ProviderResponse:\n+    providers = []\n+    query = query.lower()\n+\n+    skip = (page - 1) * page_size\n+    take = page_size\n+\n+    all_providers = _get_all_providers()\n+\n+    for provider in all_providers.values():\n+        if (\n+            query not in provider.name.value.lower()\n+            and query not in provider.description.lower()\n+        ):\n+            continue\n+        if skip > 0:\n+            skip -= 1\n+            continue\n+        if take > 0:\n+            take -= 1\n+            providers.append(provider)\n+\n+    total = len(all_providers)\n+\n+    return ProviderResponse(\n+        providers=providers,\n+        pagination=server_model.Pagination(\n+            total_items=total,\n+            total_pages=total // page_size + (1 if total % page_size > 0 else 0),\n+            current_page=page,\n+            page_size=page_size,\n+        ),\n+    )\n+\n+\n+async def get_counts(user_id: str) -> CountResponse:\n+    my_agents = await prisma.models.LibraryAgent.prisma().count(\n+        where={\n+            \"userId\": user_id,\n+            \"isDeleted\": False,\n+            \"isArchived\": False,\n+        }\n+    )\n+    counts = await _get_static_counts()\n+    return CountResponse(\n+        my_agents=my_agents,\n+        **counts,\n+    )\n+\n+\n+async def _get_static_counts():\n+    \"\"\"\n+    Get counts of blocks, integrations, and marketplace agents.\n+    This is cached to avoid unnecessary database queries and calculations.\n+    Can't use functools.cache here because the function is async.\n+    \"\"\"\n+    global _static_counts_cache\n+    if _static_counts_cache is not None:\n+        return _static_counts_cache\n+\n+    all_blocks = 0\n+    input_blocks = 0\n+    action_blocks = 0\n+    output_blocks = 0\n+    integrations = 0\n+\n+    for block_type in load_all_blocks().values():\n+        block: Block[BlockSchema, BlockSchema] = block_type()\n+        if block.disabled:\n+            continue\n+\n+        all_blocks += 1\n+\n+        if block.block_type.value == \"Input\":\n+            input_blocks += 1\n+        elif block.block_type.value == \"Output\":\n+            output_blocks += 1\n+        else:\n+            action_blocks += 1\n+\n+        credentials = list(block.input_schema.get_credentials_fields().values())\n+        if len(credentials) > 0:\n+            integrations += 1\n+\n+    marketplace_agents = await prisma.models.StoreAgent.prisma().count()\n+\n+    _static_counts_cache = {\n+        \"all_blocks\": all_blocks,\n+        \"input_blocks\": input_blocks,\n+        \"action_blocks\": action_blocks,\n+        \"output_blocks\": output_blocks,\n+        \"integrations\": integrations,\n+        \"marketplace_agents\": marketplace_agents,\n+    }\n+\n+    return _static_counts_cache\n+\n+\n+def _matches_llm_model(schema_cls: type[BlockSchema], query: str) -> bool:\n+    for field in schema_cls.model_fields.values():\n+        if field.annotation == LlmModel:\n+            # Check if query matches any value in llm_models\n+            if any(query in name for name in llm_models):\n+                return True\n+    return False\n+\n+\n+@functools.cache\n+def _get_all_providers() -> dict[ProviderName, Provider]:\n+    providers: dict[ProviderName, Provider] = {}\n+\n+    for block_type in load_all_blocks().values():\n+        block: Block[BlockSchema, BlockSchema] = block_type()\n+        if block.disabled:\n+            continue\n+\n+        credentials_info = block.input_schema.get_credentials_fields_info().values()\n+        for info in credentials_info:\n+            for provider in info.provider:  # provider is a ProviderName enum member\n+                if provider in providers:\n+                    providers[provider].integration_count += 1\n+                else:\n+                    providers[provider] = Provider(\n+                        name=provider, description=\"\", integration_count=1\n+                    )\n+    return providers\n+\n+\n+async def get_suggested_blocks(count: int = 5) -> list[BlockData]:\n+    global _suggested_blocks\n+\n+    if _suggested_blocks is not None and len(_suggested_blocks) >= count:\n+        return _suggested_blocks[:count]\n+\n+    _suggested_blocks = []\n+    # Sum the number of executions for each block type\n+    # Prisma cannot group by nested relations, so we do a raw query\n+    results = await prisma.get_client().query_raw(\n+        \"\"\"\n+        SELECT\n+            agent_node.\"agentBlockId\" AS block_id,\n+            COUNT(execution.id) AS execution_count\n+        FROM \"AgentNodeExecution\" execution\n+        JOIN \"AgentNode\" agent_node ON execution.\"agentNodeId\" = agent_node.id\n+        GROUP BY agent_node.\"agentBlockId\"\n+        ORDER BY execution_count DESC;\n+        \"\"\"\n+    )\n+\n+    # Get the top blocks based on execution count\n+    # But ignore Input and Output blocks\n+    blocks: list[tuple[BlockData, int]] = []\n+\n+    for block_type in load_all_blocks().values():\n+        block: Block[BlockSchema, BlockSchema] = block_type()\n+        if block.disabled or block.block_type in (\n+            backend.data.block.BlockType.INPUT,\n+            backend.data.block.BlockType.OUTPUT,\n+            backend.data.block.BlockType.AGENT,\n+        ):\n+            continue\n+        # Find the execution count for this block\n+        execution_count = next(\n+            (row[\"execution_count\"] for row in results if row[\"block_id\"] == block.id),\n+            0,\n+        )\n+        blocks.append((block.to_dict(), execution_count))\n+    # Sort blocks by execution count\n+    blocks.sort(key=lambda x: x[1], reverse=True)\n+\n+    _suggested_blocks = [block[0] for block in blocks]\n+\n+    # Return the top blocks\n+    return _suggested_blocks[:count]\ndiff --git a/autogpt_platform/backend/backend/server/v2/builder/model.py b/autogpt_platform/backend/backend/server/v2/builder/model.py\nnew file mode 100644\nindex 000000000000..475010642d59\n--- /dev/null\n+++ b/autogpt_platform/backend/backend/server/v2/builder/model.py\n@@ -0,0 +1,87 @@\n+from typing import Any, Literal\n+\n+from pydantic import BaseModel\n+\n+import backend.server.model as server_model\n+import backend.server.v2.library.model as library_model\n+import backend.server.v2.store.model as store_model\n+from backend.integrations.providers import ProviderName\n+\n+FilterType = Literal[\n+    \"blocks\",\n+    \"integrations\",\n+    \"marketplace_agents\",\n+    \"my_agents\",\n+]\n+\n+BlockType = Literal[\"all\", \"input\", \"action\", \"output\"]\n+\n+BlockData = dict[str, Any]\n+\n+\n+# Suggestions\n+class SuggestionsResponse(BaseModel):\n+    otto_suggestions: list[str]\n+    recent_searches: list[str]\n+    providers: list[ProviderName]\n+    top_blocks: list[BlockData]\n+\n+\n+# All blocks\n+class BlockCategoryResponse(BaseModel):\n+    name: str\n+    total_blocks: int\n+    blocks: list[BlockData]\n+\n+    model_config = {\"use_enum_values\": False}  # <== use enum names like \"AI\"\n+\n+\n+# Input/Action/Output and see all for block categories\n+class BlockResponse(BaseModel):\n+    blocks: list[BlockData]\n+    pagination: server_model.Pagination\n+\n+\n+# Providers\n+class Provider(BaseModel):\n+    name: ProviderName\n+    description: str\n+    integration_count: int\n+\n+\n+class ProviderResponse(BaseModel):\n+    providers: list[Provider]\n+    pagination: server_model.Pagination\n+\n+\n+# Search\n+class SearchRequest(BaseModel):\n+    search_query: str | None = None\n+    filter: list[FilterType] | None = None\n+    by_creator: list[str] | None = None\n+    search_id: str | None = None\n+    page: int | None = None\n+    page_size: int | None = None\n+\n+\n+class SearchBlocksResponse(BaseModel):\n+    blocks: BlockResponse\n+    total_block_count: int\n+    total_integration_count: int\n+\n+\n+class SearchResponse(BaseModel):\n+    items: list[BlockData | library_model.LibraryAgent | store_model.StoreAgent]\n+    total_items: dict[FilterType, int]\n+    page: int\n+    more_pages: bool\n+\n+\n+class CountResponse(BaseModel):\n+    all_blocks: int\n+    input_blocks: int\n+    action_blocks: int\n+    output_blocks: int\n+    integrations: int\n+    marketplace_agents: int\n+    my_agents: int\ndiff --git a/autogpt_platform/backend/backend/server/v2/builder/routes.py b/autogpt_platform/backend/backend/server/v2/builder/routes.py\nnew file mode 100644\nindex 000000000000..57934203892a\n--- /dev/null\n+++ b/autogpt_platform/backend/backend/server/v2/builder/routes.py\n@@ -0,0 +1,227 @@\n+import logging\n+from typing import Annotated, Sequence\n+\n+import fastapi\n+from autogpt_libs.auth.depends import auth_middleware, get_user_id\n+\n+import backend.server.model as server_model\n+import backend.server.v2.builder.db as builder_db\n+import backend.server.v2.builder.model as builder_model\n+import backend.server.v2.library.db as library_db\n+import backend.server.v2.library.model as library_model\n+import backend.server.v2.store.db as store_db\n+import backend.server.v2.store.model as store_model\n+from backend.integrations.providers import ProviderName\n+\n+logger = logging.getLogger(__name__)\n+\n+router = fastapi.APIRouter()\n+\n+\n+# Taken from backend/server/v2/store/db.py\n+def sanitize_query(query: str | None) -> str | None:\n+    if query is None:\n+        return query\n+    query = query.strip()[:100]\n+    return (\n+        query.replace(\"\\\\\", \"\\\\\\\\\")\n+        .replace(\"%\", \"\\\\%\")\n+        .replace(\"_\", \"\\\\_\")\n+        .replace(\"[\", \"\\\\[\")\n+        .replace(\"]\", \"\\\\]\")\n+        .replace(\"'\", \"\\\\'\")\n+        .replace('\"', '\\\\\"')\n+        .replace(\";\", \"\\\\;\")\n+        .replace(\"--\", \"\\\\--\")\n+        .replace(\"/*\", \"\\\\/*\")\n+        .replace(\"*/\", \"\\\\*/\")\n+    )\n+\n+\n+@router.get(\n+    \"/suggestions\",\n+    dependencies=[fastapi.Depends(auth_middleware)],\n+)\n+async def get_suggestions(\n+    user_id: Annotated[str, fastapi.Depends(get_user_id)],\n+) -> builder_model.SuggestionsResponse:\n+    \"\"\"\n+    Get all suggestions for the Blocks Menu.\n+    \"\"\"\n+    return builder_model.SuggestionsResponse(\n+        otto_suggestions=[\n+            \"What blocks do I need to get started?\",\n+            \"Help me create a list\",\n+            \"Help me feed my data to Google Maps\",\n+        ],\n+        recent_searches=[\n+            \"image generation\",\n+            \"deepfake\",\n+            \"competitor analysis\",\n+        ],\n+        providers=[\n+            ProviderName.TWITTER,\n+            ProviderName.GITHUB,\n+            ProviderName.NOTION,\n+            ProviderName.GOOGLE,\n+            ProviderName.DISCORD,\n+            ProviderName.GOOGLE_MAPS,\n+        ],\n+        top_blocks=await builder_db.get_suggested_blocks(),\n+    )\n+\n+\n+@router.get(\n+    \"/categories\",\n+    dependencies=[fastapi.Depends(auth_middleware)],\n+)\n+async def get_block_categories(\n+    category_blocks: Annotated[int, fastapi.Query()] = 3,\n+) -> Sequence[builder_model.BlockCategoryResponse]:\n+    \"\"\"\n+    Get all block categories with a specified number of blocks per category.\n+    \"\"\"\n+    return builder_db.get_block_categories(category_blocks)\n+\n+\n+@router.get(\n+    \"/blocks\",\n+    dependencies=[fastapi.Depends(auth_middleware)],\n+)\n+async def get_blocks(\n+    category: Annotated[str | None, fastapi.Query()] = None,\n+    type: Annotated[builder_model.BlockType | None, fastapi.Query()] = None,\n+    provider: Annotated[ProviderName | None, fastapi.Query()] = None,\n+    page: Annotated[int, fastapi.Query()] = 1,\n+    page_size: Annotated[int, fastapi.Query()] = 50,\n+) -> builder_model.BlockResponse:\n+    \"\"\"\n+    Get blocks based on either category, type, or provider.\n+    \"\"\"\n+    return builder_db.get_blocks(\n+        category=category,\n+        type=type,\n+        provider=provider,\n+        page=page,\n+        page_size=page_size,\n+    )\n+\n+\n+@router.get(\n+    \"/providers\",\n+    dependencies=[fastapi.Depends(auth_middleware)],\n+)\n+async def get_providers(\n+    page: Annotated[int, fastapi.Query()] = 1,\n+    page_size: Annotated[int, fastapi.Query()] = 50,\n+) -> builder_model.ProviderResponse:\n+    \"\"\"\n+    Get all integration providers with their block counts.\n+    \"\"\"\n+    return builder_db.get_providers(\n+        page=page,\n+        page_size=page_size,\n+    )\n+\n+\n+@router.post(\n+    \"/search\",\n+    tags=[\"store\", \"private\"],\n+    dependencies=[fastapi.Depends(auth_middleware)],\n+)\n+async def search(\n+    options: builder_model.SearchRequest,\n+    user_id: Annotated[str, fastapi.Depends(get_user_id)],\n+) -> builder_model.SearchResponse:\n+    \"\"\"\n+    Search for blocks (including integrations), marketplace agents, and user library agents.\n+    \"\"\"\n+    # If no filters are provided, then we will return all types\n+    if not options.filter:\n+        options.filter = [\n+            \"blocks\",\n+            \"integrations\",\n+            \"marketplace_agents\",\n+            \"my_agents\",\n+        ]\n+    options.search_query = sanitize_query(options.search_query)\n+    options.page = options.page or 1\n+    options.page_size = options.page_size or 50\n+\n+    # Blocks&Integrations\n+    blocks = builder_model.SearchBlocksResponse(\n+        blocks=builder_model.BlockResponse(\n+            blocks=[],\n+            pagination=server_model.Pagination.empty(),\n+        ),\n+        total_block_count=0,\n+        total_integration_count=0,\n+    )\n+    if \"blocks\" in options.filter or \"integrations\" in options.filter:\n+        blocks = builder_db.search_blocks(\n+            include_blocks=\"blocks\" in options.filter,\n+            include_integrations=\"integrations\" in options.filter,\n+            query=options.search_query or \"\",\n+            page=options.page,\n+            page_size=options.page_size,\n+        )\n+\n+    # Library Agents\n+    my_agents = library_model.LibraryAgentResponse(\n+        agents=[],\n+        pagination=server_model.Pagination.empty(),\n+    )\n+    if \"my_agents\" in options.filter:\n+        my_agents = await library_db.list_library_agents(\n+            user_id=user_id,\n+            search_term=options.search_query,\n+            page=options.page,\n+            page_size=options.page_size,\n+        )\n+\n+    # Marketplace Agents\n+    marketplace_agents = store_model.StoreAgentsResponse(\n+        agents=[],\n+        pagination=server_model.Pagination.empty(),\n+    )\n+    if \"marketplace_agents\" in options.filter:\n+        marketplace_agents = await store_db.get_store_agents(\n+            creators=options.by_creator,\n+            search_query=options.search_query,\n+            page=options.page,\n+            page_size=options.page_size,\n+        )\n+\n+    more_pages = False\n+    if (\n+        blocks.blocks.pagination.current_page < blocks.blocks.pagination.total_pages\n+        or my_agents.pagination.current_page < my_agents.pagination.total_pages\n+        or marketplace_agents.pagination.current_page\n+        < marketplace_agents.pagination.total_pages\n+    ):\n+        more_pages = True\n+\n+    return builder_model.SearchResponse(\n+        items=blocks.blocks.blocks + my_agents.agents + marketplace_agents.agents,\n+        total_items={\n+            \"blocks\": blocks.total_block_count,\n+            \"integrations\": blocks.total_integration_count,\n+            \"marketplace_agents\": marketplace_agents.pagination.total_items,\n+            \"my_agents\": my_agents.pagination.total_items,\n+        },\n+        page=options.page,\n+        more_pages=more_pages,\n+    )\n+\n+\n+@router.get(\n+    \"/counts\",\n+    dependencies=[fastapi.Depends(auth_middleware)],\n+)\n+async def get_counts(\n+    user_id: Annotated[str, fastapi.Depends(get_user_id)],\n+) -> builder_model.CountResponse:\n+    \"\"\"\n+    Get item counts for the menu categories in the Blocks Menu.\n+    \"\"\"\n+    return await builder_db.get_counts(user_id)\ndiff --git a/autogpt_platform/backend/backend/server/v2/library/db.py b/autogpt_platform/backend/backend/server/v2/library/db.py\nindex b0f8f7a755c9..d4e6d4f4a476 100644\n--- a/autogpt_platform/backend/backend/server/v2/library/db.py\n+++ b/autogpt_platform/backend/backend/server/v2/library/db.py\n@@ -448,7 +448,7 @@ async def add_store_agent_to_library(\n                             \"agentGraphVersion\": graph.version,\n                         }\n                     },\n-                    include={\"AgentGraph\": True},\n+                    include=library_agent_include(user_id),\n                 )\n             )\n             if existing_library_agent:\ndiff --git a/autogpt_platform/backend/backend/server/v2/library/model.py b/autogpt_platform/backend/backend/server/v2/library/model.py\nindex 8c39f3dc3b04..2ea8798361eb 100644\n--- a/autogpt_platform/backend/backend/server/v2/library/model.py\n+++ b/autogpt_platform/backend/backend/server/v2/library/model.py\n@@ -42,6 +42,7 @@ class LibraryAgent(pydantic.BaseModel):\n \n     # Made input_schema and output_schema match GraphMeta's type\n     input_schema: dict[str, Any]  # Should be BlockIOObjectSubSchema in frontend\n+    output_schema: dict[str, Any]\n \n     # Indicates whether there's a new output (based on recent runs)\n     new_output: bool\n@@ -106,6 +107,7 @@ def from_db(agent: prisma.models.LibraryAgent) -> \"LibraryAgent\":\n             name=graph.name,\n             description=graph.description,\n             input_schema=graph.input_schema,\n+            output_schema=graph.output_schema,\n             new_output=new_output,\n             can_access_graph=can_access_graph,\n             is_latest_version=is_latest_version,\ndiff --git a/autogpt_platform/backend/backend/server/v2/library/routes_test.py b/autogpt_platform/backend/backend/server/v2/library/routes_test.py\nindex 6cfb1ffce035..99d9bd4f1af2 100644\n--- a/autogpt_platform/backend/backend/server/v2/library/routes_test.py\n+++ b/autogpt_platform/backend/backend/server/v2/library/routes_test.py\n@@ -50,6 +50,7 @@ async def test_get_library_agents_success(\n                 creator_name=\"Test Creator\",\n                 creator_image_url=\"\",\n                 input_schema={\"type\": \"object\", \"properties\": {}},\n+                output_schema={\"type\": \"object\", \"properties\": {}},\n                 status=library_model.LibraryAgentStatus.COMPLETED,\n                 new_output=False,\n                 can_access_graph=True,\n@@ -66,6 +67,7 @@ async def test_get_library_agents_success(\n                 creator_name=\"Test Creator\",\n                 creator_image_url=\"\",\n                 input_schema={\"type\": \"object\", \"properties\": {}},\n+                output_schema={\"type\": \"object\", \"properties\": {}},\n                 status=library_model.LibraryAgentStatus.COMPLETED,\n                 new_output=False,\n                 can_access_graph=False,\ndiff --git a/autogpt_platform/backend/backend/server/v2/store/db.py b/autogpt_platform/backend/backend/server/v2/store/db.py\nindex dac8cce8a520..707e20befd9b 100644\n--- a/autogpt_platform/backend/backend/server/v2/store/db.py\n+++ b/autogpt_platform/backend/backend/server/v2/store/db.py\n@@ -37,7 +37,7 @@ def sanitize_query(query: str | None) -> str | None:\n \n async def get_store_agents(\n     featured: bool = False,\n-    creator: str | None = None,\n+    creators: list[str] | None = None,\n     sorted_by: str | None = None,\n     search_query: str | None = None,\n     category: str | None = None,\n@@ -48,15 +48,15 @@ async def get_store_agents(\n     Get PUBLIC store agents from the StoreAgent view\n     \"\"\"\n     logger.debug(\n-        f\"Getting store agents. featured={featured}, creator={creator}, sorted_by={sorted_by}, search={search_query}, category={category}, page={page}\"\n+        f\"Getting store agents. featured={featured}, creator={creators}, sorted_by={sorted_by}, search={search_query}, category={category}, page={page}\"\n     )\n     sanitized_query = sanitize_query(search_query)\n \n     where_clause = {}\n     if featured:\n         where_clause[\"featured\"] = featured\n-    if creator:\n-        where_clause[\"creator_username\"] = creator\n+    if creators:\n+        where_clause[\"creator_username\"] = {\"in\": creators}\n     if category:\n         where_clause[\"categories\"] = {\"has\": category}\n \ndiff --git a/autogpt_platform/backend/backend/server/v2/store/routes.py b/autogpt_platform/backend/backend/server/v2/store/routes.py\nindex 41795f5d887b..f71665d93794 100644\n--- a/autogpt_platform/backend/backend/server/v2/store/routes.py\n+++ b/autogpt_platform/backend/backend/server/v2/store/routes.py\n@@ -158,7 +158,7 @@ async def get_agents(\n     try:\n         agents = await backend.server.v2.store.db.get_store_agents(\n             featured=featured,\n-            creator=creator,\n+            creators=[creator] if creator else None,\n             sorted_by=sorted_by,\n             search_query=search_query,\n             category=category,\ndiff --git a/autogpt_platform/frontend/package.json b/autogpt_platform/frontend/package.json\nindex b8abd0baf04c..60e79c2472b1 100644\n--- a/autogpt_platform/frontend/package.json\n+++ b/autogpt_platform/frontend/package.json\n@@ -82,9 +82,12 @@\n     \"react-markdown\": \"9.0.3\",\n     \"react-modal\": \"3.16.3\",\n     \"react-shepherd\": \"6.1.8\",\n+    \"react-timeago\": \"^8.2.0\",\n     \"recharts\": \"2.15.3\",\n     \"shepherd.js\": \"14.5.0\",\n     \"tailwind-merge\": \"2.6.0\",\n+    \"tailwind-scrollbar\": \"^4.0.2\",\n+    \"tailwind-scrollbar-hide\": \"^2.0.0\",\n     \"tailwindcss-animate\": \"1.0.7\",\n     \"uuid\": \"11.1.0\",\n     \"zod\": \"3.25.56\"\ndiff --git a/autogpt_platform/frontend/pnpm-lock.yaml b/autogpt_platform/frontend/pnpm-lock.yaml\nindex e418b8bb879f..e6bea7076a8f 100644\n--- a/autogpt_platform/frontend/pnpm-lock.yaml\n+++ b/autogpt_platform/frontend/pnpm-lock.yaml\n@@ -79,7 +79,7 @@ importers:\n         version: 1.2.7(@types/react-dom@18.3.5(@types/react@18.3.17))(@types/react@18.3.17)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)\n       '@sentry/nextjs':\n         specifier: 9.27.0\n-        version: 9.27.0(@opentelemetry/context-async-hooks@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/core@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/instrumentation@0.57.2(@opentelemetry/api@1.9.0))(@opentelemetry/sdk-trace-base@1.30.1(@opentelemetry/api@1.9.0))(next@15.3.3(@babel/core@7.27.4)(@opentelemetry/api@1.9.0)(@playwright/test@1.52.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react@18.3.1)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+        version: 9.27.0(@opentelemetry/context-async-hooks@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/core@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/instrumentation@0.57.2(@opentelemetry/api@1.9.0))(@opentelemetry/sdk-trace-base@1.30.1(@opentelemetry/api@1.9.0))(next@15.3.3(@babel/core@7.27.4)(@opentelemetry/api@1.9.0)(@playwright/test@1.52.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react@18.3.1)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       '@supabase/ssr':\n         specifier: 0.6.1\n         version: 0.6.1(@supabase/supabase-js@2.50.0)\n@@ -182,6 +182,9 @@ importers:\n       react-shepherd:\n         specifier: 6.1.8\n         version: 6.1.8(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(typescript@5.8.3)\n+      react-timeago:\n+        specifier: ^8.2.0\n+        version: 8.2.0(react@18.3.1)\n       recharts:\n         specifier: 2.15.3\n         version: 2.15.3(react-dom@18.3.1(react@18.3.1))(react@18.3.1)\n@@ -191,6 +194,12 @@ importers:\n       tailwind-merge:\n         specifier: 2.6.0\n         version: 2.6.0\n+      tailwind-scrollbar:\n+        specifier: ^4.0.2\n+        version: 4.0.2(react@18.3.1)(tailwindcss@3.4.17)\n+      tailwind-scrollbar-hide:\n+        specifier: ^2.0.0\n+        version: 2.0.0(tailwindcss@3.4.17)\n       tailwindcss-animate:\n         specifier: 1.0.7\n         version: 1.0.7(tailwindcss@3.4.17)\n@@ -233,7 +242,7 @@ importers:\n         version: 8.6.14(storybook@8.6.14(prettier@3.5.3))\n       '@storybook/nextjs':\n         specifier: 8.6.14\n-        version: 8.6.14(@swc/core@1.12.1)(esbuild@0.25.5)(next@15.3.3(@babel/core@7.27.4)(@opentelemetry/api@1.9.0)(@playwright/test@1.52.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(type-fest@4.41.0)(typescript@5.8.3)(webpack-hot-middleware@2.26.1)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+        version: 8.6.14(@swc/core@1.11.31)(esbuild@0.24.2)(next@15.3.3(@babel/core@7.27.4)(@opentelemetry/api@1.9.0)(@playwright/test@1.52.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(type-fest@4.41.0)(typescript@5.8.3)(webpack-hot-middleware@2.26.1)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       '@storybook/react':\n         specifier: 8.6.14\n         version: 8.6.14(@storybook/test@8.6.14(storybook@8.6.14(prettier@3.5.3)))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)\n@@ -269,7 +278,7 @@ importers:\n         version: 3.16.3\n       axe-playwright:\n         specifier: 2.1.0\n-        version: 2.1.0(playwright@1.53.0)\n+        version: 2.1.0(playwright@1.52.0)\n       chromatic:\n         specifier: 11.25.2\n         version: 11.25.2\n@@ -991,152 +1000,152 @@ packages:\n   '@emotion/unitless@0.8.1':\n     resolution: {integrity: sha512-KOEGMu6dmJZtpadb476IsZBclKvILjopjUii3V+7MnXIQCYh8W3NgNcgwo21n9LXZX6EDIKvqfjYxXebDwxKmQ==}\n \n-  '@esbuild/aix-ppc64@0.25.5':\n-    resolution: {integrity: sha512-9o3TMmpmftaCMepOdA5k/yDw8SfInyzWWTjYTFCX3kPSDJMROQTb8jg+h9Cnwnmm1vOzvxN7gIfB5V2ewpjtGA==}\n+  '@esbuild/aix-ppc64@0.24.2':\n+    resolution: {integrity: sha512-thpVCb/rhxE/BnMLQ7GReQLLN8q9qbHmI55F4489/ByVg2aQaQ6kbcLb6FHkocZzQhxc4gx0sCk0tJkKBFzDhA==}\n     engines: {node: '>=18'}\n     cpu: [ppc64]\n     os: [aix]\n \n-  '@esbuild/android-arm64@0.25.5':\n-    resolution: {integrity: sha512-VGzGhj4lJO+TVGV1v8ntCZWJktV7SGCs3Pn1GRWI1SBFtRALoomm8k5E9Pmwg3HOAal2VDc2F9+PM/rEY6oIDg==}\n+  '@esbuild/android-arm64@0.24.2':\n+    resolution: {integrity: sha512-cNLgeqCqV8WxfcTIOeL4OAtSmL8JjcN6m09XIgro1Wi7cF4t/THaWEa7eL5CMoMBdjoHOTh/vwTO/o2TRXIyzg==}\n     engines: {node: '>=18'}\n     cpu: [arm64]\n     os: [android]\n \n-  '@esbuild/android-arm@0.25.5':\n-    resolution: {integrity: sha512-AdJKSPeEHgi7/ZhuIPtcQKr5RQdo6OO2IL87JkianiMYMPbCtot9fxPbrMiBADOWWm3T2si9stAiVsGbTQFkbA==}\n+  '@esbuild/android-arm@0.24.2':\n+    resolution: {integrity: sha512-tmwl4hJkCfNHwFB3nBa8z1Uy3ypZpxqxfTQOcHX+xRByyYgunVbZ9MzUUfb0RxaHIMnbHagwAxuTL+tnNM+1/Q==}\n     engines: {node: '>=18'}\n     cpu: [arm]\n     os: [android]\n \n-  '@esbuild/android-x64@0.25.5':\n-    resolution: {integrity: sha512-D2GyJT1kjvO//drbRT3Hib9XPwQeWd9vZoBJn+bu/lVsOZ13cqNdDeqIF/xQ5/VmWvMduP6AmXvylO/PIc2isw==}\n+  '@esbuild/android-x64@0.24.2':\n+    resolution: {integrity: sha512-B6Q0YQDqMx9D7rvIcsXfmJfvUYLoP722bgfBlO5cGvNVb5V/+Y7nhBE3mHV9OpxBf4eAS2S68KZztiPaWq4XYw==}\n     engines: {node: '>=18'}\n     cpu: [x64]\n     os: [android]\n \n-  '@esbuild/darwin-arm64@0.25.5':\n-    resolution: {integrity: sha512-GtaBgammVvdF7aPIgH2jxMDdivezgFu6iKpmT+48+F8Hhg5J/sfnDieg0aeG/jfSvkYQU2/pceFPDKlqZzwnfQ==}\n+  '@esbuild/darwin-arm64@0.24.2':\n+    resolution: {integrity: sha512-kj3AnYWc+CekmZnS5IPu9D+HWtUI49hbnyqk0FLEJDbzCIQt7hg7ucF1SQAilhtYpIujfaHr6O0UHlzzSPdOeA==}\n     engines: {node: '>=18'}\n     cpu: [arm64]\n     os: [darwin]\n \n-  '@esbuild/darwin-x64@0.25.5':\n-    resolution: {integrity: sha512-1iT4FVL0dJ76/q1wd7XDsXrSW+oLoquptvh4CLR4kITDtqi2e/xwXwdCVH8hVHU43wgJdsq7Gxuzcs6Iq/7bxQ==}\n+  '@esbuild/darwin-x64@0.24.2':\n+    resolution: {integrity: sha512-WeSrmwwHaPkNR5H3yYfowhZcbriGqooyu3zI/3GGpF8AyUdsrrP0X6KumITGA9WOyiJavnGZUwPGvxvwfWPHIA==}\n     engines: {node: '>=18'}\n     cpu: [x64]\n     os: [darwin]\n \n-  '@esbuild/freebsd-arm64@0.25.5':\n-    resolution: {integrity: sha512-nk4tGP3JThz4La38Uy/gzyXtpkPW8zSAmoUhK9xKKXdBCzKODMc2adkB2+8om9BDYugz+uGV7sLmpTYzvmz6Sw==}\n+  '@esbuild/freebsd-arm64@0.24.2':\n+    resolution: {integrity: sha512-UN8HXjtJ0k/Mj6a9+5u6+2eZ2ERD7Edt1Q9IZiB5UZAIdPnVKDoG7mdTVGhHJIeEml60JteamR3qhsr1r8gXvg==}\n     engines: {node: '>=18'}\n     cpu: [arm64]\n     os: [freebsd]\n \n-  '@esbuild/freebsd-x64@0.25.5':\n-    resolution: {integrity: sha512-PrikaNjiXdR2laW6OIjlbeuCPrPaAl0IwPIaRv+SMV8CiM8i2LqVUHFC1+8eORgWyY7yhQY+2U2fA55mBzReaw==}\n+  '@esbuild/freebsd-x64@0.24.2':\n+    resolution: {integrity: sha512-TvW7wE/89PYW+IevEJXZ5sF6gJRDY/14hyIGFXdIucxCsbRmLUcjseQu1SyTko+2idmCw94TgyaEZi9HUSOe3Q==}\n     engines: {node: '>=18'}\n     cpu: [x64]\n     os: [freebsd]\n \n-  '@esbuild/linux-arm64@0.25.5':\n-    resolution: {integrity: sha512-Z9kfb1v6ZlGbWj8EJk9T6czVEjjq2ntSYLY2cw6pAZl4oKtfgQuS4HOq41M/BcoLPzrUbNd+R4BXFyH//nHxVg==}\n+  '@esbuild/linux-arm64@0.24.2':\n+    resolution: {integrity: sha512-7HnAD6074BW43YvvUmE/35Id9/NB7BeX5EoNkK9obndmZBUk8xmJJeU7DwmUeN7tkysslb2eSl6CTrYz6oEMQg==}\n     engines: {node: '>=18'}\n     cpu: [arm64]\n     os: [linux]\n \n-  '@esbuild/linux-arm@0.25.5':\n-    resolution: {integrity: sha512-cPzojwW2okgh7ZlRpcBEtsX7WBuqbLrNXqLU89GxWbNt6uIg78ET82qifUy3W6OVww6ZWobWub5oqZOVtwolfw==}\n+  '@esbuild/linux-arm@0.24.2':\n+    resolution: {integrity: sha512-n0WRM/gWIdU29J57hJyUdIsk0WarGd6To0s+Y+LwvlC55wt+GT/OgkwoXCXvIue1i1sSNWblHEig00GBWiJgfA==}\n     engines: {node: '>=18'}\n     cpu: [arm]\n     os: [linux]\n \n-  '@esbuild/linux-ia32@0.25.5':\n-    resolution: {integrity: sha512-sQ7l00M8bSv36GLV95BVAdhJ2QsIbCuCjh/uYrWiMQSUuV+LpXwIqhgJDcvMTj+VsQmqAHL2yYaasENvJ7CDKA==}\n+  '@esbuild/linux-ia32@0.24.2':\n+    resolution: {integrity: sha512-sfv0tGPQhcZOgTKO3oBE9xpHuUqguHvSo4jl+wjnKwFpapx+vUDcawbwPNuBIAYdRAvIDBfZVvXprIj3HA+Ugw==}\n     engines: {node: '>=18'}\n     cpu: [ia32]\n     os: [linux]\n \n-  '@esbuild/linux-loong64@0.25.5':\n-    resolution: {integrity: sha512-0ur7ae16hDUC4OL5iEnDb0tZHDxYmuQyhKhsPBV8f99f6Z9KQM02g33f93rNH5A30agMS46u2HP6qTdEt6Q1kg==}\n+  '@esbuild/linux-loong64@0.24.2':\n+    resolution: {integrity: sha512-CN9AZr8kEndGooS35ntToZLTQLHEjtVB5n7dl8ZcTZMonJ7CCfStrYhrzF97eAecqVbVJ7APOEe18RPI4KLhwQ==}\n     engines: {node: '>=18'}\n     cpu: [loong64]\n     os: [linux]\n \n-  '@esbuild/linux-mips64el@0.25.5':\n-    resolution: {integrity: sha512-kB/66P1OsHO5zLz0i6X0RxlQ+3cu0mkxS3TKFvkb5lin6uwZ/ttOkP3Z8lfR9mJOBk14ZwZ9182SIIWFGNmqmg==}\n+  '@esbuild/linux-mips64el@0.24.2':\n+    resolution: {integrity: sha512-iMkk7qr/wl3exJATwkISxI7kTcmHKE+BlymIAbHO8xanq/TjHaaVThFF6ipWzPHryoFsesNQJPE/3wFJw4+huw==}\n     engines: {node: '>=18'}\n     cpu: [mips64el]\n     os: [linux]\n \n-  '@esbuild/linux-ppc64@0.25.5':\n-    resolution: {integrity: sha512-UZCmJ7r9X2fe2D6jBmkLBMQetXPXIsZjQJCjgwpVDz+YMcS6oFR27alkgGv3Oqkv07bxdvw7fyB71/olceJhkQ==}\n+  '@esbuild/linux-ppc64@0.24.2':\n+    resolution: {integrity: sha512-shsVrgCZ57Vr2L8mm39kO5PPIb+843FStGt7sGGoqiiWYconSxwTiuswC1VJZLCjNiMLAMh34jg4VSEQb+iEbw==}\n     engines: {node: '>=18'}\n     cpu: [ppc64]\n     os: [linux]\n \n-  '@esbuild/linux-riscv64@0.25.5':\n-    resolution: {integrity: sha512-kTxwu4mLyeOlsVIFPfQo+fQJAV9mh24xL+y+Bm6ej067sYANjyEw1dNHmvoqxJUCMnkBdKpvOn0Ahql6+4VyeA==}\n+  '@esbuild/linux-riscv64@0.24.2':\n+    resolution: {integrity: sha512-4eSFWnU9Hhd68fW16GD0TINewo1L6dRrB+oLNNbYyMUAeOD2yCK5KXGK1GH4qD/kT+bTEXjsyTCiJGHPZ3eM9Q==}\n     engines: {node: '>=18'}\n     cpu: [riscv64]\n     os: [linux]\n \n-  '@esbuild/linux-s390x@0.25.5':\n-    resolution: {integrity: sha512-K2dSKTKfmdh78uJ3NcWFiqyRrimfdinS5ErLSn3vluHNeHVnBAFWC8a4X5N+7FgVE1EjXS1QDZbpqZBjfrqMTQ==}\n+  '@esbuild/linux-s390x@0.24.2':\n+    resolution: {integrity: sha512-S0Bh0A53b0YHL2XEXC20bHLuGMOhFDO6GN4b3YjRLK//Ep3ql3erpNcPlEFed93hsQAjAQDNsvcK+hV90FubSw==}\n     engines: {node: '>=18'}\n     cpu: [s390x]\n     os: [linux]\n \n-  '@esbuild/linux-x64@0.25.5':\n-    resolution: {integrity: sha512-uhj8N2obKTE6pSZ+aMUbqq+1nXxNjZIIjCjGLfsWvVpy7gKCOL6rsY1MhRh9zLtUtAI7vpgLMK6DxjO8Qm9lJw==}\n+  '@esbuild/linux-x64@0.24.2':\n+    resolution: {integrity: sha512-8Qi4nQcCTbLnK9WoMjdC9NiTG6/E38RNICU6sUNqK0QFxCYgoARqVqxdFmWkdonVsvGqWhmm7MO0jyTqLqwj0Q==}\n     engines: {node: '>=18'}\n     cpu: [x64]\n     os: [linux]\n \n-  '@esbuild/netbsd-arm64@0.25.5':\n-    resolution: {integrity: sha512-pwHtMP9viAy1oHPvgxtOv+OkduK5ugofNTVDilIzBLpoWAM16r7b/mxBvfpuQDpRQFMfuVr5aLcn4yveGvBZvw==}\n+  '@esbuild/netbsd-arm64@0.24.2':\n+    resolution: {integrity: sha512-wuLK/VztRRpMt9zyHSazyCVdCXlpHkKm34WUyinD2lzK07FAHTq0KQvZZlXikNWkDGoT6x3TD51jKQ7gMVpopw==}\n     engines: {node: '>=18'}\n     cpu: [arm64]\n     os: [netbsd]\n \n-  '@esbuild/netbsd-x64@0.25.5':\n-    resolution: {integrity: sha512-WOb5fKrvVTRMfWFNCroYWWklbnXH0Q5rZppjq0vQIdlsQKuw6mdSihwSo4RV/YdQ5UCKKvBy7/0ZZYLBZKIbwQ==}\n+  '@esbuild/netbsd-x64@0.24.2':\n+    resolution: {integrity: sha512-VefFaQUc4FMmJuAxmIHgUmfNiLXY438XrL4GDNV1Y1H/RW3qow68xTwjZKfj/+Plp9NANmzbH5R40Meudu8mmw==}\n     engines: {node: '>=18'}\n     cpu: [x64]\n     os: [netbsd]\n \n-  '@esbuild/openbsd-arm64@0.25.5':\n-    resolution: {integrity: sha512-7A208+uQKgTxHd0G0uqZO8UjK2R0DDb4fDmERtARjSHWxqMTye4Erz4zZafx7Di9Cv+lNHYuncAkiGFySoD+Mw==}\n+  '@esbuild/openbsd-arm64@0.24.2':\n+    resolution: {integrity: sha512-YQbi46SBct6iKnszhSvdluqDmxCJA+Pu280Av9WICNwQmMxV7nLRHZfjQzwbPs3jeWnuAhE9Jy0NrnJ12Oz+0A==}\n     engines: {node: '>=18'}\n     cpu: [arm64]\n     os: [openbsd]\n \n-  '@esbuild/openbsd-x64@0.25.5':\n-    resolution: {integrity: sha512-G4hE405ErTWraiZ8UiSoesH8DaCsMm0Cay4fsFWOOUcz8b8rC6uCvnagr+gnioEjWn0wC+o1/TAHt+It+MpIMg==}\n+  '@esbuild/openbsd-x64@0.24.2':\n+    resolution: {integrity: sha512-+iDS6zpNM6EnJyWv0bMGLWSWeXGN/HTaF/LXHXHwejGsVi+ooqDfMCCTerNFxEkM3wYVcExkeGXNqshc9iMaOA==}\n     engines: {node: '>=18'}\n     cpu: [x64]\n     os: [openbsd]\n \n-  '@esbuild/sunos-x64@0.25.5':\n-    resolution: {integrity: sha512-l+azKShMy7FxzY0Rj4RCt5VD/q8mG/e+mDivgspo+yL8zW7qEwctQ6YqKX34DTEleFAvCIUviCFX1SDZRSyMQA==}\n+  '@esbuild/sunos-x64@0.24.2':\n+    resolution: {integrity: sha512-hTdsW27jcktEvpwNHJU4ZwWFGkz2zRJUz8pvddmXPtXDzVKTTINmlmga3ZzwcuMpUvLw7JkLy9QLKyGpD2Yxig==}\n     engines: {node: '>=18'}\n     cpu: [x64]\n     os: [sunos]\n \n-  '@esbuild/win32-arm64@0.25.5':\n-    resolution: {integrity: sha512-O2S7SNZzdcFG7eFKgvwUEZ2VG9D/sn/eIiz8XRZ1Q/DO5a3s76Xv0mdBzVM5j5R639lXQmPmSo0iRpHqUUrsxw==}\n+  '@esbuild/win32-arm64@0.24.2':\n+    resolution: {integrity: sha512-LihEQ2BBKVFLOC9ZItT9iFprsE9tqjDjnbulhHoFxYQtQfai7qfluVODIYxt1PgdoyQkz23+01rzwNwYfutxUQ==}\n     engines: {node: '>=18'}\n     cpu: [arm64]\n     os: [win32]\n \n-  '@esbuild/win32-ia32@0.25.5':\n-    resolution: {integrity: sha512-onOJ02pqs9h1iMJ1PQphR+VZv8qBMQ77Klcsqv9CNW2w6yLqoURLcgERAIurY6QE63bbLuqgP9ATqajFLK5AMQ==}\n+  '@esbuild/win32-ia32@0.24.2':\n+    resolution: {integrity: sha512-q+iGUwfs8tncmFC9pcnD5IvRHAzmbwQ3GPS5/ceCyHdjXubwQWI12MKWSNSMYLJMq23/IUCvJMS76PDqXe1fxA==}\n     engines: {node: '>=18'}\n     cpu: [ia32]\n     os: [win32]\n \n-  '@esbuild/win32-x64@0.25.5':\n-    resolution: {integrity: sha512-TXv6YnJ8ZMVdX+SXWVBo/0p8LTcrUYngpWjvm91TMjjBQii7Oz11Lw5lbDV5Y0TzuhSJHwiH4hEtC1I42mMS0g==}\n+  '@esbuild/win32-x64@0.24.2':\n+    resolution: {integrity: sha512-7VTgWzgMGvup6aSqDPLiW5zHaxYJGTO4OokMjIlrCtf+VpEL+cXKtCvg723iguPYI5oaUNdS+/V7OU2gvXVWEg==}\n     engines: {node: '>=18'}\n     cpu: [x64]\n     os: [win32]\n@@ -1567,8 +1576,8 @@ packages:\n     resolution: {integrity: sha512-RuzCup9Ct91Y7V79xwCb146RaBRHZ7NBbrIUySumd1rpKqHL5OonaqrGIbug5hNwP/fRyxFMA6ISgw4FTtYFYg==}\n     engines: {node: '>=18'}\n \n-  '@napi-rs/wasm-runtime@0.2.11':\n-    resolution: {integrity: sha512-9DPkXtvHydrcOsopiYpUgPHpmj0HWZKMUnL2dZqpvC42lsratuBG06V5ipyno0fUek5VlFsNQ+AcFATSrJXgMA==}\n+  '@napi-rs/wasm-runtime@0.2.10':\n+    resolution: {integrity: sha512-bCsCyeZEwVErsGmyPNSzwfwFn4OdxBj0mmv6hOFucB/k81Ojdu68RbZdxYsRQUPc9l6SU5F/cG+bXgWs3oUgsQ==}\n \n   '@next/env@15.3.3':\n     resolution: {integrity: sha512-OdiMrzCl2Xi0VTjiQQUK0Xh7bJHnOuET2s+3V+Y40WJBAXrJeGA3f+I8MZJ/YQ3mVGi5XGR1L66oFlgqXhQ4Vw==}\n@@ -2907,68 +2916,68 @@ packages:\n   '@supabase/supabase-js@2.50.0':\n     resolution: {integrity: sha512-M1Gd5tPaaghYZ9OjeO1iORRqbTWFEz/cF3pPubRnMPzA+A8SiUsXXWDP+DWsASZcjEcVEcVQIAF38i5wrijYOg==}\n \n-  '@swc/core-darwin-arm64@1.12.1':\n-    resolution: {integrity: sha512-nUjWVcJ3YS2N40ZbKwYO2RJ4+o2tWYRzNOcIQp05FqW0+aoUCVMdAUUzQinPDynfgwVshDAXCKemY8X7nN5MaA==}\n+  '@swc/core-darwin-arm64@1.11.31':\n+    resolution: {integrity: sha512-NTEaYOts0OGSbJZc0O74xsji+64JrF1stmBii6D5EevWEtrY4wlZhm8SiP/qPrOB+HqtAihxWIukWkP2aSdGSQ==}\n     engines: {node: '>=10'}\n     cpu: [arm64]\n     os: [darwin]\n \n-  '@swc/core-darwin-x64@1.12.1':\n-    resolution: {integrity: sha512-OGm4a4d3OeJn+tRt8H/eiHgTFrJbS6r8mi/Ob65tAEXZGHN900T2kR7c5ALr0V2hBOQ8BfhexwPoQlGQP/B95w==}\n+  '@swc/core-darwin-x64@1.11.31':\n+    resolution: {integrity: sha512-THSGaSwT96JwXDwuXQ6yFBbn+xDMdyw7OmBpnweAWsh5DhZmQkALEm1DgdQO3+rrE99MkmzwAfclc0UmYro/OA==}\n     engines: {node: '>=10'}\n     cpu: [x64]\n     os: [darwin]\n \n-  '@swc/core-linux-arm-gnueabihf@1.12.1':\n-    resolution: {integrity: sha512-76YeeQKyK0EtNkQiNBZ0nbVGooPf9IucY0WqVXVpaU4wuG7ZyLEE2ZAIgXafIuzODGQoLfetue7I8boMxh1/MA==}\n+  '@swc/core-linux-arm-gnueabihf@1.11.31':\n+    resolution: {integrity: sha512-laKtQFnW7KHgE57Hx32os2SNAogcuIDxYE+3DYIOmDMqD7/1DCfJe6Rln2N9WcOw6HuDbDpyQavIwZNfSAa8vQ==}\n     engines: {node: '>=10'}\n     cpu: [arm]\n     os: [linux]\n \n-  '@swc/core-linux-arm64-gnu@1.12.1':\n-    resolution: {integrity: sha512-BxJDIJPq1+aCh9UsaSAN6wo3tuln8UhNXruOrzTI8/ElIig/3sAueDM6Eq7GvZSGGSA7ljhNATMJ0elD7lFatQ==}\n+  '@swc/core-linux-arm64-gnu@1.11.31':\n+    resolution: {integrity: sha512-T+vGw9aPE1YVyRxRr1n7NAdkbgzBzrXCCJ95xAZc/0+WUwmL77Z+js0J5v1KKTRxw4FvrslNCOXzMWrSLdwPSA==}\n     engines: {node: '>=10'}\n     cpu: [arm64]\n     os: [linux]\n \n-  '@swc/core-linux-arm64-musl@1.12.1':\n-    resolution: {integrity: sha512-NhLdbffSXvY0/FwUSAl4hKBlpe5GHQGXK8DxTo3HHjLsD9sCPYieo3vG0NQoUYAy4ZUY1WeGjyxeq4qZddJzEQ==}\n+  '@swc/core-linux-arm64-musl@1.11.31':\n+    resolution: {integrity: sha512-Mztp5NZkyd5MrOAG+kl+QSn0lL4Uawd4CK4J7wm97Hs44N9DHGIG5nOz7Qve1KZo407Y25lTxi/PqzPKHo61zQ==}\n     engines: {node: '>=10'}\n     cpu: [arm64]\n     os: [linux]\n \n-  '@swc/core-linux-x64-gnu@1.12.1':\n-    resolution: {integrity: sha512-CrYnV8SZIgArQ9LKH0xEF95PKXzX9WkRSc5j55arOSBeDCeDUQk1Bg/iKdnDiuj5HC1hZpvzwMzSBJjv+Z70jA==}\n+  '@swc/core-linux-x64-gnu@1.11.31':\n+    resolution: {integrity: sha512-DDVE0LZcXOWwOqFU1Xi7gdtiUg3FHA0vbGb3trjWCuI1ZtDZHEQYL4M3/2FjqKZtIwASrDvO96w91okZbXhvMg==}\n     engines: {node: '>=10'}\n     cpu: [x64]\n     os: [linux]\n \n-  '@swc/core-linux-x64-musl@1.12.1':\n-    resolution: {integrity: sha512-BQMl3d0HaGB0/h2xcKlGtjk/cGRn2tnbsaChAKcjFdCepblKBCz1pgO/mL7w5iXq3s57wMDUn++71/a5RAkZOA==}\n+  '@swc/core-linux-x64-musl@1.11.31':\n+    resolution: {integrity: sha512-mJA1MzPPRIfaBUHZi0xJQ4vwL09MNWDeFtxXb0r4Yzpf0v5Lue9ymumcBPmw/h6TKWms+Non4+TDquAsweuKSw==}\n     engines: {node: '>=10'}\n     cpu: [x64]\n     os: [linux]\n \n-  '@swc/core-win32-arm64-msvc@1.12.1':\n-    resolution: {integrity: sha512-b7NeGnpqTfmIGtUqXBl0KqoSmOnH64nRZoT5l4BAGdvwY7nxitWR94CqZuwyLPty/bLywmyDA9uO12Kvgb3+gg==}\n+  '@swc/core-win32-arm64-msvc@1.11.31':\n+    resolution: {integrity: sha512-RdtakUkNVAb/FFIMw3LnfNdlH1/ep6KgiPDRlmyUfd0WdIQ3OACmeBegEFNFTzi7gEuzy2Yxg4LWf4IUVk8/bg==}\n     engines: {node: '>=10'}\n     cpu: [arm64]\n     os: [win32]\n \n-  '@swc/core-win32-ia32-msvc@1.12.1':\n-    resolution: {integrity: sha512-iU/29X2D7cHBp1to62cUg/5Xk8K+lyOJiKIGGW5rdzTW/c2zz3d/ehgpzVP/rqC4NVr88MXspqHU4il5gmDajw==}\n+  '@swc/core-win32-ia32-msvc@1.11.31':\n+    resolution: {integrity: sha512-hErXdCGsg7swWdG1fossuL8542I59xV+all751mYlBoZ8kOghLSKObGQTkBbuNvc0sUKWfWg1X0iBuIhAYar+w==}\n     engines: {node: '>=10'}\n     cpu: [ia32]\n     os: [win32]\n \n-  '@swc/core-win32-x64-msvc@1.12.1':\n-    resolution: {integrity: sha512-+Zh+JKDwiFqV5N9yAd2DhYVGPORGh9cfenu1ptr9yge+eHAf7vZJcC3rnj6QMR1QJh0Y5VC9+YBjRFjZVA7XDw==}\n+  '@swc/core-win32-x64-msvc@1.11.31':\n+    resolution: {integrity: sha512-5t7SGjUBMMhF9b5j17ml/f/498kiBJNf4vZFNM421UGUEETdtjPN9jZIuQrowBkoFGJTCVL/ECM4YRtTH30u/A==}\n     engines: {node: '>=10'}\n     cpu: [x64]\n     os: [win32]\n \n-  '@swc/core@1.12.1':\n-    resolution: {integrity: sha512-aKXdDTqxTVFl/bKQZ3EQUjEMBEoF6JBv29moMZq0kbVO43na6u/u+3Vcbhbrh+A2N0X5OL4RaveuWfAjEgOmeA==}\n+  '@swc/core@1.11.31':\n+    resolution: {integrity: sha512-mAby9aUnKRjMEA7v8cVZS9Ah4duoRBnX7X6r5qrhTxErx+68MoY1TPrVwj/66/SWN3Bl+jijqAqoB8Qx0QE34A==}\n     engines: {node: '>=10'}\n     peerDependencies:\n       '@swc/helpers': '>=0.5.17'\n@@ -2988,8 +2997,8 @@ packages:\n     peerDependencies:\n       '@swc/core': '*'\n \n-  '@swc/types@0.1.23':\n-    resolution: {integrity: sha512-u1iIVZV9Q0jxY+yM2vw/hZGDNudsN85bBpTqzAQ9rzkxW9D+e3aEM4Han+ow518gSewkXgjmEK0BD79ZcNVgPw==}\n+  '@swc/types@0.1.21':\n+    resolution: {integrity: sha512-2YEtj5HJVbKivud9N4bpPBAyZhj4S2Ipe5LkUG94alTpr7in/GU/EARgPAd3BwU+YOmFVJC2+kjqhGRi3r0ZpQ==}\n \n   '@tanstack/react-table@8.21.3':\n     resolution: {integrity: sha512-5nNMTSETP4ykGegmVkhjcS8tTLW6Vl4axfEGQN3v0zdHYbK4UfoqfPChclTrJ4EoK9QynqAu9oUf8VEmrpZ5Ww==}\n@@ -3100,8 +3109,8 @@ packages:\n   '@types/estree@1.0.6':\n     resolution: {integrity: sha512-AYnb1nQyY49te+VRAVgmzfcgjYS91mY5P0TKUDCLEM+gNnA+3T6rWITXRLYCpahpqSQbN5cE+gHpnPyXjHWxcw==}\n \n-  '@types/estree@1.0.8':\n-    resolution: {integrity: sha512-dWHzHa2WqEXI/O1E9OjrocMTKJl2mSrEolh1Iomrv6U+JuNwaHXsXx9bLu5gG7BUWFIN0skIQJQ/L1rIex4X6w==}\n+  '@types/estree@1.0.7':\n+    resolution: {integrity: sha512-w28IoSUCJpidD/TGviZwwMJckNESJZXFu7NBZ5YJ4mEUnNraUn9Pm8HSZm/jDF1pDWYKspWE7oVphigUPRakIQ==}\n \n   '@types/graceful-fs@4.1.9':\n     resolution: {integrity: sha512-olP3sd1qOEe5dXTSaFvQG+02VdRXcdytWLAZsAq1PecU8uqQAhkrnbli7DagjtXKW/Bl7YJbUsa8MPcuc8LHEQ==}\n@@ -3166,8 +3175,11 @@ packages:\n   '@types/phoenix@1.6.6':\n     resolution: {integrity: sha512-PIzZZlEppgrpoT2QgbnDU+MMzuR6BbCjllj0bM70lWoejMeNJAxCchxnv7J3XFkI8MpygtRpzXrIlmWUBclP5A==}\n \n-  '@types/prop-types@15.7.15':\n-    resolution: {integrity: sha512-F6bEyamV9jKGAFBEmlQnesRPGOQqS2+Uwi0Em15xenOxHaf2hv6L8YCVn3rPdPJOiJfPiCnLIRyvwVaqMY3MIw==}\n+  '@types/prismjs@1.26.5':\n+    resolution: {integrity: sha512-AUZTa7hQ2KY5L7AmtSiqxlhWxb4ina0yd8hNbl4TWuqnv/pFP0nDMb3YrfSBf4hJVGLh2YEIBfKaBW/9UEl6IQ==}\n+\n+  '@types/prop-types@15.7.14':\n+    resolution: {integrity: sha512-gNMvNH49DJ7OJYv+KAKn0Xp45p8PLl6zo2YnvDIbTd4J6MER2BmWN49TG7n9LvkyihINxeKW8+3bfS2yDC9dzQ==}\n \n   '@types/react-dom@18.3.5':\n     resolution: {integrity: sha512-P4t6saawp+b/dFrUr2cvkVsfvPguwsxtH6dNIYRllMsefqFzkZk5UIjzyDOv5g1dXIPdG4Sp1yCR4Z6RCUsG/Q==}\n@@ -3192,8 +3204,8 @@ packages:\n   '@types/stack-utils@2.0.3':\n     resolution: {integrity: sha512-9aEbYZ3TbYMznPdcdr3SmIrLXwC/AKZXQeCf9Pgao5CKb8CyHuEX5jzWPTkvregvhRJHcpRO6BFoGW9ycaOkYw==}\n \n-  '@types/statuses@2.0.6':\n-    resolution: {integrity: sha512-xMAgYwceFhRA2zY+XbEA7mxYbA093wdiW8Vu6gZPGWy9cmOyU9XesH1tNcEWsKFd5Vzrqx5T3D38PWx1FIIXkA==}\n+  '@types/statuses@2.0.5':\n+    resolution: {integrity: sha512-jmIUGWrAiwu3dZpxntxieC+1n/5c3mjrImkmOSQ2NC5uP6cYO4aAZDdSmRcI5C1oiTmqlZGHC+/NmJrKogbP5A==}\n \n   '@types/stylis@4.2.5':\n     resolution: {integrity: sha512-1Xve+NMN7FWjY14vLoY5tL3BVEQ/n42YLwaqJIPYhotZ9uBHt87VceMwWQpzmdEt2TNXIorIFG+YeCUUW7RInw==}\n@@ -3225,160 +3237,150 @@ packages:\n   '@types/yargs@17.0.33':\n     resolution: {integrity: sha512-WpxBCKWPLr4xSsHgz511rFJAM+wS28w2zEO1QDNY5zM/S8ok70NNfztH0xwhqKyaK0OHCbN98LDAZuy1ctxDkA==}\n \n-  '@typescript-eslint/eslint-plugin@8.34.1':\n-    resolution: {integrity: sha512-STXcN6ebF6li4PxwNeFnqF8/2BNDvBupf2OPx2yWNzr6mKNGF7q49VM00Pz5FaomJyqvbXpY6PhO+T9w139YEQ==}\n+  '@typescript-eslint/eslint-plugin@8.33.1':\n+    resolution: {integrity: sha512-TDCXj+YxLgtvxvFlAvpoRv9MAncDLBV2oT9Bd7YBGC/b/sEURoOYuIwLI99rjWOfY3QtDzO+mk0n4AmdFExW8A==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n     peerDependencies:\n-      '@typescript-eslint/parser': ^8.34.1\n+      '@typescript-eslint/parser': ^8.33.1\n       eslint: ^8.57.0 || ^9.0.0\n       typescript: '>=4.8.4 <5.9.0'\n \n-  '@typescript-eslint/parser@8.34.1':\n-    resolution: {integrity: sha512-4O3idHxhyzjClSMJ0a29AcoK0+YwnEqzI6oz3vlRf3xw0zbzt15MzXwItOlnr5nIth6zlY2RENLsOPvhyrKAQA==}\n+  '@typescript-eslint/parser@8.33.1':\n+    resolution: {integrity: sha512-qwxv6dq682yVvgKKp2qWwLgRbscDAYktPptK4JPojCwwi3R9cwrvIxS4lvBpzmcqzR4bdn54Z0IG1uHFskW4dA==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n     peerDependencies:\n       eslint: ^8.57.0 || ^9.0.0\n       typescript: '>=4.8.4 <5.9.0'\n \n-  '@typescript-eslint/project-service@8.34.1':\n-    resolution: {integrity: sha512-nuHlOmFZfuRwLJKDGQOVc0xnQrAmuq1Mj/ISou5044y1ajGNp2BNliIqp7F2LPQ5sForz8lempMFCovfeS1XoA==}\n+  '@typescript-eslint/project-service@8.33.1':\n+    resolution: {integrity: sha512-DZR0efeNklDIHHGRpMpR5gJITQpu6tLr9lDJnKdONTC7vvzOlLAG/wcfxcdxEWrbiZApcoBCzXqU/Z458Za5Iw==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n     peerDependencies:\n       typescript: '>=4.8.4 <5.9.0'\n \n-  '@typescript-eslint/scope-manager@8.34.1':\n-    resolution: {integrity: sha512-beu6o6QY4hJAgL1E8RaXNC071G4Kso2MGmJskCFQhRhg8VOH/FDbC8soP8NHN7e/Hdphwp8G8cE6OBzC8o41ZA==}\n+  '@typescript-eslint/scope-manager@8.33.1':\n+    resolution: {integrity: sha512-dM4UBtgmzHR9bS0Rv09JST0RcHYearoEoo3pG5B6GoTR9XcyeqX87FEhPo+5kTvVfKCvfHaHrcgeJQc6mrDKrA==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n \n-  '@typescript-eslint/tsconfig-utils@8.34.1':\n-    resolution: {integrity: sha512-K4Sjdo4/xF9NEeA2khOb7Y5nY6NSXBnod87uniVYW9kHP+hNlDV8trUSFeynA2uxWam4gIWgWoygPrv9VMWrYg==}\n+  '@typescript-eslint/tsconfig-utils@8.33.1':\n+    resolution: {integrity: sha512-STAQsGYbHCF0/e+ShUQ4EatXQ7ceh3fBCXkNU7/MZVKulrlq1usH7t2FhxvCpuCi5O5oi1vmVaAjrGeL71OK1g==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n     peerDependencies:\n       typescript: '>=4.8.4 <5.9.0'\n \n-  '@typescript-eslint/type-utils@8.34.1':\n-    resolution: {integrity: sha512-Tv7tCCr6e5m8hP4+xFugcrwTOucB8lshffJ6zf1mF1TbU67R+ntCc6DzLNKM+s/uzDyv8gLq7tufaAhIBYeV8g==}\n+  '@typescript-eslint/type-utils@8.33.1':\n+    resolution: {integrity: sha512-1cG37d9xOkhlykom55WVwG2QRNC7YXlxMaMzqw2uPeJixBFfKWZgaP/hjAObqMN/u3fr5BrTwTnc31/L9jQ2ww==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n     peerDependencies:\n       eslint: ^8.57.0 || ^9.0.0\n       typescript: '>=4.8.4 <5.9.0'\n \n-  '@typescript-eslint/types@8.34.1':\n-    resolution: {integrity: sha512-rjLVbmE7HR18kDsjNIZQHxmv9RZwlgzavryL5Lnj2ujIRTeXlKtILHgRNmQ3j4daw7zd+mQgy+uyt6Zo6I0IGA==}\n+  '@typescript-eslint/types@8.33.1':\n+    resolution: {integrity: sha512-xid1WfizGhy/TKMTwhtVOgalHwPtV8T32MS9MaH50Cwvz6x6YqRIPdD2WvW0XaqOzTV9p5xdLY0h/ZusU5Lokg==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n \n-  '@typescript-eslint/typescript-estree@8.34.1':\n-    resolution: {integrity: sha512-rjCNqqYPuMUF5ODD+hWBNmOitjBWghkGKJg6hiCHzUvXRy6rK22Jd3rwbP2Xi+R7oYVvIKhokHVhH41BxPV5mA==}\n+  '@typescript-eslint/typescript-estree@8.33.1':\n+    resolution: {integrity: sha512-+s9LYcT8LWjdYWu7IWs7FvUxpQ/DGkdjZeE/GGulHvv8rvYwQvVaUZ6DE+j5x/prADUgSbbCWZ2nPI3usuVeOA==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n     peerDependencies:\n       typescript: '>=4.8.4 <5.9.0'\n \n-  '@typescript-eslint/utils@8.34.1':\n-    resolution: {integrity: sha512-mqOwUdZ3KjtGk7xJJnLbHxTuWVn3GO2WZZuM+Slhkun4+qthLdXx32C8xIXbO1kfCECb3jIs3eoxK3eryk7aoQ==}\n+  '@typescript-eslint/utils@8.33.1':\n+    resolution: {integrity: sha512-52HaBiEQUaRYqAXpfzWSR2U3gxk92Kw006+xZpElaPMg3C4PgM+A5LqwoQI1f9E5aZ/qlxAZxzm42WX+vn92SQ==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n     peerDependencies:\n       eslint: ^8.57.0 || ^9.0.0\n       typescript: '>=4.8.4 <5.9.0'\n \n-  '@typescript-eslint/visitor-keys@8.34.1':\n-    resolution: {integrity: sha512-xoh5rJ+tgsRKoXnkBPFRLZ7rjKM0AfVbC68UZ/ECXoDbfggb9RbEySN359acY1vS3qZ0jVTVWzbtfapwm5ztxw==}\n+  '@typescript-eslint/visitor-keys@8.33.1':\n+    resolution: {integrity: sha512-3i8NrFcZeeDHJ+7ZUuDkGT+UHq+XoFGsymNK2jZCOHcfEzRQ0BdpRtdpSx/Iyf3MHLWIcLS0COuOPibKQboIiQ==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n \n   '@ungap/structured-clone@1.3.0':\n     resolution: {integrity: sha512-WmoN8qaIAo7WTYWbAZuG8PYEhn5fkz7dZrqTBZ7dtt//lL2Gwms1IcnQ5yHqjDfX8Ft5j4YzDM23f87zBfDe9g==}\n \n-  '@unrs/resolver-binding-android-arm-eabi@1.9.0':\n-    resolution: {integrity: sha512-h1T2c2Di49ekF2TE8ZCoJkb+jwETKUIPDJ/nO3tJBKlLFPu+fyd93f0rGP/BvArKx2k2HlRM4kqkNarj3dvZlg==}\n-    cpu: [arm]\n-    os: [android]\n-\n-  '@unrs/resolver-binding-android-arm64@1.9.0':\n-    resolution: {integrity: sha512-sG1NHtgXtX8owEkJ11yn34vt0Xqzi3k9TJ8zppDmyG8GZV4kVWw44FHwKwHeEFl07uKPeC4ZoyuQaGh5ruJYPA==}\n-    cpu: [arm64]\n-    os: [android]\n-\n-  '@unrs/resolver-binding-darwin-arm64@1.9.0':\n-    resolution: {integrity: sha512-nJ9z47kfFnCxN1z/oYZS7HSNsFh43y2asePzTEZpEvK7kGyuShSl3RRXnm/1QaqFL+iP+BjMwuB+DYUymOkA5A==}\n+  '@unrs/resolver-binding-darwin-arm64@1.7.10':\n+    resolution: {integrity: sha512-ABsM3eEiL3yu903G0uxgvGAoIw011XjTzyEk//gGtuVY1PuXP2IJG6novd6DBjm7MaWmRV/CZFY1rWBXSlSVVw==}\n     cpu: [arm64]\n     os: [darwin]\n \n-  '@unrs/resolver-binding-darwin-x64@1.9.0':\n-    resolution: {integrity: sha512-TK+UA1TTa0qS53rjWn7cVlEKVGz2B6JYe0C++TdQjvWYIyx83ruwh0wd4LRxYBM5HeuAzXcylA9BH2trARXJTw==}\n+  '@unrs/resolver-binding-darwin-x64@1.7.10':\n+    resolution: {integrity: sha512-lGVWy4FQEDo/PuI1VQXaQCY0XUg4xUJilf3fQ8NY4wtsQTm9lbasbUYf3nkoma+O2/do90jQTqkb02S3meyTDg==}\n     cpu: [x64]\n     os: [darwin]\n \n-  '@unrs/resolver-binding-freebsd-x64@1.9.0':\n-    resolution: {integrity: sha512-6uZwzMRFcD7CcCd0vz3Hp+9qIL2jseE/bx3ZjaLwn8t714nYGwiE84WpaMCYjU+IQET8Vu/+BNAGtYD7BG/0yA==}\n+  '@unrs/resolver-binding-freebsd-x64@1.7.10':\n+    resolution: {integrity: sha512-g9XLCHzNGatY79JJNgxrUH6uAAfBDj2NWIlTnqQN5odwGKjyVfFZ5tFL1OxYPcxTHh384TY5lvTtF+fuEZNvBQ==}\n     cpu: [x64]\n     os: [freebsd]\n \n-  '@unrs/resolver-binding-linux-arm-gnueabihf@1.9.0':\n-    resolution: {integrity: sha512-bPUBksQfrgcfv2+mm+AZinaKq8LCFvt5PThYqRotqSuuZK1TVKkhbVMS/jvSRfYl7jr3AoZLYbDkItxgqMKRkg==}\n+  '@unrs/resolver-binding-linux-arm-gnueabihf@1.7.10':\n+    resolution: {integrity: sha512-zV0ZMNy50sJFJapsjec8onyL9YREQKT88V8KwMoOA+zki/duFUP0oyTlbax1jGKdh8rQnruvW9VYkovGvdBAsw==}\n     cpu: [arm]\n     os: [linux]\n \n-  '@unrs/resolver-binding-linux-arm-musleabihf@1.9.0':\n-    resolution: {integrity: sha512-uT6E7UBIrTdCsFQ+y0tQd3g5oudmrS/hds5pbU3h4s2t/1vsGWbbSKhBSCD9mcqaqkBwoqlECpUrRJCmldl8PA==}\n+  '@unrs/resolver-binding-linux-arm-musleabihf@1.7.10':\n+    resolution: {integrity: sha512-jQxgb1DIDI7goyrabh4uvyWWBrFRfF+OOnS9SbF15h52g3Qjn/u8zG7wOQ0NjtcSMftzO75TITu9aHuI7FcqQQ==}\n     cpu: [arm]\n     os: [linux]\n \n-  '@unrs/resolver-binding-linux-arm64-gnu@1.9.0':\n-    resolution: {integrity: sha512-vdqBh911wc5awE2bX2zx3eflbyv8U9xbE/jVKAm425eRoOVv/VseGZsqi3A3SykckSpF4wSROkbQPvbQFn8EsA==}\n+  '@unrs/resolver-binding-linux-arm64-gnu@1.7.10':\n+    resolution: {integrity: sha512-9wVVlO6+aNlm90YWitwSI++HyCyBkzYCwMi7QbuGrTxDFm2pAgtpT0OEliaI7tLS8lAWYuDbzRRCJDgsdm6nwg==}\n     cpu: [arm64]\n     os: [linux]\n \n-  '@unrs/resolver-binding-linux-arm64-musl@1.9.0':\n-    resolution: {integrity: sha512-/8JFZ/SnuDr1lLEVsxsuVwrsGquTvT51RZGvyDB/dOK3oYK2UqeXzgeyq6Otp8FZXQcEYqJwxb9v+gtdXn03eQ==}\n+  '@unrs/resolver-binding-linux-arm64-musl@1.7.10':\n+    resolution: {integrity: sha512-FtFweORChdXOes0RAAyTZp6I4PodU2cZiSILAbGaEKDXp378UOumD2vaAkWHNxpsreQUKRxG5O1uq9EoV1NiVQ==}\n     cpu: [arm64]\n     os: [linux]\n \n-  '@unrs/resolver-binding-linux-ppc64-gnu@1.9.0':\n-    resolution: {integrity: sha512-FkJjybtrl+rajTw4loI3L6YqSOpeZfDls4SstL/5lsP2bka9TiHUjgMBjygeZEis1oC8LfJTS8FSgpKPaQx2tQ==}\n+  '@unrs/resolver-binding-linux-ppc64-gnu@1.7.10':\n+    resolution: {integrity: sha512-B+hOjpG2ncCR96a9d9ww1dWVuRVC2NChD0bITgrUhEWBhpdv2o/Mu2l8MsB2fzjdV/ku+twaQhr8iLHBoZafZQ==}\n     cpu: [ppc64]\n     os: [linux]\n \n-  '@unrs/resolver-binding-linux-riscv64-gnu@1.9.0':\n-    resolution: {integrity: sha512-w/NZfHNeDusbqSZ8r/hp8iL4S39h4+vQMc9/vvzuIKMWKppyUGKm3IST0Qv0aOZ1rzIbl9SrDeIqK86ZpUK37w==}\n+  '@unrs/resolver-binding-linux-riscv64-gnu@1.7.10':\n+    resolution: {integrity: sha512-DS6jFDoQCFsnsdLXlj3z3THakQLBic63B6A0rpQ1kpkyKa3OzEfqhwRNVaywuUuOKP9bX55Jk2uqpvn/hGjKCg==}\n     cpu: [riscv64]\n     os: [linux]\n \n-  '@unrs/resolver-binding-linux-riscv64-musl@1.9.0':\n-    resolution: {integrity: sha512-bEPBosut8/8KQbUixPry8zg/fOzVOWyvwzOfz0C0Rw6dp+wIBseyiHKjkcSyZKv/98edrbMknBaMNJfA/UEdqw==}\n+  '@unrs/resolver-binding-linux-riscv64-musl@1.7.10':\n+    resolution: {integrity: sha512-A82SB6yEaA8EhIW2r0I7P+k5lg7zPscFnGs1Gna5rfPwoZjeUAGX76T55+DiyTiy08VFKUi79PGCulXnfjDq0g==}\n     cpu: [riscv64]\n     os: [linux]\n \n-  '@unrs/resolver-binding-linux-s390x-gnu@1.9.0':\n-    resolution: {integrity: sha512-LDtMT7moE3gK753gG4pc31AAqGUC86j3AplaFusc717EUGF9ZFJ356sdQzzZzkBk1XzMdxFyZ4f/i35NKM/lFA==}\n+  '@unrs/resolver-binding-linux-s390x-gnu@1.7.10':\n+    resolution: {integrity: sha512-J+VmOPH16U69QshCp9WS+Zuiuu9GWTISKchKIhLbS/6JSCEfw2A4N02whv2VmrkXE287xxZbhW1p6xlAXNzwqg==}\n     cpu: [s390x]\n     os: [linux]\n \n-  '@unrs/resolver-binding-linux-x64-gnu@1.9.0':\n-    resolution: {integrity: sha512-WmFd5KINHIXj8o1mPaT8QRjA9HgSXhN1gl9Da4IZihARihEnOylu4co7i/yeaIpcfsI6sYs33cNZKyHYDh0lrA==}\n+  '@unrs/resolver-binding-linux-x64-gnu@1.7.10':\n+    resolution: {integrity: sha512-bYTdDltcB/V3fEqpx8YDwDw8ta9uEg8TUbJOtek6JM42u9ciJ7R/jBjNeAOs+QbyxGDd2d6xkBaGwty1HzOz3Q==}\n     cpu: [x64]\n     os: [linux]\n \n-  '@unrs/resolver-binding-linux-x64-musl@1.9.0':\n-    resolution: {integrity: sha512-CYuXbANW+WgzVRIl8/QvZmDaZxrqvOldOwlbUjIM4pQ46FJ0W5cinJ/Ghwa/Ng1ZPMJMk1VFdsD/XwmCGIXBWg==}\n+  '@unrs/resolver-binding-linux-x64-musl@1.7.10':\n+    resolution: {integrity: sha512-NYZ1GvSuTokJ28lqcjrMTnGMySoo4dVcNK/nsNCKCXT++1zekZtJaE+N+4jc1kR7EV0fc1OhRrOGcSt7FT9t8w==}\n     cpu: [x64]\n     os: [linux]\n \n-  '@unrs/resolver-binding-wasm32-wasi@1.9.0':\n-    resolution: {integrity: sha512-6Rp2WH0OoitMYR57Z6VE8Y6corX8C6QEMWLgOV6qXiJIeZ1F9WGXY/yQ8yDC4iTraotyLOeJ2Asea0urWj2fKQ==}\n+  '@unrs/resolver-binding-wasm32-wasi@1.7.10':\n+    resolution: {integrity: sha512-MRjJhTaQzLoX8OtzRBQDJ84OJ8IX1FqpRAUSxp/JtPeak+fyDfhXaEjcA/fhfgrACUnvC+jWC52f/V6MixSKCQ==}\n     engines: {node: '>=14.0.0'}\n     cpu: [wasm32]\n \n-  '@unrs/resolver-binding-win32-arm64-msvc@1.9.0':\n-    resolution: {integrity: sha512-rknkrTRuvujprrbPmGeHi8wYWxmNVlBoNW8+4XF2hXUnASOjmuC9FNF1tGbDiRQWn264q9U/oGtixyO3BT8adQ==}\n+  '@unrs/resolver-binding-win32-arm64-msvc@1.7.10':\n+    resolution: {integrity: sha512-Cgw6qhdsfzXJnHb006CzqgaX8mD445x5FGKuueaLeH1ptCxDbzRs8wDm6VieOI7rdbstfYBaFtaYN7zBT5CUPg==}\n     cpu: [arm64]\n     os: [win32]\n \n-  '@unrs/resolver-binding-win32-ia32-msvc@1.9.0':\n-    resolution: {integrity: sha512-Ceymm+iBl+bgAICtgiHyMLz6hjxmLJKqBim8tDzpX61wpZOx2bPK6Gjuor7I2RiUynVjvvkoRIkrPyMwzBzF3A==}\n+  '@unrs/resolver-binding-win32-ia32-msvc@1.7.10':\n+    resolution: {integrity: sha512-Z7oECyIT2/HsrWpJ6wi2b+lVbPmWqQHuW5zeatafoRXizk1+2wUl+aSop1PF58XcyBuwPP2YpEUUpMZ8ILV4fA==}\n     cpu: [ia32]\n     os: [win32]\n \n-  '@unrs/resolver-binding-win32-x64-msvc@1.9.0':\n-    resolution: {integrity: sha512-k59o9ZyeyS0hAlcaKFezYSH2agQeRFEB7KoQLXl3Nb3rgkqT1NY9Vwy+SqODiLmYnEjxWJVRE/yq2jFVqdIxZw==}\n+  '@unrs/resolver-binding-win32-x64-msvc@1.7.10':\n+    resolution: {integrity: sha512-DGAOo5asNvDsmFgwkb7xsgxNyN0If6XFYwDIC1QlRE7kEYWIMRChtWJyHDf30XmGovDNOs/37krxhnga/nm/4w==}\n     cpu: [x64]\n     os: [win32]\n \n@@ -3474,8 +3476,8 @@ packages:\n     peerDependencies:\n       acorn: ^6.0.0 || ^7.0.0 || ^8.0.0\n \n-  acorn@8.15.0:\n-    resolution: {integrity: sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==}\n+  acorn@8.14.1:\n+    resolution: {integrity: sha512-OvQ/2pUDKmgfCg++xsTX1wGxfTaszcHVcTctW4UJB4hibJx2HXxxO5UmVgyjMa+ZDsiaf5wWLXYpRWMmBI0QHg==}\n     engines: {node: '>=0.4.0'}\n     hasBin: true\n \n@@ -3666,8 +3668,8 @@ packages:\n     peerDependencies:\n       playwright: '>1.0.0'\n \n-  axios@1.10.0:\n-    resolution: {integrity: sha512-/1xYAC4MP/HEG+3duIhFr4ZQXR4sQXOIe+o6sdqzeykGLx6Upp/1p8MHqhINOvGeP7xyNHe7tsiJByc4SSVUxw==}\n+  axios@1.9.0:\n+    resolution: {integrity: sha512-re4CqKTJaURpzbLHtIi6XpDv20/CnpXOtjRY5/CU32L8gU8ek9UIivcfvSWvmKEngmVbrUtPpdDwWDWL7DNHvg==}\n \n   axobject-query@4.1.0:\n     resolution: {integrity: sha512-qIj0G9wZbMGNLjLmg1PT6v2mE9AH2zlnADJD/2tC6E00hgmhUOfEB6greHPAfLRSufHqROIUTkw6E+M3lH0PTQ==}\n@@ -3752,11 +3754,11 @@ packages:\n   boring-avatars@1.11.2:\n     resolution: {integrity: sha512-3+wkwPeObwS4R37FGXMYViqc4iTrIRj5yzfX9Qy4mnpZ26sX41dGMhsAgmKks1r/uufY1pl4vpgzMWHYfJRb2A==}\n \n-  brace-expansion@1.1.12:\n-    resolution: {integrity: sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==}\n+  brace-expansion@1.1.11:\n+    resolution: {integrity: sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==}\n \n-  brace-expansion@2.0.2:\n-    resolution: {integrity: sha512-Jt0vHyM+jmUBqojB7E1NIYadt0vI0Qxjxd2TErW94wDz+E2LAm5vKMXXwg6ZZBTHPuUlDgQHKXvjGBdfcF1ZDQ==}\n+  brace-expansion@2.0.1:\n+    resolution: {integrity: sha512-XnAIvQ8eM+kC6aULx6wuQiwVsnzsi9d3WxzV3FpWTGA19F621kwdbsAcFKXgKUHZWsy+mY6iL1sHTxWEFCytDA==}\n \n   braces@3.0.3:\n     resolution: {integrity: sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==}\n@@ -3850,8 +3852,8 @@ packages:\n   camelize@1.0.1:\n     resolution: {integrity: sha512-dU+Tx2fsypxTgtLoE36npi3UqcjSSMNYfkqgmoEhtZrraP5VWq0K7FkWVTYa8eMPtnU/G2txVsfdCJTn9uzpuQ==}\n \n-  caniuse-lite@1.0.30001723:\n-    resolution: {integrity: sha512-1R/elMjtehrFejxwmexeXAtae5UO9iSyFn6G/I806CYC/BLyyBk1EPhrKBkWhy6wM6Xnm47dSJQec+tLJ39WHw==}\n+  caniuse-lite@1.0.30001721:\n+    resolution: {integrity: sha512-cOuvmUVtKrtEaoKiO0rSc29jcjwMwX5tOHDy4MgVFEWiUXj4uBMJkwI8MDySkgXidpMiHUcviogAvFi4pA2hDQ==}\n \n   case-sensitive-paths-webpack-plugin@2.4.0:\n     resolution: {integrity: sha512-roIFONhcxog0JSSWbvVAh3OocukmSgpqOH6YpMkCvav/ySIV3JKg4Dc8vYtQjYi/UxpNE36r/9v+VqTQqgkYmw==}\n@@ -4062,11 +4064,11 @@ packages:\n     resolution: {integrity: sha512-9Kr/j4O16ISv8zBBhJoi4bXOYNTkFLOqSL3UDB0njXxCXNezjeyVrJyGOWtgfs/q2km1gwBcfH8q1yEGoMYunA==}\n     engines: {node: '>=18'}\n \n-  core-js-compat@3.43.0:\n-    resolution: {integrity: sha512-2GML2ZsCc5LR7hZYz4AXmjQw8zuy2T//2QntwdnpuYI7jteT6GVYJL7F6C2C57R7gSYrcqVW3lAALefdbhBLDA==}\n+  core-js-compat@3.42.0:\n+    resolution: {integrity: sha512-bQasjMfyDGyaeWKBIu33lHh9qlSR0MFE/Nmc6nMjf/iU9b3rSMdAYz1Baxrv4lPdGUsTqZudHA4jIGSJy0SWZQ==}\n \n-  core-js-pure@3.43.0:\n-    resolution: {integrity: sha512-i/AgxU2+A+BbJdMxh3v7/vxi2SbFqxiFmg6VsDwYB4jkucrd1BZNA9a9gphC0fYMG5IBSgQcbQnk865VCLe7xA==}\n+  core-js-pure@3.42.0:\n+    resolution: {integrity: sha512-007bM04u91fF4kMgwom2I5cQxAFIy8jVulgr9eozILl/SZE53QOqnW/+vviC+wQWLv+AunBG+8Q0TLoeSsSxRQ==}\n \n   core-util-is@1.0.3:\n     resolution: {integrity: sha512-ZQBvi1DcpJ4GDqanjucZ2Hj3wEO5pZDS89BWbkcrvdxksJorwUDDZamX9ldFkp9aw2lmBDLgkObEA4DWNJ9FYQ==}\n@@ -4258,8 +4260,8 @@ packages:\n   decimal.js-light@2.5.1:\n     resolution: {integrity: sha512-qIMFpTMZmny+MMIitAB6D7iVPEorVw6YQRWkvarTkT4tBeSLLiHzcwj6q0MmYSFCiVpiqPJTJEYIrpcPzVEIvg==}\n \n-  decode-named-character-reference@1.2.0:\n-    resolution: {integrity: sha512-c6fcElNV6ShtZXmsgNgFFV5tVX2PaV4g+MOAkb8eXHvn6sryJBrZa9r0zV6+dtTyoCKxtDy5tyQ5ZwQuidtd+Q==}\n+  decode-named-character-reference@1.1.0:\n+    resolution: {integrity: sha512-Wy+JTSbFThEOXQIR2L6mxJvEs+veIzpmqD7ynWxMXGpnk3smkHQOp6forLdHsKpAMW9iJpaBBIxz285t1n1C3w==}\n \n   dedent@0.7.0:\n     resolution: {integrity: sha512-Q6fKUPqnAHAyhiUgFU7BUzLiv0kd8saH9al7tnu5Q/okj6dnupxyTgFIBjVzJATdfIAm9NAsvXNzjaKa+bxVyA==}\n@@ -4407,8 +4409,8 @@ packages:\n   eastasianwidth@0.2.0:\n     resolution: {integrity: sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==}\n \n-  electron-to-chromium@1.5.169:\n-    resolution: {integrity: sha512-q7SQx6mkLy0GTJK9K9OiWeaBMV4XQtBSdf6MJUzDB/H/5tFXfIiX38Lci1Kl6SsgiEhz1SQI1ejEOU5asWEhwQ==}\n+  electron-to-chromium@1.5.165:\n+    resolution: {integrity: sha512-naiMx1Z6Nb2TxPU6fiFrUrDTjyPMLdTtaOd2oLmG8zVSg2hCWGkhPyxwk+qRmZ1ytwVqUv0u7ZcDA5+ALhaUtw==}\n \n   elliptic@6.6.1:\n     resolution: {integrity: sha512-RaddvvMatK2LJHqFJ+YA4WysVN5Ita9E35botqIYspQ4TkRAlCicdzKOjlyv/1Za5RyTNn7di//eEV0uTAfe3g==}\n@@ -4506,8 +4508,8 @@ packages:\n     peerDependencies:\n       esbuild: '>=0.12 <1'\n \n-  esbuild@0.25.5:\n-    resolution: {integrity: sha512-P8OtKZRv/5J5hhz0cUAdu/cLuPIKXpQl1R9pZtvmHWQvrAUVd0UNIPT4IB4W3rNOqVO0rlqHmCIbSwxh/c9yUQ==}\n+  esbuild@0.24.2:\n+    resolution: {integrity: sha512-+9egpBW8I3CD5XPe0n6BfT5fxLzxrlDzqydF3aviG+9ni1lDC/OvMHcxqEFV0+LANZG5R1bFMWfUrjVsdwxJvA==}\n     engines: {node: '>=18'}\n     hasBin: true\n \n@@ -4619,8 +4621,8 @@ packages:\n     resolution: {integrity: sha512-wpc+LXeiyiisxPlEkUzU6svyS1frIO3Mgxj1fdy7Pm8Ygzguax2N3Fa/D/ag1WqbOprdI+uY6wMUl8/a2G+iag==}\n     engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}\n \n-  eslint-visitor-keys@4.2.1:\n-    resolution: {integrity: sha512-Uhdk5sfqcee/9H/rCOJikYz67o0a2Tw2hGRPOG2Y1R2dg7brRe1uG0yaNQDHu+TO/uQPF/5eCapvYSmHUjt7JQ==}\n+  eslint-visitor-keys@4.2.0:\n+    resolution: {integrity: sha512-UyLnSehNt62FFhSwjZlHmeokpRK59rcz29j+F1/aDgbkbRTk7wIc9XzdoasMUbRNKDM0qQt/+BJ4BrpFeABemw==}\n     engines: {node: ^18.18.0 || ^20.9.0 || >=21.1.0}\n \n   eslint@8.57.1:\n@@ -4742,8 +4744,8 @@ packages:\n   fb-watchman@2.0.2:\n     resolution: {integrity: sha512-p5161BqbuCaSnB8jIbzQHOlpgsPmK5rJVDfDKO91Axs5NC1uu3HRQm6wt9cd9/+GtQQIO53JdGXXoyDpTAsgYA==}\n \n-  fdir@6.4.6:\n-    resolution: {integrity: sha512-hiFoqpyZcfNm1yc4u8oWCf9A2c4D3QjCrks3zmoVKVxpQRzmPNar1hUJcBG2RQHvEVGDN+Jm81ZheVLAQMK6+w==}\n+  fdir@6.4.5:\n+    resolution: {integrity: sha512-4BG7puHpVsIYxZUbiUE3RqGloLaSSwzYie5jvasC4LWuBWzZawynvYouhjbQKw2JuIGYdm0DzIxl8iVidKlUEw==}\n     peerDependencies:\n       picomatch: ^3 || ^4\n     peerDependenciesMeta:\n@@ -4833,8 +4835,8 @@ packages:\n       typescript: '>3.6.0'\n       webpack: ^5.11.0\n \n-  form-data@4.0.3:\n-    resolution: {integrity: sha512-qsITQPfmvMOSAdeyZ+12I1c+CKSstAFAwu+97zrnWAbIr5u8wfsExUzCesVLC8NgHuRUqNN4Zy6UPWUTRGslcA==}\n+  form-data@4.0.2:\n+    resolution: {integrity: sha512-hGfm/slu0ZabnNt4oaRZ6uREyfCj6P4fT/n6A1rGV+Z0VdGXjfOhVUpkn6qVQONHGIFwmveGXyDs75+nr6FM8w==}\n     engines: {node: '>= 6'}\n \n   forwarded-parse@2.1.2:\n@@ -5711,8 +5713,8 @@ packages:\n     resolution: {integrity: sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==}\n     hasBin: true\n \n-  loupe@3.1.4:\n-    resolution: {integrity: sha512-wJzkKwJrheKtknCOKNEtDK4iqg/MxmZheEMtSTYvnzRdEYaZzmgH976nenp8WdJRdx5Vc1X/9MO0Oszl6ezeXg==}\n+  loupe@3.1.3:\n+    resolution: {integrity: sha512-kkIp7XSkP78ZxJEsSxW3712C6teJVoeHHwgo9zJ380de7IYyJ2ISlxojcH2pC5OFLewESmnRi/+XCDIEEVyoug==}\n \n   lower-case@2.0.2:\n     resolution: {integrity: sha512-7fm3l3NAF9WfN6W3JOmf5drwpVqX78JtoGJ3A6W0a6ZnldM41w2fV5D490psKFTpMds8TJse/eHLFFsNHHjHgg==}\n@@ -5924,11 +5926,11 @@ packages:\n   moment@2.30.1:\n     resolution: {integrity: sha512-uEmtNhbDOrWPFS+hdjFCBfy9f2YoyzRpwcl+DqpC6taX21FzsTLQVbMV/W7PzNSX6x/bhC1zA3c2UQ5NzH6how==}\n \n-  motion-dom@12.18.1:\n-    resolution: {integrity: sha512-dR/4EYT23Snd+eUSLrde63Ws3oXQtJNw/krgautvTfwrN/2cHfCZMdu6CeTxVfRRWREW3Fy1f5vobRDiBb/q+w==}\n+  motion-dom@12.16.0:\n+    resolution: {integrity: sha512-Z2nGwWrrdH4egLEtgYMCEN4V2qQt1qxlKy/uV7w691ztyA41Q5Rbn0KNGbsNVDZr9E8PD2IOQ3hSccRnB6xWzw==}\n \n-  motion-utils@12.18.1:\n-    resolution: {integrity: sha512-az26YDU4WoDP0ueAkUtABLk2BIxe28d8NH1qWT8jPGhPyf44XTdDUh8pDk9OPphaSrR9McgpcJlgwSOIw/sfkA==}\n+  motion-utils@12.12.1:\n+    resolution: {integrity: sha512-f9qiqUHm7hWSLlNW8gS9pisnsN7CRFRD58vNjptKdsqFLpkVnX00TNeD6Q0d27V9KzT7ySFyK1TZ/DShfVOv6w==}\n \n   ms@2.1.3:\n     resolution: {integrity: sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==}\n@@ -6275,21 +6277,11 @@ packages:\n     engines: {node: '>=18'}\n     hasBin: true\n \n-  playwright-core@1.53.0:\n-    resolution: {integrity: sha512-mGLg8m0pm4+mmtB7M89Xw/GSqoNC+twivl8ITteqvAndachozYe2ZA7srU6uleV1vEdAHYqjq+SV8SNxRRFYBw==}\n-    engines: {node: '>=18'}\n-    hasBin: true\n-\n   playwright@1.52.0:\n     resolution: {integrity: sha512-JAwMNMBlxJ2oD1kce4KPtMkDeKGHQstdpFPcPH3maElAXon/QZeTvtsfXmTMRyO9TslfoYOXkSsvao2nE1ilTw==}\n     engines: {node: '>=18'}\n     hasBin: true\n \n-  playwright@1.53.0:\n-    resolution: {integrity: sha512-ghGNnIEYZC4E+YtclRn4/p6oYbdPiASELBIYkBXfaTVKreQUYbMUYQDwS12a8F0/HtIjr/CkGjtwABeFPGcS4Q==}\n-    engines: {node: '>=18'}\n-    hasBin: true\n-\n   pnp-webpack-plugin@1.7.0:\n     resolution: {integrity: sha512-2Rb3vm+EXble/sMXNSu6eoBx8e79gKqhNq9F5ZWW6ERNCTE/Q0wQNne5541tE5vKjfM8hpNCYL+LGc1YTfI0dg==}\n     engines: {node: '>=6'}\n@@ -6483,6 +6475,11 @@ packages:\n     resolution: {integrity: sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==}\n     engines: {node: ^14.15.0 || ^16.10.0 || >=18.0.0}\n \n+  prism-react-renderer@2.4.1:\n+    resolution: {integrity: sha512-ey8Ls/+Di31eqzUxC46h8MksNuGx/n0AAC8uKpwFau4RPDYLuE3EXTp8N8G2vX2N7UC/+IXeNUnlWBGGcAG+Ig==}\n+    peerDependencies:\n+      react: '>=16.0.0'\n+\n   process-nextick-args@2.0.1:\n     resolution: {integrity: sha512-3ouUOpQhtgrbOa17J7+uxOTpITYWaGP7/AhoR3+A+/1e9skrzelGi/dXzEYyvbxubEF6Wn2ypscTKiKJFFn1ag==}\n \n@@ -6566,8 +6563,8 @@ packages:\n     peerDependencies:\n       react: '>=16.8.0'\n \n-  react-docgen-typescript@2.4.0:\n-    resolution: {integrity: sha512-ZtAp5XTO5HRzQctjPU0ybY0RRCQO19X/8fxn3w7y2VVTUbGHDKULPTL4ky3vB05euSgG5NpALhEhDPvQ56wvXg==}\n+  react-docgen-typescript@2.2.2:\n+    resolution: {integrity: sha512-tvg2ZtOpOi6QDwsb3GZhOjDkkX0h8Z2gipvTg6OVMUyoYoURhEiRNePT8NZItTVCDh39JJHnLdfCOkzoLbFnTg==}\n     peerDependencies:\n       typescript: '>= 4.3.x'\n \n@@ -6668,6 +6665,11 @@ packages:\n       '@types/react':\n         optional: true\n \n+  react-timeago@8.2.0:\n+    resolution: {integrity: sha512-RWDlG3Jj+iwv+yNEDweA/Qk1mxE8i/Oc4oW8Irp29ZfBp+eNpqqYPMLPYQJyfRMJcGB8CmWkEGMYhB4fW8eZlQ==}\n+    peerDependencies:\n+      react: ^16.0.0 || ^17.0.0 || ^18.0.0 || ^19.0.0\n+\n   react-transition-group@4.4.5:\n     resolution: {integrity: sha512-pZcd1MCJoiKiBR2NRxeCRg13uCXbydPnmB4EOeRrY7480qNWO8IIgQG6zlDkm6uRMsURXPuKq0GWtiM59a5Q6g==}\n     peerDependencies:\n@@ -7037,8 +7039,8 @@ packages:\n     resolution: {integrity: sha512-WjlahMgHmCJpqzU8bIBy4qtsZdU9lRlcZE3Lvyej6t4tuOuv1vk57OW3MBrj6hXBFx/nNoC9MPMTcr5YA7NQbg==}\n     engines: {node: '>=6'}\n \n-  statuses@2.0.2:\n-    resolution: {integrity: sha512-DvEy55V3DB7uknRo+4iOGT5fP1slR8wQohVdknigZPMpMstaKJQWhwiYBACJE3Ul2pTnATihhBYnRhZQHGBiRw==}\n+  statuses@2.0.1:\n+    resolution: {integrity: sha512-RwNA9Z/7PrK06rYLIzFMlaF+l73iwpzsqRIFgbMLbTcLD6cOao82TaWefPXQvB2fOC4AjuYSEndS7N/mTCbkdQ==}\n     engines: {node: '>= 0.8'}\n \n   stop-iteration-iterator@1.1.0:\n@@ -7153,14 +7155,14 @@ packages:\n     peerDependencies:\n       webpack: ^5.0.0\n \n-  style-to-js@1.1.17:\n-    resolution: {integrity: sha512-xQcBGDxJb6jjFCTzvQtfiPn6YvvP2O8U1MDIPNfJQlWMYfktPy+iGsHE7cssjs7y84d9fQaK4UF3RIJaAHSoYA==}\n+  style-to-js@1.1.16:\n+    resolution: {integrity: sha512-/Q6ld50hKYPH3d/r6nr117TZkHR0w0kGGIVfpG9N6D8NymRPM9RqCUv4pRpJ62E5DqOYx2AFpbZMyCPnjQCnOw==}\n \n-  style-to-object@1.0.9:\n-    resolution: {integrity: sha512-G4qppLgKu/k6FwRpHiGiKPaPTFcG3g4wNVX/Qsfu+RqQM30E7Tyu/TEgxcL9PNLF5pdRLwQdE3YKKf+KF2Dzlw==}\n+  style-to-object@1.0.8:\n+    resolution: {integrity: sha512-xT47I/Eo0rwJmaXC4oilDGDWLohVhR6o/xAQcPQN8q6QBuZVL8qMYL85kLmST5cPjAorwvqIA4qXTRQoYHaL6g==}\n \n-  styled-components@6.1.19:\n-    resolution: {integrity: sha512-1v/e3Dl1BknC37cXMhwGomhO8AkYmN41CqyX9xhUDxry1ns3BFQy2lLDRQXJRdVVWB9OHemv/53xaStimvWyuA==}\n+  styled-components@6.1.18:\n+    resolution: {integrity: sha512-Mvf3gJFzZCkhjY2Y/Fx9z1m3dxbza0uI9H1CbNZm/jSHCojzJhQ0R7bByrlFJINnMzz/gPulpoFFGymNwrsMcw==}\n     engines: {node: '>= 16'}\n     peerDependencies:\n       react: '>= 16.8.0'\n@@ -7219,6 +7221,17 @@ packages:\n   tailwind-merge@2.6.0:\n     resolution: {integrity: sha512-P+Vu1qXfzediirmHOC3xKGAYeZtPcV9g76X+xg2FD4tYgR71ewMA35Y3sCz3zhiN/dwefRpJX0yBcgwi1fXNQA==}\n \n+  tailwind-scrollbar-hide@2.0.0:\n+    resolution: {integrity: sha512-lqiIutHliEiODwBRHy4G2+Tcayo2U7+3+4frBmoMETD72qtah+XhOk5XcPzC1nJvXhXUdfl2ajlMhUc2qC6CIg==}\n+    peerDependencies:\n+      tailwindcss: '>=3.0.0 || >= 4.0.0 || >= 4.0.0-beta.8 || >= 4.0.0-alpha.20'\n+\n+  tailwind-scrollbar@4.0.2:\n+    resolution: {integrity: sha512-wAQiIxAPqk0MNTPptVe/xoyWi27y+NRGnTwvn4PQnbvB9kp8QUBiGl/wsfoVBHnQxTmhXJSNt9NHTmcz9EivFA==}\n+    engines: {node: '>=12.13.0'}\n+    peerDependencies:\n+      tailwindcss: 4.x\n+\n   tailwindcss-animate@1.0.7:\n     resolution: {integrity: sha512-bl6mpH3T7I3UFxuvDEXLxy/VuFxBk5bbzplh7tXI68mwMokNYd1t9qPBHlnyTwfa4JGC4zP516I1hYYtQ/vspA==}\n     peerDependencies:\n@@ -7249,8 +7262,8 @@ packages:\n       uglify-js:\n         optional: true\n \n-  terser@5.42.0:\n-    resolution: {integrity: sha512-UYCvU9YQW2f/Vwl+P0GfhxJxbUGLwd+5QrrGgLajzWAtC/23AX0vcise32kkP7Eu0Wu9VlzzHAXkLObgjQfFlQ==}\n+  terser@5.41.0:\n+    resolution: {integrity: sha512-H406eLPXpZbAX14+B8psIuvIr8+3c+2hkuYzpMkoE0ij+NdsVATbA78vb8neA/eqrj7rywa2pIkdmWRsXW6wmw==}\n     engines: {node: '>=10'}\n     hasBin: true\n \n@@ -7471,8 +7484,8 @@ packages:\n     resolution: {integrity: sha512-4/u/j4FrCKdi17jaxuJA0jClGxB1AvU2hw/IuayPc4ay1XGaJs/rbb4v5WKwAjNifjmXK9PIFyuPiaK8azyR9w==}\n     engines: {node: '>=14.0.0'}\n \n-  unrs-resolver@1.9.0:\n-    resolution: {integrity: sha512-wqaRu4UnzBD2ABTC1kLfBjAqIDZ5YUTr/MLGa7By47JV1bJDSW7jq/ZSLigB7enLe7ubNaJhtnBXgrc/50cEhg==}\n+  unrs-resolver@1.7.10:\n+    resolution: {integrity: sha512-CJEMJcz6vuwRK6xxWc+uf8AGi0OyfoVtHs5mExtNecS0HZq3a3Br1JC/InwwTn6uy+qkAdAdK+nJUYO9FPtgZw==}\n \n   update-browserslist-db@1.1.3:\n     resolution: {integrity: sha512-UxhIZQ+QInVdunkDAaiazvvT/+fXL5Osr0JZlJulepYu6Jd7qJtDZjlur0emRlT71EN3ScPoE7gvsuIKKNavKw==}\n@@ -8503,7 +8516,7 @@ snapshots:\n       babel-plugin-polyfill-corejs2: 0.4.13(@babel/core@7.27.4)\n       babel-plugin-polyfill-corejs3: 0.11.1(@babel/core@7.27.4)\n       babel-plugin-polyfill-regenerator: 0.6.4(@babel/core@7.27.4)\n-      core-js-compat: 3.43.0\n+      core-js-compat: 3.42.0\n       semver: 6.3.1\n     transitivePeerDependencies:\n       - supports-color\n@@ -8571,7 +8584,7 @@ snapshots:\n \n   '@bundled-es-modules/statuses@1.0.1':\n     dependencies:\n-      statuses: 2.0.2\n+      statuses: 2.0.1\n \n   '@bundled-es-modules/tough-cookie@0.1.6':\n     dependencies:\n@@ -8617,79 +8630,79 @@ snapshots:\n \n   '@emotion/unitless@0.8.1': {}\n \n-  '@esbuild/aix-ppc64@0.25.5':\n+  '@esbuild/aix-ppc64@0.24.2':\n     optional: true\n \n-  '@esbuild/android-arm64@0.25.5':\n+  '@esbuild/android-arm64@0.24.2':\n     optional: true\n \n-  '@esbuild/android-arm@0.25.5':\n+  '@esbuild/android-arm@0.24.2':\n     optional: true\n \n-  '@esbuild/android-x64@0.25.5':\n+  '@esbuild/android-x64@0.24.2':\n     optional: true\n \n-  '@esbuild/darwin-arm64@0.25.5':\n+  '@esbuild/darwin-arm64@0.24.2':\n     optional: true\n \n-  '@esbuild/darwin-x64@0.25.5':\n+  '@esbuild/darwin-x64@0.24.2':\n     optional: true\n \n-  '@esbuild/freebsd-arm64@0.25.5':\n+  '@esbuild/freebsd-arm64@0.24.2':\n     optional: true\n \n-  '@esbuild/freebsd-x64@0.25.5':\n+  '@esbuild/freebsd-x64@0.24.2':\n     optional: true\n \n-  '@esbuild/linux-arm64@0.25.5':\n+  '@esbuild/linux-arm64@0.24.2':\n     optional: true\n \n-  '@esbuild/linux-arm@0.25.5':\n+  '@esbuild/linux-arm@0.24.2':\n     optional: true\n \n-  '@esbuild/linux-ia32@0.25.5':\n+  '@esbuild/linux-ia32@0.24.2':\n     optional: true\n \n-  '@esbuild/linux-loong64@0.25.5':\n+  '@esbuild/linux-loong64@0.24.2':\n     optional: true\n \n-  '@esbuild/linux-mips64el@0.25.5':\n+  '@esbuild/linux-mips64el@0.24.2':\n     optional: true\n \n-  '@esbuild/linux-ppc64@0.25.5':\n+  '@esbuild/linux-ppc64@0.24.2':\n     optional: true\n \n-  '@esbuild/linux-riscv64@0.25.5':\n+  '@esbuild/linux-riscv64@0.24.2':\n     optional: true\n \n-  '@esbuild/linux-s390x@0.25.5':\n+  '@esbuild/linux-s390x@0.24.2':\n     optional: true\n \n-  '@esbuild/linux-x64@0.25.5':\n+  '@esbuild/linux-x64@0.24.2':\n     optional: true\n \n-  '@esbuild/netbsd-arm64@0.25.5':\n+  '@esbuild/netbsd-arm64@0.24.2':\n     optional: true\n \n-  '@esbuild/netbsd-x64@0.25.5':\n+  '@esbuild/netbsd-x64@0.24.2':\n     optional: true\n \n-  '@esbuild/openbsd-arm64@0.25.5':\n+  '@esbuild/openbsd-arm64@0.24.2':\n     optional: true\n \n-  '@esbuild/openbsd-x64@0.25.5':\n+  '@esbuild/openbsd-x64@0.24.2':\n     optional: true\n \n-  '@esbuild/sunos-x64@0.25.5':\n+  '@esbuild/sunos-x64@0.24.2':\n     optional: true\n \n-  '@esbuild/win32-arm64@0.25.5':\n+  '@esbuild/win32-arm64@0.24.2':\n     optional: true\n \n-  '@esbuild/win32-ia32@0.25.5':\n+  '@esbuild/win32-ia32@0.24.2':\n     optional: true\n \n-  '@esbuild/win32-x64@0.25.5':\n+  '@esbuild/win32-x64@0.24.2':\n     optional: true\n \n   '@eslint-community/eslint-utils@4.7.0(eslint@8.57.1)':\n@@ -9161,7 +9174,7 @@ snapshots:\n       outvariant: 1.4.3\n       strict-event-emitter: 0.5.1\n \n-  '@napi-rs/wasm-runtime@0.2.11':\n+  '@napi-rs/wasm-runtime@0.2.10':\n     dependencies:\n       '@emnapi/core': 1.4.3\n       '@emnapi/runtime': 1.4.3\n@@ -9481,17 +9494,17 @@ snapshots:\n     dependencies:\n       playwright: 1.52.0\n \n-  '@pmmmwh/react-refresh-webpack-plugin@0.5.16(react-refresh@0.14.2)(type-fest@4.41.0)(webpack-hot-middleware@2.26.1)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))':\n+  '@pmmmwh/react-refresh-webpack-plugin@0.5.16(react-refresh@0.14.2)(type-fest@4.41.0)(webpack-hot-middleware@2.26.1)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))':\n     dependencies:\n       ansi-html: 0.0.9\n-      core-js-pure: 3.43.0\n+      core-js-pure: 3.42.0\n       error-stack-parser: 2.1.4\n       html-entities: 2.6.0\n       loader-utils: 2.0.4\n       react-refresh: 0.14.2\n       schema-utils: 4.3.2\n       source-map: 0.7.4\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n     optionalDependencies:\n       type-fest: 4.41.0\n       webpack-hot-middleware: 2.26.1\n@@ -10047,7 +10060,7 @@ snapshots:\n       '@rollup/pluginutils': 5.1.4(rollup@4.35.0)\n       commondir: 1.0.1\n       estree-walker: 2.0.2\n-      fdir: 6.4.6(picomatch@4.0.2)\n+      fdir: 6.4.5(picomatch@4.0.2)\n       is-reference: 1.2.1\n       magic-string: 0.30.17\n       picomatch: 4.0.2\n@@ -10056,7 +10069,7 @@ snapshots:\n \n   '@rollup/pluginutils@5.1.4(rollup@4.35.0)':\n     dependencies:\n-      '@types/estree': 1.0.8\n+      '@types/estree': 1.0.7\n       estree-walker: 2.0.2\n       picomatch: 4.0.2\n     optionalDependencies:\n@@ -10209,7 +10222,7 @@ snapshots:\n \n   '@sentry/core@9.27.0': {}\n \n-  '@sentry/nextjs@9.27.0(@opentelemetry/context-async-hooks@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/core@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/instrumentation@0.57.2(@opentelemetry/api@1.9.0))(@opentelemetry/sdk-trace-base@1.30.1(@opentelemetry/api@1.9.0))(next@15.3.3(@babel/core@7.27.4)(@opentelemetry/api@1.9.0)(@playwright/test@1.52.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react@18.3.1)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))':\n+  '@sentry/nextjs@9.27.0(@opentelemetry/context-async-hooks@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/core@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/instrumentation@0.57.2(@opentelemetry/api@1.9.0))(@opentelemetry/sdk-trace-base@1.30.1(@opentelemetry/api@1.9.0))(next@15.3.3(@babel/core@7.27.4)(@opentelemetry/api@1.9.0)(@playwright/test@1.52.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react@18.3.1)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))':\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n       '@opentelemetry/semantic-conventions': 1.34.0\n@@ -10220,7 +10233,7 @@ snapshots:\n       '@sentry/opentelemetry': 9.27.0(@opentelemetry/api@1.9.0)(@opentelemetry/context-async-hooks@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/core@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/instrumentation@0.57.2(@opentelemetry/api@1.9.0))(@opentelemetry/sdk-trace-base@1.30.1(@opentelemetry/api@1.9.0))(@opentelemetry/semantic-conventions@1.34.0)\n       '@sentry/react': 9.27.0(react@18.3.1)\n       '@sentry/vercel-edge': 9.27.0\n-      '@sentry/webpack-plugin': 3.5.0(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      '@sentry/webpack-plugin': 3.5.0(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       chalk: 3.0.0\n       next: 15.3.3(@babel/core@7.27.4)(@opentelemetry/api@1.9.0)(@playwright/test@1.52.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)\n       resolve: 1.22.8\n@@ -10297,12 +10310,12 @@ snapshots:\n       '@opentelemetry/api': 1.9.0\n       '@sentry/core': 9.27.0\n \n-  '@sentry/webpack-plugin@3.5.0(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))':\n+  '@sentry/webpack-plugin@3.5.0(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))':\n     dependencies:\n       '@sentry/bundler-plugin-core': 3.5.0\n       unplugin: 1.0.1\n       uuid: 9.0.1\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n     transitivePeerDependencies:\n       - encoding\n       - supports-color\n@@ -10443,7 +10456,7 @@ snapshots:\n       react: 18.3.1\n       react-dom: 18.3.1(react@18.3.1)\n \n-  '@storybook/builder-webpack5@8.6.14(@swc/core@1.12.1)(esbuild@0.25.5)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)':\n+  '@storybook/builder-webpack5@8.6.14(@swc/core@1.11.31)(esbuild@0.24.2)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)':\n     dependencies:\n       '@storybook/core-webpack': 8.6.14(storybook@8.6.14(prettier@3.5.3))\n       '@types/semver': 7.7.0\n@@ -10451,23 +10464,23 @@ snapshots:\n       case-sensitive-paths-webpack-plugin: 2.4.0\n       cjs-module-lexer: 1.4.3\n       constants-browserify: 1.0.0\n-      css-loader: 6.11.0(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      css-loader: 6.11.0(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       es-module-lexer: 1.7.0\n-      fork-ts-checker-webpack-plugin: 8.0.0(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n-      html-webpack-plugin: 5.6.3(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      fork-ts-checker-webpack-plugin: 8.0.0(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n+      html-webpack-plugin: 5.6.3(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       magic-string: 0.30.17\n       path-browserify: 1.0.1\n       process: 0.11.10\n       semver: 7.7.2\n       storybook: 8.6.14(prettier@3.5.3)\n-      style-loader: 3.3.4(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n-      terser-webpack-plugin: 5.3.14(@swc/core@1.12.1)(esbuild@0.25.5)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      style-loader: 3.3.4(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n+      terser-webpack-plugin: 5.3.14(@swc/core@1.11.31)(esbuild@0.24.2)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       ts-dedent: 2.2.0\n       url: 0.11.4\n       util: 0.12.5\n       util-deprecate: 1.0.2\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n-      webpack-dev-middleware: 6.1.3(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n+      webpack-dev-middleware: 6.1.3(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       webpack-hot-middleware: 2.26.1\n       webpack-virtual-modules: 0.6.2\n     optionalDependencies:\n@@ -10493,8 +10506,8 @@ snapshots:\n       '@storybook/theming': 8.6.14(storybook@8.6.14(prettier@3.5.3))\n       better-opn: 3.0.2\n       browser-assert: 1.2.1\n-      esbuild: 0.25.5\n-      esbuild-register: 3.6.0(esbuild@0.25.5)\n+      esbuild: 0.24.2\n+      esbuild-register: 3.6.0(esbuild@0.24.2)\n       jsdoc-type-pratt-parser: 4.1.0\n       process: 0.11.10\n       recast: 0.23.11\n@@ -10535,7 +10548,7 @@ snapshots:\n     dependencies:\n       storybook: 8.6.14(prettier@3.5.3)\n \n-  '@storybook/nextjs@8.6.14(@swc/core@1.12.1)(esbuild@0.25.5)(next@15.3.3(@babel/core@7.27.4)(@opentelemetry/api@1.9.0)(@playwright/test@1.52.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(type-fest@4.41.0)(typescript@5.8.3)(webpack-hot-middleware@2.26.1)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))':\n+  '@storybook/nextjs@8.6.14(@swc/core@1.11.31)(esbuild@0.24.2)(next@15.3.3(@babel/core@7.27.4)(@opentelemetry/api@1.9.0)(@playwright/test@1.52.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(type-fest@4.41.0)(typescript@5.8.3)(webpack-hot-middleware@2.26.1)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))':\n     dependencies:\n       '@babel/core': 7.27.4\n       '@babel/plugin-syntax-bigint': 7.8.3(@babel/core@7.27.4)\n@@ -10550,30 +10563,30 @@ snapshots:\n       '@babel/preset-react': 7.27.1(@babel/core@7.27.4)\n       '@babel/preset-typescript': 7.27.1(@babel/core@7.27.4)\n       '@babel/runtime': 7.27.6\n-      '@pmmmwh/react-refresh-webpack-plugin': 0.5.16(react-refresh@0.14.2)(type-fest@4.41.0)(webpack-hot-middleware@2.26.1)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n-      '@storybook/builder-webpack5': 8.6.14(@swc/core@1.12.1)(esbuild@0.25.5)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)\n-      '@storybook/preset-react-webpack': 8.6.14(@storybook/test@8.6.14(storybook@8.6.14(prettier@3.5.3)))(@swc/core@1.12.1)(esbuild@0.25.5)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)\n+      '@pmmmwh/react-refresh-webpack-plugin': 0.5.16(react-refresh@0.14.2)(type-fest@4.41.0)(webpack-hot-middleware@2.26.1)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n+      '@storybook/builder-webpack5': 8.6.14(@swc/core@1.11.31)(esbuild@0.24.2)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)\n+      '@storybook/preset-react-webpack': 8.6.14(@storybook/test@8.6.14(storybook@8.6.14(prettier@3.5.3)))(@swc/core@1.11.31)(esbuild@0.24.2)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)\n       '@storybook/react': 8.6.14(@storybook/test@8.6.14(storybook@8.6.14(prettier@3.5.3)))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)\n       '@storybook/test': 8.6.14(storybook@8.6.14(prettier@3.5.3))\n       '@types/semver': 7.7.0\n-      babel-loader: 9.2.1(@babel/core@7.27.4)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n-      css-loader: 6.11.0(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      babel-loader: 9.2.1(@babel/core@7.27.4)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n+      css-loader: 6.11.0(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       find-up: 5.0.0\n       image-size: 1.2.1\n       loader-utils: 3.3.1\n       next: 15.3.3(@babel/core@7.27.4)(@opentelemetry/api@1.9.0)(@playwright/test@1.52.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)\n-      node-polyfill-webpack-plugin: 2.0.1(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      node-polyfill-webpack-plugin: 2.0.1(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       pnp-webpack-plugin: 1.7.0(typescript@5.8.3)\n       postcss: 8.5.4\n-      postcss-loader: 8.1.1(postcss@8.5.4)(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      postcss-loader: 8.1.1(postcss@8.5.4)(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       react: 18.3.1\n       react-dom: 18.3.1(react@18.3.1)\n       react-refresh: 0.14.2\n       resolve-url-loader: 5.0.0\n-      sass-loader: 14.2.1(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      sass-loader: 14.2.1(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       semver: 7.7.2\n       storybook: 8.6.14(prettier@3.5.3)\n-      style-loader: 3.3.4(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      style-loader: 3.3.4(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       styled-jsx: 5.1.7(@babel/core@7.27.4)(react@18.3.1)\n       ts-dedent: 2.2.0\n       tsconfig-paths: 4.2.0\n@@ -10581,7 +10594,7 @@ snapshots:\n     optionalDependencies:\n       sharp: 0.33.5\n       typescript: 5.8.3\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n     transitivePeerDependencies:\n       - '@rspack/core'\n       - '@swc/core'\n@@ -10600,11 +10613,11 @@ snapshots:\n       - webpack-hot-middleware\n       - webpack-plugin-serve\n \n-  '@storybook/preset-react-webpack@8.6.14(@storybook/test@8.6.14(storybook@8.6.14(prettier@3.5.3)))(@swc/core@1.12.1)(esbuild@0.25.5)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)':\n+  '@storybook/preset-react-webpack@8.6.14(@storybook/test@8.6.14(storybook@8.6.14(prettier@3.5.3)))(@swc/core@1.11.31)(esbuild@0.24.2)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)':\n     dependencies:\n       '@storybook/core-webpack': 8.6.14(storybook@8.6.14(prettier@3.5.3))\n       '@storybook/react': 8.6.14(@storybook/test@8.6.14(storybook@8.6.14(prettier@3.5.3)))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(storybook@8.6.14(prettier@3.5.3))(typescript@5.8.3)\n-      '@storybook/react-docgen-typescript-plugin': 1.0.6--canary.9.0c3f3b7.0(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      '@storybook/react-docgen-typescript-plugin': 1.0.6--canary.9.0c3f3b7.0(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       '@types/semver': 7.7.0\n       find-up: 5.0.0\n       magic-string: 0.30.17\n@@ -10615,7 +10628,7 @@ snapshots:\n       semver: 7.7.2\n       storybook: 8.6.14(prettier@3.5.3)\n       tsconfig-paths: 4.2.0\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n     optionalDependencies:\n       typescript: 5.8.3\n     transitivePeerDependencies:\n@@ -10630,17 +10643,17 @@ snapshots:\n     dependencies:\n       storybook: 8.6.14(prettier@3.5.3)\n \n-  '@storybook/react-docgen-typescript-plugin@1.0.6--canary.9.0c3f3b7.0(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))':\n+  '@storybook/react-docgen-typescript-plugin@1.0.6--canary.9.0c3f3b7.0(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))':\n     dependencies:\n       debug: 4.4.1\n       endent: 2.1.0\n       find-cache-dir: 3.3.2\n       flat-cache: 3.2.0\n       micromatch: 4.0.8\n-      react-docgen-typescript: 2.4.0(typescript@5.8.3)\n+      react-docgen-typescript: 2.2.2(typescript@5.8.3)\n       tslib: 2.8.1\n       typescript: 5.8.3\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n     transitivePeerDependencies:\n       - supports-color\n \n@@ -10673,8 +10686,8 @@ snapshots:\n       '@babel/types': 7.27.6\n       '@jest/types': 29.6.3\n       '@storybook/csf': 0.1.13\n-      '@swc/core': 1.12.1\n-      '@swc/jest': 0.2.38(@swc/core@1.12.1)\n+      '@swc/core': 1.11.31\n+      '@swc/jest': 0.2.38(@swc/core@1.11.31)\n       expect-playwright: 0.8.0\n       jest: 29.7.0(@types/node@22.15.30)\n       jest-circus: 29.7.0\n@@ -10685,7 +10698,7 @@ snapshots:\n       jest-serializer-html: 7.1.0\n       jest-watch-typeahead: 2.2.2(jest@29.7.0(@types/node@22.15.30))\n       nyc: 15.1.0\n-      playwright: 1.53.0\n+      playwright: 1.52.0\n       storybook: 8.6.14(prettier@3.5.3)\n     transitivePeerDependencies:\n       - '@swc/helpers'\n@@ -10758,51 +10771,51 @@ snapshots:\n       - bufferutil\n       - utf-8-validate\n \n-  '@swc/core-darwin-arm64@1.12.1':\n+  '@swc/core-darwin-arm64@1.11.31':\n     optional: true\n \n-  '@swc/core-darwin-x64@1.12.1':\n+  '@swc/core-darwin-x64@1.11.31':\n     optional: true\n \n-  '@swc/core-linux-arm-gnueabihf@1.12.1':\n+  '@swc/core-linux-arm-gnueabihf@1.11.31':\n     optional: true\n \n-  '@swc/core-linux-arm64-gnu@1.12.1':\n+  '@swc/core-linux-arm64-gnu@1.11.31':\n     optional: true\n \n-  '@swc/core-linux-arm64-musl@1.12.1':\n+  '@swc/core-linux-arm64-musl@1.11.31':\n     optional: true\n \n-  '@swc/core-linux-x64-gnu@1.12.1':\n+  '@swc/core-linux-x64-gnu@1.11.31':\n     optional: true\n \n-  '@swc/core-linux-x64-musl@1.12.1':\n+  '@swc/core-linux-x64-musl@1.11.31':\n     optional: true\n \n-  '@swc/core-win32-arm64-msvc@1.12.1':\n+  '@swc/core-win32-arm64-msvc@1.11.31':\n     optional: true\n \n-  '@swc/core-win32-ia32-msvc@1.12.1':\n+  '@swc/core-win32-ia32-msvc@1.11.31':\n     optional: true\n \n-  '@swc/core-win32-x64-msvc@1.12.1':\n+  '@swc/core-win32-x64-msvc@1.11.31':\n     optional: true\n \n-  '@swc/core@1.12.1':\n+  '@swc/core@1.11.31':\n     dependencies:\n       '@swc/counter': 0.1.3\n-      '@swc/types': 0.1.23\n+      '@swc/types': 0.1.21\n     optionalDependencies:\n-      '@swc/core-darwin-arm64': 1.12.1\n-      '@swc/core-darwin-x64': 1.12.1\n-      '@swc/core-linux-arm-gnueabihf': 1.12.1\n-      '@swc/core-linux-arm64-gnu': 1.12.1\n-      '@swc/core-linux-arm64-musl': 1.12.1\n-      '@swc/core-linux-x64-gnu': 1.12.1\n-      '@swc/core-linux-x64-musl': 1.12.1\n-      '@swc/core-win32-arm64-msvc': 1.12.1\n-      '@swc/core-win32-ia32-msvc': 1.12.1\n-      '@swc/core-win32-x64-msvc': 1.12.1\n+      '@swc/core-darwin-arm64': 1.11.31\n+      '@swc/core-darwin-x64': 1.11.31\n+      '@swc/core-linux-arm-gnueabihf': 1.11.31\n+      '@swc/core-linux-arm64-gnu': 1.11.31\n+      '@swc/core-linux-arm64-musl': 1.11.31\n+      '@swc/core-linux-x64-gnu': 1.11.31\n+      '@swc/core-linux-x64-musl': 1.11.31\n+      '@swc/core-win32-arm64-msvc': 1.11.31\n+      '@swc/core-win32-ia32-msvc': 1.11.31\n+      '@swc/core-win32-x64-msvc': 1.11.31\n \n   '@swc/counter@0.1.3': {}\n \n@@ -10810,14 +10823,14 @@ snapshots:\n     dependencies:\n       tslib: 2.8.1\n \n-  '@swc/jest@0.2.38(@swc/core@1.12.1)':\n+  '@swc/jest@0.2.38(@swc/core@1.11.31)':\n     dependencies:\n       '@jest/create-cache-key-function': 29.7.0\n-      '@swc/core': 1.12.1\n+      '@swc/core': 1.11.31\n       '@swc/counter': 0.1.3\n       jsonc-parser: 3.3.1\n \n-  '@swc/types@0.1.23':\n+  '@swc/types@0.1.21':\n     dependencies:\n       '@swc/counter': 0.1.3\n \n@@ -10938,20 +10951,20 @@ snapshots:\n   '@types/eslint-scope@3.7.7':\n     dependencies:\n       '@types/eslint': 9.6.1\n-      '@types/estree': 1.0.8\n+      '@types/estree': 1.0.7\n \n   '@types/eslint@9.6.1':\n     dependencies:\n-      '@types/estree': 1.0.8\n+      '@types/estree': 1.0.7\n       '@types/json-schema': 7.0.15\n \n   '@types/estree-jsx@1.0.5':\n     dependencies:\n-      '@types/estree': 1.0.8\n+      '@types/estree': 1.0.7\n \n   '@types/estree@1.0.6': {}\n \n-  '@types/estree@1.0.8': {}\n+  '@types/estree@1.0.7': {}\n \n   '@types/graceful-fs@4.1.9':\n     dependencies:\n@@ -11015,7 +11028,9 @@ snapshots:\n \n   '@types/phoenix@1.6.6': {}\n \n-  '@types/prop-types@15.7.15': {}\n+  '@types/prismjs@1.26.5': {}\n+\n+  '@types/prop-types@15.7.14': {}\n \n   '@types/react-dom@18.3.5(@types/react@18.3.17)':\n     dependencies:\n@@ -11027,7 +11042,7 @@ snapshots:\n \n   '@types/react@18.3.17':\n     dependencies:\n-      '@types/prop-types': 15.7.15\n+      '@types/prop-types': 15.7.14\n       csstype: 3.1.3\n \n   '@types/resolve@1.20.6': {}\n@@ -11038,7 +11053,7 @@ snapshots:\n \n   '@types/stack-utils@2.0.3': {}\n \n-  '@types/statuses@2.0.6': {}\n+  '@types/statuses@2.0.5': {}\n \n   '@types/stylis@4.2.5': {}\n \n@@ -11068,14 +11083,14 @@ snapshots:\n     dependencies:\n       '@types/yargs-parser': 21.0.3\n \n-  '@typescript-eslint/eslint-plugin@8.34.1(@typescript-eslint/parser@8.34.1(eslint@8.57.1)(typescript@5.8.3))(eslint@8.57.1)(typescript@5.8.3)':\n+  '@typescript-eslint/eslint-plugin@8.33.1(@typescript-eslint/parser@8.33.1(eslint@8.57.1)(typescript@5.8.3))(eslint@8.57.1)(typescript@5.8.3)':\n     dependencies:\n       '@eslint-community/regexpp': 4.12.1\n-      '@typescript-eslint/parser': 8.34.1(eslint@8.57.1)(typescript@5.8.3)\n-      '@typescript-eslint/scope-manager': 8.34.1\n-      '@typescript-eslint/type-utils': 8.34.1(eslint@8.57.1)(typescript@5.8.3)\n-      '@typescript-eslint/utils': 8.34.1(eslint@8.57.1)(typescript@5.8.3)\n-      '@typescript-eslint/visitor-keys': 8.34.1\n+      '@typescript-eslint/parser': 8.33.1(eslint@8.57.1)(typescript@5.8.3)\n+      '@typescript-eslint/scope-manager': 8.33.1\n+      '@typescript-eslint/type-utils': 8.33.1(eslint@8.57.1)(typescript@5.8.3)\n+      '@typescript-eslint/utils': 8.33.1(eslint@8.57.1)(typescript@5.8.3)\n+      '@typescript-eslint/visitor-keys': 8.33.1\n       eslint: 8.57.1\n       graphemer: 1.4.0\n       ignore: 7.0.5\n@@ -11085,40 +11100,40 @@ snapshots:\n     transitivePeerDependencies:\n       - supports-color\n \n-  '@typescript-eslint/parser@8.34.1(eslint@8.57.1)(typescript@5.8.3)':\n+  '@typescript-eslint/parser@8.33.1(eslint@8.57.1)(typescript@5.8.3)':\n     dependencies:\n-      '@typescript-eslint/scope-manager': 8.34.1\n-      '@typescript-eslint/types': 8.34.1\n-      '@typescript-eslint/typescript-estree': 8.34.1(typescript@5.8.3)\n-      '@typescript-eslint/visitor-keys': 8.34.1\n+      '@typescript-eslint/scope-manager': 8.33.1\n+      '@typescript-eslint/types': 8.33.1\n+      '@typescript-eslint/typescript-estree': 8.33.1(typescript@5.8.3)\n+      '@typescript-eslint/visitor-keys': 8.33.1\n       debug: 4.4.1\n       eslint: 8.57.1\n       typescript: 5.8.3\n     transitivePeerDependencies:\n       - supports-color\n \n-  '@typescript-eslint/project-service@8.34.1(typescript@5.8.3)':\n+  '@typescript-eslint/project-service@8.33.1(typescript@5.8.3)':\n     dependencies:\n-      '@typescript-eslint/tsconfig-utils': 8.34.1(typescript@5.8.3)\n-      '@typescript-eslint/types': 8.34.1\n+      '@typescript-eslint/tsconfig-utils': 8.33.1(typescript@5.8.3)\n+      '@typescript-eslint/types': 8.33.1\n       debug: 4.4.1\n       typescript: 5.8.3\n     transitivePeerDependencies:\n       - supports-color\n \n-  '@typescript-eslint/scope-manager@8.34.1':\n+  '@typescript-eslint/scope-manager@8.33.1':\n     dependencies:\n-      '@typescript-eslint/types': 8.34.1\n-      '@typescript-eslint/visitor-keys': 8.34.1\n+      '@typescript-eslint/types': 8.33.1\n+      '@typescript-eslint/visitor-keys': 8.33.1\n \n-  '@typescript-eslint/tsconfig-utils@8.34.1(typescript@5.8.3)':\n+  '@typescript-eslint/tsconfig-utils@8.33.1(typescript@5.8.3)':\n     dependencies:\n       typescript: 5.8.3\n \n-  '@typescript-eslint/type-utils@8.34.1(eslint@8.57.1)(typescript@5.8.3)':\n+  '@typescript-eslint/type-utils@8.33.1(eslint@8.57.1)(typescript@5.8.3)':\n     dependencies:\n-      '@typescript-eslint/typescript-estree': 8.34.1(typescript@5.8.3)\n-      '@typescript-eslint/utils': 8.34.1(eslint@8.57.1)(typescript@5.8.3)\n+      '@typescript-eslint/typescript-estree': 8.33.1(typescript@5.8.3)\n+      '@typescript-eslint/utils': 8.33.1(eslint@8.57.1)(typescript@5.8.3)\n       debug: 4.4.1\n       eslint: 8.57.1\n       ts-api-utils: 2.1.0(typescript@5.8.3)\n@@ -11126,14 +11141,14 @@ snapshots:\n     transitivePeerDependencies:\n       - supports-color\n \n-  '@typescript-eslint/types@8.34.1': {}\n+  '@typescript-eslint/types@8.33.1': {}\n \n-  '@typescript-eslint/typescript-estree@8.34.1(typescript@5.8.3)':\n+  '@typescript-eslint/typescript-estree@8.33.1(typescript@5.8.3)':\n     dependencies:\n-      '@typescript-eslint/project-service': 8.34.1(typescript@5.8.3)\n-      '@typescript-eslint/tsconfig-utils': 8.34.1(typescript@5.8.3)\n-      '@typescript-eslint/types': 8.34.1\n-      '@typescript-eslint/visitor-keys': 8.34.1\n+      '@typescript-eslint/project-service': 8.33.1(typescript@5.8.3)\n+      '@typescript-eslint/tsconfig-utils': 8.33.1(typescript@5.8.3)\n+      '@typescript-eslint/types': 8.33.1\n+      '@typescript-eslint/visitor-keys': 8.33.1\n       debug: 4.4.1\n       fast-glob: 3.3.3\n       is-glob: 4.0.3\n@@ -11144,81 +11159,75 @@ snapshots:\n     transitivePeerDependencies:\n       - supports-color\n \n-  '@typescript-eslint/utils@8.34.1(eslint@8.57.1)(typescript@5.8.3)':\n+  '@typescript-eslint/utils@8.33.1(eslint@8.57.1)(typescript@5.8.3)':\n     dependencies:\n       '@eslint-community/eslint-utils': 4.7.0(eslint@8.57.1)\n-      '@typescript-eslint/scope-manager': 8.34.1\n-      '@typescript-eslint/types': 8.34.1\n-      '@typescript-eslint/typescript-estree': 8.34.1(typescript@5.8.3)\n+      '@typescript-eslint/scope-manager': 8.33.1\n+      '@typescript-eslint/types': 8.33.1\n+      '@typescript-eslint/typescript-estree': 8.33.1(typescript@5.8.3)\n       eslint: 8.57.1\n       typescript: 5.8.3\n     transitivePeerDependencies:\n       - supports-color\n \n-  '@typescript-eslint/visitor-keys@8.34.1':\n+  '@typescript-eslint/visitor-keys@8.33.1':\n     dependencies:\n-      '@typescript-eslint/types': 8.34.1\n-      eslint-visitor-keys: 4.2.1\n+      '@typescript-eslint/types': 8.33.1\n+      eslint-visitor-keys: 4.2.0\n \n   '@ungap/structured-clone@1.3.0': {}\n \n-  '@unrs/resolver-binding-android-arm-eabi@1.9.0':\n-    optional: true\n-\n-  '@unrs/resolver-binding-android-arm64@1.9.0':\n+  '@unrs/resolver-binding-darwin-arm64@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-darwin-arm64@1.9.0':\n+  '@unrs/resolver-binding-darwin-x64@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-darwin-x64@1.9.0':\n+  '@unrs/resolver-binding-freebsd-x64@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-freebsd-x64@1.9.0':\n+  '@unrs/resolver-binding-linux-arm-gnueabihf@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-linux-arm-gnueabihf@1.9.0':\n+  '@unrs/resolver-binding-linux-arm-musleabihf@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-linux-arm-musleabihf@1.9.0':\n+  '@unrs/resolver-binding-linux-arm64-gnu@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-linux-arm64-gnu@1.9.0':\n+  '@unrs/resolver-binding-linux-arm64-musl@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-linux-arm64-musl@1.9.0':\n+  '@unrs/resolver-binding-linux-ppc64-gnu@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-linux-ppc64-gnu@1.9.0':\n+  '@unrs/resolver-binding-linux-riscv64-gnu@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-linux-riscv64-gnu@1.9.0':\n+  '@unrs/resolver-binding-linux-riscv64-musl@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-linux-riscv64-musl@1.9.0':\n+  '@unrs/resolver-binding-linux-s390x-gnu@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-linux-s390x-gnu@1.9.0':\n+  '@unrs/resolver-binding-linux-x64-gnu@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-linux-x64-gnu@1.9.0':\n+  '@unrs/resolver-binding-linux-x64-musl@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-linux-x64-musl@1.9.0':\n-    optional: true\n-\n-  '@unrs/resolver-binding-wasm32-wasi@1.9.0':\n+  '@unrs/resolver-binding-wasm32-wasi@1.7.10':\n     dependencies:\n-      '@napi-rs/wasm-runtime': 0.2.11\n+      '@napi-rs/wasm-runtime': 0.2.10\n     optional: true\n \n-  '@unrs/resolver-binding-win32-arm64-msvc@1.9.0':\n+  '@unrs/resolver-binding-win32-arm64-msvc@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-win32-ia32-msvc@1.9.0':\n+  '@unrs/resolver-binding-win32-ia32-msvc@1.7.10':\n     optional: true\n \n-  '@unrs/resolver-binding-win32-x64-msvc@1.9.0':\n+  '@unrs/resolver-binding-win32-x64-msvc@1.7.10':\n     optional: true\n \n   '@vitest/expect@2.0.5':\n@@ -11244,13 +11253,13 @@ snapshots:\n     dependencies:\n       '@vitest/pretty-format': 2.0.5\n       estree-walker: 3.0.3\n-      loupe: 3.1.4\n+      loupe: 3.1.3\n       tinyrainbow: 1.2.0\n \n   '@vitest/utils@2.1.9':\n     dependencies:\n       '@vitest/pretty-format': 2.1.9\n-      loupe: 3.1.4\n+      loupe: 3.1.3\n       tinyrainbow: 1.2.0\n \n   '@webassemblyjs/ast@1.14.1':\n@@ -11358,15 +11367,15 @@ snapshots:\n     dependencies:\n       event-target-shim: 5.0.1\n \n-  acorn-import-attributes@1.9.5(acorn@8.15.0):\n+  acorn-import-attributes@1.9.5(acorn@8.14.1):\n     dependencies:\n-      acorn: 8.15.0\n+      acorn: 8.14.1\n \n-  acorn-jsx@5.3.2(acorn@8.15.0):\n+  acorn-jsx@5.3.2(acorn@8.14.1):\n     dependencies:\n-      acorn: 8.15.0\n+      acorn: 8.14.1\n \n-  acorn@8.15.0: {}\n+  acorn@8.14.1: {}\n \n   adjust-sourcemap-loader@4.0.0:\n     dependencies:\n@@ -11572,19 +11581,19 @@ snapshots:\n       axe-core: 4.10.3\n       mustache: 4.2.0\n \n-  axe-playwright@2.1.0(playwright@1.53.0):\n+  axe-playwright@2.1.0(playwright@1.52.0):\n     dependencies:\n       '@types/junit-report-builder': 3.0.2\n       axe-core: 4.10.3\n       axe-html-reporter: 2.2.11(axe-core@4.10.3)\n       junit-report-builder: 5.1.1\n       picocolors: 1.1.1\n-      playwright: 1.53.0\n+      playwright: 1.52.0\n \n-  axios@1.10.0:\n+  axios@1.9.0:\n     dependencies:\n       follow-redirects: 1.15.9\n-      form-data: 4.0.3\n+      form-data: 4.0.2\n       proxy-from-env: 1.1.0\n     transitivePeerDependencies:\n       - debug\n@@ -11604,12 +11613,12 @@ snapshots:\n     transitivePeerDependencies:\n       - supports-color\n \n-  babel-loader@9.2.1(@babel/core@7.27.4)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)):\n+  babel-loader@9.2.1(@babel/core@7.27.4)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)):\n     dependencies:\n       '@babel/core': 7.27.4\n       find-cache-dir: 4.0.0\n       schema-utils: 4.3.2\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n \n   babel-plugin-istanbul@6.1.1:\n     dependencies:\n@@ -11641,7 +11650,7 @@ snapshots:\n     dependencies:\n       '@babel/core': 7.27.4\n       '@babel/helper-define-polyfill-provider': 0.6.4(@babel/core@7.27.4)\n-      core-js-compat: 3.43.0\n+      core-js-compat: 3.42.0\n     transitivePeerDependencies:\n       - supports-color\n \n@@ -11699,12 +11708,12 @@ snapshots:\n \n   boring-avatars@1.11.2: {}\n \n-  brace-expansion@1.1.12:\n+  brace-expansion@1.1.11:\n     dependencies:\n       balanced-match: 1.0.2\n       concat-map: 0.0.1\n \n-  brace-expansion@2.0.2:\n+  brace-expansion@2.0.1:\n     dependencies:\n       balanced-match: 1.0.2\n \n@@ -11763,8 +11772,8 @@ snapshots:\n \n   browserslist@4.25.0:\n     dependencies:\n-      caniuse-lite: 1.0.30001723\n-      electron-to-chromium: 1.5.169\n+      caniuse-lite: 1.0.30001721\n+      electron-to-chromium: 1.5.165\n       node-releases: 2.0.19\n       update-browserslist-db: 1.1.3(browserslist@4.25.0)\n \n@@ -11826,7 +11835,7 @@ snapshots:\n \n   camelize@1.0.1: {}\n \n-  caniuse-lite@1.0.30001723: {}\n+  caniuse-lite@1.0.30001721: {}\n \n   case-sensitive-paths-webpack-plugin@2.4.0: {}\n \n@@ -11837,7 +11846,7 @@ snapshots:\n       assertion-error: 2.0.1\n       check-error: 2.1.1\n       deep-eql: 5.0.2\n-      loupe: 3.1.4\n+      loupe: 3.1.3\n       pathval: 2.0.0\n \n   chalk@2.4.2:\n@@ -12013,11 +12022,11 @@ snapshots:\n \n   cookie@1.0.2: {}\n \n-  core-js-compat@3.43.0:\n+  core-js-compat@3.42.0:\n     dependencies:\n       browserslist: 4.25.0\n \n-  core-js-pure@3.43.0: {}\n+  core-js-pure@3.42.0: {}\n \n   core-util-is@1.0.3: {}\n \n@@ -12098,7 +12107,7 @@ snapshots:\n \n   css-color-keywords@1.0.0: {}\n \n-  css-loader@6.11.0(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)):\n+  css-loader@6.11.0(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)):\n     dependencies:\n       icss-utils: 5.1.0(postcss@8.5.4)\n       postcss: 8.5.4\n@@ -12109,7 +12118,7 @@ snapshots:\n       postcss-value-parser: 4.2.0\n       semver: 7.7.2\n     optionalDependencies:\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n \n   css-select@4.3.0:\n     dependencies:\n@@ -12238,7 +12247,7 @@ snapshots:\n \n   decimal.js-light@2.5.1: {}\n \n-  decode-named-character-reference@1.2.0:\n+  decode-named-character-reference@1.1.0:\n     dependencies:\n       character-entities: 2.0.2\n \n@@ -12380,7 +12389,7 @@ snapshots:\n \n   eastasianwidth@0.2.0: {}\n \n-  electron-to-chromium@1.5.169: {}\n+  electron-to-chromium@1.5.165: {}\n \n   elliptic@6.6.1:\n     dependencies:\n@@ -12542,40 +12551,40 @@ snapshots:\n \n   es6-error@4.1.1: {}\n \n-  esbuild-register@3.6.0(esbuild@0.25.5):\n+  esbuild-register@3.6.0(esbuild@0.24.2):\n     dependencies:\n       debug: 4.4.1\n-      esbuild: 0.25.5\n+      esbuild: 0.24.2\n     transitivePeerDependencies:\n       - supports-color\n \n-  esbuild@0.25.5:\n+  esbuild@0.24.2:\n     optionalDependencies:\n-      '@esbuild/aix-ppc64': 0.25.5\n-      '@esbuild/android-arm': 0.25.5\n-      '@esbuild/android-arm64': 0.25.5\n-      '@esbuild/android-x64': 0.25.5\n-      '@esbuild/darwin-arm64': 0.25.5\n-      '@esbuild/darwin-x64': 0.25.5\n-      '@esbuild/freebsd-arm64': 0.25.5\n-      '@esbuild/freebsd-x64': 0.25.5\n-      '@esbuild/linux-arm': 0.25.5\n-      '@esbuild/linux-arm64': 0.25.5\n-      '@esbuild/linux-ia32': 0.25.5\n-      '@esbuild/linux-loong64': 0.25.5\n-      '@esbuild/linux-mips64el': 0.25.5\n-      '@esbuild/linux-ppc64': 0.25.5\n-      '@esbuild/linux-riscv64': 0.25.5\n-      '@esbuild/linux-s390x': 0.25.5\n-      '@esbuild/linux-x64': 0.25.5\n-      '@esbuild/netbsd-arm64': 0.25.5\n-      '@esbuild/netbsd-x64': 0.25.5\n-      '@esbuild/openbsd-arm64': 0.25.5\n-      '@esbuild/openbsd-x64': 0.25.5\n-      '@esbuild/sunos-x64': 0.25.5\n-      '@esbuild/win32-arm64': 0.25.5\n-      '@esbuild/win32-ia32': 0.25.5\n-      '@esbuild/win32-x64': 0.25.5\n+      '@esbuild/aix-ppc64': 0.24.2\n+      '@esbuild/android-arm': 0.24.2\n+      '@esbuild/android-arm64': 0.24.2\n+      '@esbuild/android-x64': 0.24.2\n+      '@esbuild/darwin-arm64': 0.24.2\n+      '@esbuild/darwin-x64': 0.24.2\n+      '@esbuild/freebsd-arm64': 0.24.2\n+      '@esbuild/freebsd-x64': 0.24.2\n+      '@esbuild/linux-arm': 0.24.2\n+      '@esbuild/linux-arm64': 0.24.2\n+      '@esbuild/linux-ia32': 0.24.2\n+      '@esbuild/linux-loong64': 0.24.2\n+      '@esbuild/linux-mips64el': 0.24.2\n+      '@esbuild/linux-ppc64': 0.24.2\n+      '@esbuild/linux-riscv64': 0.24.2\n+      '@esbuild/linux-s390x': 0.24.2\n+      '@esbuild/linux-x64': 0.24.2\n+      '@esbuild/netbsd-arm64': 0.24.2\n+      '@esbuild/netbsd-x64': 0.24.2\n+      '@esbuild/openbsd-arm64': 0.24.2\n+      '@esbuild/openbsd-x64': 0.24.2\n+      '@esbuild/sunos-x64': 0.24.2\n+      '@esbuild/win32-arm64': 0.24.2\n+      '@esbuild/win32-ia32': 0.24.2\n+      '@esbuild/win32-x64': 0.24.2\n \n   escalade@3.2.0: {}\n \n@@ -12589,12 +12598,12 @@ snapshots:\n     dependencies:\n       '@next/eslint-plugin-next': 15.3.3\n       '@rushstack/eslint-patch': 1.11.0\n-      '@typescript-eslint/eslint-plugin': 8.34.1(@typescript-eslint/parser@8.34.1(eslint@8.57.1)(typescript@5.8.3))(eslint@8.57.1)(typescript@5.8.3)\n-      '@typescript-eslint/parser': 8.34.1(eslint@8.57.1)(typescript@5.8.3)\n+      '@typescript-eslint/eslint-plugin': 8.33.1(@typescript-eslint/parser@8.33.1(eslint@8.57.1)(typescript@5.8.3))(eslint@8.57.1)(typescript@5.8.3)\n+      '@typescript-eslint/parser': 8.33.1(eslint@8.57.1)(typescript@5.8.3)\n       eslint: 8.57.1\n       eslint-import-resolver-node: 0.3.9\n       eslint-import-resolver-typescript: 3.10.1(eslint-plugin-import@2.31.0)(eslint@8.57.1)\n-      eslint-plugin-import: 2.31.0(@typescript-eslint/parser@8.34.1(eslint@8.57.1)(typescript@5.8.3))(eslint-import-resolver-typescript@3.10.1)(eslint@8.57.1)\n+      eslint-plugin-import: 2.31.0(@typescript-eslint/parser@8.33.1(eslint@8.57.1)(typescript@5.8.3))(eslint-import-resolver-typescript@3.10.1)(eslint@8.57.1)\n       eslint-plugin-jsx-a11y: 6.10.2(eslint@8.57.1)\n       eslint-plugin-react: 7.37.5(eslint@8.57.1)\n       eslint-plugin-react-hooks: 5.2.0(eslint@8.57.1)\n@@ -12622,24 +12631,24 @@ snapshots:\n       is-bun-module: 2.0.0\n       stable-hash: 0.0.5\n       tinyglobby: 0.2.14\n-      unrs-resolver: 1.9.0\n+      unrs-resolver: 1.7.10\n     optionalDependencies:\n-      eslint-plugin-import: 2.31.0(@typescript-eslint/parser@8.34.1(eslint@8.57.1)(typescript@5.8.3))(eslint-import-resolver-typescript@3.10.1)(eslint@8.57.1)\n+      eslint-plugin-import: 2.31.0(@typescript-eslint/parser@8.33.1(eslint@8.57.1)(typescript@5.8.3))(eslint-import-resolver-typescript@3.10.1)(eslint@8.57.1)\n     transitivePeerDependencies:\n       - supports-color\n \n-  eslint-module-utils@2.12.0(@typescript-eslint/parser@8.34.1(eslint@8.57.1)(typescript@5.8.3))(eslint-import-resolver-node@0.3.9)(eslint-import-resolver-typescript@3.10.1)(eslint@8.57.1):\n+  eslint-module-utils@2.12.0(@typescript-eslint/parser@8.33.1(eslint@8.57.1)(typescript@5.8.3))(eslint-import-resolver-node@0.3.9)(eslint-import-resolver-typescript@3.10.1)(eslint@8.57.1):\n     dependencies:\n       debug: 3.2.7\n     optionalDependencies:\n-      '@typescript-eslint/parser': 8.34.1(eslint@8.57.1)(typescript@5.8.3)\n+      '@typescript-eslint/parser': 8.33.1(eslint@8.57.1)(typescript@5.8.3)\n       eslint: 8.57.1\n       eslint-import-resolver-node: 0.3.9\n       eslint-import-resolver-typescript: 3.10.1(eslint-plugin-import@2.31.0)(eslint@8.57.1)\n     transitivePeerDependencies:\n       - supports-color\n \n-  eslint-plugin-import@2.31.0(@typescript-eslint/parser@8.34.1(eslint@8.57.1)(typescript@5.8.3))(eslint-import-resolver-typescript@3.10.1)(eslint@8.57.1):\n+  eslint-plugin-import@2.31.0(@typescript-eslint/parser@8.33.1(eslint@8.57.1)(typescript@5.8.3))(eslint-import-resolver-typescript@3.10.1)(eslint@8.57.1):\n     dependencies:\n       '@rtsao/scc': 1.1.0\n       array-includes: 3.1.9\n@@ -12650,7 +12659,7 @@ snapshots:\n       doctrine: 2.1.0\n       eslint: 8.57.1\n       eslint-import-resolver-node: 0.3.9\n-      eslint-module-utils: 2.12.0(@typescript-eslint/parser@8.34.1(eslint@8.57.1)(typescript@5.8.3))(eslint-import-resolver-node@0.3.9)(eslint-import-resolver-typescript@3.10.1)(eslint@8.57.1)\n+      eslint-module-utils: 2.12.0(@typescript-eslint/parser@8.33.1(eslint@8.57.1)(typescript@5.8.3))(eslint-import-resolver-node@0.3.9)(eslint-import-resolver-typescript@3.10.1)(eslint@8.57.1)\n       hasown: 2.0.2\n       is-core-module: 2.16.1\n       is-glob: 4.0.3\n@@ -12662,7 +12671,7 @@ snapshots:\n       string.prototype.trimend: 1.0.9\n       tsconfig-paths: 3.15.0\n     optionalDependencies:\n-      '@typescript-eslint/parser': 8.34.1(eslint@8.57.1)(typescript@5.8.3)\n+      '@typescript-eslint/parser': 8.33.1(eslint@8.57.1)(typescript@5.8.3)\n     transitivePeerDependencies:\n       - eslint-import-resolver-typescript\n       - eslint-import-resolver-webpack\n@@ -12716,7 +12725,7 @@ snapshots:\n   eslint-plugin-storybook@0.12.0(eslint@8.57.1)(typescript@5.8.3):\n     dependencies:\n       '@storybook/csf': 0.1.13\n-      '@typescript-eslint/utils': 8.34.1(eslint@8.57.1)(typescript@5.8.3)\n+      '@typescript-eslint/utils': 8.33.1(eslint@8.57.1)(typescript@5.8.3)\n       eslint: 8.57.1\n       ts-dedent: 2.2.0\n     transitivePeerDependencies:\n@@ -12735,7 +12744,7 @@ snapshots:\n \n   eslint-visitor-keys@3.4.3: {}\n \n-  eslint-visitor-keys@4.2.1: {}\n+  eslint-visitor-keys@4.2.0: {}\n \n   eslint@8.57.1:\n     dependencies:\n@@ -12782,8 +12791,8 @@ snapshots:\n \n   espree@9.6.1:\n     dependencies:\n-      acorn: 8.15.0\n-      acorn-jsx: 5.3.2(acorn@8.15.0)\n+      acorn: 8.14.1\n+      acorn-jsx: 5.3.2(acorn@8.14.1)\n       eslint-visitor-keys: 3.4.3\n \n   esprima@4.0.1: {}\n@@ -12806,7 +12815,7 @@ snapshots:\n \n   estree-walker@3.0.3:\n     dependencies:\n-      '@types/estree': 1.0.8\n+      '@types/estree': 1.0.7\n \n   esutils@2.0.3: {}\n \n@@ -12891,7 +12900,7 @@ snapshots:\n     dependencies:\n       bser: 2.1.1\n \n-  fdir@6.4.6(picomatch@4.0.2):\n+  fdir@6.4.5(picomatch@4.0.2):\n     optionalDependencies:\n       picomatch: 4.0.2\n \n@@ -12972,7 +12981,7 @@ snapshots:\n       cross-spawn: 7.0.6\n       signal-exit: 4.1.0\n \n-  fork-ts-checker-webpack-plugin@8.0.0(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)):\n+  fork-ts-checker-webpack-plugin@8.0.0(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)):\n     dependencies:\n       '@babel/code-frame': 7.27.1\n       chalk: 4.1.2\n@@ -12987,22 +12996,21 @@ snapshots:\n       semver: 7.7.2\n       tapable: 2.2.2\n       typescript: 5.8.3\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n \n-  form-data@4.0.3:\n+  form-data@4.0.2:\n     dependencies:\n       asynckit: 0.4.0\n       combined-stream: 1.0.8\n       es-set-tostringtag: 2.1.0\n-      hasown: 2.0.2\n       mime-types: 2.1.35\n \n   forwarded-parse@2.1.2: {}\n \n   framer-motion@12.16.0(@emotion/is-prop-valid@1.2.2)(react-dom@18.3.1(react@18.3.1))(react@18.3.1):\n     dependencies:\n-      motion-dom: 12.18.1\n-      motion-utils: 12.18.1\n+      motion-dom: 12.16.0\n+      motion-utils: 12.12.1\n       tslib: 2.8.1\n     optionalDependencies:\n       '@emotion/is-prop-valid': 1.2.2\n@@ -13191,7 +13199,7 @@ snapshots:\n \n   hast-util-to-jsx-runtime@2.3.6:\n     dependencies:\n-      '@types/estree': 1.0.8\n+      '@types/estree': 1.0.7\n       '@types/hast': 3.0.4\n       '@types/unist': 3.0.3\n       comma-separated-tokens: 2.0.3\n@@ -13203,7 +13211,7 @@ snapshots:\n       mdast-util-mdxjs-esm: 2.0.1\n       property-information: 7.1.0\n       space-separated-tokens: 2.0.2\n-      style-to-js: 1.1.17\n+      style-to-js: 1.1.16\n       unist-util-position: 5.0.0\n       vfile-message: 4.0.2\n     transitivePeerDependencies:\n@@ -13243,11 +13251,11 @@ snapshots:\n       he: 1.2.0\n       param-case: 3.0.4\n       relateurl: 0.2.7\n-      terser: 5.42.0\n+      terser: 5.41.0\n \n   html-url-attributes@3.0.1: {}\n \n-  html-webpack-plugin@5.6.3(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)):\n+  html-webpack-plugin@5.6.3(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)):\n     dependencies:\n       '@types/html-minifier-terser': 6.1.0\n       html-minifier-terser: 6.1.0\n@@ -13255,7 +13263,7 @@ snapshots:\n       pretty-error: 4.0.0\n       tapable: 2.2.2\n     optionalDependencies:\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n \n   htmlparser2@3.10.1:\n     dependencies:\n@@ -13305,8 +13313,8 @@ snapshots:\n \n   import-in-the-middle@1.14.0:\n     dependencies:\n-      acorn: 8.15.0\n-      acorn-import-attributes: 1.9.5(acorn@8.15.0)\n+      acorn: 8.14.1\n+      acorn-import-attributes: 1.9.5(acorn@8.14.1)\n       cjs-module-lexer: 1.4.3\n       module-details-from-path: 1.0.4\n \n@@ -13454,7 +13462,7 @@ snapshots:\n \n   is-reference@1.2.1:\n     dependencies:\n-      '@types/estree': 1.0.8\n+      '@types/estree': 1.0.7\n \n   is-regex@1.2.1:\n     dependencies:\n@@ -13766,7 +13774,7 @@ snapshots:\n       jest-process-manager: 0.4.0\n       jest-runner: 29.7.0\n       nyc: 15.1.0\n-      playwright-core: 1.53.0\n+      playwright-core: 1.52.0\n       rimraf: 3.0.2\n       uuid: 8.3.2\n     transitivePeerDependencies:\n@@ -14107,7 +14115,7 @@ snapshots:\n     dependencies:\n       js-tokens: 4.0.0\n \n-  loupe@3.1.4: {}\n+  loupe@3.1.3: {}\n \n   lower-case@2.0.2:\n     dependencies:\n@@ -14159,7 +14167,7 @@ snapshots:\n     dependencies:\n       '@types/mdast': 4.0.4\n       '@types/unist': 3.0.3\n-      decode-named-character-reference: 1.2.0\n+      decode-named-character-reference: 1.1.0\n       devlop: 1.1.0\n       mdast-util-to-string: 4.0.0\n       micromark: 4.0.2\n@@ -14258,7 +14266,7 @@ snapshots:\n \n   micromark-core-commonmark@2.0.3:\n     dependencies:\n-      decode-named-character-reference: 1.2.0\n+      decode-named-character-reference: 1.1.0\n       devlop: 1.1.0\n       micromark-factory-destination: 2.0.1\n       micromark-factory-label: 2.0.1\n@@ -14333,7 +14341,7 @@ snapshots:\n \n   micromark-util-decode-string@2.0.1:\n     dependencies:\n-      decode-named-character-reference: 1.2.0\n+      decode-named-character-reference: 1.1.0\n       micromark-util-character: 2.1.1\n       micromark-util-decode-numeric-character-reference: 2.0.2\n       micromark-util-symbol: 2.0.1\n@@ -14371,7 +14379,7 @@ snapshots:\n     dependencies:\n       '@types/debug': 4.1.12\n       debug: 4.4.1\n-      decode-named-character-reference: 1.2.0\n+      decode-named-character-reference: 1.1.0\n       devlop: 1.1.0\n       micromark-core-commonmark: 2.0.3\n       micromark-factory-space: 2.0.1\n@@ -14415,15 +14423,15 @@ snapshots:\n \n   minimatch@3.1.2:\n     dependencies:\n-      brace-expansion: 1.1.12\n+      brace-expansion: 1.1.11\n \n   minimatch@8.0.4:\n     dependencies:\n-      brace-expansion: 2.0.2\n+      brace-expansion: 2.0.1\n \n   minimatch@9.0.5:\n     dependencies:\n-      brace-expansion: 2.0.2\n+      brace-expansion: 2.0.1\n \n   minimist@1.2.8: {}\n \n@@ -14437,11 +14445,11 @@ snapshots:\n \n   moment@2.30.1: {}\n \n-  motion-dom@12.18.1:\n+  motion-dom@12.16.0:\n     dependencies:\n-      motion-utils: 12.18.1\n+      motion-utils: 12.12.1\n \n-  motion-utils@12.18.1: {}\n+  motion-utils@12.12.1: {}\n \n   ms@2.1.3: {}\n \n@@ -14460,7 +14468,7 @@ snapshots:\n       '@open-draft/deferred-promise': 2.2.0\n       '@open-draft/until': 2.1.0\n       '@types/cookie': 0.6.0\n-      '@types/statuses': 2.0.6\n+      '@types/statuses': 2.0.5\n       graphql: 16.11.0\n       headers-polyfill: 4.0.3\n       is-node-process: 1.2.0\n@@ -14504,7 +14512,7 @@ snapshots:\n       '@swc/counter': 0.1.3\n       '@swc/helpers': 0.5.15\n       busboy: 1.6.0\n-      caniuse-lite: 1.0.30001723\n+      caniuse-lite: 1.0.30001721\n       postcss: 8.4.31\n       react: 18.3.1\n       react-dom: 18.3.1(react@18.3.1)\n@@ -14538,7 +14546,7 @@ snapshots:\n \n   node-int64@0.4.0: {}\n \n-  node-polyfill-webpack-plugin@2.0.1(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)):\n+  node-polyfill-webpack-plugin@2.0.1(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)):\n     dependencies:\n       assert: 2.1.0\n       browserify-zlib: 0.2.0\n@@ -14565,7 +14573,7 @@ snapshots:\n       url: 0.11.4\n       util: 0.12.5\n       vm-browserify: 1.1.2\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n \n   node-preload@0.2.1:\n     dependencies:\n@@ -14765,7 +14773,7 @@ snapshots:\n       '@types/unist': 2.0.11\n       character-entities-legacy: 3.0.0\n       character-reference-invalid: 2.0.1\n-      decode-named-character-reference: 1.2.0\n+      decode-named-character-reference: 1.1.0\n       is-alphanumerical: 2.0.1\n       is-decimal: 2.0.1\n       is-hexadecimal: 2.0.1\n@@ -14849,20 +14857,12 @@ snapshots:\n \n   playwright-core@1.52.0: {}\n \n-  playwright-core@1.53.0: {}\n-\n   playwright@1.52.0:\n     dependencies:\n       playwright-core: 1.52.0\n     optionalDependencies:\n       fsevents: 2.3.2\n \n-  playwright@1.53.0:\n-    dependencies:\n-      playwright-core: 1.53.0\n-    optionalDependencies:\n-      fsevents: 2.3.2\n-\n   pnp-webpack-plugin@1.7.0(typescript@5.8.3):\n     dependencies:\n       ts-pnp: 1.2.0(typescript@5.8.3)\n@@ -14894,14 +14894,14 @@ snapshots:\n     optionalDependencies:\n       postcss: 8.5.4\n \n-  postcss-loader@8.1.1(postcss@8.5.4)(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)):\n+  postcss-loader@8.1.1(postcss@8.5.4)(typescript@5.8.3)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)):\n     dependencies:\n       cosmiconfig: 9.0.0(typescript@5.8.3)\n       jiti: 1.21.7\n       postcss: 8.5.4\n       semver: 7.7.2\n     optionalDependencies:\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n     transitivePeerDependencies:\n       - typescript\n \n@@ -14996,6 +14996,12 @@ snapshots:\n       ansi-styles: 5.2.0\n       react-is: 18.3.1\n \n+  prism-react-renderer@2.4.1(react@18.3.1):\n+    dependencies:\n+      '@types/prismjs': 1.26.5\n+      clsx: 2.1.1\n+      react: 18.3.1\n+\n   process-nextick-args@2.0.1: {}\n \n   process-on-spawn@1.1.0:\n@@ -15077,7 +15083,7 @@ snapshots:\n       date-fns-jalali: 4.1.0-0\n       react: 18.3.1\n \n-  react-docgen-typescript@2.4.0(typescript@5.8.3):\n+  react-docgen-typescript@2.2.2(typescript@5.8.3):\n     dependencies:\n       typescript: 5.8.3\n \n@@ -15107,7 +15113,7 @@ snapshots:\n       prop-types: 15.8.1\n       react: 18.3.1\n       react-dom: 18.3.1(react@18.3.1)\n-      styled-components: 6.1.19(react-dom@18.3.1(react@18.3.1))(react@18.3.1)\n+      styled-components: 6.1.18(react-dom@18.3.1(react@18.3.1))(react@18.3.1)\n \n   react-hook-form@7.57.0(react@18.3.1):\n     dependencies:\n@@ -15195,6 +15201,10 @@ snapshots:\n     optionalDependencies:\n       '@types/react': 18.3.17\n \n+  react-timeago@8.2.0(react@18.3.1):\n+    dependencies:\n+      react: 18.3.1\n+\n   react-transition-group@4.4.5(react-dom@18.3.1(react@18.3.1))(react@18.3.1):\n     dependencies:\n       '@babel/runtime': 7.27.6\n@@ -15470,11 +15480,11 @@ snapshots:\n       es-errors: 1.3.0\n       is-regex: 1.2.1\n \n-  sass-loader@14.2.1(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)):\n+  sass-loader@14.2.1(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)):\n     dependencies:\n       neo-async: 2.6.2\n     optionalDependencies:\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n \n   scheduler@0.23.2:\n     dependencies:\n@@ -15699,7 +15709,7 @@ snapshots:\n     dependencies:\n       type-fest: 0.7.1\n \n-  statuses@2.0.2: {}\n+  statuses@2.0.1: {}\n \n   stop-iteration-iterator@1.1.0:\n     dependencies:\n@@ -15841,19 +15851,19 @@ snapshots:\n \n   strip-json-comments@3.1.1: {}\n \n-  style-loader@3.3.4(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)):\n+  style-loader@3.3.4(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)):\n     dependencies:\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n \n-  style-to-js@1.1.17:\n+  style-to-js@1.1.16:\n     dependencies:\n-      style-to-object: 1.0.9\n+      style-to-object: 1.0.8\n \n-  style-to-object@1.0.9:\n+  style-to-object@1.0.8:\n     dependencies:\n       inline-style-parser: 0.2.4\n \n-  styled-components@6.1.19(react-dom@18.3.1(react@18.3.1))(react@18.3.1):\n+  styled-components@6.1.18(react-dom@18.3.1(react@18.3.1))(react@18.3.1):\n     dependencies:\n       '@emotion/is-prop-valid': 1.2.2\n       '@emotion/unitless': 0.8.1\n@@ -15909,6 +15919,17 @@ snapshots:\n \n   tailwind-merge@2.6.0: {}\n \n+  tailwind-scrollbar-hide@2.0.0(tailwindcss@3.4.17):\n+    dependencies:\n+      tailwindcss: 3.4.17\n+\n+  tailwind-scrollbar@4.0.2(react@18.3.1)(tailwindcss@3.4.17):\n+    dependencies:\n+      prism-react-renderer: 2.4.1(react@18.3.1)\n+      tailwindcss: 3.4.17\n+    transitivePeerDependencies:\n+      - react\n+\n   tailwindcss-animate@1.0.7(tailwindcss@3.4.17):\n     dependencies:\n       tailwindcss: 3.4.17\n@@ -15942,22 +15963,22 @@ snapshots:\n \n   tapable@2.2.2: {}\n \n-  terser-webpack-plugin@5.3.14(@swc/core@1.12.1)(esbuild@0.25.5)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)):\n+  terser-webpack-plugin@5.3.14(@swc/core@1.11.31)(esbuild@0.24.2)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)):\n     dependencies:\n       '@jridgewell/trace-mapping': 0.3.25\n       jest-worker: 27.5.1\n       schema-utils: 4.3.2\n       serialize-javascript: 6.0.2\n-      terser: 5.42.0\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      terser: 5.41.0\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n     optionalDependencies:\n-      '@swc/core': 1.12.1\n-      esbuild: 0.25.5\n+      '@swc/core': 1.11.31\n+      esbuild: 0.24.2\n \n-  terser@5.42.0:\n+  terser@5.41.0:\n     dependencies:\n       '@jridgewell/source-map': 0.3.6\n-      acorn: 8.15.0\n+      acorn: 8.14.1\n       commander: 2.20.3\n       source-map-support: 0.5.21\n \n@@ -15987,7 +16008,7 @@ snapshots:\n \n   tinyglobby@0.2.14:\n     dependencies:\n-      fdir: 6.4.6(picomatch@4.0.2)\n+      fdir: 6.4.5(picomatch@4.0.2)\n       picomatch: 4.0.2\n \n   tinyrainbow@1.2.0: {}\n@@ -16171,39 +16192,37 @@ snapshots:\n \n   unplugin@1.0.1:\n     dependencies:\n-      acorn: 8.15.0\n+      acorn: 8.14.1\n       chokidar: 3.6.0\n       webpack-sources: 3.3.2\n       webpack-virtual-modules: 0.5.0\n \n   unplugin@1.16.1:\n     dependencies:\n-      acorn: 8.15.0\n+      acorn: 8.14.1\n       webpack-virtual-modules: 0.6.2\n \n-  unrs-resolver@1.9.0:\n+  unrs-resolver@1.7.10:\n     dependencies:\n       napi-postinstall: 0.2.4\n     optionalDependencies:\n-      '@unrs/resolver-binding-android-arm-eabi': 1.9.0\n-      '@unrs/resolver-binding-android-arm64': 1.9.0\n-      '@unrs/resolver-binding-darwin-arm64': 1.9.0\n-      '@unrs/resolver-binding-darwin-x64': 1.9.0\n-      '@unrs/resolver-binding-freebsd-x64': 1.9.0\n-      '@unrs/resolver-binding-linux-arm-gnueabihf': 1.9.0\n-      '@unrs/resolver-binding-linux-arm-musleabihf': 1.9.0\n-      '@unrs/resolver-binding-linux-arm64-gnu': 1.9.0\n-      '@unrs/resolver-binding-linux-arm64-musl': 1.9.0\n-      '@unrs/resolver-binding-linux-ppc64-gnu': 1.9.0\n-      '@unrs/resolver-binding-linux-riscv64-gnu': 1.9.0\n-      '@unrs/resolver-binding-linux-riscv64-musl': 1.9.0\n-      '@unrs/resolver-binding-linux-s390x-gnu': 1.9.0\n-      '@unrs/resolver-binding-linux-x64-gnu': 1.9.0\n-      '@unrs/resolver-binding-linux-x64-musl': 1.9.0\n-      '@unrs/resolver-binding-wasm32-wasi': 1.9.0\n-      '@unrs/resolver-binding-win32-arm64-msvc': 1.9.0\n-      '@unrs/resolver-binding-win32-ia32-msvc': 1.9.0\n-      '@unrs/resolver-binding-win32-x64-msvc': 1.9.0\n+      '@unrs/resolver-binding-darwin-arm64': 1.7.10\n+      '@unrs/resolver-binding-darwin-x64': 1.7.10\n+      '@unrs/resolver-binding-freebsd-x64': 1.7.10\n+      '@unrs/resolver-binding-linux-arm-gnueabihf': 1.7.10\n+      '@unrs/resolver-binding-linux-arm-musleabihf': 1.7.10\n+      '@unrs/resolver-binding-linux-arm64-gnu': 1.7.10\n+      '@unrs/resolver-binding-linux-arm64-musl': 1.7.10\n+      '@unrs/resolver-binding-linux-ppc64-gnu': 1.7.10\n+      '@unrs/resolver-binding-linux-riscv64-gnu': 1.7.10\n+      '@unrs/resolver-binding-linux-riscv64-musl': 1.7.10\n+      '@unrs/resolver-binding-linux-s390x-gnu': 1.7.10\n+      '@unrs/resolver-binding-linux-x64-gnu': 1.7.10\n+      '@unrs/resolver-binding-linux-x64-musl': 1.7.10\n+      '@unrs/resolver-binding-wasm32-wasi': 1.7.10\n+      '@unrs/resolver-binding-win32-arm64-msvc': 1.7.10\n+      '@unrs/resolver-binding-win32-ia32-msvc': 1.7.10\n+      '@unrs/resolver-binding-win32-x64-msvc': 1.7.10\n \n   update-browserslist-db@1.1.3(browserslist@4.25.0):\n     dependencies:\n@@ -16299,7 +16318,7 @@ snapshots:\n \n   wait-on@7.2.0:\n     dependencies:\n-      axios: 1.10.0\n+      axios: 1.9.0\n       joi: 17.13.3\n       lodash: 4.17.21\n       minimist: 1.2.8\n@@ -16330,7 +16349,7 @@ snapshots:\n \n   webidl-conversions@3.0.1: {}\n \n-  webpack-dev-middleware@6.1.3(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)):\n+  webpack-dev-middleware@6.1.3(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)):\n     dependencies:\n       colorette: 2.0.20\n       memfs: 3.5.3\n@@ -16338,7 +16357,7 @@ snapshots:\n       range-parser: 1.2.1\n       schema-utils: 4.3.2\n     optionalDependencies:\n-      webpack: 5.99.9(@swc/core@1.12.1)(esbuild@0.25.5)\n+      webpack: 5.99.9(@swc/core@1.11.31)(esbuild@0.24.2)\n \n   webpack-hot-middleware@2.26.1:\n     dependencies:\n@@ -16352,15 +16371,15 @@ snapshots:\n \n   webpack-virtual-modules@0.6.2: {}\n \n-  webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5):\n+  webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2):\n     dependencies:\n       '@types/eslint-scope': 3.7.7\n-      '@types/estree': 1.0.8\n+      '@types/estree': 1.0.7\n       '@types/json-schema': 7.0.15\n       '@webassemblyjs/ast': 1.14.1\n       '@webassemblyjs/wasm-edit': 1.14.1\n       '@webassemblyjs/wasm-parser': 1.14.1\n-      acorn: 8.15.0\n+      acorn: 8.14.1\n       browserslist: 4.25.0\n       chrome-trace-event: 1.0.4\n       enhanced-resolve: 5.18.1\n@@ -16375,7 +16394,7 @@ snapshots:\n       neo-async: 2.6.2\n       schema-utils: 4.3.2\n       tapable: 2.2.2\n-      terser-webpack-plugin: 5.3.14(@swc/core@1.12.1)(esbuild@0.25.5)(webpack@5.99.9(@swc/core@1.12.1)(esbuild@0.25.5))\n+      terser-webpack-plugin: 5.3.14(@swc/core@1.11.31)(esbuild@0.24.2)(webpack@5.99.9(@swc/core@1.11.31)(esbuild@0.24.2))\n       watchpack: 2.4.4\n       webpack-sources: 3.3.2\n     transitivePeerDependencies:\ndiff --git a/autogpt_platform/frontend/public/integrations/anthropic.png b/autogpt_platform/frontend/public/integrations/anthropic.png\nnew file mode 100644\nindex 000000000000..23cc3ddb9d83\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/anthropic.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/apollo.png b/autogpt_platform/frontend/public/integrations/apollo.png\nnew file mode 100644\nindex 000000000000..cb3750356b32\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/apollo.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/d-id.png b/autogpt_platform/frontend/public/integrations/d-id.png\nindex 17ebf2ddb478..977cd679ceac 100644\nBinary files a/autogpt_platform/frontend/public/integrations/d-id.png and b/autogpt_platform/frontend/public/integrations/d-id.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/d_id.png b/autogpt_platform/frontend/public/integrations/d_id.png\nnew file mode 100644\nindex 000000000000..5a41621838ad\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/d_id.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/discord.png b/autogpt_platform/frontend/public/integrations/discord.png\nindex 4e4ed4662d91..e440b11672b8 100644\nBinary files a/autogpt_platform/frontend/public/integrations/discord.png and b/autogpt_platform/frontend/public/integrations/discord.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/e2b.png b/autogpt_platform/frontend/public/integrations/e2b.png\nnew file mode 100644\nindex 000000000000..986e7cc60ef7\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/e2b.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/exa.png b/autogpt_platform/frontend/public/integrations/exa.png\nnew file mode 100644\nindex 000000000000..35b25b48f827\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/exa.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/fal.png b/autogpt_platform/frontend/public/integrations/fal.png\nnew file mode 100644\nindex 000000000000..95ae1079e574\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/fal.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/github.png b/autogpt_platform/frontend/public/integrations/github.png\nindex 5e0778732890..1b4e59693628 100644\nBinary files a/autogpt_platform/frontend/public/integrations/github.png and b/autogpt_platform/frontend/public/integrations/github.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/google.png b/autogpt_platform/frontend/public/integrations/google.png\nindex 49cc06b98077..5b8b6e658ce3 100644\nBinary files a/autogpt_platform/frontend/public/integrations/google.png and b/autogpt_platform/frontend/public/integrations/google.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/google_maps.png b/autogpt_platform/frontend/public/integrations/google_maps.png\nnew file mode 100644\nindex 000000000000..928c5a558527\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/google_maps.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/groq.png b/autogpt_platform/frontend/public/integrations/groq.png\nnew file mode 100644\nindex 000000000000..4953c67a3547\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/groq.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/hubspot.png b/autogpt_platform/frontend/public/integrations/hubspot.png\nindex de4fb1dbe998..5f25ce0a3ddd 100644\nBinary files a/autogpt_platform/frontend/public/integrations/hubspot.png and b/autogpt_platform/frontend/public/integrations/hubspot.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/ideogram.png b/autogpt_platform/frontend/public/integrations/ideogram.png\nnew file mode 100644\nindex 000000000000..049cee4b28c7\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/ideogram.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/jina.png b/autogpt_platform/frontend/public/integrations/jina.png\nnew file mode 100644\nindex 000000000000..aec95773298e\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/jina.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/linear.png b/autogpt_platform/frontend/public/integrations/linear.png\nindex 5e3a0ccfe1c5..fe64191e6d98 100644\nBinary files a/autogpt_platform/frontend/public/integrations/linear.png and b/autogpt_platform/frontend/public/integrations/linear.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/llama_api.png b/autogpt_platform/frontend/public/integrations/llama_api.png\nnew file mode 100644\nindex 000000000000..5d48d62c1919\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/llama_api.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/maps.png b/autogpt_platform/frontend/public/integrations/maps.png\nindex 70a707dcd986..8bc9fddcb747 100644\nBinary files a/autogpt_platform/frontend/public/integrations/maps.png and b/autogpt_platform/frontend/public/integrations/maps.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/medium.png b/autogpt_platform/frontend/public/integrations/medium.png\nindex 41228fcdce3f..c0eec340d51c 100644\nBinary files a/autogpt_platform/frontend/public/integrations/medium.png and b/autogpt_platform/frontend/public/integrations/medium.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/mem0.png b/autogpt_platform/frontend/public/integrations/mem0.png\nindex 953ae47f3def..21ba2452c501 100644\nBinary files a/autogpt_platform/frontend/public/integrations/mem0.png and b/autogpt_platform/frontend/public/integrations/mem0.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/notion.png b/autogpt_platform/frontend/public/integrations/notion.png\nindex 9b95380a9380..a1e535fe0cb9 100644\nBinary files a/autogpt_platform/frontend/public/integrations/notion.png and b/autogpt_platform/frontend/public/integrations/notion.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/nvidia.jpg b/autogpt_platform/frontend/public/integrations/nvidia.jpg\nindex 46956b6de3fa..77513386f4c7 100644\nBinary files a/autogpt_platform/frontend/public/integrations/nvidia.jpg and b/autogpt_platform/frontend/public/integrations/nvidia.jpg differ\ndiff --git a/autogpt_platform/frontend/public/integrations/nvidia.png b/autogpt_platform/frontend/public/integrations/nvidia.png\nnew file mode 100644\nindex 000000000000..c5bf936fd304\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/nvidia.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/ollama.png b/autogpt_platform/frontend/public/integrations/ollama.png\nnew file mode 100644\nindex 000000000000..7c5f003b495b\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/ollama.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/open_router.png b/autogpt_platform/frontend/public/integrations/open_router.png\nnew file mode 100644\nindex 000000000000..62fe66752836\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/open_router.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/openai.png b/autogpt_platform/frontend/public/integrations/openai.png\nnew file mode 100644\nindex 000000000000..6f16d37ea07d\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/openai.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/openweathermap.png b/autogpt_platform/frontend/public/integrations/openweathermap.png\nindex ae4e47b8bfa9..80ae46e053e8 100644\nBinary files a/autogpt_platform/frontend/public/integrations/openweathermap.png and b/autogpt_platform/frontend/public/integrations/openweathermap.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/pinecone.png b/autogpt_platform/frontend/public/integrations/pinecone.png\nindex ec25827f7aa7..1378c6522270 100644\nBinary files a/autogpt_platform/frontend/public/integrations/pinecone.png and b/autogpt_platform/frontend/public/integrations/pinecone.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/reddit.png b/autogpt_platform/frontend/public/integrations/reddit.png\nindex 6f5777a78963..976a157866e0 100644\nBinary files a/autogpt_platform/frontend/public/integrations/reddit.png and b/autogpt_platform/frontend/public/integrations/reddit.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/replicate.png b/autogpt_platform/frontend/public/integrations/replicate.png\nnew file mode 100644\nindex 000000000000..8e70d93c8a4f\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/replicate.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/revid.png b/autogpt_platform/frontend/public/integrations/revid.png\nnew file mode 100644\nindex 000000000000..a49151b22fa1\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/revid.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/screenshotone.png b/autogpt_platform/frontend/public/integrations/screenshotone.png\nnew file mode 100644\nindex 000000000000..c3c1f9930727\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/screenshotone.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/slant3d.jpeg b/autogpt_platform/frontend/public/integrations/slant3d.jpeg\nindex 8071a6a0b90f..43b3ef88d0a8 100644\nBinary files a/autogpt_platform/frontend/public/integrations/slant3d.jpeg and b/autogpt_platform/frontend/public/integrations/slant3d.jpeg differ\ndiff --git a/autogpt_platform/frontend/public/integrations/slant3d.png b/autogpt_platform/frontend/public/integrations/slant3d.png\nnew file mode 100644\nindex 000000000000..958a30d4f4be\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/slant3d.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/smartlead.png b/autogpt_platform/frontend/public/integrations/smartlead.png\nnew file mode 100644\nindex 000000000000..30ea5d5b6f78\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/smartlead.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/smtp.png b/autogpt_platform/frontend/public/integrations/smtp.png\nindex 1e7c5dd4f045..eea99b046ef4 100644\nBinary files a/autogpt_platform/frontend/public/integrations/smtp.png and b/autogpt_platform/frontend/public/integrations/smtp.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/todoist.png b/autogpt_platform/frontend/public/integrations/todoist.png\nindex 70cc564a11b3..40aa9480d12e 100644\nBinary files a/autogpt_platform/frontend/public/integrations/todoist.png and b/autogpt_platform/frontend/public/integrations/todoist.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/twitter.png b/autogpt_platform/frontend/public/integrations/twitter.png\nnew file mode 100644\nindex 000000000000..8262c4b9cc06\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/twitter.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/unreal-speech.png b/autogpt_platform/frontend/public/integrations/unreal-speech.png\ndeleted file mode 100644\nindex 1baaf64f922f..000000000000\nBinary files a/autogpt_platform/frontend/public/integrations/unreal-speech.png and /dev/null differ\ndiff --git a/autogpt_platform/frontend/public/integrations/unreal_speech.png b/autogpt_platform/frontend/public/integrations/unreal_speech.png\nnew file mode 100644\nindex 000000000000..1446eac432ab\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/unreal_speech.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/x.png b/autogpt_platform/frontend/public/integrations/x.png\nindex 25bbe2c0585d..8262c4b9cc06 100644\nBinary files a/autogpt_platform/frontend/public/integrations/x.png and b/autogpt_platform/frontend/public/integrations/x.png differ\ndiff --git a/autogpt_platform/frontend/public/integrations/zerobounce.png b/autogpt_platform/frontend/public/integrations/zerobounce.png\nnew file mode 100644\nindex 000000000000..78168a853a27\nBinary files /dev/null and b/autogpt_platform/frontend/public/integrations/zerobounce.png differ\ndiff --git a/autogpt_platform/frontend/src/components/Flow.tsx b/autogpt_platform/frontend/src/components/Flow.tsx\nindex 345fc60b5ae8..af5469061c01 100644\n--- a/autogpt_platform/frontend/src/components/Flow.tsx\n+++ b/autogpt_platform/frontend/src/components/Flow.tsx\n@@ -28,6 +28,7 @@ import \"@xyflow/react/dist/style.css\";\n import { CustomNode } from \"./CustomNode\";\n import \"./flow.css\";\n import {\n+  Block,\n   BlockUIType,\n   formatEdgeID,\n   GraphExecutionID,\n@@ -39,7 +40,6 @@ import { CustomEdge } from \"./CustomEdge\";\n import ConnectionLine from \"./ConnectionLine\";\n import { Control, ControlPanel } from \"@/components/edit/control/ControlPanel\";\n import { SaveControl } from \"@/components/edit/control/SaveControl\";\n-import { BlocksControl } from \"@/components/edit/control/BlocksControl\";\n import { IconUndo2, IconRedo2 } from \"@/components/ui/icons\";\n import { startTutorial } from \"./tutorial\";\n import useAgentGraph from \"@/hooks/useAgentGraph\";\n@@ -53,6 +53,7 @@ import OttoChatWidget from \"@/components/OttoChatWidget\";\n import { useToast } from \"@/components/ui/use-toast\";\n import { useCopyPaste } from \"../hooks/useCopyPaste\";\n import { CronScheduler } from \"./cronScheduler\";\n+import { BlockMenu } from \"./builder/block-menu/BlockMenu\";\n \n // This is for the history, this is the minimum distance a block must move before it is logged\n // It helps to prevent spamming the history with small movements especially when pressing on a input in a block\n@@ -101,7 +102,6 @@ const FlowEditor: React.FC<{\n     setAgentDescription,\n     savedAgent,\n     availableNodes,\n-    availableFlows,\n     getOutputType,\n     requestSave,\n     requestSaveAndRun,\n@@ -136,6 +136,10 @@ const FlowEditor: React.FC<{\n   // State to control if save popover should be pinned open\n   const [pinSavePopover, setPinSavePopover] = useState(false);\n \n+  const [blockMenuSelected, setBlockMenuSelected] = useState<\n+    \"save\" | \"block\" | \"\"\n+  >(\"\");\n+\n   const runnerUIRef = useRef<RunnerUIWrapperRef>(null);\n \n   const [openCron, setOpenCron] = useState(false);\n@@ -466,13 +470,7 @@ const FlowEditor: React.FC<{\n   }, [nodes, setViewport, x, y]);\n \n   const addNode = useCallback(\n-    (blockId: string, nodeType: string, hardcodedValues: any = {}) => {\n-      const nodeSchema = availableNodes.find((node) => node.id === blockId);\n-      if (!nodeSchema) {\n-        console.error(`Schema not found for block ID: ${blockId}`);\n-        return;\n-      }\n-\n+    (block: Block) => {\n       /*\n        Calculate a position to the right of the newly added block, allowing for some margin.\n        If adding to the right side causes the new block to collide with an existing block, attempt to place it at the bottom or left.\n@@ -489,7 +487,7 @@ const FlowEditor: React.FC<{\n           ? // we will get all the dimension of nodes, then store\n             findNewlyAddedBlockCoordinates(\n               nodeDimensions,\n-              nodeSchema.uiType == BlockUIType.NOTE ? 300 : 500,\n+              block.uiType == BlockUIType.NOTE ? 300 : 500,\n               60,\n               1.0,\n             )\n@@ -504,19 +502,19 @@ const FlowEditor: React.FC<{\n         type: \"custom\",\n         position: viewportCoordinates, // Set the position to the calculated viewport center\n         data: {\n-          blockType: nodeType,\n-          blockCosts: nodeSchema.costs,\n-          title: `${nodeType} ${nodeId}`,\n-          description: nodeSchema.description,\n-          categories: nodeSchema.categories,\n-          inputSchema: nodeSchema.inputSchema,\n-          outputSchema: nodeSchema.outputSchema,\n-          hardcodedValues: hardcodedValues,\n+          blockType: block.name,\n+          blockCosts: block.costs,\n+          title: `${block.name} ${nodeId}`,\n+          description: block.description,\n+          categories: block.categories,\n+          inputSchema: block.inputSchema,\n+          outputSchema: block.outputSchema,\n+          hardcodedValues: block.hardcodedValues || {},\n           connections: [],\n           isOutputOpen: false,\n-          block_id: blockId,\n-          isOutputStatic: nodeSchema.staticOutput,\n-          uiType: nodeSchema.uiType,\n+          block_id: block.id,\n+          isOutputStatic: block.staticOutput,\n+          uiType: block.uiType,\n         },\n       };\n \n@@ -545,7 +543,6 @@ const FlowEditor: React.FC<{\n     [\n       nodeId,\n       setViewport,\n-      availableNodes,\n       addNodes,\n       nodeDimensions,\n       deleteElements,\n@@ -627,12 +624,12 @@ const FlowEditor: React.FC<{\n   const editorControls: Control[] = [\n     {\n       label: \"Undo\",\n-      icon: <IconUndo2 />,\n+      icon: <IconUndo2 className=\"h-5 w-5\" strokeWidth={2} />,\n       onClick: handleUndo,\n     },\n     {\n       label: \"Redo\",\n-      icon: <IconRedo2 />,\n+      icon: <IconRedo2 className=\"h-5 w-5\" strokeWidth={2} />,\n       onClick: handleRedo,\n     },\n   ];\n@@ -680,15 +677,13 @@ const FlowEditor: React.FC<{\n           <Controls />\n           <Background className=\"dark:bg-slate-800\" />\n           <ControlPanel\n-            className=\"absolute z-20\"\n             controls={editorControls}\n             topChildren={\n-              <BlocksControl\n-                pinBlocksPopover={pinBlocksPopover} // Pass the state to BlocksControl\n-                blocks={availableNodes}\n-                addBlock={addNode}\n-                flows={availableFlows}\n-                nodes={nodes}\n+              <BlockMenu\n+                pinBlocksPopover={pinBlocksPopover}\n+                addNode={addNode}\n+                blockMenuSelected={blockMenuSelected}\n+                setBlockMenuSelected={setBlockMenuSelected}\n               />\n             }\n             botChildren={\n@@ -701,6 +696,8 @@ const FlowEditor: React.FC<{\n                 agentName={agentName}\n                 onNameChange={setAgentName}\n                 pinSavePopover={pinSavePopover}\n+                blockMenuSelected={blockMenuSelected}\n+                setBlockMenuSelected={setBlockMenuSelected}\n               />\n             }\n           ></ControlPanel>\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/Block.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/Block.tsx\nnew file mode 100644\nindex 000000000000..4b4c04f858a5\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/Block.tsx\n@@ -0,0 +1,77 @@\n+import { Button } from \"@/components/ui/button\";\n+import { Skeleton } from \"@/components/ui/skeleton\";\n+import { beautifyString, cn } from \"@/lib/utils\";\n+import { Plus } from \"lucide-react\";\n+import React, { ButtonHTMLAttributes } from \"react\";\n+import { highlightText } from \"./IntegrationBlock\";\n+\n+interface Props extends ButtonHTMLAttributes<HTMLButtonElement> {\n+  title?: string;\n+  description?: string;\n+  highlightedText?: string;\n+}\n+\n+interface BlockComponent extends React.FC<Props> {\n+  Skeleton: React.FC<{ className?: string }>;\n+}\n+\n+export const Block: BlockComponent = ({\n+  title,\n+  description,\n+  highlightedText,\n+  className,\n+  ...rest\n+}) => {\n+  return (\n+    <Button\n+      className={cn(\n+        \"group flex h-16 w-full min-w-[7.5rem] items-center justify-start space-x-3 whitespace-normal rounded-[0.75rem] bg-zinc-50 px-[0.875rem] py-[0.625rem] text-start shadow-none\",\n+        \"hover:cursor-default hover:bg-zinc-100 focus:ring-0 active:bg-zinc-100 active:ring-1 active:ring-zinc-300 disabled:cursor-not-allowed\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      <div className=\"flex flex-1 flex-col items-start gap-0.5\">\n+        {title && (\n+          <span\n+            className={cn(\n+              \"line-clamp-1 font-sans text-sm font-medium leading-[1.375rem] text-zinc-800 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            {highlightText(beautifyString(title), highlightedText)}\n+          </span>\n+        )}\n+        {description && (\n+          <span\n+            className={cn(\n+              \"line-clamp-1 font-sans text-xs font-normal leading-5 text-zinc-500 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            {highlightText(description, highlightedText)}\n+          </span>\n+        )}\n+      </div>\n+      <div\n+        className={cn(\n+          \"flex h-7 w-7 items-center justify-center rounded-[0.5rem] bg-zinc-700 group-disabled:bg-zinc-400\",\n+        )}\n+      >\n+        <Plus className=\"h-5 w-5 text-zinc-50\" strokeWidth={2} />\n+      </div>\n+    </Button>\n+  );\n+};\n+\n+const BlockSkeleton = () => {\n+  return (\n+    <Skeleton className=\"flex h-16 w-full min-w-[7.5rem] animate-pulse items-center justify-start space-x-3 rounded-[0.75rem] bg-zinc-100 px-[0.875rem] py-[0.625rem]\">\n+      <div className=\"flex flex-1 flex-col items-start gap-0.5\">\n+        <Skeleton className=\"h-[1.375rem] w-24 rounded bg-zinc-200\" />\n+        <Skeleton className=\"h-5 w-32 rounded bg-zinc-200\" />\n+      </div>\n+      <Skeleton className=\"h-7 w-7 rounded-[0.5rem] bg-zinc-200\" />\n+    </Skeleton>\n+  );\n+};\n+\n+Block.Skeleton = BlockSkeleton;\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/BlockMenu.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/BlockMenu.tsx\nnew file mode 100644\nindex 000000000000..d3f16b8fe4c4\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/BlockMenu.tsx\n@@ -0,0 +1,62 @@\n+import React, { useState } from \"react\";\n+import {\n+  Popover,\n+  PopoverContent,\n+  PopoverTrigger,\n+} from \"@/components/ui/popover\";\n+import { ControlPanelButton } from \"@/components/builder/block-menu/ControlPanelButton\";\n+import { ToyBrick } from \"lucide-react\";\n+import { BlockMenuContent } from \"./BlockMenuContent\";\n+import { BlockMenuStateProvider } from \"./block-menu-provider\";\n+import { Block } from \"@/lib/autogpt-server-api\";\n+\n+interface BlockMenuProps {\n+  addNode: (block: Block) => void;\n+  pinBlocksPopover: boolean;\n+  blockMenuSelected: \"save\" | \"block\" | \"\";\n+  setBlockMenuSelected: React.Dispatch<\n+    React.SetStateAction<\"\" | \"save\" | \"block\">\n+  >;\n+}\n+\n+export const BlockMenu: React.FC<BlockMenuProps> = ({\n+  addNode,\n+  pinBlocksPopover,\n+  blockMenuSelected,\n+  setBlockMenuSelected,\n+}) => {\n+  const [open, setOpen] = useState(false);\n+  const onOpen = (newOpen: boolean) => {\n+    if (!pinBlocksPopover) {\n+      setOpen(newOpen);\n+      setBlockMenuSelected(newOpen ? \"block\" : \"\");\n+    }\n+  };\n+\n+  return (\n+    <Popover open={pinBlocksPopover ? true : open} onOpenChange={onOpen}>\n+      <PopoverTrigger className=\"hover:cursor-pointer\">\n+        <ControlPanelButton\n+          data-id=\"blocks-control-popover-trigger\"\n+          data-testid=\"blocks-control-blocks-button\"\n+          selected={blockMenuSelected === \"block\"}\n+          className=\"rounded-none\"\n+        >\n+          <ToyBrick className=\"h-5 w-6\" strokeWidth={2} />\n+        </ControlPanelButton>\n+      </PopoverTrigger>\n+\n+      <PopoverContent\n+        side=\"right\"\n+        align=\"start\"\n+        sideOffset={16}\n+        className=\"absolute h-[75vh] w-[46.625rem] overflow-hidden rounded-[1rem] border-none p-0 shadow-[0_2px_6px_0_rgba(0,0,0,0.05)]\"\n+        data-id=\"blocks-control-popover-content\"\n+      >\n+        <BlockMenuStateProvider addNode={addNode}>\n+          <BlockMenuContent />\n+        </BlockMenuStateProvider>\n+      </PopoverContent>\n+    </Popover>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/BlockMenuContent.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/BlockMenuContent.tsx\nnew file mode 100644\nindex 000000000000..dc7aeb562e3d\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/BlockMenuContent.tsx\n@@ -0,0 +1,18 @@\n+\"use client\";\n+import React from \"react\";\n+import { BlockMenuSearchBar } from \"./BlockMenuSearchBar\";\n+import { BlockMenuSearch } from \"./search-and-filter//BlockMenuSearch\";\n+import { BlockMenuDefault } from \"./default/BlockMenuDefault\";\n+import { Separator } from \"@/components/ui/separator\";\n+import { useBlockMenuContext } from \"./block-menu-provider\";\n+\n+export const BlockMenuContent = () => {\n+  const { searchQuery } = useBlockMenuContext();\n+  return (\n+    <div className=\"flex h-full w-full flex-col\">\n+      <BlockMenuSearchBar />\n+      <Separator className=\"h-[1px] w-full text-zinc-300\" />\n+      {searchQuery ? <BlockMenuSearch /> : <BlockMenuDefault />}\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/BlockMenuSearchBar.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/BlockMenuSearchBar.tsx\nnew file mode 100644\nindex 000000000000..3e4e05119b5b\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/BlockMenuSearchBar.tsx\n@@ -0,0 +1,90 @@\n+import { cn } from \"@/lib/utils\";\n+import { Search, X } from \"lucide-react\";\n+import React, { useRef, useState, useEffect, useMemo } from \"react\";\n+import { useBlockMenuContext } from \"./block-menu-provider\";\n+import { Button } from \"@/components/ui/button\";\n+import debounce from \"lodash/debounce\";\n+import { Input } from \"@/components/ui/input\";\n+import { getDefaultFilters } from \"./helpers\";\n+\n+const SEARCH_DEBOUNCE_MS = 500;\n+\n+interface BlockMenuSearchBarProps {\n+  className?: string;\n+}\n+\n+export const BlockMenuSearchBar: React.FC<BlockMenuSearchBarProps> = ({\n+  className = \"\",\n+}) => {\n+  const inputRef = useRef<HTMLInputElement>(null);\n+  const [localQuery, setLocalQuery] = useState(\"\");\n+  const { setSearchQuery, searchId, setSearchId, setFilters } =\n+    useBlockMenuContext();\n+\n+  const searchIdRef = useRef(searchId);\n+  useEffect(() => {\n+    searchIdRef.current = searchId;\n+  }, [searchId]);\n+\n+  const debouncedSetSearchQuery = useMemo(\n+    () =>\n+      debounce((value: string) => {\n+        setSearchQuery(value);\n+        if (value.length === 0) {\n+          setSearchId(undefined);\n+        } else if (!searchIdRef.current) {\n+          setSearchId(crypto.randomUUID());\n+        }\n+      }, SEARCH_DEBOUNCE_MS),\n+    [setSearchQuery, setSearchId],\n+  );\n+\n+  useEffect(() => {\n+    return () => {\n+      debouncedSetSearchQuery.cancel();\n+    };\n+  }, [debouncedSetSearchQuery]);\n+\n+  const handleClear = () => {\n+    setLocalQuery(\"\");\n+    setSearchQuery(\"\");\n+    setSearchId(undefined);\n+    setFilters(getDefaultFilters());\n+    debouncedSetSearchQuery.cancel();\n+  };\n+\n+  return (\n+    <div\n+      className={cn(\n+        \"flex min-h-[3.5625rem] items-center gap-2.5 px-4\",\n+        className,\n+      )}\n+    >\n+      <Search className=\"h-6 w-6 text-zinc-700\" strokeWidth={2} />\n+      <Input\n+        ref={inputRef}\n+        type=\"text\"\n+        value={localQuery}\n+        onChange={(e) => {\n+          setLocalQuery(e.target.value);\n+          debouncedSetSearchQuery(e.target.value);\n+        }}\n+        placeholder={\"Blocks, Agents, Integrations or Keywords...\"}\n+        className={cn(\n+          \"m-0 border-none p-0 font-sans text-base font-normal text-zinc-800 shadow-none outline-none\",\n+          \"placeholder:text-zinc-400 focus:shadow-none focus:outline-none focus:ring-0\",\n+        )}\n+      />\n+      {localQuery.length > 0 && (\n+        <Button\n+          variant=\"ghost\"\n+          size=\"sm\"\n+          onClick={handleClear}\n+          className=\"p-0 hover:bg-transparent\"\n+        >\n+          <X className=\"h-6 w-6 text-zinc-700\" strokeWidth={2} />\n+        </Button>\n+      )}\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/ControlPanelButton.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/ControlPanelButton.tsx\nnew file mode 100644\nindex 000000000000..8bf8f2bb5aaa\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/ControlPanelButton.tsx\n@@ -0,0 +1,34 @@\n+// BLOCK MENU TODO: We need a disable state in this, currently it's not in design.\n+\n+import { cn } from \"@/lib/utils\";\n+import React from \"react\";\n+\n+interface Props extends React.HTMLAttributes<HTMLDivElement> {\n+  selected?: boolean;\n+  children?: React.ReactNode; // For icon purpose\n+  disabled?: boolean;\n+}\n+\n+export const ControlPanelButton: React.FC<Props> = ({\n+  selected = false,\n+  children,\n+  disabled,\n+  className,\n+  ...rest\n+}) => {\n+  return (\n+    // Using div instead of button, because it's only for design purposes. We are using this to give design to PopoverTrigger.\n+    <div\n+      className={cn(\n+        \"flex h-[4.25rem] w-[4.25rem] items-center justify-center whitespace-normal bg-white p-[1.38rem] text-zinc-800 shadow-none hover:cursor-pointer hover:bg-zinc-100 hover:text-zinc-950 focus:ring-0\",\n+        selected &&\n+          \"bg-violet-50 text-violet-700 hover:cursor-default hover:bg-violet-50 hover:text-violet-700 active:bg-violet-50 active:text-violet-700\",\n+        disabled && \"cursor-not-allowed\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      {children}\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/ErrorState.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/ErrorState.tsx\nnew file mode 100644\nindex 000000000000..ae59e923dea1\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/ErrorState.tsx\n@@ -0,0 +1,54 @@\n+import { Button } from \"@/components/ui/button\";\n+import { cn, parseErrorMessage } from \"@/lib/utils\";\n+import { AlertCircle, RefreshCw } from \"lucide-react\";\n+import React from \"react\";\n+\n+interface ErrorStateProps {\n+  title?: string;\n+  message?: string;\n+  error?: string | Error | null;\n+  onRetry?: () => void;\n+  retryLabel?: string;\n+  className?: string;\n+  showIcon?: boolean;\n+}\n+\n+export const ErrorState: React.FC<ErrorStateProps> = ({\n+  title = \"Something went wrong\",\n+  message,\n+  error,\n+  onRetry,\n+  retryLabel = \"Retry\",\n+  className,\n+  showIcon = true,\n+}) => {\n+  return (\n+    <div\n+      className={cn(\n+        \"flex h-full w-full flex-col items-center justify-center space-y-4 text-center\",\n+        className,\n+      )}\n+    >\n+      {showIcon && <AlertCircle className=\"h-12 w-12\" strokeWidth={1.5} />}\n+\n+      <div className=\"space-y-2\">\n+        <p className=\"text-sm font-medium text-zinc-800\">{title}</p>\n+        <p className=\"text-sm text-zinc-600\">\n+          {parseErrorMessage(error, message)}\n+        </p>\n+      </div>\n+\n+      {onRetry && (\n+        <Button\n+          variant=\"default\"\n+          size=\"sm\"\n+          onClick={onRetry}\n+          className=\"mt-2 h-7 bg-zinc-800 text-xs\"\n+        >\n+          <RefreshCw className=\"mr-1 h-3 w-3\" />\n+          {retryLabel}\n+        </Button>\n+      )}\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/FilterChip.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/FilterChip.tsx\nnew file mode 100644\nindex 000000000000..214e5e8b25d2\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/FilterChip.tsx\n@@ -0,0 +1,54 @@\n+import { Button } from \"@/components/ui/button\";\n+import { cn } from \"@/lib/utils\";\n+import { X } from \"lucide-react\";\n+import React, { ButtonHTMLAttributes } from \"react\";\n+\n+interface Props extends ButtonHTMLAttributes<HTMLButtonElement> {\n+  selected?: boolean;\n+  number?: number;\n+  name?: string;\n+}\n+\n+export const FilterChip: React.FC<Props> = ({\n+  selected = false,\n+  number,\n+  name,\n+  className,\n+  ...rest\n+}) => {\n+  return (\n+    <Button\n+      className={cn(\n+        \"group w-fit space-x-1 rounded-[1.5rem] border border-zinc-300 bg-transparent px-[0.625rem] py-[0.375rem] shadow-none transition-transform duration-300 ease-in-out\",\n+        \"hover:border-violet-500 hover:bg-transparent focus:ring-0 disabled:cursor-not-allowed\",\n+        selected && \"border-0 bg-violet-700 hover:border\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      <span\n+        className={cn(\n+          \"font-sans text-sm font-medium leading-[1.375rem] text-zinc-600 group-hover:text-zinc-600 group-disabled:text-zinc-400\",\n+          selected && \"text-zinc-50\",\n+        )}\n+      >\n+        {name}\n+      </span>\n+      {selected && (\n+        <>\n+          <span className=\"flex h-4 w-4 items-center justify-center rounded-full bg-zinc-50 transition-all duration-300 ease-in-out group-hover:hidden\">\n+            <X\n+              className=\"h-3 w-3 rounded-full text-violet-700\"\n+              strokeWidth={2}\n+            />\n+          </span>\n+          {number !== undefined && (\n+            <span className=\"hidden h-[1.375rem] items-center rounded-[1.25rem] bg-violet-700 p-[0.375rem] text-zinc-50 transition-all duration-300 ease-in-out animate-in fade-in zoom-in group-hover:flex\">\n+              {number > 100 ? \"100+\" : number}\n+            </span>\n+          )}\n+        </>\n+      )}\n+    </Button>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/Integration.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/Integration.tsx\nnew file mode 100644\nindex 000000000000..6082df97c847\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/Integration.tsx\n@@ -0,0 +1,88 @@\n+import { Button } from \"@/components/ui/button\";\n+import { Skeleton } from \"@/components/ui/skeleton\";\n+import { beautifyString, cn } from \"@/lib/utils\";\n+import Image from \"next/image\";\n+import React, { ButtonHTMLAttributes } from \"react\";\n+\n+interface Props extends ButtonHTMLAttributes<HTMLButtonElement> {\n+  title?: string;\n+  description?: string;\n+  icon_url?: string;\n+  number_of_blocks?: number;\n+}\n+\n+interface IntegrationComponent extends React.FC<Props> {\n+  Skeleton: React.FC<{ className?: string }>;\n+}\n+\n+export const Integration: IntegrationComponent = ({\n+  title,\n+  icon_url,\n+  description,\n+  className,\n+  number_of_blocks,\n+  ...rest\n+}) => {\n+  return (\n+    <Button\n+      className={cn(\n+        \"group flex h-16 w-full min-w-[7.5rem] items-center justify-start space-x-3 whitespace-normal rounded-[0.75rem] bg-zinc-50 px-[0.875rem] py-[0.625rem] text-start shadow-none\",\n+        \"hover:cursor-default hover:bg-zinc-100 focus:ring-0 active:bg-zinc-50 active:ring-1 active:ring-zinc-300 disabled:pointer-events-none\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      <div className=\"relative h-[2.625rem] w-[2.625rem] overflow-hidden rounded-[0.5rem] bg-white\">\n+        {icon_url && (\n+          <Image\n+            src={icon_url}\n+            alt=\"integration-icon\"\n+            fill\n+            sizes=\"2.25rem\"\n+            className=\"w-full rounded-[0.5rem] object-contain group-disabled:opacity-50\"\n+          />\n+        )}\n+      </div>\n+\n+      <div className=\"w-full\">\n+        <div className=\"flex items-center justify-between gap-2\">\n+          {title && (\n+            <p className=\"line-clamp-1 flex-1 font-sans text-sm font-medium leading-[1.375rem] text-zinc-700 group-disabled:text-zinc-400\">\n+              {beautifyString(title)}\n+            </p>\n+          )}\n+          <span className=\"flex h-[1.375rem] w-[1.6875rem] items-center justify-center rounded-[1.25rem] bg-[#f0f0f0] p-1.5 font-sans text-sm leading-[1.375rem] text-zinc-500 group-disabled:text-zinc-400\">\n+            {number_of_blocks}\n+          </span>\n+        </div>\n+        <span className=\"line-clamp-1 font-sans text-xs font-normal leading-5 text-zinc-500 group-disabled:text-zinc-400\">\n+          {description}\n+        </span>\n+      </div>\n+    </Button>\n+  );\n+};\n+\n+const IntegrationSkeleton: React.FC<{ className?: string }> = ({\n+  className,\n+}) => {\n+  return (\n+    <Skeleton\n+      className={cn(\n+        \"flex h-16 w-full min-w-[7.5rem] animate-pulse items-center justify-start space-x-3 rounded-[0.75rem] bg-zinc-100 px-[0.875rem] py-[0.625rem]\",\n+        className,\n+      )}\n+    >\n+      <Skeleton className=\"h-[2.625rem] w-[2.625rem] rounded-[0.5rem] bg-zinc-200\" />\n+      <div className=\"flex flex-1 flex-col items-start gap-0.5\">\n+        <div className=\"flex w-full items-center justify-between\">\n+          <Skeleton className=\"h-[1.375rem] w-24 rounded bg-zinc-200\" />\n+          <Skeleton className=\"h-[1.375rem] w-[1.6875rem] rounded-[1.25rem] bg-zinc-200\" />\n+        </div>\n+        <Skeleton className=\"h-5 w-[80%] rounded bg-zinc-200\" />\n+      </div>\n+    </Skeleton>\n+  );\n+};\n+\n+Integration.Skeleton = IntegrationSkeleton;\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/IntegrationBlock.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/IntegrationBlock.tsx\nnew file mode 100644\nindex 000000000000..b621e805ce9a\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/IntegrationBlock.tsx\n@@ -0,0 +1,119 @@\n+import { Button } from \"@/components/ui/button\";\n+import { Skeleton } from \"@/components/ui/skeleton\";\n+import { beautifyString, cn } from \"@/lib/utils\";\n+import { Plus } from \"lucide-react\";\n+import Image from \"next/image\";\n+import React, { ButtonHTMLAttributes } from \"react\";\n+\n+interface Props extends ButtonHTMLAttributes<HTMLButtonElement> {\n+  title?: string;\n+  description?: string;\n+  icon_url?: string;\n+  highlightedText?: string;\n+}\n+\n+interface IntegrationBlockComponent extends React.FC<Props> {\n+  Skeleton: React.FC<{ className?: string }>;\n+}\n+\n+export const highlightText = (\n+  text: string | undefined,\n+  highlight: string | undefined,\n+) => {\n+  if (!text || !highlight) return text;\n+\n+  function escapeRegExp(s: string) {\n+    return s.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\");\n+  }\n+\n+  const escaped = escapeRegExp(highlight);\n+  const parts = text.split(new RegExp(`(${escaped})`, \"gi\"));\n+  return parts.map((part, i) =>\n+    part.toLowerCase() === highlight?.toLowerCase() ? (\n+      <mark key={i} className=\"bg-transparent font-bold\">\n+        {part}\n+      </mark>\n+    ) : (\n+      part\n+    ),\n+  );\n+};\n+\n+export const IntegrationBlock: IntegrationBlockComponent = ({\n+  title,\n+  icon_url,\n+  description,\n+  className,\n+  highlightedText,\n+  ...rest\n+}) => {\n+  return (\n+    <Button\n+      className={cn(\n+        \"group flex h-16 w-full min-w-[7.5rem] items-center justify-start gap-3 whitespace-normal rounded-[0.75rem] bg-zinc-50 px-[0.875rem] py-[0.625rem] text-start shadow-none\",\n+        \"hover:cursor-default hover:bg-zinc-100 focus:ring-0 active:bg-zinc-100 active:ring-1 active:ring-zinc-300 disabled:cursor-not-allowed\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      <div className=\"relative h-[2.625rem] w-[2.625rem] rounded-[0.5rem] bg-white\">\n+        {icon_url && (\n+          <Image\n+            src={icon_url}\n+            alt=\"integration-icon\"\n+            fill\n+            sizes=\"2.25rem\"\n+            className=\"w-full object-contain group-disabled:opacity-50\"\n+          />\n+        )}\n+      </div>\n+      <div className=\"flex flex-1 flex-col items-start gap-0.5\">\n+        {title && (\n+          <span\n+            className={cn(\n+              \"line-clamp-1 font-sans text-sm font-medium leading-[1.375rem] text-zinc-800 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            {highlightText(beautifyString(title), highlightedText)}\n+          </span>\n+        )}\n+        {description && (\n+          <span\n+            className={cn(\n+              \"line-clamp-1 font-sans text-xs font-normal leading-5 text-zinc-500 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            {highlightText(description, highlightedText)}\n+          </span>\n+        )}\n+      </div>\n+      <div\n+        className={cn(\n+          \"flex h-7 w-7 items-center justify-center rounded-[0.5rem] bg-zinc-700 group-disabled:bg-zinc-400\",\n+        )}\n+      >\n+        <Plus className=\"h-5 w-5 text-zinc-50\" strokeWidth={2} />\n+      </div>\n+    </Button>\n+  );\n+};\n+\n+const IntegrationBlockSkeleton = ({ className }: { className?: string }) => {\n+  return (\n+    <Skeleton\n+      className={cn(\n+        \"flex h-16 w-full min-w-[7.5rem] animate-pulse items-center justify-start gap-3 rounded-[0.75rem] bg-zinc-100 px-[0.875rem] py-[0.625rem]\",\n+        className,\n+      )}\n+    >\n+      <Skeleton className=\"h-[2.625rem] w-[2.625rem] rounded-[0.5rem] bg-zinc-200\" />\n+      <div className=\"flex flex-1 flex-col items-start gap-0.5\">\n+        <Skeleton className=\"h-[1.375rem] w-24 rounded bg-zinc-200\" />\n+        <Skeleton className=\"h-5 w-32 rounded bg-zinc-200\" />\n+      </div>\n+      <Skeleton className=\"h-7 w-7 rounded-[0.5rem] bg-zinc-200\" />\n+    </Skeleton>\n+  );\n+};\n+\n+IntegrationBlock.Skeleton = IntegrationBlockSkeleton;\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/IntegrationChip.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/IntegrationChip.tsx\nnew file mode 100644\nindex 000000000000..611e283bdb1a\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/IntegrationChip.tsx\n@@ -0,0 +1,60 @@\n+import { Button } from \"@/components/ui/button\";\n+import { Skeleton } from \"@/components/ui/skeleton\";\n+import { beautifyString, cn } from \"@/lib/utils\";\n+import Image from \"next/image\";\n+import React, { ButtonHTMLAttributes } from \"react\";\n+\n+interface Props extends ButtonHTMLAttributes<HTMLButtonElement> {\n+  name?: string;\n+  icon_url?: string;\n+}\n+\n+interface IntegrationChipComponent extends React.FC<Props> {\n+  Skeleton: React.FC;\n+}\n+\n+export const IntegrationChip: IntegrationChipComponent = ({\n+  icon_url,\n+  name,\n+  className,\n+  ...rest\n+}) => {\n+  return (\n+    <Button\n+      className={cn(\n+        \"flex h-[3.25rem] w-full min-w-[7.5rem] justify-start gap-2 whitespace-normal rounded-[0.5rem] bg-zinc-50 p-2 pr-3 shadow-none\",\n+        \"hover:cursor-default hover:bg-zinc-100 focus:ring-0 active:bg-zinc-100 active:ring-1 active:ring-zinc-300\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      <div className=\"relative h-9 w-9 rounded-[0.5rem] bg-transparent\">\n+        {icon_url && (\n+          <Image\n+            src={icon_url}\n+            alt=\"integration-icon\"\n+            fill\n+            sizes=\"2.25rem\"\n+            className=\"w-full object-contain\"\n+          />\n+        )}\n+      </div>\n+      {name && (\n+        <span className=\"truncate font-sans text-sm font-normal leading-[1.375rem] text-zinc-800\">\n+          {beautifyString(name)}\n+        </span>\n+      )}\n+    </Button>\n+  );\n+};\n+\n+const IntegrationChipSkeleton: React.FC = () => {\n+  return (\n+    <Skeleton className=\"flex h-[3.25rem] w-full min-w-[7.5rem] gap-2 rounded-[0.5rem] bg-zinc-100 p-2 pr-3\">\n+      <Skeleton className=\"h-9 w-12 rounded-[0.5rem] bg-zinc-200\" />\n+      <Skeleton className=\"h-5 w-24 self-center rounded-sm bg-zinc-200\" />\n+    </Skeleton>\n+  );\n+};\n+\n+IntegrationChip.Skeleton = IntegrationChipSkeleton;\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/MarketplaceAgentBlock.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/MarketplaceAgentBlock.tsx\nnew file mode 100644\nindex 000000000000..84184e40d074\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/MarketplaceAgentBlock.tsx\n@@ -0,0 +1,135 @@\n+import { Button } from \"@/components/ui/button\";\n+import { Skeleton } from \"@/components/ui/skeleton\";\n+import { cn } from \"@/lib/utils\";\n+import { ExternalLink, Loader2, Plus } from \"lucide-react\";\n+import Image from \"next/image\";\n+import React, { ButtonHTMLAttributes } from \"react\";\n+import { highlightText } from \"./IntegrationBlock\";\n+import Link from \"next/link\";\n+\n+interface Props extends ButtonHTMLAttributes<HTMLButtonElement> {\n+  title?: string;\n+  creator_name?: string;\n+  number_of_runs?: number;\n+  image_url?: string;\n+  highlightedText?: string;\n+  slug: string;\n+  loading: boolean;\n+}\n+\n+interface MarketplaceAgentBlockComponent extends React.FC<Props> {\n+  Skeleton: React.FC<{ className?: string }>;\n+}\n+\n+export const MarketplaceAgentBlock: MarketplaceAgentBlockComponent = ({\n+  title,\n+  image_url,\n+  creator_name,\n+  number_of_runs,\n+  className,\n+  loading,\n+  highlightedText,\n+  slug,\n+  ...rest\n+}) => {\n+  return (\n+    <Button\n+      className={cn(\n+        \"group flex h-[4.375rem] w-full min-w-[7.5rem] items-center justify-start gap-3 whitespace-normal rounded-[0.75rem] bg-zinc-50 p-[0.625rem] pr-[0.875rem] text-start shadow-none\",\n+        \"hover:cursor-default hover:bg-zinc-100 focus:ring-0 active:bg-zinc-100 active:ring-1 active:ring-zinc-300 disabled:pointer-events-none\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      <div className=\"relative h-[3.125rem] w-[5.625rem] overflow-hidden rounded-[0.375rem] bg-white\">\n+        {image_url && (\n+          <Image\n+            src={image_url}\n+            alt=\"integration-icon\"\n+            fill\n+            sizes=\"5.625rem\"\n+            className=\"w-full object-contain group-disabled:opacity-50\"\n+          />\n+        )}\n+      </div>\n+      <div className=\"flex flex-1 flex-col items-start gap-0.5\">\n+        {title && (\n+          <span\n+            className={cn(\n+              \"line-clamp-1 font-sans text-sm font-medium leading-[1.375rem] text-zinc-800 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            {highlightText(title, highlightedText)}\n+          </span>\n+        )}\n+        <div className=\"flex items-center space-x-2.5\">\n+          <span\n+            className={cn(\n+              \"truncate font-sans text-xs font-normal leading-5 text-zinc-500 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            By {creator_name}\n+          </span>\n+\n+          <span className=\"font-sans text-zinc-400\">•</span>\n+\n+          <span\n+            className={cn(\n+              \"truncate font-sans text-xs font-normal leading-5 text-zinc-500 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            {number_of_runs} runs\n+          </span>\n+          <span className=\"font-sans text-zinc-400\">•</span>\n+          <Link\n+            href={`/marketplace/agent/${creator_name}/${slug}`}\n+            className=\"flex gap-0.5 truncate\"\n+            onClick={(e) => e.stopPropagation()}\n+          >\n+            <span className=\"font-sans text-xs leading-5 text-blue-700 underline\">\n+              Agent page\n+            </span>\n+            <ExternalLink className=\"h-4 w-4 text-blue-700\" strokeWidth={1} />\n+          </Link>\n+        </div>\n+      </div>\n+      <div\n+        className={cn(\n+          \"flex h-7 min-w-7 items-center justify-center rounded-[0.5rem] bg-zinc-700 group-disabled:bg-zinc-400\",\n+        )}\n+      >\n+        {!loading ? (\n+          <Plus className=\"h-5 w-5 text-zinc-50\" strokeWidth={2} />\n+        ) : (\n+          <Loader2 className=\"h-5 w-5 animate-spin\" />\n+        )}\n+      </div>\n+    </Button>\n+  );\n+};\n+\n+const MarketplaceAgentBlockSkeleton: React.FC<{ className?: string }> = ({\n+  className,\n+}) => {\n+  return (\n+    <Skeleton\n+      className={cn(\n+        \"flex h-[4.375rem] w-full min-w-[7.5rem] animate-pulse items-center justify-start gap-3 rounded-[0.75rem] bg-zinc-100 p-[0.625rem] pr-[0.875rem]\",\n+        className,\n+      )}\n+    >\n+      <Skeleton className=\"h-[3.125rem] w-[5.625rem] rounded-[0.375rem] bg-zinc-200\" />\n+      <div className=\"flex flex-1 flex-col items-start gap-0.5\">\n+        <Skeleton className=\"h-[1.375rem] w-24 rounded bg-zinc-200\" />\n+        <div className=\"flex items-center gap-1\">\n+          <Skeleton className=\"h-5 w-16 rounded bg-zinc-200\" />\n+\n+          <Skeleton className=\"h-5 w-16 rounded bg-zinc-200\" />\n+        </div>\n+      </div>\n+      <Skeleton className=\"h-7 w-7 rounded-[0.5rem] bg-zinc-200\" />\n+    </Skeleton>\n+  );\n+};\n+\n+MarketplaceAgentBlock.Skeleton = MarketplaceAgentBlockSkeleton;\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/MenuItem.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/MenuItem.tsx\nnew file mode 100644\nindex 000000000000..89407ccfbdc1\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/MenuItem.tsx\n@@ -0,0 +1,40 @@\n+// BLOCK MENU TODO: We need to add a better hover state to it; currently it's not in the design either.\n+\n+import { Button } from \"@/components/ui/button\";\n+import { cn } from \"@/lib/utils\";\n+import React, { ButtonHTMLAttributes } from \"react\";\n+\n+interface Props extends ButtonHTMLAttributes<HTMLButtonElement> {\n+  selected?: boolean;\n+  number?: number;\n+  name?: string;\n+}\n+\n+export const MenuItem: React.FC<Props> = ({\n+  selected = false,\n+  number,\n+  name,\n+  className,\n+  ...rest\n+}) => {\n+  return (\n+    <Button\n+      className={cn(\n+        \"flex h-[2.375rem] w-[12.875rem] justify-between whitespace-normal rounded-[0.5rem] bg-transparent p-2 pl-3 shadow-none\",\n+        \"hover:cursor-default hover:bg-zinc-100 focus:ring-0\",\n+        selected && \"bg-zinc-100\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      <span className=\"truncate font-sans text-sm font-medium leading-[1.375rem] text-zinc-800\">\n+        {name}\n+      </span>\n+      {number && (\n+        <span className=\"font-sans text-sm font-normal leading-[1.375rem] text-zinc-600\">\n+          {number > 100 ? \"100+\" : number}\n+        </span>\n+      )}\n+    </Button>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/SearchHistoryChip.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/SearchHistoryChip.tsx\nnew file mode 100644\nindex 000000000000..77cad6443a99\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/SearchHistoryChip.tsx\n@@ -0,0 +1,47 @@\n+import { Button } from \"@/components/ui/button\";\n+import { Skeleton } from \"@/components/ui/skeleton\";\n+import { cn } from \"@/lib/utils\";\n+import { ArrowUpRight } from \"lucide-react\";\n+import React, { ButtonHTMLAttributes } from \"react\";\n+\n+interface Props extends ButtonHTMLAttributes<HTMLButtonElement> {\n+  content?: string;\n+}\n+\n+interface SearchHistoryChipComponent extends React.FC<Props> {\n+  Skeleton: React.FC<{ className?: string }>;\n+}\n+\n+export const SearchHistoryChip: SearchHistoryChipComponent = ({\n+  content,\n+  className,\n+  ...rest\n+}) => {\n+  return (\n+    <Button\n+      className={cn(\n+        \"my-[1px] h-[2.25rem] space-x-1 rounded-[1.5rem] bg-zinc-50 p-[0.375rem] pr-[0.625rem] shadow-none\",\n+        \"hover:cursor-default hover:bg-zinc-100 focus:ring-0 active:bg-zinc-100 active:ring-1 active:ring-zinc-300\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      <ArrowUpRight className=\"h-6 w-6 text-zinc-500\" strokeWidth={1.25} />\n+      <span className=\"font-sans text-sm font-normal leading-[1.375rem] text-zinc-800\">\n+        {content}\n+      </span>\n+    </Button>\n+  );\n+};\n+\n+const SearchHistoryChipSkeleton: React.FC<{ className?: string }> = ({\n+  className,\n+}) => {\n+  return (\n+    <Skeleton\n+      className={cn(\"h-[2.25rem] w-32 rounded-[1.5rem] bg-zinc-100\", className)}\n+    />\n+  );\n+};\n+\n+SearchHistoryChip.Skeleton = SearchHistoryChipSkeleton;\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/UGCAgentBlock.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/UGCAgentBlock.tsx\nnew file mode 100644\nindex 000000000000..7244deae886b\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/UGCAgentBlock.tsx\n@@ -0,0 +1,117 @@\n+import { Button } from \"@/components/ui/button\";\n+import { Skeleton } from \"@/components/ui/skeleton\";\n+import { cn } from \"@/lib/utils\";\n+import { Plus } from \"lucide-react\";\n+import Image from \"next/image\";\n+import React, { ButtonHTMLAttributes } from \"react\";\n+import { highlightText } from \"./IntegrationBlock\";\n+import TimeAgo from \"react-timeago\";\n+\n+interface Props extends ButtonHTMLAttributes<HTMLButtonElement> {\n+  title?: string;\n+  edited_time?: Date;\n+  version?: number;\n+  image_url?: string;\n+  highlightedText?: string;\n+}\n+\n+interface UGCAgentBlockComponent extends React.FC<Props> {\n+  Skeleton: React.FC<{ className?: string }>;\n+}\n+\n+export const UGCAgentBlock: UGCAgentBlockComponent = ({\n+  title,\n+  image_url,\n+  edited_time,\n+  version,\n+  className,\n+  highlightedText,\n+  ...rest\n+}) => {\n+  return (\n+    <Button\n+      className={cn(\n+        \"group flex h-[4.375rem] w-full min-w-[7.5rem] items-center justify-start gap-3 whitespace-normal rounded-[0.75rem] bg-zinc-50 p-[0.625rem] pr-[0.875rem] text-start shadow-none\",\n+        \"hover:cursor-default hover:bg-zinc-100 focus:ring-0 active:bg-zinc-100 active:ring-1 active:ring-zinc-300 disabled:cursor-not-allowed\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      {image_url && (\n+        <div className=\"relative h-[3.125rem] w-[5.625rem] overflow-hidden rounded-[0.375rem] bg-white\">\n+          <Image\n+            src={image_url}\n+            alt=\"integration-icon\"\n+            fill\n+            sizes=\"5.625rem\"\n+            className=\"w-full object-contain group-disabled:opacity-50\"\n+          />\n+        </div>\n+      )}\n+      <div className=\"flex flex-1 flex-col items-start gap-0.5\">\n+        {title && (\n+          <span\n+            className={cn(\n+              \"line-clamp-1 font-sans text-sm font-medium leading-[1.375rem] text-zinc-800 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            {highlightText(title, highlightedText)}\n+          </span>\n+        )}\n+        <div className=\"flex items-center space-x-1.5\">\n+          {edited_time && (\n+            <span\n+              className={cn(\n+                \"line-clamp-1 font-sans text-xs font-normal leading-5 text-zinc-500 group-disabled:text-zinc-400\",\n+              )}\n+            >\n+              Edited {<TimeAgo date={edited_time} />}\n+            </span>\n+          )}\n+\n+          <span className=\"font-sans text-zinc-400\">•</span>\n+\n+          <span\n+            className={cn(\n+              \"line-clamp-1 font-sans text-xs font-normal leading-5 text-zinc-500 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            Version {version}\n+          </span>\n+        </div>\n+      </div>\n+      <div\n+        className={cn(\n+          \"flex h-7 w-7 items-center justify-center rounded-[0.5rem] bg-zinc-700 group-disabled:bg-zinc-400\",\n+        )}\n+      >\n+        <Plus className=\"h-5 w-5 text-zinc-50\" strokeWidth={2} />\n+      </div>\n+    </Button>\n+  );\n+};\n+\n+const UGCAgentBlockSkeleton: React.FC<{ className?: string }> = ({\n+  className,\n+}) => {\n+  return (\n+    <Skeleton\n+      className={cn(\n+        \"flex h-[4.375rem] w-full min-w-[7.5rem] animate-pulse items-center justify-start gap-3 rounded-[0.75rem] bg-zinc-100 p-[0.625rem] pr-[0.875rem]\",\n+        className,\n+      )}\n+    >\n+      <Skeleton className=\"h-[3.125rem] w-[5.625rem] rounded-[0.375rem] bg-zinc-200\" />\n+      <div className=\"flex flex-1 flex-col items-start gap-0.5\">\n+        <Skeleton className=\"h-[1.375rem] w-24 rounded bg-zinc-200\" />\n+        <div className=\"flex items-center gap-1\">\n+          <Skeleton className=\"h-5 w-16 rounded bg-zinc-200\" />\n+          <Skeleton className=\"h-5 w-16 rounded bg-zinc-200\" />\n+        </div>\n+      </div>\n+      <Skeleton className=\"h-7 w-7 rounded-[0.5rem] bg-zinc-200\" />\n+    </Skeleton>\n+  );\n+};\n+\n+UGCAgentBlock.Skeleton = UGCAgentBlockSkeleton;\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/block-menu-provider.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/block-menu-provider.tsx\nnew file mode 100644\nindex 000000000000..8820a3a239eb\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/block-menu-provider.tsx\n@@ -0,0 +1,176 @@\n+\"use client\";\n+\n+import {\n+  Block,\n+  CredentialsProviderName,\n+  LibraryAgent,\n+  Provider,\n+  StoreAgent,\n+} from \"@/lib/autogpt-server-api\";\n+import { createContext, ReactNode, useContext, useState } from \"react\";\n+import { convertLibraryAgentIntoBlock } from \"@/lib/utils\";\n+import { useBackendAPI } from \"@/lib/autogpt-server-api/context\";\n+import { getDefaultFilters } from \"./helpers\";\n+\n+export type SearchItem = Block | Provider | LibraryAgent | StoreAgent;\n+\n+export type DefaultStateType =\n+  | \"suggestion\"\n+  | \"all_blocks\"\n+  | \"input_blocks\"\n+  | \"action_blocks\"\n+  | \"output_blocks\"\n+  | \"integrations\"\n+  | \"marketplace_agents\"\n+  | \"my_agents\";\n+\n+export type CategoryKey =\n+  | \"blocks\"\n+  | \"integrations\"\n+  | \"marketplace_agents\"\n+  | \"my_agents\";\n+\n+export interface Filters {\n+  categories: {\n+    blocks: boolean;\n+    integrations: boolean;\n+    marketplace_agents: boolean;\n+    my_agents: boolean;\n+    providers: boolean;\n+  };\n+  createdBy: string[];\n+}\n+\n+export type CategoryCounts = Record<CategoryKey, number>;\n+\n+interface BlockMenuContextType {\n+  defaultState: DefaultStateType;\n+  setDefaultState: React.Dispatch<React.SetStateAction<DefaultStateType>>;\n+  integration: CredentialsProviderName | null;\n+  setIntegration: React.Dispatch<\n+    React.SetStateAction<CredentialsProviderName | null>\n+  >;\n+  searchQuery: string;\n+  setSearchQuery: React.Dispatch<React.SetStateAction<string>>;\n+  searchId: string | undefined;\n+  setSearchId: React.Dispatch<React.SetStateAction<string | undefined>>;\n+  filters: Filters;\n+  setFilters: React.Dispatch<React.SetStateAction<Filters>>;\n+  searchData: SearchItem[];\n+  setSearchData: React.Dispatch<React.SetStateAction<SearchItem[]>>;\n+  categoryCounts: CategoryCounts;\n+  setCategoryCounts: React.Dispatch<React.SetStateAction<CategoryCounts>>;\n+  addNode: (block: Block) => void;\n+  handleAddStoreAgent: ({\n+    creator_name,\n+    slug,\n+  }: {\n+    creator_name: string;\n+    slug: string;\n+  }) => Promise<void>;\n+  loadingSlug: string | null;\n+  setLoadingSlug: React.Dispatch<React.SetStateAction<string | null>>;\n+}\n+\n+export const BlockMenuContext = createContext<BlockMenuContextType>(\n+  {} as BlockMenuContextType,\n+);\n+\n+interface BlockMenuStateProviderProps {\n+  children: ReactNode;\n+  addNode: (block: Block) => void;\n+}\n+\n+export function BlockMenuStateProvider({\n+  children,\n+  addNode,\n+}: BlockMenuStateProviderProps) {\n+  const [defaultState, setDefaultState] =\n+    useState<DefaultStateType>(\"suggestion\");\n+  const [integration, setIntegration] =\n+    useState<CredentialsProviderName | null>(null);\n+  const [searchQuery, setSearchQuery] = useState(\"\");\n+  const [filters, setFilters] = useState<Filters>(getDefaultFilters());\n+  const [searchData, setSearchData] = useState<SearchItem[]>([]);\n+\n+  const [searchId, setSearchId] = useState<string | undefined>(undefined);\n+\n+  const [categoryCounts, setCategoryCounts] = useState<CategoryCounts>({\n+    blocks: 0,\n+    integrations: 0,\n+    marketplace_agents: 0,\n+    my_agents: 0,\n+  });\n+\n+  const [loadingSlug, setLoadingSlug] = useState<string | null>(null);\n+\n+  const api = useBackendAPI();\n+\n+  const handleAddStoreAgent = async ({\n+    creator_name,\n+    slug,\n+  }: {\n+    creator_name: string;\n+    slug: string;\n+  }) => {\n+    try {\n+      setLoadingSlug(slug);\n+      const details = await api.getStoreAgent(creator_name, slug);\n+\n+      if (!details.active_version_id) {\n+        console.error(\n+          \"Cannot add store agent to library: active version ID is missing or undefined\",\n+        );\n+        return;\n+      }\n+\n+      const libraryAgent = await api.addMarketplaceAgentToLibrary(\n+        details.active_version_id,\n+      );\n+\n+      const block = convertLibraryAgentIntoBlock(libraryAgent);\n+      addNode(block);\n+    } catch (error) {\n+      console.error(\"Failed to add store agent:\", error);\n+    } finally {\n+      setLoadingSlug(null);\n+    }\n+  };\n+\n+  return (\n+    <BlockMenuContext.Provider\n+      value={{\n+        defaultState,\n+        setDefaultState,\n+        integration,\n+        setIntegration,\n+        searchQuery,\n+        setSearchQuery,\n+        searchId,\n+        setSearchId,\n+        filters,\n+        setFilters,\n+        searchData,\n+        setSearchData,\n+        categoryCounts,\n+        setCategoryCounts,\n+        addNode,\n+        handleAddStoreAgent,\n+        loadingSlug,\n+        setLoadingSlug,\n+      }}\n+    >\n+      {children}\n+    </BlockMenuContext.Provider>\n+  );\n+}\n+\n+export function useBlockMenuContext(): BlockMenuContextType {\n+  const context = useContext(BlockMenuContext);\n+  if (!context) {\n+    throw new Error(\n+      \"useBlockMenuContext must be used within a BlockMenuStateProvider\",\n+    );\n+  }\n+  return context;\n+}\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/AllBlocksContent.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/AllBlocksContent.tsx\nnew file mode 100644\nindex 000000000000..fdfb66d75df5\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/AllBlocksContent.tsx\n@@ -0,0 +1,162 @@\n+import React, { useState, useEffect, Fragment, useCallback } from \"react\";\n+import { Block } from \"../Block\";\n+import { Button } from \"@/components/ui/button\";\n+import { Separator } from \"@/components/ui/separator\";\n+import { Skeleton } from \"@/components/ui/skeleton\";\n+import { useBackendAPI } from \"@/lib/autogpt-server-api/context\";\n+import { BlockCategoryResponse } from \"@/lib/autogpt-server-api\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+import { ErrorState } from \"../ErrorState\";\n+import { beautifyString } from \"@/lib/utils\";\n+import { scrollbarStyles } from \"@/components/styles/scrollbar\";\n+\n+export const AllBlocksContent = () => {\n+  const { addNode } = useBlockMenuContext();\n+  const [categories, setCategories] = useState<BlockCategoryResponse[]>([]);\n+  const [loading, setLoading] = useState(true);\n+  const [error, setError] = useState<string | null>(null);\n+  const [loadingCategories, setLoadingCategories] = useState<Set<string>>(\n+    new Set(),\n+  );\n+\n+  const api = useBackendAPI();\n+\n+  const fetchBlocks = useCallback(async () => {\n+    try {\n+      setLoading(true);\n+      setError(null);\n+      const response = await api.getBlockCategories();\n+      setCategories(response);\n+    } catch (err) {\n+      console.error(\"Failed to fetch block categories:\", err);\n+      setError(\n+        err instanceof Error ? err.message : \"Failed to load block categories\",\n+      );\n+    } finally {\n+      setLoading(false);\n+    }\n+  }, [api]);\n+\n+  useEffect(() => {\n+    fetchBlocks();\n+  }, [fetchBlocks]);\n+\n+  const fetchMoreBlockOfACategory = async (category: string) => {\n+    try {\n+      setLoadingCategories((prev) => new Set(prev).add(category));\n+      const response = await api.getBuilderBlocks({ category: category });\n+      const updatedCategories = categories.map((cat) => {\n+        if (cat.name === category) {\n+          return {\n+            ...cat,\n+            blocks: [...response.blocks],\n+          };\n+        }\n+        return cat;\n+      });\n+\n+      setCategories(updatedCategories);\n+    } catch (error) {\n+      console.error(`Failed to fetch blocks for category ${category}:`, error);\n+    } finally {\n+      setLoadingCategories((prev) => {\n+        const newSet = new Set(prev);\n+        newSet.delete(category);\n+        return newSet;\n+      });\n+    }\n+  };\n+\n+  if (loading) {\n+    return (\n+      <div className={scrollbarStyles}>\n+        <div className=\"w-full space-y-3 px-4 pb-4\">\n+          {Array.from({ length: 3 }).map((_, categoryIndex) => (\n+            <Fragment key={categoryIndex}>\n+              {categoryIndex > 0 && (\n+                <Skeleton className=\"my-4 h-[1px] w-full text-zinc-100\" />\n+              )}\n+              {[0, 1, 2].map((blockIndex) => (\n+                <Block.Skeleton key={`${categoryIndex}-${blockIndex}`} />\n+              ))}\n+            </Fragment>\n+          ))}\n+        </div>\n+      </div>\n+    );\n+  }\n+\n+  if (error) {\n+    return (\n+      <div className=\"h-full p-4\">\n+        <ErrorState\n+          title=\"Failed to load blocks\"\n+          error={error}\n+          onRetry={fetchBlocks}\n+        />\n+      </div>\n+    );\n+  }\n+\n+  return (\n+    <div className={scrollbarStyles}>\n+      <div className=\"w-full space-y-3 px-4 pb-4\">\n+        {categories.map((category, index) => (\n+          <Fragment key={category.name}>\n+            {index > 0 && (\n+              <Separator className=\"h-[1px] w-full text-zinc-300\" />\n+            )}\n+\n+            {/* Category Section */}\n+            <div className=\"space-y-2.5\">\n+              <div className=\"flex items-center justify-between\">\n+                <p className=\"font-sans text-sm font-medium leading-[1.375rem] text-zinc-800\">\n+                  {category.name && beautifyString(category.name)}\n+                </p>\n+                <span className=\"rounded-full bg-zinc-100 px-[0.375rem] font-sans text-sm leading-[1.375rem] text-zinc-600\">\n+                  {category.total_blocks}\n+                </span>\n+              </div>\n+\n+              <div className=\"space-y-2\">\n+                {category.blocks.map((block) => (\n+                  <Block\n+                    key={`${category.name}-${block.id}`}\n+                    title={block.name}\n+                    description={block.name}\n+                    onClick={() => {\n+                      addNode(block);\n+                    }}\n+                  />\n+                ))}\n+\n+                {loadingCategories.has(category.name) && (\n+                  <>\n+                    {[0, 1, 2, 3, 4].map((skeletonIndex) => (\n+                      <Block.Skeleton\n+                        key={`skeleton-${category.name}-${skeletonIndex}`}\n+                      />\n+                    ))}\n+                  </>\n+                )}\n+\n+                {category.total_blocks > category.blocks.length && (\n+                  <Button\n+                    variant={\"link\"}\n+                    className=\"px-0 font-sans text-sm leading-[1.375rem] text-zinc-600 underline hover:text-zinc-800\"\n+                    disabled={loadingCategories.has(category.name)}\n+                    onClick={() => {\n+                      fetchMoreBlockOfACategory(category.name);\n+                    }}\n+                  >\n+                    see all\n+                  </Button>\n+                )}\n+              </div>\n+            </div>\n+          </Fragment>\n+        ))}\n+      </div>\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/BlockMenuDefault.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/BlockMenuDefault.tsx\nnew file mode 100644\nindex 000000000000..66cecb9c5189\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/BlockMenuDefault.tsx\n@@ -0,0 +1,14 @@\n+import React from \"react\";\n+import { BlockMenuSidebar } from \"./BlockMenuSidebar\";\n+import { Separator } from \"@/components/ui/separator\";\n+import { BlockMenuDefaultContent } from \"./BlockMenuDefaultContent\";\n+\n+export const BlockMenuDefault = () => {\n+  return (\n+    <div className=\"flex flex-1 overflow-y-auto\">\n+      <BlockMenuSidebar />\n+      <Separator className=\"h-full w-[1px] text-zinc-300\" />\n+      <BlockMenuDefaultContent />\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/BlockMenuDefaultContent.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/BlockMenuDefaultContent.tsx\nnew file mode 100644\nindex 000000000000..ef5f3c8d7c38\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/BlockMenuDefaultContent.tsx\n@@ -0,0 +1,43 @@\n+import React from \"react\";\n+import { SuggestionContent } from \"./SuggestionContent\";\n+import { AllBlocksContent } from \"./AllBlocksContent\";\n+import { IntegrationsContent } from \"./IntegrationsContent\";\n+import { MarketplaceAgentsContent } from \"./MarketplaceAgentsContent\";\n+import { MyAgentsContent } from \"./MyAgentsContent\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+import { PaginatedBlocksContent } from \"./PaginatedBlocksContent\";\n+\n+export interface ActionBlock {\n+  id: number;\n+  title: string;\n+  description: string;\n+}\n+\n+export interface BlockListType {\n+  id: number;\n+  title: string;\n+  description: string;\n+}\n+\n+export const BlockMenuDefaultContent = () => {\n+  const { defaultState } = useBlockMenuContext();\n+\n+  return (\n+    <div className=\"h-full flex-1 overflow-hidden\">\n+      {defaultState == \"suggestion\" && <SuggestionContent />}\n+      {defaultState == \"all_blocks\" && <AllBlocksContent />}\n+      {defaultState == \"input_blocks\" && (\n+        <PaginatedBlocksContent blockRequest={{ type: \"input\" }} />\n+      )}\n+      {defaultState == \"action_blocks\" && (\n+        <PaginatedBlocksContent blockRequest={{ type: \"action\" }} />\n+      )}\n+      {defaultState == \"output_blocks\" && (\n+        <PaginatedBlocksContent blockRequest={{ type: \"output\" }} />\n+      )}\n+      {defaultState == \"integrations\" && <IntegrationsContent />}\n+      {defaultState == \"marketplace_agents\" && <MarketplaceAgentsContent />}\n+      {defaultState == \"my_agents\" && <MyAgentsContent />}\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/BlockMenuSidebar.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/BlockMenuSidebar.tsx\nnew file mode 100644\nindex 000000000000..84591d61b94e\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/BlockMenuSidebar.tsx\n@@ -0,0 +1,117 @@\n+import React, { useEffect, useState } from \"react\";\n+import { MenuItem } from \"../MenuItem\";\n+import { DefaultStateType, useBlockMenuContext } from \"../block-menu-provider\";\n+import { useBackendAPI } from \"@/lib/autogpt-server-api/context\";\n+import { CountResponse } from \"@/lib/autogpt-server-api\";\n+\n+export const BlockMenuSidebar = () => {\n+  const { defaultState, setDefaultState, setIntegration } =\n+    useBlockMenuContext();\n+  const [blockCounts, setBlockCounts] = useState<CountResponse | undefined>(\n+    undefined,\n+  );\n+  const api = useBackendAPI();\n+\n+  useEffect(() => {\n+    const fetchBlockCounts = async () => {\n+      try {\n+        const counts = await api.getBlockCounts();\n+        setBlockCounts(counts);\n+      } catch (error) {\n+        console.error(\"Failed to fetch block counts:\", error);\n+      }\n+    };\n+\n+    fetchBlockCounts();\n+  }, [api]);\n+\n+  const topLevelMenuItems = [\n+    {\n+      name: \"Suggestion\",\n+      type: \"suggestion\",\n+    },\n+    {\n+      name: \"All blocks\",\n+      type: \"all_blocks\",\n+      number: blockCounts?.all_blocks,\n+    },\n+  ];\n+\n+  const subMenuItems = [\n+    {\n+      name: \"Input blocks\",\n+      type: \"input_blocks\",\n+      number: blockCounts?.input_blocks,\n+    },\n+    {\n+      name: \"Action blocks\",\n+      type: \"action_blocks\",\n+      number: blockCounts?.action_blocks,\n+    },\n+    {\n+      name: \"Output blocks\",\n+      type: \"output_blocks\",\n+      number: blockCounts?.output_blocks,\n+    },\n+  ];\n+\n+  const bottomMenuItems = [\n+    {\n+      name: \"Integrations\",\n+      type: \"integrations\",\n+      number: blockCounts?.integrations,\n+      onClick: () => {\n+        setIntegration(null);\n+        setDefaultState(\"integrations\");\n+      },\n+    },\n+    {\n+      name: \"Marketplace Agents\",\n+      type: \"marketplace_agents\",\n+      number: blockCounts?.marketplace_agents,\n+    },\n+    {\n+      name: \"My Agents\",\n+      type: \"my_agents\",\n+      number: blockCounts?.my_agents,\n+    },\n+  ];\n+\n+  return (\n+    <div className=\"w-fit space-y-2 px-4 pt-4\">\n+      {topLevelMenuItems.map((item) => (\n+        <MenuItem\n+          key={item.type}\n+          name={item.name}\n+          number={item.number}\n+          selected={defaultState === item.type}\n+          onClick={() => setDefaultState(item.type as DefaultStateType)}\n+        />\n+      ))}\n+      <div className=\"ml-[0.5365rem] space-y-2 border-l border-black/10 pl-[0.75rem]\">\n+        {subMenuItems.map((item) => (\n+          <MenuItem\n+            key={item.type}\n+            name={item.name}\n+            number={item.number}\n+            className=\"max-w-[11.5339rem]\"\n+            selected={defaultState === item.type}\n+            onClick={() => setDefaultState(item.type as DefaultStateType)}\n+          />\n+        ))}\n+      </div>\n+      {bottomMenuItems.map((item) => (\n+        <MenuItem\n+          key={item.type}\n+          name={item.name}\n+          number={item.number}\n+          selected={defaultState === item.type}\n+          onClick={\n+            item.onClick ||\n+            (() => setDefaultState(item.type as DefaultStateType))\n+          }\n+        />\n+      ))}\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/BlocksList.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/BlocksList.tsx\nnew file mode 100644\nindex 000000000000..d230fe6a04be\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/BlocksList.tsx\n@@ -0,0 +1,34 @@\n+import React from \"react\";\n+import { Block } from \"../Block\";\n+import { Block as BlockType } from \"@/lib/autogpt-server-api\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+\n+interface BlocksListProps {\n+  blocks: BlockType[];\n+  loading?: boolean;\n+}\n+\n+export const BlocksList: React.FC<BlocksListProps> = ({\n+  blocks,\n+  loading = false,\n+}) => {\n+  const { addNode } = useBlockMenuContext();\n+  return (\n+    <div className=\"w-full space-y-3 px-4 pb-4\">\n+      {loading\n+        ? Array.from({ length: 7 }).map((_, index) => (\n+            <Block.Skeleton key={index} />\n+          ))\n+        : blocks.map((block) => (\n+            <Block\n+              key={block.id}\n+              title={block.name}\n+              description={block.description}\n+              onClick={() => {\n+                addNode(block);\n+              }}\n+            />\n+          ))}\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/IntegrationBlocks.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/IntegrationBlocks.tsx\nnew file mode 100644\nindex 000000000000..72ab5d8731b1\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/IntegrationBlocks.tsx\n@@ -0,0 +1,110 @@\n+import { Button } from \"@/components/ui/button\";\n+import React, { useState, useEffect, Fragment, useCallback } from \"react\";\n+import { IntegrationBlock } from \"../IntegrationBlock\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+import { useBackendAPI } from \"@/lib/autogpt-server-api/context\";\n+import { Block } from \"@/lib/autogpt-server-api\";\n+import { ErrorState } from \"../ErrorState\";\n+import { Skeleton } from \"@/components/ui/skeleton\";\n+\n+export const IntegrationBlocks = () => {\n+  const { integration, setIntegration, addNode } = useBlockMenuContext();\n+  const [blocks, setBlocks] = useState<Block[]>([]);\n+  const [loading, setLoading] = useState(true);\n+  const [error, setError] = useState<string | null>(null);\n+\n+  const api = useBackendAPI();\n+\n+  const fetchBlocks = useCallback(async () => {\n+    if (integration) {\n+      try {\n+        setLoading(true);\n+        setError(null);\n+        const response = await api.getBuilderBlocks({ provider: integration });\n+        setBlocks(response.blocks);\n+      } catch (err) {\n+        console.error(\"Failed to fetch integration blocks:\", err);\n+        setError(\n+          err instanceof Error\n+            ? err.message\n+            : \"Failed to load integration blocks\",\n+        );\n+      } finally {\n+        setLoading(false);\n+      }\n+    }\n+  }, [api, integration]);\n+\n+  useEffect(() => {\n+    fetchBlocks();\n+  }, [fetchBlocks]);\n+\n+  if (loading) {\n+    return (\n+      <div className=\"w-full space-y-3 p-4\">\n+        {Array.from({ length: 3 }).map((_, blockIndex) => (\n+          <Fragment key={blockIndex}>\n+            {blockIndex > 0 && (\n+              <Skeleton className=\"my-4 h-[1px] w-full text-zinc-100\" />\n+            )}\n+            {[0, 1, 2].map((index) => (\n+              <IntegrationBlock.Skeleton key={`${blockIndex}-${index}`} />\n+            ))}\n+          </Fragment>\n+        ))}\n+      </div>\n+    );\n+  }\n+\n+  if (error) {\n+    return (\n+      <div className=\"h-full p-4\">\n+        <ErrorState\n+          title=\"Failed to load integration blocks\"\n+          error={error}\n+          onRetry={fetchBlocks}\n+        />\n+      </div>\n+    );\n+  }\n+\n+  return (\n+    <div className=\"space-y-2.5\">\n+      <div className=\"flex items-center justify-between\">\n+        <div className=\"flex items-center gap-1\">\n+          <Button\n+            variant={\"link\"}\n+            className=\"p-0 font-sans text-sm font-medium leading-[1.375rem] text-zinc-800\"\n+            onClick={() => {\n+              setIntegration(null);\n+            }}\n+          >\n+            Integrations\n+          </Button>\n+          <p className=\"font-sans text-sm font-medium leading-[1.375rem] text-zinc-800\">\n+            /\n+          </p>\n+          <p className=\"font-sans text-sm font-medium leading-[1.375rem] text-zinc-800\">\n+            {integration}\n+          </p>\n+        </div>\n+        <span className=\"flex h-[1.375rem] w-[1.6875rem] items-center justify-center rounded-[1.25rem] bg-[#f0f0f0] p-1.5 font-sans text-sm leading-[1.375rem] text-zinc-500 group-disabled:text-zinc-400\">\n+          {blocks.length}\n+        </span>\n+      </div>\n+      <div className=\"space-y-3\">\n+        {blocks.map((block) => (\n+          <IntegrationBlock\n+            key={block.id}\n+            title={block.name}\n+            description={block.description}\n+            icon_url={`/integrations/${integration}.png`}\n+            onClick={() => {\n+              addNode(block);\n+            }}\n+          />\n+        ))}\n+      </div>\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/IntegrationsContent.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/IntegrationsContent.tsx\nnew file mode 100644\nindex 000000000000..c394ab82d977\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/IntegrationsContent.tsx\n@@ -0,0 +1,21 @@\n+import React from \"react\";\n+import { PaginatedIntegrationList } from \"./PaginatedIntegrationList\";\n+import { IntegrationBlocks } from \"./IntegrationBlocks\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+import { scrollbarStyles } from \"@/components/styles/scrollbar\";\n+\n+export const IntegrationsContent = () => {\n+  const { integration } = useBlockMenuContext();\n+\n+  if (!integration) {\n+    return <PaginatedIntegrationList />;\n+  }\n+\n+  return (\n+    <div className={scrollbarStyles}>\n+      <div className=\"w-full px-4 pb-4\">\n+        <IntegrationBlocks />\n+      </div>\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/MarketplaceAgentsContent.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/MarketplaceAgentsContent.tsx\nnew file mode 100644\nindex 000000000000..508cf3861149\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/MarketplaceAgentsContent.tsx\n@@ -0,0 +1,77 @@\n+import React from \"react\";\n+import { MarketplaceAgentBlock } from \"../MarketplaceAgentBlock\";\n+import { usePagination } from \"@/hooks/usePagination\";\n+import { ErrorState } from \"../ErrorState\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+import { scrollbarStyles } from \"@/components/styles/scrollbar\";\n+\n+export const MarketplaceAgentsContent = () => {\n+  const {\n+    data: agents,\n+    loading,\n+    loadingMore,\n+    hasMore,\n+    error,\n+    scrollRef,\n+    refresh,\n+  } = usePagination({\n+    request: { apiType: \"store-agents\" },\n+    pageSize: 10,\n+  });\n+  const { handleAddStoreAgent, loadingSlug } = useBlockMenuContext();\n+\n+  if (loading) {\n+    return (\n+      <div ref={scrollRef} className={scrollbarStyles}>\n+        <div className=\"w-full space-y-3 px-4 pb-4\">\n+          {Array.from({ length: 5 }).map((_, index) => (\n+            <MarketplaceAgentBlock.Skeleton key={index} />\n+          ))}\n+        </div>\n+      </div>\n+    );\n+  }\n+\n+  if (error) {\n+    return (\n+      <div className=\"h-full p-4\">\n+        <ErrorState\n+          title=\"Failed to load marketplace agents\"\n+          error={error}\n+          onRetry={refresh}\n+        />\n+      </div>\n+    );\n+  }\n+\n+  return (\n+    <div ref={scrollRef} className={scrollbarStyles}>\n+      <div className=\"w-full space-y-3 px-4 pb-4\">\n+        {agents.map((agent) => (\n+          <MarketplaceAgentBlock\n+            key={agent.slug}\n+            slug={agent.slug}\n+            title={agent.agent_name}\n+            image_url={agent.agent_image}\n+            creator_name={agent.creator}\n+            number_of_runs={agent.runs}\n+            loading={loadingSlug === agent.slug}\n+            onClick={() =>\n+              handleAddStoreAgent({\n+                creator_name: agent.creator,\n+                slug: agent.slug,\n+              })\n+            }\n+          />\n+        ))}\n+        {loadingMore && hasMore && (\n+          <>\n+            {Array.from({ length: 3 }).map((_, index) => (\n+              <MarketplaceAgentBlock.Skeleton key={`loading-${index}`} />\n+            ))}\n+          </>\n+        )}\n+      </div>\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/MyAgentsContent.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/MyAgentsContent.tsx\nnew file mode 100644\nindex 000000000000..874a11d106c0\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/MyAgentsContent.tsx\n@@ -0,0 +1,74 @@\n+import React from \"react\";\n+import { UGCAgentBlock } from \"../UGCAgentBlock\";\n+import { usePagination } from \"@/hooks/usePagination\";\n+import { ErrorState } from \"../ErrorState\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+import { convertLibraryAgentIntoBlock } from \"@/lib/utils\";\n+import { scrollbarStyles } from \"@/components/styles/scrollbar\";\n+\n+export const MyAgentsContent = () => {\n+  const {\n+    data: agents,\n+    loading,\n+    loadingMore,\n+    hasMore,\n+    error,\n+    scrollRef,\n+    refresh,\n+  } = usePagination({\n+    request: { apiType: \"library-agents\" },\n+    pageSize: 10,\n+  });\n+  const { addNode } = useBlockMenuContext();\n+\n+  if (loading) {\n+    return (\n+      <div ref={scrollRef} className={scrollbarStyles}>\n+        <div className=\"w-full space-y-3 px-4 pb-4\">\n+          {Array.from({ length: 5 }).map((_, index) => (\n+            <UGCAgentBlock.Skeleton key={index} />\n+          ))}\n+        </div>\n+      </div>\n+    );\n+  }\n+\n+  if (error) {\n+    return (\n+      <div className=\"h-full p-4\">\n+        <ErrorState\n+          title=\"Failed to load library agents\"\n+          error={error}\n+          onRetry={refresh}\n+        />\n+      </div>\n+    );\n+  }\n+\n+  return (\n+    <div ref={scrollRef} className={scrollbarStyles}>\n+      <div className=\"w-full space-y-3 px-4 pb-4\">\n+        {agents.map((agent) => (\n+          <UGCAgentBlock\n+            key={agent.id}\n+            title={agent.name}\n+            edited_time={agent.updated_at}\n+            version={agent.graph_version}\n+            image_url={agent.image_url}\n+            onClick={() => {\n+              const block = convertLibraryAgentIntoBlock(agent);\n+              addNode(block);\n+            }}\n+          />\n+        ))}\n+        {loadingMore && hasMore && (\n+          <>\n+            {Array.from({ length: 3 }).map((_, index) => (\n+              <UGCAgentBlock.Skeleton key={`loading-${index}`} />\n+            ))}\n+          </>\n+        )}\n+      </div>\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/PaginatedBlocksContent.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/PaginatedBlocksContent.tsx\nnew file mode 100644\nindex 000000000000..a855bc94e13b\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/PaginatedBlocksContent.tsx\n@@ -0,0 +1,55 @@\n+import React from \"react\";\n+import { BlocksList } from \"./BlocksList\";\n+import { Block } from \"../Block\";\n+import { BlockRequest } from \"@/lib/autogpt-server-api\";\n+import { usePagination } from \"@/hooks/usePagination\";\n+import { ErrorState } from \"../ErrorState\";\n+import { scrollbarStyles } from \"@/components/styles/scrollbar\";\n+\n+interface PaginatedBlocksContentProps {\n+  blockRequest: BlockRequest;\n+  pageSize?: number;\n+}\n+\n+export const PaginatedBlocksContent: React.FC<PaginatedBlocksContentProps> = ({\n+  blockRequest,\n+  pageSize = 10,\n+}) => {\n+  const {\n+    data: blocks,\n+    loading,\n+    loadingMore,\n+    hasMore,\n+    error,\n+    scrollRef,\n+    refresh,\n+  } = usePagination({\n+    request: { apiType: \"blocks\", ...blockRequest },\n+    pageSize,\n+  });\n+\n+  if (error) {\n+    return (\n+      <div className=\"h-full w-full px-4 pb-4\">\n+        <ErrorState\n+          title=\"Failed to load blocks\"\n+          error={error}\n+          onRetry={refresh}\n+        />\n+      </div>\n+    );\n+  }\n+\n+  return (\n+    <div ref={scrollRef} className={scrollbarStyles}>\n+      <BlocksList blocks={blocks} loading={loading} />\n+      {loadingMore && hasMore && (\n+        <div className=\"w-full space-y-3 px-4 pb-4\">\n+          {Array.from({ length: 3 }).map((_, index) => (\n+            <Block.Skeleton key={`loading-${index}`} />\n+          ))}\n+        </div>\n+      )}\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/PaginatedIntegrationList.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/PaginatedIntegrationList.tsx\nnew file mode 100644\nindex 000000000000..105d5729e41f\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/PaginatedIntegrationList.tsx\n@@ -0,0 +1,72 @@\n+import React from \"react\";\n+import { Integration } from \"../Integration\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+import { usePagination } from \"@/hooks/usePagination\";\n+import { ErrorState } from \"../ErrorState\";\n+import { scrollbarStyles } from \"@/components/styles/scrollbar\";\n+\n+export const PaginatedIntegrationList = () => {\n+  const { setIntegration } = useBlockMenuContext();\n+  const {\n+    data: providers,\n+    loading,\n+    loadingMore,\n+    hasMore,\n+    error,\n+    scrollRef,\n+    refresh,\n+  } = usePagination({\n+    request: { apiType: \"providers\" },\n+    pageSize: 10,\n+  });\n+\n+  if (loading) {\n+    return (\n+      <div ref={scrollRef} className={scrollbarStyles}>\n+        <div className=\"w-full space-y-3 px-4 pb-4\">\n+          {Array.from({ length: 6 }).map((_, integrationIndex) => (\n+            <Integration.Skeleton key={integrationIndex} />\n+          ))}\n+        </div>\n+      </div>\n+    );\n+  }\n+\n+  if (error) {\n+    return (\n+      <div className=\"h-full p-4\">\n+        <ErrorState\n+          title=\"Failed to load integrations\"\n+          error={error}\n+          onRetry={refresh}\n+        />\n+      </div>\n+    );\n+  }\n+\n+  return (\n+    <div ref={scrollRef} className={scrollbarStyles}>\n+      <div className=\"w-full px-4 pb-4\">\n+        <div className=\"space-y-3\">\n+          {providers.map((integration, index) => (\n+            <Integration\n+              key={index}\n+              title={integration.name}\n+              icon_url={`/integrations/${integration.name}.png`}\n+              description={integration.description}\n+              number_of_blocks={integration.integration_count}\n+              onClick={() => setIntegration(integration.name)}\n+            />\n+          ))}\n+          {loadingMore && hasMore && (\n+            <>\n+              {Array.from({ length: 3 }).map((_, index) => (\n+                <Integration.Skeleton key={`loading-${index}`} />\n+              ))}\n+            </>\n+          )}\n+        </div>\n+      </div>\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/default/SuggestionContent.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/default/SuggestionContent.tsx\nnew file mode 100644\nindex 000000000000..125fb8484117\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/default/SuggestionContent.tsx\n@@ -0,0 +1,113 @@\n+import React, { useCallback, useEffect, useState } from \"react\";\n+import { IntegrationChip } from \"../IntegrationChip\";\n+import { Block } from \"../Block\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+import {\n+  CredentialsProviderName,\n+  SuggestionsResponse,\n+} from \"@/lib/autogpt-server-api\";\n+import { useBackendAPI } from \"@/lib/autogpt-server-api/context\";\n+import { ErrorState } from \"../ErrorState\";\n+import { scrollbarStyles } from \"@/components/styles/scrollbar\";\n+\n+export const SuggestionContent = () => {\n+  const { setIntegration, setDefaultState, addNode } = useBlockMenuContext();\n+\n+  const [suggestionsData, setSuggestionsData] =\n+    useState<SuggestionsResponse | null>(null);\n+  const [loading, setLoading] = useState<boolean>(true);\n+  const [error, setError] = useState<string | null>(null);\n+\n+  const api = useBackendAPI();\n+\n+  const fetchSuggestions = useCallback(async () => {\n+    try {\n+      setLoading(true);\n+      setError(null);\n+      const response = await api.getSuggestions();\n+      setSuggestionsData(response);\n+    } catch (err) {\n+      console.error(\"Error fetching data:\", err);\n+      setError(\n+        err instanceof Error ? err.message : \"Failed to load suggestions\",\n+      );\n+    } finally {\n+      setLoading(false);\n+    }\n+  }, [api]);\n+\n+  useEffect(() => {\n+    fetchSuggestions();\n+  }, [fetchSuggestions]);\n+\n+  if (error) {\n+    return (\n+      <div className=\"h-full p-4\">\n+        <ErrorState\n+          title=\"Failed to load suggestions\"\n+          error={error}\n+          onRetry={fetchSuggestions}\n+        />\n+      </div>\n+    );\n+  }\n+\n+  return (\n+    <div className={scrollbarStyles}>\n+      <div className=\"w-full space-y-6 pb-4\">\n+        {/* Integrations */}\n+        <div className=\"space-y-2.5 px-4\">\n+          <p className=\"font-sans text-sm font-medium leading-[1.375rem] text-zinc-800\">\n+            Integrations\n+          </p>\n+          <div className=\"grid grid-cols-3 grid-rows-2 gap-2\">\n+            {!loading && suggestionsData\n+              ? suggestionsData.providers.map((provider, index) => (\n+                  <IntegrationChip\n+                    key={`integration-${index}`}\n+                    icon_url={`/integrations/${provider}.png`}\n+                    name={provider}\n+                    onClick={() => {\n+                      setDefaultState(\"integrations\");\n+                      setIntegration(provider as CredentialsProviderName);\n+                    }}\n+                  />\n+                ))\n+              : Array(6)\n+                  .fill(0)\n+                  .map((_, index) => (\n+                    <IntegrationChip.Skeleton\n+                      key={`integration-skeleton-${index}`}\n+                    />\n+                  ))}\n+          </div>\n+        </div>\n+\n+        {/* Top blocks */}\n+        <div className=\"space-y-2.5 px-4\">\n+          <p className=\"font-sans text-sm font-medium leading-[1.375rem] text-zinc-800\">\n+            Top blocks\n+          </p>\n+          <div className=\"space-y-2\">\n+            {!loading && suggestionsData\n+              ? suggestionsData.top_blocks.map((block, index) => (\n+                  <Block\n+                    key={`block-${index}`}\n+                    title={block.name}\n+                    description={block.description}\n+                    onClick={() => {\n+                      addNode(block);\n+                    }}\n+                  />\n+                ))\n+              : Array(3)\n+                  .fill(0)\n+                  .map((_, index) => (\n+                    <Block.Skeleton key={`block-skeleton-${index}`} />\n+                  ))}\n+          </div>\n+        </div>\n+      </div>\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/helpers.ts b/autogpt_platform/frontend/src/components/builder/block-menu/helpers.ts\nnew file mode 100644\nindex 000000000000..eeb2e1f87f9c\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/helpers.ts\n@@ -0,0 +1,12 @@\n+import { Filters } from \"./block-menu-provider\";\n+\n+export const getDefaultFilters = (): Filters => ({\n+  categories: {\n+    blocks: false,\n+    integrations: false,\n+    marketplace_agents: false,\n+    my_agents: false,\n+    providers: false,\n+  },\n+  createdBy: [],\n+});\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/AiBlock.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/AiBlock.tsx\nnew file mode 100644\nindex 000000000000..8b43f2830665\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/AiBlock.tsx\n@@ -0,0 +1,63 @@\n+import { Button } from \"@/components/ui/button\";\n+import { cn } from \"@/lib/utils\";\n+import { Plus } from \"lucide-react\";\n+import { ButtonHTMLAttributes } from \"react\";\n+\n+interface Props extends ButtonHTMLAttributes<HTMLButtonElement> {\n+  title?: string;\n+  description?: string;\n+  ai_name?: string;\n+}\n+\n+export const AiBlock: React.FC<Props> = ({\n+  title,\n+  description,\n+  className,\n+  ai_name,\n+  ...rest\n+}) => {\n+  return (\n+    <Button\n+      className={cn(\n+        \"group flex h-[5.625rem] w-full min-w-[7.5rem] items-center justify-start space-x-3 whitespace-normal rounded-[0.75rem] bg-zinc-50 px-[0.875rem] py-[0.625rem] text-start shadow-none\",\n+        \"hover:bg-zinc-100 focus:ring-0 active:bg-zinc-100 active:ring-1 active:ring-zinc-300 disabled:pointer-events-none\",\n+        className,\n+      )}\n+      {...rest}\n+    >\n+      <div className=\"flex flex-1 flex-col items-start gap-1.5\">\n+        <div className=\"space-y-0.5\">\n+          <span\n+            className={cn(\n+              \"line-clamp-1 font-sans text-sm font-medium leading-[1.375rem] text-zinc-700 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            {title}\n+          </span>\n+          <span\n+            className={cn(\n+              \"line-clamp-1 font-sans text-xs font-normal leading-5 text-zinc-500 group-disabled:text-zinc-400\",\n+            )}\n+          >\n+            {description}\n+          </span>\n+        </div>\n+\n+        <span\n+          className={cn(\n+            \"rounded-[0.75rem] bg-zinc-200 px-[0.5rem] font-sans text-xs leading-[1.25rem] text-zinc-500\",\n+          )}\n+        >\n+          Supports {ai_name}\n+        </span>\n+      </div>\n+      <div\n+        className={cn(\n+          \"flex h-7 w-7 items-center justify-center rounded-[0.5rem] bg-zinc-700 group-disabled:bg-zinc-400\",\n+        )}\n+      >\n+        <Plus className=\"h-5 w-5 text-zinc-50\" strokeWidth={2} />\n+      </div>\n+    </Button>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/BlockMenuSearch.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/BlockMenuSearch.tsx\nnew file mode 100644\nindex 000000000000..21edbaf5f569\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/BlockMenuSearch.tsx\n@@ -0,0 +1,144 @@\n+import React, { useEffect, useState, useCallback, useRef } from \"react\";\n+import { FiltersList } from \"./FiltersList\";\n+import { SearchList } from \"./SearchList\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+import { useBackendAPI } from \"@/lib/autogpt-server-api/context\";\n+import { cn } from \"@/lib/utils\";\n+import { scrollbarStyles } from \"@/components/styles/scrollbar\";\n+\n+export const BlockMenuSearch = () => {\n+  const {\n+    searchData,\n+    searchQuery,\n+    searchId,\n+    setSearchData,\n+    filters,\n+    setCategoryCounts,\n+  } = useBlockMenuContext();\n+  const [isLoading, setIsLoading] = useState<boolean>(false);\n+  const [hasMore, setHasMore] = useState<boolean>(true);\n+  const [page, setPage] = useState<number>(1);\n+  const [loadingMore, setLoadingMore] = useState<boolean>(false);\n+  const [error, setError] = useState<string | null>(null);\n+  const scrollRef = useRef<HTMLDivElement>(null);\n+  const api = useBackendAPI();\n+\n+  const pageSize = 10;\n+\n+  const fetchSearchData = useCallback(\n+    async (pageNum: number, isLoadMore: boolean = false) => {\n+      if (isLoadMore) {\n+        setLoadingMore(true);\n+      } else {\n+        setIsLoading(true);\n+      }\n+\n+      try {\n+        const activeCategories = Object.entries(filters.categories)\n+          .filter(([_, isActive]) => isActive)\n+          .map(([category, _]) => category)\n+          .map(\n+            (category) =>\n+              category as\n+                | \"blocks\"\n+                | \"integrations\"\n+                | \"marketplace_agents\"\n+                | \"my_agents\",\n+          );\n+\n+        const response = await api.searchBlocks({\n+          search_query: searchQuery,\n+          search_id: searchId,\n+          page: pageNum,\n+          page_size: pageSize,\n+          filter: activeCategories.length > 0 ? activeCategories : undefined,\n+          by_creator:\n+            filters.createdBy.length > 0 ? filters.createdBy : undefined,\n+        });\n+\n+        setCategoryCounts(response.total_items);\n+\n+        if (isLoadMore) {\n+          setSearchData((prev) => [...prev, ...response.items]);\n+        } else {\n+          setSearchData(response.items);\n+        }\n+\n+        setHasMore(response.more_pages);\n+        setError(null);\n+      } catch (error) {\n+        console.error(\"Error fetching search data:\", error);\n+        setError(\n+          error instanceof Error\n+            ? error.message\n+            : \"Failed to load search results\",\n+        );\n+        if (!isLoadMore) {\n+          setPage(1);\n+        }\n+      } finally {\n+        setIsLoading(false);\n+        setLoadingMore(false);\n+      }\n+    },\n+    [\n+      searchQuery,\n+      searchId,\n+      filters,\n+      api,\n+      setCategoryCounts,\n+      setSearchData,\n+      pageSize,\n+    ],\n+  );\n+\n+  const handleScroll = useCallback(() => {\n+    if (!scrollRef.current || loadingMore || !hasMore) return;\n+\n+    const { scrollTop, scrollHeight, clientHeight } = scrollRef.current;\n+    if (scrollTop + clientHeight >= scrollHeight - 100) {\n+      const nextPage = page + 1;\n+      setPage(nextPage);\n+      fetchSearchData(nextPage, true);\n+    }\n+  }, [loadingMore, hasMore, page, fetchSearchData]);\n+\n+  useEffect(() => {\n+    const scrollElement = scrollRef.current;\n+    if (scrollElement) {\n+      scrollElement.addEventListener(\"scroll\", handleScroll);\n+      return () => scrollElement.removeEventListener(\"scroll\", handleScroll);\n+    }\n+  }, [handleScroll]);\n+\n+  useEffect(() => {\n+    if (searchQuery) {\n+      setPage(1);\n+      setHasMore(true);\n+      setError(null);\n+      fetchSearchData(1, false);\n+    } else {\n+      setSearchData([]);\n+      setError(null);\n+      setPage(1);\n+      setHasMore(true);\n+    }\n+  }, [searchQuery, searchId, filters, fetchSearchData, setSearchData]);\n+\n+  return (\n+    <div ref={scrollRef} className={cn(scrollbarStyles, \"space-y-4 py-4\")}>\n+      {searchData.length !== 0 && <FiltersList />}\n+      <SearchList\n+        isLoading={isLoading}\n+        loadingMore={loadingMore}\n+        hasMore={hasMore}\n+        error={error}\n+        onRetry={() => {\n+          setPage(1);\n+          setError(null);\n+          fetchSearchData(1, false);\n+        }}\n+      />\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/FilterSheet.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/FilterSheet.tsx\nnew file mode 100644\nindex 000000000000..9a1ba5d4ca15\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/FilterSheet.tsx\n@@ -0,0 +1,255 @@\n+import { FilterChip } from \"../FilterChip\";\n+import { useState, useEffect } from \"react\";\n+import { Button } from \"@/components/ui/button\";\n+import { X } from \"lucide-react\";\n+import { cn, getBlockType } from \"@/lib/utils\";\n+import { Separator } from \"@/components/ui/separator\";\n+import { Checkbox } from \"@/components/ui/checkbox\";\n+import {\n+  CategoryKey,\n+  Filters,\n+  useBlockMenuContext,\n+} from \"../block-menu-provider\";\n+import { StoreAgent } from \"@/lib/autogpt-server-api\";\n+import { getDefaultFilters } from \"../helpers\";\n+import { scrollbarStyles } from \"@/components/styles/scrollbar\";\n+\n+const INITIAL_CREATORS_TO_SHOW = 5;\n+\n+export function FilterSheet({\n+  categories,\n+}: {\n+  categories: Array<{ key: CategoryKey; name: string }>;\n+}) {\n+  const { filters, setFilters, searchData } = useBlockMenuContext();\n+  const [isOpen, setIsOpen] = useState(false);\n+  const [isSheetVisible, setIsSheetVisible] = useState(false);\n+  const [localFilters, setLocalFilters] = useState<Filters>(filters);\n+\n+  const [creators, setCreators] = useState<string[]>([]);\n+  const [displayedCreatorsCount, setDisplayedCreatorsCount] = useState(\n+    INITIAL_CREATORS_TO_SHOW,\n+  );\n+\n+  useEffect(() => {\n+    if (isOpen) {\n+      setIsSheetVisible(true);\n+      setLocalFilters(filters);\n+      setDisplayedCreatorsCount(INITIAL_CREATORS_TO_SHOW); // Reset on open\n+\n+      const marketplaceAgents = (searchData?.filter(\n+        (item) => getBlockType(item) === \"store_agent\",\n+      ) || []) as StoreAgent[];\n+\n+      const uniqueCreators = Array.from(\n+        new Set(marketplaceAgents.map((agent) => agent.creator)),\n+      );\n+\n+      setCreators(uniqueCreators);\n+    } else {\n+      const timer = setTimeout(() => {\n+        setIsSheetVisible(false);\n+      }, 300);\n+      return () => clearTimeout(timer);\n+    }\n+  }, [isOpen, filters, searchData]);\n+\n+  const onCategoryChange = (category: CategoryKey) => {\n+    setLocalFilters((prev) => ({\n+      ...prev,\n+      categories: {\n+        ...prev.categories,\n+        [category]: !prev.categories[category],\n+      },\n+    }));\n+  };\n+\n+  const onCreatorChange = (creator: string) => {\n+    setLocalFilters((prev) => {\n+      const updatedCreators = prev.createdBy.includes(creator)\n+        ? prev.createdBy.filter((c) => c !== creator)\n+        : [...prev.createdBy, creator];\n+\n+      return {\n+        ...prev,\n+        createdBy: updatedCreators,\n+      };\n+    });\n+  };\n+\n+  const handleApplyFilters = () => {\n+    setFilters(localFilters);\n+    setIsOpen(false);\n+  };\n+\n+  const handleClearFilters = () => {\n+    const clearedFilters: Filters = getDefaultFilters();\n+    setFilters(clearedFilters);\n+    setIsOpen(false);\n+  };\n+\n+  const hasLocalActiveFilters = () => {\n+    const hasCategoryFilter = Object.values(localFilters.categories).some(\n+      (value) => value,\n+    );\n+    const hasCreatorFilter = localFilters.createdBy.length > 0;\n+\n+    return hasCategoryFilter || hasCreatorFilter;\n+  };\n+\n+  const hasActiveFilters = () => {\n+    const hasCategoryFilter = Object.values(filters.categories).some(\n+      (value) => value,\n+    );\n+    const hasCreatorFilter = filters.createdBy.length > 0;\n+\n+    return hasCategoryFilter || hasCreatorFilter;\n+  };\n+\n+  const handleToggleShowMoreCreators = () => {\n+    if (displayedCreatorsCount < creators.length) {\n+      setDisplayedCreatorsCount(creators.length);\n+    } else {\n+      setDisplayedCreatorsCount(INITIAL_CREATORS_TO_SHOW);\n+    }\n+  };\n+\n+  const visibleCreators = creators.slice(0, displayedCreatorsCount);\n+\n+  return (\n+    <div className=\"m-0 ml-4 inline w-fit p-0\">\n+      <Button\n+        onClick={() => {\n+          setIsSheetVisible(true);\n+          requestAnimationFrame(() => {\n+            requestAnimationFrame(() => {\n+              setIsOpen(true);\n+            });\n+          });\n+        }}\n+        variant={\"link\"}\n+        className=\"m-0 p-0 hover:no-underline\"\n+      >\n+        <FilterChip\n+          name={hasActiveFilters() ? \"Edit filters\" : \"All filters\"}\n+        />\n+      </Button>\n+\n+      {isSheetVisible && (\n+        <>\n+          <div\n+            className={cn(\n+              \"absolute bottom-2 left-2 top-2 z-20 w-3/4 max-w-[22.5rem] space-y-4 overflow-hidden rounded-[0.75rem] bg-white pb-4 shadow-[0_4px_12px_2px_rgba(0,0,0,0.1)] transition-all\",\n+              isOpen\n+                ? \"translate-x-0 duration-300 ease-out\"\n+                : \"-translate-x-full duration-300 ease-out\",\n+            )}\n+          >\n+            <div className={cn(\"flex-1 space-y-4 pb-16\", scrollbarStyles)}>\n+              {/* Top */}\n+              <div className=\"flex items-center justify-between px-5\">\n+                <p className=\"font-sans text-base text-[#040404]\">Filters</p>\n+                <Button\n+                  variant=\"ghost\"\n+                  size=\"icon\"\n+                  onClick={() => setIsOpen(false)}\n+                >\n+                  <X className=\"h-5 w-5\" />\n+                </Button>\n+              </div>\n+\n+              <Separator className=\"h-[1px] w-full text-zinc-300\" />\n+\n+              {/* Categories */}\n+\n+              <div className=\"space-y-4 px-5\">\n+                <p className=\"font-sans text-base font-medium text-zinc-800\">\n+                  Categories\n+                </p>\n+                <div className=\"space-y-2\">\n+                  {categories.map((category) => (\n+                    <div\n+                      key={category.key}\n+                      className=\"flex items-center space-x-2\"\n+                    >\n+                      <Checkbox\n+                        id={category.key}\n+                        checked={localFilters.categories[category.key]}\n+                        onCheckedChange={() => onCategoryChange(category.key)}\n+                        className=\"border border-[#D4D4D4] shadow-none data-[state=checked]:border-none data-[state=checked]:bg-violet-700 data-[state=checked]:text-white\"\n+                      />\n+                      <label\n+                        htmlFor={category.key}\n+                        className=\"font-sans text-sm leading-[1.375rem] text-zinc-600\"\n+                      >\n+                        {category.name}\n+                      </label>\n+                    </div>\n+                  ))}\n+                </div>\n+              </div>\n+\n+              <Separator className=\"h-[1px] w-full text-zinc-300\" />\n+\n+              {/* Created By */}\n+\n+              <div className=\"space-y-4 px-5\">\n+                <p className=\"font-sans text-base font-medium text-zinc-800\">\n+                  Created by\n+                </p>\n+                <div className=\"space-y-2\">\n+                  {visibleCreators.map((creator) => (\n+                    <div key={creator} className=\"flex items-center space-x-2\">\n+                      <Checkbox\n+                        id={`creator-${creator}`}\n+                        checked={localFilters.createdBy.includes(creator)}\n+                        onCheckedChange={() => onCreatorChange(creator)}\n+                        className=\"border border-[#D4D4D4] shadow-none data-[state=checked]:border-none data-[state=checked]:bg-violet-700 data-[state=checked]:text-white\"\n+                      />\n+                      <label\n+                        htmlFor={`creator-${creator}`}\n+                        className=\"font-sans text-sm leading-[1.375rem] text-zinc-600\"\n+                      >\n+                        {creator}\n+                      </label>\n+                    </div>\n+                  ))}\n+                </div>\n+                {creators.length > INITIAL_CREATORS_TO_SHOW && (\n+                  <Button\n+                    variant={\"link\"}\n+                    className=\"m-0 p-0 font-sans text-sm font-medium leading-[1.375rem] text-zinc-800 underline hover:text-zinc-600\"\n+                    onClick={handleToggleShowMoreCreators}\n+                  >\n+                    {displayedCreatorsCount < creators.length ? \"More\" : \"Less\"}\n+                  </Button>\n+                )}\n+              </div>\n+            </div>\n+\n+            {/* Footer buttons */}\n+            <div className=\"fixed bottom-0 flex w-full justify-between gap-3 border-t border-zinc-300 bg-white px-5 py-3\">\n+              <Button\n+                className=\"min-w-[5rem] rounded-[0.5rem] border-none px-1.5 py-2 font-sans text-sm font-medium leading-[1.375rem] text-zinc-800 shadow-none ring-1 ring-zinc-400\"\n+                variant={\"outline\"}\n+                onClick={handleClearFilters}\n+              >\n+                Clear\n+              </Button>\n+\n+              <Button\n+                className={cn(\n+                  \"min-w-[6.25rem] rounded-[0.5rem] border-none px-1.5 py-2 font-sans text-sm font-medium leading-[1.375rem] text-white shadow-none ring-1 disabled:ring-0\",\n+                )}\n+                onClick={handleApplyFilters}\n+                disabled={!hasLocalActiveFilters()}\n+              >\n+                Apply filters\n+              </Button>\n+            </div>\n+          </div>\n+        </>\n+      )}\n+    </div>\n+  );\n+}\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/FiltersList.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/FiltersList.tsx\nnew file mode 100644\nindex 000000000000..da034fcc9f52\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/FiltersList.tsx\n@@ -0,0 +1,63 @@\n+import { useCallback } from \"react\";\n+import { FilterChip } from \"../FilterChip\";\n+import { FilterSheet } from \"./FilterSheet\";\n+import { CategoryKey, useBlockMenuContext } from \"../block-menu-provider\";\n+\n+export const FiltersList = () => {\n+  const { filters, setFilters, categoryCounts } = useBlockMenuContext();\n+  const categories: Array<{ key: CategoryKey; name: string }> = [\n+    { key: \"blocks\", name: \"Blocks\" },\n+    { key: \"integrations\", name: \"Integrations\" },\n+    { key: \"marketplace_agents\", name: \"Marketplace agents\" },\n+    { key: \"my_agents\", name: \"My agents\" },\n+  ];\n+\n+  const handleCategoryFilter = (category: CategoryKey) => {\n+    setFilters({\n+      ...filters,\n+      categories: {\n+        ...filters.categories,\n+        [category]: !filters.categories[category],\n+      },\n+    });\n+  };\n+\n+  const handleCreatorFilter = useCallback(\n+    (creator: string) => {\n+      const updatedCreators = filters.createdBy.includes(creator)\n+        ? filters.createdBy.filter((c) => c !== creator)\n+        : [...filters.createdBy, creator];\n+\n+      setFilters({\n+        ...filters,\n+        createdBy: updatedCreators,\n+      });\n+    },\n+    [filters, setFilters],\n+  );\n+\n+  return (\n+    <div className=\"flex flex-nowrap gap-3 overflow-x-auto scrollbar-hide\">\n+      <FilterSheet categories={categories} />\n+\n+      {filters.createdBy.map((creator) => (\n+        <FilterChip\n+          key={creator}\n+          name={\"Created by \" + creator}\n+          selected={true}\n+          onClick={() => handleCreatorFilter(creator)}\n+        />\n+      ))}\n+\n+      {categories.map((category) => (\n+        <FilterChip\n+          key={category.key}\n+          name={category.name}\n+          number={categoryCounts[category.key]}\n+          selected={filters.categories[category.key]}\n+          onClick={() => handleCategoryFilter(category.key)}\n+        />\n+      ))}\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/NoSearchResult.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/NoSearchResult.tsx\nnew file mode 100644\nindex 000000000000..726e3804a1a1\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/NoSearchResult.tsx\n@@ -0,0 +1,17 @@\n+import { Frown } from \"lucide-react\";\n+\n+export const NoSearchResult = () => {\n+  return (\n+    <div className=\"flex h-full w-full flex-col items-center justify-center text-center\">\n+      <Frown className=\"mb-10 h-16 w-16 text-zinc-400\" strokeWidth={1} />\n+      <div className=\"space-y-1\">\n+        <p className=\"font-sans text-sm font-medium leading-[1.375rem] text-zinc-800\">\n+          No match found\n+        </p>\n+        <p className=\"font-sans text-sm font-normal leading-[1.375rem] text-zinc-600\">\n+          Try adjusting your search terms\n+        </p>\n+      </div>\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/SearchList.tsx b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/SearchList.tsx\nnew file mode 100644\nindex 000000000000..aaad3153b454\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/builder/block-menu/search-and-filter/SearchList.tsx\n@@ -0,0 +1,171 @@\n+import React from \"react\";\n+import { MarketplaceAgentBlock } from \"../MarketplaceAgentBlock\";\n+import { Block } from \"../Block\";\n+import { UGCAgentBlock } from \"../UGCAgentBlock\";\n+import { AiBlock } from \"./AiBlock\";\n+import { IntegrationBlock } from \"../IntegrationBlock\";\n+import { useBlockMenuContext } from \"../block-menu-provider\";\n+import { NoSearchResult } from \"./NoSearchResult\";\n+import { Button } from \"@/components/ui/button\";\n+import { convertLibraryAgentIntoBlock, getBlockType } from \"@/lib/utils\";\n+\n+interface SearchListProps {\n+  isLoading: boolean;\n+  loadingMore: boolean;\n+  hasMore: boolean;\n+  error: string | null;\n+  onRetry: () => void;\n+}\n+\n+export const SearchList: React.FC<SearchListProps> = ({\n+  isLoading,\n+  loadingMore,\n+  hasMore,\n+  error,\n+  onRetry,\n+}) => {\n+  const { searchQuery, addNode, loadingSlug, searchData, handleAddStoreAgent } =\n+    useBlockMenuContext();\n+\n+  if (isLoading) {\n+    return (\n+      <div className=\"space-y-2.5 px-4\">\n+        <p className=\"font-sans text-sm font-medium leading-[1.375rem] text-zinc-800\">\n+          Search results\n+        </p>\n+        {Array(6)\n+          .fill(0)\n+          .map((_, i) => (\n+            <Block.Skeleton key={i} />\n+          ))}\n+      </div>\n+    );\n+  }\n+\n+  if (error) {\n+    return (\n+      <div className=\"px-4\">\n+        <div className=\"rounded-lg border border-red-200 bg-red-50 p-3\">\n+          <p className=\"mb-2 text-sm text-red-600\">\n+            Error loading search results: {error}\n+          </p>\n+          <Button\n+            variant=\"outline\"\n+            size=\"sm\"\n+            onClick={onRetry}\n+            className=\"h-7 text-xs\"\n+          >\n+            Retry\n+          </Button>\n+        </div>\n+      </div>\n+    );\n+  }\n+\n+  if (searchData.length === 0) {\n+    return <NoSearchResult />;\n+  }\n+\n+  return (\n+    <div className=\"space-y-2.5 px-4\">\n+      <p className=\"font-sans text-sm font-medium leading-[1.375rem] text-zinc-800\">\n+        Search results\n+      </p>\n+      {searchData.map((item: any, index: number) => {\n+        const blockType = getBlockType(item);\n+\n+        switch (blockType) {\n+          case \"store_agent\":\n+            return (\n+              <MarketplaceAgentBlock\n+                key={index}\n+                slug={item.slug}\n+                highlightedText={searchQuery}\n+                title={item.agent_name}\n+                image_url={item.agent_image}\n+                creator_name={item.creator}\n+                number_of_runs={item.runs}\n+                loading={loadingSlug == item.slug}\n+                onClick={() =>\n+                  handleAddStoreAgent({\n+                    creator_name: item.creator,\n+                    slug: item.slug,\n+                  })\n+                }\n+              />\n+            );\n+          case \"block\":\n+            return (\n+              <Block\n+                key={index}\n+                title={item.name}\n+                highlightedText={searchQuery}\n+                description={item.description}\n+                onClick={() => {\n+                  addNode(item);\n+                }}\n+              />\n+            );\n+          case \"provider\":\n+            return (\n+              <IntegrationBlock\n+                key={index}\n+                title={item.name}\n+                highlightedText={searchQuery}\n+                icon_url={`/integrations/${item.name}.png`}\n+                description={item.description}\n+                onClick={() => {\n+                  addNode(item);\n+                }}\n+              />\n+            );\n+          case \"library_agent\":\n+            return (\n+              <UGCAgentBlock\n+                key={index}\n+                title={item.name}\n+                highlightedText={searchQuery}\n+                image_url={item.image_url}\n+                version={item.graph_version}\n+                edited_time={item.updated_at}\n+                onClick={() => {\n+                  const block = convertLibraryAgentIntoBlock(item);\n+                  addNode(block);\n+                }}\n+              />\n+            );\n+          case \"ai_agent\":\n+            return (\n+              <AiBlock\n+                key={index}\n+                title={item.name}\n+                description={item.description}\n+                ai_name={item.inputSchema.properties.model.enum.find(\n+                  (model: string) =>\n+                    model\n+                      .toLowerCase()\n+                      .includes(searchQuery.toLowerCase().trim()),\n+                )}\n+                onClick={() => {\n+                  const block = convertLibraryAgentIntoBlock(item);\n+                  addNode(block);\n+                }}\n+              />\n+            );\n+\n+          default:\n+            return null;\n+        }\n+      })}\n+      {loadingMore && hasMore && (\n+        <div className=\"space-y-2.5\">\n+          {Array(3)\n+            .fill(0)\n+            .map((_, i) => (\n+              <Block.Skeleton key={`loading-more-${i}`} />\n+            ))}\n+        </div>\n+      )}\n+    </div>\n+  );\n+};\ndiff --git a/autogpt_platform/frontend/src/components/edit/control/ControlPanel.tsx b/autogpt_platform/frontend/src/components/edit/control/ControlPanel.tsx\nindex 870d34582283..6df5d191f95c 100644\n--- a/autogpt_platform/frontend/src/components/edit/control/ControlPanel.tsx\n+++ b/autogpt_platform/frontend/src/components/edit/control/ControlPanel.tsx\n@@ -1,13 +1,7 @@\n-import { Card, CardContent } from \"@/components/ui/card\";\n-import {\n-  Tooltip,\n-  TooltipContent,\n-  TooltipTrigger,\n-} from \"@/components/ui/tooltip\";\n-import { Button } from \"@/components/ui/button\";\n import { Separator } from \"@/components/ui/separator\";\n import { cn } from \"@/lib/utils\";\n import React from \"react\";\n+import { ControlPanelButton } from \"@/components/builder/block-menu/ControlPanelButton\";\n \n /**\n  * Represents a control element for the ControlPanel Component.\n@@ -27,6 +21,7 @@ interface ControlPanelProps {\n   controls: Control[];\n   topChildren?: React.ReactNode;\n   botChildren?: React.ReactNode;\n+\n   className?: string;\n }\n \n@@ -45,42 +40,31 @@ export const ControlPanel = ({\n   className,\n }: ControlPanelProps) => {\n   return (\n-    <Card className={cn(\"m-4 mt-24 w-14 dark:bg-slate-900\", className)}>\n-      <CardContent className=\"p-0\">\n-        <div className=\"flex flex-col items-center gap-3 rounded-xl py-3\">\n-          {topChildren}\n-          <Separator className=\"dark:bg-slate-700\" />\n-          {controls.map((control, index) => (\n-            <Tooltip key={index} delayDuration={500}>\n-              <TooltipTrigger asChild>\n-                <div>\n-                  <Button\n-                    variant=\"ghost\"\n-                    size=\"icon\"\n-                    onClick={() => control.onClick()}\n-                    data-id={`control-button-${index}`}\n-                    data-testid={`blocks-control-${control.label.toLowerCase()}-button`}\n-                    disabled={control.disabled || false}\n-                    className=\"dark:bg-slate-900 dark:text-slate-100 dark:hover:bg-slate-800\"\n-                  >\n-                    {control.icon}\n-                    <span className=\"sr-only\">{control.label}</span>\n-                  </Button>\n-                </div>\n-              </TooltipTrigger>\n-              <TooltipContent\n-                side=\"right\"\n-                className=\"dark:bg-slate-800 dark:text-slate-100\"\n-              >\n-                {control.label}\n-              </TooltipContent>\n-            </Tooltip>\n-          ))}\n-          <Separator className=\"dark:bg-slate-700\" />\n-          {botChildren}\n-        </div>\n-      </CardContent>\n-    </Card>\n+    <section\n+      className={cn(\n+        \"absolute left-4 top-24 z-10 w-[4.25rem] overflow-hidden rounded-[1rem] border-none bg-white p-0 shadow-[0_1px_5px_0_rgba(0,0,0,0.1)]\",\n+        className,\n+      )}\n+    >\n+      <div className=\"flex flex-col items-center justify-center rounded-[1rem] p-0\">\n+        {topChildren}\n+        <Separator className=\"text-[#E1E1E1]\" />\n+        {controls.map((control, index) => (\n+          <ControlPanelButton\n+            key={index}\n+            onClick={() => control.onClick()}\n+            data-id={`control-button-${index}`}\n+            data-testid={`blocks-control-${control.label.toLowerCase()}-button`}\n+            disabled={control.disabled || false}\n+            className=\"rounded-none\"\n+          >\n+            {control.icon}\n+          </ControlPanelButton>\n+        ))}\n+        <Separator className=\"text-[#E1E1E1]\" />\n+        {botChildren}\n+      </div>\n+    </section>\n   );\n };\n export default ControlPanel;\ndiff --git a/autogpt_platform/frontend/src/components/edit/control/SaveControl.tsx b/autogpt_platform/frontend/src/components/edit/control/SaveControl.tsx\nindex bfa0408dbad4..aeb4fc2cbef6 100644\n--- a/autogpt_platform/frontend/src/components/edit/control/SaveControl.tsx\n+++ b/autogpt_platform/frontend/src/components/edit/control/SaveControl.tsx\n@@ -10,12 +10,8 @@ import { Button } from \"@/components/ui/button\";\n import { GraphMeta } from \"@/lib/autogpt-server-api\";\n import { Label } from \"@/components/ui/label\";\n import { IconSave } from \"@/components/ui/icons\";\n-import {\n-  Tooltip,\n-  TooltipContent,\n-  TooltipTrigger,\n-} from \"@/components/ui/tooltip\";\n import { useToast } from \"@/components/ui/use-toast\";\n+import { ControlPanelButton } from \"@/components/builder/block-menu/ControlPanelButton\";\n \n interface SaveControlProps {\n   agentMeta: GraphMeta | null;\n@@ -26,6 +22,11 @@ interface SaveControlProps {\n   onNameChange: (name: string) => void;\n   onDescriptionChange: (description: string) => void;\n   pinSavePopover: boolean;\n+\n+  blockMenuSelected: \"save\" | \"block\" | \"\";\n+  setBlockMenuSelected: React.Dispatch<\n+    React.SetStateAction<\"\" | \"save\" | \"block\">\n+  >;\n }\n \n /**\n@@ -48,6 +49,8 @@ export const SaveControl = ({\n   onNameChange,\n   agentDescription,\n   onDescriptionChange,\n+  blockMenuSelected,\n+  setBlockMenuSelected,\n   pinSavePopover,\n }: SaveControlProps) => {\n   /**\n@@ -82,27 +85,29 @@ export const SaveControl = ({\n   }, [handleSave, toast]);\n \n   return (\n-    <Popover open={pinSavePopover ? true : undefined}>\n-      <Tooltip delayDuration={500}>\n-        <TooltipTrigger asChild>\n-          <PopoverTrigger asChild>\n-            <Button\n-              variant=\"ghost\"\n-              size=\"icon\"\n-              data-id=\"save-control-popover-trigger\"\n-              data-testid=\"blocks-control-save-button\"\n-              name=\"Save\"\n-            >\n-              <IconSave className=\"dark:text-gray-300\" />\n-            </Button>\n-          </PopoverTrigger>\n-        </TooltipTrigger>\n-        <TooltipContent side=\"right\">Save</TooltipContent>\n-      </Tooltip>\n+    <Popover\n+      open={pinSavePopover ? true : undefined}\n+      onOpenChange={(open) => open || setBlockMenuSelected(\"\")}\n+    >\n+      <PopoverTrigger>\n+        <ControlPanelButton\n+          data-id=\"save-control-popover-trigger\"\n+          data-testid=\"blocks-control-save-button\"\n+          selected={blockMenuSelected === \"save\"}\n+          onClick={() => {\n+            setBlockMenuSelected(\"save\");\n+          }}\n+          className=\"rounded-none\"\n+        >\n+          <IconSave className=\"h-5 w-5\" strokeWidth={2} />\n+        </ControlPanelButton>\n+      </PopoverTrigger>\n+\n       <PopoverContent\n         side=\"right\"\n-        sideOffset={15}\n+        sideOffset={16}\n         align=\"start\"\n+        className=\"w-[17rem] rounded-xl border-none p-0 shadow-none md:w-[30rem]\"\n         data-id=\"save-control-popover-content\"\n       >\n         <Card className=\"border-none shadow-none dark:bg-slate-900\">\ndiff --git a/autogpt_platform/frontend/src/components/styles/scrollbar.ts b/autogpt_platform/frontend/src/components/styles/scrollbar.ts\nnew file mode 100644\nindex 000000000000..78a14ec7fb66\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/components/styles/scrollbar.ts\n@@ -0,0 +1,2 @@\n+export const scrollbarStyles =\n+  \"scrollbar-thumb-rounded h-full overflow-y-auto pt-4 transition-all duration-200 scrollbar-thin scrollbar-track-transparent scrollbar-thumb-transparent hover:scrollbar-thumb-zinc-200\";\ndiff --git a/autogpt_platform/frontend/src/components/ui/checkbox.tsx b/autogpt_platform/frontend/src/components/ui/checkbox.tsx\nindex 81d0befff4e2..5438d5946530 100644\n--- a/autogpt_platform/frontend/src/components/ui/checkbox.tsx\n+++ b/autogpt_platform/frontend/src/components/ui/checkbox.tsx\n@@ -13,7 +13,7 @@ const Checkbox = React.forwardRef<\n   <CheckboxPrimitive.Root\n     ref={ref}\n     className={cn(\n-      \"peer h-4 w-4 shrink-0 rounded-sm border border-neutral-200 border-neutral-900 shadow focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-neutral-950 disabled:cursor-not-allowed disabled:opacity-50 data-[state=checked]:bg-neutral-900 data-[state=checked]:text-neutral-50 dark:border-neutral-50 dark:border-neutral-800 dark:focus-visible:ring-neutral-300 dark:data-[state=checked]:bg-neutral-50 dark:data-[state=checked]:text-neutral-900\",\n+      \"peer h-4 w-4 shrink-0 rounded-sm border border-neutral-900 shadow focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-neutral-950 disabled:cursor-not-allowed disabled:opacity-50 data-[state=checked]:bg-neutral-900 data-[state=checked]:text-neutral-50 dark:border-neutral-50 dark:border-neutral-800 dark:focus-visible:ring-neutral-300 dark:data-[state=checked]:bg-neutral-50 dark:data-[state=checked]:text-neutral-900\",\n       className,\n     )}\n     {...props}\n@@ -21,7 +21,7 @@ const Checkbox = React.forwardRef<\n     <CheckboxPrimitive.Indicator\n       className={cn(\"flex items-center justify-center text-current\")}\n     >\n-      <CheckIcon className=\"h-4 w-4\" />\n+      <CheckIcon className=\"h-4 w-4\" strokeWidth={2} />\n     </CheckboxPrimitive.Indicator>\n   </CheckboxPrimitive.Root>\n ));\ndiff --git a/autogpt_platform/frontend/src/components/ui/multiselect.tsx b/autogpt_platform/frontend/src/components/ui/multiselect.tsx\nindex 876444262194..6c3243015a61 100644\n--- a/autogpt_platform/frontend/src/components/ui/multiselect.tsx\n+++ b/autogpt_platform/frontend/src/components/ui/multiselect.tsx\n@@ -256,7 +256,7 @@ const MultiSelectorList = forwardRef<\n     <CommandList\n       ref={ref}\n       className={cn(\n-        \"scrollbar-thin scrollbar-track-transparent scrollbar-thumb-muted-foreground dark:scrollbar-thumb-muted scrollbar-thumb-rounded-lg absolute top-0 z-10 flex w-full flex-col gap-2 rounded-md border border-muted bg-background p-2 shadow-md transition-colors\",\n+        \"scrollbar-thumb-rounded-lg absolute top-0 z-10 flex w-full flex-col gap-2 rounded-md border border-muted bg-background p-2 shadow-md transition-colors scrollbar-thin scrollbar-track-transparent scrollbar-thumb-muted-foreground dark:scrollbar-thumb-muted\",\n         className,\n       )}\n     >\ndiff --git a/autogpt_platform/frontend/src/hooks/index.ts b/autogpt_platform/frontend/src/hooks/index.ts\nnew file mode 100644\nindex 000000000000..40d59d0e50ce\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/hooks/index.ts\n@@ -0,0 +1 @@\n+export { usePagination } from \"./usePagination\";\ndiff --git a/autogpt_platform/frontend/src/hooks/useAgentGraph.tsx b/autogpt_platform/frontend/src/hooks/useAgentGraph.tsx\nindex 55b7c4d2bdcf..4c3d11153bba 100644\n--- a/autogpt_platform/frontend/src/hooks/useAgentGraph.tsx\n+++ b/autogpt_platform/frontend/src/hooks/useAgentGraph.tsx\n@@ -14,6 +14,7 @@ import BackendAPI, {\n   GraphMeta,\n   NodeExecutionResult,\n   SpecialBlockID,\n+  Node,\n } from \"@/lib/autogpt-server-api\";\n import {\n   deepEquals,\n@@ -177,6 +178,16 @@ export default function useAgentGraph(\n       setAgentName(graph.name);\n       setAgentDescription(graph.description);\n \n+      const getGraphName = (node: Node) => {\n+        if (node.input_default.agent_name) {\n+          return node.input_default.agent_name;\n+        }\n+        return (\n+          availableFlows.find((flow) => flow.id === node.input_default.graph_id)\n+            ?.name || null\n+        );\n+      };\n+\n       setNodes((prevNodes) => {\n         const _newNodes = graph.nodes.map((node) => {\n           const block = availableNodes.find(\n@@ -184,12 +195,8 @@ export default function useAgentGraph(\n           )!;\n           if (!block) return null;\n           const prevNode = prevNodes.find((n) => n.id === node.id);\n-          const flow =\n-            block.uiType == BlockUIType.AGENT\n-              ? availableFlows.find(\n-                  (flow) => flow.id === node.input_default.graph_id,\n-                )\n-              : null;\n+          const graphName =\n+            (block.uiType == BlockUIType.AGENT && getGraphName(node)) || null;\n           const newNode: CustomNode = {\n             id: node.id,\n             type: \"custom\",\n@@ -201,7 +208,7 @@ export default function useAgentGraph(\n               isOutputOpen: false,\n               ...prevNode?.data,\n               block_id: block.id,\n-              blockType: flow?.name || block.name,\n+              blockType: graphName || block.name,\n               blockCosts: block.costs,\n               categories: block.categories,\n               description: block.description,\n@@ -281,15 +288,17 @@ export default function useAgentGraph(\n \n   const getToolFuncName = (nodeId: string) => {\n     const sinkNode = nodes.find((node) => node.id === nodeId);\n-    const sinkNodeName = sinkNode\n-      ? sinkNode.data.block_id === SpecialBlockID.AGENT\n-        ? sinkNode.data.hardcodedValues?.graph_id\n-          ? availableFlows.find(\n-              (flow) => flow.id === sinkNode.data.hardcodedValues.graph_id,\n-            )?.name || \"agentexecutorblock\"\n-          : \"agentexecutorblock\"\n-        : sinkNode.data.title.split(\" \")[0]\n-      : \"\";\n+\n+    if (!sinkNode) return \"\";\n+\n+    const sinkNodeName =\n+      sinkNode.data.block_id === SpecialBlockID.AGENT\n+        ? sinkNode.data.hardcodedValues?.agent_name ||\n+          availableFlows.find(\n+            (flow) => flow.id === sinkNode.data.hardcodedValues.graph_id,\n+          )?.name ||\n+          \"agentexecutorblock\"\n+        : sinkNode.data.title.split(\" \")[0];\n \n     return sinkNodeName;\n   };\n@@ -1120,7 +1129,6 @@ export default function useAgentGraph(\n     setAgentDescription,\n     savedAgent,\n     availableNodes,\n-    availableFlows,\n     getOutputType,\n     requestSave,\n     requestSaveAndRun,\ndiff --git a/autogpt_platform/frontend/src/hooks/usePagination.ts b/autogpt_platform/frontend/src/hooks/usePagination.ts\nnew file mode 100644\nindex 000000000000..bce8e9c96a3d\n--- /dev/null\n+++ b/autogpt_platform/frontend/src/hooks/usePagination.ts\n@@ -0,0 +1,232 @@\n+import { useState, useCallback, useRef, useEffect } from \"react\";\n+import { useBackendAPI } from \"@/lib/autogpt-server-api/context\";\n+import {\n+  Block,\n+  BlockRequest,\n+  Provider,\n+  StoreAgent,\n+  LibraryAgent,\n+  LibraryAgentSortEnum,\n+} from \"@/lib/autogpt-server-api\";\n+\n+type BlocksPaginationRequest = { apiType: \"blocks\" } & BlockRequest;\n+type ProvidersPaginationRequest = { apiType: \"providers\" } & {\n+  page?: number;\n+  page_size?: number;\n+};\n+type StoreAgentsPaginationRequest = { apiType: \"store-agents\" } & {\n+  featured?: boolean;\n+  creator?: string;\n+  sorted_by?: string;\n+  search_query?: string;\n+  category?: string;\n+  page?: number;\n+  page_size?: number;\n+};\n+type LibraryAgentsPaginationRequest = { apiType: \"library-agents\" } & {\n+  search_term?: string;\n+  sort_by?: LibraryAgentSortEnum;\n+  page?: number;\n+  page_size?: number;\n+};\n+\n+type PaginationRequest =\n+  | BlocksPaginationRequest\n+  | ProvidersPaginationRequest\n+  | StoreAgentsPaginationRequest\n+  | LibraryAgentsPaginationRequest;\n+\n+interface UsePaginationOptions<T extends PaginationRequest> {\n+  request: T;\n+  pageSize?: number;\n+  enabled?: boolean;\n+}\n+\n+interface UsePaginationReturn<T> {\n+  data: T[];\n+  loading: boolean;\n+  loadingMore: boolean;\n+  hasMore: boolean;\n+  error: string | null;\n+  scrollRef: React.RefObject<HTMLDivElement>;\n+  refresh: () => void;\n+  loadMore: () => void;\n+}\n+\n+type GetReturnType<T> = T extends BlocksPaginationRequest\n+  ? Block\n+  : T extends ProvidersPaginationRequest\n+    ? Provider\n+    : T extends StoreAgentsPaginationRequest\n+      ? StoreAgent\n+      : T extends LibraryAgentsPaginationRequest\n+        ? LibraryAgent\n+        : never;\n+\n+export const usePagination = <T extends PaginationRequest>({\n+  request,\n+  pageSize = 10,\n+  enabled = true, // to allow pagination or not\n+}: UsePaginationOptions<T>): UsePaginationReturn<GetReturnType<T>> => {\n+  const [data, setData] = useState<GetReturnType<T>[]>([]);\n+  const [loading, setLoading] = useState(true);\n+  const [loadingMore, setLoadingMore] = useState(false);\n+  const [hasMore, setHasMore] = useState(true);\n+  const [currentPage, setCurrentPage] = useState(1);\n+  const [error, setError] = useState<string | null>(null);\n+  const scrollRef = useRef<HTMLDivElement>(null);\n+  const isLoadingRef = useRef(false);\n+  const requestRef = useRef(request);\n+  const api = useBackendAPI();\n+\n+  // because we are using this pagination for multiple components\n+  requestRef.current = request;\n+\n+  const fetchData = useCallback(\n+    async (page: number, isLoadMore = false) => {\n+      if (isLoadingRef.current || !enabled) return;\n+\n+      isLoadingRef.current = true;\n+\n+      if (isLoadMore) {\n+        setLoadingMore(true);\n+      } else {\n+        setLoading(true);\n+      }\n+\n+      setError(null);\n+\n+      try {\n+        let response;\n+        let newData: GetReturnType<T>[];\n+        let pagination;\n+\n+        const currentRequest = requestRef.current;\n+        const requestWithPagination = {\n+          ...currentRequest,\n+          page,\n+          page_size: pageSize,\n+        };\n+\n+        switch (currentRequest.apiType) {\n+          case \"blocks\":\n+            const { apiType: _, ...blockRequest } = requestWithPagination;\n+            response = await api.getBuilderBlocks(blockRequest);\n+            newData = response.blocks as GetReturnType<T>[];\n+            pagination = response.pagination;\n+            break;\n+\n+          case \"providers\":\n+            const { apiType: __, ...providerRequest } = requestWithPagination;\n+            response = await api.getProviders(providerRequest);\n+            newData = response.providers as GetReturnType<T>[];\n+            pagination = response.pagination;\n+            break;\n+\n+          case \"store-agents\":\n+            const { apiType: ___, ...storeAgentRequest } =\n+              requestWithPagination;\n+            response = await api.getStoreAgents(storeAgentRequest);\n+            newData = response.agents as GetReturnType<T>[];\n+            pagination = response.pagination;\n+            break;\n+\n+          case \"library-agents\":\n+            const { apiType: ____, ...libraryAgentRequest } =\n+              requestWithPagination;\n+            response = await api.listLibraryAgents(libraryAgentRequest);\n+            newData = response.agents as GetReturnType<T>[];\n+            pagination = response.pagination;\n+            break;\n+\n+          default:\n+            throw new Error(\n+              `Unknown request type: ${(currentRequest as any).apiType}`,\n+            );\n+        }\n+\n+        if (isLoadMore) {\n+          setData((prev) => [...prev, ...newData]);\n+        } else {\n+          setData(newData);\n+        }\n+\n+        setHasMore(page < pagination.total_pages);\n+        setCurrentPage(page);\n+      } catch (err) {\n+        const errorMessage =\n+          err instanceof Error ? err.message : \"Failed to fetch data\";\n+        setError(errorMessage);\n+        console.error(\"Error fetching data:\", err);\n+      } finally {\n+        setLoading(false);\n+        setLoadingMore(false);\n+        isLoadingRef.current = false;\n+      }\n+    },\n+    [api, pageSize, enabled],\n+  );\n+\n+  const handleScroll = useCallback(() => {\n+    const scrollElement = scrollRef.current;\n+    if (\n+      !scrollElement ||\n+      loadingMore ||\n+      !hasMore ||\n+      isLoadingRef.current ||\n+      !enabled\n+    )\n+      return;\n+\n+    const { scrollTop, scrollHeight, clientHeight } = scrollElement;\n+    const threshold = 100;\n+\n+    if (scrollTop + clientHeight >= scrollHeight - threshold) {\n+      fetchData(currentPage + 1, true);\n+    }\n+  }, [fetchData, currentPage, loadingMore, hasMore, enabled]);\n+\n+  const refresh = useCallback(() => {\n+    setCurrentPage(1);\n+    setHasMore(true);\n+    setError(null);\n+    fetchData(1);\n+  }, [fetchData]);\n+\n+  const loadMore = useCallback(() => {\n+    if (!loadingMore && hasMore && !isLoadingRef.current && enabled) {\n+      fetchData(currentPage + 1, true);\n+    }\n+  }, [fetchData, currentPage, loadingMore, hasMore, enabled]);\n+\n+  const requestString = JSON.stringify(request);\n+\n+  useEffect(() => {\n+    if (enabled) {\n+      setCurrentPage(1);\n+      setHasMore(true);\n+      setError(null);\n+      setData([]);\n+      fetchData(1);\n+    }\n+  }, [requestString, enabled, fetchData]);\n+\n+  useEffect(() => {\n+    const scrollElement = scrollRef.current;\n+    if (scrollElement && enabled) {\n+      scrollElement.addEventListener(\"scroll\", handleScroll);\n+      return () => scrollElement.removeEventListener(\"scroll\", handleScroll);\n+    }\n+  }, [handleScroll, enabled]);\n+\n+  return {\n+    data,\n+    loading,\n+    loadingMore,\n+    hasMore,\n+    error,\n+    scrollRef,\n+    refresh,\n+    loadMore,\n+  };\n+};\ndiff --git a/autogpt_platform/frontend/src/lib/autogpt-server-api/client.ts b/autogpt_platform/frontend/src/lib/autogpt-server-api/client.ts\nindex f82ed8e302a8..a1b0e169a674 100644\n--- a/autogpt_platform/frontend/src/lib/autogpt-server-api/client.ts\n+++ b/autogpt_platform/frontend/src/lib/autogpt-server-api/client.ts\n@@ -9,6 +9,11 @@ import type {\n   APIKeyCredentials,\n   APIKeyPermission,\n   Block,\n+  BlockCategoryResponse,\n+  BlockRequest,\n+  BlockResponse,\n+  BlockSearchResponse,\n+  CountResponse,\n   CreateAPIKeyResponse,\n   CreatorDetails,\n   CreatorsResponse,\n@@ -42,6 +47,7 @@ import type {\n   OttoQuery,\n   OttoResponse,\n   ProfileDetails,\n+  ProviderResponse,\n   RefundRequest,\n   ReviewSubmissionRequest,\n   Schedule,\n@@ -56,6 +62,7 @@ import type {\n   StoreSubmissionRequest,\n   StoreSubmissionsResponse,\n   SubmissionStatus,\n+  SuggestionsResponse,\n   TransactionHistory,\n   User,\n   UserOnboarding,\n@@ -206,6 +213,44 @@ export default class BackendAPI {\n     return this._get(\"/onboarding/enabled\");\n   }\n \n+  ////////////////////////////////////////\n+  //////////////// BUILDER ///////////////\n+  ////////////////////////////////////////\n+\n+  getSuggestions(): Promise<SuggestionsResponse> {\n+    return this._get(\"/builder/suggestions\");\n+  }\n+\n+  getBlockCategories(): Promise<BlockCategoryResponse[]> {\n+    return this._get(\"/builder/categories\");\n+  }\n+\n+  getBuilderBlocks(request?: BlockRequest): Promise<BlockResponse> {\n+    return this._get(\"/builder/blocks\", request);\n+  }\n+\n+  getProviders(request?: {\n+    page?: number;\n+    page_size?: number;\n+  }): Promise<ProviderResponse> {\n+    return this._get(\"/builder/providers\", request);\n+  }\n+\n+  searchBlocks(options: {\n+    search_query?: string;\n+    filter?: (\"blocks\" | \"integrations\" | \"marketplace_agents\" | \"my_agents\")[];\n+    by_creator?: string[];\n+    search_id?: string;\n+    page?: number;\n+    page_size?: number;\n+  }): Promise<BlockSearchResponse> {\n+    return this._request(\"POST\", \"/builder/search\", options);\n+  }\n+\n+  getBlockCounts(): Promise<CountResponse> {\n+    return this._get(\"/builder/counts\");\n+  }\n+\n   ////////////////////////////////////////\n   //////////////// GRAPHS ////////////////\n   ////////////////////////////////////////\ndiff --git a/autogpt_platform/frontend/src/lib/autogpt-server-api/types.ts b/autogpt_platform/frontend/src/lib/autogpt-server-api/types.ts\nindex b4ba851053d0..f00dba21d2a2 100644\n--- a/autogpt_platform/frontend/src/lib/autogpt-server-api/types.ts\n+++ b/autogpt_platform/frontend/src/lib/autogpt-server-api/types.ts\n@@ -27,6 +27,71 @@ export type BlockCost = {\n   cost_filter: { [key: string]: any };\n };\n \n+/* Mirror of backend/server/v2/builder/model.py:SuggestionsResponse */\n+export type SuggestionsResponse = {\n+  otto_suggestions: string[];\n+  recent_searches: string[];\n+  providers: string[];\n+  top_blocks: Block[];\n+};\n+\n+/* Mirror of backend/server/v2/builder/model.py:BlockCategoryResponse */\n+export type BlockCategoryResponse = {\n+  name: string;\n+  total_blocks: number;\n+  blocks: Block[];\n+};\n+\n+export type BlockRequest = {\n+  page?: number;\n+  page_size?: number;\n+} & (\n+  | { category?: string }\n+  | { type?: \"all\" | \"input\" | \"action\" | \"output\" }\n+  | { provider?: CredentialsProviderName }\n+);\n+\n+/* Mirror of backend/server/v2/builder/model.py:BlockReponse */\n+export type BlockResponse = {\n+  blocks: Block[];\n+  pagination: Pagination;\n+};\n+\n+/* Mirror of backend/server/v2/builder/model.py:Provider */\n+export type Provider = {\n+  name: CredentialsProviderName;\n+  description: string;\n+  integration_count: number;\n+};\n+\n+/* Mirror of backend/server/v2/builder/model.py:ProviderResponse */\n+export type ProviderResponse = {\n+  providers: Provider[];\n+  pagination: Pagination;\n+};\n+\n+/* Mirror of backend/server/v2/builder/model.py:BlockSearchResponse */\n+export type BlockSearchResponse = {\n+  items: (Block | LibraryAgent | StoreAgent)[];\n+  total_items: Record<\n+    \"blocks\" | \"integrations\" | \"marketplace_agents\" | \"my_agents\",\n+    number\n+  >;\n+  page: number;\n+  more_pages: boolean;\n+};\n+\n+/* Mirror of backend/server/v2/builder/model.py:CountResponse */\n+export type CountResponse = {\n+  all_blocks: number;\n+  input_blocks: number;\n+  action_blocks: number;\n+  output_blocks: number;\n+  integrations: number;\n+  marketplace_agents: number;\n+  my_agents: number;\n+};\n+\n /* Mirror of backend/data/block.py:Block */\n export type Block = {\n   id: string;\n@@ -402,6 +467,7 @@ export type LibraryAgent = {\n   name: string;\n   description: string;\n   input_schema: BlockIOObjectSubSchema;\n+  output_schema: BlockIOObjectSubSchema;\n   new_output: boolean;\n   can_access_graph: boolean;\n   is_latest_version: boolean;\ndiff --git a/autogpt_platform/frontend/src/lib/utils.ts b/autogpt_platform/frontend/src/lib/utils.ts\nindex 3eea21add85f..3be378777830 100644\n--- a/autogpt_platform/frontend/src/lib/utils.ts\n+++ b/autogpt_platform/frontend/src/lib/utils.ts\n@@ -1,7 +1,13 @@\n import { type ClassValue, clsx } from \"clsx\";\n import { twMerge } from \"tailwind-merge\";\n \n-import { Category } from \"@/lib/autogpt-server-api/types\";\n+import {\n+  Block,\n+  BlockUIType,\n+  Category,\n+  LibraryAgent,\n+  SpecialBlockID,\n+} from \"@/lib/autogpt-server-api/types\";\n import { NodeDimension } from \"@/components/Flow\";\n \n export function cn(...inputs: ClassValue[]) {\n@@ -397,7 +403,59 @@ export function isEmptyOrWhitespace(str: string | undefined | null): boolean {\n   return !str || str.trim().length === 0;\n }\n \n-/** Check if a value is an object or not */\n-export function isObject(value: unknown): value is Record<string, unknown> {\n-  return typeof value === \"object\" && value !== null && !Array.isArray(value);\n+export const convertLibraryAgentIntoBlock = (agent: LibraryAgent) => {\n+  const block = {\n+    id: SpecialBlockID.AGENT,\n+    name: agent.name,\n+    description:\n+      `Ver.${agent.graph_version}` +\n+      (agent.description ? ` | ${agent.description}` : \"\"),\n+    categories: [{ category: \"AGENT\", description: \"\" }],\n+    inputSchema: agent.input_schema,\n+    outputSchema: agent.output_schema,\n+    staticOutput: false,\n+    uiType: BlockUIType.AGENT,\n+    uiKey: agent.id,\n+    costs: [],\n+    hardcodedValues: {\n+      graph_id: agent.graph_id,\n+      graph_version: agent.graph_version,\n+      input_schema: agent.input_schema,\n+      output_schema: agent.output_schema,\n+      agent_name: agent.name,\n+    },\n+  } as Block;\n+\n+  return block;\n+};\n+\n+// Need to change it once, we got provider blocks\n+export const getBlockType = (item: any) => {\n+  if (item?.inputSchema?.properties?.model?.title === \"LLM Model\") {\n+    return \"ai_agent\";\n+  }\n+  if (item.id && item.name && item.inputSchema && item.outputSchema) {\n+    return \"block\";\n+  }\n+  if (item.name && typeof item.integration_count === \"number\") {\n+    return \"provider\";\n+  }\n+  if (item.id && item.graph_id && item.status) {\n+    return \"library_agent\";\n+  }\n+  if (item.slug && item.agent_name && item.runs !== undefined) {\n+    return \"store_agent\";\n+  }\n+\n+  return null;\n+};\n+\n+export function parseErrorMessage(error: unknown, message?: string): string {\n+  const errorMessage = error\n+    ? error instanceof Error\n+      ? error.message\n+      : String(error)\n+    : message || \"An unexpected error occurred. Please try again.\";\n+\n+  return errorMessage;\n }\ndiff --git a/autogpt_platform/frontend/src/tests/build.spec.ts b/autogpt_platform/frontend/src/tests/build.spec.ts\nindex 3c6a87ba94b7..4f968242774f 100644\n--- a/autogpt_platform/frontend/src/tests/build.spec.ts\n+++ b/autogpt_platform/frontend/src/tests/build.spec.ts\n@@ -1,304 +1,304 @@\n-// Note: all the comments with //(number)! are for the docs\n-//ignore them when reading the code, but if you change something,\n-//make sure to update the docs! Your autoformmater will break this page,\n-// so don't run it on this file.\n-// --8<-- [start:BuildPageExample]\n-import { test } from \"./fixtures\";\n-import { BuildPage } from \"./pages/build.page\";\n-\n-// Reason Ignore: admonishment is in the wrong place visually with correct prettier rules\n-// prettier-ignore\n-test.describe(\"Build\", () => { //(1)!\n-  let buildPage: BuildPage; //(2)!\n-\n-  // Reason Ignore: admonishment is in the wrong place visually with correct prettier rules\n-  // prettier-ignore\n-  test.beforeEach(async ({ page, loginPage, testUser }) => { //(3)! ts-ignore\n-    buildPage = new BuildPage(page);\n-\n-    // Start each test with login using worker auth\n-    await page.goto(\"/login\"); //(4)!\n-    await loginPage.login(testUser.email, testUser.password);\n-    await test.expect(page).toHaveURL(\"/marketplace\"); //(5)!\n-    await buildPage.navbar.clickBuildLink();\n-  });\n-\n-  // Reason Ignore: admonishment is in the wrong place visually with correct prettier rules\n-  // prettier-ignore\n-  test(\"user can add a block\", async ({ page }) => { //(6)!\n-    // workaround for #8788\n-    await buildPage.navbar.clickBuildLink();\n-    await test.expect(page).toHaveURL(new RegExp(\"/build\"));\n-    await buildPage.waitForPageLoad();\n-    await test.expect(buildPage.isLoaded()).resolves.toBeTruthy(); //(7)!\n-\n-    await buildPage.closeTutorial(); //(9)!\n-    await buildPage.openBlocksPanel(); //(10)!\n-    const block = await buildPage.getDictionaryBlockDetails();\n-\n-    await buildPage.addBlock(block); //(11)!\n-    await buildPage.closeBlocksPanel(); //(12)!\n-    await test.expect(buildPage.hasBlock(block)).resolves.toBeTruthy(); //(13)!\n-  });\n-  // --8<-- [end:BuildPageExample]\n-\n-  test(\"user can add all blocks a-l\", async ({ page }, testInfo) => {\n-    // this test is slow af so we 10x the timeout (sorry future me)\n-    await test.setTimeout(testInfo.timeout * 100);\n-    await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();\n-    await test.expect(page).toHaveURL(new RegExp(\"/.*build\"));\n-    await buildPage.closeTutorial();\n-    await buildPage.openBlocksPanel();\n-    const blocks = await buildPage.getBlocks();\n-\n-    const blockIdsToSkip = await buildPage.getBlocksToSkip();\n-    const blockTypesToSkip = [\"Input\", \"Output\", \"Agent\", \"AI\"];\n-\n-    // add all the blocks in order except for the agent executor block\n-    for (const block of blocks) {\n-      if (block.name[0].toLowerCase() >= \"m\") {\n-        continue;\n-      }\n-      if (!blockIdsToSkip.some((b) => b === block.id) && !blockTypesToSkip.some((b) => block.type === b)) {\n-        console.log(\"Adding block:\", block.name, block.id, block.type, \" skipping types:\", blockTypesToSkip);\n-        await buildPage.addBlock(block);\n-      }\n-    }\n-    await buildPage.closeBlocksPanel();\n-    // check that all the blocks are visible\n-    for (const block of blocks) {\n-      if (block.name[0].toLowerCase() >= \"m\") {\n-        continue;\n-      }\n-      if (!blockIdsToSkip.some((b) => b === block.id) && !blockTypesToSkip.some((b) => block.type === b)) {\n-        console.log(\"Checking block:\", block.name, block.id, block.type, \" skipping types:\", blockTypesToSkip);\n-        await test.expect(buildPage.hasBlock(block)).resolves.toBeTruthy();\n-      }\n-    }\n-\n-    // check that we can save the agent with all the blocks\n-    await buildPage.saveAgent(\"all blocks test\", \"all blocks test\");\n-    // page should have a url like http://localhost:3000/build?flowID=f4f3a1da-cfb3-430f-a074-a455b047e340\n-    await test.expect(page).toHaveURL(new RegExp(\"/.*build\\\\?flowID=.+\"));\n-  });\n-\n-  test(\"user can add all blocks m-z\", async ({ page }, testInfo) => {\n-    // this test is slow af so we 10x the timeout (sorry future me)\n-    await test.setTimeout(testInfo.timeout * 100);\n-    await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();\n-    await test.expect(page).toHaveURL(new RegExp(\"/.*build\"));\n-    await buildPage.closeTutorial();\n-    await buildPage.openBlocksPanel();\n-    const blocks = await buildPage.getBlocks();\n-\n-    const blockIdsToSkip = await buildPage.getBlocksToSkip();\n-    const blockTypesToSkip = [\"Input\", \"Output\", \"Agent\", \"AI\"];\n-\n-    // add all the blocks in order except for the agent executor block\n-    for (const block of blocks) {\n-      if (block.name[0].toLowerCase() < \"m\") {\n-        continue;\n-      }\n-      if (!blockIdsToSkip.some((b) => b === block.id) && !blockTypesToSkip.some((b) => block.type === b)) {\n-        console.log(\"Adding block:\", block.name, block.id, block.type, \" skipping types:\", blockTypesToSkip);\n-        await buildPage.addBlock(block);\n-      }\n-    }\n-    await buildPage.closeBlocksPanel();\n-    // check that all the blocks are visible\n-    for (const block of blocks) {\n-      if (block.name[0].toLowerCase() < \"m\") {\n-        continue;\n-      }\n-      if (!blockIdsToSkip.some((b) => b === block.id) && !blockTypesToSkip.some((b) => block.type === b)) {\n-        console.log(\"Checking block:\", block.name, block.id, block.type, \" skipping types:\", blockTypesToSkip);\n-        await test.expect(buildPage.hasBlock(block)).resolves.toBeTruthy();\n-      }\n-    }\n-\n-    // check that we can save the agent with all the blocks\n-    await buildPage.saveAgent(\"all blocks test\", \"all blocks test\");\n-    // page should have a url like http://localhost:3000/build?flowID=f4f3a1da-cfb3-430f-a074-a455b047e340\n-    await test.expect(page).toHaveURL(new RegExp(\"/.*build\\\\?flowID=.+\"));\n-  });\n-\n-  test(\"build navigation is accessible from navbar\", async ({ page }) => {\n-    await buildPage.navbar.clickBuildLink();\n-    await test.expect(page).toHaveURL(new RegExp(\"/build\"));\n-    // workaround for #8788\n-    await page.reload();\n-    await page.reload();\n-    await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();\n-  });\n-\n-  test(\"user can add two blocks and connect them\", async ({\n-    page,\n-  }, testInfo) => {\n-    await test.setTimeout(testInfo.timeout * 10);\n-\n-    await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();\n-    await test.expect(page).toHaveURL(new RegExp(\"/.*build\"));\n-    await buildPage.closeTutorial();\n-    await buildPage.openBlocksPanel();\n-\n-    // Define the blocks to add\n-    const block1 = {\n-      id: \"1ff065e9-88e8-4358-9d82-8dc91f622ba9\",\n-      name: \"Store Value 1\",\n-      description: \"Store Value Block 1\",\n-      type: \"Standard\",\n-    };\n-    const block2 = {\n-      id: \"1ff065e9-88e8-4358-9d82-8dc91f622ba9\",\n-      name: \"Store Value 2\",\n-      description: \"Store Value Block 2\",\n-      type: \"Standard\",\n-    };\n-\n-    // Add the blocks\n-    await buildPage.addBlock(block1);\n-    await buildPage.addBlock(block2);\n-    await buildPage.closeBlocksPanel();\n-\n-    // Connect the blocks\n-    await buildPage.connectBlockOutputToBlockInputViaDataId(\n-      \"1-1-output-source\",\n-      \"1-2-input-target\",\n-    );\n-\n-    // Fill in the input for the first block\n-    await buildPage.fillBlockInputByPlaceholder(\n-      block1.id,\n-      \"Enter input\",\n-      \"Test Value\",\n-      \"1\",\n-    );\n-\n-    // Save the agent and wait for the URL to update\n-    await buildPage.saveAgent(\n-      \"Connected Blocks Test\",\n-      \"Testing block connections\",\n-    );\n-    await test.expect(page).toHaveURL(new RegExp(\"/.*build\\\\?flowID=.+\"));\n-\n-    // Wait for the save button to be enabled again\n-    await buildPage.waitForSaveButton();\n-\n-    // Ensure the run button is enabled\n-    await test.expect(buildPage.isRunButtonEnabled()).resolves.toBeTruthy();\n-\n-    // Run the agent\n-    await buildPage.runAgent();\n-\n-    // Wait for processing to complete by checking the completion badge\n-    await buildPage.waitForCompletionBadge();\n-\n-    // Get the first completion badge and verify it's visible\n-    await test\n-      .expect(buildPage.isCompletionBadgeVisible())\n-      .resolves.toBeTruthy();\n-  });\n-\n-  test(\"user can build an agent with inputs and output blocks\", async ({\n-    page,\n-  }) => {\n-    // simple calculator to double input and output it\n-\n-    // load the pages and prep\n-    await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();\n-    await test.expect(page).toHaveURL(new RegExp(\"/.*build\"));\n-    await buildPage.closeTutorial();\n-    await buildPage.openBlocksPanel();\n-\n-    // find the blocks we want\n-    const blocks = await buildPage.getBlocks();\n-    const inputBlock = blocks.find((b) => b.name === \"Agent Input\");\n-    const outputBlock = blocks.find((b) => b.name === \"Agent Output\");\n-    const calculatorBlock = blocks.find((b) => b.name === \"Calculator\");\n-    if (!inputBlock || !outputBlock || !calculatorBlock) {\n-      throw new Error(\"Input or output block not found\");\n-    }\n-\n-    // add the blocks\n-    await buildPage.addBlock(inputBlock);\n-    await buildPage.addBlock(outputBlock);\n-    await buildPage.addBlock(calculatorBlock);\n-    await buildPage.closeBlocksPanel();\n-\n-    // Wait for blocks to be fully loaded\n-    await page.waitForTimeout(1000);\n-\n-    await test.expect(buildPage.hasBlock(inputBlock)).resolves.toBeTruthy();\n-    await test.expect(buildPage.hasBlock(outputBlock)).resolves.toBeTruthy();\n-    await test\n-      .expect(buildPage.hasBlock(calculatorBlock))\n-      .resolves.toBeTruthy();\n-\n-    // Wait for blocks to be ready for connections\n-    await page.waitForTimeout(1000);\n-\n-    await buildPage.connectBlockOutputToBlockInputViaName(\n-      inputBlock.id,\n-      \"Result\",\n-      calculatorBlock.id,\n-      \"A\",\n-    );\n-    await buildPage.connectBlockOutputToBlockInputViaName(\n-      inputBlock.id,\n-      \"Result\",\n-      calculatorBlock.id,\n-      \"B\",\n-    );\n-    await buildPage.connectBlockOutputToBlockInputViaName(\n-      calculatorBlock.id,\n-      \"Result\",\n-      outputBlock.id,\n-      \"Value\",\n-    );\n-\n-    // Wait for connections to stabilize\n-    await page.waitForTimeout(1000);\n-\n-    await buildPage.fillBlockInputByPlaceholder(\n-      inputBlock.id,\n-      \"Enter Name\",\n-      \"Value\",\n-    );\n-    await buildPage.fillBlockInputByPlaceholder(\n-      outputBlock.id,\n-      \"Enter Name\",\n-      \"Doubled\",\n-    );\n-\n-    // Wait before changing dropdown\n-    await page.waitForTimeout(500);\n-\n-    await buildPage.selectBlockInputValue(\n-      calculatorBlock.id,\n-      \"Operation\",\n-      \"Add\",\n-    );\n-\n-    // Wait before saving\n-    await page.waitForTimeout(1000);\n-\n-    await buildPage.saveAgent(\n-      \"Input and Output Blocks Test\",\n-      \"Testing input and output blocks\",\n-    );\n-    await test.expect(page).toHaveURL(new RegExp(\"/.*build\\\\?flowID=.+\"));\n-\n-    // Wait for save to complete\n-    await page.waitForTimeout(1000);\n-\n-    await buildPage.runAgent();\n-    await buildPage.fillRunDialog({\n-      Value: \"10\",\n-    });\n-    await buildPage.clickRunDialogRunButton();\n-    await buildPage.waitForCompletionBadge();\n-    await test\n-      .expect(buildPage.isCompletionBadgeVisible())\n-      .resolves.toBeTruthy();\n-  });\n-});\n+// // Note: all the comments with //(number)! are for the docs\n+// //ignore them when reading the code, but if you change something,\n+// //make sure to update the docs! Your autoformmater will break this page,\n+// // so don't run it on this file.\n+// // --8<-- [start:BuildPageExample]\n+// import { test } from \"./fixtures\";\n+// import { BuildPage } from \"./pages/build.page\";\n+\n+// // Reason Ignore: admonishment is in the wrong place visually with correct prettier rules\n+// // prettier-ignore\n+// test.describe(\"Build\", () => { //(1)!\n+//   let buildPage: BuildPage; //(2)!\n+\n+//   // Reason Ignore: admonishment is in the wrong place visually with correct prettier rules\n+//   // prettier-ignore\n+//   test.beforeEach(async ({ page, loginPage, testUser }, testInfo) => { //(3)! ts-ignore\n+//     buildPage = new BuildPage(page);\n+\n+//     // Start each test with login using worker auth\n+//     await page.goto(\"/login\"); //(4)!\n+//     await loginPage.login(testUser.email, testUser.password);\n+//     await test.expect(page).toHaveURL(\"/marketplace\"); //(5)!\n+//     await buildPage.navbar.clickBuildLink();\n+//   });\n+\n+//   // Reason Ignore: admonishment is in the wrong place visually with correct prettier rules\n+//   // prettier-ignore\n+//   test(\"user can add a block\", async ({ page }) => { //(6)!\n+//     // workaround for #8788\n+//     await buildPage.navbar.clickBuildLink();\n+//     await test.expect(page).toHaveURL(new RegExp(\"/build\"));\n+//     await buildPage.waitForPageLoad();\n+//     await test.expect(buildPage.isLoaded()).resolves.toBeTruthy(); //(7)!\n+\n+//     await buildPage.closeTutorial(); //(9)!\n+//     await buildPage.openBlocksPanel(); //(10)!\n+//     const block = await buildPage.getDictionaryBlockDetails();\n+\n+//     await buildPage.addBlock(block); //(11)!\n+//     await buildPage.closeBlocksPanel(); //(12)!\n+//     await test.expect(buildPage.hasBlock(block)).resolves.toBeTruthy(); //(13)!\n+//   });\n+//   // --8<-- [end:BuildPageExample]\n+\n+//   test(\"user can add all blocks a-l\", async ({ page }, testInfo) => {\n+//     // this test is slow af so we 10x the timeout (sorry future me)\n+//     await test.setTimeout(testInfo.timeout * 100);\n+//     await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();\n+//     await test.expect(page).toHaveURL(new RegExp(\"/.*build\"));\n+//     await buildPage.closeTutorial();\n+//     await buildPage.openBlocksPanel();\n+//     const blocks = await buildPage.getBlocks();\n+\n+//     const blockIdsToSkip = await buildPage.getBlocksToSkip();\n+//     const blockTypesToSkip = [\"Input\", \"Output\", \"Agent\", \"AI\"];\n+\n+//     // add all the blocks in order except for the agent executor block\n+//     for (const block of blocks) {\n+//       if (block.name[0].toLowerCase() >= \"m\") {\n+//         continue;\n+//       }\n+//       if (!blockIdsToSkip.some((b) => b === block.id) && !blockTypesToSkip.some((b) => block.type === b)) {\n+//         console.log(\"Adding block:\", block.name, block.id, block.type, \" skipping types:\", blockTypesToSkip);\n+//         await buildPage.addBlock(block);\n+//       }\n+//     }\n+//     await buildPage.closeBlocksPanel();\n+//     // check that all the blocks are visible\n+//     for (const block of blocks) {\n+//       if (block.name[0].toLowerCase() >= \"m\") {\n+//         continue;\n+//       }\n+//       if (!blockIdsToSkip.some((b) => b === block.id) && !blockTypesToSkip.some((b) => block.type === b)) {\n+//         console.log(\"Checking block:\", block.name, block.id, block.type, \" skipping types:\", blockTypesToSkip);\n+//         await test.expect(buildPage.hasBlock(block)).resolves.toBeTruthy();\n+//       }\n+//     }\n+\n+//     // check that we can save the agent with all the blocks\n+//     await buildPage.saveAgent(\"all blocks test\", \"all blocks test\");\n+//     // page should have a url like http://localhost:3000/build?flowID=f4f3a1da-cfb3-430f-a074-a455b047e340\n+//     await test.expect(page).toHaveURL(new RegExp(\"/.*build\\\\?flowID=.+\"));\n+//   });\n+\n+//   test(\"user can add all blocks m-z\", async ({ page }, testInfo) => {\n+//     // this test is slow af so we 10x the timeout (sorry future me)\n+//     await test.setTimeout(testInfo.timeout * 100);\n+//     await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();\n+//     await test.expect(page).toHaveURL(new RegExp(\"/.*build\"));\n+//     await buildPage.closeTutorial();\n+//     await buildPage.openBlocksPanel();\n+//     const blocks = await buildPage.getBlocks();\n+\n+//     const blockIdsToSkip = await buildPage.getBlocksToSkip();\n+//     const blockTypesToSkip = [\"Input\", \"Output\", \"Agent\", \"AI\"];\n+\n+//     // add all the blocks in order except for the agent executor block\n+//     for (const block of blocks) {\n+//       if (block.name[0].toLowerCase() < \"m\") {\n+//         continue;\n+//       }\n+//       if (!blockIdsToSkip.some((b) => b === block.id) && !blockTypesToSkip.some((b) => block.type === b)) {\n+//         console.log(\"Adding block:\", block.name, block.id, block.type, \" skipping types:\", blockTypesToSkip);\n+//         await buildPage.addBlock(block);\n+//       }\n+//     }\n+//     await buildPage.closeBlocksPanel();\n+//     // check that all the blocks are visible\n+//     for (const block of blocks) {\n+//       if (block.name[0].toLowerCase() < \"m\") {\n+//         continue;\n+//       }\n+//       if (!blockIdsToSkip.some((b) => b === block.id) && !blockTypesToSkip.some((b) => block.type === b)) {\n+//         console.log(\"Checking block:\", block.name, block.id, block.type, \" skipping types:\", blockTypesToSkip);\n+//         await test.expect(buildPage.hasBlock(block)).resolves.toBeTruthy();\n+//       }\n+//     }\n+\n+//     // check that we can save the agent with all the blocks\n+//     await buildPage.saveAgent(\"all blocks test\", \"all blocks test\");\n+//     // page should have a url like http://localhost:3000/build?flowID=f4f3a1da-cfb3-430f-a074-a455b047e340\n+//     await test.expect(page).toHaveURL(new RegExp(\"/.*build\\\\?flowID=.+\"));\n+//   });\n+\n+//   test(\"build navigation is accessible from navbar\", async ({ page }) => {\n+//     await buildPage.navbar.clickBuildLink();\n+//     await test.expect(page).toHaveURL(new RegExp(\"/build\"));\n+//     // workaround for #8788\n+//     await page.reload();\n+//     await page.reload();\n+//     await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();\n+//   });\n+\n+//   test(\"user can add two blocks and connect them\", async ({\n+//     page,\n+//   }, testInfo) => {\n+//     await test.setTimeout(testInfo.timeout * 10);\n+\n+//     await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();\n+//     await test.expect(page).toHaveURL(new RegExp(\"/.*build\"));\n+//     await buildPage.closeTutorial();\n+//     await buildPage.openBlocksPanel();\n+\n+//     // Define the blocks to add\n+//     const block1 = {\n+//       id: \"1ff065e9-88e8-4358-9d82-8dc91f622ba9\",\n+//       name: \"Store Value 1\",\n+//       description: \"Store Value Block 1\",\n+//       type: \"Standard\",\n+//     };\n+//     const block2 = {\n+//       id: \"1ff065e9-88e8-4358-9d82-8dc91f622ba9\",\n+//       name: \"Store Value 2\",\n+//       description: \"Store Value Block 2\",\n+//       type: \"Standard\",\n+//     };\n+\n+//     // Add the blocks\n+//     await buildPage.addBlock(block1);\n+//     await buildPage.addBlock(block2);\n+//     await buildPage.closeBlocksPanel();\n+\n+//     // Connect the blocks\n+//     await buildPage.connectBlockOutputToBlockInputViaDataId(\n+//       \"1-1-output-source\",\n+//       \"1-2-input-target\",\n+//     );\n+\n+//     // Fill in the input for the first block\n+//     await buildPage.fillBlockInputByPlaceholder(\n+//       block1.id,\n+//       \"Enter input\",\n+//       \"Test Value\",\n+//       \"1\",\n+//     );\n+\n+//     // Save the agent and wait for the URL to update\n+//     await buildPage.saveAgent(\n+//       \"Connected Blocks Test\",\n+//       \"Testing block connections\",\n+//     );\n+//     await test.expect(page).toHaveURL(new RegExp(\"/.*build\\\\?flowID=.+\"));\n+\n+//     // Wait for the save button to be enabled again\n+//     await buildPage.waitForSaveButton();\n+\n+//     // Ensure the run button is enabled\n+//     await test.expect(buildPage.isRunButtonEnabled()).resolves.toBeTruthy();\n+\n+//     // Run the agent\n+//     await buildPage.runAgent();\n+\n+//     // Wait for processing to complete by checking the completion badge\n+//     await buildPage.waitForCompletionBadge();\n+\n+//     // Get the first completion badge and verify it's visible\n+//     await test\n+//       .expect(buildPage.isCompletionBadgeVisible())\n+//       .resolves.toBeTruthy();\n+//   });\n+\n+//   test(\"user can build an agent with inputs and output blocks\", async ({\n+//     page,\n+//   }) => {\n+//     // simple calculator to double input and output it\n+\n+//     // load the pages and prep\n+//     await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();\n+//     await test.expect(page).toHaveURL(new RegExp(\"/.*build\"));\n+//     await buildPage.closeTutorial();\n+//     await buildPage.openBlocksPanel();\n+\n+//     // find the blocks we want\n+//     const blocks = await buildPage.getBlocks();\n+//     const inputBlock = blocks.find((b) => b.name === \"Agent Input\");\n+//     const outputBlock = blocks.find((b) => b.name === \"Agent Output\");\n+//     const calculatorBlock = blocks.find((b) => b.name === \"Calculator\");\n+//     if (!inputBlock || !outputBlock || !calculatorBlock) {\n+//       throw new Error(\"Input or output block not found\");\n+//     }\n+\n+//     // add the blocks\n+//     await buildPage.addBlock(inputBlock);\n+//     await buildPage.addBlock(outputBlock);\n+//     await buildPage.addBlock(calculatorBlock);\n+//     await buildPage.closeBlocksPanel();\n+\n+//     // Wait for blocks to be fully loaded\n+//     await page.waitForTimeout(1000);\n+\n+//     await test.expect(buildPage.hasBlock(inputBlock)).resolves.toBeTruthy();\n+//     await test.expect(buildPage.hasBlock(outputBlock)).resolves.toBeTruthy();\n+//     await test\n+//       .expect(buildPage.hasBlock(calculatorBlock))\n+//       .resolves.toBeTruthy();\n+\n+//     // Wait for blocks to be ready for connections\n+//     await page.waitForTimeout(1000);\n+\n+//     await buildPage.connectBlockOutputToBlockInputViaName(\n+//       inputBlock.id,\n+//       \"Result\",\n+//       calculatorBlock.id,\n+//       \"A\",\n+//     );\n+//     await buildPage.connectBlockOutputToBlockInputViaName(\n+//       inputBlock.id,\n+//       \"Result\",\n+//       calculatorBlock.id,\n+//       \"B\",\n+//     );\n+//     await buildPage.connectBlockOutputToBlockInputViaName(\n+//       calculatorBlock.id,\n+//       \"Result\",\n+//       outputBlock.id,\n+//       \"Value\",\n+//     );\n+\n+//     // Wait for connections to stabilize\n+//     await page.waitForTimeout(1000);\n+\n+//     await buildPage.fillBlockInputByPlaceholder(\n+//       inputBlock.id,\n+//       \"Enter Name\",\n+//       \"Value\",\n+//     );\n+//     await buildPage.fillBlockInputByPlaceholder(\n+//       outputBlock.id,\n+//       \"Enter Name\",\n+//       \"Doubled\",\n+//     );\n+\n+//     // Wait before changing dropdown\n+//     await page.waitForTimeout(500);\n+\n+//     await buildPage.selectBlockInputValue(\n+//       calculatorBlock.id,\n+//       \"Operation\",\n+//       \"Add\",\n+//     );\n+\n+//     // Wait before saving\n+//     await page.waitForTimeout(1000);\n+\n+//     await buildPage.saveAgent(\n+//       \"Input and Output Blocks Test\",\n+//       \"Testing input and output blocks\",\n+//     );\n+//     await test.expect(page).toHaveURL(new RegExp(\"/.*build\\\\?flowID=.+\"));\n+\n+//     // Wait for save to complete\n+//     await page.waitForTimeout(1000);\n+\n+//     await buildPage.runAgent();\n+//     await buildPage.fillRunDialog({\n+//       Value: \"10\",\n+//     });\n+//     await buildPage.clickRunDialogRunButton();\n+//     await buildPage.waitForCompletionBadge();\n+//     await test\n+//       .expect(buildPage.isCompletionBadgeVisible())\n+//       .resolves.toBeTruthy();\n+//   });\n+// });\ndiff --git a/autogpt_platform/frontend/src/tests/monitor.spec.ts b/autogpt_platform/frontend/src/tests/monitor.spec.ts\nindex a7e588acf0f7..576a7c69183d 100644\n--- a/autogpt_platform/frontend/src/tests/monitor.spec.ts\n+++ b/autogpt_platform/frontend/src/tests/monitor.spec.ts\n@@ -1,126 +1,126 @@\n-import { TestInfo } from \"@playwright/test\";\n-import { test } from \"./fixtures\";\n-import { BuildPage } from \"./pages/build.page\";\n-import { MonitorPage } from \"./pages/monitor.page\";\n-import { v4 as uuidv4 } from \"uuid\";\n-import * as fs from \"fs/promises\";\n-import path from \"path\";\n-// --8<-- [start:AttachAgentId]\n-test.describe(\"Monitor\", () => {\n-  let buildPage: BuildPage;\n-  let monitorPage: MonitorPage;\n+// import { expect, TestInfo } from \"@playwright/test\";\n+// import { test } from \"./fixtures\";\n+// import { BuildPage } from \"./pages/build.page\";\n+// import { MonitorPage } from \"./pages/monitor.page\";\n+// import { v4 as uuidv4 } from \"uuid\";\n+// import * as fs from \"fs/promises\";\n+// import path from \"path\";\n+// // --8<-- [start:AttachAgentId]\n+// test.describe(\"Monitor\", () => {\n+//   let buildPage: BuildPage;\n+//   let monitorPage: MonitorPage;\n \n-  test.beforeEach(async ({ page, loginPage, testUser }, testInfo: TestInfo) => {\n-    buildPage = new BuildPage(page);\n-    monitorPage = new MonitorPage(page);\n+//   test.beforeEach(async ({ page, loginPage, testUser }, testInfo: TestInfo) => {\n+//     buildPage = new BuildPage(page);\n+//     monitorPage = new MonitorPage(page);\n \n-    // Start each test with login using worker auth\n-    await page.goto(\"/login\");\n-    await loginPage.login(testUser.email, testUser.password);\n-    await test.expect(page).toHaveURL(\"/marketplace\");\n+//     // Start each test with login using worker auth\n+//     await page.goto(\"/login\");\n+//     await loginPage.login(testUser.email, testUser.password);\n+//     await test.expect(page).toHaveURL(\"/marketplace\");\n \n-    // add a test agent\n-    const basicBlock = await buildPage.getDictionaryBlockDetails();\n-    const id = uuidv4();\n-    await buildPage.createSingleBlockAgent(\n-      `test-agent-${id}`,\n-      `test-agent-description-${id}`,\n-      basicBlock,\n-    );\n-    await buildPage.runAgent();\n-    // await monitorPage.navbar.clickMonitorLink();\n-    await page.goto(\"/monitoring\"); // Library link now points to /library\n-    await monitorPage.waitForPageLoad();\n-    await test.expect(monitorPage.isLoaded()).resolves.toBeTruthy();\n-    testInfo.attach(\"agent-id\", { body: id });\n-  });\n-  // --8<-- [end:AttachAgentId]\n+//     // add a test agent\n+//     const basicBlock = await buildPage.getDictionaryBlockDetails();\n+//     const id = uuidv4();\n+//     await buildPage.createSingleBlockAgent(\n+//       `test-agent-${id}`,\n+//       `test-agent-description-${id}`,\n+//       basicBlock,\n+//     );\n+//     await buildPage.runAgent();\n+//     // await monitorPage.navbar.clickMonitorLink();\n+//     await page.goto(\"/monitoring\"); // Library link now points to /library\n+//     await monitorPage.waitForPageLoad();\n+//     await test.expect(monitorPage.isLoaded()).resolves.toBeTruthy();\n+//     testInfo.attach(\"agent-id\", { body: id });\n+//   });\n+//   // --8<-- [end:AttachAgentId]\n \n-  test.afterAll(async ({}) => {\n-    // clear out the downloads folder\n-    console.log(\n-      `clearing out the downloads folder ${monitorPage.downloadsFolder}`,\n-    );\n+//   test.afterAll(async ({}) => {\n+//     // clear out the downloads folder\n+//     console.log(\n+//       `clearing out the downloads folder ${monitorPage.downloadsFolder}`,\n+//     );\n \n-    await fs.rm(`${monitorPage.downloadsFolder}/monitor`, {\n-      recursive: true,\n-      force: true,\n-    });\n-  });\n+//     await fs.rm(`${monitorPage.downloadsFolder}/monitor`, {\n+//       recursive: true,\n+//       force: true,\n+//     });\n+//   });\n \n-  test(\"user can view agents\", async () => {\n-    const agents = await monitorPage.listAgents();\n-    // there should be at least one agent\n-    await test.expect(agents.length).toBeGreaterThan(0);\n-  });\n+//   test(\"user can view agents\", async ({ page }) => {\n+//     const agents = await monitorPage.listAgents();\n+//     // there should be at least one agent\n+//     await test.expect(agents.length).toBeGreaterThan(0);\n+//   });\n \n-  test.skip(\"user can export and import agents\", async ({\n-    page,\n-  }, testInfo: TestInfo) => {\n-    // --8<-- [start:ReadAgentId]\n-    if (testInfo.attachments.length === 0 || !testInfo.attachments[0].body) {\n-      throw new Error(\"No agent id attached to the test\");\n-    }\n-    const testAttachName = testInfo.attachments[0].body.toString();\n-    // --8<-- [end:ReadAgentId]\n-    const agents = await monitorPage.listAgents();\n+//   test.skip(\"user can export and import agents\", async ({\n+//     page,\n+//   }, testInfo: TestInfo) => {\n+//     // --8<-- [start:ReadAgentId]\n+//     if (testInfo.attachments.length === 0 || !testInfo.attachments[0].body) {\n+//       throw new Error(\"No agent id attached to the test\");\n+//     }\n+//     const testAttachName = testInfo.attachments[0].body.toString();\n+//     // --8<-- [end:ReadAgentId]\n+//     const agents = await monitorPage.listAgents();\n \n-    const downloadPromise = page.waitForEvent(\"download\");\n-    const agent = agents.find(\n-      (a: any) => a.name === `test-agent-${testAttachName}`,\n-    );\n-    if (!agent) {\n-      throw new Error(`Agent ${testAttachName} not found`);\n-    }\n-    await monitorPage.exportToFile(agent);\n-    const download = await downloadPromise;\n+//     const downloadPromise = page.waitForEvent(\"download\");\n+//     const agent = agents.find(\n+//       (a: any) => a.name === `test-agent-${testAttachName}`,\n+//     );\n+//     if (!agent) {\n+//       throw new Error(`Agent ${testAttachName} not found`);\n+//     }\n+//     await monitorPage.exportToFile(agent);\n+//     const download = await downloadPromise;\n \n-    // Wait for the download process to complete and save the downloaded file somewhere.\n-    await download.saveAs(\n-      `${monitorPage.downloadsFolder}/monitor/${download.suggestedFilename()}`,\n-    );\n-    console.log(`downloaded file to ${download.suggestedFilename()}`);\n-    await test.expect(download.suggestedFilename()).toBeDefined();\n-    // test-agent-uuid-v1.json\n-    await test.expect(download.suggestedFilename()).toContain(\"test-agent-\");\n-    await test.expect(download.suggestedFilename()).toContain(\"v1.json\");\n+//     // Wait for the download process to complete and save the downloaded file somewhere.\n+//     await download.saveAs(\n+//       `${monitorPage.downloadsFolder}/monitor/${download.suggestedFilename()}`,\n+//     );\n+//     console.log(`downloaded file to ${download.suggestedFilename()}`);\n+//     await test.expect(download.suggestedFilename()).toBeDefined();\n+//     // test-agent-uuid-v1.json\n+//     await test.expect(download.suggestedFilename()).toContain(\"test-agent-\");\n+//     await test.expect(download.suggestedFilename()).toContain(\"v1.json\");\n \n-    // import the agent\n-    const preImportAgents = await monitorPage.listAgents();\n-    const filesInFolder = await fs.readdir(\n-      `${monitorPage.downloadsFolder}/monitor`,\n-    );\n-    const importFile = filesInFolder.find((f) => f.includes(testAttachName));\n-    if (!importFile) {\n-      throw new Error(`No import file found for agent ${testAttachName}`);\n-    }\n-    const baseName = importFile.split(\".\")[0];\n-    await monitorPage.importFromFile(\n-      path.resolve(monitorPage.downloadsFolder, \"monitor\"),\n-      importFile,\n-      baseName + \"-imported\",\n-    );\n+//     // import the agent\n+//     const preImportAgents = await monitorPage.listAgents();\n+//     const filesInFolder = await fs.readdir(\n+//       `${monitorPage.downloadsFolder}/monitor`,\n+//     );\n+//     const importFile = filesInFolder.find((f) => f.includes(testAttachName));\n+//     if (!importFile) {\n+//       throw new Error(`No import file found for agent ${testAttachName}`);\n+//     }\n+//     const baseName = importFile.split(\".\")[0];\n+//     await monitorPage.importFromFile(\n+//       path.resolve(monitorPage.downloadsFolder, \"monitor\"),\n+//       importFile,\n+//       baseName + \"-imported\",\n+//     );\n \n-    // You'll be dropped at the build page, so hit run and then go back to monitor\n-    await buildPage.runAgent();\n-    await monitorPage.navbar.clickMonitorLink();\n-    await monitorPage.waitForPageLoad();\n+//     // You'll be dropped at the build page, so hit run and then go back to monitor\n+//     await buildPage.runAgent();\n+//     await monitorPage.navbar.clickMonitorLink();\n+//     await monitorPage.waitForPageLoad();\n \n-    const postImportAgents = await monitorPage.listAgents();\n-    await test\n-      .expect(postImportAgents.length)\n-      .toBeGreaterThan(preImportAgents.length);\n-    console.log(`postImportAgents: ${JSON.stringify(postImportAgents)}`);\n-    const importedAgent = postImportAgents.find(\n-      (a: any) => a.name === `${baseName}-imported`,\n-    );\n-    await test.expect(importedAgent).toBeDefined();\n-  });\n+//     const postImportAgents = await monitorPage.listAgents();\n+//     await test\n+//       .expect(postImportAgents.length)\n+//       .toBeGreaterThan(preImportAgents.length);\n+//     console.log(`postImportAgents: ${JSON.stringify(postImportAgents)}`);\n+//     const importedAgent = postImportAgents.find(\n+//       (a: any) => a.name === `${baseName}-imported`,\n+//     );\n+//     await test.expect(importedAgent).toBeDefined();\n+//   });\n \n-  test(\"user can view runs\", async () => {\n-    const runs = await monitorPage.listRuns();\n-    console.log(runs);\n-    // there should be at least one run\n-    await test.expect(runs.length).toBeGreaterThan(0);\n-  });\n-});\n+//   test(\"user can view runs\", async ({ page }) => {\n+//     const runs = await monitorPage.listRuns();\n+//     console.log(runs);\n+//     // there should be at least one run\n+//     await test.expect(runs.length).toBeGreaterThan(0);\n+//   });\n+// });\ndiff --git a/autogpt_platform/frontend/tailwind.config.ts b/autogpt_platform/frontend/tailwind.config.ts\nindex 9f2a706bcd98..7bf88951de4a 100644\n--- a/autogpt_platform/frontend/tailwind.config.ts\n+++ b/autogpt_platform/frontend/tailwind.config.ts\n@@ -1,4 +1,5 @@\n import type { Config } from \"tailwindcss\";\n+import scrollbarHide from \"tailwind-scrollbar-hide\";\n \n const config = {\n   darkMode: [\"class\"],\n@@ -141,7 +142,11 @@ const config = {\n       },\n     },\n   },\n-  plugins: [require(\"tailwindcss-animate\")],\n+  plugins: [\n+    require(\"tailwindcss-animate\"),\n+    scrollbarHide,\n+    require(\"tailwind-scrollbar\"),\n+  ],\n } satisfies Config;\n \n export default config;\n",
    "diff_length": 314421
  },
  {
    "index": 2,
    "filtered_comments": [
      "looks like you [can use this already](https://github.com/NixOS/nixpkgs/compare/master...KiaraGrouwstra:nixpkgs:thefuck-nix-shell) using e.g. an overlay, altho i had a bit of trouble getting it to work out of the box.\r\nspecifically, without adding `doCheck = false;`, i would run into this error:\r\n\r\n```\r\nerror: builder for '/nix/store/rl44gb6qd4x2myclj9i8cpkfrvw6ysqa-thefuck-3.32.drv' failed with exit code 2;\r\n       last 10 log lines:\r\n       > thefuck/system/unix.py:6\r\n       >   /build/source/thefuck/system/unix.py:6: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\r\n       >     from distutils.spawn import find_executable\r\n       >\r\n       > -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n       > =========================== short test summary info ============================\r\n       > ERROR  - ModuleNotFoundError: No module named 'pytest_docker_pexpect'\r\n       > !!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\r\n       > ========================= 1 warning, 1 error in 0.09s ==========================\r\n       > /nix/store/bknngadwym46j65qs14ic2w79rpav888-stdenv-linux/setup: line 1582: pop_var_context: head of shell_variables not a function context\r\n```\r\n\r\ni had tried removing the added test, altho that appeared not to resolve the issue.\r\n",
      "it would seem cool to similarly get an approach using `nix run`, i.e. go from suggesting `nix-shell -p ponysay --run \"ponysay moo\"` to `nix run nixpkgs#ponysay -- moo` - this might eventually help extend beyond just `nixpkgs`.\r\n\r\nedit: https://github.com/KiaraGrouwstra/thefuck/commit/81d6786c80b86f2cc80b3ea90adc214df8266643\r\n",
      "I've been using a custom rule that supports the new [unified CLI](https://zero-to-nix.com/concepts/nix#unified-cli) for a while, and was planning on opening a PR once this one has been merged (I hesitate to update this current PR as it's already tested and ready to be merged). I don't know if that will happen soon, so in the meantime I've pushed the changes to [this](https://github.com/thenbe/thefuck/tree/nix-shell-new) new branch instead, which [builds](https://github.com/thenbe/thefuck/compare/nix-shell...thenbe:thefuck:nix-shell-new) on this here PR. You can use the updated rule by adding it as a [custom rule](https://github.com/nvbn/thefuck?tab=readme-ov-file#creating-your-own-rules) to your config.\r\n\r\nIn the new rule, three variants are suggested. Assuming I run `cowsay hello world`, I am presented with the following:\r\n\r\n1. `nix run nixpkgs#cowsay -- hello world`: This runs my command in a non-interactive shell. Uses the nix unified CLI.\r\n1. `nix shell nixpkgs#cowsay`: This enters an interactive shell with `cowsay` available, but does not run any command. This is useful if you'd rather run the command yourself after entering the shell because your command requires delicate massaging (e.g. running it with `sudo`, prefixing it with environment variable, juggling quote variants, etc).\r\n1. `nix-shell -p cowsay --run \"cowsay hello world\"`. This runs my command in a non-interactive shell. Uses the nix original CLI.\r\n1. `nix shell nixpkgs#cowsay --command cowsay hello world`: Very similar to the first one so I've personally disabled this one.\r\n\r\n### Thoughts on future updates:\r\n\r\n\r\n\r\n- It'd be nice if there was a variant that runs my command and then _keeps me_ in the shell.\r\n  - For the original CLI, we [can](https://nix.dev/manual/nix/2.19/command-ref/nix-shell#options) add a `--command \"echo hello; return\"` to our `nix-shell` invocation.\r\n  - For the unified CLI: not sure yet, we might need to do something like this example from the [docs](https://nix.dev/manual/nix/2.19/command-ref/new-cli/nix3-shell): ` nix shell nixpkgs#gnumake --command sh -c \"cd src && make\"`\r\n- We should expose a couple of flags for users to configure this.\r\n  - `disable_unified_cli` (boolean)\r\n  - `disable_original_cli` (boolean)\r\n- As far as I can tell, the `command-not-found` db doesn't really play nice if you use flakes to configure your system and might return stale results (unless you update it manually?). [`nix-index`](https://github.com/nix-community/nix-index) seems to be the go-to alternative. It'd be great if we could optionally use that instead (perhaps behind a flag `enable_nix_index` for users who have installed `nix-index` (`programs.nix-index.enable = true;` in home manager).",
      "@thenbe i agree integrating with `nix-index`'s `command-not-found` replacement seems cool, as a flake user.\r\ni kinda wish we could have `command-not-found` (and this `thefuck` integration) [extend to flake inputs beyond nixpkgs](https://github.com/nix-community/nix-index/issues/244) as well, such as to packages from NUR for example. preferably this should be dynamic based on your inputs rather than hardcoded to specific ones like nixpkgs, or NUR for that matter.\r\ni'll admit i haven't really figured out how that might work tho.",
      "just tried these with a command like `program_i_have | program_i_dont_have`, seems that may complicate the suggestions a bit",
      "@thenbe hm, i'm not sure.\r\n\r\n```\r\nfortune | cowsay\r\nThe program 'cowsay' is not in your PATH. It is provided by several packages.\r\nYou can make it available in an ephemeral shell by typing one of the following:\r\n  nix-shell -p cowsay\r\n  nix-shell -p neo-cowsay\r\n$ fuck\r\nnix run nixpkgs#fortune | cowsay\r\n```\r\n\r\nfeels like it knows about the whole command given it's reproducing it?\r\n",
      "another common nix thing we might be able to address from `thefuck` would be errors about packages being unfree\r\n\r\nedit: https://github.com/KiaraGrouwstra/thefuck/commit/16d838bf6f63117b161a2f1e6572e06108b007eb\r\n",
      "If I'm only looking to execute a program (and don't need to be dropped into a shell) then I prefer `nix run` over `nix shell` as the [documentation](https://nix.dev/manual/nix/2.19/command-ref/new-cli/nix3-run) suggests `nix run` specifically for this use case.\r\n\r\nI also recall `nix run` being more performant (perhaps because we forego the overhead of launching a shell?). This last point is not derived from benchmarks, only anecdotal evidence.\r\n\r\n> i guess the latter seems a bit more generic in case of handling non-standard binaries at least\r\n\r\nI've added this variant (the 4th one in my [previous post](https://github.com/nvbn/thefuck/pull/1393#issuecomment-1961487094)), but disabled it after a while when I realized that I never reach for it. Do you find that you still need it over `nix run` (the 1st variant in my previous post)?",
      "> another common nix thing we might be able to address from `thefuck` would be errors about packages being unfree\r\n> \r\n> edit: [KiaraGrouwstra@16d838b](https://github.com/KiaraGrouwstra/thefuck/commit/16d838bf6f63117b161a2f1e6572e06108b007eb)\r\n\r\nThis would be useful. Does it still complain about the `--impure` flag? Or do you use a workaround for that?",
      "I just have it aliased to `f` for extra convenience.\r\n\r\nI opted not to package it for nix separately since `fuck` already exposes a method for easily adding custom rules. Instead, I placed the rule in `~/mydotfiles/thefuck/rules/nix-shell.py` then told home-manager to symlink it to the appropriate place in `.config`:\r\n\r\n```nix\r\n# home.nix\r\nhome.file.\".config/thefuck/rules/nix-shell.py\".source = config.lib.file.mkOutOfStoreSymlink \"${config.home.homeDirectory}/mydotfiles/thefuck/rules/nix-shell.py\";\r\n```\r\n\r\nThis way I don't need to rebuild every time I tweak the rule.\r\n\r\n> what was the --impure error?\r\n\r\nThe unified CLI commands (`nix shell`, `nix run`, etc) will not acknowledge environment variables unless the `--impure` flag is used.\r\n\r\n<details>\r\n  <summary> output </summary>\r\n\r\n```\r\n$ NIXPKGS_ALLOW_UNFREE=1 nix shell nixpkgs#github-copilot-cli\r\n\r\nerror:\r\n       … in the condition of the assert statement\r\n\r\n         at /nix/store/xwc3zfc544jg6zhr0wi6k8253s7mwlhi-source/lib/customisation.nix:267:17:\r\n\r\n          266|     in commonAttrs // {\r\n          267|       drvPath = assert condition; drv.drvPath;\r\n             |                 ^\r\n          268|       outPath = assert condition; drv.outPath;\r\n\r\n       … while evaluating the attribute 'handled'\r\n\r\n         at /nix/store/xwc3zfc544jg6zhr0wi6k8253s7mwlhi-source/pkgs/stdenv/generic/check-meta.nix:490:7:\r\n\r\n          489|       # or, alternatively, just output a warning message.\r\n          490|       handled =\r\n             |       ^\r\n          491|         (\r\n\r\n       (stack trace truncated; use '--show-trace' to show the full trace)\r\n\r\n       error: Package ‘github-copilot-cli-0.1.36’ in /nix/store/xwc3zfc544jg6zhr0wi6k8253s7mwlhi-source/pkgs/tools/misc/github-copilot-cli/default.nix:21 has\r\n an unfree license (‘unfree’), refusing to evaluate.\r\n\r\n       a) To temporarily allow unfree packages, you can use an environment variable\r\n          for a single invocation of the nix tools.\r\n\r\n            $ export NIXPKGS_ALLOW_UNFREE=1\r\n\r\n          Note: When using `nix shell`, `nix build`, `nix develop`, etc with a flake,\r\n                then pass `--impure` in order to allow use of environment variables.\r\n\r\n       b) For `nixos-rebuild` you can set\r\n         { nixpkgs.config.allowUnfree = true; }\r\n       in configuration.nix to override this.\r\n\r\n       Alternatively you can configure a predicate to allow specific packages:\r\n         { nixpkgs.config.allowUnfreePredicate = pkg: builtins.elem (lib.getName pkg) [\r\n             \"github-copilot-cli-0.1.36\"\r\n           ];\r\n         }\r\n\r\n       c) For `nix-env`, `nix-build`, `nix-shell` or any other Nix command you can add\r\n         { allowUnfree = true; }\r\n       to ~/.config/nixpkgs/config.nix.\r\n\r\n\r\n```\r\n```bash\r\n# it wants this instead:\r\n$ NIXPKGS_ALLOW_UNFREE=1 nix shell nixpkgs#github-copilot-cli --impure\r\n```\r\n\r\n</details>\r\n"
    ],
    "code_diff": "diff --git a/README.md b/README.md\nindex 48b4b0fb3..724dc3569 100644\n--- a/README.md\n+++ b/README.md\n@@ -367,6 +367,7 @@ The following rules are enabled by default on specific platforms only:\n * `brew_update_formula` &ndash; turns `brew update <formula>` into `brew upgrade <formula>`;\n * `dnf_no_such_command` &ndash; fixes mistyped DNF commands;\n * `nixos_cmd_not_found` &ndash; installs apps on NixOS;\n+* `nix_shell` &ndash; re-runs your command in a `nix-shell`;\n * `pacman` &ndash; installs app with `pacman` if it is not installed (uses `yay`, `pikaur` or `yaourt` if available);\n * `pacman_invalid_option` &ndash; replaces lowercase `pacman` options with uppercase.\n * `pacman_not_found` &ndash; fixes package name with `pacman`, `yay`, `pikaur` or `yaourt`.\ndiff --git a/tests/rules/test_nix_shell.py b/tests/rules/test_nix_shell.py\nnew file mode 100644\nindex 000000000..69ba14872\n--- /dev/null\n+++ b/tests/rules/test_nix_shell.py\n@@ -0,0 +1,90 @@\n+import pytest\n+from thefuck.rules.nix_shell import get_nixpkgs_names, match, get_new_command\n+from thefuck.types import Command\n+from unittest.mock import patch, MagicMock\n+\n+\n+@pytest.mark.parametrize(\n+    \"script,output,nixpkgs_names\",\n+    [\n+        # output can be retrived by running `THEFUCK_DEBUG=true thefuck lsof`\n+        (\n+            \"lsof\",\n+            \"/nix/store/p6dlr3skfhxpyphipg2bqnj52999banh-bash-5.2-p15/bin/sh: line 1: lsof: command not found\",\n+            [\"lsof\"],\n+        ),\n+    ],\n+)\n+def test_match(script, output, nixpkgs_names):\n+    with patch(\"thefuck.rules.nix_shell.get_nixpkgs_names\") as mocked_get_nixpkgs_names:\n+        mocked_get_nixpkgs_names.return_value = nixpkgs_names\n+        command = Command(script, output)\n+        assert match(command)\n+\n+\n+@pytest.mark.parametrize(\n+    \"script,output,nixpkgs_names\",\n+    [\n+        # output can be retrived by running `THEFUCK_DEBUG=true thefuck foo`\n+        (\n+            \"foo\",\n+            \"/nix/store/p6dlr3skfhxpyphipg2bqnj52999banh-bash-5.2-p15/bin/sh: line 1: foo: command not found\",\n+            [],\n+        ),\n+    ],\n+)\n+def test_not_match(script, output, nixpkgs_names):\n+    with patch(\"thefuck.rules.nix_shell.get_nixpkgs_names\") as mocked_get_nixpkgs_names:\n+        mocked_get_nixpkgs_names.return_value = nixpkgs_names\n+        command = Command(script, output)\n+        assert not match(command)\n+\n+\n+@pytest.mark.parametrize(\n+    \"script,nixpkgs_names,new_command\",\n+    [\n+        (\n+            \"lsof -i :3000\",\n+            [\"busybox\", \"lsof\"],\n+            [\n+                'nix-shell -p busybox --run \"lsof -i :3000\"',\n+                'nix-shell -p lsof --run \"lsof -i :3000\"',\n+            ],\n+        ),\n+        (\"xev\", [\"xorg.xev\"], ['nix-shell -p xorg.xev --run \"xev\"']),\n+    ],\n+)\n+def test_get_new_command(script, nixpkgs_names, new_command):\n+    \"\"\"Check that flags and params are preserved in the new command\"\"\"\n+\n+    command = Command(script, \"\")\n+    with patch(\"thefuck.rules.nix_shell.get_nixpkgs_names\") as mocked_get_nixpkgs_names:\n+        mocked_get_nixpkgs_names.return_value = nixpkgs_names\n+        assert get_new_command(command) == new_command\n+\n+\n+# Mocks the stderr of `command-not-found QUERY`. Mock values are retrieved by\n+# running `THEFUCK_DEBUG=true thefuck command-not-found lsof`.\n+mocked_cnf_stderr = {\n+    \"lsof\": \"The program 'lsof' is not in your PATH. It is provided by several packages.\\nYou can make it available in an ephemeral shell by typing one of the following:\\n  nix-shell -p busybox\\n  nix-shell -p lsof\",\n+    \"xev\": \"The program 'xev' is not in your PATH. You can make it available in an ephemeral shell by typing:\\n  nix-shell -p xorg.xev\",\n+    \"foo\": \"foo: command not found\",\n+}\n+\n+\n+@pytest.mark.parametrize(\n+    \"bin,expected_nixpkgs_names,cnf_stderr\",\n+    [\n+        (\"lsof\", [\"busybox\", \"lsof\"], mocked_cnf_stderr[\"lsof\"]),\n+        (\"xev\", [\"xorg.xev\"], mocked_cnf_stderr[\"xev\"]),\n+        (\"foo\", [], mocked_cnf_stderr[\"foo\"]),\n+    ],\n+)\n+def test_get_nixpkgs_names(bin, expected_nixpkgs_names, cnf_stderr):\n+    \"\"\"Check that `get_nixpkgs_names` returns the correct names\"\"\"\n+\n+    with patch(\"subprocess.run\") as mocked_run:\n+        result = MagicMock()\n+        result.stderr = cnf_stderr\n+        mocked_run.return_value = result\n+        assert get_nixpkgs_names(bin) == expected_nixpkgs_names\ndiff --git a/thefuck/rules/nix_shell.py b/thefuck/rules/nix_shell.py\nnew file mode 100644\nindex 000000000..7bfba7eac\n--- /dev/null\n+++ b/thefuck/rules/nix_shell.py\n@@ -0,0 +1,51 @@\n+from thefuck.specific.nix import nix_available\n+import subprocess\n+\n+enabled_by_default = nix_available\n+\n+# Set the priority just ahead of `fix_file` rule, which can generate low quality matches due\n+# to the sheer amount of paths in the nix store.\n+priority = 999\n+\n+\n+def get_nixpkgs_names(bin):\n+    \"\"\"\n+    Returns the name of the Nix package that provides the given binary. It uses the\n+    `command-not-found` binary to do so, which is how nix-shell generates it's own suggestions.\n+    \"\"\"\n+\n+    result = subprocess.run(\n+        [\"command-not-found\", bin], stderr=subprocess.PIPE, universal_newlines=True\n+    )\n+\n+    # The suggestion, if any, will be found in stderr. Upstream definition: https://github.com/NixOS/nixpkgs/blob/b6fbd87328f8eabd82d65cc8f75dfb74341b0ace/nixos/modules/programs/command-not-found/command-not-found.nix#L48-L90\n+    text = result.stderr\n+\n+    # return early if binary is not available through nix\n+    if \"nix-shell\" not in text:\n+        return []\n+\n+    nixpkgs_names = [\n+        line.split()[-1] for line in text.splitlines() if \"nix-shell -p\" in line\n+    ]\n+    return nixpkgs_names\n+\n+\n+def match(command):\n+    bin = command.script_parts[0]\n+    return (\n+        \"command not found\" in command.output  # only match commands which had exit code: 127                   # noqa: E501\n+        and get_nixpkgs_names(bin)             # only match commands which could be made available through nix  # noqa: E501\n+    )\n+\n+\n+def get_new_command(command):\n+    bin = command.script_parts[0]\n+    nixpkgs_names = get_nixpkgs_names(bin)\n+\n+    # Construct a command for each package name\n+    commands = [\n+        'nix-shell -p {} --run \"{}\"'.format(name, command.script)\n+        for name in nixpkgs_names\n+    ]\n+    return commands\n",
    "diff_length": 6305
  },
  {
    "index": 3,
    "filtered_comments": [
      "I'm getting this error when try to use MPS\r\n\r\n/Users/diego/.pyenv/versions/3.10.6/lib/python3.10/site-packages/whisper-1.0-py3.10.egg/whisper/decoding.py:629: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/diego/Projects/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/2d9b4df9-4b93-11ed-b0fc-2e32217d8374/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 23200 bytes\r\n'\r\nAbort trap: 6\r\n/Users/diego/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n\r\nany clues?",
      "@DiegoGiovany Not an expert on this but It looks like PyTorch itself is missing some operators for MPS. See for example\r\nhttps://github.com/pytorch/pytorch/issues/77764#issuecomment-1254352628\r\n(which refers to repeat_interleave)\r\n\r\nand\r\nhttps://github.com/pytorch/pytorch/issues/87219\r\n",
      "Thanks for your work. I just tried this. Unfortunately, it didn't work for me on my m1 max with 32GB.\r\nHere is what I did:\r\npip install git+https://github.com/openai/whisper.git@refs/pull/382/head\r\n\r\nNo errors on install and it works fine when run without mps: whisper audiofile_name --model medium \r\n\r\nWhen I run: whisper audiofile_name --model medium --device mps\r\n\r\nHere is the error I get:\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/810eba08-405a-11ed-86e9-6af958a02716/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1024x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s). \r\n\r\nWhen I run:  whisper audiofile_name --model medium --device mps --fp16 False\r\n\r\nHere is the error I get:\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nDetected language: English\r\n/anaconda3/lib/python3.9/site-packages/whisper/decoding.py:633: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/f0468ab4-4115-11ed-8edc-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 1007280 bytes\r\n\r\nBasically, same error as @DiegoGiovany.\r\n\r\nAny ideas on how to fix?",
      "@dwarkeshsp \r\n\r\nnot work，with mbp2015 pytorch 1.3 stable，egpu RX580, MacOS 12.3.\r\n\r\nchanged the code as the same as yours.\r\n\r\nchanged  to use --device mps but show error, maybe there is still somewhere to change or modify.\r\n\r\nuse --device cpu, it works.\r\n\r\nwith other pytorch-metal project, MPS works.",
      "I also see the same errors as others mentioned above, on an M1 Mac running arm64 Python. ",
      "On an M1 16\" MBP with 16GB running MacOS 13.0.1, I'm seeing the following with `openai-whisper-20230117`:\r\n\r\nUsing this command:\r\n```(venv) whisper_ai_playground % whisper './test_file.mp3' --model tiny.en --output_dir ./output --device mps```\r\n\r\nI'm encountering the following errors:\r\n\r\n```loc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/810eba08-405a-11ed-86e9-6af958a02716/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x384x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible```\r\n\r\n```LLVM ERROR: Failed to infer result type(s).```\r\n\r\n```zsh: abort      whisper  --model tiny.en --output_dir ./output --device mps```\r\n\r\n```/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '```",
      "Same problem with osx 13.2 in MacBook Pro M2 max:\r\n\r\n```\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1280x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\nzsh: abort      whisper audio.wav --language en --model large\r\nm2@Render ~ % /opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
      "I'm getting the same error as @renderpci using the M1 Base Model\r\n```bash\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x512x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\n[1]    3746 abort      python3 test.py\r\n```\r\n**test.py:**\r\n```py\r\nimport whisper\r\n\r\nmodel = whisper.load_model(\"base\")\r\nresult = model.transcribe(\"audio.mp3\")\r\nprint(result[\"text\"])\r\n```",
      "FWIW I switched to the C++ port https://github.com/ggerganov/whisper.cpp/ and got a ~15x speedup compared to CPU pytorch on my M1 Pro. (But note that it doesn't have all the features/flags from the official whisper repo.)",
      "> FWIW I switched to the C++ port https://github.com/ggerganov/whisper.cpp/ \r\n\r\nFor us whisper.cpp is not an option:\r\n\r\n> **Should I use whisper.cpp in my project?**\r\n> \r\n> whisper.cpp is a hobby project. It does not strive to provide a production ready implementation. The main goals of the implementation is to be educational, minimalistic, portable, hackable and performant. There are no guarantees that the implementation is correct and bug-free and stuff can break at any point in the future. Support and updates will depend mostly on contributions, since with time I will move on and won't dedicate too much time on the project.\r\n> \r\n> If you plan to use whisper.cpp in your own project, keep in mind the above.\r\n> My advice is to not put all your eggs into the whisper.cpp basket.",
      "The same error as @renderpci using the M2\r\n\r\n\r\nwhisper interview.mp4 --language en --model large --device mps\r\n\r\n```\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1280x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\nzsh: abort      whisper interview.mp4 --language en --model large --device mps\r\npac@dd ~ % /opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
      "Hey @devpacdd  - this should be fixed in latest pytorch nightly (pip3 install --pre --force-reinstall torch --index-url https://download.pytorch.org/whl/nightly/cpu). Let me know if you still see any issues. Thanks",
      "Still have the same error after updating\r\n\r\nEdit: After adding `--fp16 False` to the command, I now get a new error, as well as the old one:\r\n```\r\n/opt/homebrew/lib/python3.10/site-packages/whisper/decoding.py:633: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/5b8a32f9-5db2-11ed-8aeb-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 1007280 bytes\r\n'\r\nzsh: abort      whisper --model large --language de --task transcribe  --device mps --fp16\r\n/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
      "i was able to get it to kinda work: https://github.com/davabase/whisper_real_time/issues/5#issue-1596258783",
      "> The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n>   audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n\r\n@manuthebyte could you please make sure you are on a recent nightly? `repeat_interleave` should be natively supported. If you could try grabbing today's nightly and give a try that would be awesome! (You can get today's nightly with `pip3 install --pre --force-reinstall torch==2.0.0.dev20230224 --index-url https://download.pytorch.org/whl/nightly/cpu`)\r\n\r\n",
      "Wow! \r\n\r\nwhen running:\r\n`Python3 transcribe_demo.py --model medium` (from https://github.com/davabase/whisper_real_time)\r\n\r\nwith the following packages in my pipenv's requirements.txt\r\n```\r\ncertifi==2022.12.7\r\ncharset-normalizer==3.0.1\r\nffmpeg-python==0.2.0\r\nfilelock==3.9.0\r\nfuture==0.18.3\r\nhuggingface-hub==0.12.1\r\nidna==3.4\r\nmore-itertools==9.0.0\r\nmpmath==1.2.1\r\nnetworkx==3.0rc1\r\nnumpy==1.24.2\r\nopenai-whisper @ git+https://github.com/openai/whisper.git@51c785f7c91b8c032a1fa79c0e8f862dea81b860\r\npackaging==23.0\r\nPillow==9.4.0\r\nPyAudio==0.2.13\r\nPyYAML==6.0\r\nregex==2022.10.31\r\nrequests==2.28.2\r\nSpeechRecognition==3.9.0\r\nsympy==1.11.1\r\ntokenizers==0.13.2\r\ntorch==2.0.0.dev20230224\r\ntorchaudio==0.13.1\r\ntorchvision==0.14.1\r\ntqdm==4.64.1\r\ntransformers==4.26.1\r\ntyping_extensions==4.4.0\r\nurllib3==1.26.14\r\n```\r\n\r\nit gets every word! while i was singing! in realtime, with maybe 50%~ gpu usage on the apple M2 Pro Max.",
      "> > The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n> > audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n> \r\n> @manuthebyte could you please make sure you are on a recent nightly? `repeat_interleave` should be natively supported. If you could try grabbing today's nightly and give a try that would be awesome! (You can get today's nightly with `pip3 install --pre --force-reinstall torch==2.0.0.dev20230224 --index-url https://download.pytorch.org/whl/nightly/cpu`)\r\n\r\nWith my pip3 freeze being:\r\n```\r\nbeautifulsoup4==4.11.2\r\ncertifi==2022.12.7\r\ncharset-normalizer==3.0.1\r\ncolorama==0.4.6\r\ndnspython==2.3.0\r\nffmpeg-python==0.2.0\r\nfilelock==3.9.0\r\nfuture==0.18.3\r\nhuggingface-hub==0.12.1\r\nidna==3.4\r\nmore-itertools==9.0.0\r\nmpmath==1.2.1\r\nnetworkx==3.0rc1\r\nnumpy==1.24.2\r\nopenai-whisper @ git+https://github.com/openai/whisper.git@7858aa9c08d98f75575035ecd6481f462d66ca27\r\npackaging==23.0\r\nprotobuf==4.21.12\r\nPyYAML==6.0\r\nregex==2022.10.31\r\nrequests==2.28.2\r\nsix==1.16.0\r\nsoupsieve==2.4\r\nsympy==1.11.1\r\ntokenizers==0.13.2\r\ntorch==2.0.0.dev20230224\r\ntqdm==4.64.1\r\ntransformers==4.26.1\r\ntyping_extensions==4.4.0\r\nurllib3==1.26.14\r\n```\r\n\r\nIt now seems to use the GPU but I now get these errors:\r\n```\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:636: UserWarning: 0MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:443: UserWarning: 1MPS: no support for int64 reduction ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:143.)\r\n  timestamp_logprob = logprobs[k, self.tokenizer.timestamp_begin :].logsumexp(dim=-1)\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:444: UserWarning: 1MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:1269.)\r\n  max_text_token_logprob = logprobs[k, : self.tokenizer.timestamp_begin].max()\r\nTraceback (most recent call last):\r\n  File \"/opt/homebrew/bin/whisper\", line 8, in <module>\r\n    sys.exit(cli())\r\n             ^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 314, in cli\r\n    result = transcribe(model, audio_path, temperature=temperature, **args)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 183, in transcribe\r\n    result: DecodingResult = decode_with_fallback(segment)\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 118, in decode_with_fallback\r\n    decode_result = model.decode(segment, options)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 707, in decode\r\n    result = DecodingTask(model, options).run(mel)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 640, in run\r\n    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\r\n                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 609, in _main_loop\r\n    tokens, completed = self.decoder.update(tokens, logits, sum_logprobs)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 258, in update\r\n    next_tokens = Categorical(logits=logits / self.temperature).sample()\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/distributions/categorical.py\", line 66, in __init__\r\n    super().__init__(batch_shape, validate_args=validate_args)\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/distributions/distribution.py\", line 62, in __init__\r\n    raise ValueError(\r\nValueError: Expected parameter logits (Tensor of shape (5, 51865)) of distribution Categorical(logits: torch.Size([5, 51865])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\r\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan]], device='mps:0')\r\n```\r\n\r\nWhen running the command `whisper --model small --language en --task transcribe ***.wav --device mps`",
      "> Hey @devpacdd - this should be fixed in latest pytorch nightly (pip3 install --pre --force-reinstall torch --index-url https://download.pytorch.org/whl/nightly/cpu). Let me know if you still see any issues. Thanks\r\n\r\nGeart! it works!\r\nBut.. In my test the GPU is slow than CPU... ??? \r\n\r\nAudio to transcribe: 1 minute with model large, language catalan\r\n\r\nCPU  : 2m : 33 s\r\nGPU (--device mps): 4m : 54 s\r\n\r\nI tried with different files and the result was the same; +/- double time with GPU enable.\r\n\r\nIt's normal? I expected less time for GPU than CPU.\r\n\r\nBest",
      "I get this error while trying to use MPS\r\n\r\nHere is the command I am running: `whisper --model large --language en --task transcribe test.mp3 --device mps`\r\n\r\n```\r\n$ whisper --model large --language en --task transcribe test.mp3 --device mps\r\nTraceback (most recent call last):\r\n  File \"/Users/mukul/miniconda3/envs/ml/bin/whisper\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/whisper/transcribe.py\", line 433, in cli\r\n    model = load_model(model_name, device=device, download_root=model_dir)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/whisper/__init__.py\", line 159, in load_model\r\n    return model.to(device)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1170, in to\r\n    return self._apply(convert)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 869, in _apply\r\n    self._buffers[key] = fn(buf)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1168, in convert\r\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\r\nNotImplementedError: Could not run 'aten::empty.memory_format' with arguments from the 'SparseMPS' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty.memory_format' is only available for these backends: [CPU, MPS, Meta, QuantizedCPU, QuantizedMeta, MkldnnCPU, SparseCPU, SparseMeta, SparseCsrCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\r\n\r\nCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterCPU.cpp:31085 [kernel]\r\nMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMPS.cpp:24065 [kernel]\r\nMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26824 [kernel]\r\nQuantizedCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\r\nQuantizedMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterQuantizedMeta.cpp:105 [kernel]\r\nMkldnnCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMkldnnCPU.cpp:507 [kernel]\r\nSparseCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseCPU.cpp:1379 [kernel]\r\nSparseMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\r\nSparseCsrCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseCsrCPU.cpp:1128 [kernel]\r\nBackendSelect: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterBackendSelect.cpp:734 [kernel]\r\nPython: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\r\nFuncTorchDynamicLayerBackMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\r\nFunctionalize: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:290 [backend fallback]\r\nNamed: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\r\nConjugate: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\r\nNegative: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/NegateFallback.cpp:23 [kernel]\r\nZeroTensor: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:90 [kernel]\r\nADInplaceOrView: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\r\nAutogradOther: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradCUDA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradHIP: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradXLA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradIPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradXPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradHPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradVE: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradLazy: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMTIA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse1: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse2: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse3: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradNestedTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nTracer: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:16872 [kernel]\r\nAutocastCPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\r\nAutocastCUDA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\r\nFuncTorchBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:815 [backend fallback]\r\nFuncTorchVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\r\nBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1073 [backend fallback]\r\nVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\nFuncTorchGradWrapper: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\r\nPythonTLSSnapshot: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\r\nFuncTorchDynamicLayerFrontMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\r\nPythonDispatcher: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\r\n```",
      "@mukulpatnaik \r\nMy device is M1 MacBook Pro, I got the same error with the latest version of whisper([v20230314](https://github.com/openai/whisper/releases/tag/v20230314)), then I switch to [v20230124](https://github.com/openai/whisper/releases/tag/v20230124), every thing works fine. (torch nightly version)\r\n\r\nBut, seems like mps is slower than cpu like @renderpci reported, for my task\r\n* cpu 3.26 s\r\n* mps 5.25 s\r\n* cpu+torch2 compile 3.31 s\r\n* mps+torch2 compile 4.94 s\r\n\r\n🫠"
    ],
    "code_diff": "diff --git a/whisper/__init__.py b/whisper/__init__.py\nindex 2a1fb4ec6..4f45f9969 100644\n--- a/whisper/__init__.py\n+++ b/whisper/__init__.py\n@@ -92,7 +92,12 @@ def load_model(name: str, device: Optional[Union[str, torch.device]] = None, dow\n     \"\"\"\n \n     if device is None:\n-        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n+        if torch.cuda.is_available():\n+            device = \"cuda\"\n+        elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n+            device = \"mps\"\n+        else:\n+            device = \"cpu\"\n     if download_root is None:\n         download_root = os.getenv(\n             \"XDG_CACHE_HOME\", \ndiff --git a/whisper/transcribe.py b/whisper/transcribe.py\nindex d95d3336d..0d89a5d77 100644\n--- a/whisper/transcribe.py\n+++ b/whisper/transcribe.py\n@@ -75,6 +75,8 @@ def transcribe(\n     if model.device == torch.device(\"cpu\"):\n         if torch.cuda.is_available():\n             warnings.warn(\"Performing inference on CPU when CUDA is available\")\n+        if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n+            warnings.warn(\"Performing inference on CPU when MPS is available\")\n         if dtype == torch.float16:\n             warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n             dtype = torch.float32\n",
    "diff_length": 1323
  },
  {
    "index": 4,
    "filtered_comments": [
      "Testing on another example from https://github.com/openai/whisper/discussions/679#discussioncomment-7649183\r\n\r\n<details>\r\n<summary>Output</summary>\r\n\r\n```\r\nv2 runs:\r\n\r\n[00:00.000 --> 00:05.660]  spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo\r\nDETECTED HALLUCINATION:  non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho\r\nDETECTED HALLUCINATION:  no\r\nDETECTED HALLUCINATION:  no\r\n\r\n\r\n\r\n[00:00.000 --> 00:05.660]  spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo\r\nDETECTED HALLUCINATION:  non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho\r\nDETECTED HALLUCINATION:  .....\r\nDETECTED HALLUCINATION:  .....\r\n\r\n\r\n\r\n[00:00.000 --> 00:05.660]  spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo\r\nDETECTED HALLUCINATION:  non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho\r\nDETECTED HALLUCINATION:  uh\r\nDETECTED HALLUCINATION:  uh\r\n\r\n\r\n\r\nv3 run:\r\n\r\n[00:00.000 --> 00:04.240]  Spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo.\r\nDETECTED HALLUCINATION:  Grazie a tutti.\r\nDETECTED HALLUCINATION:  E' un attimo che non dovevo.\r\n[00:54.440 --> 00:55.700]  Ehm, ehm.\r\n```",
      "I don't have the exact code anymore, but you could try temporarily inserting these two lines:\r\n\r\n```python\r\n                if score >= 3 or score + 0.01 >= len(words):\r\n                    print(f\"DETECTED HALLUCINATION: {segment['text']}\")\r\n```\r\n\r\nbefore the return in this function:\r\n\r\n```python\r\n            def is_segment_anomaly(segment: Optional[dict]) -> bool:\r\n                if segment is None or not segment[\"words\"]:\r\n                    return False\r\n                words = [w for w in segment[\"words\"] if w[\"word\"] not in punctuation]\r\n                words = words[:8]\r\n                score = sum(word_anomaly_score(w) for w in words)\r\n                return score >= 3 or score + 0.01 >= len(words)\r\n```",
      "@ryanheise\r\nSometimes `--hallucination_silence_threshold` makes whole non-hallucinating segments or part of segments disappear.\r\n\r\nBelow is example with disappeared `orange pigmentation.` segment.\r\n\r\nI'm using faster-whisper, but you should be able to reproduce it with whisper too as implementation is same.\r\nAudio file -> https://we.tl/t-U5a6Al5bRs\r\n\r\n\r\n`--language en --model=base --beam_size=5 --word_timestamps=True --hallucination_silence_threshold=None`:\r\n\r\n```\r\n[02:06.620 --> 02:11.120]  White tigers carry a mutated version of this gene, which prevents them from producing\r\n  Processing segment at 02:11.120\r\n[02:11.120 --> 02:12.460]  orange pigmentation.\r\n[02:15.360 --> 02:18.340]  Fewer than 4,000 tigers remain in the wild.\r\n```\r\n\r\n`--language en --model=base --beam_size=5 --word_timestamps=True --hallucination_silence_threshold=2`:\r\n\r\n```\r\n[02:06.620 --> 02:11.120]  White tigers carry a mutated version of this gene, which prevents them from producing\r\n  Processing segment at 02:12.380\r\n* HST_1: Skipping silence before possible hallucinations.\r\n* HST_3: DETECTED HALLUCINATION:  oxygen.\r\n  Processing segment at 02:13.380\r\n* HST_1: Skipping silence before possible hallucinations.\r\n[02:14.680 --> 02:18.360]  fewer than 4,000 tigers remain in the wild.\r\n```\r\n\r\nEDIT:\r\nfloat32 was in use",
      "I think, I've noticed a pattern, it happens when `if remaining_duration > threshold:` is not triggered, in there:\r\n`seek = previous_seek + segment_size`\r\n\r\nThen chunk go exactly by 30 secs cutting off the word.\r\n\r\nChunking when `--hallucination_silence_threshold=None`:\r\n\r\n```\r\n  Processing segment at 00:00.000\r\n  Processing segment at 00:26.040\r\n  Processing segment at 00:48.280\r\n  Processing segment at 01:14.400\r\n  Processing segment at 01:42.380\r\n  Processing segment at 02:11.120\r\n  Processing segment at 02:35.400\r\n  Processing segment at 03:05.400\r\n```\r\nChunking by setting high threshold `--hallucination_silence_threshold=40`:\r\n```\r\n  Processing segment at 00:00.000\r\n  Processing segment at 00:30.000\r\n  Processing segment at 01:00.000\r\n  Processing segment at 01:30.000\r\n  Processing segment at 02:00.000\r\n  Processing segment at 02:30.000\r\n  Processing segment at 03:00.000\r\n```",
      "Another thing, this PR affects transcription even if both new parameters are not enabled, I meant comparing vs without this PR.\r\n\r\nThis happens sometimes, but when it happens the discrepancy is always in the last chunk.\r\n\r\nAnd sometimes when discrepancy happens it tries to process additional micro chunk after it which produces some hallucination or fails because no-speech threshold is met, not sure if this is related to PR or to a discrepancy.\r\n\r\nExample of such discrepancy [audio is `05:05.877` long]:\r\n\r\nWithout this PR [perfect transcription]:\r\n```\r\nProcessing segment at 04:48.000\r\n[04:58.120 --> 05:05.260]  I just...\r\n[05:05.260 --> 05:05.760]  I...\r\n```\r\n\r\nWith this PR [all goes exactly same till the last chunk]:\r\n\r\n```\r\n  Processing segment at 04:48.000\r\n* Compression ratio threshold is not met with temperature 0.0 (3.523810 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.2 (3.523810 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.4 (8.038462 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.6 (3.523810 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.8 (2.423077 > 2.400000)\r\n[05:01.940 --> 05:02.900]  Okay.\r\n[05:02.900 --> 05:04.000]  I just-\r\n[05:04.940 --> 05:05.740]  I-\r\n[05:05.740 --> 05:05.840]  I-\r\n* Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000\r\n  Processing segment at 05:05.840\r\n* Log probability threshold is not met with temperature 0.0 (-1.105777 < -1.000000)\r\n* No speech threshold is met (0.772002 > 0.600000)\r\n```",
      "> Sometimes `--hallucination_silence_threshold` makes whole non-hallucinating segments or part of segments disappear.\r\n\r\nThis logic is part of the original Whisper strategy of advancing by the full 30 seconds to the next window whenever the current segment is unfinished. So basically, if the segment finishes before the end of the 30 second window, then Whisper will crop the window to the exact end timestamp of the last word in that segment. But if the segment does not finish by the end of the 30 second window, the window is not cropped, the speech is assumed to run all the way to the end of the window.\r\n\r\nThis logic exists whether or not the `hallucination_silence_threshold` is enabled, and I have seen it cause problems in both cases, however the larger models tend to be better at picking up the words across the window boundary.\r\n\r\nIn your case, the sentence in question is:\r\n\r\n> White tigers carry a mutated version of this gene, which prevents them from producing orange pigmentation.\r\n\r\nThis sentence does not fit within the 30 second window, and the word \"orange\" is right on the boundary. In fact, the word \"orange\" is slightly before the boundary and the human ear can pick it up (as can the larger models) but the smaller models fail to pick it up.\r\n\r\nAnd given Whisper's logic in this case, it will assume the speech went right up to the end of the 30 second window and will resume the next window from there.\r\n\r\nSo although yes the large models would probably resolve this, I think it would still be better to change Whisper's strategy and crop the window to the end timestamp of the last word even in this case where we have an unfinished segment.",
      "> This logic is part of the original Whisper strategy of advancing by the full 30 seconds to the next window whenever the current segment is unfinished.\r\n\r\nI can't connect the dots...\r\nThen why it's \"unfinished\" when using `hallucination_silence_threshold` and it's \"finished\" without it?\r\n\r\nHow `remaining_duration <= hallucination_silence_threshold` means an \"unfinished\" segment? The option doesn't read as \"finished/unfinished segment threshold\"....\r\n",
      "Apologies, my explanation of that was around the wrong way. The original Whisper behaviour was that if the last segment in the window is \"complete\", THEN it skips to the end of the full 30 second window. If the last segment is incomplete, then it crops the window to end timestamp of the last word.\r\n\r\nBut when `hallucination_silence_threshold` is set, it still applies this logic in most cases except that it also includes a misfired heuristic that skips to the end of the full 30 second window if the end of the speech is close enough to the end of the window:\r\n\r\n```python\r\n                # skip silence before possible hallucinations\r\n                if hallucination_silence_threshold is not None:\r\n                    threshold = hallucination_silence_threshold\r\n                    if not single_timestamp_ending:\r\n                        last_word_end = get_end(current_segments)\r\n                        if last_word_end is not None and last_word_end > time_offset:\r\n                            remaining_duration = window_end_time - last_word_end\r\n                            if remaining_duration > threshold:  # <--- misfired heuristic\r\n                                seek = round(last_word_end * FRAMES_PER_SECOND)\r\n                            else:\r\n                                seek = previous_seek + segment_size\r\n````\r\n\r\nThe goal was to skip over as much silence as safely possible.\r\n\r\nHowever, in hindsight, this was a bit opportunistic, since after all `single_timestamp_ending` was `False` for good reason. You should find your example will work if you remove that heuristic. i.e. Delete this entire section:\r\n\r\n```python\r\n                    if not single_timestamp_ending:\r\n                        last_word_end = get_end(current_segments)\r\n                        if last_word_end is not None and last_word_end > time_offset:\r\n                            remaining_duration = window_end_time - last_word_end\r\n                            if remaining_duration > threshold:  # <--- misfired heuristic\r\n                                seek = round(last_word_end * FRAMES_PER_SECOND)\r\n                            else:\r\n                                seek = previous_seek + segment_size\r\n```\r\n\r\n(It's OK, the other parts of this code block are already handled elsewhere.)",
      "Thanks for explanation, now this part of code makes sense.\r\nDo you have idea why seek in the last window can be affected by PR? -> https://github.com/openai/whisper/pull/1838#issuecomment-1960581637\r\n\r\n> The goal was to skip over as much silence as safely possible.\r\n\r\nImho, skipping to full 30s window is pretty unsafe.  😆\r\nAnd it contradicted the description: \"skip silent periods longer than this threshold (in seconds) **when a possible hallucination is detected**\"",
      "> Do you have an audio file to reproduce?\r\n\r\nThis file has discrepancy in the last window/chunk:\r\nt-001.mka -> https://we.tl/t-ecd6U1QaZp\r\n`--language en --model=base --beam_size 1 --word_timestamps=True`\r\n\r\nWhisper without this PR:\r\n```\r\n[01:53.920 --> 01:54.500]  I'll give you some advice.\r\n[01:59.500 --> 02:00.080]  I'll give you some advice.\r\n[02:00.080 --> 02:00.080]  I'll give you some advice.\r\n[02:00.080 --> 02:00.980]  Say the word, General.\r\n[02:02.300 --> 02:03.320]  Let him go.\r\n```\r\nWhisper with this PR:\r\n```\r\n[01:53.920 --> 01:55.200]  I'll give you some advice.\r\n[01:59.500 --> 02:00.980]  Say the word, General.\r\n[02:02.280 --> 02:03.320]  Let him go.\r\n```\r\n",
      "> I'll test tomorrow, but does this also happen on PR #2043 ?\r\n\r\nYes, because `hallucination_silence_threshold` option is not relevant for the issue.\r\n\r\nCulprit affecting only the last window is found. it happens because of this:\r\n```python\r\n            mel_segment = mel[:, seek : seek + segment_size]\r\n```\r\n\r\nThis is the fix [that's how it was before this PR]:\r\n```python\r\n            mel_segment = mel[:, seek : seek + N_FRAMES]\r\n```\r\n\r\nNot sure why you changed it, on my observation it makes more hallucinations [probably it's random].\r\nAnyway, the fix brings back the previous behavior.",
      "I've confirmed the discrepancy, which seems to be a consequence of slightly different mel spectrograms. Although in the two examples you gave (only the latter of which I have tested with the supplied audio file), the PR actually removed a hallucination on one example and introduced a hallucination on the other example. So on balance, it's hard to say whether this discrepancy it better or worse or about the same.\r\n\r\nSo if it's not clear whether it's better or worse, do you see anything incorrect in the clipping logic? I think the difference is that I am always clipping exactly to the stretch of audio being examined, and then padding it. But originally, there was padding on the end that was added immediately when the mel spectrogram was first generated, and then (in the original code), it is also possible that due to the dynamic shifting of the window starts, it could end up padding the last part of the audio twice, because there is no guarantee that that initial padding Whisper added at the start of the process was enough to reflect where this last window ended up actually starting.\r\n\r\nBut it's possible I've done something wrong which I can't see, so let me know if you do spot something incorrect in the logic.",
      "After plotting the mel spectrograms, I noticed the padding when the audio is first loaded (as a whole) contains all -1.0's, while the padding in the main loop for each 30 second window contains all 0.0's. Not sure why that is, but there are two different padding algorithms in the code, and weirdly they are producing different padding results.\r\n\r\nSo in your example, the PR ends up always using the padding algorithm that pads to 0.0's whereas originally the end of file padding had -1.0's. ",
      "There's still a chance that a hallucination will be produced.\r\nFor me it was:\r\n```\r\n[02:15:58.100 --> 02:16:05.380]  я вам вышлю. Всего доброго, до свидания.\r\n[02:16:28.100 --> 02:16:30.100]  Редактор субтитров И.Бойкова\r\n```\r\ni. e.\r\n```\r\n....\r\n[02:16:28.100 --> 02:16:30.100] Subtitle Editor I. Boykova\r\n```\r\nNotably, this timestamp belongs to the end of the audio.\r\n\r\nModel size: small. Also there are some results in google, if you search for this phrase. One of them:\r\n```\r\n[24:26.800 --> 24:30.160]  Смотрите телебарометр на нашем телеканале.\r\n[24:30.160 --> 24:32.160]  Редактор субтитров И.Бойкова\r\n[24:32.160 --> 24:39.160]  Корректор А.Кулакова\r\n```\r\nfrom https://storage.googleapis.com/data.gdeltproject.org/blog/2022-tv-news-whisperasr/BELARUSTV_20221005_161500.small.transcribe.run1.txt",
      "That's certainly possible, and unfortunately there is no single choice of parameters that will be perfect in all scenarios. You can tweak the silence threshold, which is exposed on the command line. You can also try tweaking the other thresholds that were built into the code (like how long a word must be before it is flagged as an abnormality). If we can gather a large enough dataset of audio samples that produce hallucinations, we should be able to come up with better default settings that work well across a variety of scenarios and languages.",
      "@ryanheise \r\nI was using a bit tweaked segment anomaly heuristics to reduce false-positives, didn't noticed increase of false-negatives:\r\n\r\nchanged\r\n `if duration < 0.133:`\r\nto:\r\n`if duration < 0.133 and probability < 0.8:`\r\n\r\nchanged\r\n`return score >= 3 or score + 0.01 >= len(words)`\r\nto:\r\n`return score >= 3 or score + 0.001 >= len(words)`\r\n\r\nWhat you think about this tweak?",
      "Unfortunately I'm between computers right now (my old computer died 2 weeks ago, and I'm just in the process of installing everything on the recently arrived replacement...)\r\n\r\n>  return score >= 3 or score + 0.001 >= len(words)\r\n\r\nI don't see any problem with that change.\r\n\r\n>  `if duration < 0.133 and probability < 0.8:`\r\n\r\nDo you have an example audio for this one? I'd be interested to analyse this correlation between duration < 0.133 and probability < 0.8.\r\n\r\nThe alternative is to take into account more observations (like your audio example) and try to fit a new curve to the data. I initially fitted a simple linear curve, and maybe exponential could help because it could model a slower initial gradient."
    ],
    "code_diff": "diff --git a/whisper/timing.py b/whisper/timing.py\nindex befcf464e..b695ead0a 100644\n--- a/whisper/timing.py\n+++ b/whisper/timing.py\n@@ -299,6 +299,7 @@ def add_word_timestamps(\n     word_durations = np.array([t.end - t.start for t in alignment])\n     word_durations = word_durations[word_durations.nonzero()]\n     median_duration = np.median(word_durations) if len(word_durations) > 0 else 0.0\n+    median_duration = min(0.7, float(median_duration))\n     max_duration = median_duration * 2\n \n     # hack: truncate long words at sentence boundaries.\ndiff --git a/whisper/transcribe.py b/whisper/transcribe.py\nindex e80bede1d..1c075a201 100644\n--- a/whisper/transcribe.py\n+++ b/whisper/transcribe.py\n@@ -2,7 +2,7 @@\n import os\n import traceback\n import warnings\n-from typing import TYPE_CHECKING, Optional, Tuple, Union\n+from typing import TYPE_CHECKING, List, Optional, Tuple, Union\n \n import numpy as np\n import torch\n@@ -23,6 +23,7 @@\n from .utils import (\n     exact_div,\n     format_timestamp,\n+    get_end,\n     get_writer,\n     make_safe,\n     optional_float,\n@@ -48,6 +49,8 @@ def transcribe(\n     word_timestamps: bool = False,\n     prepend_punctuations: str = \"\\\"'“¿([{-\",\n     append_punctuations: str = \"\\\"'.。,，!！?？:：”)]}、\",\n+    clip_timestamps: Union[str, List[float]] = \"0\",\n+    hallucination_silence_threshold: Optional[float] = None,\n     **decode_options,\n ):\n     \"\"\"\n@@ -102,6 +105,14 @@ def transcribe(\n     decode_options: dict\n         Keyword arguments to construct `DecodingOptions` instances\n \n+    clip_timestamps: Union[str, List[float]]\n+        Comma-separated list start,end,start,end,... timestamps (in seconds) of clips to process.\n+        The last end timestamp defaults to the end of the file.\n+\n+    hallucination_silence_threshold: Optional[float]\n+        When word_timestamps is True, skip silent periods longer than this threshold (in seconds)\n+        when a possible hallucination is detected\n+\n     Returns\n     -------\n     A dictionary containing the resulting text (\"text\") and segment-level details (\"segments\"), and\n@@ -121,6 +132,7 @@ def transcribe(\n     # Pad 30-seconds of silence to the input audio, for slicing\n     mel = log_mel_spectrogram(audio, model.dims.n_mels, padding=N_SAMPLES)\n     content_frames = mel.shape[-1] - N_FRAMES\n+    content_duration = float(content_frames * HOP_LENGTH / SAMPLE_RATE)\n \n     if decode_options.get(\"language\", None) is None:\n         if not model.is_multilingual:\n@@ -147,6 +159,19 @@ def transcribe(\n         task=task,\n     )\n \n+    if isinstance(clip_timestamps, str):\n+        clip_timestamps = [\n+            float(ts) for ts in (clip_timestamps.split(\",\") if clip_timestamps else [])\n+        ]\n+    seek_points: List[int] = [round(ts * FRAMES_PER_SECOND) for ts in clip_timestamps]\n+    if len(seek_points) == 0:\n+        seek_points.append(0)\n+    if len(seek_points) % 2 == 1:\n+        seek_points.append(content_frames)\n+    seek_clips: List[Tuple[int, int]] = list(zip(seek_points[::2], seek_points[1::2]))\n+\n+    punctuation = \"\\\"'“¿([{-\\\"'.。,，!！?？:：”)]}、\"\n+\n     if word_timestamps and task == \"translate\":\n         warnings.warn(\"Word-level timestamps on translations may not be reliable.\")\n \n@@ -190,7 +215,8 @@ def decode_with_fallback(segment: torch.Tensor) -> DecodingResult:\n \n         return decode_result\n \n-    seek = 0\n+    clip_idx = 0\n+    seek = seek_clips[clip_idx][0]\n     input_stride = exact_div(\n         N_FRAMES, model.dims.n_audio_ctx\n     )  # mel frames per output token: 2\n@@ -229,10 +255,23 @@ def new_segment(\n         total=content_frames, unit=\"frames\", disable=verbose is not False\n     ) as pbar:\n         last_speech_timestamp = 0.0\n-        while seek < content_frames:\n+        # NOTE: This loop is obscurely flattened to make the diff readable.\n+        # A later commit should turn this into a simpler nested loop.\n+        # for seek_clip_start, seek_clip_end in seek_clips:\n+        #     while seek < seek_clip_end\n+        while clip_idx < len(seek_clips):\n+            seek_clip_start, seek_clip_end = seek_clips[clip_idx]\n+            if seek < seek_clip_start:\n+                seek = seek_clip_start\n+            if seek >= seek_clip_end:\n+                clip_idx += 1\n+                if clip_idx < len(seek_clips):\n+                    seek = seek_clips[clip_idx][0]\n+                continue\n             time_offset = float(seek * HOP_LENGTH / SAMPLE_RATE)\n-            mel_segment = mel[:, seek : seek + N_FRAMES]\n-            segment_size = min(N_FRAMES, content_frames - seek)\n+            window_end_time = float((seek + N_FRAMES) * HOP_LENGTH / SAMPLE_RATE)\n+            segment_size = min(N_FRAMES, content_frames - seek, seek_clip_end - seek)\n+            mel_segment = mel[:, seek : seek + segment_size]\n             segment_duration = segment_size * HOP_LENGTH / SAMPLE_RATE\n             mel_segment = pad_or_trim(mel_segment, N_FRAMES).to(model.device).to(dtype)\n \n@@ -257,6 +296,30 @@ def new_segment(\n             previous_seek = seek\n             current_segments = []\n \n+            # anomalous words are very long/short/improbable\n+            def word_anomaly_score(word: dict) -> float:\n+                probability = word.get(\"probability\", 0.0)\n+                duration = word[\"end\"] - word[\"start\"]\n+                score = 0.0\n+                if probability < 0.15:\n+                    score += 1.0\n+                if duration < 0.133:\n+                    score += (0.133 - duration) * 15\n+                if duration > 2.0:\n+                    score += duration - 2.0\n+                return score\n+\n+            def is_segment_anomaly(segment: Optional[dict]) -> bool:\n+                if segment is None or not segment[\"words\"]:\n+                    return False\n+                words = [w for w in segment[\"words\"] if w[\"word\"] not in punctuation]\n+                words = words[:8]\n+                score = sum(word_anomaly_score(w) for w in words)\n+                return score >= 3 or score + 0.01 >= len(words)\n+\n+            def next_words_segment(segments: List[dict]) -> Optional[dict]:\n+                return next((s for s in segments if s[\"words\"]), None)\n+\n             timestamp_tokens: torch.Tensor = tokens.ge(tokenizer.timestamp_begin)\n             single_timestamp_ending = timestamp_tokens[-2:].tolist() == [False, True]\n \n@@ -330,17 +393,71 @@ def new_segment(\n                     append_punctuations=append_punctuations,\n                     last_speech_timestamp=last_speech_timestamp,\n                 )\n-                word_end_timestamps = [\n-                    w[\"end\"] for s in current_segments for w in s[\"words\"]\n-                ]\n-                if len(word_end_timestamps) > 0:\n-                    last_speech_timestamp = word_end_timestamps[-1]\n-                if not single_timestamp_ending and len(word_end_timestamps) > 0:\n-                    seek_shift = round(\n-                        (word_end_timestamps[-1] - time_offset) * FRAMES_PER_SECOND\n-                    )\n-                    if seek_shift > 0:\n-                        seek = previous_seek + seek_shift\n+\n+                if not single_timestamp_ending:\n+                    last_word_end = get_end(current_segments)\n+                    if last_word_end is not None and last_word_end > time_offset:\n+                        seek = round(last_word_end * FRAMES_PER_SECOND)\n+\n+                # skip silence before possible hallucinations\n+                if hallucination_silence_threshold is not None:\n+                    threshold = hallucination_silence_threshold\n+                    if not single_timestamp_ending:\n+                        last_word_end = get_end(current_segments)\n+                        if last_word_end is not None and last_word_end > time_offset:\n+                            remaining_duration = window_end_time - last_word_end\n+                            if remaining_duration > threshold:\n+                                seek = round(last_word_end * FRAMES_PER_SECOND)\n+                            else:\n+                                seek = previous_seek + segment_size\n+\n+                    # if first segment might be a hallucination, skip leading silence\n+                    first_segment = next_words_segment(current_segments)\n+                    if first_segment is not None and is_segment_anomaly(first_segment):\n+                        gap = first_segment[\"start\"] - time_offset\n+                        if gap > threshold:\n+                            seek = previous_seek + round(gap * FRAMES_PER_SECOND)\n+                            continue\n+\n+                    # skip silence before any possible hallucination that is surrounded\n+                    # by silence or more hallucinations\n+                    hal_last_end = last_speech_timestamp\n+                    for si in range(len(current_segments)):\n+                        segment = current_segments[si]\n+                        if not segment[\"words\"]:\n+                            continue\n+                        if is_segment_anomaly(segment):\n+                            next_segment = next_words_segment(\n+                                current_segments[si + 1 :]\n+                            )\n+                            if next_segment is not None:\n+                                hal_next_start = next_segment[\"words\"][0][\"start\"]\n+                            else:\n+                                hal_next_start = time_offset + segment_duration\n+                            silence_before = (\n+                                segment[\"start\"] - hal_last_end > threshold\n+                                or segment[\"start\"] < threshold\n+                                or segment[\"start\"] - time_offset < 2.0\n+                            )\n+                            silence_after = (\n+                                hal_next_start - segment[\"end\"] > threshold\n+                                or is_segment_anomaly(next_segment)\n+                                or window_end_time - segment[\"end\"] < 2.0\n+                            )\n+                            if silence_before and silence_after:\n+                                seek = round(\n+                                    max(time_offset + 1, segment[\"start\"])\n+                                    * FRAMES_PER_SECOND\n+                                )\n+                                if content_duration - segment[\"end\"] < threshold:\n+                                    seek = content_frames\n+                                current_segments[si:] = []\n+                                break\n+                        hal_last_end = segment[\"end\"]\n+\n+                last_word_end = get_end(current_segments)\n+                if last_word_end is not None:\n+                    last_speech_timestamp = last_word_end\n \n             if verbose:\n                 for segment in current_segments:\n@@ -427,6 +544,8 @@ def valid_model_name(name):\n     parser.add_argument(\"--max_line_count\", type=optional_int, default=None, help=\"(requires --word_timestamps True) the maximum number of lines in a segment\")\n     parser.add_argument(\"--max_words_per_line\", type=optional_int, default=None, help=\"(requires --word_timestamps True, no effect with --max_line_width) the maximum number of words in a segment\")\n     parser.add_argument(\"--threads\", type=optional_int, default=0, help=\"number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS\")\n+    parser.add_argument(\"--clip_timestamps\", type=str, default=\"0\", help=\"comma-separated list start,end,start,end,... timestamps (in seconds) of clips to process, where the last end timestamp defaults to the end of the file\")\n+    parser.add_argument(\"--hallucination_silence_threshold\", type=optional_float, help=\"(requires --word_timestamps True) skip silent periods longer than this threshold (in seconds) when a possible hallucination is detected\")\n     # fmt: on\n \n     args = parser.parse_args().__dict__\ndiff --git a/whisper/utils.py b/whisper/utils.py\nindex 7a172c401..9b9b13862 100644\n--- a/whisper/utils.py\n+++ b/whisper/utils.py\n@@ -3,7 +3,7 @@\n import re\n import sys\n import zlib\n-from typing import Callable, Optional, TextIO\n+from typing import Callable, List, Optional, TextIO\n \n system_encoding = sys.getdefaultencoding()\n \n@@ -68,6 +68,20 @@ def format_timestamp(\n     )\n \n \n+def get_start(segments: List[dict]) -> Optional[float]:\n+    return next(\n+        (w[\"start\"] for s in segments for w in s[\"words\"]),\n+        segments[0][\"start\"] if segments else None,\n+    )\n+\n+\n+def get_end(segments: List[dict]) -> Optional[float]:\n+    return next(\n+        (w[\"end\"] for s in reversed(segments) for w in reversed(s[\"words\"])),\n+        segments[-1][\"end\"] if segments else None,\n+    )\n+\n+\n class ResultWriter:\n     extension: str\n \n@@ -129,8 +143,8 @@ def iterate_subtitles():\n             line_len = 0\n             line_count = 1\n             # the next subtitle to yield (a list of word timings with whitespace)\n-            subtitle: list[dict] = []\n-            last = result[\"segments\"][0][\"words\"][0][\"start\"]\n+            subtitle: List[dict] = []\n+            last: float = get_start(result[\"segments\"]) or 0.0\n             for segment in result[\"segments\"]:\n                 chunk_index = 0\n                 words_count = max_words_per_line\n",
    "diff_length": 13328
  },
  {
    "index": 5,
    "filtered_comments": [
      "The problem triggered by the test data from @ryanheise is model sensitive. I see the problem with `small` but using either `small.en` or `medium.en` looks ok although the timing of the last few words is off. Below is the mp3 fragment converted to video to show the English subtitles.\r\n\r\nhttps://user-images.githubusercontent.com/3035114/223597998-74a8ec7f-da0b-4948-9f6a-75712820eb15.mp4\r\n\r\n\r\n",
      "Thanks all! The incorrect zero-padding of Mel spectrograms as identified in #730 and #838 was contributing to this error. The fix in 477f0be appears to fix the repetition issue.",
      "Btw have you guys tried with longer audio, e.g. 5 mins long? I am still getting a lot of repetition even with this fix.\r\nE.g. on the TEDLIUM test set \"AimeeMullins_2009P.wav\"\r\n>[02:10.440 --> 02:14.720]  and needless to say, thank God, I wasn't using a thesaurus back then.\r\n[02:14.720 --> 02:14.720]  and needless to say, thank God, I wasn't using a thesaurus back then.\r\n[02:15.460 --> 02:18.580]  I mean from this entry, it would seem that\r\n[02:18.580 --> 02:22.800]  I was born into a world that perceived someone like me\r\n[02:22.800 --> 02:23.340]  I was born into a world that perceived someone like me\r\n[02:23.340 --> 02:27.540]  to have nothing positive, whatsoever, going for them\r\n[02:27.540 --> 02:27.540]  to have nothing positive, whatsoever, going for them\r\n[02:27.540 --> 02:35.340]  When in fact today, I'm celebrated for the opportunities and adventures my life has procured\r\n[02:35.340 --> 02:35.960]  When in fact today, I'm celebrated for the opportunities and adventures my life has procured\r\n[02:35.960 --> 02:42.140]  So I immediately went to look up the 2009 online edition\r\n[02:42.140 --> 02:42.160]  So I immediately went to look up the 2009 online edition\r\n[02:42.160 --> 02:42.160]  So I immediately went to look up the 2009 online edition\r\n\r\nI was hoping to update word segmentation results for whisper-only word timestamps in our paper https://arxiv.org/abs/2303.00747\r\n\r\nBut currently i am getting better results with our implementation which is similar to https://github.com/linto-ai/whisper-timestamped\r\n",
      "@jongwook Note from @m-bain example above the repetition occurring with verbose print. The repetitions in this example are all \"instantaneous\" ; eg same start and end time\r\n> [02:14.720 --> 02:14.720] and needless to say, thank God, I wasn't using a thesaurus back then.\r\n\r\nthey are printed but then immediately cleared by this code, which looks like a bug unique to `--verbose True`\r\n\r\nhttps://github.com/openai/whisper/blob/aac47c98349b98cec5ca7b1be53960fb59f4436b/whisper/transcribe.py#L345",
      "This is not a verbose error, and the start times and end times of repetition are not always instantaneous, see output for the .srt file without verbose:\r\n\r\n271\r\n00:02:14,440 --> 00:02:14,720\r\nand needless to say, thank God, I wasn't using a thesaurus back<u> then.</u>\r\n\r\n272\r\n00:02:14,720 --> 00:02:14,720\r\n\r\n\r\n273\r\n00:02:15,460 --> 00:02:16,180\r\n<u>I</u> mean from this entry, it would seem that\r\n\r\n274\r\n00:02:16,180 --> 00:02:16,360\r\nI<u> mean</u> from this entry, it would seem that\r\n\r\n275\r\n00:02:16,360 --> 00:02:16,960\r\nI mean<u> from</u> this entry, it would seem that\r\n\r\n276\r\n00:02:16,960 --> 00:02:17,220\r\nI mean from<u> this</u> entry, it would seem that\r\n\r\n277\r\n00:02:17,220 --> 00:02:17,620\r\nI mean from this<u> entry,</u> it would seem that\r\n\r\n278\r\n00:02:17,620 --> 00:02:17,800\r\nI mean from this entry, it would seem that\r\n>",
      "So there are at least two problems then\r\n* verbose mode can print cleared segments\r\n* something else triggered by word_timestamps\r\n\r\nGiven how close the start/end times are it feels like something related to `seek_shift` is still off\r\nhttps://github.com/openai/whisper/blob/aac47c98349b98cec5ca7b1be53960fb59f4436b/whisper/transcribe.py#L337\r\n\r\n@m-bain Do the same repetitions happen with `word_timestamps False` or no? ",
      "Update, I realise there is some specific underline formatting in the word_timestamps, was able to get it working in the end. See here for comparison on word-level timestamp accuracy\r\n\r\n![image](https://user-images.githubusercontent.com/36994049/224011580-4782f2ad-a178-4b2d-80c3-4baa8ca54ab9.png)\r\n\r\n@jongwook could you share the evaluation for long-form transcription WER? I am unable to reproduce whisper results, right now I report in the vanilla setting -- greedy/beam5 decoding without the heuristic tricks\r\n"
    ],
    "code_diff": "diff --git a/whisper/audio.py b/whisper/audio.py\nindex a19b7ab0d..513ab7c9d 100644\n--- a/whisper/audio.py\n+++ b/whisper/audio.py\n@@ -1,6 +1,6 @@\n import os\n from functools import lru_cache\n-from typing import Union\n+from typing import Optional, Union\n \n import ffmpeg\n import numpy as np\n@@ -15,10 +15,8 @@\n N_MELS = 80\n HOP_LENGTH = 160\n CHUNK_LENGTH = 30\n-N_SAMPLES = CHUNK_LENGTH * SAMPLE_RATE  # 480000: number of samples in a chunk\n-N_FRAMES = exact_div(\n-    N_SAMPLES, HOP_LENGTH\n-)  # 3000: number of frames in a mel spectrogram input\n+N_SAMPLES = CHUNK_LENGTH * SAMPLE_RATE  # 480000 samples in a 30-second chunk\n+N_FRAMES = exact_div(N_SAMPLES, HOP_LENGTH)  # 3000 frames in a mel spectrogram input\n \n N_SAMPLES_PER_TOKEN = HOP_LENGTH * 2  # the initial convolutions has stride 2\n FRAMES_PER_SECOND = exact_div(SAMPLE_RATE, HOP_LENGTH)  # 10ms per audio frame\n@@ -100,7 +98,10 @@ def mel_filters(device, n_mels: int = N_MELS) -> torch.Tensor:\n \n \n def log_mel_spectrogram(\n-    audio: Union[str, np.ndarray, torch.Tensor], n_mels: int = N_MELS\n+    audio: Union[str, np.ndarray, torch.Tensor],\n+    n_mels: int = N_MELS,\n+    padding: int = 0,\n+    device: Optional[Union[str, torch.device]] = None,\n ):\n     \"\"\"\n     Compute the log-Mel spectrogram of\n@@ -113,6 +114,12 @@ def log_mel_spectrogram(\n     n_mels: int\n         The number of Mel-frequency filters, only 80 is supported\n \n+    padding: int\n+        Number of zero samples to pad to the right\n+\n+    device: Optional[Union[str, torch.device]]\n+        If given, the audio tensor is moved to this device before STFT\n+\n     Returns\n     -------\n     torch.Tensor, shape = (80, n_frames)\n@@ -123,6 +130,10 @@ def log_mel_spectrogram(\n             audio = load_audio(audio)\n         audio = torch.from_numpy(audio)\n \n+    if device is not None:\n+        audio = audio.to(device)\n+    if padding > 0:\n+        audio = F.pad(audio, (0, padding))\n     window = torch.hann_window(N_FFT).to(audio.device)\n     stft = torch.stft(audio, N_FFT, HOP_LENGTH, window=window, return_complex=True)\n     magnitudes = stft[..., :-1].abs() ** 2\ndiff --git a/whisper/transcribe.py b/whisper/transcribe.py\nindex 20f01477e..773e6365e 100644\n--- a/whisper/transcribe.py\n+++ b/whisper/transcribe.py\n@@ -11,6 +11,7 @@\n     FRAMES_PER_SECOND,\n     HOP_LENGTH,\n     N_FRAMES,\n+    N_SAMPLES,\n     SAMPLE_RATE,\n     log_mel_spectrogram,\n     pad_or_trim,\n@@ -116,7 +117,9 @@ def transcribe(\n     if dtype == torch.float32:\n         decode_options[\"fp16\"] = False\n \n-    mel = log_mel_spectrogram(audio)\n+    # Pad 30-seconds of silence to the input audio, for slicing\n+    mel = log_mel_spectrogram(audio, padding=N_SAMPLES)\n+    content_frames = mel.shape[-1] - N_FRAMES\n \n     if decode_options.get(\"language\", None) is None:\n         if not model.is_multilingual:\n@@ -212,14 +215,13 @@ def new_segment(\n         }\n \n     # show the progress bar when verbose is False (if True, transcribed text will be printed)\n-    num_frames = mel.shape[-1]\n     with tqdm.tqdm(\n-        total=num_frames, unit=\"frames\", disable=verbose is not False\n+        total=content_frames, unit=\"frames\", disable=verbose is not False\n     ) as pbar:\n-        while seek < num_frames:\n+        while seek < content_frames:\n             time_offset = float(seek * HOP_LENGTH / SAMPLE_RATE)\n-            mel_segment = mel[:, seek:]\n-            segment_size = min(mel_segment.shape[-1], N_FRAMES)\n+            mel_segment = mel[:, seek : seek + N_FRAMES]\n+            segment_size = min(N_FRAMES, content_frames - seek)\n             segment_duration = segment_size * HOP_LENGTH / SAMPLE_RATE\n             mel_segment = pad_or_trim(mel_segment, N_FRAMES).to(model.device).to(dtype)\n \n@@ -246,20 +248,18 @@ def new_segment(\n             current_tokens = []\n \n             timestamp_tokens: torch.Tensor = tokens.ge(tokenizer.timestamp_begin)\n-            consecutive = torch.where(timestamp_tokens[:-1] & timestamp_tokens[1:])[\n-                0\n-            ].add_(1)\n-            if (\n-                len(consecutive) > 0\n-            ):  # if the output contains two consecutive timestamp tokens\n-                if ended_with_single_timestamp := timestamp_tokens[-2:].tolist() == [\n-                    False,\n-                    True,\n-                ]:\n-                    consecutive = consecutive.tolist() + [len(tokens)]\n+            single_timestamp_ending = timestamp_tokens[-2:].tolist() == [False, True]\n+\n+            consecutive = torch.where(timestamp_tokens[:-1] & timestamp_tokens[1:])[0]\n+            consecutive.add_(1)\n+            if len(consecutive) > 0:\n+                # if the output contains two consecutive timestamp tokens\n+                slices = consecutive.tolist()\n+                if single_timestamp_ending:\n+                    slices.append(len(tokens))\n \n                 last_slice = 0\n-                for current_slice in consecutive:\n+                for current_slice in slices:\n                     sliced_tokens = tokens[last_slice:current_slice]\n                     start_timestamp_pos = (\n                         sliced_tokens[0].item() - tokenizer.timestamp_begin\n@@ -278,7 +278,7 @@ def new_segment(\n                     current_tokens.append(sliced_tokens.tolist())\n                     last_slice = current_slice\n \n-                if ended_with_single_timestamp:\n+                if single_timestamp_ending:\n                     # single timestamp at the end means no speech after the last timestamp.\n                     seek += segment_size\n                 else:\n@@ -329,7 +329,7 @@ def new_segment(\n                 word_end_timestamps = [\n                     w[\"end\"] for s in current_segments for w in s[\"words\"]\n                 ]\n-                if len(consecutive) > 0 and len(word_end_timestamps) > 0:\n+                if not single_timestamp_ending and len(word_end_timestamps) > 0:\n                     seek_shift = round(\n                         (word_end_timestamps[-1] - time_offset) * FRAMES_PER_SECOND\n                     )\n@@ -356,7 +356,7 @@ def new_segment(\n             )\n \n             # update progress bar\n-            pbar.update(min(num_frames, seek) - previous_seek)\n+            pbar.update(min(content_frames, seek) - previous_seek)\n \n     return dict(\n         text=tokenizer.decode(all_tokens[len(initial_prompt_tokens) :]),\n",
    "diff_length": 6338
  },
  {
    "index": 6,
    "filtered_comments": [
      "This can be really useful for proofing the output via something like Subtitle Edit.  \r\n\r\nWould really need an command line option to output an additional subtitle though, right?  \r\n\r\nI get the impression @jongwook doesn't want to stuff too many features in though, so how does such a useful feature get added without having a fork?",
      "Hello!\r\n\r\n> Although the colour terminal stuff might be questionable\r\n\r\nI implemented the per-token confidence as is and implemented the colorful CLI output only in an example.\r\nThe main whisper code does not contain anything with color\r\n\r\n@jongwook is there anything I should modify or change for you to accept the PR? ",
      "I'm hesitant to add this because the incremental utility of this compared to the probabilities returned by `word_timestamps=True` is quite niche, versus the added complexity & latency due to the additional GPU operations. The decoding logic is already taking as much as the forward pass, and I'm hoping to reduce this overhead. The subword token probabilities are not very useful anyway, because it's usually influenced more by language modeling than from speech recognition.\r\n\r\nFor the case you need per-token probs, you can add another forward pass without modifying decoding.py (similar to how it's done in [timing.py](https://github.com/openai/whisper/blob/76c901ab8d4558992c44138479c4d69eb52fadcb/whisper/timing.py#L197)) without incurring too much additional latency. It may even be faster than adding GPU operations for every autoregressive step.\r\n\r\nThe example script looks nifty, but i'd prefer it in the [show and tell](https://github.com/openai/whisper/discussions/categories/show-and-tell) section.",
      "@SinanAkkoyun thanks for your contribution. Not sure, but seems it works incorrect, \r\nI made distorted speech example https://drive.google.com/file/d/12zGWllJg6edftcnwuHX_ZHMuwk7PlVjg/view?usp=sharing .\r\nIf I don't set the language of decoding i.e. `options = whisper.DecodingOptions() `,  the output is correct in terms of locating mispronounce (I can read this slavic) though it translates it to random language.\r\n![Screenshot from 2023-08-09 10-58-49](https://github.com/openai/whisper/assets/54935496/cf45eaab-1799-45d0-a386-2fc2e3076b1a)\r\n\r\nBut if I set 'en' for decoding  `options = whisper.DecodingOptions(language=\"en\")` the picture is wrong.\r\n![Screenshot from 2023-08-09 10-58-53](https://github.com/openai/whisper/assets/54935496/8c009a46-ec4d-4a47-abe3-786408580857)\r\n The rest of the code is the same as in your PR except I used \"small\" model.\r\n",
      "@Rtut654 Hi, I don't quite understand the issue you are having, the \"I like to play badminton and football.\" seems to be correct, the football especially sounds vague in the audio you provided. Could you please tell me more about your issue?\r\n\r\nDespite that, the PR is not going to get merged, so I stopped working on it and use that modification in my own work which does not include translation\r\n\r\nIf the random translation is the problem you are referring to, I believe that my PR did not modify nor change the output prediction by any means, it just grabbed the logits and displays them as confidence",
      "@SinanAkkoyun \r\nThe issue is in the accuracy of token_probs. The first version (with translation to Ukrainian) gives very accurate result since \"like\" was also mispronounced very much. Also the word \"football \" was mispronounced in the last part which is correctly shown in the first picture. \r\n\r\nI did the same test with other audio, setting language of decoding to English.  The picture was same. Somehow it is lowering the prob of the last word even when it is pronounced correctly. At the same time probs of mispronounciations were high which is strange. So something is wrong in the way it predicts probs when language is set to English.",
      "In case it's of interest, I created a small web component to view the Whisper JSON file when `--word_timestamps` has been used. Ideas for improving it would be welcome!\r\n\r\nhttps://edsu.github.io/whisper-transcript/"
    ],
    "code_diff": "diff --git a/.gitignore b/.gitignore\nindex 7ae8fabc6..9f5ed862b 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -9,3 +9,6 @@ thumbs.db\n .DS_Store\n .idea\n \n+.venv/\n+\n+samples/\ndiff --git a/README.md b/README.md\nindex eba82ce22..9ea3a38e5 100644\n--- a/README.md\n+++ b/README.md\n@@ -144,4 +144,4 @@ Please use the [🙌 Show and tell](https://github.com/openai/whisper/discussion\n \n ## License\n \n-Whisper's code and model weights are released under the MIT License. See [LICENSE](https://github.com/openai/whisper/blob/main/LICENSE) for further details.\n+Whisper's code and model weights are released under the MIT License. See [LICENSE](https://github.com/openai/whisper/blob/main/LICENSE) for further details.\n\\ No newline at end of file\ndiff --git a/examples/confidence_per_token.py b/examples/confidence_per_token.py\nnew file mode 100644\nindex 000000000..0bf2a30d7\n--- /dev/null\n+++ b/examples/confidence_per_token.py\n@@ -0,0 +1,59 @@\n+# IMPORTANT: This is just for using the local whisper dir as the package directly. Delete until next comment when just installing whisper normally.\n+import sys\n+from pathlib import Path\n+sys.path.insert(0, str(Path(__file__).resolve().parents[1]))\n+# end of dev import\n+import whisper\n+\n+import colorsys\n+from typing import List\n+from whisper.tokenizer import get_tokenizer\n+from colorama import init, Style\n+\n+\n+print('Loading model')\n+model = whisper.load_model(\"large\")\n+\n+\n+print('Loading audio') # load audio and pad/trim it to fit 30 seconds\n+audio = whisper.load_audio(\"samples/your_audio.wav\")\n+audio = whisper.pad_or_trim(audio)\n+\n+\n+mel = whisper.log_mel_spectrogram(audio).to(model.device) # make log-Mel spectrogram and move to the same device as the model\n+\n+\n+detect_lang = False\n+language = \"en\"\n+if detect_lang: # detect the spoken language\n+    print('Detecting language')\n+    _, probs = model.detect_language(mel)\n+    print(f\"Detected language: {max(probs, key=probs.get)}\")\n+    language=max(probs, key=probs.get)\n+\n+\n+print('Decoding audio') # decode the audio\n+options = whisper.DecodingOptions()\n+result = whisper.decode(model, mel, options)\n+\n+\n+def get_colored_text(tokens: List[int], token_probs: List[float], tokenizer, prompt: str=\"\"):\n+    init(autoreset=False)  # Initialize colorama\n+    text_tokens = [tokenizer.decode([t]) for t in tokens]\n+\n+    output_text = \"\"\n+    for i, (token, prob) in enumerate(zip(text_tokens, token_probs)):\n+        # Interpolate between red and green in the HSV color space\n+        r, g, b = colorsys.hsv_to_rgb(prob * (1/3), 1, 1)\n+        r, g, b = int(r * 255), int(g * 255), int(b * 255)\n+        color_code = f\"\\033[38;2;{r};{g};{b}m\"\n+\n+        colored_token = f\"{color_code}{Style.BRIGHT}{token}{Style.RESET_ALL}\"\n+        output_text += colored_token\n+\n+    return output_text\n+\n+\n+tokenizer = get_tokenizer(multilingual=model.is_multilingual, language=language, task=options.task)\n+print(get_colored_text(result.tokens, result.token_probs, tokenizer))  # print text with fancy confidence colors\n+# HINT: when using a prompt, you must provide it in the get_colored_text as well\ndiff --git a/whisper/decoding.py b/whisper/decoding.py\nindex 81cd8452b..4ded71bd7 100644\n--- a/whisper/decoding.py\n+++ b/whisper/decoding.py\n@@ -118,6 +118,7 @@ class DecodingResult:\n     language: str\n     language_probs: Optional[Dict[str, float]] = None\n     tokens: List[int] = field(default_factory=list)\n+    token_probs: List[float] = field(default_factory=list)\n     text: str = \"\"\n     avg_logprob: float = np.nan\n     no_speech_prob: float = np.nan\n@@ -211,7 +212,7 @@ def reset(self):\n         \"\"\"Initialize any stateful variables for decoding a new sequence\"\"\"\n \n     def update(\n-        self, tokens: Tensor, logits: Tensor, sum_logprobs: Tensor\n+        self, tokens: Tensor, logits: Tensor, sum_logprobs: Tensor, token_probs: Tensor\n     ) -> Tuple[Tensor, bool]:\n         \"\"\"Specify how to select the next token, based on the current trace and logits\n \n@@ -238,7 +239,7 @@ def update(\n         raise NotImplementedError\n \n     def finalize(\n-        self, tokens: Tensor, sum_logprobs: Tensor\n+        self, tokens: Tensor, sum_logprobs: Tensor, token_probs: Tensor\n     ) -> Tuple[Sequence[Sequence[Tensor]], List[List[float]]]:\n         \"\"\"Finalize search and return the final candidate sequences\n \n@@ -268,7 +269,7 @@ def __init__(self, temperature: float, eot: int):\n         self.eot = eot\n \n     def update(\n-        self, tokens: Tensor, logits: Tensor, sum_logprobs: Tensor\n+        self, tokens: Tensor, logits: Tensor, sum_logprobs: Tensor, token_probs: Tensor\n     ) -> Tuple[Tensor, bool]:\n         if self.temperature == 0:\n             next_tokens = logits.argmax(dim=-1)\n@@ -276,19 +277,28 @@ def update(\n             next_tokens = Categorical(logits=logits / self.temperature).sample()\n \n         logprobs = F.log_softmax(logits.float(), dim=-1)\n+        probs = torch.exp(logprobs)\n         current_logprobs = logprobs[torch.arange(logprobs.shape[0]), next_tokens]\n         sum_logprobs += current_logprobs * (tokens[:, -1] != self.eot)\n \n         next_tokens[tokens[:, -1] == self.eot] = self.eot\n         tokens = torch.cat([tokens, next_tokens[:, None]], dim=-1)\n \n+        current_token_probs = probs[torch.arange(probs.shape[0]), next_tokens]\n+        token_probs = torch.cat([token_probs, current_token_probs[:, None]], dim=-1)\n+\n+        # token_logits = torch.stack([logits[k, next_tokens[k]] for k in range(next_tokens .shape[0])], dim=0)\n+        # or use logprobs, the log softmax of the logits\n+        # return it along with tokens and completed\n+\n         completed = (tokens[:, -1] == self.eot).all()\n-        return tokens, completed\n+        return tokens, completed, token_probs\n \n-    def finalize(self, tokens: Tensor, sum_logprobs: Tensor):\n+    def finalize(self, tokens: Tensor, sum_logprobs: Tensor, token_probs: Tensor):\n         # make sure each sequence has at least one EOT token at the end\n         tokens = F.pad(tokens, (0, 1), value=self.eot)\n-        return tokens, sum_logprobs.tolist()\n+        token_probs = F.pad(token_probs, (0, 1), value=0) # 0 ok?\n+        return tokens, sum_logprobs.tolist(), token_probs.tolist()\n \n \n class BeamSearchDecoder(TokenDecoder):\n@@ -374,7 +384,7 @@ def update(\n         )\n         return tokens, completed\n \n-    def finalize(self, preceding_tokens: Tensor, sum_logprobs: Tensor):\n+    def finalize(self, preceding_tokens: Tensor, sum_logprobs: Tensor, token_probs: Tensor):\n         # collect all finished sequences, including patience, and add unfinished ones if not enough\n         sum_logprobs = sum_logprobs.cpu()\n         for i, sequences in enumerate(self.finished_sequences):\n@@ -668,6 +678,8 @@ def _main_loop(self, audio_features: Tensor, tokens: Tensor):\n         sum_logprobs: Tensor = torch.zeros(n_batch, device=audio_features.device)\n         no_speech_probs = [np.nan] * n_batch\n \n+        token_probs = torch.zeros_like(tokens).float()\n+\n         try:\n             for i in range(self.sample_len):\n                 logits = self.inference.logits(tokens, audio_features)\n@@ -686,14 +698,14 @@ def _main_loop(self, audio_features: Tensor, tokens: Tensor):\n                     logit_filter.apply(logits, tokens)\n \n                 # expand the tokens tensor with the selected next tokens\n-                tokens, completed = self.decoder.update(tokens, logits, sum_logprobs)\n+                tokens, completed, token_probs = self.decoder.update(tokens, logits, sum_logprobs, token_probs)\n \n                 if completed or tokens.shape[-1] > self.n_ctx:\n                     break\n         finally:\n             self.inference.cleanup_caching()\n \n-        return tokens, sum_logprobs, no_speech_probs\n+        return tokens, sum_logprobs, no_speech_probs, token_probs\n \n     @torch.no_grad()\n     def run(self, mel: Tensor) -> List[DecodingResult]:\n@@ -721,7 +733,7 @@ def run(self, mel: Tensor) -> List[DecodingResult]:\n         tokens = tokens.repeat_interleave(self.n_group, dim=0).to(audio_features.device)\n \n         # call the main sampling loop\n-        tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n+        tokens, sum_logprobs, no_speech_probs, token_probs = self._main_loop(audio_features, tokens)\n \n         # reshape the tensors to have (n_audio, n_group) as the first two dimensions\n         audio_features = audio_features[:: self.n_group]\n@@ -732,7 +744,7 @@ def run(self, mel: Tensor) -> List[DecodingResult]:\n         sum_logprobs = sum_logprobs.reshape(n_audio, self.n_group)\n \n         # get the final candidates for each group, and slice between the first sampled token and EOT\n-        tokens, sum_logprobs = self.decoder.finalize(tokens, sum_logprobs)\n+        tokens, sum_logprobs, token_probs = self.decoder.finalize(tokens, sum_logprobs, token_probs)\n         tokens: List[List[Tensor]] = [\n             [t[self.sample_begin : (t == tokenizer.eot).nonzero()[0, 0]] for t in s]\n             for s in tokens\n@@ -755,6 +767,7 @@ def run(self, mel: Tensor) -> List[DecodingResult]:\n             audio_features,\n             avg_logprobs,\n             no_speech_probs,\n+            token_probs\n         )\n         if len(set(map(len, fields))) != 1:\n             raise RuntimeError(f\"inconsistent result lengths: {list(map(len, fields))}\")\n@@ -769,8 +782,9 @@ def run(self, mel: Tensor) -> List[DecodingResult]:\n                 no_speech_prob=no_speech_prob,\n                 temperature=self.options.temperature,\n                 compression_ratio=compression_ratio(text),\n+                token_probs=token_probs[-len(tokens):]\n             )\n-            for text, language, tokens, features, avg_logprob, no_speech_prob in zip(\n+            for text, language, tokens, features, avg_logprob, no_speech_prob, token_probs in zip(\n                 *fields\n             )\n         ]\n",
    "diff_length": 9839
  },
  {
    "index": 7,
    "filtered_comments": [
      "I was trying out this exciting branch and ran into this error when running a test:\r\n```\r\n<...>/lib/python3.12/site-packages/django/db/models/lookups.py:30: in __init__\r\n    self.rhs = self.get_prep_lookup()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = TupleIn(<django.db.models.fields.composite.Cols object at 0x107560980>, <django.db.models.sql.query.Query object at 0x1074e23f0>)\r\n\r\n    def get_prep_lookup(self):\r\n        if not isinstance(self.lhs, Cols):\r\n            raise ValueError(\r\n                \"The left-hand side of the 'in' lookup must be an instance of Cols\"\r\n            )\r\n        if not isinstance(self.rhs, Iterable):\r\n>           raise ValueError(\r\n                \"The right-hand side of the 'in' lookup must be an iterable\"\r\n            )\r\nE           ValueError: The right-hand side of the 'in' lookup must be an iterable\r\n```\r\n\r\nThe issue stems from the use of `isnull` like so:\r\n\r\n```\r\nMyModel.objects.filter(\r\n    type_override__severity__isnull=False\r\n).update(severity=\"high\")\r\n```\r\n\r\nCurious if anyone ran into this as well.\r\n\r\nEdited for traceback:\r\n\r\n```\r\n<...>\r\nlib/python3.12/site-packages/django/db/models/sql/compiler.py:2080: in pre_sql_setup\r\n    self.query.add_filter(\"pk__in\", query)\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1601: in add_filter\r\n    self.add_q(Q((filter_lhs, filter_rhs)))\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1617: in add_q\r\n    clause, _ = self._add_q(q_object, self.used_aliases)\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1649: in _add_q\r\n    child_clause, needed_inner = self.build_filter(\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1563: in build_filter\r\n    condition = self.build_lookup(lookups, col, value)\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1393: in build_lookup\r\n    lookup = lookup_class(lhs, rhs)\r\nlib/python3.12/site-packages/django/db/models/lookups.py:30: in __init__\r\n    self.rhs = self.get_prep_lookup()\r\n```\r\n\r\nSo, this is part of `SQLUpdateCompiler` and is coming from the `update` code path.",
      "I may have found one other small issue. When adding a regular `primary_key=True` on a single field, a unique constraint is added. But when using this branch, it becomes an `IntegrityError` instead. Adding a `UniqueConstraint` on the composite fields is a work-a-round but ideally would be captured in this PR. Imo, this PR is sooooo close. I'm excited for it to be merged in.",
      "@grjones , thanks, I appreciate the feedback, I'll look into it. If a model defines `Meta.primary_key`, defining `primary_key=True` on a field should not be possible - could you give me a code example so I know how to reproduce the issue? I didn't know Django added unique constraints to primary keys, I'll check, but isn't that redundant?",
      "> @grjones , thanks, I appreciate the feedback, I'll look into it. If a model defines `Meta.primary_key`, defining `primary_key=True` on a field should not be possible - could you give me a code example so I know how to reproduce the issue? I didn't know Django added unique constraints to primary keys, I'll check, but isn't that redundant?\r\n\r\nI'll see if I can give you a solid failing test. My \"unique constraint\" phrasing might not be exactly right. But ultimately, I believe Django queries the DB first to see if the new object's PK already exists and throws a validation error. The composite key logic doesn't seem to be doing that and so an unhandled IntegrityError is raised instead.",
      "> @grjones , sorry for the late reply, I've been busy last week. Could you give me more specifics? What's the error message you expect?\r\n\r\nActually, I think it's mostly ok. I was using [Django Spanner](https://github.com/googleapis/python-spanner-django) and it's just not quite working with composite keys and will need to be fixed there. I wrote this and it passed. It probably shouldn't say `Id` though?\r\n\r\n```\r\nfrom django.core.exceptions import ValidationError\r\nfrom django.test import TestCase\r\n\r\nfrom .models import Tenant, User\r\n\r\n\r\nclass CompositePKCleanTests(TestCase):\r\n    \"\"\"\r\n    Test the .clean() method of composite_pk models.\r\n    \"\"\"\r\n\r\n    @classmethod\r\n    def setUpTestData(cls):\r\n        cls.tenant = Tenant.objects.create()\r\n\r\n    def test_validation_error_is_raised_when_pk_already_exists(self):\r\n        test_cases = [\r\n            {\"tenant\": self.tenant, \"id\": 2412, \"email\": \"user2412@example.com\"},\r\n            {\"tenant_id\": self.tenant.id, \"id\": 5316, \"email\": \"user5316@example.com\"},\r\n            {\"pk\": (self.tenant.id, 7424), \"email\": \"user7424@example.com\"},\r\n        ]\r\n        expected = \"{'id': ['User with this Id already exists.']}\"\r\n        for fields in test_cases:\r\n            User.objects.create(**fields)\r\n            with self.assertRaisesMessage(ValidationError, expected):\r\n                User(**fields).clean()\r\n```",
      "Thank you so much for taking the time to review my changes @LilyFoote !\r\nI have two questions:\r\n\r\n1. If `Meta.primary_key` is defined, this PR will automatically add a composite field called `primary_key` to the model. What do you think about this approach? I felt like it was easier to handle the composite primary keys this way as we can run checks against the meta class instead of traversing the model's fields for a composite field.\r\n2. I wrote a lot of tests testing the underlying queries made by the ORM. It makes a lot of sense to me, but I haven't seen this type of tests that much in the Django source code - do these tests look okay to you?",
      " \r\n> If `Meta.primary_key` is defined, this PR will automatically add a composite field called `primary_key` to the model. What do you think about this approach?\r\n\r\nI don't feel strongly that this is better or worse than another option here, so happy to go with what you think is best.\r\n\r\n> I wrote a lot of tests testing the underlying queries made by the ORM. It makes a lot of sense to me, but I haven't seen this type of tests that much in the Django source code - do these tests look okay to you?\r\n\r\nI like your tests quite a bit - they're pretty readable and comprehensive. The main issue I have with them is that they're written for specific databases instead of for generic database features. Where possible Django strongly prefers to test based on features because then the tests apply to as many databases as possible (including third party database libraries). I think the asserts of the actual SQL might be a bit tricky to adapt though, so we might need a different way to check what they're checking.\r\n\r\nAlso, after I reviewed yesterday, I thought of some more things:\r\n\r\n* We should add migrations tests to make sure that adding/removing `Meta.primary_key` works correctly and that removing a field that's part of a primary key also does something appropriate.\r\n* We might want tests for composite keys in forms and the admin. Maybe there's other areas too that we need to check the interactions.",
      "Thanks @charettes !\r\n\r\n> Something that came through my mind while reviewing is that we likely want a plan to eventually deprecate `Options.pk` in favor of `Options.primary_key`?\r\n\r\nI'm not sure what you mean by that, I don't think we can, because `Options.pk` refers to the field, while `Options.primary_key` is the list of field names.",
      "So as far as I understand, at the moment `MultiColSource` is used by Django internally to represent `JOIN`s on multiple fields - that's why it has a `sources` field.\r\n\r\nI'm not sure it's the right decision to reuse this for composite fields, which on the other hand don't need `sources`, it just needs to represent a list of `Col`s as an expression.\r\n\r\nLet me know what you think!",
      "> I'm not sure what you mean by that, I don't think we can, because Options.pk refers to the field, while Options.primary_key is the list of field names.\r\n\r\nYou're completely right. In this case is `pk` set to `CompositePrimaryKey` when `Meta.primary_key` is defined and is `primary_key` set when a non-composite primary is used as well?",
      "> > I'm not sure what you mean by that, I don't think we can, because Options.pk refers to the field, while Options.primary_key is the list of field names.\r\n> \r\n> You're completely right. In this case is `pk` set to `CompositePrimaryKey` when `Meta.primary_key` is defined and is `primary_key` set when a non-composite primary is used as well?\r\n\r\nIt would not be set, if it's a regular primary key, `Meta.primary_key` is `None`.",
      "Hey @csirmazbendeguz, thank you for the amazing work out there! I was trying to test this branch on my local with SQLite and realised a few things:\r\n\r\n1. If you run `makemigrations` for a model with a `CompositePrimaryKey`, the resulting migration file has erroneous imports. To fix this, I believe we need to add `django.db.models.fields.composite` path to the `if...elif` block [here](https://github.com/django/django/blob/main/django/db/models/fields/__init__.py#L645).\r\n2. Assume that I have the following models:\r\n\r\n    ```py\r\n    class Author(models.Model):\r\n    name = models.CharField(max_length=100)\r\n\r\n    class Book(models.Model):\r\n        id = models.CompositePrimaryKey(\"author\", \"title\")\r\n        author = models.ForeignKey(Author, on_delete=models.CASCADE, related_name=\"books\")\r\n        title = models.CharField(max_length=255)\r\n    ```\r\n\r\n    With the current implementation, following test fails:\r\n    ```py\r\n    class TestCompositeFks(TestCase):\r\n        def test_composite_fks(self):\r\n            author = Author.objects.create(name=\"Author\")\r\n            book = Book.objects.create(author=author, title=\"Title\")\r\n            list(Author.objects.filter(books__in=[book])) == book\r\n    ```\r\n    with an `OperationalError`, caused by a syntax error. Executed SQL is as following:\r\n    ```SQL\r\n    SELECT\r\n        \"books_author\".\"id\",\r\n        \"books_author\".\"name\"\r\n    FROM\r\n        \"books_author\"\r\n        INNER JOIN \"books_book\" ON (\"books_author\".\"id\" = \"books_book\".\"author_id\")\r\n    WHERE\r\n        \"books_book\".\"author_id\", \"books_book\".\"title\" IN ((1, 'Title'))\r\n    ```\r\n    because LHS in WHERE clause should have been wrapped with parantheses like this:\r\n    ```SQL\r\n    ...\r\n    WHERE\r\n        (\"books_book\".\"author_id\", \"books_book\".\"title\") IN ((1, 'Title'))\r\n    ```\r\n    Unfortunately I didn't have a time to deep-dive to this.\r\n3. Not a big issue but my code editor (VSCode) does not recognize `models.CompositePrimaryKey`, although the import is working fine. This is probably related with Pylance or something that VSCode uses to recognize fields under `models` module.\r\n\r\nAgain thanks for this amazing initiative! 🚀 ",
      "@csirmazbendeguz Thanks for your answers, now the above issues seem like fixed, created migration is correct and reverse relation lookup is working as expected. Thank you! 🚀\r\n\r\nWhile I was testing it further with the exact [same models](https://github.com/django/django/pull/18056#issuecomment-2158820017), I realized another issue:\r\n\r\n```py\r\nclass TestCompositeFks(TestCase):\r\n    def test_composite_fks(self):\r\n        author = Author.objects.create(name=\"Author\")\r\n        Book.objects.create(author=author, title=\"Title\")\r\n        author = Author.objects.annotate(book_count=Count(\"books\")).get()\r\n        assert author.book_count == 1\r\n```\r\n\r\nThis test fails with the following error:\r\n\r\n```\r\ndjango.db.utils.OperationalError: wrong number of arguments to function COUNT()\r\n```\r\n\r\nExecuted SQL is as following:\r\n\r\n```SQL\r\nSELECT\r\n    \"books_author\".\"id\",\r\n    \"books_author\".\"name\",\r\n    COUNT(\"books_book\".\"author_id\", \"books_book\".\"title\") AS \"book_count\"\r\nFROM\r\n    \"books_author\"\r\n    LEFT OUTER JOIN \"books_book\" ON (\"books_author\".\"id\" = \"books_book\".\"author_id\")\r\nGROUP BY\r\n    \"books_author\".\"id\",\r\n    \"books_author\".\"name\"\r\n```\r\n\r\nIf we could change the parameter we pass to the `COUNT` function to a concatenation as below:\r\n\r\n```SQL\r\nCOUNT(\"books_book\".\"author_id\" || '-' || \"books_book\".\"title\")\r\n```\r\n\r\nit should work fine (if I am not missing something), with the exception that for some databases we need to use `CONCAT` function instead of `||` operator, which might be resolved using the existing `db.models.functions.Concat` function.\r\n\r\nNote: I am not sure if concatenation works between every data type that is allowed to be a primary key, although this could be considered as an edge case.",
      "@omerfarukabaci , I thought about the issue of `Count(\"books\")`.\r\n\r\nMy conclusion is we can't support this.\r\n\r\nI don't think concatenating is a good solution. The only way we could support this is if we could get Django to count this with `*` instead of the primary key.\r\n\r\nThis is an edge case that is only needed for `Count` though, and it's not as simple to implement as it is to explain.\r\n\r\nI added a section to the docs about this. This is a case of using a database function with a composite primary key directly, which cannot be expected to work in general.\r\n\r\nIn your case, `Count(\"books__author_id\")` would do the trick instead.",
      "Regarding the issue raised by @sarahboyce last week...\r\n\r\nI think it is okay to merge this without support for generic relations. I added a section to the docs about this not being supported for now.\r\n\r\nThe only impact is some third-party packages using generic relations won't work with composite primary keys (e.g. `django-guardian`).\r\n\r\nLet's have a separate discussion on how to support this. I lean towards storing composite primary keys serialized as JSON in a single CharField.",
      "Btw, semantically it would be nice if it were possible to write:\r\n```python \r\nclass User(models.Model):\r\n    pk = models.CompositePrimaryKey(\"tenant_id\", \"id\")\r\n    tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE)\r\n    id = models.IntegerField()\r\n```\r\n\r\nie to let `CompositePrimaryKey` replace the automatically generated `pk`. Would that be possible?",
      "> Btw, semantically it would be nice if it were possible to write:\r\n> \r\n> ```python\r\n> class User(models.Model):\r\n>     pk = models.CompositePrimaryKey(\"tenant_id\", \"id\")\r\n>     tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE)\r\n>     id = models.IntegerField()\r\n> ```\r\n> \r\n> ie to let `CompositePrimaryKey` replace the automatically generated `pk`. Would that be possible?\r\n\r\n@apollo13 , good point! It also came up when we were discussing this with @LilyFoote and @charettes . It seems like a natural thing to do, so it's worth a discussion. Here are a couple ideas that make sense to me:\r\n\r\n1. `pk` at the moment is reserved, users can't add a field named `pk`. We could remove this restriction.\r\n2. If `pk` is defined, it should always set `primary_key=True`.\r\n3. If `pk` is not defined, it should still refer to the `primary_key=True` field (e.g. `id` field). This is required for backwards-compatibility.\r\n4. If `pk` is defined, and it's an `IntegerField`, then a field called `pk` should be created in the database (same as any field, e.g. `id`).\r\n5. If `pk` is defined, and it's a `CompositePrimaryKey`, then a field called `pk` shouldn't be created in the database (same as any field, e.g. `primary_key`).\r\n\r\nMy only issue with this is, it adds extra complexity to how `pk` works. In this case, `pk` can be both a reference to the primary key field, or the primary key field itself.\r\n\r\nSo I'm not sure if it's worth doing this. It doesn't feel like an elegant or consistent solution to me.\r\n\r\n---\r\n\r\nThe other approach @charettes and @LilyFoote mentioned is to always have `pk` be a `CompositePrimaryKey` (could be renamed to `PrimaryKey`):\r\n\r\n1. `pk` cannot be defined explicitly.\r\n2. `CompositePrimaryKey` cannot be used explicitly.\r\n3. `pk` is _always_ added to the model in the background, and it's _always_ an instance of `CompositePrimaryKey`.\r\n4. Consequently, `pk` will cease to be a reference to another field, it will always be a field itself.\r\n5. If field `x` defines `primary_key=True`, `pk` is `CompositePrimaryKey(\"x\")`. `obj.pk` returns the value of `x` for backwards-compatibility (instead of a tuple).\r\n6. If `Meta.primary_key` option is `(\"a\", \"b\", \"c\")`, `pk` is `CompositePrimaryKey(\"a\", \"b\", \"c\")`. `obj.pk` returns a tuple.\r\n7. If `Meta.primary_key` is not set, it could be set to `(\"x\",)` automatically.\r\n\r\nThis is quite an invasive change. It would mean all existing models get a new field called `pk`.\r\n`meta.pk` would return a different field. Instead of `IntegerField`, it would return `CompositePrimaryKey`. Is breaking backwards-compatibility okay here?\r\n\r\nI don't have anything against it other than that. It does feel more intuitive. If the community wants this, I could fork this branch and open another PR."
    ],
    "code_diff": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 3399bd87b85a..201f28ef3744 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -113,6 +113,11 @@ def register(self, model_or_iterable, admin_class=None, **options):\n                     \"The model %s is abstract, so it cannot be registered with admin.\"\n                     % model.__name__\n                 )\n+            if model._meta.is_composite_pk:\n+                raise ImproperlyConfigured(\n+                    \"The model %s has a composite primary key, so it cannot be \"\n+                    \"registered with admin.\" % model.__name__\n+                )\n \n             if self.is_registered(model):\n                 registered_admin = str(self.get_model_admin(model))\ndiff --git a/django/core/serializers/python.py b/django/core/serializers/python.py\nindex 46ef9f077161..57edebbb70e4 100644\n--- a/django/core/serializers/python.py\n+++ b/django/core/serializers/python.py\n@@ -7,6 +7,7 @@\n from django.apps import apps\n from django.core.serializers import base\n from django.db import DEFAULT_DB_ALIAS, models\n+from django.db.models import CompositePrimaryKey\n from django.utils.encoding import is_protected_type\n \n \n@@ -39,6 +40,8 @@ def get_dump_object(self, obj):\n         return data\n \n     def _value_from_field(self, obj, field):\n+        if isinstance(field, CompositePrimaryKey):\n+            return [self._value_from_field(obj, f) for f in field]\n         value = field.value_from_object(obj)\n         # Protected types (i.e., primitives like None, numbers, dates,\n         # and Decimals) are passed through as is. All other values are\ndiff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 3e38c56d50d4..de4886837ecf 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -14,6 +14,7 @@\n )\n from django.db.backends.utils import names_digest, split_identifier, truncate_name\n from django.db.models import NOT_PROVIDED, Deferrable, Index\n+from django.db.models.fields.composite import CompositePrimaryKey\n from django.db.models.sql import Query\n from django.db.transaction import TransactionManagementError, atomic\n from django.utils import timezone\n@@ -106,6 +107,7 @@ class BaseDatabaseSchemaEditor:\n     sql_check_constraint = \"CHECK (%(check)s)\"\n     sql_delete_constraint = \"ALTER TABLE %(table)s DROP CONSTRAINT %(name)s\"\n     sql_constraint = \"CONSTRAINT %(name)s %(constraint)s\"\n+    sql_pk_constraint = \"PRIMARY KEY (%(columns)s)\"\n \n     sql_create_check = \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s CHECK (%(check)s)\"\n     sql_delete_check = sql_delete_constraint\n@@ -282,6 +284,11 @@ def table_sql(self, model):\n                 constraint.constraint_sql(model, self)\n                 for constraint in model._meta.constraints\n             )\n+\n+        pk = model._meta.pk\n+        if isinstance(pk, CompositePrimaryKey):\n+            constraint_sqls.append(self._pk_constraint_sql(pk.columns))\n+\n         sql = self.sql_create_table % {\n             \"table\": self.quote_name(model._meta.db_table),\n             \"definition\": \", \".join(\n@@ -1999,6 +2006,11 @@ def _constraint_names(\n                     result.append(name)\n         return result\n \n+    def _pk_constraint_sql(self, columns):\n+        return self.sql_pk_constraint % {\n+            \"columns\": \", \".join(self.quote_name(column) for column in columns)\n+        }\n+\n     def _delete_primary_key(self, model, strict=False):\n         constraint_names = self._constraint_names(model, primary_key=True)\n         if strict and len(constraint_names) != 1:\ndiff --git a/django/db/backends/oracle/schema.py b/django/db/backends/oracle/schema.py\nindex 0d70522a2afa..ba3c4778d30d 100644\n--- a/django/db/backends/oracle/schema.py\n+++ b/django/db/backends/oracle/schema.py\n@@ -211,6 +211,8 @@ def _field_should_be_indexed(self, model, field):\n         return create_index\n \n     def _is_identity_column(self, table_name, column_name):\n+        if not column_name:\n+            return False\n         with self.connection.cursor() as cursor:\n             cursor.execute(\n                 \"\"\"\ndiff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex c5b428fc678c..6da98522822f 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -6,7 +6,7 @@\n from django.db.backends.base.schema import BaseDatabaseSchemaEditor\n from django.db.backends.ddl_references import Statement\n from django.db.backends.utils import strip_quotes\n-from django.db.models import NOT_PROVIDED, UniqueConstraint\n+from django.db.models import NOT_PROVIDED, CompositePrimaryKey, UniqueConstraint\n \n \n class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n@@ -104,6 +104,13 @@ def is_self_referential(f):\n             f.name: f.clone() if is_self_referential(f) else f\n             for f in model._meta.local_concrete_fields\n         }\n+\n+        # Since CompositePrimaryKey is not a concrete field (column is None),\n+        # it's not copied by default.\n+        pk = model._meta.pk\n+        if isinstance(pk, CompositePrimaryKey):\n+            body[pk.name] = pk.clone()\n+\n         # Since mapping might mix column names and default values,\n         # its values must be already quoted.\n         mapping = {\n@@ -296,6 +303,12 @@ def add_field(self, model, field):\n         # Special-case implicit M2M tables.\n         if field.many_to_many and field.remote_field.through._meta.auto_created:\n             self.create_model(field.remote_field.through)\n+        elif isinstance(field, CompositePrimaryKey):\n+            # If a CompositePrimaryKey field was added, the existing primary key field\n+            # had to be altered too, resulting in an AddField, AlterField migration.\n+            # The table cannot be re-created on AddField, it would result in a\n+            # duplicate primary key error.\n+            return\n         elif (\n             # Primary keys and unique fields are not supported in ALTER TABLE\n             # ADD COLUMN.\ndiff --git a/django/db/models/__init__.py b/django/db/models/__init__.py\nindex fe81d92d3666..ec54b652409d 100644\n--- a/django/db/models/__init__.py\n+++ b/django/db/models/__init__.py\n@@ -38,6 +38,7 @@\n )\n from django.db.models.fields import *  # NOQA\n from django.db.models.fields import __all__ as fields_all\n+from django.db.models.fields.composite import CompositePrimaryKey\n from django.db.models.fields.files import FileField, ImageField\n from django.db.models.fields.generated import GeneratedField\n from django.db.models.fields.json import JSONField\n@@ -82,6 +83,7 @@\n     \"ProtectedError\",\n     \"RestrictedError\",\n     \"Case\",\n+    \"CompositePrimaryKey\",\n     \"Exists\",\n     \"Expression\",\n     \"ExpressionList\",\ndiff --git a/django/db/models/aggregates.py b/django/db/models/aggregates.py\nindex bf94decab7a8..73f03a4916f2 100644\n--- a/django/db/models/aggregates.py\n+++ b/django/db/models/aggregates.py\n@@ -3,7 +3,8 @@\n \"\"\"\n \n from django.core.exceptions import FieldError, FullResultSet\n-from django.db.models.expressions import Case, Func, Star, Value, When\n+from django.db import NotSupportedError\n+from django.db.models.expressions import Case, ColPairs, Func, Star, Value, When\n from django.db.models.fields import IntegerField\n from django.db.models.functions.comparison import Coalesce\n from django.db.models.functions.mixins import (\n@@ -174,6 +175,22 @@ def __init__(self, expression, filter=None, **extra):\n             raise ValueError(\"Star cannot be used with filter. Please specify a field.\")\n         super().__init__(expression, filter=filter, **extra)\n \n+    def resolve_expression(self, *args, **kwargs):\n+        result = super().resolve_expression(*args, **kwargs)\n+        expr = result.source_expressions[0]\n+\n+        # In case of composite primary keys, count the first column.\n+        if isinstance(expr, ColPairs):\n+            if self.distinct:\n+                raise NotSupportedError(\n+                    \"COUNT(DISTINCT) doesn't support composite primary keys\"\n+                )\n+\n+            cols = expr.get_cols()\n+            return Count(cols[0], filter=result.filter)\n+\n+        return result\n+\n \n class Max(Aggregate):\n     function = \"MAX\"\ndiff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 5b819b1406a2..a20e88749f5a 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1,6 +1,7 @@\n import copy\n import inspect\n import warnings\n+from collections import defaultdict\n from functools import partialmethod\n from itertools import chain\n \n@@ -30,6 +31,7 @@\n from django.db.models.constants import LOOKUP_SEP\n from django.db.models.deletion import CASCADE, Collector\n from django.db.models.expressions import DatabaseDefault\n+from django.db.models.fields.composite import CompositePrimaryKey\n from django.db.models.fields.related import (\n     ForeignObjectRel,\n     OneToOneField,\n@@ -508,7 +510,7 @@ def __init__(self, *args, **kwargs):\n         for field in fields_iter:\n             is_related_object = False\n             # Virtual field\n-            if field.attname not in kwargs and field.column is None or field.generated:\n+            if field.column is None or field.generated:\n                 continue\n             if kwargs:\n                 if isinstance(field.remote_field, ForeignObjectRel):\n@@ -663,7 +665,11 @@ def _set_pk_val(self, value):\n     pk = property(_get_pk_val, _set_pk_val)\n \n     def _is_pk_set(self, meta=None):\n-        return self._get_pk_val(meta) is not None\n+        pk_val = self._get_pk_val(meta)\n+        return not (\n+            pk_val is None\n+            or (isinstance(pk_val, tuple) and any(f is None for f in pk_val))\n+        )\n \n     def get_deferred_fields(self):\n         \"\"\"\n@@ -1454,6 +1460,11 @@ def _get_unique_checks(self, exclude=None, include_meta_constraints=False):\n                 name = f.name\n                 if name in exclude:\n                     continue\n+                if isinstance(f, CompositePrimaryKey):\n+                    names = tuple(field.name for field in f.fields)\n+                    if exclude.isdisjoint(names):\n+                        unique_checks.append((model_class, names))\n+                    continue\n                 if f.unique:\n                     unique_checks.append((model_class, (name,)))\n                 if f.unique_for_date and f.unique_for_date not in exclude:\n@@ -1728,6 +1739,7 @@ def check(cls, **kwargs):\n                 *cls._check_constraints(databases),\n                 *cls._check_default_pk(),\n                 *cls._check_db_table_comment(databases),\n+                *cls._check_composite_pk(),\n             ]\n \n         return errors\n@@ -1764,6 +1776,63 @@ def _check_default_pk(cls):\n             ]\n         return []\n \n+    @classmethod\n+    def _check_composite_pk(cls):\n+        errors = []\n+        meta = cls._meta\n+        pk = meta.pk\n+\n+        if not isinstance(pk, CompositePrimaryKey):\n+            return errors\n+\n+        seen_columns = defaultdict(list)\n+\n+        for field_name in pk.field_names:\n+            hint = None\n+\n+            try:\n+                field = meta.get_field(field_name)\n+            except FieldDoesNotExist:\n+                field = None\n+\n+            if not field:\n+                hint = f\"{field_name!r} is not a valid field.\"\n+            elif not field.column:\n+                hint = f\"{field_name!r} field has no column.\"\n+            elif field.null:\n+                hint = f\"{field_name!r} field may not set 'null=True'.\"\n+            elif field.generated:\n+                hint = f\"{field_name!r} field is a generated field.\"\n+            else:\n+                seen_columns[field.column].append(field_name)\n+\n+            if hint:\n+                errors.append(\n+                    checks.Error(\n+                        f\"{field_name!r} cannot be included in the composite primary \"\n+                        \"key.\",\n+                        hint=hint,\n+                        obj=cls,\n+                        id=\"models.E042\",\n+                    )\n+                )\n+\n+        for column, field_names in seen_columns.items():\n+            if len(field_names) > 1:\n+                field_name, *rest = field_names\n+                duplicates = \", \".join(repr(field) for field in rest)\n+                errors.append(\n+                    checks.Error(\n+                        f\"{duplicates} cannot be included in the composite primary \"\n+                        \"key.\",\n+                        hint=f\"{duplicates} and {field_name!r} are the same fields.\",\n+                        obj=cls,\n+                        id=\"models.E042\",\n+                    )\n+                )\n+\n+        return errors\n+\n     @classmethod\n     def _check_db_table_comment(cls, databases):\n         if not cls._meta.db_table_comment:\ndiff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex f9cafdb4bb40..855e8cc28d24 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -656,6 +656,8 @@ def deconstruct(self):\n             path = path.replace(\"django.db.models.fields.json\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields.proxy\"):\n             path = path.replace(\"django.db.models.fields.proxy\", \"django.db.models\")\n+        elif path.startswith(\"django.db.models.fields.composite\"):\n+            path = path.replace(\"django.db.models.fields.composite\", \"django.db.models\")\n         elif path.startswith(\"django.db.models.fields\"):\n             path = path.replace(\"django.db.models.fields\", \"django.db.models\")\n         # Return basic info - other fields should override this.\ndiff --git a/django/db/models/fields/composite.py b/django/db/models/fields/composite.py\nnew file mode 100644\nindex 000000000000..550a440dcf39\n--- /dev/null\n+++ b/django/db/models/fields/composite.py\n@@ -0,0 +1,150 @@\n+from django.core import checks\n+from django.db.models import NOT_PROVIDED, Field\n+from django.db.models.expressions import ColPairs\n+from django.db.models.fields.tuple_lookups import (\n+    TupleExact,\n+    TupleGreaterThan,\n+    TupleGreaterThanOrEqual,\n+    TupleIn,\n+    TupleIsNull,\n+    TupleLessThan,\n+    TupleLessThanOrEqual,\n+)\n+from django.utils.functional import cached_property\n+\n+\n+class CompositeAttribute:\n+    def __init__(self, field):\n+        self.field = field\n+\n+    @property\n+    def attnames(self):\n+        return [field.attname for field in self.field.fields]\n+\n+    def __get__(self, instance, cls=None):\n+        return tuple(getattr(instance, attname) for attname in self.attnames)\n+\n+    def __set__(self, instance, values):\n+        attnames = self.attnames\n+        length = len(attnames)\n+\n+        if values is None:\n+            values = (None,) * length\n+\n+        if not isinstance(values, (list, tuple)):\n+            raise ValueError(f\"{self.field.name!r} must be a list or a tuple.\")\n+        if length != len(values):\n+            raise ValueError(f\"{self.field.name!r} must have {length} elements.\")\n+\n+        for attname, value in zip(attnames, values):\n+            setattr(instance, attname, value)\n+\n+\n+class CompositePrimaryKey(Field):\n+    descriptor_class = CompositeAttribute\n+\n+    def __init__(self, *args, **kwargs):\n+        if (\n+            not args\n+            or not all(isinstance(field, str) for field in args)\n+            or len(set(args)) != len(args)\n+        ):\n+            raise ValueError(\"CompositePrimaryKey args must be unique strings.\")\n+        if len(args) == 1:\n+            raise ValueError(\"CompositePrimaryKey must include at least two fields.\")\n+        if kwargs.get(\"default\", NOT_PROVIDED) is not NOT_PROVIDED:\n+            raise ValueError(\"CompositePrimaryKey cannot have a default.\")\n+        if kwargs.get(\"db_default\", NOT_PROVIDED) is not NOT_PROVIDED:\n+            raise ValueError(\"CompositePrimaryKey cannot have a database default.\")\n+        if kwargs.setdefault(\"editable\", False):\n+            raise ValueError(\"CompositePrimaryKey cannot be editable.\")\n+        if not kwargs.setdefault(\"primary_key\", True):\n+            raise ValueError(\"CompositePrimaryKey must be a primary key.\")\n+        if not kwargs.setdefault(\"blank\", True):\n+            raise ValueError(\"CompositePrimaryKey must be blank.\")\n+\n+        self.field_names = args\n+        super().__init__(**kwargs)\n+\n+    def deconstruct(self):\n+        # args is always [] so it can be ignored.\n+        name, path, _, kwargs = super().deconstruct()\n+        return name, path, self.field_names, kwargs\n+\n+    @cached_property\n+    def fields(self):\n+        meta = self.model._meta\n+        return tuple(meta.get_field(field_name) for field_name in self.field_names)\n+\n+    @cached_property\n+    def columns(self):\n+        return tuple(field.column for field in self.fields)\n+\n+    def contribute_to_class(self, cls, name, private_only=False):\n+        super().contribute_to_class(cls, name, private_only=private_only)\n+        cls._meta.pk = self\n+        setattr(cls, self.attname, self.descriptor_class(self))\n+\n+    def get_attname_column(self):\n+        return self.get_attname(), None\n+\n+    def __iter__(self):\n+        return iter(self.fields)\n+\n+    def __len__(self):\n+        return len(self.field_names)\n+\n+    @cached_property\n+    def cached_col(self):\n+        return ColPairs(self.model._meta.db_table, self.fields, self.fields, self)\n+\n+    def get_col(self, alias, output_field=None):\n+        if alias == self.model._meta.db_table and (\n+            output_field is None or output_field == self\n+        ):\n+            return self.cached_col\n+\n+        return ColPairs(alias, self.fields, self.fields, output_field)\n+\n+    def get_pk_value_on_save(self, instance):\n+        values = []\n+\n+        for field in self.fields:\n+            value = field.value_from_object(instance)\n+            if value is None:\n+                value = field.get_pk_value_on_save(instance)\n+            values.append(value)\n+\n+        return tuple(values)\n+\n+    def _check_field_name(self):\n+        if self.name == \"pk\":\n+            return []\n+        return [\n+            checks.Error(\n+                \"'CompositePrimaryKey' must be named 'pk'.\",\n+                obj=self,\n+                id=\"fields.E013\",\n+            )\n+        ]\n+\n+\n+CompositePrimaryKey.register_lookup(TupleExact)\n+CompositePrimaryKey.register_lookup(TupleGreaterThan)\n+CompositePrimaryKey.register_lookup(TupleGreaterThanOrEqual)\n+CompositePrimaryKey.register_lookup(TupleLessThan)\n+CompositePrimaryKey.register_lookup(TupleLessThanOrEqual)\n+CompositePrimaryKey.register_lookup(TupleIn)\n+CompositePrimaryKey.register_lookup(TupleIsNull)\n+\n+\n+def unnest(fields):\n+    result = []\n+\n+    for field in fields:\n+        if isinstance(field, CompositePrimaryKey):\n+            result.extend(field.fields)\n+        else:\n+            result.append(field)\n+\n+    return result\ndiff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex b672a4b488ef..9ef2d2902475 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -624,11 +624,21 @@ def _check_unique_target(self):\n         if not has_unique_constraint:\n             foreign_fields = {f.name for f in self.foreign_related_fields}\n             remote_opts = self.remote_field.model._meta\n-            has_unique_constraint = any(\n-                frozenset(ut) <= foreign_fields for ut in remote_opts.unique_together\n-            ) or any(\n-                frozenset(uc.fields) <= foreign_fields\n-                for uc in remote_opts.total_unique_constraints\n+            has_unique_constraint = (\n+                any(\n+                    frozenset(ut) <= foreign_fields\n+                    for ut in remote_opts.unique_together\n+                )\n+                or any(\n+                    frozenset(uc.fields) <= foreign_fields\n+                    for uc in remote_opts.total_unique_constraints\n+                )\n+                # If the model defines a composite primary key and the foreign key\n+                # refers to it, the target is unique.\n+                or (\n+                    frozenset(field.name for field in remote_opts.pk_fields)\n+                    == foreign_fields\n+                )\n             )\n \n         if not has_unique_constraint:\ndiff --git a/django/db/models/fields/related_lookups.py b/django/db/models/fields/related_lookups.py\nindex 8b5663dfea47..6992d75833f6 100644\n--- a/django/db/models/fields/related_lookups.py\n+++ b/django/db/models/fields/related_lookups.py\n@@ -1,5 +1,6 @@\n from django.db import NotSupportedError\n from django.db.models.expressions import ColPairs\n+from django.db.models.fields import composite\n from django.db.models.fields.tuple_lookups import TupleIn, tuple_lookups\n from django.db.models.lookups import (\n     Exact,\n@@ -19,7 +20,7 @@ def get_normalized_value(value, lhs):\n         if not value._is_pk_set():\n             raise ValueError(\"Model instances passed to related filters must be saved.\")\n         value_list = []\n-        sources = lhs.output_field.path_infos[-1].target_fields\n+        sources = composite.unnest(lhs.output_field.path_infos[-1].target_fields)\n         for source in sources:\n             while not isinstance(value, source.model) and source.remote_field:\n                 source = source.remote_field.model._meta.get_field(\n@@ -30,7 +31,8 @@ def get_normalized_value(value, lhs):\n             except AttributeError:\n                 # A case like Restaurant.objects.filter(place=restaurant_instance),\n                 # where place is a OneToOneField and the primary key of Restaurant.\n-                return (value.pk,)\n+                pk = value.pk\n+                return pk if isinstance(pk, tuple) else (pk,)\n         return tuple(value_list)\n     if not isinstance(value, tuple):\n         return (value,)\ndiff --git a/django/db/models/fields/tuple_lookups.py b/django/db/models/fields/tuple_lookups.py\nindex 6342937cd6ce..e515e971b400 100644\n--- a/django/db/models/fields/tuple_lookups.py\n+++ b/django/db/models/fields/tuple_lookups.py\n@@ -250,6 +250,8 @@ def check_rhs_is_query(self):\n \n     def check_rhs_select_length_equals_lhs_length(self):\n         len_rhs = len(self.rhs.select)\n+        if len_rhs == 1 and isinstance(self.rhs.select[0], ColPairs):\n+            len_rhs = len(self.rhs.select[0])\n         len_lhs = len(self.lhs)\n         if len_rhs != len_lhs:\n             lhs_str = self.get_lhs_str()\n@@ -304,7 +306,13 @@ def as_sqlite(self, compiler, connection):\n         return root.as_sql(compiler, connection)\n \n     def as_subquery(self, compiler, connection):\n-        return compiler.compile(In(self.lhs, self.rhs))\n+        lhs = self.lhs\n+        rhs = self.rhs\n+        if isinstance(lhs, ColPairs):\n+            rhs = rhs.clone()\n+            rhs.set_values([source.name for source in lhs.sources])\n+            lhs = Tuple(lhs)\n+        return compiler.compile(In(lhs, rhs))\n \n \n tuple_lookups = {\ndiff --git a/django/db/models/options.py b/django/db/models/options.py\nindex 68a7228cbea6..7c4cf2229a31 100644\n--- a/django/db/models/options.py\n+++ b/django/db/models/options.py\n@@ -7,7 +7,14 @@\n from django.core.exceptions import FieldDoesNotExist, ImproperlyConfigured\n from django.core.signals import setting_changed\n from django.db import connections\n-from django.db.models import AutoField, Manager, OrderWrt, UniqueConstraint\n+from django.db.models import (\n+    AutoField,\n+    CompositePrimaryKey,\n+    Manager,\n+    OrderWrt,\n+    UniqueConstraint,\n+)\n+from django.db.models.fields import composite\n from django.db.models.query_utils import PathInfo\n from django.utils.datastructures import ImmutableList, OrderedSet\n from django.utils.functional import cached_property\n@@ -973,6 +980,14 @@ def total_unique_constraints(self):\n             )\n         ]\n \n+    @cached_property\n+    def pk_fields(self):\n+        return composite.unnest([self.pk])\n+\n+    @property\n+    def is_composite_pk(self):\n+        return isinstance(self.pk, CompositePrimaryKey)\n+\n     @cached_property\n     def _property_names(self):\n         \"\"\"Return a set of the names of the properties defined on the model.\"\"\"\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 21d5534cc9fc..ea8cc179f3f9 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -171,11 +171,14 @@ def __iter__(self):\n                     \"Raw query must include the primary key\"\n                 )\n             fields = [self.queryset.model_fields.get(c) for c in self.queryset.columns]\n-            converters = compiler.get_converters(\n-                [f.get_col(f.model._meta.db_table) if f else None for f in fields]\n-            )\n+            cols = [f.get_col(f.model._meta.db_table) if f else None for f in fields]\n+            converters = compiler.get_converters(cols)\n             if converters:\n                 query_iterator = compiler.apply_converters(query_iterator, converters)\n+            if compiler.has_composite_fields(cols):\n+                query_iterator = compiler.composite_fields_to_tuples(\n+                    query_iterator, cols\n+                )\n             for values in query_iterator:\n                 # Associate fields to values\n                 model_init_values = [values[pos] for pos in model_init_pos]\ndiff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 49263d5944e4..053bdc09d589 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -7,7 +7,9 @@\n from django.core.exceptions import EmptyResultSet, FieldError, FullResultSet\n from django.db import DatabaseError, NotSupportedError\n from django.db.models.constants import LOOKUP_SEP\n-from django.db.models.expressions import F, OrderBy, RawSQL, Ref, Value\n+from django.db.models.expressions import ColPairs, F, OrderBy, RawSQL, Ref, Value\n+from django.db.models.fields import composite\n+from django.db.models.fields.composite import CompositePrimaryKey\n from django.db.models.functions import Cast, Random\n from django.db.models.lookups import Lookup\n from django.db.models.query_utils import select_related_descend\n@@ -283,6 +285,9 @@ def get_select(self, with_col_aliases=False):\n                 # Reference to a column.\n                 elif isinstance(expression, int):\n                     expression = cols[expression]\n+                # ColPairs cannot be aliased.\n+                if isinstance(expression, ColPairs):\n+                    alias = None\n                 selected.append((alias, expression))\n \n         for select_idx, (alias, expression) in enumerate(selected):\n@@ -997,6 +1002,7 @@ def get_default_columns(\n         # alias for a given field. This also includes None -> start_alias to\n         # be used by local fields.\n         seen_models = {None: start_alias}\n+        select_mask_fields = set(composite.unnest(select_mask))\n \n         for field in opts.concrete_fields:\n             model = field.model._meta.concrete_model\n@@ -1017,7 +1023,7 @@ def get_default_columns(\n                 # parent model data is already present in the SELECT clause,\n                 # and we want to avoid reloading the same data again.\n                 continue\n-            if select_mask and field not in select_mask:\n+            if select_mask and field not in select_mask_fields:\n                 continue\n             alias = self.query.join_parent_model(opts, model, start_alias, seen_models)\n             column = field.get_col(alias)\n@@ -1110,9 +1116,10 @@ def find_ordering_name(\n                 )\n             return results\n         targets, alias, _ = self.query.trim_joins(targets, joins, path)\n+        target_fields = composite.unnest(targets)\n         return [\n             (OrderBy(transform_function(t, alias), descending=descending), False)\n-            for t in targets\n+            for t in target_fields\n         ]\n \n     def _setup_joins(self, pieces, opts, alias):\n@@ -1504,13 +1511,25 @@ def _get_field_choices():\n         return result\n \n     def get_converters(self, expressions):\n+        i = 0\n         converters = {}\n-        for i, expression in enumerate(expressions):\n-            if expression:\n+\n+        for expression in expressions:\n+            if isinstance(expression, ColPairs):\n+                cols = expression.get_source_expressions()\n+                cols_converters = self.get_converters(cols)\n+                for j, (convs, col) in cols_converters.items():\n+                    converters[i + j] = (convs, col)\n+                i += len(expression)\n+            elif expression:\n                 backend_converters = self.connection.ops.get_db_converters(expression)\n                 field_converters = expression.get_db_converters(self.connection)\n                 if backend_converters or field_converters:\n                     converters[i] = (backend_converters + field_converters, expression)\n+                i += 1\n+            else:\n+                i += 1\n+\n         return converters\n \n     def apply_converters(self, rows, converters):\n@@ -1524,6 +1543,24 @@ def apply_converters(self, rows, converters):\n                 row[pos] = value\n             yield row\n \n+    def has_composite_fields(self, expressions):\n+        # Check for composite fields before calling the relatively costly\n+        # composite_fields_to_tuples.\n+        return any(isinstance(expression, ColPairs) for expression in expressions)\n+\n+    def composite_fields_to_tuples(self, rows, expressions):\n+        col_pair_slices = [\n+            slice(i, i + len(expression))\n+            for i, expression in enumerate(expressions)\n+            if isinstance(expression, ColPairs)\n+        ]\n+\n+        for row in map(list, rows):\n+            for pos in col_pair_slices:\n+                row[pos] = (tuple(row[pos]),)\n+\n+            yield row\n+\n     def results_iter(\n         self,\n         results=None,\n@@ -1541,8 +1578,10 @@ def results_iter(\n         rows = chain.from_iterable(results)\n         if converters:\n             rows = self.apply_converters(rows, converters)\n-            if tuple_expected:\n-                rows = map(tuple, rows)\n+        if self.has_composite_fields(fields):\n+            rows = self.composite_fields_to_tuples(rows, fields)\n+        if tuple_expected:\n+            rows = map(tuple, rows)\n         return rows\n \n     def has_results(self):\n@@ -1863,6 +1902,18 @@ def execute_sql(self, returning_fields=None):\n                     )\n                 ]\n                 cols = [field.get_col(opts.db_table) for field in self.returning_fields]\n+            elif isinstance(opts.pk, CompositePrimaryKey):\n+                returning_field = returning_fields[0]\n+                cols = [returning_field.get_col(opts.db_table)]\n+                rows = [\n+                    (\n+                        self.connection.ops.last_insert_id(\n+                            cursor,\n+                            opts.db_table,\n+                            returning_field.column,\n+                        ),\n+                    )\n+                ]\n             else:\n                 cols = [opts.pk.get_col(opts.db_table)]\n                 rows = [\n@@ -1876,8 +1927,10 @@ def execute_sql(self, returning_fields=None):\n                 ]\n         converters = self.get_converters(cols)\n         if converters:\n-            rows = list(self.apply_converters(rows, converters))\n-        return rows\n+            rows = self.apply_converters(rows, converters)\n+        if self.has_composite_fields(cols):\n+            rows = self.composite_fields_to_tuples(rows, cols)\n+        return list(rows)\n \n \n class SQLDeleteCompiler(SQLCompiler):\n@@ -2065,6 +2118,7 @@ def pre_sql_setup(self):\n         query.add_fields(fields)\n         super().pre_sql_setup()\n \n+        is_composite_pk = meta.is_composite_pk\n         must_pre_select = (\n             count > 1 and not self.connection.features.update_can_self_select\n         )\n@@ -2079,7 +2133,8 @@ def pre_sql_setup(self):\n             idents = []\n             related_ids = collections.defaultdict(list)\n             for rows in query.get_compiler(self.using).execute_sql(MULTI):\n-                idents.extend(r[0] for r in rows)\n+                pks = [row if is_composite_pk else row[0] for row in rows]\n+                idents.extend(pks)\n                 for parent, index in related_ids_index:\n                     related_ids[parent].extend(r[index] for r in rows)\n             self.query.add_filter(\"pk__in\", idents)\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex b7b93c235ae1..cca11bfcc213 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -627,8 +627,12 @@ def get_aggregation(self, using, aggregate_exprs):\n         if result is None:\n             result = empty_set_result\n         else:\n-            converters = compiler.get_converters(outer_query.annotation_select.values())\n-            result = next(compiler.apply_converters((result,), converters))\n+            cols = outer_query.annotation_select.values()\n+            converters = compiler.get_converters(cols)\n+            rows = compiler.apply_converters((result,), converters)\n+            if compiler.has_composite_fields(cols):\n+                rows = compiler.composite_fields_to_tuples(rows, cols)\n+            result = next(rows)\n \n         return dict(zip(outer_query.annotation_select, result))\n \ndiff --git a/docs/ref/checks.txt b/docs/ref/checks.txt\nindex 2308a854c73d..b0a98bde2810 100644\n--- a/docs/ref/checks.txt\n+++ b/docs/ref/checks.txt\n@@ -181,6 +181,7 @@ Model fields\n * **fields.E011**: ``<database>`` does not support default database values with\n   expressions (``db_default``).\n * **fields.E012**: ``<expression>`` cannot be used in ``db_default``.\n+* **fields.E013**: ``CompositePrimaryKey`` must be named ``pk``.\n * **fields.E100**: ``AutoField``\\s must set primary_key=True.\n * **fields.E110**: ``BooleanField``\\s do not accept null values. *This check\n   appeared before support for null values was added in Django 2.1.*\n@@ -417,6 +418,8 @@ Models\n * **models.W040**: ``<database>`` does not support indexes with non-key\n   columns.\n * **models.E041**: ``constraints`` refers to the joined field ``<field name>``.\n+* **models.E042**: ``<field name>`` cannot be included in the composite\n+  primary key.\n * **models.W042**: Auto-created primary key used when not defining a primary\n   key type, by default ``django.db.models.AutoField``.\n * **models.W043**: ``<database>`` does not support indexes on expressions.\ndiff --git a/docs/ref/models/fields.txt b/docs/ref/models/fields.txt\nindex 07e86785d91f..5b0f127c6f28 100644\n--- a/docs/ref/models/fields.txt\n+++ b/docs/ref/models/fields.txt\n@@ -707,6 +707,23 @@ or :class:`~django.forms.NullBooleanSelect` if :attr:`null=True <Field.null>`.\n The default value of ``BooleanField`` is ``None`` when :attr:`Field.default`\n isn't defined.\n \n+``CompositePrimaryKey``\n+-----------------------\n+\n+.. versionadded:: 5.2\n+\n+.. class:: CompositePrimaryKey(*field_names, **options)\n+\n+A virtual field used for defining a composite primary key.\n+\n+This field must be defined as the model's ``pk`` field. If present, Django will\n+create the underlying model table with a composite primary key.\n+\n+The ``*field_names`` argument is a list of positional field names that compose\n+the primary key.\n+\n+See :doc:`/topics/composite-primary-key` for more details.\n+\n ``CharField``\n -------------\n \n@@ -1615,6 +1632,8 @@ not an instance of ``UUID``.\n     hyphens, because PostgreSQL and MariaDB 10.7+ store them in a hyphenated\n     uuid datatype type.\n \n+.. _relationship-fields:\n+\n Relationship fields\n ===================\n \ndiff --git a/docs/releases/5.2.txt b/docs/releases/5.2.txt\nindex 88a1daa45dc7..6d6e83a7f6d8 100644\n--- a/docs/releases/5.2.txt\n+++ b/docs/releases/5.2.txt\n@@ -31,6 +31,25 @@ and only officially support the latest release of each series.\n What's new in Django 5.2\n ========================\n \n+Composite Primary Keys\n+----------------------\n+\n+The new :class:`django.db.models.CompositePrimaryKey` allows tables to be\n+created with a primary key consisting of multiple fields.\n+\n+To use a composite primary key, when creating a model set the ``pk`` field to\n+be a ``CompositePrimaryKey``::\n+\n+    from django.db import models\n+\n+\n+    class Release(models.Model):\n+        pk = models.CompositePrimaryKey(\"version\", \"name\")\n+        version = models.IntegerField()\n+        name = models.CharField(max_length=20)\n+\n+See :doc:`/topics/composite-primary-key` for more details.\n+\n Minor features\n --------------\n \ndiff --git a/docs/topics/composite-primary-key.txt b/docs/topics/composite-primary-key.txt\nnew file mode 100644\nindex 000000000000..9e5234ca9faa\n--- /dev/null\n+++ b/docs/topics/composite-primary-key.txt\n@@ -0,0 +1,183 @@\n+======================\n+Composite primary keys\n+======================\n+\n+.. versionadded:: 5.2\n+\n+In Django, each model has a primary key. By default, this primary key consists\n+of a single field.\n+\n+In most cases, a single primary key should suffice. In database design,\n+however, defining a primary key consisting of multiple fields is sometimes\n+necessary.\n+\n+To use a composite primary key, when creating a model set the ``pk`` field to\n+be a :class:`.CompositePrimaryKey`::\n+\n+    class Product(models.Model):\n+        name = models.CharField(max_length=100)\n+\n+\n+    class Order(models.Model):\n+        reference = models.CharField(max_length=20, primary_key=True)\n+\n+\n+    class OrderLineItem(models.Model):\n+        pk = models.CompositePrimaryKey(\"product_id\", \"order_id\")\n+        product = models.ForeignKey(Product, on_delete=models.CASCADE)\n+        order = models.ForeignKey(Order, on_delete=models.CASCADE)\n+        quantity = models.IntegerField()\n+\n+This will instruct Django to create a composite primary key\n+(``PRIMARY KEY (product_id, order_id)``) when creating the table.\n+\n+A composite primary key is represented by a ``tuple``:\n+\n+.. code-block:: pycon\n+\n+    >>> product = Product.objects.create(name=\"apple\")\n+    >>> order = Order.objects.create(reference=\"A755H\")\n+    >>> item = OrderLineItem.objects.create(product=product, order=order, quantity=1)\n+    >>> item.pk\n+    (1, \"A755H\")\n+\n+You can assign a ``tuple`` to a composite primary key. This sets the associated\n+field values.\n+\n+.. code-block:: pycon\n+\n+    >>> item = OrderLineItem(pk=(2, \"B142C\"))\n+    >>> item.pk\n+    (2, \"B142C\")\n+    >>> item.product_id\n+    2\n+    >>> item.order_id\n+    \"B142C\"\n+\n+A composite primary key can also be filtered by a ``tuple``:\n+\n+.. code-block:: pycon\n+\n+    >>> OrderLineItem.objects.filter(pk=(1, \"A755H\")).count()\n+    1\n+\n+We're still working on composite primary key support for\n+:ref:`relational fields <cpk-and-relations>`, including\n+:class:`.GenericForeignKey` fields, and the Django admin. Models with composite\n+primary keys cannot be registered in the Django admin at this time. You can\n+expect to see this in future releases.\n+\n+Migrating to a composite primary key\n+====================================\n+\n+Django doesn't support migrating to, or from, a composite primary key after the\n+table is created. It also doesn't support adding or removing fields from the\n+composite primary key.\n+\n+If you would like to migrate an existing table from a single primary key to a\n+composite primary key, follow your database backend's instructions to do so.\n+\n+Once the composite primary key is in place, add the ``CompositePrimaryKey``\n+field to your model. This allows Django to recognize and handle the composite\n+primary key appropriately.\n+\n+While migration operations (e.g. ``AddField``, ``AlterField``) on primary key\n+fields are not supported, ``makemigrations`` will still detect changes.\n+\n+In order to avoid errors, it's recommended to apply such migrations with\n+``--fake``.\n+\n+Alternatively, :class:`.SeparateDatabaseAndState` may be used to execute the\n+backend-specific migrations and Django-generated migrations in a single\n+operation.\n+\n+.. _cpk-and-relations:\n+\n+Composite primary keys and relations\n+====================================\n+\n+:ref:`Relationship fields <relationship-fields>`, including\n+:ref:`generic relations <generic-relations>` do not support composite primary\n+keys.\n+\n+For example, given the ``OrderLineItem`` model, the following is not\n+supported::\n+\n+    class Foo(models.Model):\n+        item = models.ForeignKey(OrderLineItem, on_delete=models.CASCADE)\n+\n+Because ``ForeignKey`` currently cannot reference models with composite primary\n+keys.\n+\n+To work around this limitation, ``ForeignObject`` can be used as an\n+alternative::\n+\n+    class Foo(models.Model):\n+        item_order_id = models.IntegerField()\n+        item_product_id = models.CharField(max_length=20)\n+        item = models.ForeignObject(\n+            OrderLineItem,\n+            on_delete=models.CASCADE,\n+            from_fields=(\"item_order_id\", \"item_product_id\"),\n+            to_fields=(\"order_id\", \"product_id\"),\n+        )\n+\n+``ForeignObject`` is much like ``ForeignKey``, except that it doesn't create\n+any columns (e.g. ``item_id``), foreign key constraints or indexes in the\n+database.\n+\n+.. warning::\n+\n+    ``ForeignObject`` is an internal API. This means it is not covered by our\n+    :ref:`deprecation policy <internal-release-deprecation-policy>`.\n+\n+Composite primary keys and database functions\n+=============================================\n+\n+Many database functions only accept a single expression.\n+\n+.. code-block:: sql\n+\n+    MAX(\"order_id\")  -- OK\n+    MAX(\"product_id\", \"order_id\")  -- ERROR\n+\n+As a consequence, they cannot be used with composite primary key references as\n+they are composed of multiple column expressions.\n+\n+.. code-block:: python\n+\n+    Max(\"order_id\")  # OK\n+    Max(\"pk\")  # ERROR\n+\n+Composite primary keys in forms\n+===============================\n+\n+As a composite primary key is a virtual field, a field which doesn't represent\n+a single database column, this field is excluded from ModelForms.\n+\n+For example, take the following form::\n+\n+    class OrderLineItemForm(forms.ModelForm):\n+        class Meta:\n+            model = OrderLineItem\n+            fields = \"__all__\"\n+\n+This form does not have a form field ``pk`` for the composite primary key:\n+\n+.. code-block:: pycon\n+\n+    >>> OrderLineItemForm()\n+    <OrderLineItemForm bound=False, valid=Unknown, fields=(product;order;quantity)>\n+\n+Setting the primary composite field ``pk`` as a form field raises an unknown\n+field :exc:`.FieldError`.\n+\n+.. admonition:: Primary key fields are read only\n+\n+    If you change the value of a primary key on an existing object and then\n+    save it, a new object will be created alongside the old one (see\n+    :attr:`.Field.primary_key`).\n+\n+    This is also true of composite primary keys. Hence, you may want to set\n+    :attr:`.Field.editable` to ``False`` on all primary key fields to exclude\n+    them from ModelForms.\ndiff --git a/docs/topics/index.txt b/docs/topics/index.txt\nindex ffb9fa9d9273..4f837c81e2c7 100644\n--- a/docs/topics/index.txt\n+++ b/docs/topics/index.txt\n@@ -19,6 +19,7 @@ Introductions to all the key parts of Django you'll need to know:\n    auth/index\n    cache\n    conditional-view-processing\n+   composite-primary-key\n    signing\n    email\n    i18n/index\ndiff --git a/tests/admin_registration/models.py b/tests/admin_registration/models.py\nindex 0ae925113346..2231c236dee4 100644\n--- a/tests/admin_registration/models.py\n+++ b/tests/admin_registration/models.py\n@@ -20,3 +20,9 @@ class Meta:\n \n class Place(Location):\n     name = models.CharField(max_length=200)\n+\n+\n+class Guest(models.Model):\n+    pk = models.CompositePrimaryKey(\"traveler\", \"place\")\n+    traveler = models.ForeignKey(Traveler, on_delete=models.CASCADE)\n+    place = models.ForeignKey(Place, on_delete=models.CASCADE)\ndiff --git a/tests/admin_registration/tests.py b/tests/admin_registration/tests.py\nindex 3b0e656f5f35..0a881caf6506 100644\n--- a/tests/admin_registration/tests.py\n+++ b/tests/admin_registration/tests.py\n@@ -5,7 +5,7 @@\n from django.core.exceptions import ImproperlyConfigured\n from django.test import SimpleTestCase\n \n-from .models import Location, Person, Place, Traveler\n+from .models import Guest, Location, Person, Place, Traveler\n \n \n class NameAdmin(admin.ModelAdmin):\n@@ -92,6 +92,14 @@ def test_abstract_model(self):\n         with self.assertRaisesMessage(ImproperlyConfigured, msg):\n             self.site.register(Location)\n \n+    def test_composite_pk_model(self):\n+        msg = (\n+            \"The model Guest has a composite primary key, so it cannot be registered \"\n+            \"with admin.\"\n+        )\n+        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n+            self.site.register(Guest)\n+\n     def test_is_registered_model(self):\n         \"Checks for registered models should return true.\"\n         self.site.register(Person)\ndiff --git a/tests/composite_pk/__init__.py b/tests/composite_pk/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/composite_pk/fixtures/tenant.json b/tests/composite_pk/fixtures/tenant.json\nnew file mode 100644\nindex 000000000000..3eeff42fefde\n--- /dev/null\n+++ b/tests/composite_pk/fixtures/tenant.json\n@@ -0,0 +1,75 @@\n+[\n+    {\n+        \"pk\": 1,\n+        \"model\": \"composite_pk.tenant\",\n+        \"fields\": {\n+            \"id\": 1,\n+            \"name\": \"Tenant 1\"\n+        }\n+    },\n+    {\n+        \"pk\": 2,\n+        \"model\": \"composite_pk.tenant\",\n+        \"fields\": {\n+            \"id\": 2,\n+            \"name\": \"Tenant 2\"\n+        }\n+    },\n+    {\n+        \"pk\": 3,\n+        \"model\": \"composite_pk.tenant\",\n+        \"fields\": {\n+            \"id\": 3,\n+            \"name\": \"Tenant 3\"\n+        }\n+    },\n+    {\n+        \"pk\": [1, 1],\n+        \"model\": \"composite_pk.user\",\n+        \"fields\": {\n+            \"tenant_id\": 1,\n+            \"id\": 1,\n+            \"email\": \"user0001@example.com\"\n+        }\n+    },\n+    {\n+        \"pk\": [1, 2],\n+        \"model\": \"composite_pk.user\",\n+        \"fields\": {\n+            \"tenant_id\": 1,\n+            \"id\": 2,\n+            \"email\": \"user0002@example.com\"\n+        }\n+    },\n+    {\n+        \"pk\": [2, 3],\n+        \"model\": \"composite_pk.user\",\n+        \"fields\": {\n+            \"email\": \"user0003@example.com\"\n+        }\n+    },\n+    {\n+        \"model\": \"composite_pk.user\",\n+        \"fields\": {\n+            \"tenant_id\": 2,\n+            \"id\": 4,\n+            \"email\": \"user0004@example.com\"\n+        }\n+    },\n+    {\n+        \"pk\": [2, \"11111111-1111-1111-1111-111111111111\"],\n+        \"model\": \"composite_pk.post\",\n+        \"fields\": {\n+            \"tenant_id\": 2,\n+            \"id\": \"11111111-1111-1111-1111-111111111111\"\n+        }\n+    },\n+    {\n+        \"pk\": [2, \"ffffffff-ffff-ffff-ffff-ffffffffffff\"],\n+        \"model\": \"composite_pk.post\",\n+        \"fields\": {\n+            \"tenant_id\": 2,\n+            \"id\": \"ffffffff-ffff-ffff-ffff-ffffffffffff\"\n+        }\n+    }\n+]\ndiff --git a/tests/composite_pk/models/__init__.py b/tests/composite_pk/models/__init__.py\nnew file mode 100644\nindex 000000000000..35c394371696\n--- /dev/null\n+++ b/tests/composite_pk/models/__init__.py\n@@ -0,0 +1,9 @@\n+from .tenant import Comment, Post, Tenant, Token, User\n+\n+__all__ = [\n+    \"Comment\",\n+    \"Post\",\n+    \"Tenant\",\n+    \"Token\",\n+    \"User\",\n+]\ndiff --git a/tests/composite_pk/models/tenant.py b/tests/composite_pk/models/tenant.py\nnew file mode 100644\nindex 000000000000..ac0b3d9715a1\n--- /dev/null\n+++ b/tests/composite_pk/models/tenant.py\n@@ -0,0 +1,50 @@\n+from django.db import models\n+\n+\n+class Tenant(models.Model):\n+    name = models.CharField(max_length=10, default=\"\", blank=True)\n+\n+\n+class Token(models.Model):\n+    pk = models.CompositePrimaryKey(\"tenant_id\", \"id\")\n+    tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE, related_name=\"tokens\")\n+    id = models.SmallIntegerField()\n+    secret = models.CharField(max_length=10, default=\"\", blank=True)\n+\n+\n+class BaseModel(models.Model):\n+    pk = models.CompositePrimaryKey(\"tenant_id\", \"id\")\n+    tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE)\n+    id = models.SmallIntegerField(unique=True)\n+\n+    class Meta:\n+        abstract = True\n+\n+\n+class User(BaseModel):\n+    email = models.EmailField(unique=True)\n+\n+\n+class Comment(models.Model):\n+    pk = models.CompositePrimaryKey(\"tenant\", \"id\")\n+    tenant = models.ForeignKey(\n+        Tenant,\n+        on_delete=models.CASCADE,\n+        related_name=\"comments\",\n+    )\n+    id = models.SmallIntegerField(unique=True, db_column=\"comment_id\")\n+    user_id = models.SmallIntegerField()\n+    user = models.ForeignObject(\n+        User,\n+        on_delete=models.CASCADE,\n+        from_fields=(\"tenant_id\", \"user_id\"),\n+        to_fields=(\"tenant_id\", \"id\"),\n+        related_name=\"comments\",\n+    )\n+    text = models.TextField(default=\"\", blank=True)\n+\n+\n+class Post(models.Model):\n+    pk = models.CompositePrimaryKey(\"tenant_id\", \"id\")\n+    tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE)\n+    id = models.UUIDField()\ndiff --git a/tests/composite_pk/test_aggregate.py b/tests/composite_pk/test_aggregate.py\nnew file mode 100644\nindex 000000000000..b5474c5218bc\n--- /dev/null\n+++ b/tests/composite_pk/test_aggregate.py\n@@ -0,0 +1,139 @@\n+from django.db import NotSupportedError\n+from django.db.models import Count, Q\n+from django.test import TestCase\n+\n+from .models import Comment, Tenant, User\n+\n+\n+class CompositePKAggregateTests(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.tenant_1 = Tenant.objects.create()\n+        cls.tenant_2 = Tenant.objects.create()\n+        cls.user_1 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=1,\n+            email=\"user0001@example.com\",\n+        )\n+        cls.user_2 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=2,\n+            email=\"user0002@example.com\",\n+        )\n+        cls.user_3 = User.objects.create(\n+            tenant=cls.tenant_2,\n+            id=3,\n+            email=\"user0003@example.com\",\n+        )\n+        cls.comment_1 = Comment.objects.create(id=1, user=cls.user_2, text=\"foo\")\n+        cls.comment_2 = Comment.objects.create(id=2, user=cls.user_1, text=\"bar\")\n+        cls.comment_3 = Comment.objects.create(id=3, user=cls.user_1, text=\"foobar\")\n+        cls.comment_4 = Comment.objects.create(id=4, user=cls.user_3, text=\"foobarbaz\")\n+        cls.comment_5 = Comment.objects.create(id=5, user=cls.user_3, text=\"barbaz\")\n+        cls.comment_6 = Comment.objects.create(id=6, user=cls.user_3, text=\"baz\")\n+\n+    def test_users_annotated_with_comments_id_count(self):\n+        user_1, user_2, user_3 = User.objects.annotate(Count(\"comments__id\")).order_by(\n+            \"pk\"\n+        )\n+\n+        self.assertEqual(user_1, self.user_1)\n+        self.assertEqual(user_1.comments__id__count, 2)\n+        self.assertEqual(user_2, self.user_2)\n+        self.assertEqual(user_2.comments__id__count, 1)\n+        self.assertEqual(user_3, self.user_3)\n+        self.assertEqual(user_3.comments__id__count, 3)\n+\n+    def test_users_annotated_with_aliased_comments_id_count(self):\n+        user_1, user_2, user_3 = User.objects.annotate(\n+            comments_count=Count(\"comments__id\")\n+        ).order_by(\"pk\")\n+\n+        self.assertEqual(user_1, self.user_1)\n+        self.assertEqual(user_1.comments_count, 2)\n+        self.assertEqual(user_2, self.user_2)\n+        self.assertEqual(user_2.comments_count, 1)\n+        self.assertEqual(user_3, self.user_3)\n+        self.assertEqual(user_3.comments_count, 3)\n+\n+    def test_users_annotated_with_comments_count(self):\n+        user_1, user_2, user_3 = User.objects.annotate(Count(\"comments\")).order_by(\"pk\")\n+\n+        self.assertEqual(user_1, self.user_1)\n+        self.assertEqual(user_1.comments__count, 2)\n+        self.assertEqual(user_2, self.user_2)\n+        self.assertEqual(user_2.comments__count, 1)\n+        self.assertEqual(user_3, self.user_3)\n+        self.assertEqual(user_3.comments__count, 3)\n+\n+    def test_users_annotated_with_comments_count_filter(self):\n+        user_1, user_2, user_3 = User.objects.annotate(\n+            comments__count=Count(\n+                \"comments\", filter=Q(pk__in=[self.user_1.pk, self.user_2.pk])\n+            )\n+        ).order_by(\"pk\")\n+\n+        self.assertEqual(user_1, self.user_1)\n+        self.assertEqual(user_1.comments__count, 2)\n+        self.assertEqual(user_2, self.user_2)\n+        self.assertEqual(user_2.comments__count, 1)\n+        self.assertEqual(user_3, self.user_3)\n+        self.assertEqual(user_3.comments__count, 0)\n+\n+    def test_count_distinct_not_supported(self):\n+        with self.assertRaisesMessage(\n+            NotSupportedError, \"COUNT(DISTINCT) doesn't support composite primary keys\"\n+        ):\n+            self.assertIsNone(\n+                User.objects.annotate(comments__count=Count(\"comments\", distinct=True))\n+            )\n+\n+    def test_user_values_annotated_with_comments_id_count(self):\n+        self.assertSequenceEqual(\n+            User.objects.values(\"pk\").annotate(Count(\"comments__id\")).order_by(\"pk\"),\n+            (\n+                {\"pk\": self.user_1.pk, \"comments__id__count\": 2},\n+                {\"pk\": self.user_2.pk, \"comments__id__count\": 1},\n+                {\"pk\": self.user_3.pk, \"comments__id__count\": 3},\n+            ),\n+        )\n+\n+    def test_user_values_annotated_with_filtered_comments_id_count(self):\n+        self.assertSequenceEqual(\n+            User.objects.values(\"pk\")\n+            .annotate(\n+                comments_count=Count(\n+                    \"comments__id\",\n+                    filter=Q(comments__text__icontains=\"foo\"),\n+                )\n+            )\n+            .order_by(\"pk\"),\n+            (\n+                {\"pk\": self.user_1.pk, \"comments_count\": 1},\n+                {\"pk\": self.user_2.pk, \"comments_count\": 1},\n+                {\"pk\": self.user_3.pk, \"comments_count\": 1},\n+            ),\n+        )\n+\n+    def test_filter_and_count_users_by_comments_fields(self):\n+        users = User.objects.filter(comments__id__gt=2).order_by(\"pk\")\n+        self.assertEqual(users.count(), 4)\n+        self.assertSequenceEqual(\n+            users, (self.user_1, self.user_3, self.user_3, self.user_3)\n+        )\n+\n+        users = User.objects.filter(comments__text__icontains=\"foo\").order_by(\"pk\")\n+        self.assertEqual(users.count(), 3)\n+        self.assertSequenceEqual(users, (self.user_1, self.user_2, self.user_3))\n+\n+        users = User.objects.filter(comments__text__icontains=\"baz\").order_by(\"pk\")\n+        self.assertEqual(users.count(), 3)\n+        self.assertSequenceEqual(users, (self.user_3, self.user_3, self.user_3))\n+\n+    def test_order_by_comments_id_count(self):\n+        self.assertSequenceEqual(\n+            User.objects.annotate(comments_count=Count(\"comments__id\")).order_by(\n+                \"-comments_count\"\n+            ),\n+            (self.user_3, self.user_1, self.user_2),\n+        )\ndiff --git a/tests/composite_pk/test_checks.py b/tests/composite_pk/test_checks.py\nnew file mode 100644\nindex 000000000000..02a162c31df5\n--- /dev/null\n+++ b/tests/composite_pk/test_checks.py\n@@ -0,0 +1,242 @@\n+from django.core import checks\n+from django.db import connection, models\n+from django.db.models import F\n+from django.test import TestCase\n+from django.test.utils import isolate_apps\n+\n+\n+@isolate_apps(\"composite_pk\")\n+class CompositePKChecksTests(TestCase):\n+    maxDiff = None\n+\n+    def test_composite_pk_must_be_unique_strings(self):\n+        test_cases = (\n+            (),\n+            (0,),\n+            (1,),\n+            (\"id\", False),\n+            (\"id\", \"id\"),\n+            ((\"id\",),),\n+        )\n+\n+        for i, args in enumerate(test_cases):\n+            with (\n+                self.subTest(args=args),\n+                self.assertRaisesMessage(\n+                    ValueError, \"CompositePrimaryKey args must be unique strings.\"\n+                ),\n+            ):\n+                models.CompositePrimaryKey(*args)\n+\n+    def test_composite_pk_must_include_at_least_2_fields(self):\n+        expected_message = \"CompositePrimaryKey must include at least two fields.\"\n+        with self.assertRaisesMessage(ValueError, expected_message):\n+            models.CompositePrimaryKey(\"id\")\n+\n+    def test_composite_pk_cannot_have_a_default(self):\n+        expected_message = \"CompositePrimaryKey cannot have a default.\"\n+        with self.assertRaisesMessage(ValueError, expected_message):\n+            models.CompositePrimaryKey(\"tenant_id\", \"id\", default=(1, 1))\n+\n+    def test_composite_pk_cannot_have_a_database_default(self):\n+        expected_message = \"CompositePrimaryKey cannot have a database default.\"\n+        with self.assertRaisesMessage(ValueError, expected_message):\n+            models.CompositePrimaryKey(\"tenant_id\", \"id\", db_default=models.F(\"id\"))\n+\n+    def test_composite_pk_cannot_be_editable(self):\n+        expected_message = \"CompositePrimaryKey cannot be editable.\"\n+        with self.assertRaisesMessage(ValueError, expected_message):\n+            models.CompositePrimaryKey(\"tenant_id\", \"id\", editable=True)\n+\n+    def test_composite_pk_must_be_a_primary_key(self):\n+        expected_message = \"CompositePrimaryKey must be a primary key.\"\n+        with self.assertRaisesMessage(ValueError, expected_message):\n+            models.CompositePrimaryKey(\"tenant_id\", \"id\", primary_key=False)\n+\n+    def test_composite_pk_must_be_blank(self):\n+        expected_message = \"CompositePrimaryKey must be blank.\"\n+        with self.assertRaisesMessage(ValueError, expected_message):\n+            models.CompositePrimaryKey(\"tenant_id\", \"id\", blank=False)\n+\n+    def test_composite_pk_must_not_have_other_pk_field(self):\n+        class Foo(models.Model):\n+            pk = models.CompositePrimaryKey(\"foo_id\", \"id\")\n+            foo_id = models.IntegerField()\n+            id = models.IntegerField(primary_key=True)\n+\n+        self.assertEqual(\n+            Foo.check(databases=self.databases),\n+            [\n+                checks.Error(\n+                    \"The model cannot have more than one field with \"\n+                    \"'primary_key=True'.\",\n+                    obj=Foo,\n+                    id=\"models.E026\",\n+                ),\n+            ],\n+        )\n+\n+    def test_composite_pk_cannot_include_nullable_field(self):\n+        class Foo(models.Model):\n+            pk = models.CompositePrimaryKey(\"foo_id\", \"id\")\n+            foo_id = models.IntegerField()\n+            id = models.IntegerField(null=True)\n+\n+        self.assertEqual(\n+            Foo.check(databases=self.databases),\n+            [\n+                checks.Error(\n+                    \"'id' cannot be included in the composite primary key.\",\n+                    hint=\"'id' field may not set 'null=True'.\",\n+                    obj=Foo,\n+                    id=\"models.E042\",\n+                ),\n+            ],\n+        )\n+\n+    def test_composite_pk_can_include_fk_name(self):\n+        class Foo(models.Model):\n+            pass\n+\n+        class Bar(models.Model):\n+            pk = models.CompositePrimaryKey(\"foo\", \"id\")\n+            foo = models.ForeignKey(Foo, on_delete=models.CASCADE)\n+            id = models.SmallIntegerField()\n+\n+        self.assertEqual(Foo.check(databases=self.databases), [])\n+        self.assertEqual(Bar.check(databases=self.databases), [])\n+\n+    def test_composite_pk_cannot_include_same_field(self):\n+        class Foo(models.Model):\n+            pass\n+\n+        class Bar(models.Model):\n+            pk = models.CompositePrimaryKey(\"foo\", \"foo_id\")\n+            foo = models.ForeignKey(Foo, on_delete=models.CASCADE)\n+            id = models.SmallIntegerField()\n+\n+        self.assertEqual(Foo.check(databases=self.databases), [])\n+        self.assertEqual(\n+            Bar.check(databases=self.databases),\n+            [\n+                checks.Error(\n+                    \"'foo_id' cannot be included in the composite primary key.\",\n+                    hint=\"'foo_id' and 'foo' are the same fields.\",\n+                    obj=Bar,\n+                    id=\"models.E042\",\n+                ),\n+            ],\n+        )\n+\n+    def test_composite_pk_cannot_include_composite_pk_field(self):\n+        class Foo(models.Model):\n+            pk = models.CompositePrimaryKey(\"id\", \"pk\")\n+            id = models.SmallIntegerField()\n+\n+        self.assertEqual(\n+            Foo.check(databases=self.databases),\n+            [\n+                checks.Error(\n+                    \"'pk' cannot be included in the composite primary key.\",\n+                    hint=\"'pk' field has no column.\",\n+                    obj=Foo,\n+                    id=\"models.E042\",\n+                ),\n+            ],\n+        )\n+\n+    def test_composite_pk_cannot_include_db_column(self):\n+        class Foo(models.Model):\n+            pk = models.CompositePrimaryKey(\"foo\", \"bar\")\n+            foo = models.SmallIntegerField(db_column=\"foo_id\")\n+            bar = models.SmallIntegerField(db_column=\"bar_id\")\n+\n+        class Bar(models.Model):\n+            pk = models.CompositePrimaryKey(\"foo_id\", \"bar_id\")\n+            foo = models.SmallIntegerField(db_column=\"foo_id\")\n+            bar = models.SmallIntegerField(db_column=\"bar_id\")\n+\n+        self.assertEqual(Foo.check(databases=self.databases), [])\n+        self.assertEqual(\n+            Bar.check(databases=self.databases),\n+            [\n+                checks.Error(\n+                    \"'foo_id' cannot be included in the composite primary key.\",\n+                    hint=\"'foo_id' is not a valid field.\",\n+                    obj=Bar,\n+                    id=\"models.E042\",\n+                ),\n+                checks.Error(\n+                    \"'bar_id' cannot be included in the composite primary key.\",\n+                    hint=\"'bar_id' is not a valid field.\",\n+                    obj=Bar,\n+                    id=\"models.E042\",\n+                ),\n+            ],\n+        )\n+\n+    def test_foreign_object_can_refer_composite_pk(self):\n+        class Foo(models.Model):\n+            pass\n+\n+        class Bar(models.Model):\n+            pk = models.CompositePrimaryKey(\"foo_id\", \"id\")\n+            foo = models.ForeignKey(Foo, on_delete=models.CASCADE)\n+            id = models.IntegerField()\n+\n+        class Baz(models.Model):\n+            pk = models.CompositePrimaryKey(\"foo_id\", \"id\")\n+            foo = models.ForeignKey(Foo, on_delete=models.CASCADE)\n+            id = models.IntegerField()\n+            bar_id = models.IntegerField()\n+            bar = models.ForeignObject(\n+                Bar,\n+                on_delete=models.CASCADE,\n+                from_fields=(\"foo_id\", \"bar_id\"),\n+                to_fields=(\"foo_id\", \"id\"),\n+            )\n+\n+        self.assertEqual(Foo.check(databases=self.databases), [])\n+        self.assertEqual(Bar.check(databases=self.databases), [])\n+        self.assertEqual(Baz.check(databases=self.databases), [])\n+\n+    def test_composite_pk_must_be_named_pk(self):\n+        class Foo(models.Model):\n+            primary_key = models.CompositePrimaryKey(\"foo_id\", \"id\")\n+            foo_id = models.IntegerField()\n+            id = models.IntegerField()\n+\n+        self.assertEqual(\n+            Foo.check(databases=self.databases),\n+            [\n+                checks.Error(\n+                    \"'CompositePrimaryKey' must be named 'pk'.\",\n+                    obj=Foo._meta.get_field(\"primary_key\"),\n+                    id=\"fields.E013\",\n+                ),\n+            ],\n+        )\n+\n+    def test_composite_pk_cannot_include_generated_field(self):\n+        is_oracle = connection.vendor == \"oracle\"\n+\n+        class Foo(models.Model):\n+            pk = models.CompositePrimaryKey(\"id\", \"foo\")\n+            id = models.IntegerField()\n+            foo = models.GeneratedField(\n+                expression=F(\"id\"),\n+                output_field=models.IntegerField(),\n+                db_persist=not is_oracle,\n+            )\n+\n+        self.assertEqual(\n+            Foo.check(databases=self.databases),\n+            [\n+                checks.Error(\n+                    \"'foo' cannot be included in the composite primary key.\",\n+                    hint=\"'foo' field is a generated field.\",\n+                    obj=Foo,\n+                    id=\"models.E042\",\n+                ),\n+            ],\n+        )\ndiff --git a/tests/composite_pk/test_create.py b/tests/composite_pk/test_create.py\nnew file mode 100644\nindex 000000000000..7c9925b94656\n--- /dev/null\n+++ b/tests/composite_pk/test_create.py\n@@ -0,0 +1,138 @@\n+from django.test import TestCase\n+\n+from .models import Tenant, User\n+\n+\n+class CompositePKCreateTests(TestCase):\n+    maxDiff = None\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.tenant = Tenant.objects.create()\n+        cls.user = User.objects.create(\n+            tenant=cls.tenant,\n+            id=1,\n+            email=\"user0001@example.com\",\n+        )\n+\n+    def test_create_user(self):\n+        test_cases = (\n+            {\"tenant\": self.tenant, \"id\": 2412, \"email\": \"user2412@example.com\"},\n+            {\"tenant_id\": self.tenant.id, \"id\": 5316, \"email\": \"user5316@example.com\"},\n+            {\"pk\": (self.tenant.id, 7424), \"email\": \"user7424@example.com\"},\n+        )\n+\n+        for fields in test_cases:\n+            with self.subTest(fields=fields):\n+                count = User.objects.count()\n+                user = User(**fields)\n+                obj = User.objects.create(**fields)\n+                self.assertEqual(obj.tenant_id, self.tenant.id)\n+                self.assertEqual(obj.id, user.id)\n+                self.assertEqual(obj.pk, (self.tenant.id, user.id))\n+                self.assertEqual(obj.email, user.email)\n+                self.assertEqual(count + 1, User.objects.count())\n+\n+    def test_save_user(self):\n+        test_cases = (\n+            {\"tenant\": self.tenant, \"id\": 9241, \"email\": \"user9241@example.com\"},\n+            {\"tenant_id\": self.tenant.id, \"id\": 5132, \"email\": \"user5132@example.com\"},\n+            {\"pk\": (self.tenant.id, 3014), \"email\": \"user3014@example.com\"},\n+        )\n+\n+        for fields in test_cases:\n+            with self.subTest(fields=fields):\n+                count = User.objects.count()\n+                user = User(**fields)\n+                self.assertIsNotNone(user.id)\n+                self.assertIsNotNone(user.email)\n+                user.save()\n+                self.assertEqual(user.tenant_id, self.tenant.id)\n+                self.assertEqual(user.tenant, self.tenant)\n+                self.assertIsNotNone(user.id)\n+                self.assertEqual(user.pk, (self.tenant.id, user.id))\n+                self.assertEqual(user.email, fields[\"email\"])\n+                self.assertEqual(user.email, f\"user{user.id}@example.com\")\n+                self.assertEqual(count + 1, User.objects.count())\n+\n+    def test_bulk_create_users(self):\n+        objs = [\n+            User(tenant=self.tenant, id=8291, email=\"user8291@example.com\"),\n+            User(tenant_id=self.tenant.id, id=4021, email=\"user4021@example.com\"),\n+            User(pk=(self.tenant.id, 8214), email=\"user8214@example.com\"),\n+        ]\n+\n+        obj_1, obj_2, obj_3 = User.objects.bulk_create(objs)\n+\n+        self.assertEqual(obj_1.tenant_id, self.tenant.id)\n+        self.assertEqual(obj_1.id, 8291)\n+        self.assertEqual(obj_1.pk, (obj_1.tenant_id, obj_1.id))\n+        self.assertEqual(obj_1.email, \"user8291@example.com\")\n+        self.assertEqual(obj_2.tenant_id, self.tenant.id)\n+        self.assertEqual(obj_2.id, 4021)\n+        self.assertEqual(obj_2.pk, (obj_2.tenant_id, obj_2.id))\n+        self.assertEqual(obj_2.email, \"user4021@example.com\")\n+        self.assertEqual(obj_3.tenant_id, self.tenant.id)\n+        self.assertEqual(obj_3.id, 8214)\n+        self.assertEqual(obj_3.pk, (obj_3.tenant_id, obj_3.id))\n+        self.assertEqual(obj_3.email, \"user8214@example.com\")\n+\n+    def test_get_or_create_user(self):\n+        test_cases = (\n+            {\n+                \"pk\": (self.tenant.id, 8314),\n+                \"defaults\": {\"email\": \"user8314@example.com\"},\n+            },\n+            {\n+                \"tenant\": self.tenant,\n+                \"id\": 3142,\n+                \"defaults\": {\"email\": \"user3142@example.com\"},\n+            },\n+            {\n+                \"tenant_id\": self.tenant.id,\n+                \"id\": 4218,\n+                \"defaults\": {\"email\": \"user4218@example.com\"},\n+            },\n+        )\n+\n+        for fields in test_cases:\n+            with self.subTest(fields=fields):\n+                count = User.objects.count()\n+                user, created = User.objects.get_or_create(**fields)\n+                self.assertIs(created, True)\n+                self.assertIsNotNone(user.id)\n+                self.assertEqual(user.pk, (self.tenant.id, user.id))\n+                self.assertEqual(user.tenant_id, self.tenant.id)\n+                self.assertEqual(user.email, fields[\"defaults\"][\"email\"])\n+                self.assertEqual(user.email, f\"user{user.id}@example.com\")\n+                self.assertEqual(count + 1, User.objects.count())\n+\n+    def test_update_or_create_user(self):\n+        test_cases = (\n+            {\n+                \"pk\": (self.tenant.id, 2931),\n+                \"defaults\": {\"email\": \"user2931@example.com\"},\n+            },\n+            {\n+                \"tenant\": self.tenant,\n+                \"id\": 6428,\n+                \"defaults\": {\"email\": \"user6428@example.com\"},\n+            },\n+            {\n+                \"tenant_id\": self.tenant.id,\n+                \"id\": 5278,\n+                \"defaults\": {\"email\": \"user5278@example.com\"},\n+            },\n+        )\n+\n+        for fields in test_cases:\n+            with self.subTest(fields=fields):\n+                count = User.objects.count()\n+                user, created = User.objects.update_or_create(**fields)\n+                self.assertIs(created, True)\n+                self.assertIsNotNone(user.id)\n+                self.assertEqual(user.pk, (self.tenant.id, user.id))\n+                self.assertEqual(user.tenant_id, self.tenant.id)\n+                self.assertEqual(user.email, fields[\"defaults\"][\"email\"])\n+                self.assertEqual(user.email, f\"user{user.id}@example.com\")\n+                self.assertEqual(count + 1, User.objects.count())\ndiff --git a/tests/composite_pk/test_delete.py b/tests/composite_pk/test_delete.py\nnew file mode 100644\nindex 000000000000..9a14deb81334\n--- /dev/null\n+++ b/tests/composite_pk/test_delete.py\n@@ -0,0 +1,83 @@\n+from django.test import TestCase\n+\n+from .models import Comment, Tenant, User\n+\n+\n+class CompositePKDeleteTests(TestCase):\n+    maxDiff = None\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.tenant_1 = Tenant.objects.create()\n+        cls.tenant_2 = Tenant.objects.create()\n+        cls.user_1 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=1,\n+            email=\"user0001@example.com\",\n+        )\n+        cls.user_2 = User.objects.create(\n+            tenant=cls.tenant_2,\n+            id=2,\n+            email=\"user0002@example.com\",\n+        )\n+        cls.comment_1 = Comment.objects.create(id=1, user=cls.user_1)\n+        cls.comment_2 = Comment.objects.create(id=2, user=cls.user_2)\n+        cls.comment_3 = Comment.objects.create(id=3, user=cls.user_2)\n+\n+    def test_delete_tenant_by_pk(self):\n+        result = Tenant.objects.filter(pk=self.tenant_1.pk).delete()\n+\n+        self.assertEqual(\n+            result,\n+            (\n+                3,\n+                {\n+                    \"composite_pk.Comment\": 1,\n+                    \"composite_pk.User\": 1,\n+                    \"composite_pk.Tenant\": 1,\n+                },\n+            ),\n+        )\n+\n+        self.assertIs(Tenant.objects.filter(pk=self.tenant_1.pk).exists(), False)\n+        self.assertIs(Tenant.objects.filter(pk=self.tenant_2.pk).exists(), True)\n+        self.assertIs(User.objects.filter(pk=self.user_1.pk).exists(), False)\n+        self.assertIs(User.objects.filter(pk=self.user_2.pk).exists(), True)\n+        self.assertIs(Comment.objects.filter(pk=self.comment_1.pk).exists(), False)\n+        self.assertIs(Comment.objects.filter(pk=self.comment_2.pk).exists(), True)\n+        self.assertIs(Comment.objects.filter(pk=self.comment_3.pk).exists(), True)\n+\n+    def test_delete_user_by_pk(self):\n+        result = User.objects.filter(pk=self.user_1.pk).delete()\n+\n+        self.assertEqual(\n+            result, (2, {\"composite_pk.User\": 1, \"composite_pk.Comment\": 1})\n+        )\n+\n+        self.assertIs(User.objects.filter(pk=self.user_1.pk).exists(), False)\n+        self.assertIs(User.objects.filter(pk=self.user_2.pk).exists(), True)\n+        self.assertIs(Comment.objects.filter(pk=self.comment_1.pk).exists(), False)\n+        self.assertIs(Comment.objects.filter(pk=self.comment_2.pk).exists(), True)\n+        self.assertIs(Comment.objects.filter(pk=self.comment_3.pk).exists(), True)\n+\n+    def test_delete_comments_by_user(self):\n+        result = Comment.objects.filter(user=self.user_2).delete()\n+\n+        self.assertEqual(result, (2, {\"composite_pk.Comment\": 2}))\n+\n+        self.assertIs(Comment.objects.filter(pk=self.comment_1.pk).exists(), True)\n+        self.assertIs(Comment.objects.filter(pk=self.comment_2.pk).exists(), False)\n+        self.assertIs(Comment.objects.filter(pk=self.comment_3.pk).exists(), False)\n+\n+    def test_delete_without_pk(self):\n+        msg = (\n+            \"Comment object can't be deleted because its pk attribute is set \"\n+            \"to None.\"\n+        )\n+\n+        with self.assertRaisesMessage(ValueError, msg):\n+            Comment().delete()\n+        with self.assertRaisesMessage(ValueError, msg):\n+            Comment(tenant_id=1).delete()\n+        with self.assertRaisesMessage(ValueError, msg):\n+            Comment(id=1).delete()\ndiff --git a/tests/composite_pk/test_filter.py b/tests/composite_pk/test_filter.py\nnew file mode 100644\nindex 000000000000..7e361c5925b2\n--- /dev/null\n+++ b/tests/composite_pk/test_filter.py\n@@ -0,0 +1,412 @@\n+from django.test import TestCase\n+\n+from .models import Comment, Tenant, User\n+\n+\n+class CompositePKFilterTests(TestCase):\n+    maxDiff = None\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.tenant_1 = Tenant.objects.create()\n+        cls.tenant_2 = Tenant.objects.create()\n+        cls.tenant_3 = Tenant.objects.create()\n+        cls.user_1 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=1,\n+            email=\"user0001@example.com\",\n+        )\n+        cls.user_2 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=2,\n+            email=\"user0002@example.com\",\n+        )\n+        cls.user_3 = User.objects.create(\n+            tenant=cls.tenant_2,\n+            id=3,\n+            email=\"user0003@example.com\",\n+        )\n+        cls.user_4 = User.objects.create(\n+            tenant=cls.tenant_3,\n+            id=4,\n+            email=\"user0004@example.com\",\n+        )\n+        cls.comment_1 = Comment.objects.create(id=1, user=cls.user_1)\n+        cls.comment_2 = Comment.objects.create(id=2, user=cls.user_1)\n+        cls.comment_3 = Comment.objects.create(id=3, user=cls.user_2)\n+        cls.comment_4 = Comment.objects.create(id=4, user=cls.user_3)\n+        cls.comment_5 = Comment.objects.create(id=5, user=cls.user_1)\n+\n+    def test_filter_and_count_user_by_pk(self):\n+        test_cases = (\n+            ({\"pk\": self.user_1.pk}, 1),\n+            ({\"pk\": self.user_2.pk}, 1),\n+            ({\"pk\": self.user_3.pk}, 1),\n+            ({\"pk\": (self.tenant_1.id, self.user_1.id)}, 1),\n+            ({\"pk\": (self.tenant_1.id, self.user_2.id)}, 1),\n+            ({\"pk\": (self.tenant_2.id, self.user_3.id)}, 1),\n+            ({\"pk\": (self.tenant_1.id, self.user_3.id)}, 0),\n+            ({\"pk\": (self.tenant_2.id, self.user_1.id)}, 0),\n+            ({\"pk\": (self.tenant_2.id, self.user_2.id)}, 0),\n+        )\n+\n+        for lookup, count in test_cases:\n+            with self.subTest(lookup=lookup, count=count):\n+                self.assertEqual(User.objects.filter(**lookup).count(), count)\n+\n+    def test_order_comments_by_pk_asc(self):\n+        self.assertSequenceEqual(\n+            Comment.objects.order_by(\"pk\"),\n+            (\n+                self.comment_1,  # (1, 1)\n+                self.comment_2,  # (1, 2)\n+                self.comment_3,  # (1, 3)\n+                self.comment_5,  # (1, 5)\n+                self.comment_4,  # (2, 4)\n+            ),\n+        )\n+\n+    def test_order_comments_by_pk_desc(self):\n+        self.assertSequenceEqual(\n+            Comment.objects.order_by(\"-pk\"),\n+            (\n+                self.comment_4,  # (2, 4)\n+                self.comment_5,  # (1, 5)\n+                self.comment_3,  # (1, 3)\n+                self.comment_2,  # (1, 2)\n+                self.comment_1,  # (1, 1)\n+            ),\n+        )\n+\n+    def test_filter_comments_by_pk_gt(self):\n+        c11, c12, c13, c24, c15 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+        test_cases = (\n+            (c11, (c12, c13, c15, c24)),\n+            (c12, (c13, c15, c24)),\n+            (c13, (c15, c24)),\n+            (c15, (c24,)),\n+            (c24, ()),\n+        )\n+\n+        for obj, objs in test_cases:\n+            with self.subTest(obj=obj, objs=objs):\n+                self.assertSequenceEqual(\n+                    Comment.objects.filter(pk__gt=obj.pk).order_by(\"pk\"), objs\n+                )\n+\n+    def test_filter_comments_by_pk_gte(self):\n+        c11, c12, c13, c24, c15 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+        test_cases = (\n+            (c11, (c11, c12, c13, c15, c24)),\n+            (c12, (c12, c13, c15, c24)),\n+            (c13, (c13, c15, c24)),\n+            (c15, (c15, c24)),\n+            (c24, (c24,)),\n+        )\n+\n+        for obj, objs in test_cases:\n+            with self.subTest(obj=obj, objs=objs):\n+                self.assertSequenceEqual(\n+                    Comment.objects.filter(pk__gte=obj.pk).order_by(\"pk\"), objs\n+                )\n+\n+    def test_filter_comments_by_pk_lt(self):\n+        c11, c12, c13, c24, c15 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+        test_cases = (\n+            (c24, (c11, c12, c13, c15)),\n+            (c15, (c11, c12, c13)),\n+            (c13, (c11, c12)),\n+            (c12, (c11,)),\n+            (c11, ()),\n+        )\n+\n+        for obj, objs in test_cases:\n+            with self.subTest(obj=obj, objs=objs):\n+                self.assertSequenceEqual(\n+                    Comment.objects.filter(pk__lt=obj.pk).order_by(\"pk\"), objs\n+                )\n+\n+    def test_filter_comments_by_pk_lte(self):\n+        c11, c12, c13, c24, c15 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+        test_cases = (\n+            (c24, (c11, c12, c13, c15, c24)),\n+            (c15, (c11, c12, c13, c15)),\n+            (c13, (c11, c12, c13)),\n+            (c12, (c11, c12)),\n+            (c11, (c11,)),\n+        )\n+\n+        for obj, objs in test_cases:\n+            with self.subTest(obj=obj, objs=objs):\n+                self.assertSequenceEqual(\n+                    Comment.objects.filter(pk__lte=obj.pk).order_by(\"pk\"), objs\n+                )\n+\n+    def test_filter_comments_by_pk_in(self):\n+        test_cases = (\n+            (),\n+            (self.comment_1,),\n+            (self.comment_1, self.comment_4),\n+        )\n+\n+        for objs in test_cases:\n+            with self.subTest(objs=objs):\n+                pks = [obj.pk for obj in objs]\n+                self.assertSequenceEqual(\n+                    Comment.objects.filter(pk__in=pks).order_by(\"pk\"), objs\n+                )\n+\n+    def test_filter_comments_by_user_and_order_by_pk_asc(self):\n+        self.assertSequenceEqual(\n+            Comment.objects.filter(user=self.user_1).order_by(\"pk\"),\n+            (self.comment_1, self.comment_2, self.comment_5),\n+        )\n+\n+    def test_filter_comments_by_user_and_order_by_pk_desc(self):\n+        self.assertSequenceEqual(\n+            Comment.objects.filter(user=self.user_1).order_by(\"-pk\"),\n+            (self.comment_5, self.comment_2, self.comment_1),\n+        )\n+\n+    def test_filter_comments_by_user_and_exclude_by_pk(self):\n+        self.assertSequenceEqual(\n+            Comment.objects.filter(user=self.user_1)\n+            .exclude(pk=self.comment_1.pk)\n+            .order_by(\"pk\"),\n+            (self.comment_2, self.comment_5),\n+        )\n+\n+    def test_filter_comments_by_user_and_contains(self):\n+        self.assertIs(\n+            Comment.objects.filter(user=self.user_1).contains(self.comment_1), True\n+        )\n+\n+    def test_filter_users_by_comments_in(self):\n+        c1, c2, c3, c4, c5 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+        u1, u2, u3 = (\n+            self.user_1,\n+            self.user_2,\n+            self.user_3,\n+        )\n+        test_cases = (\n+            ((), ()),\n+            ((c1,), (u1,)),\n+            ((c1, c2), (u1, u1)),\n+            ((c1, c2, c3), (u1, u1, u2)),\n+            ((c1, c2, c3, c4), (u1, u1, u2, u3)),\n+            ((c1, c2, c3, c4, c5), (u1, u1, u1, u2, u3)),\n+        )\n+\n+        for comments, users in test_cases:\n+            with self.subTest(comments=comments, users=users):\n+                self.assertSequenceEqual(\n+                    User.objects.filter(comments__in=comments).order_by(\"pk\"), users\n+                )\n+\n+    def test_filter_users_by_comments_lt(self):\n+        c11, c12, c13, c24, c15 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+        u1, u2 = (\n+            self.user_1,\n+            self.user_2,\n+        )\n+        test_cases = (\n+            (c11, ()),\n+            (c12, (u1,)),\n+            (c13, (u1, u1)),\n+            (c15, (u1, u1, u2)),\n+            (c24, (u1, u1, u1, u2)),\n+        )\n+\n+        for comment, users in test_cases:\n+            with self.subTest(comment=comment, users=users):\n+                self.assertSequenceEqual(\n+                    User.objects.filter(comments__lt=comment).order_by(\"pk\"), users\n+                )\n+\n+    def test_filter_users_by_comments_lte(self):\n+        c11, c12, c13, c24, c15 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+        u1, u2, u3 = (\n+            self.user_1,\n+            self.user_2,\n+            self.user_3,\n+        )\n+        test_cases = (\n+            (c11, (u1,)),\n+            (c12, (u1, u1)),\n+            (c13, (u1, u1, u2)),\n+            (c15, (u1, u1, u1, u2)),\n+            (c24, (u1, u1, u1, u2, u3)),\n+        )\n+\n+        for comment, users in test_cases:\n+            with self.subTest(comment=comment, users=users):\n+                self.assertSequenceEqual(\n+                    User.objects.filter(comments__lte=comment).order_by(\"pk\"), users\n+                )\n+\n+    def test_filter_users_by_comments_gt(self):\n+        c11, c12, c13, c24, c15 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+        u1, u2, u3 = (\n+            self.user_1,\n+            self.user_2,\n+            self.user_3,\n+        )\n+        test_cases = (\n+            (c11, (u1, u1, u2, u3)),\n+            (c12, (u1, u2, u3)),\n+            (c13, (u1, u3)),\n+            (c15, (u3,)),\n+            (c24, ()),\n+        )\n+\n+        for comment, users in test_cases:\n+            with self.subTest(comment=comment, users=users):\n+                self.assertSequenceEqual(\n+                    User.objects.filter(comments__gt=comment).order_by(\"pk\"), users\n+                )\n+\n+    def test_filter_users_by_comments_gte(self):\n+        c11, c12, c13, c24, c15 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+        u1, u2, u3 = (\n+            self.user_1,\n+            self.user_2,\n+            self.user_3,\n+        )\n+        test_cases = (\n+            (c11, (u1, u1, u1, u2, u3)),\n+            (c12, (u1, u1, u2, u3)),\n+            (c13, (u1, u2, u3)),\n+            (c15, (u1, u3)),\n+            (c24, (u3,)),\n+        )\n+\n+        for comment, users in test_cases:\n+            with self.subTest(comment=comment, users=users):\n+                self.assertSequenceEqual(\n+                    User.objects.filter(comments__gte=comment).order_by(\"pk\"), users\n+                )\n+\n+    def test_filter_users_by_comments_exact(self):\n+        c11, c12, c13, c24, c15 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+        u1, u2, u3 = (\n+            self.user_1,\n+            self.user_2,\n+            self.user_3,\n+        )\n+        test_cases = (\n+            (c11, (u1,)),\n+            (c12, (u1,)),\n+            (c13, (u2,)),\n+            (c15, (u1,)),\n+            (c24, (u3,)),\n+        )\n+\n+        for comment, users in test_cases:\n+            with self.subTest(comment=comment, users=users):\n+                self.assertSequenceEqual(\n+                    User.objects.filter(comments=comment).order_by(\"pk\"), users\n+                )\n+\n+    def test_filter_users_by_comments_isnull(self):\n+        u1, u2, u3, u4 = (\n+            self.user_1,\n+            self.user_2,\n+            self.user_3,\n+            self.user_4,\n+        )\n+\n+        with self.subTest(\"comments__isnull=True\"):\n+            self.assertSequenceEqual(\n+                User.objects.filter(comments__isnull=True).order_by(\"pk\"),\n+                (u4,),\n+            )\n+        with self.subTest(\"comments__isnull=False\"):\n+            self.assertSequenceEqual(\n+                User.objects.filter(comments__isnull=False).order_by(\"pk\"),\n+                (u1, u1, u1, u2, u3),\n+            )\n+\n+    def test_filter_comments_by_pk_isnull(self):\n+        c11, c12, c13, c24, c15 = (\n+            self.comment_1,\n+            self.comment_2,\n+            self.comment_3,\n+            self.comment_4,\n+            self.comment_5,\n+        )\n+\n+        with self.subTest(\"pk__isnull=True\"):\n+            self.assertSequenceEqual(\n+                Comment.objects.filter(pk__isnull=True).order_by(\"pk\"),\n+                (),\n+            )\n+        with self.subTest(\"pk__isnull=False\"):\n+            self.assertSequenceEqual(\n+                Comment.objects.filter(pk__isnull=False).order_by(\"pk\"),\n+                (c11, c12, c13, c15, c24),\n+            )\n+\n+    def test_filter_users_by_comments_subquery(self):\n+        subquery = Comment.objects.filter(id=3).only(\"pk\")\n+        queryset = User.objects.filter(comments__in=subquery)\n+        self.assertSequenceEqual(queryset, (self.user_2,))\ndiff --git a/tests/composite_pk/test_get.py b/tests/composite_pk/test_get.py\nnew file mode 100644\nindex 000000000000..c896ec26ed49\n--- /dev/null\n+++ b/tests/composite_pk/test_get.py\n@@ -0,0 +1,126 @@\n+from django.test import TestCase\n+\n+from .models import Comment, Tenant, User\n+\n+\n+class CompositePKGetTests(TestCase):\n+    maxDiff = None\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.tenant_1 = Tenant.objects.create()\n+        cls.tenant_2 = Tenant.objects.create()\n+        cls.user_1 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=1,\n+            email=\"user0001@example.com\",\n+        )\n+        cls.user_2 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=2,\n+            email=\"user0002@example.com\",\n+        )\n+        cls.user_3 = User.objects.create(\n+            tenant=cls.tenant_2,\n+            id=3,\n+            email=\"user0003@example.com\",\n+        )\n+        cls.comment_1 = Comment.objects.create(id=1, user=cls.user_1)\n+\n+    def test_get_user(self):\n+        test_cases = (\n+            {\"pk\": self.user_1.pk},\n+            {\"pk\": (self.tenant_1.id, self.user_1.id)},\n+            {\"id\": self.user_1.id},\n+        )\n+\n+        for lookup in test_cases:\n+            with self.subTest(lookup=lookup):\n+                self.assertEqual(User.objects.get(**lookup), self.user_1)\n+\n+    def test_get_comment(self):\n+        test_cases = (\n+            {\"pk\": self.comment_1.pk},\n+            {\"pk\": (self.tenant_1.id, self.comment_1.id)},\n+            {\"id\": self.comment_1.id},\n+            {\"user\": self.user_1},\n+            {\"user_id\": self.user_1.id},\n+            {\"user__id\": self.user_1.id},\n+            {\"user__pk\": self.user_1.pk},\n+            {\"tenant\": self.tenant_1},\n+            {\"tenant_id\": self.tenant_1.id},\n+            {\"tenant__id\": self.tenant_1.id},\n+            {\"tenant__pk\": self.tenant_1.pk},\n+        )\n+\n+        for lookup in test_cases:\n+            with self.subTest(lookup=lookup):\n+                self.assertEqual(Comment.objects.get(**lookup), self.comment_1)\n+\n+    def test_get_or_create_user(self):\n+        test_cases = (\n+            {\n+                \"pk\": self.user_1.pk,\n+                \"defaults\": {\"email\": \"user9201@example.com\"},\n+            },\n+            {\n+                \"pk\": (self.tenant_1.id, self.user_1.id),\n+                \"defaults\": {\"email\": \"user9201@example.com\"},\n+            },\n+            {\n+                \"tenant\": self.tenant_1,\n+                \"id\": self.user_1.id,\n+                \"defaults\": {\"email\": \"user3512@example.com\"},\n+            },\n+            {\n+                \"tenant_id\": self.tenant_1.id,\n+                \"id\": self.user_1.id,\n+                \"defaults\": {\"email\": \"user8239@example.com\"},\n+            },\n+        )\n+\n+        for fields in test_cases:\n+            with self.subTest(fields=fields):\n+                count = User.objects.count()\n+                user, created = User.objects.get_or_create(**fields)\n+                self.assertIs(created, False)\n+                self.assertEqual(user.id, self.user_1.id)\n+                self.assertEqual(user.pk, (self.tenant_1.id, self.user_1.id))\n+                self.assertEqual(user.tenant_id, self.tenant_1.id)\n+                self.assertEqual(user.email, self.user_1.email)\n+                self.assertEqual(count, User.objects.count())\n+\n+    def test_lookup_errors(self):\n+        m_tuple = \"'%s' lookup of 'pk' must be a tuple or a list\"\n+        m_2_elements = \"'%s' lookup of 'pk' must have 2 elements\"\n+        m_tuple_collection = (\n+            \"'in' lookup of 'pk' must be a collection of tuples or lists\"\n+        )\n+        m_2_elements_each = \"'in' lookup of 'pk' must have 2 elements each\"\n+        test_cases = (\n+            ({\"pk\": 1}, m_tuple % \"exact\"),\n+            ({\"pk\": (1, 2, 3)}, m_2_elements % \"exact\"),\n+            ({\"pk__exact\": 1}, m_tuple % \"exact\"),\n+            ({\"pk__exact\": (1, 2, 3)}, m_2_elements % \"exact\"),\n+            ({\"pk__in\": 1}, m_tuple % \"in\"),\n+            ({\"pk__in\": (1, 2, 3)}, m_tuple_collection),\n+            ({\"pk__in\": ((1, 2, 3),)}, m_2_elements_each),\n+            ({\"pk__gt\": 1}, m_tuple % \"gt\"),\n+            ({\"pk__gt\": (1, 2, 3)}, m_2_elements % \"gt\"),\n+            ({\"pk__gte\": 1}, m_tuple % \"gte\"),\n+            ({\"pk__gte\": (1, 2, 3)}, m_2_elements % \"gte\"),\n+            ({\"pk__lt\": 1}, m_tuple % \"lt\"),\n+            ({\"pk__lt\": (1, 2, 3)}, m_2_elements % \"lt\"),\n+            ({\"pk__lte\": 1}, m_tuple % \"lte\"),\n+            ({\"pk__lte\": (1, 2, 3)}, m_2_elements % \"lte\"),\n+        )\n+\n+        for kwargs, message in test_cases:\n+            with (\n+                self.subTest(kwargs=kwargs),\n+                self.assertRaisesMessage(ValueError, message),\n+            ):\n+                Comment.objects.get(**kwargs)\n+\n+    def test_get_user_by_comments(self):\n+        self.assertEqual(User.objects.get(comments=self.comment_1), self.user_1)\ndiff --git a/tests/composite_pk/test_models.py b/tests/composite_pk/test_models.py\nnew file mode 100644\nindex 000000000000..ca6ad8b5dc3a\n--- /dev/null\n+++ b/tests/composite_pk/test_models.py\n@@ -0,0 +1,153 @@\n+from django.contrib.contenttypes.models import ContentType\n+from django.core.exceptions import ValidationError\n+from django.test import TestCase\n+\n+from .models import Comment, Tenant, Token, User\n+\n+\n+class CompositePKModelsTests(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.tenant_1 = Tenant.objects.create()\n+        cls.tenant_2 = Tenant.objects.create()\n+        cls.user_1 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=1,\n+            email=\"user0001@example.com\",\n+        )\n+        cls.user_2 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=2,\n+            email=\"user0002@example.com\",\n+        )\n+        cls.user_3 = User.objects.create(\n+            tenant=cls.tenant_2,\n+            id=3,\n+            email=\"user0003@example.com\",\n+        )\n+        cls.comment_1 = Comment.objects.create(id=1, user=cls.user_1)\n+        cls.comment_2 = Comment.objects.create(id=2, user=cls.user_1)\n+        cls.comment_3 = Comment.objects.create(id=3, user=cls.user_2)\n+        cls.comment_4 = Comment.objects.create(id=4, user=cls.user_3)\n+\n+    def test_fields(self):\n+        # tenant_1\n+        self.assertSequenceEqual(\n+            self.tenant_1.user_set.order_by(\"pk\"),\n+            [self.user_1, self.user_2],\n+        )\n+        self.assertSequenceEqual(\n+            self.tenant_1.comments.order_by(\"pk\"),\n+            [self.comment_1, self.comment_2, self.comment_3],\n+        )\n+\n+        # tenant_2\n+        self.assertSequenceEqual(self.tenant_2.user_set.order_by(\"pk\"), [self.user_3])\n+        self.assertSequenceEqual(\n+            self.tenant_2.comments.order_by(\"pk\"), [self.comment_4]\n+        )\n+\n+        # user_1\n+        self.assertEqual(self.user_1.id, 1)\n+        self.assertEqual(self.user_1.tenant_id, self.tenant_1.id)\n+        self.assertEqual(self.user_1.tenant, self.tenant_1)\n+        self.assertEqual(self.user_1.pk, (self.tenant_1.id, self.user_1.id))\n+        self.assertSequenceEqual(\n+            self.user_1.comments.order_by(\"pk\"), [self.comment_1, self.comment_2]\n+        )\n+\n+        # user_2\n+        self.assertEqual(self.user_2.id, 2)\n+        self.assertEqual(self.user_2.tenant_id, self.tenant_1.id)\n+        self.assertEqual(self.user_2.tenant, self.tenant_1)\n+        self.assertEqual(self.user_2.pk, (self.tenant_1.id, self.user_2.id))\n+        self.assertSequenceEqual(self.user_2.comments.order_by(\"pk\"), [self.comment_3])\n+\n+        # comment_1\n+        self.assertEqual(self.comment_1.id, 1)\n+        self.assertEqual(self.comment_1.user_id, self.user_1.id)\n+        self.assertEqual(self.comment_1.user, self.user_1)\n+        self.assertEqual(self.comment_1.tenant_id, self.tenant_1.id)\n+        self.assertEqual(self.comment_1.tenant, self.tenant_1)\n+        self.assertEqual(self.comment_1.pk, (self.tenant_1.id, self.user_1.id))\n+\n+    def test_full_clean_success(self):\n+        test_cases = (\n+            # 1, 1234, {}\n+            ({\"tenant\": self.tenant_1, \"id\": 1234}, {}),\n+            ({\"tenant_id\": self.tenant_1.id, \"id\": 1234}, {}),\n+            ({\"pk\": (self.tenant_1.id, 1234)}, {}),\n+            # 1, 1, {\"id\"}\n+            ({\"tenant\": self.tenant_1, \"id\": 1}, {\"id\"}),\n+            ({\"tenant_id\": self.tenant_1.id, \"id\": 1}, {\"id\"}),\n+            ({\"pk\": (self.tenant_1.id, 1)}, {\"id\"}),\n+            # 1, 1, {\"tenant\", \"id\"}\n+            ({\"tenant\": self.tenant_1, \"id\": 1}, {\"tenant\", \"id\"}),\n+            ({\"tenant_id\": self.tenant_1.id, \"id\": 1}, {\"tenant\", \"id\"}),\n+            ({\"pk\": (self.tenant_1.id, 1)}, {\"tenant\", \"id\"}),\n+        )\n+\n+        for kwargs, exclude in test_cases:\n+            with self.subTest(kwargs):\n+                kwargs[\"email\"] = \"user0004@example.com\"\n+                User(**kwargs).full_clean(exclude=exclude)\n+\n+    def test_full_clean_failure(self):\n+        e_tenant_and_id = \"User with this Tenant and Id already exists.\"\n+        e_id = \"User with this Id already exists.\"\n+        test_cases = (\n+            # 1, 1, {}\n+            ({\"tenant\": self.tenant_1, \"id\": 1}, {}, (e_tenant_and_id, e_id)),\n+            ({\"tenant_id\": self.tenant_1.id, \"id\": 1}, {}, (e_tenant_and_id, e_id)),\n+            ({\"pk\": (self.tenant_1.id, 1)}, {}, (e_tenant_and_id, e_id)),\n+            # 2, 1, {}\n+            ({\"tenant\": self.tenant_2, \"id\": 1}, {}, (e_id,)),\n+            ({\"tenant_id\": self.tenant_2.id, \"id\": 1}, {}, (e_id,)),\n+            ({\"pk\": (self.tenant_2.id, 1)}, {}, (e_id,)),\n+            # 1, 1, {\"tenant\"}\n+            ({\"tenant\": self.tenant_1, \"id\": 1}, {\"tenant\"}, (e_id,)),\n+            ({\"tenant_id\": self.tenant_1.id, \"id\": 1}, {\"tenant\"}, (e_id,)),\n+            ({\"pk\": (self.tenant_1.id, 1)}, {\"tenant\"}, (e_id,)),\n+        )\n+\n+        for kwargs, exclude, messages in test_cases:\n+            with self.subTest(kwargs):\n+                with self.assertRaises(ValidationError) as ctx:\n+                    kwargs[\"email\"] = \"user0004@example.com\"\n+                    User(**kwargs).full_clean(exclude=exclude)\n+\n+                self.assertSequenceEqual(ctx.exception.messages, messages)\n+\n+    def test_field_conflicts(self):\n+        test_cases = (\n+            ({\"pk\": (1, 1), \"id\": 2}, (1, 1)),\n+            ({\"id\": 2, \"pk\": (1, 1)}, (1, 1)),\n+            ({\"pk\": (1, 1), \"tenant_id\": 2}, (1, 1)),\n+            ({\"tenant_id\": 2, \"pk\": (1, 1)}, (1, 1)),\n+            ({\"pk\": (2, 2), \"tenant_id\": 3, \"id\": 4}, (2, 2)),\n+            ({\"tenant_id\": 3, \"id\": 4, \"pk\": (2, 2)}, (2, 2)),\n+        )\n+\n+        for kwargs, pk in test_cases:\n+            with self.subTest(kwargs=kwargs):\n+                user = User(**kwargs)\n+                self.assertEqual(user.pk, pk)\n+\n+    def test_validate_unique(self):\n+        user = User.objects.get(pk=self.user_1.pk)\n+        user.id = None\n+\n+        with self.assertRaises(ValidationError) as ctx:\n+            user.validate_unique()\n+\n+        self.assertSequenceEqual(\n+            ctx.exception.messages, (\"User with this Email already exists.\",)\n+        )\n+\n+    def test_permissions(self):\n+        token = ContentType.objects.get_for_model(Token)\n+        user = ContentType.objects.get_for_model(User)\n+        comment = ContentType.objects.get_for_model(Comment)\n+        self.assertEqual(4, token.permission_set.count())\n+        self.assertEqual(4, user.permission_set.count())\n+        self.assertEqual(4, comment.permission_set.count())\ndiff --git a/tests/composite_pk/test_names_to_path.py b/tests/composite_pk/test_names_to_path.py\nnew file mode 100644\nindex 000000000000..de4a04f4cba7\n--- /dev/null\n+++ b/tests/composite_pk/test_names_to_path.py\n@@ -0,0 +1,134 @@\n+from django.db.models.query_utils import PathInfo\n+from django.db.models.sql import Query\n+from django.test import TestCase\n+\n+from .models import Comment, Tenant, User\n+\n+\n+class NamesToPathTests(TestCase):\n+    def test_id(self):\n+        query = Query(User)\n+        path, final_field, targets, rest = query.names_to_path([\"id\"], User._meta)\n+\n+        self.assertEqual(path, [])\n+        self.assertEqual(final_field, User._meta.get_field(\"id\"))\n+        self.assertEqual(targets, (User._meta.get_field(\"id\"),))\n+        self.assertEqual(rest, [])\n+\n+    def test_pk(self):\n+        query = Query(User)\n+        path, final_field, targets, rest = query.names_to_path([\"pk\"], User._meta)\n+\n+        self.assertEqual(path, [])\n+        self.assertEqual(final_field, User._meta.get_field(\"pk\"))\n+        self.assertEqual(targets, (User._meta.get_field(\"pk\"),))\n+        self.assertEqual(rest, [])\n+\n+    def test_tenant_id(self):\n+        query = Query(User)\n+        path, final_field, targets, rest = query.names_to_path(\n+            [\"tenant\", \"id\"], User._meta\n+        )\n+\n+        self.assertEqual(\n+            path,\n+            [\n+                PathInfo(\n+                    from_opts=User._meta,\n+                    to_opts=Tenant._meta,\n+                    target_fields=(Tenant._meta.get_field(\"id\"),),\n+                    join_field=User._meta.get_field(\"tenant\"),\n+                    m2m=False,\n+                    direct=True,\n+                    filtered_relation=None,\n+                ),\n+            ],\n+        )\n+        self.assertEqual(final_field, Tenant._meta.get_field(\"id\"))\n+        self.assertEqual(targets, (Tenant._meta.get_field(\"id\"),))\n+        self.assertEqual(rest, [])\n+\n+    def test_user_id(self):\n+        query = Query(Comment)\n+        path, final_field, targets, rest = query.names_to_path(\n+            [\"user\", \"id\"], Comment._meta\n+        )\n+\n+        self.assertEqual(\n+            path,\n+            [\n+                PathInfo(\n+                    from_opts=Comment._meta,\n+                    to_opts=User._meta,\n+                    target_fields=(\n+                        User._meta.get_field(\"tenant\"),\n+                        User._meta.get_field(\"id\"),\n+                    ),\n+                    join_field=Comment._meta.get_field(\"user\"),\n+                    m2m=False,\n+                    direct=True,\n+                    filtered_relation=None,\n+                ),\n+            ],\n+        )\n+        self.assertEqual(final_field, User._meta.get_field(\"id\"))\n+        self.assertEqual(targets, (User._meta.get_field(\"id\"),))\n+        self.assertEqual(rest, [])\n+\n+    def test_user_tenant_id(self):\n+        query = Query(Comment)\n+        path, final_field, targets, rest = query.names_to_path(\n+            [\"user\", \"tenant\", \"id\"], Comment._meta\n+        )\n+\n+        self.assertEqual(\n+            path,\n+            [\n+                PathInfo(\n+                    from_opts=Comment._meta,\n+                    to_opts=User._meta,\n+                    target_fields=(\n+                        User._meta.get_field(\"tenant\"),\n+                        User._meta.get_field(\"id\"),\n+                    ),\n+                    join_field=Comment._meta.get_field(\"user\"),\n+                    m2m=False,\n+                    direct=True,\n+                    filtered_relation=None,\n+                ),\n+                PathInfo(\n+                    from_opts=User._meta,\n+                    to_opts=Tenant._meta,\n+                    target_fields=(Tenant._meta.get_field(\"id\"),),\n+                    join_field=User._meta.get_field(\"tenant\"),\n+                    m2m=False,\n+                    direct=True,\n+                    filtered_relation=None,\n+                ),\n+            ],\n+        )\n+        self.assertEqual(final_field, Tenant._meta.get_field(\"id\"))\n+        self.assertEqual(targets, (Tenant._meta.get_field(\"id\"),))\n+        self.assertEqual(rest, [])\n+\n+    def test_comments(self):\n+        query = Query(User)\n+        path, final_field, targets, rest = query.names_to_path([\"comments\"], User._meta)\n+\n+        self.assertEqual(\n+            path,\n+            [\n+                PathInfo(\n+                    from_opts=User._meta,\n+                    to_opts=Comment._meta,\n+                    target_fields=(Comment._meta.get_field(\"pk\"),),\n+                    join_field=User._meta.get_field(\"comments\"),\n+                    m2m=True,\n+                    direct=False,\n+                    filtered_relation=None,\n+                ),\n+            ],\n+        )\n+        self.assertEqual(final_field, User._meta.get_field(\"comments\"))\n+        self.assertEqual(targets, (Comment._meta.get_field(\"pk\"),))\n+        self.assertEqual(rest, [])\ndiff --git a/tests/composite_pk/test_update.py b/tests/composite_pk/test_update.py\nnew file mode 100644\nindex 000000000000..e7117454477c\n--- /dev/null\n+++ b/tests/composite_pk/test_update.py\n@@ -0,0 +1,135 @@\n+from django.test import TestCase\n+\n+from .models import Comment, Tenant, Token, User\n+\n+\n+class CompositePKUpdateTests(TestCase):\n+    maxDiff = None\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.tenant_1 = Tenant.objects.create(name=\"A\")\n+        cls.tenant_2 = Tenant.objects.create(name=\"B\")\n+        cls.user_1 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=1,\n+            email=\"user0001@example.com\",\n+        )\n+        cls.user_2 = User.objects.create(\n+            tenant=cls.tenant_1,\n+            id=2,\n+            email=\"user0002@example.com\",\n+        )\n+        cls.user_3 = User.objects.create(\n+            tenant=cls.tenant_2,\n+            id=3,\n+            email=\"user0003@example.com\",\n+        )\n+        cls.comment_1 = Comment.objects.create(id=1, user=cls.user_1)\n+        cls.comment_2 = Comment.objects.create(id=2, user=cls.user_1)\n+        cls.comment_3 = Comment.objects.create(id=3, user=cls.user_2)\n+        cls.token_1 = Token.objects.create(id=1, tenant=cls.tenant_1)\n+        cls.token_2 = Token.objects.create(id=2, tenant=cls.tenant_2)\n+        cls.token_3 = Token.objects.create(id=3, tenant=cls.tenant_1)\n+        cls.token_4 = Token.objects.create(id=4, tenant=cls.tenant_2)\n+\n+    def test_update_user(self):\n+        email = \"user9315@example.com\"\n+        result = User.objects.filter(pk=self.user_1.pk).update(email=email)\n+        self.assertEqual(result, 1)\n+        user = User.objects.get(pk=self.user_1.pk)\n+        self.assertEqual(user.email, email)\n+\n+    def test_save_user(self):\n+        count = User.objects.count()\n+        email = \"user9314@example.com\"\n+        user = User.objects.get(pk=self.user_1.pk)\n+        user.email = email\n+        user.save()\n+        user.refresh_from_db()\n+        self.assertEqual(user.email, email)\n+        user = User.objects.get(pk=self.user_1.pk)\n+        self.assertEqual(user.email, email)\n+        self.assertEqual(count, User.objects.count())\n+\n+    def test_bulk_update_comments(self):\n+        comment_1 = Comment.objects.get(pk=self.comment_1.pk)\n+        comment_2 = Comment.objects.get(pk=self.comment_2.pk)\n+        comment_3 = Comment.objects.get(pk=self.comment_3.pk)\n+        comment_1.text = \"foo\"\n+        comment_2.text = \"bar\"\n+        comment_3.text = \"baz\"\n+\n+        result = Comment.objects.bulk_update(\n+            [comment_1, comment_2, comment_3], [\"text\"]\n+        )\n+\n+        self.assertEqual(result, 3)\n+        comment_1 = Comment.objects.get(pk=self.comment_1.pk)\n+        comment_2 = Comment.objects.get(pk=self.comment_2.pk)\n+        comment_3 = Comment.objects.get(pk=self.comment_3.pk)\n+        self.assertEqual(comment_1.text, \"foo\")\n+        self.assertEqual(comment_2.text, \"bar\")\n+        self.assertEqual(comment_3.text, \"baz\")\n+\n+    def test_update_or_create_user(self):\n+        test_cases = (\n+            {\n+                \"pk\": self.user_1.pk,\n+                \"defaults\": {\"email\": \"user3914@example.com\"},\n+            },\n+            {\n+                \"pk\": (self.tenant_1.id, self.user_1.id),\n+                \"defaults\": {\"email\": \"user9375@example.com\"},\n+            },\n+            {\n+                \"tenant\": self.tenant_1,\n+                \"id\": self.user_1.id,\n+                \"defaults\": {\"email\": \"user3517@example.com\"},\n+            },\n+            {\n+                \"tenant_id\": self.tenant_1.id,\n+                \"id\": self.user_1.id,\n+                \"defaults\": {\"email\": \"user8391@example.com\"},\n+            },\n+        )\n+\n+        for fields in test_cases:\n+            with self.subTest(fields=fields):\n+                count = User.objects.count()\n+                user, created = User.objects.update_or_create(**fields)\n+                self.assertIs(created, False)\n+                self.assertEqual(user.id, self.user_1.id)\n+                self.assertEqual(user.pk, (self.tenant_1.id, self.user_1.id))\n+                self.assertEqual(user.tenant_id, self.tenant_1.id)\n+                self.assertEqual(user.email, fields[\"defaults\"][\"email\"])\n+                self.assertEqual(count, User.objects.count())\n+\n+    def test_update_comment_by_user_email(self):\n+        result = Comment.objects.filter(user__email=self.user_1.email).update(\n+            text=\"foo\"\n+        )\n+\n+        self.assertEqual(result, 2)\n+        comment_1 = Comment.objects.get(pk=self.comment_1.pk)\n+        comment_2 = Comment.objects.get(pk=self.comment_2.pk)\n+        self.assertEqual(comment_1.text, \"foo\")\n+        self.assertEqual(comment_2.text, \"foo\")\n+\n+    def test_update_token_by_tenant_name(self):\n+        result = Token.objects.filter(tenant__name=\"A\").update(secret=\"bar\")\n+\n+        self.assertEqual(result, 2)\n+        token_1 = Token.objects.get(pk=self.token_1.pk)\n+        self.assertEqual(token_1.secret, \"bar\")\n+        token_3 = Token.objects.get(pk=self.token_3.pk)\n+        self.assertEqual(token_3.secret, \"bar\")\n+\n+    def test_cant_update_to_unsaved_object(self):\n+        msg = (\n+            \"Unsaved model instance <User: User object ((None, None))> cannot be used \"\n+            \"in an ORM query.\"\n+        )\n+\n+        with self.assertRaisesMessage(ValueError, msg):\n+            Comment.objects.update(user=User())\ndiff --git a/tests/composite_pk/test_values.py b/tests/composite_pk/test_values.py\nnew file mode 100644\nindex 000000000000..a3c7a589ccbc\n--- /dev/null\n+++ b/tests/composite_pk/test_values.py\n@@ -0,0 +1,212 @@\n+from collections import namedtuple\n+from uuid import UUID\n+\n+from django.test import TestCase\n+\n+from .models import Post, Tenant, User\n+\n+\n+class CompositePKValuesTests(TestCase):\n+    USER_1_EMAIL = \"user0001@example.com\"\n+    USER_2_EMAIL = \"user0002@example.com\"\n+    USER_3_EMAIL = \"user0003@example.com\"\n+    POST_1_ID = \"77777777-7777-7777-7777-777777777777\"\n+    POST_2_ID = \"bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb\"\n+    POST_3_ID = \"aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa\"\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        super().setUpTestData()\n+        cls.tenant_1 = Tenant.objects.create()\n+        cls.tenant_2 = Tenant.objects.create()\n+        cls.user_1 = User.objects.create(\n+            tenant=cls.tenant_1, id=1, email=cls.USER_1_EMAIL\n+        )\n+        cls.user_2 = User.objects.create(\n+            tenant=cls.tenant_1, id=2, email=cls.USER_2_EMAIL\n+        )\n+        cls.user_3 = User.objects.create(\n+            tenant=cls.tenant_2, id=3, email=cls.USER_3_EMAIL\n+        )\n+        cls.post_1 = Post.objects.create(tenant=cls.tenant_1, id=cls.POST_1_ID)\n+        cls.post_2 = Post.objects.create(tenant=cls.tenant_1, id=cls.POST_2_ID)\n+        cls.post_3 = Post.objects.create(tenant=cls.tenant_2, id=cls.POST_3_ID)\n+\n+    def test_values_list(self):\n+        with self.subTest('User.objects.values_list(\"pk\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values_list(\"pk\").order_by(\"pk\"),\n+                (\n+                    (self.user_1.pk,),\n+                    (self.user_2.pk,),\n+                    (self.user_3.pk,),\n+                ),\n+            )\n+        with self.subTest('User.objects.values_list(\"pk\", \"email\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values_list(\"pk\", \"email\").order_by(\"pk\"),\n+                (\n+                    (self.user_1.pk, self.USER_1_EMAIL),\n+                    (self.user_2.pk, self.USER_2_EMAIL),\n+                    (self.user_3.pk, self.USER_3_EMAIL),\n+                ),\n+            )\n+        with self.subTest('User.objects.values_list(\"pk\", \"id\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values_list(\"pk\", \"id\").order_by(\"pk\"),\n+                (\n+                    (self.user_1.pk, self.user_1.id),\n+                    (self.user_2.pk, self.user_2.id),\n+                    (self.user_3.pk, self.user_3.id),\n+                ),\n+            )\n+        with self.subTest('User.objects.values_list(\"pk\", \"tenant_id\", \"id\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values_list(\"pk\", \"tenant_id\", \"id\").order_by(\"pk\"),\n+                (\n+                    (self.user_1.pk, self.user_1.tenant_id, self.user_1.id),\n+                    (self.user_2.pk, self.user_2.tenant_id, self.user_2.id),\n+                    (self.user_3.pk, self.user_3.tenant_id, self.user_3.id),\n+                ),\n+            )\n+        with self.subTest('User.objects.values_list(\"pk\", flat=True)'):\n+            self.assertSequenceEqual(\n+                User.objects.values_list(\"pk\", flat=True).order_by(\"pk\"),\n+                (\n+                    self.user_1.pk,\n+                    self.user_2.pk,\n+                    self.user_3.pk,\n+                ),\n+            )\n+        with self.subTest('Post.objects.values_list(\"pk\", flat=True)'):\n+            self.assertSequenceEqual(\n+                Post.objects.values_list(\"pk\", flat=True).order_by(\"pk\"),\n+                (\n+                    (self.tenant_1.id, UUID(self.POST_1_ID)),\n+                    (self.tenant_1.id, UUID(self.POST_2_ID)),\n+                    (self.tenant_2.id, UUID(self.POST_3_ID)),\n+                ),\n+            )\n+        with self.subTest('Post.objects.values_list(\"pk\")'):\n+            self.assertSequenceEqual(\n+                Post.objects.values_list(\"pk\").order_by(\"pk\"),\n+                (\n+                    ((self.tenant_1.id, UUID(self.POST_1_ID)),),\n+                    ((self.tenant_1.id, UUID(self.POST_2_ID)),),\n+                    ((self.tenant_2.id, UUID(self.POST_3_ID)),),\n+                ),\n+            )\n+        with self.subTest('Post.objects.values_list(\"pk\", \"id\")'):\n+            self.assertSequenceEqual(\n+                Post.objects.values_list(\"pk\", \"id\").order_by(\"pk\"),\n+                (\n+                    ((self.tenant_1.id, UUID(self.POST_1_ID)), UUID(self.POST_1_ID)),\n+                    ((self.tenant_1.id, UUID(self.POST_2_ID)), UUID(self.POST_2_ID)),\n+                    ((self.tenant_2.id, UUID(self.POST_3_ID)), UUID(self.POST_3_ID)),\n+                ),\n+            )\n+        with self.subTest('Post.objects.values_list(\"id\", \"pk\")'):\n+            self.assertSequenceEqual(\n+                Post.objects.values_list(\"id\", \"pk\").order_by(\"pk\"),\n+                (\n+                    (UUID(self.POST_1_ID), (self.tenant_1.id, UUID(self.POST_1_ID))),\n+                    (UUID(self.POST_2_ID), (self.tenant_1.id, UUID(self.POST_2_ID))),\n+                    (UUID(self.POST_3_ID), (self.tenant_2.id, UUID(self.POST_3_ID))),\n+                ),\n+            )\n+        with self.subTest('User.objects.values_list(\"pk\", named=True)'):\n+            Row = namedtuple(\"Row\", [\"pk\"])\n+            self.assertSequenceEqual(\n+                User.objects.values_list(\"pk\", named=True).order_by(\"pk\"),\n+                (\n+                    Row(pk=self.user_1.pk),\n+                    Row(pk=self.user_2.pk),\n+                    Row(pk=self.user_3.pk),\n+                ),\n+            )\n+        with self.subTest('User.objects.values_list(\"pk\", \"pk\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values_list(\"pk\", \"pk\").order_by(\"pk\"),\n+                (\n+                    (self.user_1.pk,),\n+                    (self.user_2.pk,),\n+                    (self.user_3.pk,),\n+                ),\n+            )\n+        with self.subTest('User.objects.values_list(\"pk\", \"id\", \"pk\", \"id\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values_list(\"pk\", \"id\", \"pk\", \"id\").order_by(\"pk\"),\n+                (\n+                    (self.user_1.pk, self.user_1.id),\n+                    (self.user_2.pk, self.user_2.id),\n+                    (self.user_3.pk, self.user_3.id),\n+                ),\n+            )\n+\n+    def test_values(self):\n+        with self.subTest('User.objects.values(\"pk\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values(\"pk\").order_by(\"pk\"),\n+                (\n+                    {\"pk\": self.user_1.pk},\n+                    {\"pk\": self.user_2.pk},\n+                    {\"pk\": self.user_3.pk},\n+                ),\n+            )\n+        with self.subTest('User.objects.values(\"pk\", \"email\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values(\"pk\", \"email\").order_by(\"pk\"),\n+                (\n+                    {\"pk\": self.user_1.pk, \"email\": self.USER_1_EMAIL},\n+                    {\"pk\": self.user_2.pk, \"email\": self.USER_2_EMAIL},\n+                    {\"pk\": self.user_3.pk, \"email\": self.USER_3_EMAIL},\n+                ),\n+            )\n+        with self.subTest('User.objects.values(\"pk\", \"id\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values(\"pk\", \"id\").order_by(\"pk\"),\n+                (\n+                    {\"pk\": self.user_1.pk, \"id\": self.user_1.id},\n+                    {\"pk\": self.user_2.pk, \"id\": self.user_2.id},\n+                    {\"pk\": self.user_3.pk, \"id\": self.user_3.id},\n+                ),\n+            )\n+        with self.subTest('User.objects.values(\"pk\", \"tenant_id\", \"id\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values(\"pk\", \"tenant_id\", \"id\").order_by(\"pk\"),\n+                (\n+                    {\n+                        \"pk\": self.user_1.pk,\n+                        \"tenant_id\": self.user_1.tenant_id,\n+                        \"id\": self.user_1.id,\n+                    },\n+                    {\n+                        \"pk\": self.user_2.pk,\n+                        \"tenant_id\": self.user_2.tenant_id,\n+                        \"id\": self.user_2.id,\n+                    },\n+                    {\n+                        \"pk\": self.user_3.pk,\n+                        \"tenant_id\": self.user_3.tenant_id,\n+                        \"id\": self.user_3.id,\n+                    },\n+                ),\n+            )\n+        with self.subTest('User.objects.values(\"pk\", \"pk\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values(\"pk\", \"pk\").order_by(\"pk\"),\n+                (\n+                    {\"pk\": self.user_1.pk},\n+                    {\"pk\": self.user_2.pk},\n+                    {\"pk\": self.user_3.pk},\n+                ),\n+            )\n+        with self.subTest('User.objects.values(\"pk\", \"id\", \"pk\", \"id\")'):\n+            self.assertSequenceEqual(\n+                User.objects.values(\"pk\", \"id\", \"pk\", \"id\").order_by(\"pk\"),\n+                (\n+                    {\"pk\": self.user_1.pk, \"id\": self.user_1.id},\n+                    {\"pk\": self.user_2.pk, \"id\": self.user_2.id},\n+                    {\"pk\": self.user_3.pk, \"id\": self.user_3.id},\n+                ),\n+            )\ndiff --git a/tests/composite_pk/tests.py b/tests/composite_pk/tests.py\nnew file mode 100644\nindex 000000000000..71522cb836fe\n--- /dev/null\n+++ b/tests/composite_pk/tests.py\n@@ -0,0 +1,345 @@\n+import json\n+import unittest\n+from uuid import UUID\n+\n+import yaml\n+\n+from django import forms\n+from django.core import serializers\n+from django.core.exceptions import FieldError\n+from django.db import IntegrityError, connection\n+from django.db.models import CompositePrimaryKey\n+from django.forms import modelform_factory\n+from django.test import TestCase\n+\n+from .models import Comment, Post, Tenant, User\n+\n+\n+class CommentForm(forms.ModelForm):\n+    class Meta:\n+        model = Comment\n+        fields = \"__all__\"\n+\n+\n+class CompositePKTests(TestCase):\n+    maxDiff = None\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.tenant = Tenant.objects.create()\n+        cls.user = User.objects.create(\n+            tenant=cls.tenant,\n+            id=1,\n+            email=\"user0001@example.com\",\n+        )\n+        cls.comment = Comment.objects.create(tenant=cls.tenant, id=1, user=cls.user)\n+\n+    @staticmethod\n+    def get_constraints(table):\n+        with connection.cursor() as cursor:\n+            return connection.introspection.get_constraints(cursor, table)\n+\n+    def test_pk_updated_if_field_updated(self):\n+        user = User.objects.get(pk=self.user.pk)\n+        self.assertEqual(user.pk, (self.tenant.id, self.user.id))\n+        self.assertIs(user._is_pk_set(), True)\n+        user.tenant_id = 9831\n+        self.assertEqual(user.pk, (9831, self.user.id))\n+        self.assertIs(user._is_pk_set(), True)\n+        user.id = 4321\n+        self.assertEqual(user.pk, (9831, 4321))\n+        self.assertIs(user._is_pk_set(), True)\n+        user.pk = (9132, 3521)\n+        self.assertEqual(user.tenant_id, 9132)\n+        self.assertEqual(user.id, 3521)\n+        self.assertIs(user._is_pk_set(), True)\n+        user.id = None\n+        self.assertEqual(user.pk, (9132, None))\n+        self.assertEqual(user.tenant_id, 9132)\n+        self.assertIsNone(user.id)\n+        self.assertIs(user._is_pk_set(), False)\n+\n+    def test_hash(self):\n+        self.assertEqual(hash(User(pk=(1, 2))), hash((1, 2)))\n+        self.assertEqual(hash(User(tenant_id=2, id=3)), hash((2, 3)))\n+        msg = \"Model instances without primary key value are unhashable\"\n+\n+        with self.assertRaisesMessage(TypeError, msg):\n+            hash(User())\n+        with self.assertRaisesMessage(TypeError, msg):\n+            hash(User(tenant_id=1))\n+        with self.assertRaisesMessage(TypeError, msg):\n+            hash(User(id=1))\n+\n+    def test_pk_must_be_list_or_tuple(self):\n+        user = User.objects.get(pk=self.user.pk)\n+        test_cases = [\n+            \"foo\",\n+            1000,\n+            3.14,\n+            True,\n+            False,\n+        ]\n+\n+        for pk in test_cases:\n+            with self.assertRaisesMessage(\n+                ValueError, \"'pk' must be a list or a tuple.\"\n+            ):\n+                user.pk = pk\n+\n+    def test_pk_must_have_2_elements(self):\n+        user = User.objects.get(pk=self.user.pk)\n+        test_cases = [\n+            (),\n+            [],\n+            (1000,),\n+            [1000],\n+            (1, 2, 3),\n+            [1, 2, 3],\n+        ]\n+\n+        for pk in test_cases:\n+            with self.assertRaisesMessage(ValueError, \"'pk' must have 2 elements.\"):\n+                user.pk = pk\n+\n+    def test_composite_pk_in_fields(self):\n+        user_fields = {f.name for f in User._meta.get_fields()}\n+        self.assertEqual(user_fields, {\"pk\", \"tenant\", \"id\", \"email\", \"comments\"})\n+\n+        comment_fields = {f.name for f in Comment._meta.get_fields()}\n+        self.assertEqual(\n+            comment_fields,\n+            {\"pk\", \"tenant\", \"id\", \"user_id\", \"user\", \"text\"},\n+        )\n+\n+    def test_pk_field(self):\n+        pk = User._meta.get_field(\"pk\")\n+        self.assertIsInstance(pk, CompositePrimaryKey)\n+        self.assertIs(User._meta.pk, pk)\n+\n+    def test_error_on_user_pk_conflict(self):\n+        with self.assertRaises(IntegrityError):\n+            User.objects.create(tenant=self.tenant, id=self.user.id)\n+\n+    def test_error_on_comment_pk_conflict(self):\n+        with self.assertRaises(IntegrityError):\n+            Comment.objects.create(tenant=self.tenant, id=self.comment.id)\n+\n+    @unittest.skipUnless(connection.vendor == \"postgresql\", \"PostgreSQL specific test\")\n+    def test_get_constraints_postgresql(self):\n+        user_constraints = self.get_constraints(User._meta.db_table)\n+        user_pk = user_constraints[\"composite_pk_user_pkey\"]\n+        self.assertEqual(user_pk[\"columns\"], [\"tenant_id\", \"id\"])\n+        self.assertIs(user_pk[\"primary_key\"], True)\n+\n+        comment_constraints = self.get_constraints(Comment._meta.db_table)\n+        comment_pk = comment_constraints[\"composite_pk_comment_pkey\"]\n+        self.assertEqual(comment_pk[\"columns\"], [\"tenant_id\", \"comment_id\"])\n+        self.assertIs(comment_pk[\"primary_key\"], True)\n+\n+    @unittest.skipUnless(connection.vendor == \"sqlite\", \"SQLite specific test\")\n+    def test_get_constraints_sqlite(self):\n+        user_constraints = self.get_constraints(User._meta.db_table)\n+        user_pk = user_constraints[\"__primary__\"]\n+        self.assertEqual(user_pk[\"columns\"], [\"tenant_id\", \"id\"])\n+        self.assertIs(user_pk[\"primary_key\"], True)\n+\n+        comment_constraints = self.get_constraints(Comment._meta.db_table)\n+        comment_pk = comment_constraints[\"__primary__\"]\n+        self.assertEqual(comment_pk[\"columns\"], [\"tenant_id\", \"comment_id\"])\n+        self.assertIs(comment_pk[\"primary_key\"], True)\n+\n+    @unittest.skipUnless(connection.vendor == \"mysql\", \"MySQL specific test\")\n+    def test_get_constraints_mysql(self):\n+        user_constraints = self.get_constraints(User._meta.db_table)\n+        user_pk = user_constraints[\"PRIMARY\"]\n+        self.assertEqual(user_pk[\"columns\"], [\"tenant_id\", \"id\"])\n+        self.assertIs(user_pk[\"primary_key\"], True)\n+\n+        comment_constraints = self.get_constraints(Comment._meta.db_table)\n+        comment_pk = comment_constraints[\"PRIMARY\"]\n+        self.assertEqual(comment_pk[\"columns\"], [\"tenant_id\", \"comment_id\"])\n+        self.assertIs(comment_pk[\"primary_key\"], True)\n+\n+    @unittest.skipUnless(connection.vendor == \"oracle\", \"Oracle specific test\")\n+    def test_get_constraints_oracle(self):\n+        user_constraints = self.get_constraints(User._meta.db_table)\n+        user_pk = next(c for c in user_constraints.values() if c[\"primary_key\"])\n+        self.assertEqual(user_pk[\"columns\"], [\"tenant_id\", \"id\"])\n+        self.assertEqual(user_pk[\"primary_key\"], 1)\n+\n+        comment_constraints = self.get_constraints(Comment._meta.db_table)\n+        comment_pk = next(c for c in comment_constraints.values() if c[\"primary_key\"])\n+        self.assertEqual(comment_pk[\"columns\"], [\"tenant_id\", \"comment_id\"])\n+        self.assertEqual(comment_pk[\"primary_key\"], 1)\n+\n+    def test_in_bulk(self):\n+        \"\"\"\n+        Test the .in_bulk() method of composite_pk models.\n+        \"\"\"\n+        result = Comment.objects.in_bulk()\n+        self.assertEqual(result, {self.comment.pk: self.comment})\n+\n+        result = Comment.objects.in_bulk([self.comment.pk])\n+        self.assertEqual(result, {self.comment.pk: self.comment})\n+\n+    def test_iterator(self):\n+        \"\"\"\n+        Test the .iterator() method of composite_pk models.\n+        \"\"\"\n+        result = list(Comment.objects.iterator())\n+        self.assertEqual(result, [self.comment])\n+\n+    def test_query(self):\n+        users = User.objects.values_list(\"pk\").order_by(\"pk\")\n+        self.assertNotIn('AS \"pk\"', str(users.query))\n+\n+    def test_only(self):\n+        users = User.objects.only(\"pk\")\n+        self.assertSequenceEqual(users, (self.user,))\n+        user = users[0]\n+\n+        with self.assertNumQueries(0):\n+            self.assertEqual(user.pk, (self.user.tenant_id, self.user.id))\n+            self.assertEqual(user.tenant_id, self.user.tenant_id)\n+            self.assertEqual(user.id, self.user.id)\n+        with self.assertNumQueries(1):\n+            self.assertEqual(user.email, self.user.email)\n+\n+    def test_model_forms(self):\n+        fields = [\"tenant\", \"id\", \"user_id\", \"text\"]\n+        self.assertEqual(list(CommentForm.base_fields), fields)\n+\n+        form = modelform_factory(Comment, fields=\"__all__\")\n+        self.assertEqual(list(form().fields), fields)\n+\n+        with self.assertRaisesMessage(\n+            FieldError, \"Unknown field(s) (pk) specified for Comment\"\n+        ):\n+            self.assertIsNone(modelform_factory(Comment, fields=[\"pk\"]))\n+\n+\n+class CompositePKFixturesTests(TestCase):\n+    fixtures = [\"tenant\"]\n+\n+    def test_objects(self):\n+        tenant_1, tenant_2, tenant_3 = Tenant.objects.order_by(\"pk\")\n+        self.assertEqual(tenant_1.id, 1)\n+        self.assertEqual(tenant_1.name, \"Tenant 1\")\n+        self.assertEqual(tenant_2.id, 2)\n+        self.assertEqual(tenant_2.name, \"Tenant 2\")\n+        self.assertEqual(tenant_3.id, 3)\n+        self.assertEqual(tenant_3.name, \"Tenant 3\")\n+\n+        user_1, user_2, user_3, user_4 = User.objects.order_by(\"pk\")\n+        self.assertEqual(user_1.id, 1)\n+        self.assertEqual(user_1.tenant_id, 1)\n+        self.assertEqual(user_1.pk, (user_1.tenant_id, user_1.id))\n+        self.assertEqual(user_1.email, \"user0001@example.com\")\n+        self.assertEqual(user_2.id, 2)\n+        self.assertEqual(user_2.tenant_id, 1)\n+        self.assertEqual(user_2.pk, (user_2.tenant_id, user_2.id))\n+        self.assertEqual(user_2.email, \"user0002@example.com\")\n+        self.assertEqual(user_3.id, 3)\n+        self.assertEqual(user_3.tenant_id, 2)\n+        self.assertEqual(user_3.pk, (user_3.tenant_id, user_3.id))\n+        self.assertEqual(user_3.email, \"user0003@example.com\")\n+        self.assertEqual(user_4.id, 4)\n+        self.assertEqual(user_4.tenant_id, 2)\n+        self.assertEqual(user_4.pk, (user_4.tenant_id, user_4.id))\n+        self.assertEqual(user_4.email, \"user0004@example.com\")\n+\n+        post_1, post_2 = Post.objects.order_by(\"pk\")\n+        self.assertEqual(post_1.id, UUID(\"11111111-1111-1111-1111-111111111111\"))\n+        self.assertEqual(post_1.tenant_id, 2)\n+        self.assertEqual(post_1.pk, (post_1.tenant_id, post_1.id))\n+        self.assertEqual(post_2.id, UUID(\"ffffffff-ffff-ffff-ffff-ffffffffffff\"))\n+        self.assertEqual(post_2.tenant_id, 2)\n+        self.assertEqual(post_2.pk, (post_2.tenant_id, post_2.id))\n+\n+    def test_serialize_user_json(self):\n+        users = User.objects.filter(pk=(1, 1))\n+        result = serializers.serialize(\"json\", users)\n+        self.assertEqual(\n+            json.loads(result),\n+            [\n+                {\n+                    \"model\": \"composite_pk.user\",\n+                    \"pk\": [1, 1],\n+                    \"fields\": {\n+                        \"email\": \"user0001@example.com\",\n+                        \"id\": 1,\n+                        \"tenant\": 1,\n+                    },\n+                }\n+            ],\n+        )\n+\n+    def test_serialize_user_jsonl(self):\n+        users = User.objects.filter(pk=(1, 2))\n+        result = serializers.serialize(\"jsonl\", users)\n+        self.assertEqual(\n+            json.loads(result),\n+            {\n+                \"model\": \"composite_pk.user\",\n+                \"pk\": [1, 2],\n+                \"fields\": {\n+                    \"email\": \"user0002@example.com\",\n+                    \"id\": 2,\n+                    \"tenant\": 1,\n+                },\n+            },\n+        )\n+\n+    def test_serialize_user_yaml(self):\n+        users = User.objects.filter(pk=(2, 3))\n+        result = serializers.serialize(\"yaml\", users)\n+        self.assertEqual(\n+            yaml.safe_load(result),\n+            [\n+                {\n+                    \"model\": \"composite_pk.user\",\n+                    \"pk\": [2, 3],\n+                    \"fields\": {\n+                        \"email\": \"user0003@example.com\",\n+                        \"id\": 3,\n+                        \"tenant\": 2,\n+                    },\n+                },\n+            ],\n+        )\n+\n+    def test_serialize_user_python(self):\n+        users = User.objects.filter(pk=(2, 4))\n+        result = serializers.serialize(\"python\", users)\n+        self.assertEqual(\n+            result,\n+            [\n+                {\n+                    \"model\": \"composite_pk.user\",\n+                    \"pk\": [2, 4],\n+                    \"fields\": {\n+                        \"email\": \"user0004@example.com\",\n+                        \"id\": 4,\n+                        \"tenant\": 2,\n+                    },\n+                },\n+            ],\n+        )\n+\n+    def test_serialize_post_uuid(self):\n+        posts = Post.objects.filter(pk=(2, \"11111111-1111-1111-1111-111111111111\"))\n+        result = serializers.serialize(\"json\", posts)\n+        self.assertEqual(\n+            json.loads(result),\n+            [\n+                {\n+                    \"model\": \"composite_pk.post\",\n+                    \"pk\": [2, \"11111111-1111-1111-1111-111111111111\"],\n+                    \"fields\": {\n+                        \"id\": \"11111111-1111-1111-1111-111111111111\",\n+                        \"tenant\": 2,\n+                    },\n+                },\n+            ],\n+        )\ndiff --git a/tests/migrations/test_autodetector.py b/tests/migrations/test_autodetector.py\nindex d4345208ca43..67d258c7004b 100644\n--- a/tests/migrations/test_autodetector.py\n+++ b/tests/migrations/test_autodetector.py\n@@ -4957,6 +4957,95 @@ def deconstruct(self):\n         self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\"])\n         self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Book\")\n \n+    @mock.patch(\n+        \"django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition\"\n+    )\n+    def test_add_composite_pk(self, mocked_ask_method):\n+        before = [\n+            ModelState(\n+                \"app\",\n+                \"foo\",\n+                [\n+                    (\"id\", models.AutoField(primary_key=True)),\n+                ],\n+            ),\n+        ]\n+        after = [\n+            ModelState(\n+                \"app\",\n+                \"foo\",\n+                [\n+                    (\"pk\", models.CompositePrimaryKey(\"foo_id\", \"bar_id\")),\n+                    (\"id\", models.IntegerField()),\n+                ],\n+            ),\n+        ]\n+\n+        changes = self.get_changes(before, after)\n+        self.assertEqual(mocked_ask_method.call_count, 0)\n+        self.assertNumberMigrations(changes, \"app\", 1)\n+        self.assertOperationTypes(changes, \"app\", 0, [\"AddField\", \"AlterField\"])\n+        self.assertOperationAttributes(\n+            changes,\n+            \"app\",\n+            0,\n+            0,\n+            name=\"pk\",\n+            model_name=\"foo\",\n+            preserve_default=True,\n+        )\n+        self.assertOperationAttributes(\n+            changes,\n+            \"app\",\n+            0,\n+            1,\n+            name=\"id\",\n+            model_name=\"foo\",\n+            preserve_default=True,\n+        )\n+\n+    def test_remove_composite_pk(self):\n+        before = [\n+            ModelState(\n+                \"app\",\n+                \"foo\",\n+                [\n+                    (\"pk\", models.CompositePrimaryKey(\"foo_id\", \"bar_id\")),\n+                    (\"id\", models.IntegerField()),\n+                ],\n+            ),\n+        ]\n+        after = [\n+            ModelState(\n+                \"app\",\n+                \"foo\",\n+                [\n+                    (\"id\", models.AutoField(primary_key=True)),\n+                ],\n+            ),\n+        ]\n+\n+        changes = self.get_changes(before, after)\n+        self.assertNumberMigrations(changes, \"app\", 1)\n+        self.assertOperationTypes(changes, \"app\", 0, [\"RemoveField\", \"AlterField\"])\n+        self.assertOperationAttributes(\n+            changes,\n+            \"app\",\n+            0,\n+            0,\n+            name=\"pk\",\n+            model_name=\"foo\",\n+        )\n+        self.assertOperationAttributes(\n+            changes,\n+            \"app\",\n+            0,\n+            1,\n+            name=\"id\",\n+            model_name=\"foo\",\n+            preserve_default=True,\n+        )\n+\n \n class MigrationSuggestNameTests(SimpleTestCase):\n     def test_no_operations(self):\ndiff --git a/tests/migrations/test_operations.py b/tests/migrations/test_operations.py\nindex 3ac813b899b7..d12533d3ac33 100644\n--- a/tests/migrations/test_operations.py\n+++ b/tests/migrations/test_operations.py\n@@ -6212,6 +6212,61 @@ def test_add_field_after_generated_field(self):\n         self.assertEqual(pony_new.generated, 1)\n         self.assertEqual(pony_new.static, 2)\n \n+    def test_composite_pk_operations(self):\n+        app_label = \"test_d8d90af6\"\n+        project_state = self.set_up_test_model(app_label)\n+        operation_1 = migrations.AddField(\n+            \"Pony\", \"pk\", models.CompositePrimaryKey(\"id\", \"pink\")\n+        )\n+        operation_2 = migrations.AlterField(\"Pony\", \"id\", models.IntegerField())\n+        operation_3 = migrations.RemoveField(\"Pony\", \"pk\")\n+        table_name = f\"{app_label}_pony\"\n+\n+        # 1. Add field (pk).\n+        new_state = project_state.clone()\n+        operation_1.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation_1.database_forwards(app_label, editor, project_state, new_state)\n+        self.assertColumnNotExists(table_name, \"pk\")\n+        Pony = new_state.apps.get_model(app_label, \"pony\")\n+        obj_1 = Pony.objects.create(weight=1)\n+        msg = (\n+            f\"obj_1={obj_1}, \"\n+            f\"obj_1.id={obj_1.id}, \"\n+            f\"obj_1.pink={obj_1.pink}, \"\n+            f\"obj_1.pk={obj_1.pk}, \"\n+            f\"Pony._meta.pk={repr(Pony._meta.pk)}, \"\n+            f\"Pony._meta.get_field('id')={repr(Pony._meta.get_field('id'))}\"\n+        )\n+        self.assertEqual(obj_1.pink, 3, msg)\n+        self.assertEqual(obj_1.pk, (obj_1.id, obj_1.pink), msg)\n+\n+        # 2. Alter field (id -> IntegerField()).\n+        project_state, new_state = new_state, new_state.clone()\n+        operation_2.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation_2.database_forwards(app_label, editor, project_state, new_state)\n+        Pony = new_state.apps.get_model(app_label, \"pony\")\n+        obj_1 = Pony.objects.get(id=obj_1.id)\n+        self.assertEqual(obj_1.pink, 3)\n+        self.assertEqual(obj_1.pk, (obj_1.id, obj_1.pink))\n+        obj_2 = Pony.objects.create(id=2, weight=2)\n+        self.assertEqual(obj_2.id, 2)\n+        self.assertEqual(obj_2.pink, 3)\n+        self.assertEqual(obj_2.pk, (obj_2.id, obj_2.pink))\n+\n+        # 3. Remove field (pk).\n+        project_state, new_state = new_state, new_state.clone()\n+        operation_3.state_forwards(app_label, new_state)\n+        with connection.schema_editor() as editor:\n+            operation_3.database_forwards(app_label, editor, project_state, new_state)\n+        Pony = new_state.apps.get_model(app_label, \"pony\")\n+        obj_1 = Pony.objects.get(id=obj_1.id)\n+        self.assertEqual(obj_1.pk, obj_1.id)\n+        obj_2 = Pony.objects.get(id=obj_2.id)\n+        self.assertEqual(obj_2.id, 2)\n+        self.assertEqual(obj_2.pk, obj_2.id)\n+\n \n class SwappableOperationTests(OperationTestBase):\n     \"\"\"\ndiff --git a/tests/migrations/test_state.py b/tests/migrations/test_state.py\nindex dbbdf777345c..d6ecaa1c5d0a 100644\n--- a/tests/migrations/test_state.py\n+++ b/tests/migrations/test_state.py\n@@ -1206,6 +1206,28 @@ class Meta:\n         choices_field = Author._meta.get_field(\"choice\")\n         self.assertEqual(list(choices_field.choices), choices)\n \n+    def test_composite_pk_state(self):\n+        new_apps = Apps([\"migrations\"])\n+\n+        class Foo(models.Model):\n+            pk = models.CompositePrimaryKey(\"account_id\", \"id\")\n+            account_id = models.SmallIntegerField()\n+            id = models.SmallIntegerField()\n+\n+            class Meta:\n+                app_label = \"migrations\"\n+                apps = new_apps\n+\n+        project_state = ProjectState.from_apps(new_apps)\n+        model_state = project_state.models[\"migrations\", \"foo\"]\n+        self.assertEqual(len(model_state.options), 2)\n+        self.assertEqual(model_state.options[\"constraints\"], [])\n+        self.assertEqual(model_state.options[\"indexes\"], [])\n+        self.assertEqual(len(model_state.fields), 3)\n+        self.assertIn(\"pk\", model_state.fields)\n+        self.assertIn(\"account_id\", model_state.fields)\n+        self.assertIn(\"id\", model_state.fields)\n+\n \n class StateRelationsTests(SimpleTestCase):\n     def get_base_project_state(self):\ndiff --git a/tests/migrations/test_writer.py b/tests/migrations/test_writer.py\nindex 51783b73465a..953a3cdb6cf9 100644\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -1138,3 +1138,22 @@ def test_register_non_serializer(self):\n             ValueError, \"'TestModel1' must inherit from 'BaseSerializer'.\"\n         ):\n             MigrationWriter.register_serializer(complex, TestModel1)\n+\n+    def test_composite_pk_import(self):\n+        migration = type(\n+            \"Migration\",\n+            (migrations.Migration,),\n+            {\n+                \"operations\": [\n+                    migrations.AddField(\n+                        \"foo\",\n+                        \"bar\",\n+                        models.CompositePrimaryKey(\"foo_id\", \"bar_id\"),\n+                    ),\n+                ],\n+            },\n+        )\n+        writer = MigrationWriter(migration)\n+        output = writer.as_string()\n+        self.assertEqual(output.count(\"import\"), 1)\n+        self.assertIn(\"from django.db import migrations, models\", output)\n",
    "diff_length": 140643
  },
  {
    "index": 8,
    "filtered_comments": [
      "I ran into this issue using the code from the tutorial:\n\n```\n$ python manage.py shell\nTraceback (most recent call last):\n  File \"manage.py\", line 10, in <module>\n    execute_from_command_line(sys.argv)\n  File \"/home/tim/code/django/django/core/management/__init__.py\", line 336, in execute_from_command_line\n    utility.execute()\n  File \"/home/tim/code/django/django/core/management/__init__.py\", line 310, in execute\n    django.setup()\n  File \"/home/tim/code/django/django/__init__.py\", line 23, in setup\n    apps.populate(settings.INSTALLED_APPS)\n  File \"/home/tim/code/django/django/apps/registry.py\", line 115, in populate\n    app_config.ready()\n  File \"/home/tim/code/django/django/contrib/admin/apps.py\", line 22, in ready\n    self.module.autodiscover()\n  File \"/home/tim/code/django/django/contrib/admin/__init__.py\", line 24, in autodiscover\n    autodiscover_modules('admin', register_to=site)\n  File \"/home/tim/code/django/django/utils/module_loading.py\", line 73, in autodiscover_modules\n    import_module('%s.%s' % (app_config.name, module_to_search))\n  File \"/usr/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\n  File \"/home/tim/code/django/django/contrib/auth/admin.py\", line 182, in <module>\n    admin.site.register(Group, GroupAdmin)\n  File \"/home/tim/code/django/django/contrib/admin/sites.py\", line 101, in register\n    admin_class.check(model)\n  File \"/home/tim/code/django/django/contrib/admin/options.py\", line 149, in check\n    return cls.checks_class().check(cls, model, **kwargs)\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 492, in check\n    errors = super(ModelAdminChecks, self).check(cls, model=model, **kwargs)\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 32, in check\n    errors.extend(self._check_filter_horizontal(cls, model))\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 245, in _check_filter_horizontal\n    for index, field_name in enumerate(cls.filter_horizontal)\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 253, in _check_filter_item\n    field = model._meta.get_field(field_name)\n  File \"/home/tim/code/django/django/db/models/options.py\", line 434, in get_field\n    \"The Apps registry is still not ready, this means get_field() is not able \"\ndjango.core.exceptions.AppRegistryNotReady: The Apps registry is still not ready, this means get_field() is not able to find related objects that point to this model.\n```\n",
      "There is still some usage of `get_field_by_name()` and other deprecated APIs in the tests. Run the tests with `python -Wall runtests.py` and ensure there are no errors.\n\nThere are also a fair number of flake8 errors -- some appear not related to your changes, but rather like you haven't merged in some commits from master. I think you could probably rebase and squash most of the commits now.\n",
      "@timgraham \nRE \"I ran into this issue using the code from the tutorial: ....\"\nTotally right, I added a fix for it, currently running unit tests. It looks like some admin checks are happening prior to the apps registry being ready. This should never happen actually, so I added a fix for it.\nI'll let you know once all tests pass with -Wall\n",
      "There are still many flake8 errors on your branch aren't there? This is what I see:\n\n```\n./django/db/models/manager.py:6:1: F401 'FieldDoesNotExist' imported but unused\n./django/db/models/options.py:13:1: F401 'Field' imported but unused\n./django/db/models/options.py:500:17: E126 continuation line over-indented for hanging indent\n./django/db/models/base.py:1420:9: F401 'FieldDoesNotExist' imported but unused\n./django/db/models/fields/__init__.py:45:1: E302 expected 2 blank lines, found 1\n./django/contrib/contenttypes/fields.py:41:15: W291 trailing whitespace\n./django/contrib/admin/utils.py:462:1: E302 expected 2 blank lines, found 1\n./django/contrib/admin/utils.py:481:1: E302 expected 2 blank lines, found 1\n./tests/prefetch_related/tests.py:723:45: E127 continuation line over-indented for visual indent\n./tests/apps/tests.py:18:1: F401 'AbstractPerson' imported but unused\n./tests/apps/tests.py:18:1: F401 'BasePerson' imported but unused\n./tests/apps/tests.py:18:1: F401 'Relation' imported but unused\n./tests/apps/tests.py:18:1: F401 'new_apps_2' imported but unused\n./tests/test_client_regress/tests.py:997:31: E127 continuation line over-indented for visual indent\n./tests/introspection/tests.py:133:18: E127 continuation line over-indented for visual indent\n```\n",
      "@timgraham To me it looks like the admin checks should be triggered from `AdminAppConfig.ready()`.\n",
      "# Further API change\n\n### Properties changes\n- many_to_many becomes _many_to_many and is only used internally, as there should be no more external distinction between m2m and forward fields\n- fields, concrete_fields, local_concrete_fields become all internal, (with a _ before and not documented) , as there should be no more external distinction between m2m and forward fields\n- related_objects become reverse_fields, in order to keep the same name convention\n- we add another property called \"forward_fields\"\n- make get_fields() internal, but we don't change the endpoint name for legacy reasons (there was already a get_fields())\n\n### Final _meta API\n- field_names => [\"name\", \"surname\", ...]\n- get_field(field_name) => FieldInstance\n- forward_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- reverse_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n\n### Final internal _meta API\n- _fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- _concrete_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- _local_concrete_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- _many_to_many => [FieldInstance, FieldInstance, FieldInstance, .. ]\n",
      "If we make it a public API, I am in favor of moving it to `core.exceptions` (and keeping backwards compatibility where it is now)\n",
      "\"We can move it there and then alias it back on db.models.fields\"\n\nYes, that sounds like the right thing to do.\n\nOptionally we _could_ have the `db.models.fields` version be pushed into the pending deprecation state, but I don't much mind either way on that.\n",
      "A quick question on API correctness:\n`opts.field_names` API can also return more than 1 name for each field, this usually happens with ForeignKeys, where fields can be fetched by property or property_id.\n\nThis is an example where `manager` is a ForeignKey: `{u'id', 'item', 'manager', u'manager_id', 'name'}`\n\nDo you think this is the correct way to go? or shall we exclude duplicates from `field_names`?\n",
      "Gut reaction: I'd certainly expect it to only return the canonical attribute names, and not the `_id` variants.\n\nSo long as the API gives enough information for users to be able to derive the \"_id\" style ones if needed then that would seem sufficient.\n",
      "@tomchristie interestingly Django also uses the *_id stuff internally. I suggest we keep the possibility of Django fetching fields by *_id using get_field(), but we remove duplicates in field_names\n",
      "@PirosB3 What's the hold-up in using `_meta.fields` as the main (and only) entry point? Is that backward compatibility because `fields` doesn't have \"fake\" fields like reverse relations?\n\nIf that's the case I think we have here a unique opportunity to get it right and it's easy enough to provide an upgrade path.\n"
    ],
    "code_diff": "diff --git a/django/apps/registry.py b/django/apps/registry.py\nindex fe53d965de10..68aa411d91f6 100644\n--- a/django/apps/registry.py\n+++ b/django/apps/registry.py\n@@ -337,7 +337,12 @@ def clear_cache(self):\n \n         This is mostly used in tests.\n         \"\"\"\n+        # Call expire cache on each model. This will purge\n+        # the relation tree and the fields cache.\n         self.get_models.cache_clear()\n+        if self.ready:\n+            for model in self.get_models(include_auto_created=True):\n+                model._meta._expire_cache()\n \n     ### DEPRECATED METHODS GO BELOW THIS LINE ###\n \ndiff --git a/django/contrib/admin/checks.py b/django/contrib/admin/checks.py\nindex ee47f911b177..896d59155c3c 100644\n--- a/django/contrib/admin/checks.py\n+++ b/django/contrib/admin/checks.py\n@@ -762,7 +762,7 @@ def _check_list_editable(self, cls, model):\n \n     def _check_list_editable_item(self, cls, model, field_name, label):\n         try:\n-            field = model._meta.get_field_by_name(field_name)[0]\n+            field = model._meta.get_field(field_name)\n         except FieldDoesNotExist:\n             return refer_to_missing_field(field=field_name, option=label,\n                                           model=model, obj=cls, id='admin.E121')\ndiff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 35758cfdaf7b..3e682f9b1021 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -406,7 +406,7 @@ def lookup_allowed(self, lookup, value):\n         rel_name = None\n         for part in parts[:-1]:\n             try:\n-                field, _, _, _ = model._meta.get_field_by_name(part)\n+                field = model._meta.get_field(part)\n             except FieldDoesNotExist:\n                 # Lookups on non-existent fields are ok, since they're ignored\n                 # later.\n@@ -422,7 +422,7 @@ def lookup_allowed(self, lookup, value):\n                 else:\n                     rel_name = None\n             elif isinstance(field, ForeignObjectRel):\n-                model = field.model\n+                model = field.related_model\n                 rel_name = model._meta.pk.name\n             else:\n                 rel_name = None\n@@ -473,9 +473,12 @@ def to_field_allowed(self, request, to_field):\n             for inline in admin.inlines:\n                 registered_models.add(inline.model)\n \n-        for related_object in (opts.get_all_related_objects(include_hidden=True) +\n-                               opts.get_all_related_many_to_many_objects()):\n-            related_model = related_object.model\n+        related_objects = (\n+            f for f in opts.get_fields(include_hidden=True)\n+            if (f.auto_created and not f.concrete)\n+        )\n+        for related_object in related_objects:\n+            related_model = related_object.related_model\n             if (any(issubclass(model, related_model) for model in registered_models) and\n                     related_object.field.rel.get_related_field() == field):\n                 return True\ndiff --git a/django/contrib/admin/templatetags/admin_list.py b/django/contrib/admin/templatetags/admin_list.py\nindex 544c5503ec70..266b880d9947 100644\n--- a/django/contrib/admin/templatetags/admin_list.py\n+++ b/django/contrib/admin/templatetags/admin_list.py\n@@ -326,7 +326,7 @@ def date_hierarchy(cl):\n     \"\"\"\n     if cl.date_hierarchy:\n         field_name = cl.date_hierarchy\n-        field = cl.opts.get_field_by_name(field_name)[0]\n+        field = cl.opts.get_field(field_name)\n         dates_or_datetimes = 'datetimes' if isinstance(field, models.DateTimeField) else 'dates'\n         year_field = '%s__year' % field_name\n         month_field = '%s__month' % field_name\ndiff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex 5da461351a71..0f617b3fb964 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -25,7 +25,7 @@ def lookup_needs_distinct(opts, lookup_path):\n     Returns True if 'distinct()' should be used to query the given lookup path.\n     \"\"\"\n     field_name = lookup_path.split('__', 1)[0]\n-    field = opts.get_field_by_name(field_name)[0]\n+    field = opts.get_field(field_name)\n     if hasattr(field, 'get_path_info') and any(path.m2m for path in field.get_path_info()):\n         return True\n     return False\n@@ -265,7 +265,7 @@ def model_ngettext(obj, n=None):\n def lookup_field(name, obj, model_admin=None):\n     opts = obj._meta\n     try:\n-        f = opts.get_field(name)\n+        f = _get_non_gfk_field(opts, name)\n     except FieldDoesNotExist:\n         # For non-field values, the value is either a method, property or\n         # returned via a callable.\n@@ -291,6 +291,17 @@ def lookup_field(name, obj, model_admin=None):\n     return f, attr, value\n \n \n+def _get_non_gfk_field(opts, name):\n+    \"\"\"\n+    For historical reasons, the admin app relies on GenericForeignKeys as being\n+    \"not found\" by get_field(). This could likely be cleaned up.\n+    \"\"\"\n+    field = opts.get_field(name)\n+    if field.is_relation and field.one_to_many and not field.related_model:\n+        raise FieldDoesNotExist()\n+    return field\n+\n+\n def label_for_field(name, model, model_admin=None, return_attr=False):\n     \"\"\"\n     Returns a sensible label for a field name. The name can be a callable,\n@@ -301,7 +312,7 @@ def label_for_field(name, model, model_admin=None, return_attr=False):\n     \"\"\"\n     attr = None\n     try:\n-        field = model._meta.get_field_by_name(name)[0]\n+        field = _get_non_gfk_field(model._meta, name)\n         try:\n             label = field.verbose_name\n         except AttributeError:\n@@ -349,11 +360,10 @@ def label_for_field(name, model, model_admin=None, return_attr=False):\n def help_text_for_field(name, model):\n     help_text = \"\"\n     try:\n-        field_data = model._meta.get_field_by_name(name)\n+        field = _get_non_gfk_field(model._meta, name)\n     except FieldDoesNotExist:\n         pass\n     else:\n-        field = field_data[0]\n         if hasattr(field, 'help_text'):\n             help_text = field.help_text\n     return smart_text(help_text)\n@@ -425,19 +435,21 @@ def reverse_field_path(model, path):\n     parent = model\n     pieces = path.split(LOOKUP_SEP)\n     for piece in pieces:\n-        field, model, direct, m2m = parent._meta.get_field_by_name(piece)\n+        field = parent._meta.get_field(piece)\n         # skip trailing data field if extant:\n         if len(reversed_path) == len(pieces) - 1:  # final iteration\n             try:\n                 get_model_from_relation(field)\n             except NotRelationField:\n                 break\n-        if direct:\n+\n+        # Field should point to another model\n+        if field.is_relation and not (field.auto_created and not field.concrete):\n             related_name = field.related_query_name()\n             parent = field.rel.to\n         else:\n             related_name = field.field.name\n-            parent = field.model\n+            parent = field.related_model\n         reversed_path.insert(0, related_name)\n     return (parent, LOOKUP_SEP.join(reversed_path))\n \n@@ -458,7 +470,7 @@ def get_fields_from_path(model, path):\n             parent = get_model_from_relation(fields[-1])\n         else:\n             parent = model\n-        fields.append(parent._meta.get_field_by_name(piece)[0])\n+        fields.append(parent._meta.get_field(piece))\n     return fields\n \n \ndiff --git a/django/contrib/admin/validation.py b/django/contrib/admin/validation.py\nindex 92ede613ec72..67b97f776edd 100644\n--- a/django/contrib/admin/validation.py\n+++ b/django/contrib/admin/validation.py\n@@ -346,7 +346,7 @@ def validate_list_editable(self, cls, model):\n             check_isseq(cls, 'list_editable', cls.list_editable)\n             for idx, field_name in enumerate(cls.list_editable):\n                 try:\n-                    field = model._meta.get_field_by_name(field_name)[0]\n+                    field = model._meta.get_field(field_name)\n                 except FieldDoesNotExist:\n                     raise ImproperlyConfigured(\"'%s.list_editable[%d]' refers to a \"\n                         \"field, '%s', not defined on %s.%s.\"\ndiff --git a/django/contrib/admindocs/views.py b/django/contrib/admindocs/views.py\nindex 2b45301f3a41..2ffd402c95d0 100644\n--- a/django/contrib/admindocs/views.py\n+++ b/django/contrib/admindocs/views.py\n@@ -262,7 +262,7 @@ def get_context_data(self, **kwargs):\n                 })\n \n         # Gather related objects\n-        for rel in opts.get_all_related_objects() + opts.get_all_related_many_to_many_objects():\n+        for rel in opts.related_objects:\n             verbose = _(\"related `%(app_label)s.%(object_name)s` objects\") % {\n                 'app_label': rel.opts.app_label,\n                 'object_name': rel.opts.object_name,\ndiff --git a/django/contrib/contenttypes/fields.py b/django/contrib/contenttypes/fields.py\nindex 2297ad63a9b5..07d47becf86e 100644\n--- a/django/contrib/contenttypes/fields.py\n+++ b/django/contrib/contenttypes/fields.py\n@@ -21,6 +21,18 @@ class GenericForeignKey(object):\n     Provides a generic relation to any object through content-type/object-id\n     fields.\n     \"\"\"\n+    # Field flags\n+    auto_created = False\n+    concrete = False\n+    editable = False\n+    hidden = False\n+\n+    is_relation = True\n+    many_to_many = False\n+    many_to_one = False\n+    one_to_many = True\n+    one_to_one = False\n+    related_model = None\n \n     def __init__(self, ct_field=\"content_type\", fk_field=\"object_id\", for_concrete_model=True):\n         self.ct_field = ct_field\n@@ -28,12 +40,13 @@ def __init__(self, ct_field=\"content_type\", fk_field=\"object_id\", for_concrete_m\n         self.for_concrete_model = for_concrete_model\n         self.editable = False\n         self.rel = None\n+        self.column = None\n \n     def contribute_to_class(self, cls, name, **kwargs):\n         self.name = name\n         self.model = cls\n         self.cache_attr = \"_%s_cache\" % name\n-        cls._meta.add_virtual_field(self)\n+        cls._meta.add_field(self, virtual=True)\n \n         # Only run pre-initialization field assignment on non-abstract models\n         if not cls._meta.abstract:\n@@ -243,6 +256,13 @@ def __set__(self, instance, value):\n \n class GenericRelation(ForeignObject):\n     \"\"\"Provides an accessor to generic related objects (e.g. comments)\"\"\"\n+    # Field flags\n+    auto_created = False\n+\n+    many_to_many = False\n+    many_to_one = True\n+    one_to_many = False\n+    one_to_one = False\n \n     def __init__(self, to, **kwargs):\n         kwargs['verbose_name'] = kwargs.get('verbose_name', None)\n@@ -303,8 +323,7 @@ def _check_generic_foreign_key_existence(self):\n \n     def resolve_related_fields(self):\n         self.to_fields = [self.model._meta.pk.name]\n-        return [(self.rel.to._meta.get_field_by_name(self.object_id_field_name)[0],\n-                 self.model._meta.pk)]\n+        return [(self.rel.to._meta.get_field(self.object_id_field_name), self.model._meta.pk)]\n \n     def get_path_info(self):\n         opts = self.rel.to._meta\n@@ -345,7 +364,7 @@ def get_content_type(self):\n                                                  for_concrete_model=self.for_concrete_model)\n \n     def get_extra_restriction(self, where_class, alias, remote_alias):\n-        field = self.rel.to._meta.get_field_by_name(self.content_type_field_name)[0]\n+        field = self.rel.to._meta.get_field(self.content_type_field_name)\n         contenttype_pk = self.get_content_type().pk\n         cond = where_class()\n         lookup = field.get_lookup('exact')(Col(remote_alias, field, field), contenttype_pk)\ndiff --git a/django/contrib/gis/db/models/query.py b/django/contrib/gis/db/models/query.py\nindex f2e76578508b..c05688dec9bc 100644\n--- a/django/contrib/gis/db/models/query.py\n+++ b/django/contrib/gis/db/models/query.py\n@@ -758,7 +758,7 @@ def _geocol_select(self, geo_field, field_name):\n         elif geo_field not in opts.local_fields:\n             # This geographic field is inherited from another model, so we have to\n             # use the db table for the _parent_ model instead.\n-            tmp_fld, parent_model, direct, m2m = opts.get_field_by_name(geo_field.name)\n+            parent_model = geo_field.model._meta.concrete_model\n             return self.query.get_compiler(self.db)._field_column(geo_field, parent_model._meta.db_table)\n         else:\n             return self.query.get_compiler(self.db)._field_column(geo_field)\ndiff --git a/django/contrib/gis/db/models/sql/compiler.py b/django/contrib/gis/db/models/sql/compiler.py\nindex dd156ea4b621..1501c981369c 100644\n--- a/django/contrib/gis/db/models/sql/compiler.py\n+++ b/django/contrib/gis/db/models/sql/compiler.py\n@@ -118,7 +118,10 @@ def get_default_columns(self, with_aliases=False, col_aliases=None,\n         seen = self.query.included_inherited_models.copy()\n         if start_alias:\n             seen[None] = start_alias\n-        for field, model in opts.get_concrete_fields_with_model():\n+        for field in opts.concrete_fields:\n+            model = field.model._meta.concrete_model\n+            if model is opts.model:\n+                model = None\n             if from_parent and model is not None and issubclass(from_parent, model):\n                 # Avoid loading data for already loaded parents.\n                 continue\ndiff --git a/django/contrib/gis/sitemaps/views.py b/django/contrib/gis/sitemaps/views.py\nindex c0c2f835983d..d12ed53298ee 100644\n--- a/django/contrib/gis/sitemaps/views.py\n+++ b/django/contrib/gis/sitemaps/views.py\n@@ -23,7 +23,7 @@ def kml(request, label, model, field_name=None, compress=False, using=DEFAULT_DB\n \n     if field_name:\n         try:\n-            field, _, _, _ = klass._meta.get_field_by_name(field_name)\n+            field = klass._meta.get_field(field_name)\n             if not isinstance(field, GeometryField):\n                 raise FieldDoesNotExist\n         except FieldDoesNotExist:\ndiff --git a/django/contrib/gis/utils/layermapping.py b/django/contrib/gis/utils/layermapping.py\nindex 1c848f105ef6..2ff23fc38be0 100644\n--- a/django/contrib/gis/utils/layermapping.py\n+++ b/django/contrib/gis/utils/layermapping.py\n@@ -457,11 +457,10 @@ def coord_transform(self):\n \n     def geometry_field(self):\n         \"Returns the GeometryField instance associated with the geographic column.\"\n-        # Use the `get_field_by_name` on the model's options so that we\n+        # Use `get_field()` on the model's options so that we\n         # get the correct field instance if there's model inheritance.\n         opts = self.model._meta\n-        fld, model, direct, m2m = opts.get_field_by_name(self.geom_field)\n-        return fld\n+        return opts.get_field(self.geom_field)\n \n     def make_multi(self, geom_type, model_field):\n         \"\"\"\ndiff --git a/django/contrib/gis/utils/srs.py b/django/contrib/gis/utils/srs.py\nindex e5aa5a703956..1460be2de90c 100644\n--- a/django/contrib/gis/utils/srs.py\n+++ b/django/contrib/gis/utils/srs.py\n@@ -61,7 +61,7 @@ def add_srs_entry(srs, auth_name='EPSG', auth_srid=None, ref_sys_name=None,\n               }\n \n     # Backend-specific fields for the SpatialRefSys model.\n-    srs_field_names = SpatialRefSys._meta.get_all_field_names()\n+    srs_field_names = {f.name for f in SpatialRefSys._meta.get_fields()}\n     if 'srtext' in srs_field_names:\n         kwargs['srtext'] = srs.wkt\n     if 'ref_sys_name' in srs_field_names:\ndiff --git a/django/core/serializers/python.py b/django/core/serializers/python.py\nindex b4712c76be52..f8dd7aebac51 100644\n--- a/django/core/serializers/python.py\n+++ b/django/core/serializers/python.py\n@@ -8,7 +8,7 @@\n from django.apps import apps\n from django.conf import settings\n from django.core.serializers import base\n-from django.db import models, DEFAULT_DB_ALIAS\n+from django.db import DEFAULT_DB_ALIAS, models\n from django.utils.encoding import force_text, is_protected_type\n from django.utils import six\n \n@@ -101,12 +101,12 @@ def Deserializer(object_list, **options):\n         if 'pk' in d:\n             data[Model._meta.pk.attname] = Model._meta.pk.to_python(d.get(\"pk\", None))\n         m2m_data = {}\n-        model_fields = Model._meta.get_all_field_names()\n+        field_names = {f.name for f in Model._meta.get_fields()}\n \n         # Handle each field\n         for (field_name, field_value) in six.iteritems(d[\"fields\"]):\n \n-            if ignore and field_name not in model_fields:\n+            if ignore and field_name not in field_names:\n                 # skip fields no longer on model\n                 continue\n \ndiff --git a/django/core/serializers/xml_serializer.py b/django/core/serializers/xml_serializer.py\nindex de82a969c17e..0b759799d2ea 100644\n--- a/django/core/serializers/xml_serializer.py\n+++ b/django/core/serializers/xml_serializer.py\n@@ -186,7 +186,7 @@ def _handle_object(self, node):\n         # {m2m_accessor_attribute : [list_of_related_objects]})\n         m2m_data = {}\n \n-        model_fields = Model._meta.get_all_field_names()\n+        field_names = {f.name for f in Model._meta.get_fields()}\n         # Deserialize each field.\n         for field_node in node.getElementsByTagName(\"field\"):\n             # If the field is missing the name attribute, bail (are you\n@@ -198,7 +198,7 @@ def _handle_object(self, node):\n             # Get the field from the Model. This will raise a\n             # FieldDoesNotExist if, well, the field doesn't exist, which will\n             # be propagated correctly unless ignorenonexistent=True is used.\n-            if self.ignore and field_name not in model_fields:\n+            if self.ignore and field_name not in field_names:\n                 continue\n             field = Model._meta.get_field(field_name)\n \ndiff --git a/django/db/backends/creation.py b/django/db/backends/creation.py\nindex 5e0248d4df27..42a58c03e85c 100644\n--- a/django/db/backends/creation.py\n+++ b/django/db/backends/creation.py\n@@ -199,7 +199,7 @@ def sql_indexes_for_model(self, model, style):\n         for f in model._meta.local_fields:\n             output.extend(self.sql_indexes_for_field(model, f, style))\n         for fs in model._meta.index_together:\n-            fields = [model._meta.get_field_by_name(f)[0] for f in fs]\n+            fields = [model._meta.get_field(f) for f in fs]\n             output.extend(self.sql_indexes_for_fields(model, fields, style))\n         return output\n \n@@ -290,7 +290,7 @@ def sql_destroy_indexes_for_model(self, model, style):\n         for f in model._meta.local_fields:\n             output.extend(self.sql_destroy_indexes_for_field(model, f, style))\n         for fs in model._meta.index_together:\n-            fields = [model._meta.get_field_by_name(f)[0] for f in fs]\n+            fields = [model._meta.get_field(f) for f in fs]\n             output.extend(self.sql_destroy_indexes_for_fields(model, fields, style))\n         return output\n \ndiff --git a/django/db/backends/schema.py b/django/db/backends/schema.py\nindex 40db888e5016..dfda05bc19bb 100644\n--- a/django/db/backends/schema.py\n+++ b/django/db/backends/schema.py\n@@ -10,6 +10,11 @@\n logger = getLogger('django.db.backends.schema')\n \n \n+def _related_non_m2m_objects(opts):\n+    # filters out m2m objects from reverse relations.\n+    return (obj for obj in opts.related_objects if not obj.field.many_to_many)\n+\n+\n class BaseDatabaseSchemaEditor(object):\n     \"\"\"\n     This class (and its subclasses) are responsible for emitting schema-changing\n@@ -261,7 +266,7 @@ def create_model(self, model):\n \n         # Add any unique_togethers\n         for fields in model._meta.unique_together:\n-            columns = [model._meta.get_field_by_name(field)[0].column for field in fields]\n+            columns = [model._meta.get_field(field).column for field in fields]\n             column_sqls.append(self.sql_create_table_unique % {\n                 \"columns\": \", \".join(self.quote_name(column) for column in columns),\n             })\n@@ -309,7 +314,7 @@ def alter_unique_together(self, model, old_unique_together, new_unique_together)\n         news = set(tuple(fields) for fields in new_unique_together)\n         # Deleted uniques\n         for fields in olds.difference(news):\n-            columns = [model._meta.get_field_by_name(field)[0].column for field in fields]\n+            columns = [model._meta.get_field(field).column for field in fields]\n             constraint_names = self._constraint_names(model, columns, unique=True)\n             if len(constraint_names) != 1:\n                 raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n@@ -320,7 +325,7 @@ def alter_unique_together(self, model, old_unique_together, new_unique_together)\n             self.execute(self._delete_constraint_sql(self.sql_delete_unique, model, constraint_names[0]))\n         # Created uniques\n         for fields in news.difference(olds):\n-            columns = [model._meta.get_field_by_name(field)[0].column for field in fields]\n+            columns = [model._meta.get_field(field).column for field in fields]\n             self.execute(self._create_unique_sql(model, columns))\n \n     def alter_index_together(self, model, old_index_together, new_index_together):\n@@ -333,7 +338,7 @@ def alter_index_together(self, model, old_index_together, new_index_together):\n         news = set(tuple(fields) for fields in new_index_together)\n         # Deleted indexes\n         for fields in olds.difference(news):\n-            columns = [model._meta.get_field_by_name(field)[0].column for field in fields]\n+            columns = [model._meta.get_field(field).column for field in fields]\n             constraint_names = self._constraint_names(model, list(columns), index=True)\n             if len(constraint_names) != 1:\n                 raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n@@ -344,7 +349,7 @@ def alter_index_together(self, model, old_index_together, new_index_together):\n             self.execute(self._delete_constraint_sql(self.sql_delete_index, model, constraint_names[0]))\n         # Created indexes\n         for field_names in news.difference(olds):\n-            fields = [model._meta.get_field_by_name(field)[0] for field in field_names]\n+            fields = [model._meta.get_field(field) for field in field_names]\n             self.execute(self._create_index_sql(model, fields, suffix=\"_idx\"))\n \n     def alter_db_table(self, model, old_db_table, new_db_table):\n@@ -511,10 +516,12 @@ def _alter_field(self, model, old_field, new_field, old_type, new_type,\n         # Drop incoming FK constraints if we're a primary key and things are going\n         # to change.\n         if old_field.primary_key and new_field.primary_key and old_type != new_type:\n-            for rel in new_field.model._meta.get_all_related_objects():\n-                rel_fk_names = self._constraint_names(rel.model, [rel.field.column], foreign_key=True)\n+            # '_meta.related_field' also contains M2M reverse fields, these\n+            # will be filtered out\n+            for rel in _related_non_m2m_objects(new_field.model._meta):\n+                rel_fk_names = self._constraint_names(rel.related_model, [rel.field.column], foreign_key=True)\n                 for fk_name in rel_fk_names:\n-                    self.execute(self._delete_constraint_sql(self.sql_delete_fk, rel.model, fk_name))\n+                    self.execute(self._delete_constraint_sql(self.sql_delete_fk, rel.related_model, fk_name))\n         # Removed an index? (no strict check, as multiple indexes are possible)\n         if (old_field.db_index and not new_field.db_index and\n                 not old_field.unique and not\n@@ -661,7 +668,7 @@ def _alter_field(self, model, old_field, new_field, old_type, new_type,\n         # referring to us.\n         rels_to_update = []\n         if old_field.primary_key and new_field.primary_key and old_type != new_type:\n-            rels_to_update.extend(new_field.model._meta.get_all_related_objects())\n+            rels_to_update.extend(_related_non_m2m_objects(new_field.model._meta))\n         # Changed to become primary key?\n         # Note that we don't detect unsetting of a PK, as we assume another field\n         # will always come along and replace it.\n@@ -684,14 +691,14 @@ def _alter_field(self, model, old_field, new_field, old_type, new_type,\n                 }\n             )\n             # Update all referencing columns\n-            rels_to_update.extend(new_field.model._meta.get_all_related_objects())\n+            rels_to_update.extend(_related_non_m2m_objects(new_field.model._meta))\n         # Handle our type alters on the other end of rels from the PK stuff above\n         for rel in rels_to_update:\n             rel_db_params = rel.field.db_parameters(connection=self.connection)\n             rel_type = rel_db_params['type']\n             self.execute(\n                 self.sql_alter_column % {\n-                    \"table\": self.quote_name(rel.model._meta.db_table),\n+                    \"table\": self.quote_name(rel.related_model._meta.db_table),\n                     \"changes\": self.sql_alter_column_type % {\n                         \"column\": self.quote_name(rel.field.column),\n                         \"type\": rel_type,\n@@ -705,8 +712,9 @@ def _alter_field(self, model, old_field, new_field, old_type, new_type,\n             self.execute(self._create_fk_sql(model, new_field, \"_fk_%(to_table)s_%(to_column)s\"))\n         # Rebuild FKs that pointed to us if we previously had to drop them\n         if old_field.primary_key and new_field.primary_key and old_type != new_type:\n-            for rel in new_field.model._meta.get_all_related_objects():\n-                self.execute(self._create_fk_sql(rel.model, rel.field, \"_fk\"))\n+            for rel in new_field.model._meta.related_objects:\n+                if not rel.many_to_many:\n+                    self.execute(self._create_fk_sql(rel.related_model, rel.field, \"_fk\"))\n         # Does it have check constraints we need to add?\n         if old_db_params['check'] != new_db_params['check'] and new_db_params['check']:\n             self.execute(\n@@ -765,14 +773,14 @@ def _alter_many_to_many(self, model, old_field, new_field, strict):\n             new_field.rel.through,\n             # We need the field that points to the target model, so we can tell alter_field to change it -\n             # this is m2m_reverse_field_name() (as opposed to m2m_field_name, which points to our model)\n-            old_field.rel.through._meta.get_field_by_name(old_field.m2m_reverse_field_name())[0],\n-            new_field.rel.through._meta.get_field_by_name(new_field.m2m_reverse_field_name())[0],\n+            old_field.rel.through._meta.get_field(old_field.m2m_reverse_field_name()),\n+            new_field.rel.through._meta.get_field(new_field.m2m_reverse_field_name()),\n         )\n         self.alter_field(\n             new_field.rel.through,\n             # for self-referential models we need to alter field from the other end too\n-            old_field.rel.through._meta.get_field_by_name(old_field.m2m_field_name())[0],\n-            new_field.rel.through._meta.get_field_by_name(new_field.m2m_field_name())[0],\n+            old_field.rel.through._meta.get_field(old_field.m2m_field_name()),\n+            new_field.rel.through._meta.get_field(new_field.m2m_field_name()),\n         )\n \n     def _create_index_name(self, model, column_names, suffix=\"\"):\n@@ -844,7 +852,7 @@ def _model_indexes_sql(self, model):\n                 output.append(self._create_index_sql(model, [field], suffix=\"\"))\n \n         for field_names in model._meta.index_together:\n-            fields = [model._meta.get_field_by_name(field)[0] for field in field_names]\n+            fields = [model._meta.get_field(field) for field in field_names]\n             output.append(self._create_index_sql(model, fields, suffix=\"_idx\"))\n         return output\n \ndiff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex 9aeca56bf731..e0433b0c13b1 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -227,8 +227,8 @@ def _alter_many_to_many(self, model, old_field, new_field, strict):\n                 alter_fields=[(\n                     # We need the field that points to the target model, so we can tell alter_field to change it -\n                     # this is m2m_reverse_field_name() (as opposed to m2m_field_name, which points to our model)\n-                    old_field.rel.through._meta.get_field_by_name(old_field.m2m_reverse_field_name())[0],\n-                    new_field.rel.through._meta.get_field_by_name(new_field.m2m_reverse_field_name())[0],\n+                    old_field.rel.through._meta.get_field(old_field.m2m_reverse_field_name()),\n+                    new_field.rel.through._meta.get_field(new_field.m2m_reverse_field_name()),\n                 )],\n                 override_uniques=(new_field.m2m_field_name(), new_field.m2m_reverse_field_name()),\n             )\ndiff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex e3dd87e3bd2b..8535a98e7357 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -163,7 +163,7 @@ def _detect_changes(self, convert_apps=None, graph=None):\n             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n             old_model_state = self.from_state.models[app_label, old_model_name]\n             for field_name, field in old_model_state.fields:\n-                old_field = self.old_apps.get_model(app_label, old_model_name)._meta.get_field_by_name(field_name)[0]\n+                old_field = self.old_apps.get_model(app_label, old_model_name)._meta.get_field(field_name)\n                 if (hasattr(old_field, \"rel\") and getattr(old_field.rel, \"through\", None)\n                         and not old_field.rel.through._meta.auto_created):\n                     through_key = (\n@@ -685,26 +685,14 @@ def generate_deleted_models(self):\n             # and the removal of all its own related fields, and if it's\n             # a through model the field that references it.\n             dependencies = []\n-            for related_object in model._meta.get_all_related_objects():\n-                dependencies.append((\n-                    related_object.model._meta.app_label,\n-                    related_object.model._meta.object_name,\n-                    related_object.field.name,\n-                    False,\n-                ))\n-                dependencies.append((\n-                    related_object.model._meta.app_label,\n-                    related_object.model._meta.object_name,\n-                    related_object.field.name,\n-                    \"alter\",\n-                ))\n-            for related_object in model._meta.get_all_related_many_to_many_objects():\n-                dependencies.append((\n-                    related_object.model._meta.app_label,\n-                    related_object.model._meta.object_name,\n-                    related_object.field.name,\n-                    False,\n-                ))\n+            for related_object in model._meta.related_objects:\n+                related_object_app_label = related_object.related_model._meta.app_label\n+                object_name = related_object.related_model._meta.object_name\n+                field_name = related_object.field.name\n+                dependencies.append((related_object_app_label, object_name, field_name, False))\n+                if not related_object.many_to_many:\n+                    dependencies.append((related_object_app_label, object_name, field_name, \"alter\"))\n+\n             for name, field in sorted(related_fields.items()):\n                 dependencies.append((app_label, model_name, name, False))\n             # We're referenced in another field's through=\n@@ -743,7 +731,7 @@ def generate_renamed_fields(self):\n         for app_label, model_name, field_name in sorted(self.new_field_keys - self.old_field_keys):\n             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n             old_model_state = self.from_state.models[app_label, old_model_name]\n-            field = self.new_apps.get_model(app_label, model_name)._meta.get_field_by_name(field_name)[0]\n+            field = self.new_apps.get_model(app_label, model_name)._meta.get_field(field_name)\n             # Scan to see if this is actually a rename!\n             field_dec = self.deep_deconstruct(field)\n             for rem_app_label, rem_model_name, rem_field_name in sorted(self.old_field_keys - self.new_field_keys):\n@@ -776,7 +764,7 @@ def generate_added_fields(self):\n             self._generate_added_field(app_label, model_name, field_name)\n \n     def _generate_added_field(self, app_label, model_name, field_name):\n-        field = self.new_apps.get_model(app_label, model_name)._meta.get_field_by_name(field_name)[0]\n+        field = self.new_apps.get_model(app_label, model_name)._meta.get_field(field_name)\n         # Fields that are foreignkeys/m2ms depend on stuff\n         dependencies = []\n         if field.rel and field.rel.to:\n@@ -847,8 +835,8 @@ def generate_altered_fields(self):\n             # Did the field change?\n             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n             old_field_name = self.renamed_fields.get((app_label, model_name, field_name), field_name)\n-            old_field = self.old_apps.get_model(app_label, old_model_name)._meta.get_field_by_name(old_field_name)[0]\n-            new_field = self.new_apps.get_model(app_label, model_name)._meta.get_field_by_name(field_name)[0]\n+            old_field = self.old_apps.get_model(app_label, old_model_name)._meta.get_field(old_field_name)\n+            new_field = self.new_apps.get_model(app_label, model_name)._meta.get_field(field_name)\n             # Implement any model renames on relations; these are handled by RenameModel\n             # so we need to exclude them from the comparison\n             if hasattr(new_field, \"rel\") and getattr(new_field.rel, \"to\", None):\ndiff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py\nindex 54251cf6edc6..6ce5e372969d 100644\n--- a/django/db/migrations/operations/fields.py\n+++ b/django/db/migrations/operations/fields.py\n@@ -44,7 +44,7 @@ def database_forwards(self, app_label, schema_editor, from_state, to_state):\n         to_model = to_state.apps.get_model(app_label, self.model_name)\n         if self.allowed_to_migrate(schema_editor.connection.alias, to_model):\n             from_model = from_state.apps.get_model(app_label, self.model_name)\n-            field = to_model._meta.get_field_by_name(self.name)[0]\n+            field = to_model._meta.get_field(self.name)\n             if not self.preserve_default:\n                 field.default = self.field.default\n             schema_editor.add_field(\n@@ -57,7 +57,7 @@ def database_forwards(self, app_label, schema_editor, from_state, to_state):\n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         from_model = from_state.apps.get_model(app_label, self.model_name)\n         if self.allowed_to_migrate(schema_editor.connection.alias, from_model):\n-            schema_editor.remove_field(from_model, from_model._meta.get_field_by_name(self.name)[0])\n+            schema_editor.remove_field(from_model, from_model._meta.get_field(self.name))\n \n     def describe(self):\n         return \"Add field %s to %s\" % (self.name, self.model_name)\n@@ -100,13 +100,13 @@ def state_forwards(self, app_label, state):\n     def database_forwards(self, app_label, schema_editor, from_state, to_state):\n         from_model = from_state.apps.get_model(app_label, self.model_name)\n         if self.allowed_to_migrate(schema_editor.connection.alias, from_model):\n-            schema_editor.remove_field(from_model, from_model._meta.get_field_by_name(self.name)[0])\n+            schema_editor.remove_field(from_model, from_model._meta.get_field(self.name))\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         to_model = to_state.apps.get_model(app_label, self.model_name)\n         if self.allowed_to_migrate(schema_editor.connection.alias, to_model):\n             from_model = from_state.apps.get_model(app_label, self.model_name)\n-            schema_editor.add_field(from_model, to_model._meta.get_field_by_name(self.name)[0])\n+            schema_editor.add_field(from_model, to_model._meta.get_field(self.name))\n \n     def describe(self):\n         return \"Remove field %s from %s\" % (self.name, self.model_name)\n@@ -158,8 +158,8 @@ def database_forwards(self, app_label, schema_editor, from_state, to_state):\n         to_model = to_state.apps.get_model(app_label, self.model_name)\n         if self.allowed_to_migrate(schema_editor.connection.alias, to_model):\n             from_model = from_state.apps.get_model(app_label, self.model_name)\n-            from_field = from_model._meta.get_field_by_name(self.name)[0]\n-            to_field = to_model._meta.get_field_by_name(self.name)[0]\n+            from_field = from_model._meta.get_field(self.name)\n+            to_field = to_model._meta.get_field(self.name)\n             # If the field is a relatedfield with an unresolved rel.to, just\n             # set it equal to the other field side. Bandaid fix for AlterField\n             # migrations that are part of a RenameModel change.\n@@ -231,8 +231,8 @@ def database_forwards(self, app_label, schema_editor, from_state, to_state):\n             from_model = from_state.apps.get_model(app_label, self.model_name)\n             schema_editor.alter_field(\n                 from_model,\n-                from_model._meta.get_field_by_name(self.old_name)[0],\n-                to_model._meta.get_field_by_name(self.new_name)[0],\n+                from_model._meta.get_field(self.old_name),\n+                to_model._meta.get_field(self.new_name),\n             )\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n@@ -241,8 +241,8 @@ def database_backwards(self, app_label, schema_editor, from_state, to_state):\n             from_model = from_state.apps.get_model(app_label, self.model_name)\n             schema_editor.alter_field(\n                 from_model,\n-                from_model._meta.get_field_by_name(self.new_name)[0],\n-                to_model._meta.get_field_by_name(self.old_name)[0],\n+                from_model._meta.get_field(self.new_name),\n+                to_model._meta.get_field(self.old_name),\n             )\n \n     def describe(self):\ndiff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex f07f667c51f3..6dd66ae4541b 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -138,25 +138,27 @@ def deconstruct(self):\n         )\n \n     def state_forwards(self, app_label, state):\n-        # Get all of the related objects we need to repoint\n         apps = state.apps\n         model = apps.get_model(app_label, self.old_name)\n         model._meta.apps = apps\n-        related_objects = model._meta.get_all_related_objects()\n-        related_m2m_objects = model._meta.get_all_related_many_to_many_objects()\n+        # Get all of the related objects we need to repoint\n+        all_related_objects = (\n+            f for f in model._meta.get_fields(include_hidden=True)\n+            if f.auto_created and not f.concrete and not (f.hidden or f.many_to_many)\n+        )\n         # Rename the model\n         state.models[app_label, self.new_name.lower()] = state.models[app_label, self.old_name.lower()]\n         state.models[app_label, self.new_name.lower()].name = self.new_name\n         state.remove_model(app_label, self.old_name)\n         # Repoint the FKs and M2Ms pointing to us\n-        for related_object in (related_objects + related_m2m_objects):\n+        for related_object in all_related_objects:\n             # Use the new related key for self referential related objects.\n-            if related_object.model == model:\n+            if related_object.related_model == model:\n                 related_key = (app_label, self.new_name.lower())\n             else:\n                 related_key = (\n-                    related_object.model._meta.app_label,\n-                    related_object.model._meta.object_name.lower(),\n+                    related_object.related_model._meta.app_label,\n+                    related_object.related_model._meta.object_name.lower(),\n                 )\n             new_fields = []\n             for name, field in state.models[related_key].fields:\n@@ -179,21 +181,19 @@ def database_forwards(self, app_label, schema_editor, from_state, to_state):\n                 new_model._meta.db_table,\n             )\n             # Alter the fields pointing to us\n-            related_objects = old_model._meta.get_all_related_objects()\n-            related_m2m_objects = old_model._meta.get_all_related_many_to_many_objects()\n-            for related_object in (related_objects + related_m2m_objects):\n-                if related_object.model == old_model:\n+            for related_object in old_model._meta.related_objects:\n+                if related_object.related_model == old_model:\n                     model = new_model\n                     related_key = (app_label, self.new_name.lower())\n                 else:\n-                    model = related_object.model\n+                    model = related_object.related_model\n                     related_key = (\n-                        related_object.model._meta.app_label,\n-                        related_object.model._meta.object_name.lower(),\n+                        related_object.related_model._meta.app_label,\n+                        related_object.related_model._meta.object_name.lower(),\n                     )\n                 to_field = to_state.apps.get_model(\n                     *related_key\n-                )._meta.get_field_by_name(related_object.field.name)[0]\n+                )._meta.get_field(related_object.field.name)\n                 schema_editor.alter_field(\n                     model,\n                     related_object.field,\n@@ -394,11 +394,11 @@ def database_forwards(self, app_label, schema_editor, from_state, to_state):\n             from_model = from_state.apps.get_model(app_label, self.name)\n             # Remove a field if we need to\n             if from_model._meta.order_with_respect_to and not to_model._meta.order_with_respect_to:\n-                schema_editor.remove_field(from_model, from_model._meta.get_field_by_name(\"_order\")[0])\n+                schema_editor.remove_field(from_model, from_model._meta.get_field(\"_order\"))\n             # Add a field if we need to (altering the column is untouched as\n             # it's likely a rename)\n             elif to_model._meta.order_with_respect_to and not from_model._meta.order_with_respect_to:\n-                field = to_model._meta.get_field_by_name(\"_order\")[0]\n+                field = to_model._meta.get_field(\"_order\")\n                 if not field.has_default():\n                     field.default = 0\n                 schema_editor.add_field(\ndiff --git a/django/db/migrations/state.py b/django/db/migrations/state.py\nindex 8a45a0d2f299..6626e31442ca 100644\n--- a/django/db/migrations/state.py\n+++ b/django/db/migrations/state.py\n@@ -50,15 +50,15 @@ def reload_model(self, app_label, model_name):\n             model_name = model_name.lower()\n             try:\n                 related_old = {\n-                    f.model for f in\n-                    self.apps.get_model(app_label, model_name)._meta.get_all_related_objects()\n+                    f.related_model for f in\n+                    self.apps.get_model(app_label, model_name)._meta.related_objects\n                 }\n             except LookupError:\n                 related_old = set()\n             self._reload_one_model(app_label, model_name)\n             # Reload models if there are relations\n             model = self.apps.get_model(app_label, model_name)\n-            related_m2m = {f.rel.to for f, _ in model._meta.get_m2m_with_model()}\n+            related_m2m = {f.related_model for f in model._meta.many_to_many}\n             for rel_model in related_old.union(related_m2m):\n                 self._reload_one_model(rel_model._meta.app_label, rel_model._meta.model_name)\n             if related_m2m:\ndiff --git a/django/db/models/base.py b/django/db/models/base.py\nindex ec5d4c7c1c39..945cd0154b79 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -2,6 +2,7 @@\n \n import copy\n import inspect\n+from itertools import chain\n import sys\n import warnings\n \n@@ -175,12 +176,12 @@ def __new__(cls, name, bases, attrs):\n             new_class.add_to_class(obj_name, obj)\n \n         # All the fields of any type declared on this model\n-        new_fields = (\n-            new_class._meta.local_fields +\n-            new_class._meta.local_many_to_many +\n+        new_fields = chain(\n+            new_class._meta.local_fields,\n+            new_class._meta.local_many_to_many,\n             new_class._meta.virtual_fields\n         )\n-        field_names = set(f.name for f in new_fields)\n+        field_names = {f.name for f in new_fields}\n \n         # Basic setup for proxy models.\n         if is_proxy:\n@@ -202,6 +203,7 @@ def __new__(cls, name, bases, attrs):\n                 raise TypeError(\"Proxy model '%s' has no non-abstract model base class.\" % name)\n             new_class._meta.setup_proxy(base)\n             new_class._meta.concrete_model = base._meta.concrete_model\n+            base._meta.concrete_model._meta.proxied_children.append(new_class._meta)\n         else:\n             new_class._meta.concrete_model = new_class\n \n@@ -342,7 +344,7 @@ def make_foreign_order_accessors(field, model, cls):\n \n         # Give the class a docstring -- its definition.\n         if cls.__doc__ is None:\n-            cls.__doc__ = \"%s(%s)\" % (cls.__name__, \", \".join(f.attname for f in opts.fields))\n+            cls.__doc__ = \"%s(%s)\" % (cls.__name__, \", \".join(f.name for f in opts.fields))\n \n         get_absolute_url_override = settings.ABSOLUTE_URL_OVERRIDES.get(\n             '%s.%s' % (opts.app_label, opts.model_name)\n@@ -630,7 +632,7 @@ def serializable_value(self, field_name):\n         and not use this method.\n         \"\"\"\n         try:\n-            field = self._meta.get_field_by_name(field_name)[0]\n+            field = self._meta.get_field(field_name)\n         except FieldDoesNotExist:\n             return getattr(self, field_name)\n         return getattr(self, field.attname)\n@@ -1438,12 +1440,17 @@ def _check_unique_together(cls):\n     def _check_local_fields(cls, fields, option):\n         from django.db import models\n \n+        # In order to avoid hitting the relation tree prematurely, we use our\n+        # own fields_map instead of using get_field()\n+        forward_fields_map = {\n+            field.name: field for field in cls._meta._get_fields(reverse=False)\n+        }\n+\n         errors = []\n         for field_name in fields:\n             try:\n-                field = cls._meta.get_field(field_name,\n-                    many_to_many=True)\n-            except FieldDoesNotExist:\n+                field = forward_fields_map[field_name]\n+            except KeyError:\n                 errors.append(\n                     checks.Error(\n                         \"'%s' refers to the non-existent field '%s'.\" % (option, field_name),\n@@ -1484,7 +1491,6 @@ def _check_local_fields(cls, fields, option):\n     def _check_ordering(cls):\n         \"\"\" Check \"ordering\" option -- is it a list of strings and do all fields\n         exist? \"\"\"\n-\n         if not cls._meta.ordering:\n             return []\n \n@@ -1500,7 +1506,6 @@ def _check_ordering(cls):\n             ]\n \n         errors = []\n-\n         fields = cls._meta.ordering\n \n         # Skip '?' fields.\n@@ -1518,28 +1523,30 @@ def _check_ordering(cls):\n \n         # Skip ordering on pk. This is always a valid order_by field\n         # but is an alias and therefore won't be found by opts.get_field.\n-        fields = (f for f in fields if f != 'pk')\n+        fields = {f for f in fields if f != 'pk'}\n \n-        for field_name in fields:\n-            try:\n-                cls._meta.get_field(field_name, many_to_many=False)\n-            except FieldDoesNotExist:\n-                if field_name.endswith('_id'):\n-                    try:\n-                        field = cls._meta.get_field(field_name[:-3], many_to_many=False)\n-                    except FieldDoesNotExist:\n-                        pass\n-                    else:\n-                        if field.attname == field_name:\n-                            continue\n-                errors.append(\n-                    checks.Error(\n-                        \"'ordering' refers to the non-existent field '%s'.\" % field_name,\n-                        hint=None,\n-                        obj=cls,\n-                        id='models.E015',\n-                    )\n+        # Check for invalid or non-existent fields in ordering.\n+        invalid_fields = []\n+\n+        # Any field name that is not present in field_names does not exist.\n+        # Also, ordering by m2m fields is not allowed.\n+        opts = cls._meta\n+        valid_fields = set(chain.from_iterable(\n+            (f.name, f.attname) if not (f.auto_created and not f.concrete) else (f.field.related_query_name(),)\n+            for f in chain(opts.fields, opts.related_objects)\n+        ))\n+\n+        invalid_fields.extend(fields - valid_fields)\n+\n+        for invalid_field in invalid_fields:\n+            errors.append(\n+                checks.Error(\n+                    \"'ordering' refers to the non-existent field '%s'.\" % invalid_field,\n+                    hint=None,\n+                    obj=cls,\n+                    id='models.E015',\n                 )\n+            )\n         return errors\n \n     @classmethod\ndiff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex c61f865be2c0..016fc5637e7c 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -1,4 +1,5 @@\n from collections import OrderedDict\n+from itertools import chain\n from operator import attrgetter\n \n from django.db import connections, transaction, IntegrityError\n@@ -51,6 +52,23 @@ def DO_NOTHING(collector, field, sub_objs, using):\n     pass\n \n \n+def get_candidate_relations_to_delete(opts):\n+    # Collect models that contain candidate relations to delete. This may include\n+    # relations coming from proxy models.\n+    candidate_models = {opts}\n+    candidate_models = candidate_models.union(opts.concrete_model._meta.proxied_children)\n+    # For each model, get all candidate fields.\n+    candidate_model_fields = chain.from_iterable(\n+        opts.get_fields(include_hidden=True) for opts in candidate_models\n+    )\n+    # The candidate relations are the ones that come from N-1 and 1-1 relations.\n+    # N-N  (i.e., many-to-many) relations aren't candidates for deletion.\n+    return (\n+        f for f in candidate_model_fields\n+        if f.auto_created and not f.concrete and (f.one_to_one or f.many_to_one)\n+    )\n+\n+\n class Collector(object):\n     def __init__(self, using):\n         self.using = using\n@@ -134,8 +152,7 @@ def can_fast_delete(self, objs, from_field=None):\n             return False\n         # Foreign keys pointing to this model, both from m2m and other\n         # models.\n-        for related in opts.get_all_related_objects(\n-                include_hidden=True, include_proxy_eq=True):\n+        for related in get_candidate_relations_to_delete(opts):\n             if related.field.rel.on_delete is not DO_NOTHING:\n                 return False\n         for field in model._meta.virtual_fields:\n@@ -184,7 +201,7 @@ def collect(self, objs, source=None, nullable=False, collect_related=True,\n         model = new_objs[0].__class__\n \n         # Recursively collect concrete model's parent models, but not their\n-        # related objects. These will be found by meta.get_all_related_objects()\n+        # related objects. These will be found by meta.get_fields()\n         concrete_model = model._meta.concrete_model\n         for ptr in six.itervalues(concrete_model._meta.parents):\n             if ptr:\n@@ -199,8 +216,7 @@ def collect(self, objs, source=None, nullable=False, collect_related=True,\n                              reverse_dependency=True)\n \n         if collect_related:\n-            for related in model._meta.get_all_related_objects(\n-                    include_hidden=True, include_proxy_eq=True):\n+            for related in get_candidate_relations_to_delete(model._meta):\n                 field = related.field\n                 if field.rel.on_delete == DO_NOTHING:\n                     continue\n@@ -225,7 +241,7 @@ def related_objects(self, related, objs):\n         Gets a QuerySet of objects related to ``objs`` via the relation ``related``.\n \n         \"\"\"\n-        return related.model._base_manager.using(self.using).filter(\n+        return related.related_model._base_manager.using(self.using).filter(\n             **{\"%s__in\" % related.field.name: objs}\n         )\n \ndiff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 8dc9c554ddc2..a1995452a3c5 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -31,7 +31,9 @@\n from django.utils import six\n from django.utils.itercompat import is_iterable\n \n-# imported for backwards compatibility\n+# When the _meta object was formalized, this exception was moved to\n+# django.core.exceptions. It is retained here for backwards compatibility\n+# purposes.\n from django.core.exceptions import FieldDoesNotExist  # NOQA\n \n # Avoid \"TypeError: Item in ``from list'' not a string\" -- unicode_literals\n@@ -61,7 +63,7 @@ class NOT_PROVIDED:\n \n \n def _load_field(app_label, model_name, field_name):\n-    return apps.get_model(app_label, model_name)._meta.get_field_by_name(field_name)[0]\n+    return apps.get_model(app_label, model_name)._meta.get_field(field_name)\n \n \n # A guide to Field parameters:\n@@ -116,6 +118,15 @@ class Field(RegisterLookupMixin):\n     system_check_deprecated_details = None\n     system_check_removed_details = None\n \n+    # Field flags\n+    hidden = False\n+\n+    many_to_many = None\n+    many_to_one = None\n+    one_to_many = None\n+    one_to_one = None\n+    related_model = None\n+\n     # Generic field type description, usually overridden by subclasses\n     def _description(self):\n         return _('Field of type: %(field_type)s') % {\n@@ -137,6 +148,7 @@ def __init__(self, verbose_name=None, name=None, primary_key=False,\n         self.max_length, self._unique = max_length, unique\n         self.blank, self.null = blank, null\n         self.rel = rel\n+        self.is_relation = self.rel is not None\n         self.default = default\n         self.editable = editable\n         self.serialize = serialize\n@@ -603,6 +615,7 @@ def set_attributes_from_name(self, name):\n         if not self.name:\n             self.name = name\n         self.attname, self.column = self.get_attname_column()\n+        self.concrete = self.column is not None\n         if self.verbose_name is None and self.name:\n             self.verbose_name = self.name.replace('_', ' ')\n \n@@ -610,7 +623,7 @@ def contribute_to_class(self, cls, name, virtual_only=False):\n         self.set_attributes_from_name(name)\n         self.model = cls\n         if virtual_only:\n-            cls._meta.add_virtual_field(self)\n+            cls._meta.add_field(self, virtual=True)\n         else:\n             cls._meta.add_field(self)\n         if self.choices:\ndiff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 2e05e57e5145..9ef6c1350a4d 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -98,6 +98,18 @@ def do_pending_lookups(sender, **kwargs):\n \n \n class RelatedField(Field):\n+    # Field flags\n+    one_to_many = False\n+    one_to_one = False\n+    many_to_many = False\n+    many_to_one = False\n+\n+    @cached_property\n+    def related_model(self):\n+        # Can't cache this property until all the models are loaded.\n+        apps.check_models_ready()\n+        return self.rel.to\n+\n     def check(self, **kwargs):\n         errors = super(RelatedField, self).check(**kwargs)\n         errors.extend(self._check_related_name_is_valid())\n@@ -235,13 +247,10 @@ def _check_clashes(self):\n         # Check clashes between accessors/reverse query names of `field` and\n         # any other field accessor -- i. e. Model.foreign accessor clashes with\n         # Model.m2m accessor.\n-        potential_clashes = rel_opts.get_all_related_many_to_many_objects()\n-        potential_clashes += rel_opts.get_all_related_objects()\n-        potential_clashes = (r for r in potential_clashes\n-            if r.field is not self)\n+        potential_clashes = (r for r in rel_opts.related_objects if r.field is not self)\n         for clash_field in potential_clashes:\n             clash_name = \"%s.%s\" % (  # i. e. \"Model.m2m\"\n-                clash_field.model._meta.object_name,\n+                clash_field.related_model._meta.object_name,\n                 clash_field.field.name)\n             if clash_field.get_accessor_name() == rel_name:\n                 errors.append(\n@@ -392,7 +401,7 @@ def RelatedObjectDoesNotExist(self):\n         # consistency with `ReverseSingleRelatedObjectDescriptor`.\n         return type(\n             str('RelatedObjectDoesNotExist'),\n-            (self.related.model.DoesNotExist, AttributeError),\n+            (self.related.related_model.DoesNotExist, AttributeError),\n             {}\n         )\n \n@@ -400,11 +409,11 @@ def is_cached(self, instance):\n         return hasattr(instance, self.cache_name)\n \n     def get_queryset(self, **hints):\n-        manager = self.related.model._default_manager\n+        manager = self.related.related_model._default_manager\n         # If the related manager indicates that it should be used for\n         # related fields, respect that.\n         if not getattr(manager, 'use_for_related_fields', False):\n-            manager = self.related.model._base_manager\n+            manager = self.related.related_model._base_manager\n         return manager.db_manager(hints=hints).all()\n \n     def get_prefetch_queryset(self, instances, queryset=None):\n@@ -441,7 +450,7 @@ def __get__(self, instance, instance_type=None):\n                     params['%s__%s' % (self.related.field.name, rh_field.name)] = getattr(instance, rh_field.attname)\n                 try:\n                     rel_obj = self.get_queryset(instance=instance).get(**params)\n-                except self.related.model.DoesNotExist:\n+                except self.related.related_model.DoesNotExist:\n                     rel_obj = None\n                 else:\n                     setattr(rel_obj, self.related.field.get_cache_name(), instance)\n@@ -470,7 +479,7 @@ def __set__(self, instance, value):\n                     self.related.get_accessor_name(),\n                 )\n             )\n-        elif value is not None and not isinstance(value, self.related.model):\n+        elif value is not None and not isinstance(value, self.related.related_model):\n             raise ValueError(\n                 'Cannot assign \"%r\": \"%s.%s\" must be a \"%s\" instance.' % (\n                     value,\n@@ -825,9 +834,9 @@ def related_manager_cls(self):\n         # Dynamically create a class that subclasses the related model's default\n         # manager.\n         return create_foreign_related_manager(\n-            self.related.model._default_manager.__class__,\n+            self.related.related_model._default_manager.__class__,\n             self.related.field,\n-            self.related.model,\n+            self.related.related_model,\n         )\n \n \n@@ -1148,7 +1157,7 @@ def related_manager_cls(self):\n         # Dynamically create a class that subclasses the related\n         # model's default manager.\n         return create_many_related_manager(\n-            self.related.model._default_manager.__class__,\n+            self.related.related_model._default_manager.__class__,\n             self.related.field.rel\n         )\n \n@@ -1156,7 +1165,7 @@ def __get__(self, instance, instance_type=None):\n         if instance is None:\n             return self\n \n-        rel_model = self.related.model\n+        rel_model = self.related.related_model\n \n         manager = self.related_manager_cls(\n             model=rel_model,\n@@ -1255,6 +1264,12 @@ def __set__(self, instance, value):\n \n \n class ForeignObjectRel(object):\n+    # Field flags\n+    auto_created = True\n+    concrete = False\n+    editable = False\n+    is_relation = True\n+\n     def __init__(self, field, to, related_name=None, limit_choices_to=None,\n                  parent_link=False, on_delete=None, related_query_name=None):\n         self.field = field\n@@ -1267,32 +1282,55 @@ def __init__(self, field, to, related_name=None, limit_choices_to=None,\n         self.on_delete = on_delete\n         self.symmetrical = False\n \n-    # This and the following cached_properties can't be initialized in\n+    # Some of the following cached_properties can't be initialized in\n     # __init__ as the field doesn't have its model yet. Calling these methods\n     # before field.contribute_to_class() has been called will result in\n     # AttributeError\n     @cached_property\n     def model(self):\n-        if not self.field.model:\n-            raise AttributeError(\n-                \"This property can't be accessed before self.field.contribute_to_class has been called.\")\n-        return self.field.model\n+        return self.to\n \n     @cached_property\n     def opts(self):\n-        return self.model._meta\n+        return self.related_model._meta\n \n     @cached_property\n     def to_opts(self):\n         return self.to._meta\n \n     @cached_property\n-    def parent_model(self):\n-        return self.to\n+    def hidden(self):\n+        return self.is_hidden()\n \n     @cached_property\n     def name(self):\n-        return '%s.%s' % (self.opts.app_label, self.opts.model_name)\n+        return self.field.related_query_name()\n+\n+    @cached_property\n+    def related_model(self):\n+        if not self.field.model:\n+            raise AttributeError(\n+                \"This property can't be accessed before self.field.contribute_to_class has been called.\")\n+        return self.field.model\n+\n+    @cached_property\n+    def many_to_many(self):\n+        return self.field.many_to_many\n+\n+    @cached_property\n+    def many_to_one(self):\n+        return self.field.one_to_many\n+\n+    @cached_property\n+    def one_to_many(self):\n+        return self.field.many_to_one\n+\n+    @cached_property\n+    def one_to_one(self):\n+        return self.field.one_to_one\n+\n+    def __repr__(self):\n+        return '<%s: %s.%s>' % (type(self).__name__, self.opts.app_label, self.opts.model_name)\n \n     def get_choices(self, include_blank=True, blank_choice=BLANK_CHOICE_DASH,\n                     limit_to_currently_related=False):\n@@ -1304,10 +1342,10 @@ def get_choices(self, include_blank=True, blank_choice=BLANK_CHOICE_DASH,\n         initially for utilization by RelatedFieldListFilter.\n         \"\"\"\n         first_choice = blank_choice if include_blank else []\n-        queryset = self.model._default_manager.all()\n+        queryset = self.related_model._default_manager.all()\n         if limit_to_currently_related:\n             queryset = queryset.complex_filter(\n-                {'%s__isnull' % self.parent_model._meta.model_name: False}\n+                {'%s__isnull' % self.related_model._meta.model_name: False}\n             )\n         lst = [(x._get_pk_val(), smart_text(x)) for x in queryset]\n         return first_choice + lst\n@@ -1318,7 +1356,7 @@ def get_db_prep_lookup(self, lookup_type, value, connection, prepared=False):\n \n     def is_hidden(self):\n         \"Should the related object be hidden?\"\n-        return self.related_name and self.related_name[-1] == '+'\n+        return self.related_name is not None and self.related_name[-1] == '+'\n \n     def get_joining_columns(self):\n         return self.field.get_reverse_joining_columns()\n@@ -1349,7 +1387,7 @@ def get_accessor_name(self, model=None):\n         # Due to backwards compatibility ModelForms need to be able to provide\n         # an alternate model. See BaseInlineFormSet.get_default_prefix().\n         opts = model._meta if model else self.opts\n-        model = model or self.model\n+        model = model or self.related_model\n         if self.multiple:\n             # If this is a symmetrical m2m relation on self, there is no reverse accessor.\n             if self.symmetrical and model == self.to:\n@@ -1383,11 +1421,11 @@ def get_related_field(self):\n         Returns the Field in the 'to' object to which this relationship is\n         tied.\n         \"\"\"\n-        data = self.to._meta.get_field_by_name(self.field_name)\n-        if not data[2]:\n+        field = self.to._meta.get_field(self.field_name)\n+        if not field.concrete:\n             raise FieldDoesNotExist(\"No related field named '%s'\" %\n                     self.field_name)\n-        return data[0]\n+        return field\n \n     def set_field_name(self):\n         self.field_name = self.field_name or self.to._meta.pk.name\n@@ -1419,6 +1457,10 @@ def __init__(self, field, to, related_name=None, limit_choices_to=None,\n         self.through_fields = through_fields\n         self.db_constraint = db_constraint\n \n+    def is_hidden(self):\n+        \"Should the related object be hidden?\"\n+        return self.related_name is not None and self.related_name[-1] == '+'\n+\n     def get_related_field(self):\n         \"\"\"\n         Returns the field in the 'to' object to which this relationship is tied.\n@@ -1436,8 +1478,13 @@ def get_related_field(self):\n \n \n class ForeignObject(RelatedField):\n+    # Field flags\n+    many_to_many = False\n+    many_to_one = False\n+    one_to_many = True\n+    one_to_one = False\n+\n     requires_unique_target = True\n-    generate_reverse_relation = True\n     related_accessor_class = ForeignRelatedObjectsDescriptor\n \n     def __init__(self, to, from_fields, to_fields, swappable=True, **kwargs):\n@@ -1556,9 +1603,9 @@ def resolve_related_fields(self):\n             from_field_name = self.from_fields[index]\n             to_field_name = self.to_fields[index]\n             from_field = (self if from_field_name == 'self'\n-                          else self.opts.get_field_by_name(from_field_name)[0])\n+                          else self.opts.get_field(from_field_name))\n             to_field = (self.rel.to._meta.pk if to_field_name is None\n-                        else self.rel.to._meta.get_field_by_name(to_field_name)[0])\n+                        else self.rel.to._meta.get_field(to_field_name))\n             related_fields.append((from_field, to_field))\n         return related_fields\n \n@@ -1731,7 +1778,7 @@ def contribute_to_class(self, cls, name, virtual_only=False):\n     def contribute_to_related_class(self, cls, related):\n         # Internal FK's - i.e., those with a related name ending with '+' -\n         # and swapped models don't get a related descriptor.\n-        if not self.rel.is_hidden() and not related.model._meta.swapped:\n+        if not self.rel.is_hidden() and not related.related_model._meta.swapped:\n             setattr(cls, related.get_accessor_name(), self.related_accessor_class(related))\n             # While 'limit_choices_to' might be a callable, simply pass\n             # it along for later - this is too early because it's still\n@@ -1741,6 +1788,12 @@ def contribute_to_related_class(self, cls, related):\n \n \n class ForeignKey(ForeignObject):\n+    # Field flags\n+    many_to_many = False\n+    many_to_one = False\n+    one_to_many = True\n+    one_to_one = False\n+\n     empty_strings_allowed = False\n     default_error_messages = {\n         'invalid': _('%(model)s instance with %(field)s %(value)r does not exist.')\n@@ -1951,6 +2004,12 @@ class OneToOneField(ForeignKey):\n     always returns the object pointed to (since there will only ever be one),\n     rather than returning a list.\n     \"\"\"\n+    # Field flags\n+    many_to_many = False\n+    many_to_one = False\n+    one_to_many = False\n+    one_to_one = True\n+\n     related_accessor_class = SingleRelatedObjectDescriptor\n     description = _(\"One-to-one relationship\")\n \n@@ -2036,6 +2095,12 @@ def set_managed(field, model, cls):\n \n \n class ManyToManyField(RelatedField):\n+    # Field flags\n+    many_to_many = True\n+    many_to_one = False\n+    one_to_many = False\n+    one_to_one = False\n+\n     description = _(\"Many-to-many relationship\")\n \n     def __init__(self, to, db_constraint=True, swappable=True, **kwargs):\n@@ -2050,7 +2115,6 @@ def __init__(self, to, db_constraint=True, swappable=True, **kwargs):\n             # Class names must be ASCII in Python 2.x, so we forcibly coerce it\n             # here to break early if there's a problem.\n             to = str(to)\n-\n         kwargs['verbose_name'] = kwargs.get('verbose_name', None)\n         kwargs['rel'] = ManyToManyRel(\n             self, to,\n@@ -2357,8 +2421,8 @@ def _get_path_info(self, direct=False):\n         \"\"\"\n         pathinfos = []\n         int_model = self.rel.through\n-        linkfield1 = int_model._meta.get_field_by_name(self.m2m_field_name())[0]\n-        linkfield2 = int_model._meta.get_field_by_name(self.m2m_reverse_field_name())[0]\n+        linkfield1 = int_model._meta.get_field(self.m2m_field_name())\n+        linkfield2 = int_model._meta.get_field(self.m2m_reverse_field_name())\n         if direct:\n             join1infos = linkfield1.get_reverse_path_info()\n             join2infos = linkfield2.get_path_info()\n@@ -2398,8 +2462,8 @@ def _get_m2m_attr(self, related, attr):\n         else:\n             link_field_name = None\n         for f in self.rel.through._meta.fields:\n-            if hasattr(f, 'rel') and f.rel and f.rel.to == related.model and \\\n-                    (link_field_name is None or link_field_name == f.name):\n+            if (f.is_relation and f.rel.to == related.related_model and\n+                    (link_field_name is None or link_field_name == f.name)):\n                 setattr(self, cache_attr, getattr(f, attr))\n                 return getattr(self, cache_attr)\n \n@@ -2414,8 +2478,9 @@ def _get_m2m_reverse_attr(self, related, attr):\n         else:\n             link_field_name = None\n         for f in self.rel.through._meta.fields:\n-            if hasattr(f, 'rel') and f.rel and f.rel.to == related.parent_model:\n-                if link_field_name is None and related.model == related.parent_model:\n+            # NOTE f.rel.to != f.related_model\n+            if f.is_relation and f.rel.to == related.model:\n+                if link_field_name is None and related.related_model == related.model:\n                     # If this is an m2m-intermediate to self,\n                     # the first foreign key you find will be\n                     # the source column. Keep searching for\n@@ -2479,7 +2544,7 @@ def resolve_through_model(field, model, cls):\n     def contribute_to_related_class(self, cls, related):\n         # Internal M2Ms (i.e., those with a related name ending with '+')\n         # and swapped models don't get a related descriptor.\n-        if not self.rel.is_hidden() and not related.model._meta.swapped:\n+        if not self.rel.is_hidden() and not related.related_model._meta.swapped:\n             setattr(cls, related.get_accessor_name(), ManyRelatedObjectsDescriptor(related))\n \n         # Set up the accessors for the column names on the m2m table\ndiff --git a/django/db/models/manager.py b/django/db/models/manager.py\nindex 179ea7cee3a0..aa2df3f0e860 100644\n--- a/django/db/models/manager.py\n+++ b/django/db/models/manager.py\n@@ -2,7 +2,6 @@\n from importlib import import_module\n import inspect\n \n-from django.core.exceptions import FieldDoesNotExist\n from django.db import router\n from django.db.models.query import QuerySet\n from django.utils import six\n@@ -23,15 +22,12 @@ def ensure_default_manager(cls):\n         setattr(cls, 'objects', SwappedManagerDescriptor(cls))\n         return\n     if not getattr(cls, '_default_manager', None):\n-        # Create the default manager, if needed.\n-        try:\n-            cls._meta.get_field('objects')\n+        if any(f.name == 'objects' for f in cls._meta.fields):\n             raise ValueError(\n                 \"Model %s must specify a custom Manager, because it has a \"\n                 \"field named 'objects'\" % cls.__name__\n             )\n-        except FieldDoesNotExist:\n-            pass\n+        # Create the default manager, if needed.\n         cls.add_to_class('objects', Manager())\n         cls._base_manager = cls.objects\n     elif not getattr(cls, '_base_manager', None):\ndiff --git a/django/db/models/options.py b/django/db/models/options.py\nindex 79954a87e610..6b48d2733bee 100644\n--- a/django/db/models/options.py\n+++ b/django/db/models/options.py\n@@ -1,20 +1,31 @@\n from __future__ import unicode_literals\n \n from bisect import bisect\n-from collections import OrderedDict\n+from collections import OrderedDict, defaultdict\n+from itertools import chain\n+import warnings\n \n from django.apps import apps\n from django.conf import settings\n from django.core.exceptions import FieldDoesNotExist\n-from django.db.models.fields.related import ManyToManyRel\n+from django.db.models.fields.related import ManyToManyField\n from django.db.models.fields import AutoField\n from django.db.models.fields.proxy import OrderWrt\n from django.utils import six\n+from django.utils.datastructures import ImmutableList\n+from django.utils.deprecation import RemovedInDjango20Warning\n from django.utils.encoding import force_text, smart_text, python_2_unicode_compatible\n from django.utils.functional import cached_property\n+from django.utils.lru_cache import lru_cache\n from django.utils.text import camel_case_to_spaces\n from django.utils.translation import activate, deactivate_all, get_language, string_concat\n \n+EMPTY_RELATION_TREE = tuple()\n+\n+IMMUTABLE_WARNING = (\n+    \"The return type of '%s' should never be mutated. If you want to manipulate this list \"\n+    \"for your own use, make a copy first.\"\n+)\n \n DEFAULT_NAMES = ('verbose_name', 'verbose_name_plural', 'db_table', 'ordering',\n                  'unique_together', 'permissions', 'get_latest_by',\n@@ -24,6 +35,24 @@\n                  'select_on_save', 'default_related_name')\n \n \n+class raise_deprecation(object):\n+    def __init__(self, suggested_alternative):\n+        self.suggested_alternative = suggested_alternative\n+\n+    def __call__(self, fn):\n+        def wrapper(*args, **kwargs):\n+            warnings.warn(\n+                \"'%s is an unofficial API that has been deprecated. \"\n+                \"You may be able to replace it with '%s'\" % (\n+                    fn.__name__,\n+                    self.suggested_alternative,\n+                ),\n+                RemovedInDjango20Warning, stacklevel=2\n+            )\n+            return fn(*args, **kwargs)\n+        return wrapper\n+\n+\n def normalize_together(option_together):\n     \"\"\"\n     option_together can be either a tuple of tuples, or a single\n@@ -46,9 +75,19 @@ def normalize_together(option_together):\n         return option_together\n \n \n+def make_immutable_fields_list(name, data):\n+    return ImmutableList(data, warning=IMMUTABLE_WARNING % name)\n+\n+\n @python_2_unicode_compatible\n class Options(object):\n+    FORWARD_PROPERTIES = ('fields', 'many_to_many', 'concrete_fields',\n+                          'local_concrete_fields', '_forward_fields_map')\n+    REVERSE_PROPERTIES = ('related_objects', 'fields_map', '_relation_tree')\n+\n     def __init__(self, meta, app_label=None):\n+        self._get_fields_cache = {}\n+        self.proxied_children = []\n         self.local_fields = []\n         self.local_many_to_many = []\n         self.virtual_fields = []\n@@ -103,6 +142,31 @@ def __init__(self, meta, app_label=None):\n \n         self.default_related_name = None\n \n+    @lru_cache(maxsize=None)\n+    def _map_model(self, link):\n+        # This helper function is used to allow backwards compatibility with\n+        # the previous API. No future methods should use this function.\n+        # It maps a field to (field, model or related_model,) depending on the\n+        # field type.\n+        model = link.model._meta.concrete_model\n+        if model is self.model:\n+            model = None\n+        return link, model\n+\n+    @lru_cache(maxsize=None)\n+    def _map_model_details(self, link):\n+        # This helper function is used to allow backwards compatibility with\n+        # the previous API. No future methods should use this function.\n+        # This function maps a field to a tuple of:\n+        #  (field, model or related_model, direct, is_m2m) depending on the\n+        # field type.\n+        direct = not link.auto_created or link.concrete\n+        model = link.model._meta.concrete_model\n+        if model is self.model:\n+            model = None\n+        m2m = link.is_relation and link.many_to_many\n+        return link, model, direct, m2m\n+\n     @property\n     def app_config(self):\n         # Don't go through get_app_config to avoid triggering imports.\n@@ -183,7 +247,17 @@ def contribute_to_class(self, cls, name):\n \n     def _prepare(self, model):\n         if self.order_with_respect_to:\n-            self.order_with_respect_to = self.get_field(self.order_with_respect_to)\n+            # The app registry will not be ready at this point, so we cannot\n+            # use get_field().\n+            query = self.order_with_respect_to\n+            try:\n+                self.order_with_respect_to = next(\n+                    f for f in self._get_fields(reverse=False)\n+                    if f.name == query or f.attname == query\n+                )\n+            except StopIteration:\n+                raise FieldDoesNotExist('%s has no field named %r' % (self.object_name, query))\n+\n             self.ordering = ('_order',)\n             if not any(isinstance(field, OrderWrt) for field in model._meta.local_fields):\n                 model.add_to_class('_order', OrderWrt())\n@@ -208,56 +282,41 @@ def _prepare(self, model):\n                         auto_created=True)\n                 model.add_to_class('id', auto)\n \n-    def add_field(self, field):\n+    def add_field(self, field, virtual=False):\n         # Insert the given field in the order in which it was created, using\n         # the \"creation_counter\" attribute of the field.\n         # Move many-to-many related fields from self.fields into\n         # self.many_to_many.\n-        if field.rel and isinstance(field.rel, ManyToManyRel):\n+        if virtual:\n+            self.virtual_fields.append(field)\n+        elif field.is_relation and field.many_to_many:\n             self.local_many_to_many.insert(bisect(self.local_many_to_many, field), field)\n-            if hasattr(self, '_m2m_cache'):\n-                del self._m2m_cache\n         else:\n             self.local_fields.insert(bisect(self.local_fields, field), field)\n             self.setup_pk(field)\n-            if hasattr(self, '_field_cache'):\n-                del self._field_cache\n-                del self._field_name_cache\n-                # The fields, concrete_fields and local_concrete_fields are\n-                # implemented as cached properties for performance reasons.\n-                # The attrs will not exists if the cached property isn't\n-                # accessed yet, hence the try-excepts.\n-                try:\n-                    del self.fields\n-                except AttributeError:\n-                    pass\n-                try:\n-                    del self.concrete_fields\n-                except AttributeError:\n-                    pass\n-                try:\n-                    del self.local_concrete_fields\n-                except AttributeError:\n-                    pass\n-\n-        if hasattr(self, '_name_map'):\n-            del self._name_map\n \n-    def add_virtual_field(self, field):\n-        self.virtual_fields.append(field)\n+        # If the field being added is a relation to another known field,\n+        # expire the cache on this field and the forward cache on the field\n+        # being referenced, because there will be new relationships in the\n+        # cache. Otherwise, expire the cache of references *to* this field.\n+        # The mechanism for getting at the related model is slightly odd -\n+        # ideally, we'd just ask for field.related_model. However, related_model\n+        # is a cached property, and all the models haven't been loaded yet, so\n+        # we need to make sure we don't cache a string reference.\n+        if field.is_relation and hasattr(field.rel, 'to') and field.rel.to:\n+            try:\n+                field.rel.to._meta._expire_cache(forward=False)\n+            except AttributeError:\n+                pass\n+            self._expire_cache()\n+        else:\n+            self._expire_cache(reverse=False)\n \n     def setup_pk(self, field):\n         if not self.pk and field.primary_key:\n             self.pk = field\n             field.serialize = False\n \n-    def pk_index(self):\n-        \"\"\"\n-        Returns the index of the primary key field in the self.concrete_fields\n-        list.\n-        \"\"\"\n-        return self.concrete_fields.index(self.pk)\n-\n     def setup_proxy(self, target):\n         \"\"\"\n         Does the internal setup so that the current model is a proxy for\n@@ -273,6 +332,7 @@ def __repr__(self):\n     def __str__(self):\n         return \"%s.%s\" % (smart_text(self.app_label), smart_text(self.model_name))\n \n+    @property\n     def verbose_name_raw(self):\n         \"\"\"\n         There are a few places where the untranslated verbose name is needed\n@@ -284,9 +344,9 @@ def verbose_name_raw(self):\n         raw = force_text(self.verbose_name)\n         activate(lang)\n         return raw\n-    verbose_name_raw = property(verbose_name_raw)\n \n-    def _swapped(self):\n+    @property\n+    def swapped(self):\n         \"\"\"\n         Has this model been swapped out for another? If so, return the model\n         name of the replacement; otherwise, return None.\n@@ -310,253 +370,253 @@ def _swapped(self):\n                 if '%s.%s' % (swapped_label, swapped_object.lower()) not in (None, model_label):\n                     return swapped_for\n         return None\n-    swapped = property(_swapped)\n \n     @cached_property\n     def fields(self):\n         \"\"\"\n-        The getter for self.fields. This returns the list of field objects\n-        available to this model (including through parent models).\n-\n-        Callers are not permitted to modify this list, since it's a reference\n-        to this instance (not a copy).\n-        \"\"\"\n-        try:\n-            self._field_name_cache\n-        except AttributeError:\n-            self._fill_fields_cache()\n-        return self._field_name_cache\n+        Returns a list of all forward fields on the model and its parents,\n+        excluding ManyToManyFields.\n+\n+        Private API intended only to be used by Django itself; get_fields()\n+        combined with filtering of field properties is the public API for\n+        obtaining this field list.\n+        \"\"\"\n+        # For legacy reasons, the fields property should only contain forward\n+        # fields that are not virtual or with a m2m cardinality. Therefore we\n+        # pass these three filters as filters to the generator.\n+        # The third lambda is a longwinded way of checking f.related_model - we don't\n+        # use that property directly because related_model is a cached property,\n+        # and all the models may not have been loaded yet; we don't want to cache\n+        # the string reference to the related_model.\n+        is_not_an_m2m_field = lambda f: not (f.is_relation and f.many_to_many)\n+        is_not_a_generic_relation = lambda f: not (f.is_relation and f.many_to_one)\n+        is_not_a_generic_foreign_key = lambda f: not (\n+            f.is_relation and f.one_to_many and not (hasattr(f.rel, 'to') and f.rel.to)\n+        )\n+        return make_immutable_fields_list(\n+            \"fields\",\n+            (f for f in self._get_fields(reverse=False) if\n+            is_not_an_m2m_field(f) and is_not_a_generic_relation(f)\n+            and is_not_a_generic_foreign_key(f))\n+        )\n \n     @cached_property\n     def concrete_fields(self):\n-        return [f for f in self.fields if f.column is not None]\n+        \"\"\"\n+        Returns a list of all concrete fields on the model and its parents.\n+\n+        Private API intended only to be used by Django itself; get_fields()\n+        combined with filtering of field properties is the public API for\n+        obtaining this field list.\n+        \"\"\"\n+        return make_immutable_fields_list(\n+            \"concrete_fields\", (f for f in self.fields if f.concrete)\n+        )\n \n     @cached_property\n     def local_concrete_fields(self):\n-        return [f for f in self.local_fields if f.column is not None]\n-\n-    def get_fields_with_model(self):\n         \"\"\"\n-        Returns a sequence of (field, model) pairs for all fields. The \"model\"\n-        element is None for fields on the current model. Mostly of use when\n-        constructing queries so that we know which model a field belongs to.\n+        Returns a list of all concrete fields on the model.\n+\n+        Private API intended only to be used by Django itself; get_fields()\n+        combined with filtering of field properties is the public API for\n+        obtaining this field list.\n         \"\"\"\n-        try:\n-            self._field_cache\n-        except AttributeError:\n-            self._fill_fields_cache()\n-        return self._field_cache\n+        return make_immutable_fields_list(\n+            \"local_concrete_fields\", (f for f in self.local_fields if f.concrete)\n+        )\n \n-    def get_concrete_fields_with_model(self):\n-        return [(field, model) for field, model in self.get_fields_with_model() if\n-                field.column is not None]\n+    @raise_deprecation(suggested_alternative=\"get_fields()\")\n+    def get_fields_with_model(self):\n+        return [self._map_model(f) for f in self.get_fields()]\n \n-    def _fill_fields_cache(self):\n-        cache = []\n-        for parent in self.parents:\n-            for field, model in parent._meta.get_fields_with_model():\n-                if model:\n-                    cache.append((field, model))\n-                else:\n-                    cache.append((field, parent))\n-        cache.extend((f, None) for f in self.local_fields)\n-        self._field_cache = tuple(cache)\n-        self._field_name_cache = [x for x, _ in cache]\n-\n-    def _many_to_many(self):\n-        try:\n-            self._m2m_cache\n-        except AttributeError:\n-            self._fill_m2m_cache()\n-        return list(self._m2m_cache)\n-    many_to_many = property(_many_to_many)\n+    @raise_deprecation(suggested_alternative=\"get_fields()\")\n+    def get_concrete_fields_with_model(self):\n+        return [self._map_model(f) for f in self.concrete_fields]\n \n-    def get_m2m_with_model(self):\n-        \"\"\"\n-        The many-to-many version of get_fields_with_model().\n+    @cached_property\n+    def many_to_many(self):\n         \"\"\"\n-        try:\n-            self._m2m_cache\n-        except AttributeError:\n-            self._fill_m2m_cache()\n-        return list(six.iteritems(self._m2m_cache))\n+        Returns a list of all many to many fields on the model and its parents.\n \n-    def _fill_m2m_cache(self):\n-        cache = OrderedDict()\n-        for parent in self.parents:\n-            for field, model in parent._meta.get_m2m_with_model():\n-                if model:\n-                    cache[field] = model\n-                else:\n-                    cache[field] = parent\n-        for field in self.local_many_to_many:\n-            cache[field] = None\n-        self._m2m_cache = cache\n-\n-    def get_field(self, name, many_to_many=True):\n+        Private API intended only to be used by Django itself; get_fields()\n+        combined with filtering of field properties is the public API for\n+        obtaining this list.\n         \"\"\"\n-        Returns the requested field by name. Raises FieldDoesNotExist on error.\n-        \"\"\"\n-        to_search = (self.fields + self.many_to_many) if many_to_many else self.fields\n-        for f in to_search:\n-            if f.name == name:\n-                return f\n-        raise FieldDoesNotExist('%s has no field named %r' % (self.object_name, name))\n+        return make_immutable_fields_list(\n+            \"many_to_many\",\n+            (f for f in self._get_fields(reverse=False)\n+            if f.is_relation and f.many_to_many)\n+        )\n \n-    def get_field_by_name(self, name):\n+    @cached_property\n+    def related_objects(self):\n         \"\"\"\n-        Returns the (field_object, model, direct, m2m), where field_object is\n-        the Field instance for the given name, model is the model containing\n-        this field (None for local fields), direct is True if the field exists\n-        on this model, and m2m is True for many-to-many relations. When\n-        'direct' is False, 'field_object' is the corresponding ForeignObjectRel\n-        for this field (since the field doesn't have an instance associated\n-        with it).\n-\n-        Uses a cache internally, so after the first access, this is very fast.\n+        Returns all related objects pointing to the current model. The related\n+        objects can come from a one-to-one, one-to-many, or many-to-many field\n+        relation type.\n+\n+        Private API intended only to be used by Django itself; get_fields()\n+        combined with filtering of field properties is the public API for\n+        obtaining this field list.\n         \"\"\"\n-        try:\n+        all_related_fields = self._get_fields(forward=False, reverse=True, include_hidden=True)\n+        return make_immutable_fields_list(\n+            \"related_objects\",\n+            (obj for obj in all_related_fields\n+            if not obj.hidden or obj.field.many_to_many)\n+        )\n+\n+    @raise_deprecation(suggested_alternative=\"get_fields()\")\n+    def get_m2m_with_model(self):\n+        return [self._map_model(f) for f in self.many_to_many]\n+\n+    @cached_property\n+    def _forward_fields_map(self):\n+        res = {}\n+        # call get_fields() with export_ordered_set=True in order to have a\n+        # field_instance -> names map\n+        fields = self._get_fields(reverse=False)\n+        for field in fields:\n+            res[field.name] = field\n+            # Due to the way Django's internals work, get_field() should also\n+            # be able to fetch a field by attname. In the case of a concrete\n+            # field with relation, includes the *_id name too\n             try:\n-                return self._name_map[name]\n+                res[field.attname] = field\n             except AttributeError:\n-                cache = self.init_name_map()\n-                return cache[name]\n-        except KeyError:\n-            raise FieldDoesNotExist('%s has no field named %r'\n-                    % (self.object_name, name))\n+                pass\n+        return res\n \n-    def get_all_field_names(self):\n+    @cached_property\n+    def fields_map(self):\n+        res = {}\n+        fields = self._get_fields(forward=False, include_hidden=True)\n+        for field in fields:\n+            res[field.name] = field\n+            # Due to the way Django's internals work, get_field() should also\n+            # be able to fetch a field by attname. In the case of a concrete\n+            # field with relation, includes the *_id name too\n+            try:\n+                res[field.attname] = field\n+            except AttributeError:\n+                pass\n+        return res\n+\n+    def get_field(self, field_name, many_to_many=None):\n         \"\"\"\n-        Returns a list of all field names that are possible for this model\n-        (including reverse relation names). This is used for pretty printing\n-        debugging output (a list of choices), so any internal-only field names\n-        are not included.\n+        Returns a field instance given a field name. The field can be either a\n+        forward or reverse field, unless many_to_many is specified; if it is,\n+        only forward fields will be returned.\n+\n+        The many_to_many argument exists for backwards compatibility reasons;\n+        it has been deprecated and will be removed in Django 2.0.\n         \"\"\"\n+        m2m_in_kwargs = many_to_many is not None\n+        if m2m_in_kwargs:\n+            # Always throw a warning if many_to_many is used regardless of\n+            # whether it alters the return type or not.\n+            warnings.warn(\n+                \"The 'many_to_many' argument on get_field() is deprecated; \"\n+                \"use a filter on field.many_to_many instead.\",\n+                RemovedInDjango20Warning\n+            )\n+\n         try:\n-            cache = self._name_map\n-        except AttributeError:\n-            cache = self.init_name_map()\n-        names = sorted(cache.keys())\n-        # Internal-only names end with \"+\" (symmetrical m2m related names being\n-        # the main example). Trim them.\n-        return [val for val in names if not val.endswith('+')]\n-\n-    def init_name_map(self):\n-        \"\"\"\n-        Initialises the field name -> field object mapping.\n-        \"\"\"\n-        cache = {}\n-        # We intentionally handle related m2m objects first so that symmetrical\n-        # m2m accessor names can be overridden, if necessary.\n-        for f, model in self.get_all_related_m2m_objects_with_model():\n-            cache[f.field.related_query_name()] = (f, model, False, True)\n-        for f, model in self.get_all_related_objects_with_model():\n-            cache[f.field.related_query_name()] = (f, model, False, False)\n-        for f, model in self.get_m2m_with_model():\n-            cache[f.name] = cache[f.attname] = (f, model, True, True)\n-        for f, model in self.get_fields_with_model():\n-            cache[f.name] = cache[f.attname] = (f, model, True, False)\n-        for f in self.virtual_fields:\n-            if f.rel:\n-                cache[f.name] = cache[f.attname] = (\n-                    f, None if f.model == self.model else f.model, True, False)\n-        if apps.ready:\n-            self._name_map = cache\n-        return cache\n+            # In order to avoid premature loading of the relation tree\n+            # (expensive) we prefer checking if the field is a forward field.\n+            field = self._forward_fields_map[field_name]\n+\n+            if many_to_many is False and field.many_to_many:\n+                raise FieldDoesNotExist(\n+                    '%s has no field named %r' % (self.object_name, field_name)\n+                )\n+\n+            return field\n+        except KeyError:\n+            # If the app registry is not ready, reverse fields are\n+            # unavailable, therefore we throw a FieldDoesNotExist exception.\n+            if not self.apps.ready:\n+                raise FieldDoesNotExist(\n+                    \"%s has no field named %r. The app cache isn't \"\n+                    \"ready yet, so if this is a forward field, it won't \"\n+                    \"be available yet.\" % (self.object_name, field_name)\n+                )\n+\n+        try:\n+            if m2m_in_kwargs:\n+                # Previous API does not allow searching reverse fields.\n+                raise FieldDoesNotExist('%s has no field named %r' % (self.object_name, field_name))\n \n+            # Retrieve field instance by name from cached or just-computed\n+            # field map.\n+            return self.fields_map[field_name]\n+        except KeyError:\n+            raise FieldDoesNotExist('%s has no field named %r' % (self.object_name, field_name))\n+\n+    @raise_deprecation(suggested_alternative=\"get_field()\")\n+    def get_field_by_name(self, name):\n+        return self._map_model_details(self.get_field(name))\n+\n+    @raise_deprecation(suggested_alternative=\"get_fields()\")\n+    def get_all_field_names(self):\n+        names = set()\n+        fields = self.get_fields()\n+        for field in fields:\n+            # For backwards compatibility GenericForeignKey should not be\n+            # included in the results.\n+            if field.is_relation and field.one_to_many and field.related_model is None:\n+                continue\n+\n+            names.add(field.name)\n+            if hasattr(field, 'attname'):\n+                names.add(field.attname)\n+        return list(names)\n+\n+    @raise_deprecation(suggested_alternative=\"get_fields()\")\n     def get_all_related_objects(self, local_only=False, include_hidden=False,\n                                 include_proxy_eq=False):\n-        return [k for k, v in self.get_all_related_objects_with_model(\n-                local_only=local_only, include_hidden=include_hidden,\n-                include_proxy_eq=include_proxy_eq)]\n \n-    def get_all_related_objects_with_model(self, local_only=False,\n-                                           include_hidden=False,\n+        include_parents = local_only is False\n+        fields = self._get_fields(\n+            forward=False, reverse=True,\n+            include_parents=include_parents,\n+            include_hidden=include_hidden,\n+        )\n+        fields = (obj for obj in fields if not isinstance(obj.field, ManyToManyField))\n+\n+        if include_proxy_eq:\n+            children = chain.from_iterable(c._relation_tree\n+                                           for c in self.concrete_model._meta.proxied_children\n+                                           if c is not self)\n+            relations = (f.rel for f in children\n+                         if include_hidden or not f.rel.field.rel.is_hidden())\n+            fields = chain(fields, relations)\n+        return list(fields)\n+\n+    @raise_deprecation(suggested_alternative=\"get_fields()\")\n+    def get_all_related_objects_with_model(self, local_only=False, include_hidden=False,\n                                            include_proxy_eq=False):\n-        \"\"\"\n-        Returns a list of (related-object, model) pairs. Similar to\n-        get_fields_with_model().\n-        \"\"\"\n-        try:\n-            self._related_objects_cache\n-        except AttributeError:\n-            self._fill_related_objects_cache()\n-        predicates = []\n-        if local_only:\n-            predicates.append(lambda k, v: not v)\n-        if not include_hidden:\n-            predicates.append(lambda k, v: not k.field.rel.is_hidden())\n-        cache = (self._related_objects_proxy_cache if include_proxy_eq\n-                 else self._related_objects_cache)\n-        return [t for t in cache.items() if all(p(*t) for p in predicates)]\n-\n-    def _fill_related_objects_cache(self):\n-        cache = OrderedDict()\n-        parent_list = self.get_parent_list()\n-        for parent in self.parents:\n-            for obj, model in parent._meta.get_all_related_objects_with_model(include_hidden=True):\n-                if (obj.field.creation_counter < 0 or obj.field.rel.parent_link) and obj.model not in parent_list:\n-                    continue\n-                if not model:\n-                    cache[obj] = parent\n-                else:\n-                    cache[obj] = model\n-        # Collect also objects which are in relation to some proxy child/parent of self.\n-        proxy_cache = cache.copy()\n-        for klass in self.apps.get_models(include_auto_created=True):\n-            if not klass._meta.swapped:\n-                for f in klass._meta.local_fields + klass._meta.virtual_fields:\n-                    if (hasattr(f, 'rel') and f.rel and not isinstance(f.rel.to, six.string_types)\n-                            and f.generate_reverse_relation):\n-                        if self == f.rel.to._meta:\n-                            cache[f.rel] = None\n-                            proxy_cache[f.rel] = None\n-                        elif self.concrete_model == f.rel.to._meta.concrete_model:\n-                            proxy_cache[f.rel] = None\n-        self._related_objects_cache = cache\n-        self._related_objects_proxy_cache = proxy_cache\n+        return [\n+            self._map_model(f) for f in self.get_all_related_objects(\n+                local_only=local_only,\n+                include_hidden=include_hidden,\n+                include_proxy_eq=include_proxy_eq,\n+            )\n+        ]\n \n+    @raise_deprecation(suggested_alternative=\"get_fields()\")\n     def get_all_related_many_to_many_objects(self, local_only=False):\n-        try:\n-            cache = self._related_many_to_many_cache\n-        except AttributeError:\n-            cache = self._fill_related_many_to_many_cache()\n-        if local_only:\n-            return [k for k, v in cache.items() if not v]\n-        return list(cache)\n+        fields = self._get_fields(\n+            forward=False, reverse=True,\n+            include_parents=local_only is not True, include_hidden=True\n+        )\n+        return [obj for obj in fields if isinstance(obj.field, ManyToManyField)]\n \n+    @raise_deprecation(suggested_alternative=\"get_fields()\")\n     def get_all_related_m2m_objects_with_model(self):\n-        \"\"\"\n-        Returns a list of (related-m2m-object, model) pairs. Similar to\n-        get_fields_with_model().\n-        \"\"\"\n-        try:\n-            cache = self._related_many_to_many_cache\n-        except AttributeError:\n-            cache = self._fill_related_many_to_many_cache()\n-        return list(six.iteritems(cache))\n-\n-    def _fill_related_many_to_many_cache(self):\n-        cache = OrderedDict()\n-        parent_list = self.get_parent_list()\n-        for parent in self.parents:\n-            for obj, model in parent._meta.get_all_related_m2m_objects_with_model():\n-                if obj.field.creation_counter < 0 and obj.model not in parent_list:\n-                    continue\n-                if not model:\n-                    cache[obj] = parent\n-                else:\n-                    cache[obj] = model\n-        for klass in self.apps.get_models():\n-            if not klass._meta.swapped:\n-                for f in klass._meta.local_many_to_many:\n-                    if (f.rel\n-                            and not isinstance(f.rel.to, six.string_types)\n-                            and self == f.rel.to._meta):\n-                        cache[f.rel] = None\n-        if apps.ready:\n-            self._related_many_to_many_cache = cache\n-        return cache\n+        fields = self._get_fields(forward=False, reverse=True, include_hidden=True)\n+        return [self._map_model(obj) for obj in fields if isinstance(obj.field, ManyToManyField)]\n \n     def get_base_chain(self, model):\n         \"\"\"\n@@ -605,3 +665,173 @@ def get_ancestor_link(self, ancestor):\n                 # of the chain to the ancestor is that parent\n                 # links\n                 return self.parents[parent] or parent_link\n+\n+    def _populate_directed_relation_graph(self):\n+        \"\"\"\n+        This method is used by each model to find its reverse objects. As this\n+        method is very expensive and is accessed frequently (it looks up every\n+        field in a model, in every app), it is computed on first access and then\n+        is set as a property on every model.\n+        \"\"\"\n+        related_objects_graph = defaultdict(list)\n+\n+        all_models = self.apps.get_models(include_auto_created=True)\n+        for model in all_models:\n+            fields_with_relations = (\n+                f for f in model._meta._get_fields(reverse=False)\n+                if f.is_relation and f.related_model is not None\n+            )\n+            if model._meta.auto_created:\n+                fields_with_relations = (\n+                    f for f in fields_with_relations\n+                    if not f.many_to_many\n+                )\n+\n+            for f in fields_with_relations:\n+                if not isinstance(f.rel.to, six.string_types):\n+                    # Set options_instance -> field\n+                    related_objects_graph[f.rel.to._meta].append(f)\n+\n+        for model in all_models:\n+            # Set the relation_tree using the internal __dict__. In this way\n+            # we avoid calling the cached property. In attribute lookup,\n+            # __dict__ takes precedence over a data descriptor (such as\n+            # @cached_property). This means that the _meta._relation_tree is\n+            # only called if related_objects is not in __dict__.\n+            related_objects = related_objects_graph[model._meta]\n+\n+            # If related_objects are empty, it makes sense to set\n+            # EMPTY_RELATION_TREE. This will avoid allocating multiple empty\n+            # relation trees.\n+            relation_tree = EMPTY_RELATION_TREE\n+            if related_objects:\n+                relation_tree = related_objects\n+            model._meta.__dict__['_relation_tree'] = relation_tree\n+\n+    @cached_property\n+    def _relation_tree(self):\n+        # If cache is not present, populate the cache\n+        self._populate_directed_relation_graph()\n+        # It may happen, often when the registry is not ready, that a not yet\n+        # registered model is queried. In this very rare case we simply return\n+        # an EMPTY_RELATION_TREE. When the registry will be ready, cache will\n+        # be flushed and this model will be computed properly.\n+        return self.__dict__.get('_relation_tree', EMPTY_RELATION_TREE)\n+\n+    def _expire_cache(self, forward=True, reverse=True):\n+        # This method is usually called by apps.cache_clear(), when the\n+        # registry is finalized, or when a new field is added.\n+        properties_to_expire = []\n+        if forward:\n+            properties_to_expire.extend(self.FORWARD_PROPERTIES)\n+        if reverse and not self.abstract:\n+            properties_to_expire.extend(self.REVERSE_PROPERTIES)\n+\n+        for cache_key in properties_to_expire:\n+            try:\n+                delattr(self, cache_key)\n+            except AttributeError:\n+                pass\n+\n+        self._get_fields_cache = {}\n+\n+    def get_fields(self, include_parents=True, include_hidden=False):\n+        \"\"\"\n+        Returns a list of fields associated to the model. By default will only\n+        return forward fields. This can be changed by enabling or disabling\n+        field types using the parameters:\n+\n+        - include_parents: include fields derived from inheritance\n+        - include_hidden:  include fields that have a related_name that\n+                           starts with a \"+\"\n+        \"\"\"\n+        return self._get_fields(include_parents=include_parents, include_hidden=include_hidden)\n+\n+    def _get_fields(self, forward=True, reverse=True, include_parents=True, include_hidden=False,\n+                    export_ordered_set=False):\n+        # This helper function is used to allow recursion in ``get_fields()``\n+        # implementation and to provide a fast way for Django's internals to\n+        # access specific subsets of fields.\n+\n+        # Creates a cache key composed of all arguments\n+        cache_key = (forward, reverse, include_parents, include_hidden, export_ordered_set)\n+        try:\n+            # In order to avoid list manipulation. Always return a shallow copy\n+            # of the results.\n+            return self._get_fields_cache[cache_key]\n+        except KeyError:\n+            pass\n+\n+        # Using an OrderedDict preserves the order of insertion. This is\n+        # important when displaying a ModelForm or the contrib.admin panel\n+        # and no specific ordering is provided.\n+        fields = OrderedDict()\n+        options = {\n+            'include_parents': include_parents,\n+            'include_hidden': include_hidden,\n+            'export_ordered_set': True,\n+        }\n+\n+        # Abstract models cannot hold reverse fields.\n+        if reverse and not self.abstract:\n+            if include_parents:\n+                parent_list = self.get_parent_list()\n+                # Recursively call _get_fields() on each parent, with the same\n+                # options provided in this call.\n+                for parent in self.parents:\n+                    for obj, _ in six.iteritems(parent._meta._get_fields(forward=False, **options)):\n+                        if obj.many_to_many:\n+                            # In order for a reverse ManyToManyRel object to be\n+                            # valid, its creation counter must be > 0 and must\n+                            # be in the parent list.\n+                            if not (obj.field.creation_counter < 0 and obj.related_model not in parent_list):\n+                                fields[obj] = True\n+\n+                        elif not ((obj.field.creation_counter < 0 or obj.field.rel.parent_link)\n+                                  and obj.related_model not in parent_list):\n+                            fields[obj] = True\n+\n+            # Tree is computed once and cached until the app cache is expired.\n+            # It is composed of a list of fields pointing to the current model\n+            # from other models. If the model is a proxy model, then we also\n+            # add the concrete model.\n+            all_fields = (\n+                self._relation_tree if not self.proxy else\n+                chain(self._relation_tree, self.concrete_model._meta._relation_tree)\n+            )\n+\n+            # Pull out all related objects from forward fields\n+            for field in (f.rel for f in all_fields):\n+                # If hidden fields should be included or the relation is not\n+                # intentionally hidden, add to the fields dict.\n+                if include_hidden or not field.hidden:\n+                    fields[field] = True\n+        if forward:\n+            if include_parents:\n+                for parent in self.parents:\n+                    # Add the forward fields of each parent.\n+                    fields.update(parent._meta._get_fields(reverse=False, **options))\n+            fields.update(\n+                (field, True,)\n+                for field in chain(self.local_fields, self.local_many_to_many)\n+            )\n+\n+        if not export_ordered_set:\n+            # By default, fields contains field instances as keys and all\n+            # possible names if the field instance as values. When\n+            # _get_fields() is called, we only want to return field instances,\n+            # so we just preserve the keys.\n+            fields = list(fields.keys())\n+\n+            # Virtual fields are not inheritable, therefore they are inserted\n+            # only when the recursive _get_fields() call comes to an end.\n+            if forward:\n+                fields.extend(self.virtual_fields)\n+            fields = make_immutable_fields_list(\"get_fields()\", fields)\n+\n+        # Store result into cache for later access\n+        self._get_fields_cache[cache_key] = fields\n+\n+        # In order to avoid list manipulation. Always\n+        # return a shallow copy of the results\n+        return fields\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 318e3ecf846f..7a447f031311 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -252,9 +252,8 @@ def iterator(self):\n         # If only/defer clauses have been specified,\n         # build the list of fields that are to be loaded.\n         if only_load:\n-            for field, model in self.model._meta.get_concrete_fields_with_model():\n-                if model is None:\n-                    model = self.model\n+            for field in self.model._meta.concrete_fields:\n+                model = field.model._meta.model\n                 try:\n                     if field.name in only_load[model]:\n                         # Add a field that has been explicitly included\n@@ -818,7 +817,7 @@ def annotate(self, *args, **kwargs):\n         obj = self._clone()\n         names = getattr(self, '_fields', None)\n         if names is None:\n-            names = set(self.model._meta.get_all_field_names())\n+            names = {f.name for f in self.model._meta.get_fields()}\n \n         # Add the annotations to the query\n         for alias, annotation in annotations.items():\n@@ -1329,7 +1328,8 @@ def get_klass_info(klass, max_depth=0, cur_depth=0, requested=None,\n         skip = set()\n         init_list = []\n         # Build the list of fields that *haven't* been requested\n-        for field, model in klass._meta.get_concrete_fields_with_model():\n+        for field in klass._meta.concrete_fields:\n+            model = field.model._meta.concrete_model\n             if from_parent and model and issubclass(from_parent, model):\n                 # Avoid loading fields already loaded for parent model for\n                 # child models.\n@@ -1381,18 +1381,19 @@ def get_klass_info(klass, max_depth=0, cur_depth=0, requested=None,\n \n     reverse_related_fields = []\n     if restricted:\n-        for o in klass._meta.get_all_related_objects():\n+        for o in klass._meta.related_objects:\n             if o.field.unique and select_related_descend(o.field, restricted, requested,\n-                                                         only_load.get(o.model), reverse=True):\n+                                                         only_load.get(o.related_model), reverse=True):\n                 next = requested[o.field.related_query_name()]\n-                parent = klass if issubclass(o.model, klass) else None\n-                klass_info = get_klass_info(o.model, max_depth=max_depth, cur_depth=cur_depth + 1,\n+                parent = klass if issubclass(o.related_model, klass) else None\n+                klass_info = get_klass_info(o.related_model, max_depth=max_depth, cur_depth=cur_depth + 1,\n                                             requested=next, only_load=only_load, from_parent=parent)\n                 reverse_related_fields.append((o.field, klass_info))\n     if field_names:\n         pk_idx = field_names.index(klass._meta.pk.attname)\n     else:\n-        pk_idx = klass._meta.pk_index()\n+        meta = klass._meta\n+        pk_idx = meta.concrete_fields.index(meta.pk)\n \n     return klass, field_names, field_count, related_fields, reverse_related_fields, pk_idx\n \n@@ -1485,7 +1486,10 @@ def get_cached_row(row, index_start, using, klass_info, offset=0,\n     for f, klass_info in reverse_related_fields:\n         # Transfer data from this object to childs.\n         parent_data = []\n-        for rel_field, rel_model in klass_info[0]._meta.get_fields_with_model():\n+        for rel_field in klass_info[0]._meta.fields:\n+            rel_model = rel_field.model._meta.concrete_model\n+            if rel_model == klass_info[0]._meta.model:\n+                rel_model = None\n             if rel_model is not None and isinstance(obj, rel_model):\n                 parent_data.append((rel_field, getattr(obj, rel_field.attname)))\n         # Recursively retrieve the data for the related object\ndiff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex 69bc878caa22..e8b6cfb8c19b 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -109,7 +109,7 @@ def __get__(self, instance, owner):\n             # self.field_name is the attname of the field, but only() takes the\n             # actual name, so we need to translate it here.\n             try:\n-                f = opts.get_field_by_name(self.field_name)[0]\n+                f = opts.get_field(self.field_name)\n             except FieldDoesNotExist:\n                 f = [f for f in opts.fields if f.attname == self.field_name][0]\n             name = f.name\n@@ -136,7 +136,7 @@ def _check_parent_chain(self, instance, name):\n         field is a primary key field.\n         \"\"\"\n         opts = instance._meta\n-        f = opts.get_field_by_name(name)[0]\n+        f = opts.get_field(name)\n         link_field = opts.get_ancestor_link(f.model)\n         if f.primary_key and f != link_field:\n             return getattr(instance, link_field.attname)\ndiff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex e8948cb9e1eb..1c0b99e897dd 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -298,7 +298,12 @@ def get_default_columns(self, with_aliases=False, col_aliases=None,\n         # be used by local fields.\n         seen_models = {None: start_alias}\n \n-        for field, model in opts.get_concrete_fields_with_model():\n+        for field in opts.concrete_fields:\n+            model = field.model._meta.concrete_model\n+            # A proxy model will have a different model and concrete_model. We\n+            # will assign None if the field belongs to this model.\n+            if model == opts.model:\n+                model = None\n             if from_parent and model is not None and issubclass(from_parent, model):\n                 # Avoid loading data for already loaded parents.\n                 continue\n@@ -601,10 +606,10 @@ def fill_related_selections(self, opts=None, root_alias=None, cur_depth=1,\n         connections to the root model).\n         \"\"\"\n         def _get_field_choices():\n-            direct_choices = (f.name for (f, _) in opts.get_fields_with_model() if f.rel)\n+            direct_choices = (f.name for f in opts.fields if f.is_relation)\n             reverse_choices = (\n                 f.field.related_query_name()\n-                for f in opts.get_all_related_objects() if f.field.unique\n+                for f in opts.related_objects if f.field.unique\n             )\n             return chain(direct_choices, reverse_choices)\n \n@@ -628,12 +633,13 @@ def _get_field_choices():\n             else:\n                 restricted = False\n \n-        for f, model in opts.get_fields_with_model():\n+        for f in opts.fields:\n+            field_model = f.model._meta.concrete_model\n             fields_found.add(f.name)\n \n             if restricted:\n                 next = requested.get(f.name, {})\n-                if not f.rel:\n+                if not f.is_relation:\n                     # If a non-related field is used like a relation,\n                     # or if a single non-relational field is given.\n                     if next or (cur_depth == 1 and f.name in requested):\n@@ -647,10 +653,6 @@ def _get_field_choices():\n             else:\n                 next = False\n \n-            # The get_fields_with_model() returns None for fields that live\n-            # in the field's local model. So, for those fields we want to use\n-            # the f.model - that is the field's local model.\n-            field_model = model or f.model\n             if not select_related_descend(f, restricted, requested,\n                                           only_load.get(field_model)):\n                 continue\n@@ -666,9 +668,9 @@ def _get_field_choices():\n \n         if restricted:\n             related_fields = [\n-                (o.field, o.model)\n-                for o in opts.get_all_related_objects()\n-                if o.field.unique\n+                (o.field, o.related_model)\n+                for o in opts.related_objects\n+                if o.field.unique and not o.many_to_many\n             ]\n             for f, model in related_fields:\n                 if not select_related_descend(f, restricted, requested,\n@@ -760,7 +762,7 @@ def results_iter(self):\n                     if self.query.select:\n                         fields = [f.field for f in self.query.select]\n                     elif self.query.default_cols:\n-                        fields = self.query.get_meta().concrete_fields\n+                        fields = list(self.query.get_meta().concrete_fields)\n                     else:\n                         fields = []\n \ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex eb1641909156..1d1dbd8162c0 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -11,6 +11,7 @@\n \n from collections import Mapping, OrderedDict\n import copy\n+from itertools import chain\n import warnings\n \n from django.core.exceptions import FieldDoesNotExist, FieldError\n@@ -33,6 +34,13 @@\n __all__ = ['Query', 'RawQuery']\n \n \n+def get_field_names_from_opts(opts):\n+    return set(chain.from_iterable(\n+        (f.name, f.attname) if f.concrete else (f.name,)\n+        for f in opts.get_fields()\n+    ))\n+\n+\n class RawQuery(object):\n     \"\"\"\n     A single raw SQL query\n@@ -593,9 +601,9 @@ def deferred_to_data(self, target, callback):\n             opts = orig_opts\n             for name in parts[:-1]:\n                 old_model = cur_model\n-                source = opts.get_field_by_name(name)[0]\n+                source = opts.get_field(name)\n                 if is_reverse_o2o(source):\n-                    cur_model = source.model\n+                    cur_model = source.related_model\n                 else:\n                     cur_model = source.rel.to\n                 opts = cur_model._meta\n@@ -605,8 +613,11 @@ def deferred_to_data(self, target, callback):\n                 if not is_reverse_o2o(source):\n                     must_include[old_model].add(source)\n                 add_to_dict(must_include, cur_model, opts.pk)\n-            field, model, _, _ = opts.get_field_by_name(parts[-1])\n-            if model is None:\n+            field = opts.get_field(parts[-1])\n+            is_reverse_object = field.auto_created and not field.concrete\n+            model = field.related_model if is_reverse_object else field.model\n+            model = model._meta.concrete_model\n+            if model == opts.model:\n                 model = cur_model\n             if not is_reverse_o2o(field):\n                 add_to_dict(seen, model, field)\n@@ -618,10 +629,11 @@ def deferred_to_data(self, target, callback):\n             # models.\n             workset = {}\n             for model, values in six.iteritems(seen):\n-                for field, m in model._meta.get_fields_with_model():\n+                for field in model._meta.fields:\n                     if field in values:\n                         continue\n-                    add_to_dict(workset, m or model, field)\n+                    m = field.model._meta.concrete_model\n+                    add_to_dict(workset, m, field)\n             for model, values in six.iteritems(must_include):\n                 # If we haven't included a model in workset, we don't add the\n                 # corresponding must_include fields for that model, since an\n@@ -934,8 +946,9 @@ def setup_inherited_models(self):\n         root_alias = self.tables[0]\n         seen = {None: root_alias}\n \n-        for field, model in opts.get_fields_with_model():\n-            if model not in seen:\n+        for field in opts.fields:\n+            model = field.model._meta.concrete_model\n+            if model is not opts.model and model not in seen:\n                 self.join_parent_model(opts, model, root_alias, seen)\n         self.included_inherited_models = seen\n \n@@ -1368,7 +1381,19 @@ def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):\n             if name == 'pk':\n                 name = opts.pk.name\n             try:\n-                field, model, _, _ = opts.get_field_by_name(name)\n+                field = opts.get_field(name)\n+\n+                # Fields that contain one-to-many relations with a generic\n+                # model (like a GenericForeignKey) cannot generate reverse\n+                # relations and therefore cannot be used for reverse querying.\n+                if field.is_relation and not field.related_model:\n+                    raise FieldError(\n+                        \"Field %r does not generate an automatic reverse \"\n+                        \"relation and therefore cannot be used for reverse \"\n+                        \"querying. If it is a GenericForeignKey, consider \"\n+                        \"adding a GenericRelation.\" % name\n+                    )\n+                model = field.model._meta.concrete_model\n             except FieldDoesNotExist:\n                 # is it an annotation?\n                 if self._annotations and name in self._annotations:\n@@ -1382,14 +1407,15 @@ def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):\n                 # one step.\n                 pos -= 1\n                 if pos == -1 or fail_on_missing:\n-                    available = opts.get_all_field_names() + list(self.annotation_select)\n+                    field_names = list(get_field_names_from_opts(opts))\n+                    available = sorted(field_names + list(self.annotation_select))\n                     raise FieldError(\"Cannot resolve keyword %r into field. \"\n                                      \"Choices are: %s\" % (name, \", \".join(available)))\n                 break\n             # Check if we need any joins for concrete inheritance cases (the\n             # field lives in parent, but we are currently in one of its\n             # children)\n-            if model:\n+            if model is not opts.model:\n                 # The field lives on a base class of the current model.\n                 # Skip the chain of proxy to the concrete proxied model\n                 proxied_model = opts.concrete_model\n@@ -1432,7 +1458,7 @@ def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):\n         return path, final_field, targets, names[pos + 1:]\n \n     def raise_field_error(self, opts, name):\n-        available = opts.get_all_field_names() + list(self.annotation_select)\n+        available = list(get_field_names_from_opts(opts)) + list(self.annotation_select)\n         raise FieldError(\"Cannot resolve keyword %r into field. \"\n                          \"Choices are: %s\" % (name, \", \".join(available)))\n \n@@ -1693,7 +1719,7 @@ def add_fields(self, field_names, allow_m2m=True):\n                 # from the model on which the lookup failed.\n                 raise\n             else:\n-                names = sorted(opts.get_all_field_names() + list(self.extra)\n+                names = sorted(list(get_field_names_from_opts(opts)) + list(self.extra)\n                                + list(self.annotation_select))\n                 raise FieldError(\"Cannot resolve keyword %r into field. \"\n                                  \"Choices are: %s\" % (name, \", \".join(names)))\ndiff --git a/django/db/models/sql/subqueries.py b/django/db/models/sql/subqueries.py\nindex 12bde13bf348..bae9f11c2359 100644\n--- a/django/db/models/sql/subqueries.py\n+++ b/django/db/models/sql/subqueries.py\n@@ -120,13 +120,15 @@ def add_update_values(self, values):\n         \"\"\"\n         values_seq = []\n         for name, val in six.iteritems(values):\n-            field, model, direct, m2m = self.get_meta().get_field_by_name(name)\n-            if not direct or m2m:\n+            field = self.get_meta().get_field(name)\n+            direct = not (field.auto_created and not field.concrete) or not field.concrete\n+            model = field.model._meta.concrete_model\n+            if not direct or (field.is_relation and field.many_to_many):\n                 raise FieldError(\n                     'Cannot update model field %r (only non-relations and '\n                     'foreign keys permitted).' % field\n                 )\n-            if model:\n+            if model is not self.get_meta().model:\n                 self.add_related_update(model, field, val)\n                 continue\n             values_seq.append((field, model, val))\ndiff --git a/django/forms/models.py b/django/forms/models.py\nindex c57c8af0b964..443d0559a6f5 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -6,6 +6,7 @@\n from __future__ import unicode_literals\n \n from collections import OrderedDict\n+from itertools import chain\n import warnings\n \n from django.core.exceptions import (\n@@ -89,7 +90,7 @@ def save_m2m():\n         # Note that for historical reasons we want to include also\n         # virtual_fields here. (GenericRelation was previously a fake\n         # m2m field).\n-        for f in opts.many_to_many + opts.virtual_fields:\n+        for f in chain(opts.many_to_many, opts.virtual_fields):\n             if not hasattr(f, 'save_form_data'):\n                 continue\n             if fields and f.name not in fields:\n@@ -127,7 +128,7 @@ def model_to_dict(instance, fields=None, exclude=None):\n     from django.db.models.fields.related import ManyToManyField\n     opts = instance._meta\n     data = {}\n-    for f in opts.concrete_fields + opts.virtual_fields + opts.many_to_many:\n+    for f in chain(opts.concrete_fields, opts.virtual_fields, opts.many_to_many):\n         if not getattr(f, 'editable', False):\n             continue\n         if fields and f.name not in fields:\n@@ -186,7 +187,7 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n     from django.db.models.fields import Field as ModelField\n     sortable_virtual_fields = [f for f in opts.virtual_fields\n                                if isinstance(f, ModelField)]\n-    for f in sorted(opts.concrete_fields + sortable_virtual_fields + opts.many_to_many):\n+    for f in sorted(chain(opts.concrete_fields, sortable_virtual_fields, opts.many_to_many)):\n         if not getattr(f, 'editable', False):\n             continue\n         if fields is not None and f.name not in fields:\ndiff --git a/docs/howto/custom-model-fields.txt b/docs/howto/custom-model-fields.txt\nindex 568831523c52..647474222229 100644\n--- a/docs/howto/custom-model-fields.txt\n+++ b/docs/howto/custom-model-fields.txt\n@@ -217,9 +217,9 @@ The ``Field.__init__()`` method takes the following parameters:\n * :attr:`~django.db.models.Field.db_tablespace`: Only for index creation, if the\n   backend supports :doc:`tablespaces </topics/db/tablespaces>`. You can usually\n   ignore this option.\n-* ``auto_created``: ``True`` if the field was automatically created, as for the\n-  :class:`~django.db.models.OneToOneField` used by model inheritance. For\n-  advanced use only.\n+* :attr:`~django.db.models.Field.auto_created`: ``True`` if the field was\n+  automatically created, as for the :class:`~django.db.models.OneToOneField`\n+  used by model inheritance. For advanced use only.\n \n All of the options without an explanation in the above list have the same\n meaning they do for normal Django fields. See the :doc:`field documentation\ndiff --git a/docs/internals/deprecation.txt b/docs/internals/deprecation.txt\nindex b74f550ba866..e2c89d360b60 100644\n--- a/docs/internals/deprecation.txt\n+++ b/docs/internals/deprecation.txt\n@@ -56,6 +56,19 @@ details on these changes.\n \n * ``django.template.resolve_variable`` will be removed.\n \n+* The following private APIs will be removed from\n+  :class:`django.db.models.options.Options` (``Model._meta``):\n+\n+  * ``get_field_by_name()``\n+  * ``get_all_field_names()``\n+  * ``get_fields_with_model()``\n+  * ``get_concrete_fields_with_model()``\n+  * ``get_m2m_with_model()``\n+  * ``get_all_related_objects()``\n+  * ``get_all_related_objects_with_model()``\n+  * ``get_all_related_many_to_many_objects()``\n+  * ``get_all_related_m2m_objects_with_model()``\n+\n * The ``error_message`` argument of ``django.forms.RegexField`` will be removed.\n \n * The ``unordered_list`` filter will no longer support old style lists.\ndiff --git a/docs/ref/models/fields.txt b/docs/ref/models/fields.txt\nindex 35997801fb08..bc214fae00c4 100644\n--- a/docs/ref/models/fields.txt\n+++ b/docs/ref/models/fields.txt\n@@ -1790,3 +1790,95 @@ Field API reference\n \n         This method must be added to fields prior to 1.7 to migrate its data\n         using :doc:`/topics/migrations`.\n+\n+.. _model-field-attributes:\n+\n+=========================\n+Field attribute reference\n+=========================\n+\n+.. versionadded:: 1.8\n+\n+Every ``Field`` instance contains several attributes that allow\n+introspecting its behavior. Use these attributes instead of ``isinstance``\n+checks when you need to write code that depends on a field's functionality.\n+These attributes can be used together with the :ref:`Model._meta API\n+<model-meta-field-api>` to narrow down a search for specific field types.\n+Custom model fields should implement these flags.\n+\n+Attributes for fields\n+=====================\n+\n+.. attribute:: Field.auto_created\n+\n+     Boolean flag that indicates if the field was automatically created, such\n+     as the ``OneToOneField`` used by model inheritance.\n+\n+.. attribute:: Field.concrete\n+\n+    Boolean flag that indicates if the field has a database column associated\n+    with it.\n+\n+.. attribute:: Field.hidden\n+\n+    Boolean flag that indicates if a field is used to back another non-hidden\n+    field's functionality (e.g. the ``content_type`` and ``object_id`` fields\n+    that make up a ``GenericForeignKey``). The ``hidden`` flag is used to\n+    distinguish what constitutes the public subset of fields on the model from\n+    all the fields on the model.\n+\n+    .. note::\n+\n+        :meth:`Options.get_fields()\n+        <django.db.models.options.Options.get_fields()>`\n+        excludes hidden fields by default. Pass in ``include_hidden=True`` to\n+        return hidden fields in the results.\n+\n+.. attribute:: Field.is_relation\n+\n+    Boolean flag that indicates if a field contains references to one or\n+    more other models for its functionality (e.g. ``ForeignKey``,\n+    ``ManyToManyField``, ``OneToOneField``, etc.).\n+\n+.. attribute:: Field.model\n+\n+    Returns the model on which the field is defined. If a field is defined on\n+    a superclass of a model, ``model`` will refer to the superclass, not the\n+    class of the instance.\n+\n+Attributes for fields with relations\n+====================================\n+\n+These attributes are used to query for the cardinality and other details of a\n+relation. These attribute are present on all fields; however, they will only\n+have meaningful values if the field is a relation type\n+(:attr:`Field.is_relation=True <Field.is_relation>`).\n+\n+.. attribute:: Field.one_to_many\n+\n+    Boolean flag that is ``True`` if the field has a one-to-many relation, such\n+    as a ``ForeignKey``; ``False`` otherwise.\n+\n+.. attribute:: Field.one_to_one\n+\n+    Boolean flag that is ``True`` if the field has a one-to-one relation, such\n+    as a ``OneToOneField``; ``False`` otherwise.\n+\n+.. attribute:: Field.many_to_many\n+\n+    Boolean flag that is ``True`` if the field has a many-to-many relation;\n+    ``False`` otherwise. The only field included with Django where this is\n+    ``True`` is ``ManyToManyField``.\n+\n+.. attribute:: Field.many_to_one\n+\n+    Boolean flag that is ``True`` if the field has a many-to-one relation, such\n+    as a ``GenericRelation`` or the reverse of a ``ForeignKey``; ``False``\n+    otherwise.\n+\n+.. attribute:: Field.related_model\n+\n+    Points to the model the field relates to. For example, ``Author`` in\n+    ``ForeignKey(Author)``. If a field has a generic relation (such as a\n+    ``GenericForeignKey`` or a ``GenericRelation``) then ``related_model``\n+    will be ``None``.\ndiff --git a/docs/ref/models/index.txt b/docs/ref/models/index.txt\nindex d1d3680dd871..284743e7d09a 100644\n--- a/docs/ref/models/index.txt\n+++ b/docs/ref/models/index.txt\n@@ -8,6 +8,7 @@ Model API reference. For introductory material, see :doc:`/topics/db/models`.\n    :maxdepth: 1\n \n    fields\n+   meta\n    relations\n    class\n    options\ndiff --git a/docs/ref/models/meta.txt b/docs/ref/models/meta.txt\nnew file mode 100644\nindex 000000000000..c00888c79dea\n--- /dev/null\n+++ b/docs/ref/models/meta.txt\n@@ -0,0 +1,289 @@\n+===================\n+Model ``_meta`` API\n+===================\n+\n+.. module:: django.db.models.options\n+   :synopsis: Model meta-class layer\n+\n+.. class:: Options\n+\n+The model ``_meta`` API is at the core of the Django ORM. It enables other\n+parts of the system such as lookups, queries, forms, and the admin to\n+understand the capabilities of each model. The API is accessible through\n+the ``_meta`` attribute of each model class, which is an instance of an\n+``django.db.models.options.Options`` object.\n+\n+Methods that it provides can be used to:\n+\n+* Retrieve all field instances of a model\n+* Retrieve a single field instance of a model by name\n+\n+.. versionchanged:: 1.8\n+\n+    The Model ``_meta`` API has always existed as a Django internal, but\n+    wasn't formally documented and supported. As part of the effort to\n+    make this API public, some of the already existing API entry points\n+    have changed slightly. A :ref:`migration guide <migrating-old-meta-api>`\n+    has been provided to assist in converting your code to use the new,\n+    official API.\n+\n+.. _model-meta-field-api:\n+\n+Field access API\n+================\n+\n+Retrieving a single field instance of a model by name\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. method:: Options.get_field(field_name)\n+\n+    Returns the field instance given a name of a field.\n+\n+    ``field_name`` can be the name of a field on the model, a field\n+    on an abstract or inherited model, or a field defined on another\n+    model that points to the model. In the latter case, the ``field_name``\n+    will be the ``related_name`` defined by the user or the name automatically\n+    generated by Django itself.\n+\n+    :attr:`Hidden fields <django.db.models.Field.hidden>` cannot be retrieved\n+    by name.\n+\n+    If a field with the given name is not found a\n+    :class:`~django.core.exceptions.FieldDoesNotExist` exception will be\n+    raised.\n+\n+    .. code-block:: python\n+\n+        >>> from django.contrib.auth.models import User\n+\n+        # A field on the model\n+        >>> User._meta.get_field('username')\n+        <django.db.models.fields.CharField: username>\n+\n+        # A field from another model that has a relation with the current model\n+        >>> User._meta.get_field('logentry')\n+        <ManyToOneRel: admin.logentry>\n+\n+        # A non existent field\n+        >>> User._meta.get_field('does_not_exist')\n+        Traceback (most recent call last):\n+            ...\n+        FieldDoesNotExist: User has no field named 'does_not_exist'\n+\n+    .. deprecated:: 1.8\n+\n+        :meth:`Options.get_field()` previously accepted a ``many_to_many``\n+        parameter which could be set to ``False`` to avoid searching\n+        ``ManyToManyField``\\s. The old behavior has been preserved for\n+        backwards compatibility; however, the parameter and this behavior\n+        has been deprecated.\n+\n+        If you wish to filter out ``ManyToManyField``\\s, you can inspect the\n+        :attr:`Field.many_to_many <django.db.models.Field.many_to_many>`\n+        attribute after calling ``get_field()``.\n+\n+Retrieving all field instances of a model\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. method:: Options.get_fields(include_parents=True, include_hidden=False)\n+\n+    .. versionadded:: 1.8\n+\n+    Returns a tuple of fields associated with a model. ``get_fields()`` accepts\n+    two parameters that can be used to control which fields are returned:\n+\n+    ``include_parents``\n+        ``True`` by default. Recursively includes fields defined on parent\n+        classes. If set to ``False``, ``get_fields()`` will only search for\n+        fields declared directly on the current model. Fields from models that\n+        directly inherit from abstract models or proxy classes are considered\n+        to be local, not on the parent.\n+\n+    ``include_hidden``\n+        ``False`` by default. If set to ``True``, ``get_fields()`` will include\n+        fields that are used to back other field's functionality. This will\n+        also include any fields that have a ``related_name`` (such\n+        as :class:`~django.db.models.ManyToManyField`, or\n+        :class:`~django.db.models.ForeignKey`) that start with a \"+\".\n+\n+    .. code-block:: python\n+\n+        >>> from django.contrib.auth.models import User\n+        >>> User._meta.get_fields()\n+        (<ManyToOneRel: admin.logentry>,\n+         <django.db.models.fields.AutoField: id>,\n+         <django.db.models.fields.CharField: password>,\n+         <django.db.models.fields.DateTimeField: last_login>,\n+         <django.db.models.fields.BooleanField: is_superuser>,\n+         <django.db.models.fields.CharField: username>,\n+         <django.db.models.fields.CharField: first_name>,\n+         <django.db.models.fields.CharField: last_name>,\n+         <django.db.models.fields.EmailField: email>,\n+         <django.db.models.fields.BooleanField: is_staff>,\n+         <django.db.models.fields.BooleanField: is_active>,\n+         <django.db.models.fields.DateTimeField: date_joined>,\n+         <django.db.models.fields.related.ManyToManyField: groups>,\n+         <django.db.models.fields.related.ManyToManyField: user_permissions>)\n+\n+        # Also include hidden fields.\n+        >>> User._meta.get_fields(include_hidden=True)\n+        (<ManyToOneRel: auth.user_groups>,\n+         <ManyToOneRel: auth.user_user_permissions>,\n+         <ManyToOneRel: admin.logentry>,\n+         <django.db.models.fields.AutoField: id>,\n+         <django.db.models.fields.CharField: password>,\n+         <django.db.models.fields.DateTimeField: last_login>,\n+         <django.db.models.fields.BooleanField: is_superuser>,\n+         <django.db.models.fields.CharField: username>,\n+         <django.db.models.fields.CharField: first_name>,\n+         <django.db.models.fields.CharField: last_name>,\n+         <django.db.models.fields.EmailField: email>,\n+         <django.db.models.fields.BooleanField: is_staff>,\n+         <django.db.models.fields.BooleanField: is_active>,\n+         <django.db.models.fields.DateTimeField: date_joined>,\n+         <django.db.models.fields.related.ManyToManyField: groups>,\n+         <django.db.models.fields.related.ManyToManyField: user_permissions>)\n+\n+.. _migrating-old-meta-api:\n+\n+Migrating from the old API\n+==========================\n+\n+As part of the formalization of the ``Model._meta`` API (from the\n+:class:`django.db.models.options.Options` class), a number of methods and\n+properties have been deprecated and will be removed in Django 2.0.\n+\n+These old APIs can be replicated by either:\n+\n+* invoking :meth:`Options.get_field()\n+  <django.db.models.options.Options.get_field()>`, or;\n+\n+* invoking :meth:`Options.get_fields()\n+  <django.db.models.options.Options.get_fields()>` to retrieve a list of all\n+  fields, and then filtering this list using the :ref:`field attributes\n+  <model-field-attributes>` that describe (or retrieve, in the case of\n+  ``_with_model`` variants) the properties of the desired fields.\n+\n+Although it would be possible to provide replacements for the old API, a\n+simple drop-in replacement probably won't be the best approach in practice.\n+Taking the time to refactor any field loops to make better use of the new\n+API - and possibly include fields that were previously excluded - will\n+almost certainly result in better code.\n+\n+Assuming you have a model named ``MyModel``, the following substitutions\n+can be made to convert your code to the new API:\n+\n+* ``MyModel._meta.get_field(name)``::\n+\n+      f = MyModel._meta.get_field(name)\n+\n+  then check if:\n+\n+  - ``f.auto_created == False``, because the new ``get_field()``\n+    API will find \"reverse\" relations), and:\n+\n+  - ``f.is_relation and f.related_model is None``, because the new\n+    ``get_field()`` API will find\n+    :class:`~django.contrib.contenttypes.fields.GenericForeignKey` relations;\n+\n+* ``MyModel._meta.get_field_by_name(name)``:\n+\n+  ``get_field_by_name()`` returned four values:\n+  ``(field, model, direct,  m2m)``:\n+\n+  - ``field`` can be found by ``MyModel._meta.get_field(name)``\n+\n+  - ``model`` can be found through the\n+    :attr:`~django.db.models.Field.model` attribute on the field.\n+\n+  - ``direct`` can be found by: ``not field.auto_created or field.concrete``\n+\n+    The :attr:`~django.db.models.Field.auto_created` check excludes\n+    all \"forward\" and \"reverse\" relations that are created by Django, but\n+    this also includes ``AutoField`` and ``OneToOneField`` on proxy models.\n+    We avoid filtering out these attributes using the\n+    :attr:`concrete <django.db.models.Field.concrete>` attribute.\n+\n+  - ``m2m`` can be found through the\n+    :attr:`~django.db.models.Field.many_to_many` attribute on the field.\n+\n+* ``MyModel._meta.get_fields_with_model()``::\n+\n+      [\n+          (f, f.model if f.model != MyModel else None)\n+          for f in MyModel._meta.get_fields()\n+          if not f.is_relation\n+              or f.one_to_one\n+              or (f.one_to_many and f.related_model)\n+      ]\n+\n+* ``MyModel._meta.get_concrete_fields_with_model()``::\n+\n+      [\n+          (f, f.model if f.model != MyModel else None)\n+          for f in MyModel._meta.get_fields()\n+          if f.concrete and (\n+              not f.is_relation\n+              or f.one_to_one\n+              or (f.one_to_many and f.related_model)\n+          )\n+      ]\n+\n+* ``MyModel._meta.get_m2m_with_model()``::\n+\n+      [\n+          (f, f.model if f.model != MyModel else None)\n+          for f in MyModel._meta.get_fields()\n+          if f.many_to_many and not f.auto_created\n+      ]\n+\n+* ``MyModel._meta.get_all_related_objects()``::\n+\n+      [\n+          f for f in MyModel._meta.get_fields()\n+          if f.many_to_one and f.auto_created\n+      ]\n+\n+* ``MyModel._meta.get_all_related_objects_with_model()``::\n+\n+      [\n+          (f, f.model if f.model != MyModel else None)\n+          for f in MyModel._meta.get_fields()\n+          if f.many_to_one and f.auto_created\n+      ]\n+\n+* ``MyModel._meta.get_all_related_many_to_many_objects()``::\n+\n+      [\n+          f for f in MyModel._meta.get_fields(include_hidden=True)\n+          if f.many_to_many and f.auto_created\n+      ]\n+\n+* ``MyModel._meta.get_all_related_m2m_objects_with_model()``::\n+\n+      [\n+          (f, f.model if f.model != MyModel else None)\n+          for f in MyModel._meta.get_fields(include_hidden=True)\n+          if f.many_to_many and f.auto_created\n+      ]\n+\n+* ``MyModel._meta.get_all_field_names()``::\n+\n+      from itertools import chain\n+      list(set(chain.from_iterable(\n+          (field.name, field.attname) if hasattr(field, 'attname') else (field.name,)\n+          for field in MyModel._meta.get_fields()\n+          # For complete backwards compatibility, you may want to exclude\n+          # GenericForeignKey from the results.\n+          if not (field.one_to_many and field.related_model is None)\n+      )))\n+\n+  This provides a 100% backwards compatible replacement, ensuring that both\n+  field names and attribute names ``ForeignKey``\\s are included, but fields\n+  associated with``GenericForeignKey``\\s are not. A simpler version would be::\n+\n+      [f.name for f in MyModel._meta.get_fields()]\n+\n+  While this isn't 100% backwards compatible, it may be sufficient in many\n+  situations.\n+\ndiff --git a/docs/releases/1.8.txt b/docs/releases/1.8.txt\nindex 460d637d9def..457850159f59 100644\n--- a/docs/releases/1.8.txt\n+++ b/docs/releases/1.8.txt\n@@ -29,6 +29,22 @@ Like Django 1.7, Django 1.8 requires Python 2.7 or above, though we\n What's new in Django 1.8\n ========================\n \n+``Model._meta`` API\n+~~~~~~~~~~~~~~~~~~~\n+\n+Django now has a formalized API for :doc:`Model._meta </ref/models/meta>`,\n+providing an officially supported way to :ref:`retrieve fields\n+<model-meta-field-api>` and filter fields based on their :ref:`attributes\n+<model-field-attributes>`.\n+\n+The ``Model._meta`` object has been part of Django since the days of pre-0.96\n+\"Magic Removal\" -- it just wasn't an official, stable API. In recognition of\n+this, we've endeavored to maintain backwards-compatibility with the old\n+API endpoint where possible. However, API endpoints that aren't part of the\n+new official API have been deprecated and will eventually be removed. A\n+:ref:`guide to migrating from the old API to the new API\n+<migrating-old-meta-api>` has been provided.\n+\n Security enhancements\n ~~~~~~~~~~~~~~~~~~~~~\n \n@@ -998,6 +1014,26 @@ Miscellaneous\n Features deprecated in 1.8\n ==========================\n \n+Selected methods in ``django.db.models.options.Options``\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+As part of the formalization of the ``Model._meta`` API (from the\n+:class:`django.db.models.options.Options` class), a number of methods have been\n+deprecated and will be removed in in Django 2.0:\n+\n+* ``get_all_field_names()``\n+* ``get_all_related_objects()``\n+* ``get_all_related_objects_with_model()``\n+* ``get_all_related_many_to_many_objects()``\n+* ``get_all_related_m2m_objects_with_model()``\n+* ``get_concrete_fields_with_model()``\n+* ``get_field_by_name()``\n+* ``get_fields_with_model()``\n+* ``get_m2m_with_model()``\n+\n+A :ref:`migration guide <migrating-old-meta-api>` has been provided to assist\n+in converting your code from the old API to the new, official API.\n+\n Loading ``cycle`` and ``firstof`` template tags from ``future`` library\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n \ndiff --git a/tests/backends/tests.py b/tests/backends/tests.py\nindex 7fbb57ba0caa..9eeb90335c2e 100644\n--- a/tests/backends/tests.py\n+++ b/tests/backends/tests.py\n@@ -1020,7 +1020,7 @@ def test_many_to_many(self):\n         self.assertEqual(models.Object.objects.count(), 2)\n         self.assertEqual(obj.related_objects.count(), 1)\n \n-        intermediary_model = models.Object._meta.get_field_by_name(\"related_objects\")[0].rel.through\n+        intermediary_model = models.Object._meta.get_field(\"related_objects\").rel.through\n         intermediary_model.objects.create(from_object_id=obj.id, to_object_id=12345)\n         self.assertEqual(obj.related_objects.count(), 1)\n         self.assertEqual(intermediary_model.objects.count(), 2)\ndiff --git a/tests/basic/tests.py b/tests/basic/tests.py\nindex 74515047f557..3ba94d058d14 100644\n--- a/tests/basic/tests.py\n+++ b/tests/basic/tests.py\n@@ -776,7 +776,7 @@ def test_refresh_no_fields(self):\n \n class TestRelatedObjectDeprecation(TestCase):\n     def test_field_related_deprecation(self):\n-        field = SelfRef._meta.get_field_by_name('selfref')[0]\n+        field = SelfRef._meta.get_field('selfref')\n         with warnings.catch_warnings(record=True) as warns:\n             warnings.simplefilter('always')\n             self.assertIsInstance(field.related, ForeignObjectRel)\ndiff --git a/tests/fixtures/tests.py b/tests/fixtures/tests.py\nindex adef8ec5e5be..0201693dba6f 100644\n--- a/tests/fixtures/tests.py\n+++ b/tests/fixtures/tests.py\n@@ -3,6 +3,7 @@\n import os\n import warnings\n \n+from django.apps import apps\n from django.contrib.sites.models import Site\n from django.core import management\n from django.db import connection, IntegrityError\n@@ -76,6 +77,7 @@ def test_initial_data(self):\n         ])\n \n     def test_loading_and_dumping(self):\n+        apps.clear_cache()\n         Site.objects.all().delete()\n         # Load fixture 1. Single JSON file, with two objects.\n         management.call_command('loaddata', 'fixture1.json', verbosity=0)\ndiff --git a/tests/generic_relations/tests.py b/tests/generic_relations/tests.py\nindex e7f7b02f5b2d..c6230b057e18 100644\n--- a/tests/generic_relations/tests.py\n+++ b/tests/generic_relations/tests.py\n@@ -403,7 +403,8 @@ def test_update_or_create_defaults(self):\n         self.assertEqual(tag.content_object.id, diamond.id)\n \n     def test_query_content_type(self):\n-        with six.assertRaisesRegex(self, FieldError, \"^Cannot resolve keyword 'content_object' into field.\"):\n+        msg = \"Field 'content_object' does not generate an automatic reverse relation\"\n+        with self.assertRaisesMessage(FieldError, msg):\n             TaggedItem.objects.get(content_object='')\n \n \ndiff --git a/tests/generic_relations_regress/tests.py b/tests/generic_relations_regress/tests.py\nindex 65afa9f298d6..88243bade0ce 100644\n--- a/tests/generic_relations_regress/tests.py\n+++ b/tests/generic_relations_regress/tests.py\n@@ -260,7 +260,7 @@ def test_editable_generic_rel(self):\n         form = GenericRelationForm({'links': None})\n         self.assertTrue(form.is_valid())\n         form.save()\n-        links = HasLinkThing._meta.get_field_by_name('links')[0]\n+        links = HasLinkThing._meta.get_field('links')\n         self.assertEqual(links.save_form_data_calls, 1)\n \n     def test_ticket_22998(self):\ndiff --git a/tests/m2m_and_m2o/tests.py b/tests/m2m_and_m2o/tests.py\nindex e950a839d21b..2317f62300ec 100644\n--- a/tests/m2m_and_m2o/tests.py\n+++ b/tests/m2m_and_m2o/tests.py\n@@ -5,6 +5,12 @@\n \n \n class RelatedObjectTests(TestCase):\n+\n+    def test_related_objects_have_name_attribute(self):\n+        for field_name in ('test_issue_client', 'test_issue_cc'):\n+            obj = User._meta.get_field(field_name)\n+            self.assertEqual(field_name, obj.field.related_query_name())\n+\n     def test_m2m_and_m2o(self):\n         r = User.objects.create(username=\"russell\")\n         g = User.objects.create(username=\"gustav\")\ndiff --git a/tests/many_to_one/tests.py b/tests/many_to_one/tests.py\nindex 0195e5d2d8b7..e82d8eefe608 100644\n--- a/tests/many_to_one/tests.py\n+++ b/tests/many_to_one/tests.py\n@@ -437,11 +437,11 @@ def test_values_list_exception(self):\n         expected_message = \"Cannot resolve keyword 'notafield' into field. Choices are: %s\"\n \n         self.assertRaisesMessage(FieldError,\n-                                 expected_message % ', '.join(Reporter._meta.get_all_field_names()),\n+                                 expected_message % ', '.join(sorted(f.name for f in Reporter._meta.get_fields())),\n                                  Article.objects.values_list,\n                                  'reporter__notafield')\n         self.assertRaisesMessage(FieldError,\n-                                 expected_message % ', '.join(['EXTRA'] + Article._meta.get_all_field_names()),\n+                                 expected_message % ', '.join(['EXTRA'] + sorted(f.name for f in Article._meta.get_fields())),\n                                  Article.objects.extra(select={'EXTRA': 'EXTRA_SELECT'}).values_list,\n                                  'notafield')\n \ndiff --git a/tests/migrations/test_state.py b/tests/migrations/test_state.py\nindex 6f510813afb6..e069649810eb 100644\n--- a/tests/migrations/test_state.py\n+++ b/tests/migrations/test_state.py\n@@ -202,8 +202,8 @@ def test_render(self):\n         ))\n \n         new_apps = project_state.apps\n-        self.assertEqual(new_apps.get_model(\"migrations\", \"Tag\")._meta.get_field_by_name(\"name\")[0].max_length, 100)\n-        self.assertEqual(new_apps.get_model(\"migrations\", \"Tag\")._meta.get_field_by_name(\"hidden\")[0].null, False)\n+        self.assertEqual(new_apps.get_model(\"migrations\", \"Tag\")._meta.get_field(\"name\").max_length, 100)\n+        self.assertEqual(new_apps.get_model(\"migrations\", \"Tag\")._meta.get_field(\"hidden\").null, False)\n \n         self.assertEqual(len(new_apps.get_model(\"migrations\", \"SubTag\")._meta.local_fields), 2)\n \ndiff --git a/tests/model_fields/models.py b/tests/model_fields/models.py\nindex 2a7bebc9ddf7..8927ae8830b9 100644\n--- a/tests/model_fields/models.py\n+++ b/tests/model_fields/models.py\n@@ -8,6 +8,11 @@\n     Image = None\n \n from django.core.files.storage import FileSystemStorage\n+from django.contrib.contenttypes.fields import GenericForeignKey, GenericRelation\n+from django.contrib.contenttypes.models import ContentType\n+from django.db.models.fields.related import (\n+    ForeignObject, ForeignKey, ManyToManyField, OneToOneField,\n+)\n from django.db import models\n from django.db.models.fields.files import ImageFieldFile, ImageField\n from django.utils import six\n@@ -295,6 +300,52 @@ class PersonTwoImages(models.Model):\n                                   height_field='headshot_height',\n                                   width_field='headshot_width')\n \n+\n+class AllFieldsModel(models.Model):\n+    big_integer = models.BigIntegerField()\n+    binary = models.BinaryField()\n+    boolean = models.BooleanField(default=False)\n+    char = models.CharField(max_length=10)\n+    csv = models.CommaSeparatedIntegerField(max_length=10)\n+    date = models.DateField()\n+    datetime = models.DateTimeField()\n+    decimal = models.DecimalField(decimal_places=2, max_digits=2)\n+    duration = models.DurationField()\n+    email = models.EmailField()\n+    file_path = models.FilePathField()\n+    floatf = models.FloatField()\n+    integer = models.IntegerField()\n+    ip_address = models.IPAddressField()\n+    generic_ip = models.GenericIPAddressField()\n+    null_boolean = models.NullBooleanField()\n+    positive_integer = models.PositiveIntegerField()\n+    positive_small_integer = models.PositiveSmallIntegerField()\n+    slug = models.SlugField()\n+    small_integer = models.SmallIntegerField()\n+    text = models.TextField()\n+    time = models.TimeField()\n+    url = models.URLField()\n+    uuid = models.UUIDField()\n+\n+    fo = ForeignObject(\n+        'self',\n+        from_fields=['abstract_non_concrete_id'],\n+        to_fields=['id'],\n+        related_name='reverse'\n+    )\n+    fk = ForeignKey(\n+        'self',\n+        related_name='reverse2'\n+    )\n+    m2m = ManyToManyField('self')\n+    oto = OneToOneField('self')\n+\n+    object_id = models.PositiveIntegerField()\n+    content_type = models.ForeignKey(ContentType)\n+    gfk = GenericForeignKey()\n+    gr = GenericRelation(DataModel)\n+\n+\n ###############################################################################\n \n \ndiff --git a/tests/model_fields/test_field_flags.py b/tests/model_fields/test_field_flags.py\nnew file mode 100644\nindex 000000000000..08a57db5019c\n--- /dev/null\n+++ b/tests/model_fields/test_field_flags.py\n@@ -0,0 +1,220 @@\n+from django import test\n+\n+from django.contrib.contenttypes.fields import (\n+    GenericForeignKey, GenericRelation,\n+)\n+from django.db import models\n+from django.db.models.fields.related import (\n+    ForeignObject, ForeignKey, OneToOneField, ManyToManyField,\n+    ManyToOneRel, ForeignObjectRel,\n+)\n+\n+from .models import AllFieldsModel\n+\n+\n+NON_CONCRETE_FIELDS = (\n+    ForeignObject,\n+    GenericForeignKey,\n+    GenericRelation,\n+)\n+\n+NON_EDITABLE_FIELDS = (\n+    models.BinaryField,\n+    GenericForeignKey,\n+    GenericRelation,\n+)\n+\n+RELATION_FIELDS = (\n+    ForeignKey,\n+    ForeignObject,\n+    ManyToManyField,\n+    OneToOneField,\n+    GenericForeignKey,\n+    GenericRelation,\n+)\n+\n+ONE_TO_MANY_CLASSES = {\n+    ForeignObject,\n+    ForeignKey,\n+    GenericForeignKey,\n+}\n+\n+MANY_TO_ONE_CLASSES = {\n+    ForeignObjectRel,\n+    ManyToOneRel,\n+    GenericRelation,\n+}\n+\n+MANY_TO_MANY_CLASSES = {\n+    ManyToManyField,\n+}\n+\n+ONE_TO_ONE_CLASSES = {\n+    OneToOneField,\n+}\n+\n+FLAG_PROPERTIES = (\n+    'concrete',\n+    'editable',\n+    'is_relation',\n+    'model',\n+    'hidden',\n+    'one_to_many',\n+    'many_to_one',\n+    'many_to_many',\n+    'one_to_one',\n+    'related_model',\n+)\n+\n+FLAG_PROPERTIES_FOR_RELATIONS = (\n+    'one_to_many',\n+    'many_to_one',\n+    'many_to_many',\n+    'one_to_one',\n+)\n+\n+\n+class FieldFlagsTests(test.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n+        super(FieldFlagsTests, cls).setUpClass()\n+        cls.fields = (\n+            list(AllFieldsModel._meta.fields) +\n+            list(AllFieldsModel._meta.virtual_fields)\n+        )\n+\n+        cls.all_fields = (\n+            cls.fields +\n+            list(AllFieldsModel._meta.many_to_many) +\n+            list(AllFieldsModel._meta.virtual_fields)\n+        )\n+\n+        cls.fields_and_reverse_objects = (\n+            cls.all_fields +\n+            list(AllFieldsModel._meta.related_objects)\n+        )\n+\n+    def test_each_field_should_have_a_concrete_attribute(self):\n+        self.assertTrue(all(f.concrete.__class__ == bool for f in self.fields))\n+\n+    def test_each_field_should_have_an_editable_attribute(self):\n+        self.assertTrue(all(f.editable.__class__ == bool for f in self.all_fields))\n+\n+    def test_each_field_should_have_a_has_rel_attribute(self):\n+        self.assertTrue(all(f.is_relation.__class__ == bool for f in self.all_fields))\n+\n+    def test_each_object_should_have_auto_created(self):\n+        self.assertTrue(\n+            all(f.auto_created.__class__ == bool\n+            for f in self.fields_and_reverse_objects)\n+        )\n+\n+    def test_non_concrete_fields(self):\n+        for field in self.fields:\n+            if type(field) in NON_CONCRETE_FIELDS:\n+                self.assertFalse(field.concrete)\n+            else:\n+                self.assertTrue(field.concrete)\n+\n+    def test_non_editable_fields(self):\n+        for field in self.all_fields:\n+            if type(field) in NON_EDITABLE_FIELDS:\n+                self.assertFalse(field.editable)\n+            else:\n+                self.assertTrue(field.editable)\n+\n+    def test_related_fields(self):\n+        for field in self.all_fields:\n+            if type(field) in RELATION_FIELDS:\n+                self.assertTrue(field.is_relation)\n+            else:\n+                self.assertFalse(field.is_relation)\n+\n+    def test_field_names_should_always_be_available(self):\n+        for field in self.fields_and_reverse_objects:\n+            self.assertTrue(field.name)\n+\n+    def test_all_field_types_should_have_flags(self):\n+        for field in self.fields_and_reverse_objects:\n+            for flag in FLAG_PROPERTIES:\n+                self.assertTrue(hasattr(field, flag), \"Field %s does not have flag %s\" % (field, flag))\n+            if field.is_relation:\n+                true_cardinality_flags = sum(\n+                    getattr(field, flag) is True\n+                    for flag in FLAG_PROPERTIES_FOR_RELATIONS\n+                )\n+                # If the field has a relation, there should be only one of the\n+                # 4 cardinality flags available.\n+                self.assertEqual(1, true_cardinality_flags)\n+\n+    def test_cardinality_m2m(self):\n+        m2m_type_fields = (\n+            f for f in self.all_fields\n+            if f.is_relation and f.many_to_many\n+        )\n+        # Test classes are what we expect\n+        self.assertEqual(MANY_TO_MANY_CLASSES, {f.__class__ for f in m2m_type_fields})\n+\n+        # Ensure all m2m reverses are m2m\n+        for field in m2m_type_fields:\n+            reverse_field = field.rel\n+            self.assertTrue(reverse_field.is_relation)\n+            self.assertTrue(reverse_field.many_to_many)\n+            self.assertTrue(reverse_field.related_model)\n+\n+    def test_cardinality_o2m(self):\n+        o2m_type_fields = [\n+            f for f in self.fields_and_reverse_objects\n+            if f.is_relation and f.one_to_many\n+        ]\n+        # Test classes are what we expect\n+        self.assertEqual(ONE_TO_MANY_CLASSES, {f.__class__ for f in o2m_type_fields})\n+\n+        # Ensure all o2m reverses are m2o\n+        for field in o2m_type_fields:\n+            if field.concrete:\n+                reverse_field = field.rel\n+                self.assertTrue(reverse_field.is_relation and reverse_field.many_to_one)\n+\n+    def test_cardinality_m2o(self):\n+        m2o_type_fields = [\n+            f for f in self.fields_and_reverse_objects\n+            if f.is_relation and f.many_to_one\n+        ]\n+        # Test classes are what we expect\n+        self.assertEqual(MANY_TO_ONE_CLASSES, {f.__class__ for f in m2o_type_fields})\n+\n+        # Ensure all m2o reverses are o2m\n+        for obj in m2o_type_fields:\n+            if hasattr(obj, 'field'):\n+                reverse_field = obj.field\n+                self.assertTrue(reverse_field.is_relation and reverse_field.one_to_many)\n+\n+    def test_cardinality_o2o(self):\n+        o2o_type_fields = [\n+            f for f in self.all_fields\n+            if f.is_relation and f.one_to_one\n+        ]\n+        # Test classes are what we expect\n+        self.assertEqual(ONE_TO_ONE_CLASSES, {f.__class__ for f in o2o_type_fields})\n+\n+        # Ensure all o2o reverses are o2o\n+        for obj in o2o_type_fields:\n+            if hasattr(obj, 'field'):\n+                reverse_field = obj.field\n+                self.assertTrue(reverse_field.is_relation and reverse_field.one_to_one)\n+\n+    def test_hidden_flag(self):\n+        incl_hidden = set(AllFieldsModel._meta.get_fields(include_hidden=True))\n+        no_hidden = set(AllFieldsModel._meta.get_fields())\n+        fields_that_should_be_hidden = (incl_hidden - no_hidden)\n+        for f in incl_hidden:\n+            self.assertEqual(f in fields_that_should_be_hidden, f.hidden)\n+\n+    def test_model_and_reverse_model_should_equal_on_relations(self):\n+        for field in AllFieldsModel._meta.get_fields():\n+            is_concrete_forward_field = field.concrete and field.related_model\n+            if is_concrete_forward_field:\n+                reverse_field = field.rel\n+                self.assertEqual(field.model, reverse_field.related_model)\n+                self.assertEqual(field.related_model, reverse_field.model)\ndiff --git a/tests/model_fields/tests.py b/tests/model_fields/tests.py\nindex e63cc007dd96..d891645ca0c3 100644\n--- a/tests/model_fields/tests.py\n+++ b/tests/model_fields/tests.py\n@@ -198,7 +198,7 @@ class FKUniqueTrue(models.Model):\n         self.assertEqual(warnings, expected_warnings)\n \n     def test_related_name_converted_to_text(self):\n-        rel_name = Bar._meta.get_field_by_name('a')[0].rel.related_name\n+        rel_name = Bar._meta.get_field('a').rel.related_name\n         self.assertIsInstance(rel_name, six.text_type)\n \n \ndiff --git a/tests/model_meta/results.py b/tests/model_meta/results.py\nnew file mode 100644\nindex 000000000000..1efc49ed235b\n--- /dev/null\n+++ b/tests/model_meta/results.py\n@@ -0,0 +1,796 @@\n+from .models import (\n+    AbstractPerson, BasePerson, Person, Relating, Relation,\n+)\n+\n+TEST_RESULTS = {\n+    'get_all_field_names': {\n+        Person: [\n+            'baseperson_ptr',\n+            'baseperson_ptr_id',\n+            'content_type_abstract',\n+            'content_type_abstract_id',\n+            'content_type_base',\n+            'content_type_base_id',\n+            'content_type_concrete',\n+            'content_type_concrete_id',\n+            'data_abstract',\n+            'data_base',\n+            'data_inherited',\n+            'data_not_concrete_abstract',\n+            'data_not_concrete_base',\n+            'data_not_concrete_inherited',\n+            'fk_abstract',\n+            'fk_abstract_id',\n+            'fk_base',\n+            'fk_base_id',\n+            'fk_inherited',\n+            'fk_inherited_id',\n+            'followers_abstract',\n+            'followers_base',\n+            'followers_concrete',\n+            'following_abstract',\n+            'following_base',\n+            'following_inherited',\n+            'friends_abstract',\n+            'friends_base',\n+            'friends_inherited',\n+            'generic_relation_abstract',\n+            'generic_relation_base',\n+            'generic_relation_concrete',\n+            'id',\n+            'm2m_abstract',\n+            'm2m_base',\n+            'm2m_inherited',\n+            'object_id_abstract',\n+            'object_id_base',\n+            'object_id_concrete',\n+            'relating_basepeople',\n+            'relating_baseperson',\n+            'relating_people',\n+            'relating_person',\n+        ],\n+        BasePerson: [\n+            'content_type_abstract',\n+            'content_type_abstract_id',\n+            'content_type_base',\n+            'content_type_base_id',\n+            'data_abstract',\n+            'data_base',\n+            'data_not_concrete_abstract',\n+            'data_not_concrete_base',\n+            'fk_abstract',\n+            'fk_abstract_id',\n+            'fk_base',\n+            'fk_base_id',\n+            'followers_abstract',\n+            'followers_base',\n+            'following_abstract',\n+            'following_base',\n+            'friends_abstract',\n+            'friends_base',\n+            'generic_relation_abstract',\n+            'generic_relation_base',\n+            'id',\n+            'm2m_abstract',\n+            'm2m_base',\n+            'object_id_abstract',\n+            'object_id_base',\n+            'person',\n+            'relating_basepeople',\n+            'relating_baseperson'\n+        ],\n+        AbstractPerson: [\n+            'content_type_abstract',\n+            'content_type_abstract_id',\n+            'data_abstract',\n+            'data_not_concrete_abstract',\n+            'fk_abstract',\n+            'fk_abstract_id',\n+            'following_abstract',\n+            'friends_abstract',\n+            'generic_relation_abstract',\n+            'm2m_abstract',\n+            'object_id_abstract',\n+        ],\n+        Relating: [\n+            'basepeople',\n+            'basepeople_hidden',\n+            'baseperson',\n+            'baseperson_hidden',\n+            'baseperson_hidden_id',\n+            'baseperson_id',\n+            'id',\n+            'people',\n+            'people_hidden',\n+            'person',\n+            'person_hidden',\n+            'person_hidden_id',\n+            'person_id',\n+            'proxyperson',\n+            'proxyperson_hidden',\n+            'proxyperson_hidden_id',\n+            'proxyperson_id',\n+        ],\n+    },\n+    'fields': {\n+        Person: [\n+            'id',\n+            'data_abstract',\n+            'fk_abstract_id',\n+            'data_not_concrete_abstract',\n+            'content_type_abstract_id',\n+            'object_id_abstract',\n+            'data_base',\n+            'fk_base_id',\n+            'data_not_concrete_base',\n+            'content_type_base_id',\n+            'object_id_base',\n+            'baseperson_ptr_id',\n+            'data_inherited',\n+            'fk_inherited_id',\n+            'data_not_concrete_inherited',\n+            'content_type_concrete_id',\n+            'object_id_concrete',\n+        ],\n+        BasePerson: [\n+            'id',\n+            'data_abstract',\n+            'fk_abstract_id',\n+            'data_not_concrete_abstract',\n+            'content_type_abstract_id',\n+            'object_id_abstract',\n+            'data_base',\n+            'fk_base_id',\n+            'data_not_concrete_base',\n+            'content_type_base_id',\n+            'object_id_base',\n+        ],\n+        AbstractPerson: [\n+            'data_abstract',\n+            'fk_abstract_id',\n+            'data_not_concrete_abstract',\n+            'content_type_abstract_id',\n+            'object_id_abstract',\n+        ],\n+        Relating: [\n+            'id',\n+            'baseperson_id',\n+            'baseperson_hidden_id',\n+            'person_id',\n+            'person_hidden_id',\n+            'proxyperson_id',\n+            'proxyperson_hidden_id',\n+        ],\n+    },\n+    'local_fields': {\n+        Person: [\n+            'baseperson_ptr_id',\n+            'data_inherited',\n+            'fk_inherited_id',\n+            'data_not_concrete_inherited',\n+            'content_type_concrete_id',\n+            'object_id_concrete',\n+        ],\n+        BasePerson: [\n+            'id',\n+            'data_abstract',\n+            'fk_abstract_id',\n+            'data_not_concrete_abstract',\n+            'content_type_abstract_id',\n+            'object_id_abstract',\n+            'data_base',\n+            'fk_base_id',\n+            'data_not_concrete_base',\n+            'content_type_base_id',\n+            'object_id_base',\n+        ],\n+        AbstractPerson: [\n+            'data_abstract',\n+            'fk_abstract_id',\n+            'data_not_concrete_abstract',\n+            'content_type_abstract_id',\n+            'object_id_abstract',\n+        ],\n+        Relating: [\n+            'id',\n+            'baseperson_id',\n+            'baseperson_hidden_id',\n+            'person_id',\n+            'person_hidden_id',\n+            'proxyperson_id',\n+            'proxyperson_hidden_id',\n+        ],\n+    },\n+    'local_concrete_fields': {\n+        Person: [\n+            'baseperson_ptr_id',\n+            'data_inherited',\n+            'fk_inherited_id',\n+            'content_type_concrete_id',\n+            'object_id_concrete',\n+        ],\n+        BasePerson: [\n+            'id',\n+            'data_abstract',\n+            'fk_abstract_id',\n+            'content_type_abstract_id',\n+            'object_id_abstract',\n+            'data_base',\n+            'fk_base_id',\n+            'content_type_base_id',\n+            'object_id_base',\n+        ],\n+        AbstractPerson: [\n+            'data_abstract',\n+            'fk_abstract_id',\n+            'content_type_abstract_id',\n+            'object_id_abstract',\n+        ],\n+        Relating: [\n+            'id',\n+            'baseperson_id',\n+            'baseperson_hidden_id',\n+            'person_id',\n+            'person_hidden_id',\n+            'proxyperson_id',\n+            'proxyperson_hidden_id',\n+        ],\n+    },\n+    'many_to_many': {\n+        Person: [\n+            'm2m_abstract',\n+            'friends_abstract',\n+            'following_abstract',\n+            'm2m_base',\n+            'friends_base',\n+            'following_base',\n+            'm2m_inherited',\n+            'friends_inherited',\n+            'following_inherited',\n+        ],\n+        BasePerson: [\n+            'm2m_abstract',\n+            'friends_abstract',\n+            'following_abstract',\n+            'm2m_base',\n+            'friends_base',\n+            'following_base',\n+        ],\n+        AbstractPerson: [\n+            'm2m_abstract',\n+            'friends_abstract',\n+            'following_abstract',\n+        ],\n+        Relating: [\n+            'basepeople',\n+            'basepeople_hidden',\n+            'people',\n+            'people_hidden',\n+        ],\n+    },\n+    'many_to_many_with_model': {\n+        Person: [\n+            BasePerson,\n+            BasePerson,\n+            BasePerson,\n+            BasePerson,\n+            BasePerson,\n+            BasePerson,\n+            None,\n+            None,\n+            None,\n+        ],\n+        BasePerson: [\n+            None,\n+            None,\n+            None,\n+            None,\n+            None,\n+            None,\n+        ],\n+        AbstractPerson: [\n+            None,\n+            None,\n+            None,\n+        ],\n+        Relating: [\n+            None,\n+            None,\n+            None,\n+            None,\n+        ],\n+    },\n+    'get_all_related_objects_with_model_legacy': {\n+        Person: (\n+            ('relating_baseperson', BasePerson),\n+            ('relating_person', None),\n+        ),\n+        BasePerson: (\n+            ('person', None),\n+            ('relating_baseperson', None),\n+        ),\n+        Relation: (\n+            ('fk_abstract_rel', None),\n+            ('fo_abstract_rel', None),\n+            ('fk_base_rel', None),\n+            ('fo_base_rel', None),\n+            ('fk_concrete_rel', None),\n+            ('fo_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_objects_with_model_hidden_local': {\n+        Person: (\n+            ('+', None),\n+            ('+', None),\n+            ('Person_following_inherited+', None),\n+            ('Person_following_inherited+', None),\n+            ('Person_friends_inherited+', None),\n+            ('Person_friends_inherited+', None),\n+            ('Person_m2m_inherited+', None),\n+            ('Relating_people+', None),\n+            ('Relating_people_hidden+', None),\n+            ('followers_concrete', None),\n+            ('friends_inherited_rel_+', None),\n+            ('relating_people', None),\n+            ('relating_person', None),\n+        ),\n+        BasePerson: (\n+            ('+', None),\n+            ('+', None),\n+            ('BasePerson_following_abstract+', None),\n+            ('BasePerson_following_abstract+', None),\n+            ('BasePerson_following_base+', None),\n+            ('BasePerson_following_base+', None),\n+            ('BasePerson_friends_abstract+', None),\n+            ('BasePerson_friends_abstract+', None),\n+            ('BasePerson_friends_base+', None),\n+            ('BasePerson_friends_base+', None),\n+            ('BasePerson_m2m_abstract+', None),\n+            ('BasePerson_m2m_base+', None),\n+            ('Relating_basepeople+', None),\n+            ('Relating_basepeople_hidden+', None),\n+            ('followers_abstract', None),\n+            ('followers_base', None),\n+            ('friends_abstract_rel_+', None),\n+            ('friends_base_rel_+', None),\n+            ('person', None),\n+            ('relating_basepeople', None),\n+            ('relating_baseperson', None),\n+        ),\n+        Relation: (\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('BasePerson_m2m_abstract+', None),\n+            ('BasePerson_m2m_base+', None),\n+            ('Person_m2m_inherited+', None),\n+            ('fk_abstract_rel', None),\n+            ('fk_base_rel', None),\n+            ('fk_concrete_rel', None),\n+            ('fo_abstract_rel', None),\n+            ('fo_base_rel', None),\n+            ('fo_concrete_rel', None),\n+            ('m2m_abstract_rel', None),\n+            ('m2m_base_rel', None),\n+            ('m2m_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_objects_with_model_hidden': {\n+        Person: (\n+            ('+', BasePerson),\n+            ('+', BasePerson),\n+            ('+', None),\n+            ('+', None),\n+            ('BasePerson_following_abstract+', BasePerson),\n+            ('BasePerson_following_abstract+', BasePerson),\n+            ('BasePerson_following_base+', BasePerson),\n+            ('BasePerson_following_base+', BasePerson),\n+            ('BasePerson_friends_abstract+', BasePerson),\n+            ('BasePerson_friends_abstract+', BasePerson),\n+            ('BasePerson_friends_base+', BasePerson),\n+            ('BasePerson_friends_base+', BasePerson),\n+            ('BasePerson_m2m_abstract+', BasePerson),\n+            ('BasePerson_m2m_base+', BasePerson),\n+            ('Person_following_inherited+', None),\n+            ('Person_following_inherited+', None),\n+            ('Person_friends_inherited+', None),\n+            ('Person_friends_inherited+', None),\n+            ('Person_m2m_inherited+', None),\n+            ('Relating_basepeople+', BasePerson),\n+            ('Relating_basepeople_hidden+', BasePerson),\n+            ('Relating_people+', None),\n+            ('Relating_people_hidden+', None),\n+            ('followers_abstract', BasePerson),\n+            ('followers_base', BasePerson),\n+            ('followers_concrete', None),\n+            ('friends_abstract_rel_+', BasePerson),\n+            ('friends_base_rel_+', BasePerson),\n+            ('friends_inherited_rel_+', None),\n+            ('relating_basepeople', BasePerson),\n+            ('relating_baseperson', BasePerson),\n+            ('relating_people', None),\n+            ('relating_person', None),\n+        ),\n+        BasePerson: (\n+            ('+', None),\n+            ('+', None),\n+            ('BasePerson_following_abstract+', None),\n+            ('BasePerson_following_abstract+', None),\n+            ('BasePerson_following_base+', None),\n+            ('BasePerson_following_base+', None),\n+            ('BasePerson_friends_abstract+', None),\n+            ('BasePerson_friends_abstract+', None),\n+            ('BasePerson_friends_base+', None),\n+            ('BasePerson_friends_base+', None),\n+            ('BasePerson_m2m_abstract+', None),\n+            ('BasePerson_m2m_base+', None),\n+            ('Relating_basepeople+', None),\n+            ('Relating_basepeople_hidden+', None),\n+            ('followers_abstract', None),\n+            ('followers_base', None),\n+            ('friends_abstract_rel_+', None),\n+            ('friends_base_rel_+', None),\n+            ('person', None),\n+            ('relating_basepeople', None),\n+            ('relating_baseperson', None),\n+        ),\n+        Relation: (\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('BasePerson_m2m_abstract+', None),\n+            ('BasePerson_m2m_base+', None),\n+            ('Person_m2m_inherited+', None),\n+            ('fk_abstract_rel', None),\n+            ('fk_base_rel', None),\n+            ('fk_concrete_rel', None),\n+            ('fo_abstract_rel', None),\n+            ('fo_base_rel', None),\n+            ('fo_concrete_rel', None),\n+            ('m2m_abstract_rel', None),\n+            ('m2m_base_rel', None),\n+            ('m2m_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_objects_with_model_local': {\n+        Person: (\n+            ('followers_concrete', None),\n+            ('relating_person', None),\n+            ('relating_people', None),\n+        ),\n+        BasePerson: (\n+            ('followers_abstract', None),\n+            ('followers_base', None),\n+            ('person', None),\n+            ('relating_baseperson', None),\n+            ('relating_basepeople', None),\n+        ),\n+        Relation: (\n+            ('fk_abstract_rel', None),\n+            ('fo_abstract_rel', None),\n+            ('fk_base_rel', None),\n+            ('fo_base_rel', None),\n+            ('m2m_abstract_rel', None),\n+            ('m2m_base_rel', None),\n+            ('fk_concrete_rel', None),\n+            ('fo_concrete_rel', None),\n+            ('m2m_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_objects_with_model': {\n+        Person: (\n+            ('followers_abstract', BasePerson),\n+            ('followers_base', BasePerson),\n+            ('relating_baseperson', BasePerson),\n+            ('relating_basepeople', BasePerson),\n+            ('followers_concrete', None),\n+            ('relating_person', None),\n+            ('relating_people', None),\n+        ),\n+        BasePerson: (\n+            ('followers_abstract', None),\n+            ('followers_base', None),\n+            ('person', None),\n+            ('relating_baseperson', None),\n+            ('relating_basepeople', None),\n+        ),\n+        Relation: (\n+            ('fk_abstract_rel', None),\n+            ('fo_abstract_rel', None),\n+            ('fk_base_rel', None),\n+            ('fo_base_rel', None),\n+            ('m2m_abstract_rel', None),\n+            ('m2m_base_rel', None),\n+            ('fk_concrete_rel', None),\n+            ('fo_concrete_rel', None),\n+            ('m2m_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_objects_with_model_local_legacy': {\n+        Person: (\n+            ('relating_person', None),\n+        ),\n+        BasePerson: (\n+            ('person', None),\n+            ('relating_baseperson', None)\n+        ),\n+        Relation: (\n+            ('fk_abstract_rel', None),\n+            ('fo_abstract_rel', None),\n+            ('fk_base_rel', None),\n+            ('fo_base_rel', None),\n+            ('fk_concrete_rel', None),\n+            ('fo_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_objects_with_model_hidden_legacy': {\n+        BasePerson: (\n+            ('+', None),\n+            ('BasePerson_following_abstract+', None),\n+            ('BasePerson_following_abstract+', None),\n+            ('BasePerson_following_base+', None),\n+            ('BasePerson_following_base+', None),\n+            ('BasePerson_friends_abstract+', None),\n+            ('BasePerson_friends_abstract+', None),\n+            ('BasePerson_friends_base+', None),\n+            ('BasePerson_friends_base+', None),\n+            ('BasePerson_m2m_abstract+', None),\n+            ('BasePerson_m2m_base+', None),\n+            ('Relating_basepeople+', None),\n+            ('Relating_basepeople_hidden+', None),\n+            ('person', None),\n+            ('relating_baseperson', None),\n+        ),\n+        Person: (\n+            ('+', BasePerson),\n+            ('+', None),\n+            ('BasePerson_following_abstract+', BasePerson),\n+            ('BasePerson_following_abstract+', BasePerson),\n+            ('BasePerson_following_base+', BasePerson),\n+            ('BasePerson_following_base+', BasePerson),\n+            ('BasePerson_friends_abstract+', BasePerson),\n+            ('BasePerson_friends_abstract+', BasePerson),\n+            ('BasePerson_friends_base+', BasePerson),\n+            ('BasePerson_friends_base+', BasePerson),\n+            ('BasePerson_m2m_abstract+', BasePerson),\n+            ('BasePerson_m2m_base+', BasePerson),\n+            ('Person_following_inherited+', None),\n+            ('Person_following_inherited+', None),\n+            ('Person_friends_inherited+', None),\n+            ('Person_friends_inherited+', None),\n+            ('Person_m2m_inherited+', None),\n+            ('Relating_basepeople+', BasePerson),\n+            ('Relating_basepeople_hidden+', BasePerson),\n+            ('Relating_people+', None),\n+            ('Relating_people_hidden+', None),\n+            ('relating_baseperson', BasePerson),\n+            ('relating_person', None),\n+        ),\n+        Relation: (\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('BasePerson_m2m_abstract+', None),\n+            ('BasePerson_m2m_base+', None),\n+            ('Person_m2m_inherited+', None),\n+            ('fk_abstract_rel', None),\n+            ('fk_base_rel', None),\n+            ('fk_concrete_rel', None),\n+            ('fo_abstract_rel', None),\n+            ('fo_base_rel', None),\n+            ('fo_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_objects_with_model_hidden_local_legacy': {\n+        BasePerson: (\n+            ('+', None),\n+            ('BasePerson_following_abstract+', None),\n+            ('BasePerson_following_abstract+', None),\n+            ('BasePerson_following_base+', None),\n+            ('BasePerson_following_base+', None),\n+            ('BasePerson_friends_abstract+', None),\n+            ('BasePerson_friends_abstract+', None),\n+            ('BasePerson_friends_base+', None),\n+            ('BasePerson_friends_base+', None),\n+            ('BasePerson_m2m_abstract+', None),\n+            ('BasePerson_m2m_base+', None),\n+            ('Relating_basepeople+', None),\n+            ('Relating_basepeople_hidden+', None),\n+            ('person', None),\n+            ('relating_baseperson', None),\n+        ),\n+        Person: (\n+            ('+', None),\n+            ('Person_following_inherited+', None),\n+            ('Person_following_inherited+', None),\n+            ('Person_friends_inherited+', None),\n+            ('Person_friends_inherited+', None),\n+            ('Person_m2m_inherited+', None),\n+            ('Relating_people+', None),\n+            ('Relating_people_hidden+', None),\n+            ('relating_person', None),\n+        ),\n+        Relation: (\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('BasePerson_m2m_abstract+', None),\n+            ('BasePerson_m2m_base+', None),\n+            ('Person_m2m_inherited+', None),\n+            ('fk_abstract_rel', None),\n+            ('fk_base_rel', None),\n+            ('fk_concrete_rel', None),\n+            ('fo_abstract_rel', None),\n+            ('fo_base_rel', None),\n+            ('fo_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_objects_with_model_proxy_legacy': {\n+        BasePerson: (\n+            ('person', None),\n+            ('relating_baseperson', None),\n+        ),\n+        Person: (\n+            ('relating_baseperson', BasePerson),\n+            ('relating_person', None), ('relating_proxyperson', None),\n+        ),\n+        Relation: (\n+            ('fk_abstract_rel', None), ('fo_abstract_rel', None),\n+            ('fk_base_rel', None), ('fo_base_rel', None),\n+            ('fk_concrete_rel', None), ('fo_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_objects_with_model_proxy_hidden_legacy': {\n+        BasePerson: (\n+            ('+', None),\n+            ('BasePerson_following_abstract+', None),\n+            ('BasePerson_following_abstract+', None),\n+            ('BasePerson_following_base+', None),\n+            ('BasePerson_following_base+', None),\n+            ('BasePerson_friends_abstract+', None),\n+            ('BasePerson_friends_abstract+', None),\n+            ('BasePerson_friends_base+', None),\n+            ('BasePerson_friends_base+', None),\n+            ('BasePerson_m2m_abstract+', None),\n+            ('BasePerson_m2m_base+', None),\n+            ('Relating_basepeople+', None),\n+            ('Relating_basepeople_hidden+', None),\n+            ('person', None),\n+            ('relating_baseperson', None),\n+        ),\n+        Person: (\n+            ('+', BasePerson),\n+            ('+', None),\n+            ('+', None),\n+            ('BasePerson_following_abstract+', BasePerson),\n+            ('BasePerson_following_abstract+', BasePerson),\n+            ('BasePerson_following_base+', BasePerson),\n+            ('BasePerson_following_base+', BasePerson),\n+            ('BasePerson_friends_abstract+', BasePerson),\n+            ('BasePerson_friends_abstract+', BasePerson),\n+            ('BasePerson_friends_base+', BasePerson),\n+            ('BasePerson_friends_base+', BasePerson),\n+            ('BasePerson_m2m_abstract+', BasePerson),\n+            ('BasePerson_m2m_base+', BasePerson),\n+            ('Person_following_inherited+', None),\n+            ('Person_following_inherited+', None),\n+            ('Person_friends_inherited+', None),\n+            ('Person_friends_inherited+', None),\n+            ('Person_m2m_inherited+', None),\n+            ('Relating_basepeople+', BasePerson),\n+            ('Relating_basepeople_hidden+', BasePerson),\n+            ('Relating_people+', None),\n+            ('Relating_people_hidden+', None),\n+            ('relating_baseperson', BasePerson),\n+            ('relating_person', None),\n+            ('relating_proxyperson', None),\n+        ),\n+        Relation: (\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('+', None),\n+            ('BasePerson_m2m_abstract+', None),\n+            ('BasePerson_m2m_base+', None),\n+            ('Person_m2m_inherited+', None),\n+            ('fk_abstract_rel', None),\n+            ('fk_base_rel', None),\n+            ('fk_concrete_rel', None),\n+            ('fo_abstract_rel', None),\n+            ('fo_base_rel', None),\n+            ('fo_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_many_to_many_with_model_legacy': {\n+        BasePerson: (\n+            ('friends_abstract_rel_+', None),\n+            ('followers_abstract', None),\n+            ('friends_base_rel_+', None),\n+            ('followers_base', None),\n+            ('relating_basepeople', None),\n+            ('+', None),\n+        ),\n+        Person: (\n+            ('friends_abstract_rel_+', BasePerson),\n+            ('followers_abstract', BasePerson),\n+            ('friends_base_rel_+', BasePerson),\n+            ('followers_base', BasePerson),\n+            ('relating_basepeople', BasePerson),\n+            ('+', BasePerson),\n+            ('friends_inherited_rel_+', None),\n+            ('followers_concrete', None),\n+            ('relating_people', None),\n+            ('+', None),\n+        ),\n+        Relation: (\n+            ('m2m_abstract_rel', None),\n+            ('m2m_base_rel', None),\n+            ('m2m_concrete_rel', None),\n+        ),\n+    },\n+    'get_all_related_many_to_many_local_legacy': {\n+        BasePerson: [\n+            'friends_abstract_rel_+',\n+            'followers_abstract',\n+            'friends_base_rel_+',\n+            'followers_base',\n+            'relating_basepeople',\n+            '+',\n+        ],\n+        Person: [\n+            'friends_inherited_rel_+',\n+            'followers_concrete',\n+            'relating_people',\n+            '+',\n+        ],\n+        Relation: [\n+            'm2m_abstract_rel',\n+            'm2m_base_rel',\n+            'm2m_concrete_rel',\n+        ],\n+    },\n+    'virtual_fields': {\n+        AbstractPerson: [\n+            'generic_relation_abstract',\n+            'content_object_abstract',\n+        ],\n+        BasePerson: [\n+            'generic_relation_base',\n+            'content_object_base',\n+            'generic_relation_abstract',\n+            'content_object_abstract',\n+        ],\n+        Person: [\n+            'content_object_concrete',\n+            'generic_relation_concrete',\n+            'generic_relation_base',\n+            'content_object_base',\n+            'generic_relation_abstract',\n+            'content_object_abstract',\n+        ],\n+    },\n+}\ndiff --git a/tests/model_meta/test.py b/tests/model_meta/test.py\ndeleted file mode 100644\nindex ea861d5ad5b4..000000000000\n--- a/tests/model_meta/test.py\n+++ /dev/null\n@@ -1,661 +0,0 @@\n-from django import test\n-from django.contrib.contenttypes.fields import GenericRelation\n-from django.core.exceptions import FieldDoesNotExist\n-from django.db.models.fields import related, CharField, Field\n-\n-from .models import (\n-    AbstractPerson, BasePerson, Person, Relating, Relation\n-)\n-\n-TEST_RESULTS = {\n-    'fields': {\n-        Person: [\n-            'id',\n-            'data_abstract',\n-            'fk_abstract_id',\n-            'data_not_concrete_abstract',\n-            'content_type_abstract_id',\n-            'object_id_abstract',\n-            'data_base',\n-            'fk_base_id',\n-            'data_not_concrete_base',\n-            'content_type_base_id',\n-            'object_id_base',\n-            'baseperson_ptr_id',\n-            'data_inherited',\n-            'fk_inherited_id',\n-            'data_not_concrete_inherited',\n-            'content_type_concrete_id',\n-            'object_id_concrete',\n-        ],\n-        BasePerson: [\n-            'id',\n-            'data_abstract',\n-            'fk_abstract_id',\n-            'data_not_concrete_abstract',\n-            'content_type_abstract_id',\n-            'object_id_abstract',\n-            'data_base',\n-            'fk_base_id',\n-            'data_not_concrete_base',\n-            'content_type_base_id',\n-            'object_id_base',\n-        ],\n-        AbstractPerson: [\n-            'data_abstract',\n-            'fk_abstract_id',\n-            'data_not_concrete_abstract',\n-            'content_type_abstract_id',\n-            'object_id_abstract',\n-        ],\n-        Relating: [\n-            'id',\n-            'baseperson_id',\n-            'baseperson_hidden_id',\n-            'person_id',\n-            'person_hidden_id',\n-            'proxyperson_id',\n-            'proxyperson_hidden_id',\n-        ],\n-    },\n-    'local_fields': {\n-        Person: [\n-            'baseperson_ptr_id',\n-            'data_inherited',\n-            'fk_inherited_id',\n-            'data_not_concrete_inherited',\n-            'content_type_concrete_id',\n-            'object_id_concrete',\n-        ],\n-        BasePerson: [\n-            'id',\n-            'data_abstract',\n-            'fk_abstract_id',\n-            'data_not_concrete_abstract',\n-            'content_type_abstract_id',\n-            'object_id_abstract',\n-            'data_base',\n-            'fk_base_id',\n-            'data_not_concrete_base',\n-            'content_type_base_id',\n-            'object_id_base',\n-        ],\n-        AbstractPerson: [\n-            'data_abstract',\n-            'fk_abstract_id',\n-            'data_not_concrete_abstract',\n-            'content_type_abstract_id',\n-            'object_id_abstract',\n-        ],\n-        Relating: [\n-            'id',\n-            'baseperson_id',\n-            'baseperson_hidden_id',\n-            'person_id',\n-            'person_hidden_id',\n-            'proxyperson_id',\n-            'proxyperson_hidden_id',\n-        ],\n-    },\n-    'local_concrete_fields': {\n-        Person: [\n-            'baseperson_ptr_id',\n-            'data_inherited',\n-            'fk_inherited_id',\n-            'content_type_concrete_id',\n-            'object_id_concrete',\n-        ],\n-        BasePerson: [\n-            'id',\n-            'data_abstract',\n-            'fk_abstract_id',\n-            'content_type_abstract_id',\n-            'object_id_abstract',\n-            'data_base',\n-            'fk_base_id',\n-            'content_type_base_id',\n-            'object_id_base',\n-        ],\n-        AbstractPerson: [\n-            'data_abstract',\n-            'fk_abstract_id',\n-            'content_type_abstract_id',\n-            'object_id_abstract',\n-        ],\n-        Relating: [\n-            'id',\n-            'baseperson_id',\n-            'baseperson_hidden_id',\n-            'person_id',\n-            'person_hidden_id',\n-            'proxyperson_id',\n-            'proxyperson_hidden_id',\n-        ],\n-    },\n-    'many_to_many': {\n-        Person: [\n-            'm2m_abstract',\n-            'friends_abstract',\n-            'following_abstract',\n-            'm2m_base',\n-            'friends_base',\n-            'following_base',\n-            'm2m_inherited',\n-            'friends_inherited',\n-            'following_inherited',\n-        ],\n-        BasePerson: [\n-            'm2m_abstract',\n-            'friends_abstract',\n-            'following_abstract',\n-            'm2m_base',\n-            'friends_base',\n-            'following_base',\n-        ],\n-        AbstractPerson: [\n-            'm2m_abstract',\n-            'friends_abstract',\n-            'following_abstract',\n-        ],\n-        Relating: [\n-            'basepeople',\n-            'basepeople_hidden',\n-            'people',\n-            'people_hidden',\n-        ],\n-    },\n-    'many_to_many_with_model': {\n-        Person: [\n-            BasePerson,\n-            BasePerson,\n-            BasePerson,\n-            BasePerson,\n-            BasePerson,\n-            BasePerson,\n-            None,\n-            None,\n-            None,\n-        ],\n-        BasePerson: [\n-            None,\n-            None,\n-            None,\n-            None,\n-            None,\n-            None,\n-        ],\n-        AbstractPerson: [\n-            None,\n-            None,\n-            None,\n-        ],\n-        Relating: [\n-            None,\n-            None,\n-            None,\n-            None,\n-        ],\n-    },\n-    'get_all_related_objects_with_model': {\n-        Person: (\n-            ('relating_baseperson', BasePerson),\n-            ('relating_person', None),\n-        ),\n-        BasePerson: (\n-            ('person', None),\n-            ('relating_baseperson', None),\n-        ),\n-        Relation: (\n-            ('fk_abstract_rel', None),\n-            ('fo_abstract_rel', None),\n-            ('fk_base_rel', None),\n-            ('fo_base_rel', None),\n-            ('fk_concrete_rel', None),\n-            ('fo_concrete_rel', None),\n-        ),\n-    },\n-    'get_all_related_objects_with_model_local': {\n-        Person: (\n-            ('relating_person', None),\n-        ),\n-        BasePerson: (\n-            ('person', None),\n-            ('relating_baseperson', None)\n-        ),\n-        Relation: (\n-            ('fk_abstract_rel', None),\n-            ('fo_abstract_rel', None),\n-            ('fk_base_rel', None),\n-            ('fo_base_rel', None),\n-            ('fk_concrete_rel', None),\n-            ('fo_concrete_rel', None),\n-        ),\n-    },\n-    'get_all_related_objects_with_model_hidden': {\n-        BasePerson: (\n-            ('model_meta.baseperson_friends_base', None),\n-            ('model_meta.baseperson_friends_base', None),\n-            ('model_meta.baseperson_m2m_base', None),\n-            ('model_meta.baseperson_following_base', None),\n-            ('model_meta.baseperson_following_base', None),\n-            ('model_meta.baseperson_m2m_abstract', None),\n-            ('model_meta.baseperson_friends_abstract', None),\n-            ('model_meta.baseperson_friends_abstract', None),\n-            ('model_meta.baseperson_following_abstract', None),\n-            ('model_meta.baseperson_following_abstract', None),\n-            ('model_meta.person', None),\n-            ('model_meta.relating_basepeople', None),\n-            ('model_meta.relating_basepeople_hidden', None),\n-            ('model_meta.relating', None),\n-            ('model_meta.relating', None),\n-        ),\n-        Person: (\n-            ('model_meta.baseperson_friends_base', BasePerson),\n-            ('model_meta.baseperson_friends_base', BasePerson),\n-            ('model_meta.baseperson_m2m_base', BasePerson),\n-            ('model_meta.baseperson_following_base', BasePerson),\n-            ('model_meta.baseperson_following_base', BasePerson),\n-            ('model_meta.baseperson_m2m_abstract', BasePerson),\n-            ('model_meta.baseperson_friends_abstract', BasePerson),\n-            ('model_meta.baseperson_friends_abstract', BasePerson),\n-            ('model_meta.baseperson_following_abstract', BasePerson),\n-            ('model_meta.baseperson_following_abstract', BasePerson),\n-            ('model_meta.relating_basepeople', BasePerson),\n-            ('model_meta.relating_basepeople_hidden', BasePerson),\n-            ('model_meta.relating', BasePerson),\n-            ('model_meta.relating', BasePerson),\n-            ('model_meta.person_m2m_inherited', None),\n-            ('model_meta.person_friends_inherited', None),\n-            ('model_meta.person_friends_inherited', None),\n-            ('model_meta.person_following_inherited', None),\n-            ('model_meta.person_following_inherited', None),\n-            ('model_meta.relating_people', None),\n-            ('model_meta.relating_people_hidden', None),\n-            ('model_meta.relating', None),\n-            ('model_meta.relating', None),\n-        ),\n-        Relation: (\n-            ('model_meta.baseperson_m2m_base', None),\n-            ('model_meta.baseperson_m2m_abstract', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.person_m2m_inherited', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.proxyperson', None),\n-            ('model_meta.proxyperson', None),\n-            ('model_meta.proxyperson', None),\n-        ),\n-    },\n-    'get_all_related_objects_with_model_hidden_local': {\n-        BasePerson: (\n-            ('model_meta.baseperson_friends_base', None),\n-            ('model_meta.baseperson_friends_base', None),\n-            ('model_meta.baseperson_m2m_base', None),\n-            ('model_meta.baseperson_following_base', None),\n-            ('model_meta.baseperson_following_base', None),\n-            ('model_meta.baseperson_m2m_abstract', None),\n-            ('model_meta.baseperson_friends_abstract', None),\n-            ('model_meta.baseperson_friends_abstract', None),\n-            ('model_meta.baseperson_following_abstract', None),\n-            ('model_meta.baseperson_following_abstract', None),\n-            ('model_meta.person', None),\n-            ('model_meta.relating_basepeople', None),\n-            ('model_meta.relating_basepeople_hidden', None),\n-            ('model_meta.relating', None),\n-            ('model_meta.relating', None),\n-        ),\n-        Person: (\n-            ('model_meta.person_m2m_inherited', None),\n-            ('model_meta.person_friends_inherited', None),\n-            ('model_meta.person_friends_inherited', None),\n-            ('model_meta.person_following_inherited', None),\n-            ('model_meta.person_following_inherited', None),\n-            ('model_meta.relating_people', None),\n-            ('model_meta.relating_people_hidden', None),\n-            ('model_meta.relating', None),\n-            ('model_meta.relating', None),\n-        ),\n-        Relation: (\n-            ('model_meta.baseperson_m2m_base', None),\n-            ('model_meta.baseperson_m2m_abstract', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.person_m2m_inherited', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.proxyperson', None),\n-            ('model_meta.proxyperson', None),\n-            ('model_meta.proxyperson', None),\n-        ),\n-    },\n-    'get_all_related_objects_with_model_proxy': {\n-        BasePerson: (\n-            ('person', None),\n-            ('relating_baseperson', None),\n-        ),\n-        Person: (\n-            ('relating_baseperson', BasePerson),\n-            ('relating_person', None), ('relating_proxyperson', None),\n-        ),\n-        Relation: (\n-            ('fk_abstract_rel', None), ('fo_abstract_rel', None),\n-            ('fk_base_rel', None), ('fo_base_rel', None),\n-            ('fk_concrete_rel', None), ('fo_concrete_rel', None),\n-        ),\n-    },\n-    'get_all_related_objects_with_model_proxy_hidden': {\n-        BasePerson: (\n-            ('model_meta.baseperson_friends_base', None),\n-            ('model_meta.baseperson_friends_base', None),\n-            ('model_meta.baseperson_m2m_base', None),\n-            ('model_meta.baseperson_following_base', None),\n-            ('model_meta.baseperson_following_base', None),\n-            ('model_meta.baseperson_m2m_abstract', None),\n-            ('model_meta.baseperson_friends_abstract', None),\n-            ('model_meta.baseperson_friends_abstract', None),\n-            ('model_meta.baseperson_following_abstract', None),\n-            ('model_meta.baseperson_following_abstract', None),\n-            ('model_meta.person', None),\n-            ('model_meta.relating_basepeople', None),\n-            ('model_meta.relating_basepeople_hidden', None),\n-            ('model_meta.relating', None),\n-            ('model_meta.relating', None),\n-        ),\n-        Person: (\n-            ('model_meta.baseperson_friends_base', BasePerson),\n-            ('model_meta.baseperson_friends_base', BasePerson),\n-            ('model_meta.baseperson_m2m_base', BasePerson),\n-            ('model_meta.baseperson_following_base', BasePerson),\n-            ('model_meta.baseperson_following_base', BasePerson),\n-            ('model_meta.baseperson_m2m_abstract', BasePerson),\n-            ('model_meta.baseperson_friends_abstract', BasePerson),\n-            ('model_meta.baseperson_friends_abstract', BasePerson),\n-            ('model_meta.baseperson_following_abstract', BasePerson),\n-            ('model_meta.baseperson_following_abstract', BasePerson),\n-            ('model_meta.relating_basepeople', BasePerson),\n-            ('model_meta.relating_basepeople_hidden', BasePerson),\n-            ('model_meta.relating', BasePerson),\n-            ('model_meta.relating', BasePerson),\n-            ('model_meta.person_m2m_inherited', None),\n-            ('model_meta.person_friends_inherited', None),\n-            ('model_meta.person_friends_inherited', None),\n-            ('model_meta.person_following_inherited', None),\n-            ('model_meta.person_following_inherited', None),\n-            ('model_meta.relating_people', None),\n-            ('model_meta.relating_people_hidden', None),\n-            ('model_meta.relating', None),\n-            ('model_meta.relating', None),\n-            ('model_meta.relating', None),\n-            ('model_meta.relating', None),\n-        ),\n-        Relation: (\n-            ('model_meta.baseperson_m2m_base', None),\n-            ('model_meta.baseperson_m2m_abstract', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.baseperson', None),\n-            ('model_meta.person_m2m_inherited', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.person', None),\n-            ('model_meta.proxyperson', None),\n-            ('model_meta.proxyperson', None),\n-            ('model_meta.proxyperson', None),\n-        ),\n-    },\n-    'get_all_related_many_to_many_with_model': {\n-        BasePerson: (\n-            ('friends_abstract_rel_+', None),\n-            ('followers_abstract', None),\n-            ('friends_base_rel_+', None),\n-            ('followers_base', None),\n-            ('relating_basepeople', None),\n-            ('+', None),\n-        ),\n-        Person: (\n-            ('friends_abstract_rel_+', BasePerson),\n-            ('followers_abstract', BasePerson),\n-            ('friends_base_rel_+', BasePerson),\n-            ('followers_base', BasePerson),\n-            ('relating_basepeople', BasePerson),\n-            ('+', BasePerson),\n-            ('friends_inherited_rel_+', None),\n-            ('followers_concrete', None),\n-            ('relating_people', None),\n-            ('+', None),\n-        ),\n-        Relation: (\n-            ('m2m_abstract_rel', None),\n-            ('m2m_base_rel', None),\n-            ('m2m_concrete_rel', None),\n-        ),\n-    },\n-    'get_all_related_many_to_many_local': {\n-        BasePerson: [\n-            'friends_abstract_rel_+',\n-            'followers_abstract',\n-            'friends_base_rel_+',\n-            'followers_base',\n-            'relating_basepeople',\n-            '+',\n-        ],\n-        Person: [\n-            'friends_inherited_rel_+',\n-            'followers_concrete',\n-            'relating_people',\n-            '+',\n-        ],\n-        Relation: [\n-            'm2m_abstract_rel',\n-            'm2m_base_rel',\n-            'm2m_concrete_rel',\n-        ],\n-    },\n-    'virtual_fields': {\n-        AbstractPerson: [\n-            'generic_relation_abstract',\n-            'content_object_abstract',\n-        ],\n-        BasePerson: [\n-            'generic_relation_base',\n-            'content_object_base',\n-            'generic_relation_abstract',\n-            'content_object_abstract',\n-        ],\n-        Person: [\n-            'content_object_concrete',\n-            'generic_relation_concrete',\n-            'generic_relation_base',\n-            'content_object_base',\n-            'generic_relation_abstract',\n-            'content_object_abstract',\n-        ],\n-    },\n-}\n-\n-\n-class OptionsBaseTests(test.TestCase):\n-\n-    def _map_rq_names(self, res):\n-        return tuple((o.field.related_query_name(), m) for o, m in res)\n-\n-    def _map_names(self, res):\n-        return tuple((f.name, m) for f, m in res)\n-\n-\n-class DataTests(OptionsBaseTests):\n-\n-    def test_fields(self):\n-        for model, expected_result in TEST_RESULTS['fields'].items():\n-            fields = model._meta.fields\n-            self.assertEqual([f.attname for f in fields], expected_result)\n-\n-    def test_local_fields(self):\n-        is_data_field = lambda f: isinstance(f, Field) and not isinstance(f, related.ManyToManyField)\n-\n-        for model, expected_result in TEST_RESULTS['local_fields'].items():\n-            fields = model._meta.local_fields\n-            self.assertEqual([f.attname for f in fields], expected_result)\n-            self.assertTrue(all([f.model is model for f in fields]))\n-            self.assertTrue(all([is_data_field(f) for f in fields]))\n-\n-    def test_local_concrete_fields(self):\n-        for model, expected_result in TEST_RESULTS['local_concrete_fields'].items():\n-            fields = model._meta.local_concrete_fields\n-            self.assertEqual([f.attname for f in fields], expected_result)\n-            self.assertTrue(all([f.column is not None for f in fields]))\n-\n-\n-class M2MTests(OptionsBaseTests):\n-\n-    def test_many_to_many(self):\n-        for model, expected_result in TEST_RESULTS['many_to_many'].items():\n-            fields = model._meta.many_to_many\n-            self.assertEqual([f.attname for f in fields], expected_result)\n-            self.assertTrue(all([isinstance(f.rel, related.ManyToManyRel) for f in fields]))\n-\n-    def test_many_to_many_with_model(self):\n-        for model, expected_result in TEST_RESULTS['many_to_many_with_model'].items():\n-            models = [model for field, model in model._meta.get_m2m_with_model()]\n-            self.assertEqual(models, expected_result)\n-\n-\n-class RelatedObjectsTests(OptionsBaseTests):\n-    def setUp(self):\n-        self.key_name = lambda r: r[0]\n-\n-    def test_related_objects(self):\n-        result_key = 'get_all_related_objects_with_model'\n-        for model, expected in TEST_RESULTS[result_key].items():\n-            objects = model._meta.get_all_related_objects_with_model()\n-            self.assertEqual(self._map_rq_names(objects), expected)\n-\n-    def test_related_objects_local(self):\n-        result_key = 'get_all_related_objects_with_model_local'\n-        for model, expected in TEST_RESULTS[result_key].items():\n-            objects = model._meta.get_all_related_objects_with_model(local_only=True)\n-            self.assertEqual(self._map_rq_names(objects), expected)\n-\n-    def test_related_objects_include_hidden(self):\n-        result_key = 'get_all_related_objects_with_model_hidden'\n-        for model, expected in TEST_RESULTS[result_key].items():\n-            objects = model._meta.get_all_related_objects_with_model(include_hidden=True)\n-            self.assertEqual(\n-                sorted(self._map_names(objects), key=self.key_name),\n-                sorted(expected, key=self.key_name)\n-            )\n-\n-    def test_related_objects_include_hidden_local_only(self):\n-        result_key = 'get_all_related_objects_with_model_hidden_local'\n-        for model, expected in TEST_RESULTS[result_key].items():\n-            objects = model._meta.get_all_related_objects_with_model(\n-                include_hidden=True, local_only=True)\n-            self.assertEqual(\n-                sorted(self._map_names(objects), key=self.key_name),\n-                sorted(expected, key=self.key_name)\n-            )\n-\n-    def test_related_objects_proxy(self):\n-        result_key = 'get_all_related_objects_with_model_proxy'\n-        for model, expected in TEST_RESULTS[result_key].items():\n-            objects = model._meta.get_all_related_objects_with_model(\n-                include_proxy_eq=True)\n-            self.assertEqual(self._map_rq_names(objects), expected)\n-\n-    def test_related_objects_proxy_hidden(self):\n-        result_key = 'get_all_related_objects_with_model_proxy_hidden'\n-        for model, expected in TEST_RESULTS[result_key].items():\n-            objects = model._meta.get_all_related_objects_with_model(\n-                include_proxy_eq=True, include_hidden=True)\n-            self.assertEqual(\n-                sorted(self._map_names(objects), key=self.key_name),\n-                sorted(expected, key=self.key_name)\n-            )\n-\n-\n-class RelatedM2MTests(OptionsBaseTests):\n-\n-    def test_related_m2m_with_model(self):\n-        result_key = 'get_all_related_many_to_many_with_model'\n-        for model, expected in TEST_RESULTS[result_key].items():\n-            objects = model._meta.get_all_related_m2m_objects_with_model()\n-            self.assertEqual(self._map_rq_names(objects), expected)\n-\n-    def test_related_m2m_local_only(self):\n-        result_key = 'get_all_related_many_to_many_local'\n-        for model, expected in TEST_RESULTS[result_key].items():\n-            objects = model._meta.get_all_related_many_to_many_objects(local_only=True)\n-            self.assertEqual([o.field.related_query_name() for o in objects], expected)\n-\n-    def test_related_m2m_asymmetrical(self):\n-        m2m = Person._meta.many_to_many\n-        self.assertIn('following_base', [f.attname for f in m2m])\n-        related_m2m = Person._meta.get_all_related_many_to_many_objects()\n-        self.assertIn('followers_base', [o.field.related_query_name() for o in related_m2m])\n-\n-    def test_related_m2m_symmetrical(self):\n-        m2m = Person._meta.many_to_many\n-        self.assertIn('friends_base', [f.attname for f in m2m])\n-        related_m2m = Person._meta.get_all_related_many_to_many_objects()\n-        self.assertIn('friends_inherited_rel_+', [o.field.related_query_name() for o in related_m2m])\n-\n-\n-class VirtualFieldsTests(OptionsBaseTests):\n-\n-    def test_virtual_fields(self):\n-        for model, expected_names in TEST_RESULTS['virtual_fields'].items():\n-            objects = model._meta.virtual_fields\n-            self.assertEqual(sorted([f.name for f in objects]), sorted(expected_names))\n-\n-\n-class GetFieldByNameTests(OptionsBaseTests):\n-\n-    def test_get_data_field(self):\n-        field_info = Person._meta.get_field_by_name('data_abstract')\n-        self.assertEqual(field_info[1:], (BasePerson, True, False))\n-        self.assertIsInstance(field_info[0], CharField)\n-\n-    def test_get_m2m_field(self):\n-        field_info = Person._meta.get_field_by_name('m2m_base')\n-        self.assertEqual(field_info[1:], (BasePerson, True, True))\n-        self.assertIsInstance(field_info[0], related.ManyToManyField)\n-\n-    def test_get_related_object(self):\n-        field_info = Person._meta.get_field_by_name('relating_baseperson')\n-        self.assertEqual(field_info[1:], (BasePerson, False, False))\n-        self.assertIsInstance(field_info[0], related.ForeignObjectRel)\n-\n-    def test_get_related_m2m(self):\n-        field_info = Person._meta.get_field_by_name('relating_people')\n-        self.assertEqual(field_info[1:], (None, False, True))\n-        self.assertIsInstance(field_info[0], related.ForeignObjectRel)\n-\n-    def test_get_generic_foreign_key(self):\n-        # For historic reasons generic foreign keys aren't available.\n-        with self.assertRaises(FieldDoesNotExist):\n-            Person._meta.get_field_by_name('content_object_base')\n-\n-    def test_get_generic_relation(self):\n-        field_info = Person._meta.get_field_by_name('generic_relation_base')\n-        self.assertEqual(field_info[1:], (None, True, False))\n-        self.assertIsInstance(field_info[0], GenericRelation)\ndiff --git a/tests/model_meta/test_legacy.py b/tests/model_meta/test_legacy.py\nnew file mode 100644\nindex 000000000000..60bfb1641ff4\n--- /dev/null\n+++ b/tests/model_meta/test_legacy.py\n@@ -0,0 +1,166 @@\n+import warnings\n+\n+from django import test\n+from django.contrib.contenttypes.fields import GenericRelation\n+from django.core.exceptions import FieldDoesNotExist\n+from django.db.models.fields import related, CharField\n+from django.utils.deprecation import RemovedInDjango20Warning\n+\n+from .models import BasePerson, Person\n+from .results import TEST_RESULTS\n+\n+\n+class OptionsBaseTests(test.TestCase):\n+\n+    def _map_related_query_names(self, res):\n+        return tuple((o.field.related_query_name(), m) for o, m in res)\n+\n+    def _map_names(self, res):\n+        return tuple((f.name, m) for f, m in res)\n+\n+\n+class M2MTests(OptionsBaseTests):\n+\n+    def test_many_to_many_with_model(self):\n+        for model, expected_result in TEST_RESULTS['many_to_many_with_model'].items():\n+            with warnings.catch_warnings(record=True) as warning:\n+                warnings.simplefilter(\"always\")\n+                models = [model for field, model in model._meta.get_m2m_with_model()]\n+                self.assertEqual([RemovedInDjango20Warning], [w.message.__class__ for w in warning])\n+            self.assertEqual(models, expected_result)\n+\n+\n+@test.ignore_warnings(category=RemovedInDjango20Warning)\n+class RelatedObjectsTests(OptionsBaseTests):\n+    key_name = lambda self, r: r[0]\n+\n+    def test_related_objects(self):\n+        result_key = 'get_all_related_objects_with_model_legacy'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = model._meta.get_all_related_objects_with_model()\n+            self.assertEqual(self._map_related_query_names(objects), expected)\n+\n+    def test_related_objects_local(self):\n+        result_key = 'get_all_related_objects_with_model_local_legacy'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = model._meta.get_all_related_objects_with_model(local_only=True)\n+            self.assertEqual(self._map_related_query_names(objects), expected)\n+\n+    def test_related_objects_include_hidden(self):\n+        result_key = 'get_all_related_objects_with_model_hidden_legacy'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = model._meta.get_all_related_objects_with_model(include_hidden=True)\n+            self.assertEqual(\n+                sorted(self._map_names(objects), key=self.key_name),\n+                sorted(expected, key=self.key_name)\n+            )\n+\n+    def test_related_objects_include_hidden_local_only(self):\n+        result_key = 'get_all_related_objects_with_model_hidden_local_legacy'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = model._meta.get_all_related_objects_with_model(\n+                include_hidden=True, local_only=True)\n+            self.assertEqual(\n+                sorted(self._map_names(objects), key=self.key_name),\n+                sorted(expected, key=self.key_name)\n+            )\n+\n+    def test_related_objects_proxy(self):\n+        result_key = 'get_all_related_objects_with_model_proxy_legacy'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = model._meta.get_all_related_objects_with_model(\n+                include_proxy_eq=True)\n+            self.assertEqual(self._map_related_query_names(objects), expected)\n+\n+    def test_related_objects_proxy_hidden(self):\n+        result_key = 'get_all_related_objects_with_model_proxy_hidden_legacy'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = model._meta.get_all_related_objects_with_model(\n+                include_proxy_eq=True, include_hidden=True)\n+            self.assertEqual(\n+                sorted(self._map_names(objects), key=self.key_name),\n+                sorted(expected, key=self.key_name)\n+            )\n+\n+\n+@test.ignore_warnings(category=RemovedInDjango20Warning)\n+class RelatedM2MTests(OptionsBaseTests):\n+\n+    def test_related_m2m_with_model(self):\n+        result_key = 'get_all_related_many_to_many_with_model_legacy'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = model._meta.get_all_related_m2m_objects_with_model()\n+            self.assertEqual(self._map_related_query_names(objects), expected)\n+\n+    def test_related_m2m_local_only(self):\n+        result_key = 'get_all_related_many_to_many_local_legacy'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = model._meta.get_all_related_many_to_many_objects(local_only=True)\n+            self.assertEqual([o.field.related_query_name() for o in objects], expected)\n+\n+    def test_related_m2m_asymmetrical(self):\n+        m2m = Person._meta.many_to_many\n+        self.assertTrue('following_base' in [f.attname for f in m2m])\n+        related_m2m = Person._meta.get_all_related_many_to_many_objects()\n+        self.assertTrue('followers_base' in [o.field.related_query_name() for o in related_m2m])\n+\n+    def test_related_m2m_symmetrical(self):\n+        m2m = Person._meta.many_to_many\n+        self.assertTrue('friends_base' in [f.attname for f in m2m])\n+        related_m2m = Person._meta.get_all_related_many_to_many_objects()\n+        self.assertIn('friends_inherited_rel_+', [o.field.related_query_name() for o in related_m2m])\n+\n+\n+@test.ignore_warnings(category=RemovedInDjango20Warning)\n+class GetFieldByNameTests(OptionsBaseTests):\n+\n+    def test_get_data_field(self):\n+        field_info = Person._meta.get_field_by_name('data_abstract')\n+        self.assertEqual(field_info[1:], (BasePerson, True, False))\n+        self.assertIsInstance(field_info[0], CharField)\n+\n+    def test_get_m2m_field(self):\n+        field_info = Person._meta.get_field_by_name('m2m_base')\n+        self.assertEqual(field_info[1:], (BasePerson, True, True))\n+        self.assertIsInstance(field_info[0], related.ManyToManyField)\n+\n+    def test_get_related_object(self):\n+        field_info = Person._meta.get_field_by_name('relating_baseperson')\n+        self.assertEqual(field_info[1:], (BasePerson, False, False))\n+        self.assertTrue(field_info[0].auto_created)\n+\n+    def test_get_related_m2m(self):\n+        field_info = Person._meta.get_field_by_name('relating_people')\n+        self.assertEqual(field_info[1:], (None, False, True))\n+        self.assertTrue(field_info[0].auto_created)\n+\n+    def test_get_generic_relation(self):\n+        field_info = Person._meta.get_field_by_name('generic_relation_base')\n+        self.assertEqual(field_info[1:], (None, True, False))\n+        self.assertIsInstance(field_info[0], GenericRelation)\n+\n+    def test_get_m2m_field_invalid(self):\n+        with warnings.catch_warnings(record=True) as warning:\n+            warnings.simplefilter(\"always\")\n+            self.assertRaises(\n+                FieldDoesNotExist,\n+                Person._meta.get_field,\n+                **{'field_name': 'm2m_base', 'many_to_many': False}\n+            )\n+            self.assertEqual(Person._meta.get_field('m2m_base', many_to_many=True).name, 'm2m_base')\n+\n+            # 2 RemovedInDjango20Warning messages should be raised, one for each call of get_field()\n+            # with the 'many_to_many' argument.\n+            self.assertEqual(\n+                [RemovedInDjango20Warning, RemovedInDjango20Warning],\n+                [w.message.__class__ for w in warning]\n+            )\n+\n+\n+@test.ignore_warnings(category=RemovedInDjango20Warning)\n+class GetAllFieldNamesTestCase(OptionsBaseTests):\n+\n+    def test_get_all_field_names(self):\n+        for model, expected_names in TEST_RESULTS['get_all_field_names'].items():\n+            objects = model._meta.get_all_field_names()\n+            self.assertEqual(sorted(map(str, objects)), sorted(expected_names))\ndiff --git a/tests/model_meta/tests.py b/tests/model_meta/tests.py\nnew file mode 100644\nindex 000000000000..31ffa4ac9383\n--- /dev/null\n+++ b/tests/model_meta/tests.py\n@@ -0,0 +1,247 @@\n+from django.apps import apps\n+from django.contrib.contenttypes.fields import GenericForeignKey, GenericRelation\n+from django.core.exceptions import FieldDoesNotExist\n+from django.db.models.fields import related, CharField, Field\n+from django.db.models.options import IMMUTABLE_WARNING, EMPTY_RELATION_TREE\n+from django.test import TestCase\n+\n+from .models import Relation, AbstractPerson, BasePerson, Person, ProxyPerson, Relating\n+from .results import TEST_RESULTS\n+\n+\n+class OptionsBaseTests(TestCase):\n+\n+    def _map_related_query_names(self, res):\n+        return tuple((o.name, m) for o, m in res)\n+\n+    def _map_names(self, res):\n+        return tuple((f.name, m) for f, m in res)\n+\n+    def _model(self, current_model, field):\n+        model = field.model._meta.concrete_model\n+        return None if model == current_model else model\n+\n+    def _details(self, current_model, relation):\n+        direct = isinstance(relation, Field) or isinstance(relation, GenericForeignKey)\n+        model = relation.model._meta.concrete_model\n+        if model == current_model:\n+            model = None\n+\n+        field = relation if direct else relation.field\n+        m2m = isinstance(field, related.ManyToManyField)\n+        return relation, model, direct, m2m\n+\n+\n+class GetFieldsTests(OptionsBaseTests):\n+\n+    def test_get_fields_is_immutable(self):\n+        msg = IMMUTABLE_WARNING % \"get_fields()\"\n+        for _ in range(2):\n+            # Running unit test twice to ensure both non-cached and cached result\n+            # are immutable.\n+            fields = Person._meta.get_fields()\n+            with self.assertRaisesMessage(AttributeError, msg):\n+                fields += [\"errors\"]\n+\n+\n+class DataTests(OptionsBaseTests):\n+\n+    def test_fields(self):\n+        for model, expected_result in TEST_RESULTS['fields'].items():\n+            fields = model._meta.fields\n+            self.assertEqual([f.attname for f in fields], expected_result)\n+\n+    def test_local_fields(self):\n+        is_data_field = lambda f: isinstance(f, Field) and not isinstance(f, related.ManyToManyField)\n+\n+        for model, expected_result in TEST_RESULTS['local_fields'].items():\n+            fields = model._meta.local_fields\n+            self.assertEqual([f.attname for f in fields], expected_result)\n+            for f in fields:\n+                self.assertEqual(f.model, model)\n+                self.assertTrue(is_data_field(f))\n+\n+    def test_local_concrete_fields(self):\n+        for model, expected_result in TEST_RESULTS['local_concrete_fields'].items():\n+            fields = model._meta.local_concrete_fields\n+            self.assertEqual([f.attname for f in fields], expected_result)\n+            for f in fields:\n+                self.assertIsNotNone(f.column)\n+\n+\n+class M2MTests(OptionsBaseTests):\n+\n+    def test_many_to_many(self):\n+        for model, expected_result in TEST_RESULTS['many_to_many'].items():\n+            fields = model._meta.many_to_many\n+            self.assertEqual([f.attname for f in fields], expected_result)\n+            for f in fields:\n+                self.assertTrue(f.many_to_many and f.is_relation)\n+\n+    def test_many_to_many_with_model(self):\n+        for model, expected_result in TEST_RESULTS['many_to_many_with_model'].items():\n+            models = [self._model(model, field) for field in model._meta.many_to_many]\n+            self.assertEqual(models, expected_result)\n+\n+\n+class RelatedObjectsTests(OptionsBaseTests):\n+    key_name = lambda self, r: r[0]\n+\n+    def test_related_objects(self):\n+        result_key = 'get_all_related_objects_with_model'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = [\n+                (field, self._model(model, field))\n+                for field in model._meta.get_fields()\n+                if field.auto_created and not field.concrete\n+            ]\n+            self.assertEqual(self._map_related_query_names(objects), expected)\n+\n+    def test_related_objects_local(self):\n+        result_key = 'get_all_related_objects_with_model_local'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = [\n+                (field, self._model(model, field))\n+                for field in model._meta.get_fields(include_parents=False)\n+                if field.auto_created and not field.concrete\n+            ]\n+            self.assertEqual(self._map_related_query_names(objects), expected)\n+\n+    def test_related_objects_include_hidden(self):\n+        result_key = 'get_all_related_objects_with_model_hidden'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = [\n+                (field, self._model(model, field))\n+                for field in model._meta.get_fields(include_hidden=True)\n+                if field.auto_created and not field.concrete\n+            ]\n+            self.assertEqual(\n+                sorted(self._map_names(objects), key=self.key_name),\n+                sorted(expected, key=self.key_name)\n+            )\n+\n+    def test_related_objects_include_hidden_local_only(self):\n+        result_key = 'get_all_related_objects_with_model_hidden_local'\n+        for model, expected in TEST_RESULTS[result_key].items():\n+            objects = [\n+                (field, self._model(model, field))\n+                for field in model._meta.get_fields(include_hidden=True, include_parents=False)\n+                if field.auto_created and not field.concrete\n+            ]\n+            self.assertEqual(\n+                sorted(self._map_names(objects), key=self.key_name),\n+                sorted(expected, key=self.key_name)\n+            )\n+\n+\n+class VirtualFieldsTests(OptionsBaseTests):\n+\n+    def test_virtual_fields(self):\n+        for model, expected_names in TEST_RESULTS['virtual_fields'].items():\n+            objects = model._meta.virtual_fields\n+            self.assertEqual(sorted([f.name for f in objects]), sorted(expected_names))\n+\n+\n+class GetFieldByNameTests(OptionsBaseTests):\n+\n+    def test_get_data_field(self):\n+        field_info = self._details(Person, Person._meta.get_field('data_abstract'))\n+        self.assertEqual(field_info[1:], (BasePerson, True, False))\n+        self.assertIsInstance(field_info[0], CharField)\n+\n+    def test_get_m2m_field(self):\n+        field_info = self._details(Person, Person._meta.get_field('m2m_base'))\n+        self.assertEqual(field_info[1:], (BasePerson, True, True))\n+        self.assertIsInstance(field_info[0], related.ManyToManyField)\n+\n+    def test_get_related_object(self):\n+        field_info = self._details(Person, Person._meta.get_field('relating_baseperson'))\n+        self.assertEqual(field_info[1:], (BasePerson, False, False))\n+        self.assertIsInstance(field_info[0], related.ForeignObjectRel)\n+\n+    def test_get_related_m2m(self):\n+        field_info = self._details(Person, Person._meta.get_field('relating_people'))\n+        self.assertEqual(field_info[1:], (None, False, True))\n+        self.assertIsInstance(field_info[0], related.ForeignObjectRel)\n+\n+    def test_get_generic_relation(self):\n+        field_info = self._details(Person, Person._meta.get_field('generic_relation_base'))\n+        self.assertEqual(field_info[1:], (None, True, False))\n+        self.assertIsInstance(field_info[0], GenericRelation)\n+\n+    def test_get_fields_only_searaches_forward_on_apps_not_ready(self):\n+        opts = Person._meta\n+        # If apps registry is not ready, get_field() searches over only\n+        # forward fields.\n+        opts.apps.ready = False\n+        try:\n+            # 'data_abstract' is a forward field, and therefore will be found\n+            self.assertTrue(opts.get_field('data_abstract'))\n+            msg = (\n+                \"Person has no field named 'relating_baseperson'. The app \"\n+                \"cache isn't ready yet, so if this is a forward field, it \"\n+                \"won't be available yet.\"\n+            )\n+            # 'data_abstract' is a reverse field, and will raise an exception\n+            with self.assertRaisesMessage(FieldDoesNotExist, msg):\n+                opts.get_field('relating_baseperson')\n+        finally:\n+            opts.apps.ready = True\n+\n+\n+class RelationTreeTests(TestCase):\n+    all_models = (Relation, AbstractPerson, BasePerson, Person, ProxyPerson, Relating)\n+\n+    def setUp(self):\n+        apps.clear_cache()\n+\n+    def test_clear_cache_clears_relation_tree(self):\n+        # The apps.clear_cache is setUp() should have deleted all trees.\n+        # Exclude abstract models that are not included in the Apps registry\n+        # and have no cache.\n+        all_models_with_cache = (m for m in self.all_models if not m._meta.abstract)\n+        for m in all_models_with_cache:\n+            self.assertNotIn('_relation_tree', m._meta.__dict__)\n+\n+    def test_first_relation_tree_access_populates_all(self):\n+        # On first access, relation tree should have populated cache.\n+        self.assertTrue(self.all_models[0]._meta._relation_tree)\n+\n+        # AbstractPerson does not have any relations, so relation_tree\n+        # should just return an EMPTY_RELATION_TREE.\n+        self.assertEqual(AbstractPerson._meta._relation_tree, EMPTY_RELATION_TREE)\n+\n+        # All the other models should already have their relation tree\n+        # in the internal __dict__ .\n+        all_models_but_abstractperson = (m for m in self.all_models if m is not AbstractPerson)\n+        for m in all_models_but_abstractperson:\n+            self.assertIn('_relation_tree', m._meta.__dict__)\n+\n+    def test_relations_related_objects(self):\n+        # Testing non hidden related objects\n+        self.assertEqual(\n+            sorted([field.related_query_name() for field in Relation._meta._relation_tree\n+                   if not field.rel.field.rel.is_hidden()]),\n+            sorted([\n+                'fk_abstract_rel', 'fk_abstract_rel', 'fk_abstract_rel', 'fk_base_rel', 'fk_base_rel',\n+                'fk_base_rel', 'fk_concrete_rel', 'fk_concrete_rel', 'fo_abstract_rel', 'fo_abstract_rel',\n+                'fo_abstract_rel', 'fo_base_rel', 'fo_base_rel', 'fo_base_rel', 'fo_concrete_rel',\n+                'fo_concrete_rel', 'm2m_abstract_rel', 'm2m_abstract_rel', 'm2m_abstract_rel',\n+                'm2m_base_rel', 'm2m_base_rel', 'm2m_base_rel', 'm2m_concrete_rel', 'm2m_concrete_rel',\n+            ])\n+        )\n+        # Testing hidden related objects\n+        self.assertEqual(\n+            sorted([field.related_query_name() for field in BasePerson._meta._relation_tree]),\n+            sorted([\n+                '+', '+', 'BasePerson_following_abstract+', 'BasePerson_following_abstract+',\n+                'BasePerson_following_base+', 'BasePerson_following_base+', 'BasePerson_friends_abstract+',\n+                'BasePerson_friends_abstract+', 'BasePerson_friends_base+', 'BasePerson_friends_base+',\n+                'BasePerson_m2m_abstract+', 'BasePerson_m2m_base+', 'Relating_basepeople+',\n+                'Relating_basepeople_hidden+', 'followers_abstract', 'followers_abstract', 'followers_abstract',\n+                'followers_base', 'followers_base', 'followers_base', 'friends_abstract_rel_+', 'friends_abstract_rel_+',\n+                'friends_abstract_rel_+', 'friends_base_rel_+', 'friends_base_rel_+', 'friends_base_rel_+', 'person',\n+                'person', 'relating_basepeople', 'relating_baseperson',\n+            ])\n+        )\n+        self.assertEqual([field.related_query_name() for field in AbstractPerson._meta._relation_tree], [])\ndiff --git a/tests/queries/tests.py b/tests/queries/tests.py\nindex aed122a7c13b..900149b873a0 100644\n--- a/tests/queries/tests.py\n+++ b/tests/queries/tests.py\n@@ -2093,7 +2093,7 @@ def test_no_fields_cloning(self):\n         testing is impossible, this is a sanity check against invalid use of\n         deepcopy. refs #16759.\n         \"\"\"\n-        opts_class = type(Note._meta.get_field_by_name(\"misc\")[0])\n+        opts_class = type(Note._meta.get_field(\"misc\"))\n         note_deepcopy = getattr(opts_class, \"__deepcopy__\", None)\n         opts_class.__deepcopy__ = lambda obj, memo: self.fail(\"Model fields shouldn't be cloned\")\n         try:\ndiff --git a/tests/queryset_pickle/tests.py b/tests/queryset_pickle/tests.py\nindex 22b61199f474..91fe304f9d80 100644\n--- a/tests/queryset_pickle/tests.py\n+++ b/tests/queryset_pickle/tests.py\n@@ -79,7 +79,7 @@ def test_model_pickle_m2m(self):\n         m1 = M2MModel.objects.create()\n         g1 = Group.objects.create(name='foof')\n         m1.groups.add(g1)\n-        m2m_through = M2MModel._meta.get_field_by_name('groups')[0].rel.through\n+        m2m_through = M2MModel._meta.get_field('groups').rel.through\n         original = m2m_through.objects.get()\n         dumped = pickle.dumps(original)\n         reloaded = pickle.loads(dumped)\ndiff --git a/tests/schema/tests.py b/tests/schema/tests.py\nindex e9de2131a967..b10ad07251b0 100644\n--- a/tests/schema/tests.py\n+++ b/tests/schema/tests.py\n@@ -138,7 +138,7 @@ def test_fk(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Book,\n-                Book._meta.get_field_by_name(\"author\")[0],\n+                Book._meta.get_field(\"author\"),\n                 new_field,\n                 strict=True,\n             )\n@@ -393,7 +393,7 @@ def test_alter(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Author,\n-                Author._meta.get_field_by_name(\"name\")[0],\n+                Author._meta.get_field(\"name\"),\n                 new_field,\n                 strict=True,\n             )\n@@ -424,7 +424,7 @@ def test_alter_text_field(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Note,\n-                Note._meta.get_field_by_name(\"info\")[0],\n+                Note._meta.get_field(\"info\"),\n                 new_field,\n                 strict=True,\n             )\n@@ -451,7 +451,7 @@ def test_alter_null_to_not_null(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Author,\n-                Author._meta.get_field_by_name(\"height\")[0],\n+                Author._meta.get_field(\"height\"),\n                 new_field\n             )\n         # Ensure the field is right afterwards\n@@ -479,7 +479,7 @@ def test_alter_null_to_not_null_keeping_default(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 AuthorWithDefaultHeight,\n-                AuthorWithDefaultHeight._meta.get_field_by_name(\"height\")[0],\n+                AuthorWithDefaultHeight._meta.get_field(\"height\"),\n                 new_field,\n             )\n         # Ensure the field is right afterwards\n@@ -512,7 +512,7 @@ def test_alter_fk(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Book,\n-                Book._meta.get_field_by_name(\"author\")[0],\n+                Book._meta.get_field(\"author\"),\n                 new_field,\n                 strict=True,\n             )\n@@ -542,7 +542,7 @@ def test_alter_implicit_id_to_explicit(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Author,\n-                Author._meta.get_field_by_name(\"id\")[0],\n+                Author._meta.get_field(\"id\"),\n                 new_field,\n                 strict=True,\n             )\n@@ -568,7 +568,7 @@ def test_rename(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Author,\n-                Author._meta.get_field_by_name(\"name\")[0],\n+                Author._meta.get_field(\"name\"),\n                 new_field,\n                 strict=True,\n             )\n@@ -587,7 +587,7 @@ def test_m2m_create(self):\n             editor.create_model(TagM2MTest)\n             editor.create_model(BookWithM2M)\n         # Ensure there is now an m2m table there\n-        columns = self.column_classes(BookWithM2M._meta.get_field_by_name(\"tags\")[0].rel.through)\n+        columns = self.column_classes(BookWithM2M._meta.get_field(\"tags\").rel.through)\n         self.assertEqual(columns['tagm2mtest_id'][0], \"IntegerField\")\n \n     def test_m2m_create_through(self):\n@@ -661,7 +661,7 @@ def test_m2m_through_alter(self):\n         self.assertEqual(len(self.column_classes(AuthorTag)), 3)\n         # \"Alter\" the field's blankness. This should not actually do anything.\n         with connection.schema_editor() as editor:\n-            old_field = AuthorWithM2MThrough._meta.get_field_by_name(\"tags\")[0]\n+            old_field = AuthorWithM2MThrough._meta.get_field(\"tags\")\n             new_field = ManyToManyField(\"schema.TagM2MTest\", related_name=\"authors\", through=\"AuthorTag\")\n             new_field.contribute_to_class(AuthorWithM2MThrough, \"tags\")\n             editor.alter_field(\n@@ -683,7 +683,7 @@ def test_m2m_repoint(self):\n             editor.create_model(TagM2MTest)\n             editor.create_model(UniqueTest)\n         # Ensure the M2M exists and points to TagM2MTest\n-        constraints = self.get_constraints(BookWithM2M._meta.get_field_by_name(\"tags\")[0].rel.through._meta.db_table)\n+        constraints = self.get_constraints(BookWithM2M._meta.get_field(\"tags\").rel.through._meta.db_table)\n         if connection.features.supports_foreign_keys:\n             for name, details in constraints.items():\n                 if details['columns'] == [\"tagm2mtest_id\"] and details['foreign_key']:\n@@ -698,11 +698,11 @@ def test_m2m_repoint(self):\n             with connection.schema_editor() as editor:\n                 editor.alter_field(\n                     Author,\n-                    BookWithM2M._meta.get_field_by_name(\"tags\")[0],\n+                    BookWithM2M._meta.get_field(\"tags\"),\n                     new_field,\n                 )\n             # Ensure old M2M is gone\n-            self.assertRaises(DatabaseError, self.column_classes, BookWithM2M._meta.get_field_by_name(\"tags\")[0].rel.through)\n+            self.assertRaises(DatabaseError, self.column_classes, BookWithM2M._meta.get_field(\"tags\").rel.through)\n             # Ensure the new M2M exists and points to UniqueTest\n             constraints = self.get_constraints(new_field.rel.through._meta.db_table)\n             if connection.features.supports_foreign_keys:\n@@ -715,10 +715,10 @@ def test_m2m_repoint(self):\n         finally:\n             # Cleanup through table separately\n             with connection.schema_editor() as editor:\n-                editor.remove_field(BookWithM2M, BookWithM2M._meta.get_field_by_name(\"uniques\")[0])\n+                editor.remove_field(BookWithM2M, BookWithM2M._meta.get_field(\"uniques\"))\n             # Cleanup model states\n             BookWithM2M._meta.local_many_to_many.remove(new_field)\n-            del BookWithM2M._meta._m2m_cache\n+            BookWithM2M._meta._expire_cache()\n \n     @unittest.skipUnless(connection.features.supports_column_check_constraints, \"No check constraints\")\n     def test_check_constraints(self):\n@@ -741,7 +741,7 @@ def test_check_constraints(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Author,\n-                Author._meta.get_field_by_name(\"height\")[0],\n+                Author._meta.get_field(\"height\"),\n                 new_field,\n                 strict=True,\n             )\n@@ -754,7 +754,7 @@ def test_check_constraints(self):\n             editor.alter_field(\n                 Author,\n                 new_field,\n-                Author._meta.get_field_by_name(\"height\")[0],\n+                Author._meta.get_field(\"height\"),\n                 strict=True,\n             )\n         constraints = self.get_constraints(Author._meta.db_table)\n@@ -781,7 +781,7 @@ def test_unique(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Tag,\n-                Tag._meta.get_field_by_name(\"slug\")[0],\n+                Tag._meta.get_field(\"slug\"),\n                 new_field,\n                 strict=True,\n             )\n@@ -809,8 +809,8 @@ def test_unique(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Tag,\n-                Tag._meta.get_field_by_name(\"slug\")[0],\n-                TagUniqueRename._meta.get_field_by_name(\"slug2\")[0],\n+                Tag._meta.get_field(\"slug\"),\n+                TagUniqueRename._meta.get_field(\"slug2\"),\n                 strict=True,\n             )\n         # Ensure the field is still unique\n@@ -976,7 +976,7 @@ def test_indexes(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 Book,\n-                Book._meta.get_field_by_name(\"title\")[0],\n+                Book._meta.get_field(\"title\"),\n                 new_field,\n                 strict=True,\n             )\n@@ -990,7 +990,7 @@ def test_indexes(self):\n             editor.alter_field(\n                 Book,\n                 new_field,\n-                Book._meta.get_field_by_name(\"title\")[0],\n+                Book._meta.get_field(\"title\"),\n                 strict=True,\n             )\n         # Ensure the table is there and has the index again\n@@ -1002,7 +1002,7 @@ def test_indexes(self):\n         with connection.schema_editor() as editor:\n             editor.add_field(\n                 Book,\n-                BookWithSlug._meta.get_field_by_name(\"slug\")[0],\n+                BookWithSlug._meta.get_field(\"slug\"),\n             )\n         self.assertIn(\n             \"slug\",\n@@ -1014,7 +1014,7 @@ def test_indexes(self):\n         with connection.schema_editor() as editor:\n             editor.alter_field(\n                 BookWithSlug,\n-                BookWithSlug._meta.get_field_by_name(\"slug\")[0],\n+                BookWithSlug._meta.get_field(\"slug\"),\n                 new_field2,\n                 strict=True,\n             )\n@@ -1039,10 +1039,10 @@ def test_primary_key(self):\n         new_field.set_attributes_from_name(\"slug\")\n         new_field.model = Tag\n         with connection.schema_editor() as editor:\n-            editor.remove_field(Tag, Tag._meta.get_field_by_name(\"id\")[0])\n+            editor.remove_field(Tag, Tag._meta.get_field(\"id\"))\n             editor.alter_field(\n                 Tag,\n-                Tag._meta.get_field_by_name(\"slug\")[0],\n+                Tag._meta.get_field(\"slug\"),\n                 new_field,\n             )\n         # Ensure the PK changed\n",
    "diff_length": 248741
  },
  {
    "index": 9,
    "filtered_comments": [
      "> > djangoci uses MariaDB 10.1.40. I can bump MariaDB version in the next few days. We need to remember that Django 3.0 supports MariaDB 10.1 and higher so a new db feature is required e.g. has_json_field.\r\n> \r\n> How about `supports_json` ? It's not really a separate data type on SQLite or MariaDB.\r\n\r\nIt is also not a separate field on Oracle, but a feature flag will determine if backend has JSON field or not, so ... :thinking:   ",
      "> @laymonage I updated MariaDB to 10.2.24 on Jenkins.\r\n\r\nThanks! As expected, the tests have passed now.\r\n\r\nI have added a `supports_json` feature (can be renamed if desired). Not sure if I should check the SQLite version, though. I don't think there's any way to check if the JSON1 extension is enabled (maybe we could try to do `SELECT json('\"test\"')`, but that's a bit hack-ish).\r\nThe JSON1 extension was introduced with the release of SQLite 3.9.0. However, since it's a loadable extension, it *might* work if it's loaded on older SQLite version(s). I haven't tried.\r\n\r\nAlso, I'm not sure if I should use `check` and extend the list returned by that method instead of raising a `NotSupportedError`. I've seen both examples in the existing codebase.",
      "> I have added a supports_json feature (can be renamed if desired). Not sure if I should check the SQLite version, though. I don't think there's any way to check if the JSON1 extension is enabled (maybe we could try to do SELECT json('\"test\"'), but that's a bit hack-ish).\r\n> The JSON1 extension was introduced with the release of SQLite 3.9.0. However, since it's a loadable extension, it might work if it's loaded on older SQLite version(s). I haven't tried.\r\n\r\nI think trying the `json` function and catching the error isn't so bad, as long as it won't break any transactions.\r\n\r\nThe other option is to use `PRAGMA compile_options` and check if the extension is in there, however I am not sure if it's possible to load the `json1` extension without it being built in at compile time...\r\n\r\n```\r\nsqlite> PRAGMA compile_options;\r\nBUG_COMPATIBLE_20160819\r\nCOMPILER=clang-10.0.1\r\nDEFAULT_CACHE_SIZE=2000\r\nDEFAULT_CKPTFULLFSYNC\r\nDEFAULT_JOURNAL_SIZE_LIMIT=32768\r\nDEFAULT_PAGE_SIZE=4096\r\nDEFAULT_SYNCHRONOUS=2\r\nDEFAULT_WAL_SYNCHRONOUS=1\r\nENABLE_API_ARMOR\r\nENABLE_COLUMN_METADATA\r\nENABLE_DBSTAT_VTAB\r\nENABLE_FTS3\r\nENABLE_FTS3_PARENTHESIS\r\nENABLE_FTS3_TOKENIZER\r\nENABLE_FTS4\r\nENABLE_FTS5\r\nENABLE_JSON1\r\nENABLE_LOCKING_STYLE=1\r\nENABLE_PREUPDATE_HOOK\r\nENABLE_RTREE\r\nENABLE_SESSION\r\nENABLE_SNAPSHOT\r\nENABLE_SQLLOG\r\nENABLE_UNKNOWN_SQL_FUNCTION\r\nENABLE_UPDATE_DELETE_LIMIT\r\nHAVE_ISNAN\r\nMAX_LENGTH=2147483645\r\nMAX_MMAP_SIZE=1073741824\r\nMAX_VARIABLE_NUMBER=500000\r\nOMIT_AUTORESET\r\nOMIT_LOAD_EXTENSION\r\nSTMTJRNL_SPILL=131072\r\nTHREADSAFE=2\r\nUSE_URI\r\n```",
      "> I think trying the json function and catching the error isn't so bad, as long as it won't break any transactions.\r\n\r\nI'm not sure where and how to properly put it in Django's source code, though.\r\n\r\n---\r\n\r\nI tried compiling SQLite 3.28.0 without JSON1, compiling JSON1 separately, and loading it with the `.load` command.\r\n`SELECT JSON('\"test\"');` works, but `ENABLE_JSON1` doesn't show up with `PRAGMA compile_options` (which is correct since I didn't build JSON1 along with SQLite).\r\n\r\nOn the other hand, I also tried loading JSON1 (compiled from SQLite 3.28.0 source code) on SQLite 3.8.7.1 (what's available on Debian Jessie). This SQLite version supports extension loading, but I got a segmentation fault when I tried to load JSON1. So, I guess it needs SQLite 3.9.0 and up.\r\n\r\nBy the way... JSON1 is also enabled by default if SQLite is compiled using `make` with the amalgamation and the given configurations.",
      "> > I'm not sure where and how to properly put it in Django's source code, though.\r\n> \r\n> You can use a `@cached_property` for the feature, for example https://github.com/django/django/blob/master/django/db/backends/mysql/features.py#L110\r\n\r\nYeah, I've used it in my `supports_json` DB feature. What I mean is, should I do something like this?\r\n\r\n```python\r\ntry:\r\n    with self.connection.cursor() as cursor:\r\n        cursor.execute(\"SELECT JSON('\\\"test\\\"')\r\nexcept DatabaseError:\r\n    return False\r\nelse:\r\n    return True\r\n```",
      "> No, `json.dumps` and `json.loads` take `None` as the default argument for the `cls` parameter. See https://docs.python.org/3/library/json.html#json.dumps.\r\n\r\nActually, I didn't test it but I saw [this part](https://github.com/django/django/blob/698df6a009cb1c4dbd55905264f24f6edf41066e/django/contrib/postgres/fields/jsonb.py#L25) in code.",
      "> Actually, I didn't test it but I saw [this part](https://github.com/django/django/blob/698df6a009cb1c4dbd55905264f24f6edf41066e/django/contrib/postgres/fields/jsonb.py#L25) in code.\r\n\r\nYes, but that's unnecessary since the default argument is `None`.\r\n\r\n> I would move under class as instance method.\r\n\r\nI don't think that would work since the first argument would be the `JSONField` instance, instead of the value?\r\n",
      "@laymonage Thanks for updates :+1: I think that we should currently move all PostgreSQL tests related with JSONField (e.g. `postgres_tests/test_json.py`) to all databases scope and start to work on failures. I would also recommend to remove current implementation from `contrib.postgres` and for backward compatibility leave it only as a reference to a new implementation (probably some workaround should be added to migrations):\r\n\r\n- `django.contrib.postgres.fields.JSONField` -> `django.db.models.JSONField`,\r\n- `django.contrib.postgres.forms.JSONField` -> `django.forms.JSONField`,\r\n\r\nFor example, `django/contrib/postgres/fields/jsonb.py`:\r\n```python\r\nfrom django.db.models import JSONField\r\n\r\n__all__ = ['JSONField']\r\n```\r\nall lookups should be moved from `contrib/postgres/fields/jsonb.py`  to `db/models/lookups.py`.\r\n\r\nWith these changes we will be able to find caveats for each database :male_detective: .",
      "@felixxm I remember some folks saying it'd be better to leave the current implementation in `contrib.postgres` as it is (and add a deprecation message). However, I see your idea is reasonable, as long as we can maintain all of the lookups and transforms. I guess I'll try going down that route and see if we can do that.\r\n\r\nMeanwhile, I've removed some tests in `postgres_tests` and incorporated them into `test_jsonfield.py`.\r\n\r\nSome updates:\r\n\r\n- `JSON_VALID(NULL)` returns `0` (false) on SQLite, while it returns true on MySQL and MariaDB (or maybe the check just doesn't occur). This makes it impossible to store SQL `NULL` even if we specify `blank=True, null=True`. I've updated the SQLite constraint with `OR \"%(column)s\" IS NULL` and now it works correctly.\r\n- Oracle Database stores SQL `NULL` as an empty string `''` on fields that support empty strings. I've updated `JSONField` to accommodate this behavior. Saving empty Python strings would still work, as they would be encoded as `'\"\"'`.\r\n- I've refactored the tests into different classes for cohesiveness.",
      "Apparently, it's not because the values aren't quoted.  \r\ncx_Oracle uses bind variables:  \r\nhttps://www.oracle.com/technetwork/articles/dsl/prez-python-queries-101587.html\r\nhttps://oracle.readthedocs.io/en/latest/plsql/bind/\r\n\r\nBasically, query parameters get passed using variables, so queries look like this on Oracle:\r\n\r\n```sql\r\nSELECT * FROM TABLE WHERE col1 = :arg1 AND col2 = :arg2 ...\r\n```\r\n\r\nand the arguments can be passed using a dictionary, kwargs, or sequence (list, tuple), e.g.\r\n```python\r\nparams = {'arg1': 'hello', 'arg2': 'world'}\r\n```\r\n\r\n(see also: https://github.com/django/django/blob/master/django/db/backends/oracle/base.py#L478)\r\n\r\nThe problem is, `JSON_EXISTS` function on Oracle [doesn't support bind variables](https://stackoverflow.com/questions/48913687/jdbc-prepared-statement-to-query-json-using-json-exists). We can format the arguments directly into the SQL string (which is what I've done), but this opens up the possibility of SQL injections.\r\n\r\nHowever, I do `json.dumps()` on the specified key before formatting it, so the key will be double-quoted. If someone were to execute an SQL injection, they should end the quote first, which I don't think is possible since `\"` will be escaped by `json.dumps()` into `\\\"`. I think the worst that could happen is a `DatabaseError`. I currently can't think of a key string that can be used to perform an SQL injection.\r\n\r\nShould we go through with it, or drop support for these lookups on Oracle?\r\n\r\n",
      "Thanks a lot for the feedback. I started working on the lookups and transforms on MySQL using @adamchainz's and @raphaelm's existing code. It turns out that the code doesn't pass all of the tests from `contrib.postgres`, so I still have to fix things up.\r\n\r\nI also try to simplify or find better ways to implement the lookups and transforms, but fixing one thing tends to break another. It's very confusing, to be honest. Not to mention debugging it isn't so easy since I have to inspect the queries most of the time... :grimacing: \r\n\r\nEdit: on the other hand, `TestQuerying` test cases aren't run by djangoci. What's up with that?",
      "I've implemented the transforms and lookups on Oracle. Some features aren't supported, so I skipped the tests for those on Oracle.\r\n\r\nSome notes:\r\n- I didn't choose to implement it using the simple dot-notation syntax.\r\n  It's mainly because it requires the tables to be given aliases in the query. I could not find an easy and clean way to do that. The [oracle_json_field](https://github.com/Exscientia/oracle-json-field/blob/master/oracle_json_field/managers.py) package uses a custom Queryset and Manager with forced self-join to make table aliases.\r\n- In effect, I had to use `JSON_QUERY` to retrieve JSON objects and arrays, and `JSON_VALUE` to retrieve scalar values. To combine this, I used `COALESCE`. I probably should use `models.functions.Coalesce` for this, but if that's the case, it would make sense to also write `JSON_QUERY` and `JSON_VALUE` functions. It would probably add a little overhead on the Python-side. I'm not sure if I should do this. If I should, I'll probably also write some JSON `Func`s for all database backends that support them. For now, I'm just writing `COALESCE` directly into the SQL.\r\n- On the upside, using `JSON_QUERY` and `JSON_VALUE` supports querying > 4 KBytes of data while using the dot-notation syntax does not.",
      "I've implemented the transforms and lookups on SQLite. It turns out I can reuse most of the code from MySQL implementation. I only had to handle the case for querying JSON `null` values in JSON objects to differentiate them from missing keys (by using the `JSON_TYPE` function).\r\nSurprisingly, the support is equivalent to MySQL, which is much better than on Oracle.\r\n\r\nI have also added tests for storing JSON `null` scalar values. It is possible to do so by using `Value` during object creation. However, the Python representation of SQL `NULL` and JSON `null` are the same, i.e. `None`.",
      "I think I've found a way to implement `contains` and `contained_by` on SQLite and Oracle. I'll see what I can do.",
      "I managed to get `contains` working on SQLite and Oracle, though it was a bit of a hack since they both don't include a function similar to `JSON_CONTAINS`. It seems to work fine for its intended use (a `dict` rhs, to be checked on the top level of the JSON document). I added more tests, but I cannot guarantee it to work uniformly across all backends, especially for scalar and array rhs.\r\n\r\nEdit: I cannot think of a way to implement `contained_by`. Without a `JSON_CONTAINS` function, one would need to enumerate the JSON document in the database, which I think is impossible to do in one query."
    ],
    "code_diff": "diff --git a/AUTHORS b/AUTHORS\nindex 4632c66a62e8..03ed3fb7d643 100644\n--- a/AUTHORS\n+++ b/AUTHORS\n@@ -784,6 +784,7 @@ answer newbie questions, and generally made Django that much better:\n     Ryan Rubin <ryanmrubin@gmail.com>\n     Ryno Mathee <rmathee@gmail.com>\n     Sachin Jat <sanch.jat@gmail.com>\n+    Sage M. Abdullah <https://github.com/laymonage>\n     Sam Newman <http://www.magpiebrain.com/>\n     Sander Dijkhuis <sander.dijkhuis@gmail.com>\n     Sanket Saurav <sanketsaurav@gmail.com>\ndiff --git a/django/contrib/postgres/aggregates/general.py b/django/contrib/postgres/aggregates/general.py\nindex 918373e926e7..8390747c096b 100644\n--- a/django/contrib/postgres/aggregates/general.py\n+++ b/django/contrib/postgres/aggregates/general.py\n@@ -1,4 +1,5 @@\n-from django.contrib.postgres.fields import ArrayField, JSONField\n+from django.contrib.postgres.fields import ArrayField\n+from django.db.models import JSONField\n from django.db.models.aggregates import Aggregate\n \n from .mixins import OrderableAggMixin\ndiff --git a/django/contrib/postgres/apps.py b/django/contrib/postgres/apps.py\nindex 97475de6f7a2..25cfa1a814ce 100644\n--- a/django/contrib/postgres/apps.py\n+++ b/django/contrib/postgres/apps.py\n@@ -47,7 +47,6 @@ def ready(self):\n         for conn in connections.all():\n             if conn.vendor == 'postgresql':\n                 conn.introspection.data_types_reverse.update({\n-                    3802: 'django.contrib.postgres.fields.JSONField',\n                     3904: 'django.contrib.postgres.fields.IntegerRangeField',\n                     3906: 'django.contrib.postgres.fields.DecimalRangeField',\n                     3910: 'django.contrib.postgres.fields.DateTimeRangeField',\ndiff --git a/django/contrib/postgres/fields/jsonb.py b/django/contrib/postgres/fields/jsonb.py\nindex c402dd19d8e4..15d4daf466f0 100644\n--- a/django/contrib/postgres/fields/jsonb.py\n+++ b/django/contrib/postgres/fields/jsonb.py\n@@ -1,185 +1,41 @@\n-import json\n+import warnings\n \n-from psycopg2.extras import Json\n-\n-from django.contrib.postgres import forms, lookups\n-from django.core import exceptions\n-from django.db.models import (\n-    Field, TextField, Transform, lookups as builtin_lookups,\n+from django.db.models import JSONField as BuiltinJSONField\n+from django.db.models.fields.json import (\n+    KeyTextTransform as BuiltinKeyTextTransform,\n+    KeyTransform as BuiltinKeyTransform,\n )\n-from django.db.models.fields.mixins import CheckFieldDefaultMixin\n-from django.utils.translation import gettext_lazy as _\n+from django.utils.deprecation import RemovedInDjango40Warning\n \n __all__ = ['JSONField']\n \n \n-class JsonAdapter(Json):\n-    \"\"\"\n-    Customized psycopg2.extras.Json to allow for a custom encoder.\n-    \"\"\"\n-    def __init__(self, adapted, dumps=None, encoder=None):\n-        self.encoder = encoder\n-        super().__init__(adapted, dumps=dumps)\n-\n-    def dumps(self, obj):\n-        options = {'cls': self.encoder} if self.encoder else {}\n-        return json.dumps(obj, **options)\n-\n-\n-class JSONField(CheckFieldDefaultMixin, Field):\n-    empty_strings_allowed = False\n-    description = _('A JSON object')\n-    default_error_messages = {\n-        'invalid': _(\"Value must be valid JSON.\"),\n+class JSONField(BuiltinJSONField):\n+    system_check_deprecated_details = {\n+        'msg': (\n+            'django.contrib.postgres.fields.JSONField is deprecated '\n+            'and will be removed in Django 4.0.'\n+        ),\n+        'hint': 'Use django.db.models.JSONField instead.',\n+        'id': 'fields.W903'\n     }\n-    _default_hint = ('dict', '{}')\n-\n-    def __init__(self, verbose_name=None, name=None, encoder=None, **kwargs):\n-        if encoder and not callable(encoder):\n-            raise ValueError(\"The encoder parameter must be a callable object.\")\n-        self.encoder = encoder\n-        super().__init__(verbose_name, name, **kwargs)\n-\n-    def db_type(self, connection):\n-        return 'jsonb'\n-\n-    def deconstruct(self):\n-        name, path, args, kwargs = super().deconstruct()\n-        if self.encoder is not None:\n-            kwargs['encoder'] = self.encoder\n-        return name, path, args, kwargs\n-\n-    def get_transform(self, name):\n-        transform = super().get_transform(name)\n-        if transform:\n-            return transform\n-        return KeyTransformFactory(name)\n-\n-    def get_prep_value(self, value):\n-        if value is not None:\n-            return JsonAdapter(value, encoder=self.encoder)\n-        return value\n-\n-    def validate(self, value, model_instance):\n-        super().validate(value, model_instance)\n-        options = {'cls': self.encoder} if self.encoder else {}\n-        try:\n-            json.dumps(value, **options)\n-        except TypeError:\n-            raise exceptions.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n-            )\n-\n-    def value_to_string(self, obj):\n-        return self.value_from_object(obj)\n \n-    def formfield(self, **kwargs):\n-        return super().formfield(**{\n-            'form_class': forms.JSONField,\n-            **kwargs,\n-        })\n \n-\n-JSONField.register_lookup(lookups.DataContains)\n-JSONField.register_lookup(lookups.ContainedBy)\n-JSONField.register_lookup(lookups.HasKey)\n-JSONField.register_lookup(lookups.HasKeys)\n-JSONField.register_lookup(lookups.HasAnyKeys)\n-JSONField.register_lookup(lookups.JSONExact)\n-\n-\n-class KeyTransform(Transform):\n-    operator = '->'\n-    nested_operator = '#>'\n-\n-    def __init__(self, key_name, *args, **kwargs):\n+class KeyTransform(BuiltinKeyTransform):\n+    def __init__(self, *args, **kwargs):\n+        warnings.warn(\n+            'django.contrib.postgres.fields.jsonb.KeyTransform is deprecated in favor of '\n+            'django.db.models.fields.json.KeyTransform',\n+            RemovedInDjango40Warning, stacklevel=2\n+        )\n         super().__init__(*args, **kwargs)\n-        self.key_name = key_name\n \n-    def as_sql(self, compiler, connection):\n-        key_transforms = [self.key_name]\n-        previous = self.lhs\n-        while isinstance(previous, KeyTransform):\n-            key_transforms.insert(0, previous.key_name)\n-            previous = previous.lhs\n-        lhs, params = compiler.compile(previous)\n-        if len(key_transforms) > 1:\n-            return '(%s %s %%s)' % (lhs, self.nested_operator), params + [key_transforms]\n-        try:\n-            lookup = int(self.key_name)\n-        except ValueError:\n-            lookup = self.key_name\n-        return '(%s %s %%s)' % (lhs, self.operator), tuple(params) + (lookup,)\n \n-\n-class KeyTextTransform(KeyTransform):\n-    operator = '->>'\n-    nested_operator = '#>>'\n-    output_field = TextField()\n-\n-\n-class KeyTransformTextLookupMixin:\n-    \"\"\"\n-    Mixin for combining with a lookup expecting a text lhs from a JSONField\n-    key lookup. Make use of the ->> operator instead of casting key values to\n-    text and performing the lookup on the resulting representation.\n-    \"\"\"\n-    def __init__(self, key_transform, *args, **kwargs):\n-        assert isinstance(key_transform, KeyTransform)\n-        key_text_transform = KeyTextTransform(\n-            key_transform.key_name, *key_transform.source_expressions, **key_transform.extra\n+class KeyTextTransform(BuiltinKeyTextTransform):\n+    def __init__(self, *args, **kwargs):\n+        warnings.warn(\n+            'django.contrib.postgres.fields.jsonb.KeyTextTransform is deprecated in favor of '\n+            'django.db.models.fields.json.KeyTextTransform',\n+            RemovedInDjango40Warning, stacklevel=2\n         )\n-        super().__init__(key_text_transform, *args, **kwargs)\n-\n-\n-class KeyTransformIExact(KeyTransformTextLookupMixin, builtin_lookups.IExact):\n-    pass\n-\n-\n-class KeyTransformIContains(KeyTransformTextLookupMixin, builtin_lookups.IContains):\n-    pass\n-\n-\n-class KeyTransformStartsWith(KeyTransformTextLookupMixin, builtin_lookups.StartsWith):\n-    pass\n-\n-\n-class KeyTransformIStartsWith(KeyTransformTextLookupMixin, builtin_lookups.IStartsWith):\n-    pass\n-\n-\n-class KeyTransformEndsWith(KeyTransformTextLookupMixin, builtin_lookups.EndsWith):\n-    pass\n-\n-\n-class KeyTransformIEndsWith(KeyTransformTextLookupMixin, builtin_lookups.IEndsWith):\n-    pass\n-\n-\n-class KeyTransformRegex(KeyTransformTextLookupMixin, builtin_lookups.Regex):\n-    pass\n-\n-\n-class KeyTransformIRegex(KeyTransformTextLookupMixin, builtin_lookups.IRegex):\n-    pass\n-\n-\n-KeyTransform.register_lookup(KeyTransformIExact)\n-KeyTransform.register_lookup(KeyTransformIContains)\n-KeyTransform.register_lookup(KeyTransformStartsWith)\n-KeyTransform.register_lookup(KeyTransformIStartsWith)\n-KeyTransform.register_lookup(KeyTransformEndsWith)\n-KeyTransform.register_lookup(KeyTransformIEndsWith)\n-KeyTransform.register_lookup(KeyTransformRegex)\n-KeyTransform.register_lookup(KeyTransformIRegex)\n-\n-\n-class KeyTransformFactory:\n-\n-    def __init__(self, key_name):\n-        self.key_name = key_name\n-\n-    def __call__(self, *args, **kwargs):\n-        return KeyTransform(self.key_name, *args, **kwargs)\n+        super().__init__(*args, **kwargs)\ndiff --git a/django/contrib/postgres/forms/jsonb.py b/django/contrib/postgres/forms/jsonb.py\nindex 2865498d689a..39d248088a99 100644\n--- a/django/contrib/postgres/forms/jsonb.py\n+++ b/django/contrib/postgres/forms/jsonb.py\n@@ -1,62 +1,16 @@\n-import json\n+import warnings\n \n-from django import forms\n-from django.utils.translation import gettext_lazy as _\n+from django.forms import JSONField as BuiltinJSONField\n+from django.utils.deprecation import RemovedInDjango40Warning\n \n __all__ = ['JSONField']\n \n \n-class InvalidJSONInput(str):\n-    pass\n-\n-\n-class JSONString(str):\n-    pass\n-\n-\n-class JSONField(forms.CharField):\n-    default_error_messages = {\n-        'invalid': _('“%(value)s” value must be valid JSON.'),\n-    }\n-    widget = forms.Textarea\n-\n-    def to_python(self, value):\n-        if self.disabled:\n-            return value\n-        if value in self.empty_values:\n-            return None\n-        elif isinstance(value, (list, dict, int, float, JSONString)):\n-            return value\n-        try:\n-            converted = json.loads(value)\n-        except json.JSONDecodeError:\n-            raise forms.ValidationError(\n-                self.error_messages['invalid'],\n-                code='invalid',\n-                params={'value': value},\n-            )\n-        if isinstance(converted, str):\n-            return JSONString(converted)\n-        else:\n-            return converted\n-\n-    def bound_data(self, data, initial):\n-        if self.disabled:\n-            return initial\n-        try:\n-            return json.loads(data)\n-        except json.JSONDecodeError:\n-            return InvalidJSONInput(data)\n-\n-    def prepare_value(self, value):\n-        if isinstance(value, InvalidJSONInput):\n-            return value\n-        return json.dumps(value)\n-\n-    def has_changed(self, initial, data):\n-        if super().has_changed(initial, data):\n-            return True\n-        # For purposes of seeing whether something has changed, True isn't the\n-        # same as 1 and the order of keys doesn't matter.\n-        data = self.to_python(data)\n-        return json.dumps(initial, sort_keys=True) != json.dumps(data, sort_keys=True)\n+class JSONField(BuiltinJSONField):\n+    def __init__(self, *args, **kwargs):\n+        warnings.warn(\n+            'django.contrib.postgres.forms.JSONField is deprecated in favor of '\n+            'django.forms.JSONField',\n+            RemovedInDjango40Warning, stacklevel=2\n+        )\n+        super().__init__(*args, **kwargs)\ndiff --git a/django/db/backends/base/features.py b/django/db/backends/base/features.py\nindex 45c62f463b8f..f7bf241f590b 100644\n--- a/django/db/backends/base/features.py\n+++ b/django/db/backends/base/features.py\n@@ -295,6 +295,13 @@ class BaseDatabaseFeatures:\n     # Does the backend support boolean expressions in the SELECT clause?\n     supports_boolean_expr_in_select_clause = True\n \n+    # Does the backend support JSONField?\n+    supports_json_field = True\n+    # Does the backend support primities in JSONField?\n+    supports_primitives_in_json_field = True\n+    # Can the backend introspect JSONField?\n+    can_introspect_json_field = True\n+\n     def __init__(self, connection):\n         self.connection = connection\n \ndiff --git a/django/db/backends/mysql/base.py b/django/db/backends/mysql/base.py\nindex aeb935e91fa2..c2cd1ddb4fda 100644\n--- a/django/db/backends/mysql/base.py\n+++ b/django/db/backends/mysql/base.py\n@@ -118,6 +118,7 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n         'BigIntegerField': 'bigint',\n         'IPAddressField': 'char(15)',\n         'GenericIPAddressField': 'char(39)',\n+        'JSONField': 'json',\n         'NullBooleanField': 'bool',\n         'OneToOneField': 'integer',\n         'PositiveBigIntegerField': 'bigint UNSIGNED',\n@@ -339,11 +340,14 @@ def display_name(self):\n     @cached_property\n     def data_type_check_constraints(self):\n         if self.features.supports_column_check_constraints:\n-            return {\n+            check_constraints = {\n                 'PositiveBigIntegerField': '`%(column)s` >= 0',\n                 'PositiveIntegerField': '`%(column)s` >= 0',\n                 'PositiveSmallIntegerField': '`%(column)s` >= 0',\n             }\n+            if self.mysql_is_mariadb and self.mysql_version < (10, 4, 3):\n+                check_constraints['JSONField'] = 'JSON_VALID(`%(column)s`)'\n+            return check_constraints\n         return {}\n \n     @cached_property\ndiff --git a/django/db/backends/mysql/features.py b/django/db/backends/mysql/features.py\nindex 1d0cd365dbc8..bff2e7b0bff6 100644\n--- a/django/db/backends/mysql/features.py\n+++ b/django/db/backends/mysql/features.py\n@@ -153,3 +153,15 @@ def ignores_table_name_case(self):\n     def supports_default_in_lead_lag(self):\n         # To be added in https://jira.mariadb.org/browse/MDEV-12981.\n         return not self.connection.mysql_is_mariadb\n+\n+    @cached_property\n+    def supports_json_field(self):\n+        if self.connection.mysql_is_mariadb:\n+            return self.connection.mysql_version >= (10, 2, 7)\n+        return self.connection.mysql_version >= (5, 7, 8)\n+\n+    @cached_property\n+    def can_introspect_json_field(self):\n+        if self.connection.mysql_is_mariadb:\n+            return self.supports_json_field and self.can_introspect_check_constraints\n+        return self.supports_json_field\ndiff --git a/django/db/backends/mysql/introspection.py b/django/db/backends/mysql/introspection.py\nindex 9334cc57481e..926665c99e9a 100644\n--- a/django/db/backends/mysql/introspection.py\n+++ b/django/db/backends/mysql/introspection.py\n@@ -9,7 +9,7 @@\n from django.db.models.indexes import Index\n from django.utils.datastructures import OrderedSet\n \n-FieldInfo = namedtuple('FieldInfo', BaseFieldInfo._fields + ('extra', 'is_unsigned'))\n+FieldInfo = namedtuple('FieldInfo', BaseFieldInfo._fields + ('extra', 'is_unsigned', 'has_json_constraint'))\n InfoLine = namedtuple('InfoLine', 'col_name data_type max_len num_prec num_scale extra column_default is_unsigned')\n \n \n@@ -24,6 +24,7 @@ class DatabaseIntrospection(BaseDatabaseIntrospection):\n         FIELD_TYPE.DOUBLE: 'FloatField',\n         FIELD_TYPE.FLOAT: 'FloatField',\n         FIELD_TYPE.INT24: 'IntegerField',\n+        FIELD_TYPE.JSON: 'JSONField',\n         FIELD_TYPE.LONG: 'IntegerField',\n         FIELD_TYPE.LONGLONG: 'BigIntegerField',\n         FIELD_TYPE.SHORT: 'SmallIntegerField',\n@@ -53,6 +54,10 @@ def get_field_type(self, data_type, description):\n                 return 'PositiveIntegerField'\n             elif field_type == 'SmallIntegerField':\n                 return 'PositiveSmallIntegerField'\n+        # JSON data type is an alias to LONGTEXT on MariaDB, use check\n+        # constraints clauses to introspect JSONField.\n+        if description.has_json_constraint:\n+            return 'JSONField'\n         return field_type\n \n     def get_table_list(self, cursor):\n@@ -66,6 +71,17 @@ def get_table_description(self, cursor, table_name):\n         Return a description of the table with the DB-API cursor.description\n         interface.\"\n         \"\"\"\n+        json_constraints = {}\n+        if self.connection.mysql_is_mariadb and self.connection.features.can_introspect_json_field:\n+            cursor.execute(\"\"\"\n+                SELECT c.constraint_name AS column_name\n+                FROM information_schema.check_constraints AS c\n+                WHERE\n+                    c.table_name = %s AND\n+                    LOWER(c.check_clause) = 'json_valid(`' + LOWER(c.constraint_name) + '`)' AND\n+                    c.constraint_schema = DATABASE()\n+            \"\"\", [table_name])\n+            json_constraints = {row[0] for row in cursor.fetchall()}\n         # information_schema database gives more accurate results for some figures:\n         # - varchar length returned by cursor.description is an internal length,\n         #   not visible length (#5725)\n@@ -100,6 +116,7 @@ def to_int(i):\n                 info.column_default,\n                 info.extra,\n                 info.is_unsigned,\n+                line[0] in json_constraints,\n             ))\n         return fields\n \ndiff --git a/django/db/backends/mysql/operations.py b/django/db/backends/mysql/operations.py\nindex 534295776720..6ce48df96982 100644\n--- a/django/db/backends/mysql/operations.py\n+++ b/django/db/backends/mysql/operations.py\n@@ -327,3 +327,13 @@ def regex_lookup(self, lookup_type):\n \n     def insert_statement(self, ignore_conflicts=False):\n         return 'INSERT IGNORE INTO' if ignore_conflicts else super().insert_statement(ignore_conflicts)\n+\n+    def lookup_cast(self, lookup_type, internal_type=None):\n+        lookup = '%s'\n+        if internal_type == 'JSONField':\n+            if self.connection.mysql_is_mariadb or lookup_type in (\n+                'iexact', 'contains', 'icontains', 'startswith', 'istartswith',\n+                'endswith', 'iendswith', 'regex', 'iregex',\n+            ):\n+                lookup = 'JSON_UNQUOTE(%s)'\n+        return lookup\ndiff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py\nindex e1c76ec058ab..39444dc04ed3 100644\n--- a/django/db/backends/oracle/base.py\n+++ b/django/db/backends/oracle/base.py\n@@ -115,6 +115,7 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n         'FilePathField': 'NVARCHAR2(%(max_length)s)',\n         'FloatField': 'DOUBLE PRECISION',\n         'IntegerField': 'NUMBER(11)',\n+        'JSONField': 'NCLOB',\n         'BigIntegerField': 'NUMBER(19)',\n         'IPAddressField': 'VARCHAR2(15)',\n         'GenericIPAddressField': 'VARCHAR2(39)',\n@@ -133,6 +134,7 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n     }\n     data_type_check_constraints = {\n         'BooleanField': '%(qn_column)s IN (0,1)',\n+        'JSONField': '%(qn_column)s IS JSON',\n         'NullBooleanField': '%(qn_column)s IN (0,1)',\n         'PositiveBigIntegerField': '%(qn_column)s >= 0',\n         'PositiveIntegerField': '%(qn_column)s >= 0',\ndiff --git a/django/db/backends/oracle/features.py b/django/db/backends/oracle/features.py\nindex 73a6e8668648..0ad193f77111 100644\n--- a/django/db/backends/oracle/features.py\n+++ b/django/db/backends/oracle/features.py\n@@ -59,3 +59,4 @@ class DatabaseFeatures(BaseDatabaseFeatures):\n     supports_slicing_ordering_in_compound = True\n     allows_multiple_constraints_on_same_fields = False\n     supports_boolean_expr_in_select_clause = False\n+    supports_primitives_in_json_field = False\ndiff --git a/django/db/backends/oracle/introspection.py b/django/db/backends/oracle/introspection.py\nindex 2322ae0b5d6a..3fab497b2aec 100644\n--- a/django/db/backends/oracle/introspection.py\n+++ b/django/db/backends/oracle/introspection.py\n@@ -7,7 +7,7 @@\n     BaseDatabaseIntrospection, FieldInfo as BaseFieldInfo, TableInfo,\n )\n \n-FieldInfo = namedtuple('FieldInfo', BaseFieldInfo._fields + ('is_autofield',))\n+FieldInfo = namedtuple('FieldInfo', BaseFieldInfo._fields + ('is_autofield', 'is_json'))\n \n \n class DatabaseIntrospection(BaseDatabaseIntrospection):\n@@ -45,6 +45,8 @@ def get_field_type(self, data_type, description):\n                     return 'IntegerField'\n             elif scale == -127:\n                 return 'FloatField'\n+        elif data_type == cx_Oracle.NCLOB and description.is_json:\n+            return 'JSONField'\n \n         return super().get_field_type(data_type, description)\n \n@@ -83,12 +85,23 @@ def get_table_description(self, cursor, table_name):\n                 CASE\n                     WHEN identity_column = 'YES' THEN 1\n                     ELSE 0\n-                END as is_autofield\n+                END as is_autofield,\n+                CASE\n+                    WHEN EXISTS (\n+                        SELECT  1\n+                        FROM user_json_columns\n+                        WHERE\n+                            user_json_columns.table_name = user_tab_cols.table_name AND\n+                            user_json_columns.column_name = user_tab_cols.column_name\n+                    )\n+                    THEN 1\n+                    ELSE 0\n+                END as is_json\n             FROM user_tab_cols\n             WHERE table_name = UPPER(%s)\"\"\", [table_name])\n         field_map = {\n-            column: (internal_size, default if default != 'NULL' else None, is_autofield)\n-            for column, default, internal_size, is_autofield in cursor.fetchall()\n+            column: (internal_size, default if default != 'NULL' else None, is_autofield, is_json)\n+            for column, default, internal_size, is_autofield, is_json in cursor.fetchall()\n         }\n         self.cache_bust_counter += 1\n         cursor.execute(\"SELECT * FROM {} WHERE ROWNUM < 2 AND {} > 0\".format(\n@@ -97,11 +110,11 @@ def get_table_description(self, cursor, table_name):\n         description = []\n         for desc in cursor.description:\n             name = desc[0]\n-            internal_size, default, is_autofield = field_map[name]\n+            internal_size, default, is_autofield, is_json = field_map[name]\n             name = name % {}  # cx_Oracle, for some reason, doubles percent signs.\n             description.append(FieldInfo(\n                 self.identifier_converter(name), *desc[1:3], internal_size, desc[4] or 0,\n-                desc[5] or 0, *desc[6:], default, is_autofield,\n+                desc[5] or 0, *desc[6:], default, is_autofield, is_json,\n             ))\n         return description\n \ndiff --git a/django/db/backends/oracle/operations.py b/django/db/backends/oracle/operations.py\nindex 358c91505f66..59ed65510068 100644\n--- a/django/db/backends/oracle/operations.py\n+++ b/django/db/backends/oracle/operations.py\n@@ -175,7 +175,7 @@ def time_trunc_sql(self, lookup_type, field_name):\n     def get_db_converters(self, expression):\n         converters = super().get_db_converters(expression)\n         internal_type = expression.output_field.get_internal_type()\n-        if internal_type == 'TextField':\n+        if internal_type in ['JSONField', 'TextField']:\n             converters.append(self.convert_textfield_value)\n         elif internal_type == 'BinaryField':\n             converters.append(self.convert_binaryfield_value)\ndiff --git a/django/db/backends/postgresql/base.py b/django/db/backends/postgresql/base.py\nindex 0ab81ced74fd..3136367b63a6 100644\n--- a/django/db/backends/postgresql/base.py\n+++ b/django/db/backends/postgresql/base.py\n@@ -86,6 +86,7 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n         'BigIntegerField': 'bigint',\n         'IPAddressField': 'inet',\n         'GenericIPAddressField': 'inet',\n+        'JSONField': 'jsonb',\n         'NullBooleanField': 'boolean',\n         'OneToOneField': 'integer',\n         'PositiveBigIntegerField': 'bigint',\ndiff --git a/django/db/backends/postgresql/introspection.py b/django/db/backends/postgresql/introspection.py\nindex b7bf18691c39..feb54643b9c7 100644\n--- a/django/db/backends/postgresql/introspection.py\n+++ b/django/db/backends/postgresql/introspection.py\n@@ -26,6 +26,7 @@ class DatabaseIntrospection(BaseDatabaseIntrospection):\n         1266: 'TimeField',\n         1700: 'DecimalField',\n         2950: 'UUIDField',\n+        3802: 'JSONField',\n     }\n \n     ignored_tables = []\ndiff --git a/django/db/backends/sqlite3/base.py b/django/db/backends/sqlite3/base.py\nindex a3ae1f048ef3..b017b5f5c884 100644\n--- a/django/db/backends/sqlite3/base.py\n+++ b/django/db/backends/sqlite3/base.py\n@@ -5,6 +5,7 @@\n import decimal\n import functools\n import hashlib\n+import json\n import math\n import operator\n import re\n@@ -100,6 +101,7 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n         'BigIntegerField': 'bigint',\n         'IPAddressField': 'char(15)',\n         'GenericIPAddressField': 'char(39)',\n+        'JSONField': 'text',\n         'NullBooleanField': 'bool',\n         'OneToOneField': 'integer',\n         'PositiveBigIntegerField': 'bigint unsigned',\n@@ -114,6 +116,7 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n     }\n     data_type_check_constraints = {\n         'PositiveBigIntegerField': '\"%(column)s\" >= 0',\n+        'JSONField': '(JSON_VALID(\"%(column)s\") OR \"%(column)s\" IS NULL)',\n         'PositiveIntegerField': '\"%(column)s\" >= 0',\n         'PositiveSmallIntegerField': '\"%(column)s\" >= 0',\n     }\n@@ -213,6 +216,7 @@ def get_new_connection(self, conn_params):\n         conn.create_function(\"django_time_diff\", 2, _sqlite_time_diff)\n         conn.create_function(\"django_timestamp_diff\", 2, _sqlite_timestamp_diff)\n         conn.create_function(\"django_format_dtdelta\", 3, _sqlite_format_dtdelta)\n+        conn.create_function(\"django_json_contains\", 2, _sqlite_json_contains)\n         conn.create_function('regexp', 2, _sqlite_regexp)\n         conn.create_function('ACOS', 1, none_guard(math.acos))\n         conn.create_function('ASIN', 1, none_guard(math.asin))\n@@ -588,3 +592,12 @@ def _sqlite_lpad(text, length, fill_text):\n @none_guard\n def _sqlite_rpad(text, length, fill_text):\n     return (text + fill_text * length)[:length]\n+\n+\n+@none_guard\n+def _sqlite_json_contains(haystack, needle):\n+    target, candidate = json.loads(haystack), json.loads(needle)\n+    if isinstance(target, dict) and isinstance(candidate, dict):\n+        return target.items() >= candidate.items()\n+    else:\n+        return target == candidate\ndiff --git a/django/db/backends/sqlite3/features.py b/django/db/backends/sqlite3/features.py\nindex 6aebbc32627a..2301ed0b889e 100644\n--- a/django/db/backends/sqlite3/features.py\n+++ b/django/db/backends/sqlite3/features.py\n@@ -1,4 +1,9 @@\n+import operator\n+\n+from django.db import transaction\n from django.db.backends.base.features import BaseDatabaseFeatures\n+from django.db.utils import OperationalError\n+from django.utils.functional import cached_property\n \n from .base import Database\n \n@@ -45,3 +50,14 @@ class DatabaseFeatures(BaseDatabaseFeatures):\n     supports_frame_range_fixed_distance = Database.sqlite_version_info >= (3, 28, 0)\n     supports_aggregate_filter_clause = Database.sqlite_version_info >= (3, 30, 1)\n     supports_order_by_nulls_modifier = Database.sqlite_version_info >= (3, 30, 0)\n+\n+    @cached_property\n+    def supports_json_field(self):\n+        try:\n+            with self.connection.cursor() as cursor, transaction.atomic():\n+                cursor.execute('SELECT JSON(\\'{\"a\": \"b\"}\\')')\n+        except OperationalError:\n+            return False\n+        return True\n+\n+    can_introspect_json_field = property(operator.attrgetter('supports_json_field'))\ndiff --git a/django/db/backends/sqlite3/introspection.py b/django/db/backends/sqlite3/introspection.py\nindex 2b5e732a4737..d87ff4633100 100644\n--- a/django/db/backends/sqlite3/introspection.py\n+++ b/django/db/backends/sqlite3/introspection.py\n@@ -9,7 +9,7 @@\n from django.db.models.indexes import Index\n from django.utils.regex_helper import _lazy_re_compile\n \n-FieldInfo = namedtuple('FieldInfo', BaseFieldInfo._fields + ('pk',))\n+FieldInfo = namedtuple('FieldInfo', BaseFieldInfo._fields + ('pk', 'has_json_constraint'))\n \n field_size_re = _lazy_re_compile(r'^\\s*(?:var)?char\\s*\\(\\s*(\\d+)\\s*\\)\\s*$')\n \n@@ -63,6 +63,8 @@ def get_field_type(self, data_type, description):\n             # No support for BigAutoField or SmallAutoField as SQLite treats\n             # all integer primary keys as signed 64-bit integers.\n             return 'AutoField'\n+        if description.has_json_constraint:\n+            return 'JSONField'\n         return field_type\n \n     def get_table_list(self, cursor):\n@@ -81,12 +83,24 @@ def get_table_description(self, cursor, table_name):\n         interface.\n         \"\"\"\n         cursor.execute('PRAGMA table_info(%s)' % self.connection.ops.quote_name(table_name))\n+        table_info = cursor.fetchall()\n+        json_columns = set()\n+        if self.connection.features.can_introspect_json_field:\n+            for line in table_info:\n+                column = line[1]\n+                has_json_constraint = cursor.execute(\n+                    \"SELECT sql FROM sqlite_master WHERE type='table' AND name=%s \"\n+                    \"AND sql LIKE '%%json_valid(%s)%%'\" %\n+                    (self.connection.ops.quote_name(table_name), self.connection.ops.quote_name(column))\n+                ).fetchone()\n+                if has_json_constraint:\n+                    json_columns.add(column)\n         return [\n             FieldInfo(\n                 name, data_type, None, get_field_size(data_type), None, None,\n-                not notnull, default, pk == 1,\n+                not notnull, default, pk == 1, name in json_columns\n             )\n-            for cid, name, data_type, notnull, default, pk in cursor.fetchall()\n+            for cid, name, data_type, notnull, default, pk in table_info\n         ]\n \n     def get_sequences(self, cursor, table_name, table_fields=()):\ndiff --git a/django/db/models/__init__.py b/django/db/models/__init__.py\nindex 06bd72f8b98e..b81482e3b6f1 100644\n--- a/django/db/models/__init__.py\n+++ b/django/db/models/__init__.py\n@@ -17,6 +17,7 @@\n from django.db.models.fields import *  # NOQA\n from django.db.models.fields import __all__ as fields_all\n from django.db.models.fields.files import FileField, ImageField\n+from django.db.models.fields.json import JSONField\n from django.db.models.fields.proxy import OrderWrt\n from django.db.models.indexes import *  # NOQA\n from django.db.models.indexes import __all__ as indexes_all\n@@ -43,9 +44,9 @@\n     'Case', 'Exists', 'Expression', 'ExpressionList', 'ExpressionWrapper', 'F',\n     'Func', 'OuterRef', 'RowRange', 'Subquery', 'Value', 'ValueRange', 'When',\n     'Window', 'WindowFrame',\n-    'FileField', 'ImageField', 'OrderWrt', 'Lookup', 'Transform', 'Manager',\n-    'Prefetch', 'Q', 'QuerySet', 'prefetch_related_objects', 'DEFERRED', 'Model',\n-    'FilteredRelation',\n+    'FileField', 'ImageField', 'JSONField', 'OrderWrt', 'Lookup', 'Transform',\n+    'Manager', 'Prefetch', 'Q', 'QuerySet', 'prefetch_related_objects',\n+    'DEFERRED', 'Model', 'FilteredRelation',\n     'ForeignKey', 'ForeignObject', 'OneToOneField', 'ManyToManyField',\n     'ManyToOneRel', 'ManyToManyRel', 'OneToOneRel',\n ]\ndiff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 24453e218a43..60d77d5becf0 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -16,7 +16,7 @@\n     connections, router, transaction,\n )\n from django.db.models import (\n-    NOT_PROVIDED, ExpressionWrapper, IntegerField, Max, Value,\n+    NOT_PROVIDED, ExpressionWrapper, IntegerField, JSONField, Max, Value,\n )\n from django.db.models.constants import LOOKUP_SEP\n from django.db.models.constraints import CheckConstraint, UniqueConstraint\n@@ -1333,13 +1333,35 @@ def _check_managers(cls, **kwargs):\n     @classmethod\n     def _check_fields(cls, **kwargs):\n         \"\"\"Perform all field checks.\"\"\"\n-        errors = []\n+        errors = cls._check_json_fields(**kwargs)\n         for field in cls._meta.local_fields:\n             errors.extend(field.check(**kwargs))\n         for field in cls._meta.local_many_to_many:\n             errors.extend(field.check(from_model=cls, **kwargs))\n         return errors\n \n+    @classmethod\n+    def _check_json_fields(cls, **kwargs):\n+        errors = []\n+        for db in settings.DATABASES:\n+            if not router.allow_migrate_model(db, cls):\n+                continue\n+            connection = connections[db]\n+            if (\n+                'supports_json_field' in cls._meta.required_db_features or\n+                connection.features.supports_json_field\n+            ):\n+                continue\n+            if any(isinstance(field, JSONField) for field in cls._meta.local_fields):\n+                errors.append(\n+                    checks.Error(\n+                        '%s does not support JSONFields.' % connection.display_name,\n+                        obj=cls,\n+                        id='models.E036',\n+                    )\n+                )\n+        return errors\n+\n     @classmethod\n     def _check_m2m_through_same_relationship(cls):\n         \"\"\" Check if no relationship model is used by more than one m2m field.\ndiff --git a/django/db/models/fields/json.py b/django/db/models/fields/json.py\nnew file mode 100644\nindex 000000000000..a4d3d22f833e\n--- /dev/null\n+++ b/django/db/models/fields/json.py\n@@ -0,0 +1,527 @@\n+import json\n+\n+from django import forms\n+from django.core import exceptions\n+from django.db.models import lookups\n+from django.db.models.lookups import (\n+    FieldGetDbPrepValueMixin, Lookup, Transform,\n+)\n+from django.db.utils import NotSupportedError\n+from django.utils.translation import gettext_lazy as _\n+\n+from . import Field\n+from .mixins import CheckFieldDefaultMixin\n+\n+\n+class JSONField(CheckFieldDefaultMixin, Field):\n+    description = _('A JSON object')\n+    default_error_messages = {\n+        'invalid': _('Value must be valid JSON.'),\n+    }\n+    _default_hint = ('dict', '{}')\n+\n+    def __init__(\n+        self, verbose_name=None, name=None, encoder=None,\n+        decoder=None, *args, **kwargs\n+    ):\n+        self.encoder, self.decoder = encoder, decoder\n+        super().__init__(verbose_name, name, *args, **kwargs)\n+\n+    def deconstruct(self):\n+        name, path, args, kwargs = super().deconstruct()\n+        path = 'django.db.models.JSONField'\n+        if self.encoder is not None:\n+            kwargs['encoder'] = self.encoder\n+        if self.decoder is not None:\n+            kwargs['decoder'] = self.decoder\n+        return name, path, args, kwargs\n+\n+    def from_db_value(self, value, expression, connection):\n+        if value is None:\n+            return value\n+        elif connection.vendor == 'postgresql' and self.decoder is None:\n+            return value\n+        else:\n+            try:\n+                return json.loads(value, cls=self.decoder)\n+            except json.JSONDecodeError:\n+                return value\n+\n+    def get_internal_type(self):\n+        return 'JSONField'\n+\n+    def get_prep_value(self, value):\n+        if value is None:\n+            return value\n+        return json.dumps(value, cls=self.encoder)\n+\n+    def get_transform(self, name):\n+        transform = super().get_transform(name)\n+        if transform:\n+            return transform\n+        return KeyTransformFactory(name)\n+\n+    def select_format(self, compiler, sql, params):\n+        if compiler.connection.vendor == 'postgresql' and self.decoder is not None:\n+            # Avoid psycopg2's automatic decoding to allow custom decoder\n+            return '%s::text' % sql, params\n+        return super().select_format(compiler, sql, params)\n+\n+    def validate(self, value, model_instance):\n+        super().validate(value, model_instance)\n+        try:\n+            json.dumps(value, cls=self.encoder)\n+        except TypeError:\n+            raise exceptions.ValidationError(\n+                self.error_messages['invalid'],\n+                code='invalid',\n+                params={'value': value},\n+            )\n+\n+    def value_to_string(self, obj):\n+        return self.value_from_object(obj)\n+\n+    def formfield(self, **kwargs):\n+        return super().formfield(**{\n+            'form_class': forms.JSONField,\n+            'encoder': self.encoder,\n+            'decoder': self.decoder,\n+            **kwargs,\n+        })\n+\n+\n+def compile_json_path(key_transforms):\n+    path = ['$']\n+    for key_transform in key_transforms:\n+        try:\n+            num = int(key_transform)\n+        except ValueError:  # non-integer\n+            path.append('.')\n+            path.append(json.dumps(key_transform))\n+        else:\n+            path.append('[%s]' % num)\n+    return ''.join(path)\n+\n+\n+class SimpleFunctionOperatorMixin(FieldGetDbPrepValueMixin):\n+    def as_sql_function(self, compiler, connection, template, flipped=False):\n+        lhs, lhs_params = self.process_lhs(compiler, connection)\n+        rhs, rhs_params = self.process_rhs(compiler, connection)\n+        if flipped:\n+            return template % (rhs, lhs), tuple(rhs_params) + tuple(lhs_params)\n+        else:\n+            return template % (lhs, rhs), tuple(lhs_params) + tuple(rhs_params)\n+\n+    def as_sql_operator(self, compiler, connection, operator):\n+        lhs, lhs_params = self.process_lhs(compiler, connection)\n+        rhs, rhs_params = self.process_rhs(compiler, connection)\n+        params = tuple(lhs_params) + tuple(rhs_params)\n+        return '%s %s %s' % (lhs, operator, rhs), params\n+\n+    def as_postgresql(self, compiler, connection):\n+        return self.as_sql_operator(compiler, connection, self.postgres_operator)\n+\n+    def as_sql(self, compiler, connection):\n+        raise NotSupportedError(\n+            '%s lookup is not supported by this database backend.' % self.lookup_name\n+        )\n+\n+\n+class HasKeyLookup(SimpleFunctionOperatorMixin, Lookup):\n+    logical_operator = None\n+\n+    def as_sql(self, compiler, connection, template=None):\n+        if isinstance(self.lhs, KeyTransform):\n+            lhs, lhs_params, lhs_key_transforms = self.lhs.preprocess_lhs(compiler, connection)\n+        else:\n+            lhs, lhs_params, lhs_key_transforms = *compiler.compile(self.lhs), []\n+        rhs = [self.rhs] if not isinstance(self.rhs, (list, tuple)) else list(self.rhs)\n+        rhs_params = []\n+        for key in rhs:\n+            if isinstance(key, str):\n+                rhs_params.insert(0, compile_json_path(lhs_key_transforms + [key]))\n+            else:\n+                if isinstance(key, KeyTransform):\n+                    _, _, key_transforms = key.preprocess_lhs(compiler, connection)\n+                else:\n+                    key_transforms = []\n+                rhs_params.insert(0, compile_json_path(lhs_key_transforms + key_transforms))\n+        sql = template % lhs\n+        if self.logical_operator:\n+            # Add condition for each key.\n+            sql = '(%s)' % self.logical_operator.join([sql] * len(rhs_params))\n+        return sql, tuple(lhs_params) + tuple(rhs_params)\n+\n+    def as_mysql(self, compiler, connection):\n+        return self.as_sql(compiler, connection, template=\"JSON_CONTAINS_PATH(%s, 'one', %%s)\")\n+\n+    def as_oracle(self, compiler, connection):\n+        sql, params = self.as_sql(compiler, connection, template=\"JSON_EXISTS(%s, '%%s')\")\n+        # Add paths directly into SQL because path expressions cannot be passed\n+        # as bind variables on Oracle.\n+        return sql % tuple(params), []\n+\n+    def as_sqlite(self, compiler, connection):\n+        return self.as_sql(compiler, connection, template='JSON_TYPE(%s, %%s) IS NOT NULL')\n+\n+\n+@JSONField.register_lookup\n+class HasKey(HasKeyLookup):\n+    lookup_name = 'has_key'\n+    postgres_operator = '?'\n+    prepare_rhs = False\n+\n+\n+@JSONField.register_lookup\n+class HasAnyKeys(HasKeyLookup):\n+    lookup_name = 'has_any_keys'\n+    postgres_operator = '?|'\n+    logical_operator = ' OR '\n+\n+    def get_prep_lookup(self):\n+        return [\n+            str(item) if not isinstance(item, KeyTransform) else item\n+            for item in self.rhs\n+        ]\n+\n+\n+@JSONField.register_lookup\n+class HasKeys(HasAnyKeys):\n+    lookup_name = 'has_keys'\n+    postgres_operator = '?&'\n+    logical_operator = ' AND '\n+\n+\n+@JSONField.register_lookup\n+class DataContains(SimpleFunctionOperatorMixin, Lookup):\n+    lookup_name = 'contains'\n+    postgres_operator = '@>'\n+\n+    def as_mysql(self, compiler, connection, flipped=False):\n+        return super().as_sql_function(\n+            compiler, connection, template=\"JSON_CONTAINS(%s, %s, '$')\", flipped=flipped\n+        )\n+\n+    def as_oracle(self, compiler, connection):\n+        lhs, lhs_params = self.process_lhs(compiler, connection)\n+        if isinstance(self.rhs, KeyTransform):\n+            _, _, key_transforms = self.rhs.preprocess_lhs(compiler, connection)\n+            return \"JSON_EXISTS(%s, '%s')\" % (lhs, compile_json_path(key_transforms)), []\n+        else:\n+            rhs = json.loads(self.rhs)\n+        if isinstance(rhs, dict):\n+            if not rhs:\n+                return \"DBMS_LOB.SUBSTR(%s) LIKE '{%%%%}'\" % lhs, []\n+            conditions = []\n+            for key, value in rhs.items():\n+                k = json.dumps(key)\n+                if value is None:\n+                    conditions.append(\n+                        \"(JSON_EXISTS(%s, '$.%s') AND\"\n+                        \" COALESCE(JSON_QUERY(%s, '$.%s'), JSON_VALUE(%s, '$.%s')) IS NULL)\" % ((lhs, k) * 3)\n+                    )\n+                elif isinstance(value, (list, dict)):\n+                    conditions.append(\n+                        \"JSON_QUERY(%s, '$.%s') = JSON_QUERY('{\\\"val\\\": %s}', '$.val')\" % (lhs, k, json.dumps(value))\n+                    )\n+                else:\n+                    conditions.append(\n+                        \"JSON_VALUE(%s, '$.%s') = JSON_VALUE('{\\\"val\\\": %s}', '$.val')\" % (lhs, k, json.dumps(value))\n+                    )\n+            return ' AND '.join(conditions), []\n+        else:\n+            return 'DBMS_LOB.SUBSTR(%s) = %%s' % lhs, [self.rhs]\n+\n+    def as_sqlite(self, compiler, connection, flipped=False):\n+        return super().as_sql_function(\n+            compiler, connection, template='django_json_contains(%s, %s)', flipped=flipped\n+        )\n+\n+\n+@JSONField.register_lookup\n+class ContainedBy(DataContains):\n+    lookup_name = 'contained_by'\n+    postgres_operator = '<@'\n+\n+    def as_mysql(self, compiler, connection):\n+        return super().as_mysql(compiler, connection, flipped=True)\n+\n+    def as_oracle(self, compiler, connection):\n+        return super().as_sql(compiler, connection)\n+\n+    def as_sqlite(self, compiler, connection):\n+        return super().as_sqlite(compiler, connection, flipped=True)\n+\n+\n+@JSONField.register_lookup\n+class JSONExact(lookups.Exact):\n+    can_use_none_as_rhs = True\n+\n+    def process_lhs(self, compiler, connection):\n+        lhs, lhs_params = super().process_lhs(compiler, connection)\n+        if connection.vendor == 'sqlite':\n+            rhs, rhs_params = super().process_rhs(compiler, connection)\n+            if rhs == '%s' and rhs_params == [None]:\n+                # Need to use JSON_TYPE instead of JSON_EXTRACT\n+                # to determine JSON null values.\n+                lhs = \"JSON_TYPE(%s, '$')\" % lhs\n+        return lhs, lhs_params\n+\n+    def process_rhs(self, compiler, connection):\n+        rhs, rhs_params = super().process_rhs(compiler, connection)\n+        # Treat None lookup values as null.\n+        if rhs == '%s' and rhs_params == [None]:\n+            rhs, rhs_params = ('%s', ['null'])\n+        if connection.vendor == 'mysql':\n+            func = [\"JSON_EXTRACT(%s, '$')\" for value in rhs_params]\n+            rhs = rhs % tuple(func)\n+        return rhs, rhs_params\n+\n+\n+class KeyTransform(Transform):\n+    postgres_operator = '->'\n+    postgres_nested_operator = '#>'\n+\n+    def __init__(self, key_name, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self.key_name = key_name\n+\n+    def preprocess_lhs(self, compiler, connection, lhs_only=False):\n+        if not lhs_only:\n+            key_transforms = [self.key_name]\n+        previous = self.lhs\n+        while isinstance(previous, KeyTransform):\n+            if not lhs_only:\n+                key_transforms.insert(0, previous.key_name)\n+            previous = previous.lhs\n+        lhs, params = compiler.compile(previous)\n+        return (lhs, params, key_transforms) if not lhs_only else (lhs, params)\n+\n+    def as_mysql(self, compiler, connection):\n+        lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n+        json_path = compile_json_path(key_transforms)\n+        return 'JSON_EXTRACT(%s, %%s)' % lhs, tuple(params) + (json_path,)\n+\n+    def as_oracle(self, compiler, connection):\n+        lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n+        json_path = compile_json_path(key_transforms)\n+        return \"COALESCE(JSON_QUERY(%s, '%s'), JSON_VALUE(%s, '%s'))\" % ((lhs, json_path) * 2), tuple(params)\n+\n+    def as_postgresql(self, compiler, connection):\n+        lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n+        if len(key_transforms) > 1:\n+            return '(%s %s %%s)' % (lhs, self.postgres_nested_operator), params + [key_transforms]\n+        try:\n+            lookup = int(self.key_name)\n+        except ValueError:\n+            lookup = self.key_name\n+        return '(%s %s %%s)' % (lhs, self.postgres_operator), tuple(params) + (lookup,)\n+\n+    def as_sqlite(self, compiler, connection):\n+        lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n+        json_path = compile_json_path(key_transforms)\n+        return 'JSON_EXTRACT(%s, %%s)' % lhs, tuple(params) + (json_path,)\n+\n+\n+class KeyTextTransform(KeyTransform):\n+    postgres_operator = '->>'\n+    postgres_nested_operator = '#>>'\n+\n+\n+class KeyTransformTextLookupMixin:\n+    \"\"\"\n+    Mixin for combining with a lookup expecting a text lhs from a JSONField\n+    key lookup. On PostgreSQL, make use of the ->> operator instead of casting\n+    key values to text and performing the lookup on the resulting representation.\n+    On MySQL, JSON_UNQUOTE is applied to the lhs.\n+    \"\"\"\n+    def __init__(self, key_transform, *args, **kwargs):\n+        if not isinstance(key_transform, KeyTransform):\n+            raise TypeError(\n+                'Transform should be an instance of KeyTransform in order to use this lookup.'\n+            )\n+        key_text_transform = KeyTextTransform(\n+            key_transform.key_name, *key_transform.source_expressions, **key_transform.extra\n+        )\n+        super().__init__(key_text_transform, *args, **kwargs)\n+\n+\n+class KeyTransformNumericLookupMixin:\n+    def process_rhs(self, compiler, connection):\n+        rhs, rhs_params = super().process_rhs(compiler, connection)\n+        if connection.vendor != 'postgresql':\n+            rhs_params = [json.loads(value) for value in rhs_params]\n+        return rhs, rhs_params\n+\n+\n+class CaseInsensitiveMixin:\n+    \"\"\"\n+    Mixin to allow case-insensitive comparison of JSON values on MySQL.\n+    MySQL handles strings used in JSON context using the utf8mb4_bin collation.\n+    Because utf8mb4_bin is a binary collation, comparison of JSON values is case-sensitive.\n+    \"\"\"\n+    def process_lhs(self, compiler, connection):\n+        lhs, lhs_params = super().process_lhs(compiler, connection)\n+        if connection.vendor == 'mysql':\n+            return 'LOWER(%s)' % lhs, lhs_params\n+        return lhs, lhs_params\n+\n+    def process_rhs(self, compiler, connection):\n+        rhs, rhs_params = super().process_rhs(compiler, connection)\n+        if connection.vendor == 'mysql':\n+            return 'LOWER(%s)' % rhs, rhs_params\n+        return rhs, rhs_params\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformIsNull(lookups.IsNull):\n+    def as_oracle(self, compiler, connection):\n+        if isinstance(self.lhs, KeyTransform):\n+            prev_lhs, prev_params, key_transforms = self.lhs.preprocess_lhs(compiler, connection)\n+        else:\n+            prev_lhs, prev_params, key_transforms = *compiler.compile(self.lhs), []\n+        json_path = compile_json_path(key_transforms)\n+        if self.rhs:\n+            return (\n+                \"(NOT JSON_EXISTS(%s, '%s') OR JSON_QUERY(%s, '$') IS NULL)\" % (prev_lhs, json_path, prev_lhs),\n+                prev_params\n+            )\n+        else:\n+            return \"JSON_EXISTS(%s, '%s')\" % (prev_lhs, json_path), prev_params\n+\n+    def as_sqlite(self, compiler, connection):\n+        lhs, lhs_params = super().process_lhs(compiler, connection)\n+        if isinstance(self.lhs, KeyTransform):\n+            prev_lhs, prev_params = self.lhs.preprocess_lhs(compiler, connection, lhs_only=True)\n+        else:\n+            prev_lhs, prev_params = compiler.compile(self.lhs)\n+        if self.rhs:\n+            return 'JSON_TYPE(%s, %%s) IS NULL' % prev_lhs, lhs_params\n+        else:\n+            return 'JSON_TYPE(%s, %%s) IS NOT NULL' % prev_lhs, lhs_params\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformExact(JSONExact):\n+    def process_lhs(self, compiler, connection):\n+        lhs, lhs_params = super().process_lhs(compiler, connection)\n+        if connection.vendor == 'sqlite':\n+            rhs, rhs_params = super().process_rhs(compiler, connection)\n+            if rhs == '%s' and rhs_params == ['null']:\n+                if isinstance(self.lhs, KeyTransform):\n+                    lhs, params = self.lhs.preprocess_lhs(compiler, connection, lhs_only=True)\n+                else:\n+                    lhs, params = compiler.compile(self.lhs)\n+                lhs = 'JSON_TYPE(%s, %%s)' % lhs\n+        return lhs, lhs_params\n+\n+    def process_rhs(self, compiler, connection):\n+        if isinstance(self.rhs, KeyTransform):\n+            rhs, rhs_params = super(lookups.Exact, self).process_rhs(compiler, connection)\n+            if connection.vendor == 'oracle':\n+                rhs_params *= 2\n+            return rhs, rhs_params\n+        else:\n+            rhs, rhs_params = super().process_rhs(compiler, connection)\n+        if connection.vendor == 'oracle':\n+            func = []\n+            for value in rhs_params:\n+                val = json.loads(value)\n+                if isinstance(val, (list, dict)):\n+                    func.append(\"JSON_QUERY('{\\\"val\\\": %s}', '$.val')\" % value)\n+                else:\n+                    func.append(\"JSON_VALUE('{\\\"val\\\": %s}', '$.val')\" % value)\n+            rhs = rhs % tuple(func)\n+            rhs_params = []\n+        elif connection.vendor == 'sqlite':\n+            func = [\"JSON_EXTRACT(%s, '$')\" if value != 'null' else '%s' for value in rhs_params]\n+            rhs = rhs % tuple(func)\n+        return rhs, rhs_params\n+\n+    def as_oracle(self, compiler, connection):\n+        rhs, rhs_params = super().process_rhs(compiler, connection)\n+        if rhs_params == ['null']:\n+            lhs, lhs_params = self.process_lhs(compiler, connection)\n+            if isinstance(self.lhs, KeyTransform):\n+                prev_lhs, _, key_transforms = self.lhs.preprocess_lhs(compiler, connection)\n+            else:\n+                prev_lhs, _, key_transforms = *compiler.compile(self.lhs), []\n+            json_path = compile_json_path(key_transforms)\n+            sql = \"(JSON_EXISTS(%s, '%s') AND %s IS NULL)\" % (prev_lhs, json_path, lhs)\n+            return sql, []\n+        else:\n+            return super().as_sql(compiler, connection)\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformIExact(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IExact):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformIContains(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IContains):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformContains(KeyTransformTextLookupMixin, lookups.Contains):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformStartsWith(KeyTransformTextLookupMixin, lookups.StartsWith):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformIStartsWith(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IStartsWith):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformEndsWith(KeyTransformTextLookupMixin, lookups.EndsWith):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformIEndsWith(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IEndsWith):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformRegex(KeyTransformTextLookupMixin, lookups.Regex):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformIRegex(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IRegex):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformLte(KeyTransformNumericLookupMixin, lookups.LessThanOrEqual):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformLt(KeyTransformNumericLookupMixin, lookups.LessThan):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformGte(KeyTransformNumericLookupMixin, lookups.GreaterThanOrEqual):\n+    pass\n+\n+\n+@KeyTransform.register_lookup\n+class KeyTransformGt(KeyTransformNumericLookupMixin, lookups.GreaterThan):\n+    pass\n+\n+\n+class KeyTransformFactory:\n+\n+    def __init__(self, key_name):\n+        self.key_name = key_name\n+\n+    def __call__(self, *args, **kwargs):\n+        return KeyTransform(self.key_name, *args, **kwargs)\ndiff --git a/django/forms/fields.py b/django/forms/fields.py\nindex c5374c7e9dba..f26ca1fbe15f 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -4,6 +4,7 @@\n \n import copy\n import datetime\n+import json\n import math\n import operator\n import os\n@@ -21,8 +22,8 @@\n     FILE_INPUT_CONTRADICTION, CheckboxInput, ClearableFileInput, DateInput,\n     DateTimeInput, EmailInput, FileInput, HiddenInput, MultipleHiddenInput,\n     NullBooleanSelect, NumberInput, Select, SelectMultiple,\n-    SplitDateTimeWidget, SplitHiddenDateTimeWidget, TextInput, TimeInput,\n-    URLInput,\n+    SplitDateTimeWidget, SplitHiddenDateTimeWidget, Textarea, TextInput,\n+    TimeInput, URLInput,\n )\n from django.utils import formats\n from django.utils.dateparse import parse_datetime, parse_duration\n@@ -37,7 +38,7 @@\n     'RegexField', 'EmailField', 'FileField', 'ImageField', 'URLField',\n     'BooleanField', 'NullBooleanField', 'ChoiceField', 'MultipleChoiceField',\n     'ComboField', 'MultiValueField', 'FloatField', 'DecimalField',\n-    'SplitDateTimeField', 'GenericIPAddressField', 'FilePathField',\n+    'SplitDateTimeField', 'GenericIPAddressField', 'JSONField', 'FilePathField',\n     'SlugField', 'TypedChoiceField', 'TypedMultipleChoiceField', 'UUIDField',\n )\n \n@@ -1211,3 +1212,65 @@ def to_python(self, value):\n             except ValueError:\n                 raise ValidationError(self.error_messages['invalid'], code='invalid')\n         return value\n+\n+\n+class InvalidJSONInput(str):\n+    pass\n+\n+\n+class JSONString(str):\n+    pass\n+\n+\n+class JSONField(CharField):\n+    default_error_messages = {\n+        'invalid': _('Enter a valid JSON value.'),\n+    }\n+    widget = Textarea\n+\n+    def __init__(self, encoder=None, decoder=None, **kwargs):\n+        self.encoder, self.decoder = encoder, decoder\n+        super().__init__(**kwargs)\n+\n+    def to_python(self, value):\n+        if self.disabled:\n+            return value\n+        if value in self.empty_values:\n+            return None\n+        elif isinstance(value, (list, dict, int, float, JSONString)):\n+            return value\n+        try:\n+            converted = json.loads(value, cls=self.decoder)\n+        except json.JSONDecodeError:\n+            raise ValidationError(\n+                self.error_messages['invalid'],\n+                code='invalid',\n+                params={'value': value},\n+            )\n+        if isinstance(converted, str):\n+            return JSONString(converted)\n+        else:\n+            return converted\n+\n+    def bound_data(self, data, initial):\n+        if self.disabled:\n+            return initial\n+        try:\n+            return json.loads(data, cls=self.decoder)\n+        except json.JSONDecodeError:\n+            return InvalidJSONInput(data)\n+\n+    def prepare_value(self, value):\n+        if isinstance(value, InvalidJSONInput):\n+            return value\n+        return json.dumps(value, cls=self.encoder)\n+\n+    def has_changed(self, initial, data):\n+        if super().has_changed(initial, data):\n+            return True\n+        # For purposes of seeing whether something has changed, True isn't the\n+        # same as 1 and the order of keys doesn't matter.\n+        return (\n+            json.dumps(initial, sort_keys=True, cls=self.encoder) !=\n+            json.dumps(self.to_python(data), sort_keys=True, cls=self.encoder)\n+        )\ndiff --git a/docs/internals/deprecation.txt b/docs/internals/deprecation.txt\nindex dc6923d48883..b35c9e57e12d 100644\n--- a/docs/internals/deprecation.txt\n+++ b/docs/internals/deprecation.txt\n@@ -46,6 +46,9 @@ details on these changes.\n \n * The ``HttpRequest.is_ajax()`` method will be removed.\n \n+* ``django.contrib.postgres.fields.JSONField`` and\n+  ``django.contrib.postgres.forms.JSONField`` will be removed.\n+\n See the :ref:`Django 3.1 release notes <deprecated-features-3.1>` for more\n details on these changes.\n \ndiff --git a/docs/ref/checks.txt b/docs/ref/checks.txt\nindex e7b0a5ec8ce8..22efbd7a4e71 100644\n--- a/docs/ref/checks.txt\n+++ b/docs/ref/checks.txt\n@@ -177,6 +177,8 @@ Model fields\n   in historical migrations.\n * **fields.W902**: ``FloatRangeField`` is deprecated and will be removed in\n   Django 3.1. *This check appeared in Django 2.2 and 3.0*.\n+* **fields.W903**: ``django.contrib.postgres.fields.JSONField`` is deprecated\n+  and will be removed in Django 4.0.\n \n File fields\n ~~~~~~~~~~~\n@@ -323,6 +325,7 @@ Models\n   ``<max_length>`` characters.\n * **models.W035**: ``db_table`` ``<db_table>`` is used by multiple models:\n   ``<model list>``.\n+* **models.E036**: ``<database>`` does not support ``JSONField``\\s.\n \n Security\n --------\ndiff --git a/docs/ref/contrib/postgres/fields.txt b/docs/ref/contrib/postgres/fields.txt\nindex e8fcef62158c..d7c40094111a 100644\n--- a/docs/ref/contrib/postgres/fields.txt\n+++ b/docs/ref/contrib/postgres/fields.txt\n@@ -517,6 +517,14 @@ using in conjunction with lookups on\n     of the JSON which allows indexing. The trade-off is a small additional cost\n     on writing to the ``jsonb`` field. ``JSONField`` uses ``jsonb``.\n \n+.. deprecated:: 3.1\n+\n+    A new :class:`~django.db.models.JSONField` that works on all supported\n+    database backends is available starting with Django 3.1. It is advised to\n+    migrate and use the new ``JSONField``. For now, this PostgreSQL-only\n+    ``JSONField`` is left as a reference to the new one and is deprecated as of\n+    this release.\n+\n Querying ``JSONField``\n ----------------------\n \ndiff --git a/docs/ref/contrib/postgres/forms.txt b/docs/ref/contrib/postgres/forms.txt\nindex f559ac75cb8a..9faf51c71eaa 100644\n--- a/docs/ref/contrib/postgres/forms.txt\n+++ b/docs/ref/contrib/postgres/forms.txt\n@@ -173,6 +173,14 @@ Fields\n         it is a useful way to format data from a client-side widget for\n         submission to the server.\n \n+.. deprecated:: 3.1\n+\n+    A new :class:`~django.forms.JSONField` that works on all supported\n+    database backends is available starting with Django 3.1. It is advised to\n+    migrate and use the new JSONField. For now, this PostgreSQL-only\n+    ``JSONField`` is left as a reference to the new one and is deprecated as of\n+    this release.\n+\n Range Fields\n ------------\n \ndiff --git a/docs/ref/databases.txt b/docs/ref/databases.txt\nindex b4c190bafddd..5610fdb7d707 100644\n--- a/docs/ref/databases.txt\n+++ b/docs/ref/databases.txt\n@@ -778,6 +778,95 @@ iterator. Your code must handle this.\n \n .. _`Isolation in SQLite`: https://sqlite.org/isolation.html\n \n+.. _sqlite-json1:\n+\n+Enabling JSON1 extension on SQLite\n+----------------------------------\n+\n+This document describes how to enable JSON1 extension on Python's\n+:py:mod:`sqlite3` library so that :class:`~django.db.models.JSONField` can be\n+used. If the extension is not enabled on your installation and there is no\n+other database connection that supports ``JSONField``, a system error will be\n+raised (\"``No database connection that supports JSONField is found.``\"). To\n+check if the extension is enabled on your installation, you can do a query with\n+one of the functions included in the extension, e.g. ``JSON()``. For example::\n+\n+    >>> import sqlite3\n+    >>> conn = sqlite3.connect(':memory:')\n+    >>> c = conn.cursor()\n+    >>> c.execute(\"SELECT JSON('123');\")\n+\n+If the query doesn't throw any errors, then the JSON1 extension should already\n+be enabled. Otherwise, follow the instructions below according to your\n+operating system to set it up correctly.\n+\n+Linux\n+~~~~~\n+\n+On most major Linux distributions, the JSON1 extension is included in their\n+SQLite and/or Python packages and enabled by default. If that's not the case on\n+your installation, then do the following:\n+\n+- Download the `SQLite amalgamation`_,\n+  with or without the configuration script.\n+- Extract the source code archive and enter the directory of the result.\n+- Compile the source code using the ``-DSQLITE_ENABLE_JSON1`` flag to enable\n+  the JSON1 extension. For example:\n+\n+  .. code-block:: console\n+\n+      gcc -DSQLITE_ENABLE_JSON1 -c -fPIC sqlite3.c\n+\n+  To enable other extensions, see the `compilation instructions`_.\n+- Create a shared library. For example:\n+\n+  .. code-block:: console\n+\n+      gcc -shared -o libsqlite3.so -fPIC sqlite3.o -ldl -lpthread\n+\n+- Place the resulting file (``libsqlite3.so``) in a desired directory, e.g.\n+  ``/usr/lib/sqlite3/``.\n+- Set the ``LD_PRELOAD`` environment variable to use your compiled SQLite every\n+  time you run Django. For example:\n+\n+  .. code-block:: console\n+\n+      export LD_PRELOAD=/usr/lib/sqlite3/libsqlite3.so\n+\n+- Now, the JSON1 extension should be ready to be used in Python and Django.\n+\n+.. _`SQLite amalgamation`: https://www.sqlite.org/download.html\n+.. _`compilation instructions`: https://www.sqlite.org/howtocompile.html\n+\n+Mac\n+~~~\n+\n+On Mac, follow the instructions for Linux above, but instead of setting the\n+``LD_PRELOAD`` environment variable, use ``DYLD_LIBRARY_PATH``. For example:\n+\n+  .. code-block:: console\n+\n+      export DYLD_LIBRARY_PATH=/usr/lib/sqlite3\n+\n+Windows\n+~~~~~~~\n+\n+- Download the `precompiled DLL`_ that matches your Python installation (32-bit\n+  or 64-bit).\n+- Locate your Python installation. By default, it should be in\n+  ``%localappdata%\\Programs\\Python\\PythonXX``, where ``XX`` is the Python\n+  version. For example, it's located in\n+  ``C:\\Users\\<username>\\AppData\\Local\\Programs\\Python\\Python37``. If you added\n+  Python installation directory to your ``PATH`` environment variable, you can\n+  run the command ``where python`` on a command prompt to locate it.\n+- Enter the ``DLLs`` directory in your Python installation.\n+- Rename (or delete) ``sqlite3.dll`` inside the ``DLLs`` directory.\n+- Extract ``sqlite3.dll`` from the downloaded DLL archive and put it in the\n+  ``DLLs`` directory.\n+- Now, the JSON1 extension should be ready to be used in Python and Django.\n+\n+.. _`precompiled DLL`: https://www.sqlite.org/download.html\n+\n .. _oracle-notes:\n \n Oracle notes\ndiff --git a/docs/ref/forms/fields.txt b/docs/ref/forms/fields.txt\nindex d2a0550a47e2..da05905af497 100644\n--- a/docs/ref/forms/fields.txt\n+++ b/docs/ref/forms/fields.txt\n@@ -809,6 +809,64 @@ For each field, we describe the default widget used if you don't specify\n         ``192.0.2.1``. Default is disabled. Can only be used\n         when ``protocol`` is set to ``'both'``.\n \n+``JSONField``\n+-------------\n+\n+.. class:: JSONField(encoder=None, decoder=None, **kwargs)\n+\n+    A field which accepts JSON encoded data for a\n+    :class:`~django.db.models.JSONField`.\n+\n+    * Default widget: :class:`Textarea`\n+    * Empty value: ``''`` (an empty string)\n+    * Normalizes to: Python representation of the JSON value (usually as a\n+      dictionary, list, string, number, boolean or ``None``), depending on\n+      ``decoder``.\n+    * Validates that the given value is a valid JSON value.\n+    * Error message keys: ``required``, ``invalid``\n+\n+    Takes two optional arguments:\n+\n+    .. attribute:: encoder\n+\n+        A :py:class:`json.JSONEncoder` subclass to serialize data types\n+        not supported by the standard JSON serializer (``datetime``, ``uuid``,\n+        etc.). For example, you can use the\n+        :class:`~django.core.serializers.json.DjangoJSONEncoder` class.\n+\n+        The ``encoder`` is used to serialize the data before it's rendered by the\n+        widget. It is also used in :meth:`Field.has_changed()`.\n+\n+        If ``None`` is specified, it defaults to ``json.JSONEncoder``.\n+\n+    .. attribute:: decoder\n+\n+        A :py:class:`json.JSONDecoder` subclass to deserialize the input.\n+        Your deserialization may need to account for the fact that you can't be\n+        certain of the input type. For example, you run the risk of returning a\n+        ``datetime`` that was actually a string that just happened to be in the\n+        same format chosen for ``datetime``\\s.\n+\n+        The ``decoder`` can be used to validate the input. If\n+        :py:class:`json.JSONDecodeError` is raised during the deserialization, a\n+        ``ValidationError`` will be raised.\n+\n+        If ``None`` is specified, it defaults to ``json.JSONDecoder``.\n+\n+    Specification for ``JSONEncoder`` and ``JSONDecoder`` subclasses can be found\n+    in the Python documentation.\n+\n+    .. note::\n+\n+        If you use a :class:`ModelForm <django.forms.ModelForm>`, the ``encoder`` and\n+        ``decoder`` from its :class:`~django.db.models.JSONField` will be used.\n+\n+    .. admonition:: User friendly forms\n+\n+        ``JSONField`` is not particularly user friendly in most cases. However,\n+        it is a useful way to format data from a client-side widget for\n+        submission to the server.\n+\n ``MultipleChoiceField``\n -----------------------\n \ndiff --git a/docs/ref/models/fields.txt b/docs/ref/models/fields.txt\nindex d321506d996a..3b4f88367fd8 100644\n--- a/docs/ref/models/fields.txt\n+++ b/docs/ref/models/fields.txt\n@@ -345,7 +345,7 @@ The default can't be a mutable object (model instance, ``list``, ``set``, etc.),\n as a reference to the same instance of that object would be used as the default\n value in all new model instances. Instead, wrap the desired default in a\n callable. For example, if you want to specify a default ``dict`` for\n-:class:`~django.contrib.postgres.fields.JSONField`, use a function::\n+:class:`~django.db.models.JSONField`, use a function::\n \n     def contact_default():\n         return {\"email\": \"to1@example.com\"}\n@@ -1169,6 +1169,84 @@ are converted to lowercase.\n If you allow for blank values, you have to allow for null values since blank\n values are stored as null.\n \n+``JSONField``\n+-------------\n+\n+.. class:: JSONField(encoder=None, decoder=None, **options)\n+\n+A field for storing JSON encoded data. In Python the data is represented in\n+its Python native format: dictionaries, lists, strings, numbers, booleans\n+and ``None``.\n+\n+.. attribute:: JSONField.encoder\n+\n+    An optional :py:class:`json.JSONEncoder` subclass to serialize data types\n+    not supported by the standard JSON serializer (``datetime``, ``uuid``,\n+    etc.). For example, you can use the\n+    :class:`~django.core.serializers.json.DjangoJSONEncoder` class.\n+\n+    If ``None`` is specified, it defaults to ``json.JSONEncoder``.\n+\n+.. attribute:: JSONField.decoder\n+\n+    An optional :py:class:`json.JSONDecoder` subclass to deserialize the value\n+    retrieved from the database. The value will be in the format chosen by the\n+    custom encoder (most often a string). Your deserialization may need to\n+    account for the fact that you can't be certain of the input type. For\n+    example, you run the risk of returning a ``datetime`` that was actually a\n+    string that just happened to be in the same format chosen for\n+    ``datetime``\\s.\n+\n+    If ``None`` is specified, it defaults to ``json.JSONDecoder``.\n+\n+Specification for ``JSONEncoder`` and ``JSONDecoder`` subclasses can be found\n+in the Python documentation.\n+\n+If you give the field a :attr:`~django.db.models.Field.default`, ensure\n+it's an immutable object, such as a ``str``, or a callable object that returns\n+a fresh mutable object each time, such as ``dict`` or a function. Providing a\n+mutable default object like ``default={}`` or ``default=[]`` shares the one\n+object between all model instances. There is a system check for this.\n+\n+To query ``JSONField`` in the database, see\n+:ref:`Querying JSONField <querying-jsonfield>`.\n+\n+.. note::\n+\n+    Oracle Database supports storing JSON data using SQL data types\n+    ``VARCHAR2``, ``CLOB``, and ``BLOB``. ``JSONField`` uses ``CLOB``.\n+\n+.. note::\n+\n+    PostgreSQL has two native JSON based data types: ``json`` and ``jsonb``.\n+    The main difference between them is how they are stored and how they can be\n+    queried. PostgreSQL's ``json`` field is stored as the original string\n+    representation of the JSON and must be decoded on the fly when queried\n+    based on keys. The ``jsonb`` field is stored based on the actual structure\n+    of the JSON which allows indexing. The trade-off is a small additional cost\n+    on writing to the ``jsonb`` field. ``JSONField`` uses ``jsonb``.\n+\n+.. admonition:: MariaDB users\n+\n+    Requires MariaDB 10.2.7 or later.\n+\n+.. admonition:: MySQL users\n+\n+    Requires MySQL 5.7.8 or later.\n+\n+.. admonition:: Oracle users\n+\n+    Oracle Database does not support storing JSON scalar values. Only JSON\n+    objects and arrays (represented in Python using :py:class:`dict` and\n+    :py:class:`list`) are supported.\n+\n+.. admonition:: SQLite users\n+\n+    Requires SQLite 3.9.0 or later with the JSON1_ extension enabled. See\n+    :ref:`sqlite-json1` for more details.\n+\n+.. _JSON1: https://www.sqlite.org/json1.html\n+\n ``NullBooleanField``\n --------------------\n \ndiff --git a/docs/releases/3.1.txt b/docs/releases/3.1.txt\nindex 221cf39dee0d..110a268bb247 100644\n--- a/docs/releases/3.1.txt\n+++ b/docs/releases/3.1.txt\n@@ -27,6 +27,20 @@ officially support the latest release of each series.\n What's new in Django 3.1\n ========================\n \n+JSONField for all supported database backends\n+---------------------------------------------\n+\n+Django now includes a :class:`models.JSONField <django.db.models.JSONField>`\n+and a :class:`forms.JSONField <django.forms.JSONField>` that work on all\n+supported database backends. Both fields support the use of custom JSON encoder\n+and decoder. The model field also supports lookups and transforms supported in\n+previously\n+:class:`PostgreSQL-only JSONField <django.contrib.postgres.fields.JSONField>`.\n+\n+If your project uses the PostgreSQL ``JSONField`` form and/or model fields, it\n+is advised to migrate and use the new fields. For now, the old fields are left\n+as a reference to the new ones and are deprecated as of this release.\n+\n Minor features\n --------------\n \n@@ -421,6 +435,11 @@ Miscellaneous\n \n * ``django.utils.decorators.classproperty()`` decorator is moved to\n   ``django.utils.functional.classproperty()``.\n+* Third party database backends must implement support for\n+  :class:`~django.db.models.JSONField` or set\n+  ``DatabaseFeatures.supports_json_field`` to ``False``. If ``JSONField``\n+  introspection is also implemented, set\n+  ``DatabaseFeatures.can_introspect_json_field`` to ``True``.\n \n * :tfilter:`floatformat` template filter now outputs (positive) ``0`` for\n   negative numbers which round to zero.\n@@ -454,6 +473,15 @@ Miscellaneous\n Features deprecated in 3.1\n ==========================\n \n+PostgreSQL ``JSONField``\n+------------------------\n+\n+:class:`django.contrib.postgres.fields.JSONField` and\n+:class:`django.contrib.postgres.forms.JSONField` are\n+deprecated in favor of the similar fields that work on all supported database\n+backends: :class:`models.JSONField <django.db.models.JSONField>` and\n+:class:`forms.JSONField <django.forms.JSONField>`.\n+\n Miscellaneous\n -------------\n \ndiff --git a/docs/topics/db/queries.txt b/docs/topics/db/queries.txt\nindex 79f38084fa55..fba275616178 100644\n--- a/docs/topics/db/queries.txt\n+++ b/docs/topics/db/queries.txt\n@@ -790,6 +790,286 @@ being evaluated and therefore populate the cache::\n     Simply printing the queryset will not populate the cache. This is because\n     the call to ``__repr__()`` only returns a slice of the entire queryset.\n \n+.. _querying-jsonfield:\n+\n+Querying ``JSONField``\n+======================\n+\n+Lookups implementation is different in :class:`~django.db.models.JSONField`,\n+mainly due to the existence of key transformations. To demonstrate, we will\n+use the following example model::\n+\n+    from django.db import models\n+\n+    class Dog(models.Model):\n+        name = models.CharField(max_length=200)\n+        data = models.JSONField()\n+\n+        def __str__(self):\n+            return self.name\n+\n+As with other fields, storing ``None`` as the field's value will store it as\n+SQL ``NULL``. While not recommended, it is possible to store JSON scalar\n+``null`` instead of SQL ``NULL`` by using\n+:meth:`Value('null') <django.db.models.Value>`. However, after retrieved from\n+the database, the Python representation of the data is the same as SQL\n+``NULL``, i.e. ``None``. Therefore, it can be hard to distinguish between the\n+two.\n+\n+Note that this only applies to ``None`` as the top-level value of the field.\n+If ``None`` is inside a :py:class:`list` or :py:class:`dict`, it will always\n+be interpreted as JSON ``null``.\n+\n+When querying, ``None`` value will always be interpreted as JSON ``null``.\n+To query for SQL ``NULL``, use :lookup:`isnull`.\n+\n+To illustrate::\n+\n+    >>> Dog.objects.create(name='Max', data=None)  # Stored as SQL NULL\n+    >>> Dog.objects.create(name='Archie', data=Value('null'))  # Stored as JSON null\n+\n+    >>> Dog.objects.filter(data=None)\n+    <QuerySet [<Dog: Archie>]>\n+    >>> Dog.objects.filter(data=Value('null'))\n+    <QuerySet [<Dog: Archie>]>\n+    >>> Dog.objects.filter(data__isnull=True)\n+    <QuerySet [<Dog: Max>]>\n+\n+.. note::\n+\n+    Storing JSON scalar ``null`` does not violate\n+    :attr:`null=False <django.db.models.Field.null>`.\n+\n+.. fieldlookup:: jsonfield.key\n+\n+Key, index, and path transforms\n+-------------------------------\n+\n+To query based on a given dictionary key, simply use that key as the lookup\n+name::\n+\n+    >>> Dog.objects.create(name='Rufus', data={\n+    ...     'breed': 'labrador',\n+    ...     'owner': {\n+    ...         'name': 'Bob',\n+    ...         'other_pets': [{\n+    ...             'name': 'Fishy',\n+    ...         }],\n+    ...     },\n+    ... })\n+    >>> Dog.objects.create(name='Meg', data={'breed': 'collie', 'owner': None})\n+\n+    >>> Dog.objects.filter(data__breed='collie')\n+    <QuerySet [<Dog: Meg>]>\n+\n+Multiple keys can be chained together to form a path transform::\n+\n+    >>> Dog.objects.filter(data__owner__name='Bob')\n+    <QuerySet [<Dog: Rufus>]>\n+\n+If the key is an integer, it will be interpreted as an index transform in an\n+array::\n+\n+    >>> Dog.objects.filter(data__owner__other_pets__0__name='Fishy')\n+    <QuerySet [<Dog: Rufus>]>\n+\n+If the key you wish to query by clashes with the name of another lookup, use\n+the :lookup:`contains <jsonfield.contains>` lookup instead.\n+\n+.. note::\n+\n+    The transform examples given above implicitly use the :lookup:`exact`\n+    lookup. Key, index, and path transforms can also be chained with\n+    :lookup:`iexact`, :lookup:`contains`, :lookup:`icontains`,\n+    :lookup:`startswith`, :lookup:`istartswith`, :lookup:`endswith`,\n+    :lookup:`iendswith`, :lookup:`regex`, :lookup:`iregex`, :lookup:`lt`,\n+    :lookup:`lte`, :lookup:`gt`, and :lookup:`gte` lookups.\n+\n+To query for ``null`` in JSON data, use ``None`` as a value::\n+\n+    >>> Dog.objects.filter(data__owner=None)\n+    <QuerySet [<Dog: Meg>]>\n+\n+To query for missing keys, use the ``isnull`` lookup::\n+\n+    >>> Dog.objects.create(name='Shep', data={'breed': 'collie'})\n+    >>> Dog.objects.filter(data__owner__isnull=True)\n+    <QuerySet [<Dog: Shep>]>\n+\n+.. warning::\n+\n+    Since any string could be a key in a JSON object, any lookup other than\n+    those listed below will be interpreted as a key lookup. No errors are\n+    raised. Be extra careful for typing mistakes, and always check your queries\n+    work as you intend.\n+\n+.. admonition:: MariaDB and Oracle users\n+\n+    Using :meth:`~django.db.models.query.QuerySet.order_by` on key, index,\n+    or path transforms will sort the objects using the string representation\n+    of the values. This is because MariaDB and Oracle Database do not provide\n+    a function that converts JSON values into their equivalent SQL values.\n+    Therefore, ordering by numerical JSON values does not work as expected.\n+\n+.. admonition:: Oracle users\n+\n+    On Oracle Database, using ``None`` as the lookup value in an\n+    :meth:`~django.db.models.query.QuerySet.exclude` query will return objects\n+    that do not have ``null`` as the value at the given path, including objects\n+    that do not have the path. On other database backends, the query will\n+    return objects that have the path and the value is not ``null``.\n+\n+.. note::\n+\n+    On PostgreSQL, if only one key or index is used, the SQL operator ``->`` is\n+    used. If multiple operators are used then the ``#>`` operator is used.\n+    On MySQL, MariaDB, and SQLite, the ``JSON_EXTRACT`` function is used.\n+    On Oracle Database, a combination of ``JSON_QUERY`` and ``JSON_VALUE``\n+    using ``COALESCE`` is used.\n+\n+Containment and key operations\n+------------------------------\n+\n+.. fieldlookup:: jsonfield.contains\n+\n+``contains``\n+~~~~~~~~~~~~\n+\n+The :lookup:`contains` lookup is overridden on ``JSONField``. The returned\n+objects are those where the given ``dict`` of key-value pairs are all\n+contained in the top-level of the field. For example::\n+\n+    >>> Dog.objects.create(name='Rufus', data={'breed': 'labrador', 'owner': 'Bob'})\n+    >>> Dog.objects.create(name='Meg', data={'breed': 'collie', 'owner': 'Bob'})\n+    >>> Dog.objects.create(name='Fred', data={})\n+\n+    >>> Dog.objects.filter(data__contains={'owner': 'Bob'})\n+    <QuerySet [<Dog: Rufus>, <Dog: Meg>]>\n+\n+    >>> Dog.objects.filter(data__contains={'breed': 'collie'})\n+    <QuerySet [<Dog: Meg>]>\n+\n+.. note::\n+\n+    This lookup is only overridden on ``JSONField``. It is not overridden on\n+    key, index, and path transforms.\n+\n+.. note::\n+\n+    On PostgreSQL, the implementation uses the SQL operator ``@>``. On MySQL\n+    and MariaDB, it uses the SQL function ``JSON_CONTAINS``. On Oracle\n+    Database, it uses the SQL function ``JSON_QUERY`` and ``JSON_VALUE``.\n+    On SQLite, it uses the SQL function ``JSON_EXTRACT`` and ``JSON_TYPE``.\n+\n+.. admonition:: Oracle and SQLite users\n+\n+    Since Oracle Database and SQLite don't provide a built-in function to\n+    support this lookup, the implementation is actually similar to key\n+    lookups chained together with the SQL operator ``AND``.\n+\n+.. fieldlookup:: jsonfield.contained_by\n+\n+``contained_by``\n+~~~~~~~~~~~~~~~~\n+\n+This is the inverse of the :lookup:`contains <jsonfield.contains>` lookup -\n+the objects returned will be those where the key-value pairs on the object are\n+a subset of those in the value passed. For\n+example::\n+\n+    >>> Dog.objects.create(name='Rufus', data={'breed': 'labrador', 'owner': 'Bob'})\n+    >>> Dog.objects.create(name='Meg', data={'breed': 'collie', 'owner': 'Bob'})\n+    >>> Dog.objects.create(name='Fred', data={})\n+\n+    >>> Dog.objects.filter(data__contained_by={'breed': 'collie', 'owner': 'Bob'})\n+    <QuerySet [<Dog: Meg>, <Dog: Fred>]>\n+\n+    >>> Dog.objects.filter(data__contained_by={'breed': 'collie'})\n+    <QuerySet [<Dog: Fred>]>\n+\n+.. note::\n+\n+    On PostgreSQL, the implementation uses the SQL operator ``<@``. On MySQL\n+    and MariaDB, it uses the SQL function ``JSON_CONTAINS`` like ``contains``\n+    lookup but with the arguments switched.\n+\n+.. admonition:: Oracle and SQLite users\n+\n+    Due to the limitation on Oracle and SQLite database backends, this lookup\n+    is not supported.\n+\n+.. fieldlookup:: jsonfield.has_key\n+\n+``has_key``\n+~~~~~~~~~~~\n+\n+Returns objects where the given key is in the top-level of the data. For\n+example::\n+\n+    >>> Dog.objects.create(name='Rufus', data={'breed': 'labrador'})\n+    >>> Dog.objects.create(name='Meg', data={'breed': 'collie', 'owner': 'Bob'})\n+\n+    >>> Dog.objects.filter(data__has_key='owner')\n+    <QuerySet [<Dog: Meg>]>\n+\n+.. note::\n+\n+    On PostgreSQL, the implementation uses the SQL operator ``?``. On MySQL\n+    and MariaDB, it uses the SQL function ``JSON_CONTAINS_PATH``. On Oracle\n+    Database, it uses the SQL function ``JSON_EXISTS``. On SQLite, it uses\n+    the SQL function ``JSON_TYPE``.\n+\n+.. admonition:: SQLite users\n+\n+    The implementation uses ``JSON_TYPE`` along with ``IS NOT NULL`` clause.\n+    The function ``JSON_EXTRACT`` is not used because it also returns SQL\n+    ``NULL`` for JSON value ``null``, which makes it impossible to\n+    differentiate between a missing key and an existing key with a ``null``\n+    value.\n+\n+.. fieldlookup:: jsonfield.has_any_keys\n+\n+``has_any_keys``\n+~~~~~~~~~~~~~~~~\n+\n+Returns objects where any of the given keys are in the top-level of the data.\n+For example::\n+\n+    >>> Dog.objects.create(name='Rufus', data={'breed': 'labrador'})\n+    >>> Dog.objects.create(name='Meg', data={'owner': 'Bob'})\n+    >>> Dog.objects.create(name='Fred', data={})\n+\n+    >>> Dog.objects.filter(data__has_any_keys=['owner', 'breed'])\n+    <QuerySet [<Dog: Rufus>, <Dog: Meg>]>\n+\n+.. note::\n+\n+    On PostgreSQL, the implementation uses the SQL operator ``?|``. On all\n+    other database backends, the implementation is similar to\n+    :lookup:`contains <jsonfield.contains>` lookup and each key is joined\n+    using the SQL ``OR`` operator.\n+\n+.. fieldlookup:: jsonfield.has_keys\n+\n+``has_keys``\n+~~~~~~~~~~~~\n+\n+Returns objects where all of the given keys are in the top-level of the data.\n+For example::\n+\n+    >>> Dog.objects.create(name='Rufus', data={})\n+    >>> Dog.objects.create(name='Meg', data={'breed': 'collie', 'owner': 'Bob'})\n+\n+    >>> Dog.objects.filter(data__has_keys=['breed', 'owner'])\n+    <QuerySet [<Dog: Meg>]>\n+\n+.. note::\n+\n+    On PostgreSQL, the implementation uses the SQL operator ``?&``. On all\n+    other database backends, the implementation is similar to\n+    :lookup:`contains <jsonfield.contains>` lookup and each key is joined\n+    using the SQL ``AND`` operator.\n+\n .. _complex-lookups-with-q:\n \n Complex lookups with ``Q`` objects\ndiff --git a/tests/forms_tests/field_tests/test_jsonfield.py b/tests/forms_tests/field_tests/test_jsonfield.py\nnew file mode 100644\nindex 000000000000..521b74e98c98\n--- /dev/null\n+++ b/tests/forms_tests/field_tests/test_jsonfield.py\n@@ -0,0 +1,110 @@\n+import json\n+import uuid\n+\n+from django import forms\n+from django.core import exceptions\n+from django.core.serializers.json import DjangoJSONEncoder\n+from django.test import SimpleTestCase\n+\n+\n+class CustomDecoder(json.JSONDecoder):\n+    def __init__(self, object_hook=None, *args, **kwargs):\n+        return super().__init__(object_hook=self.object_hook, *args, **kwargs)\n+\n+    def object_hook(self, dct):\n+        try:\n+            dct['uuid'] = uuid.UUID(dct['uuid'])\n+        except KeyError:\n+            pass\n+        return dct\n+\n+\n+class TestFormField(SimpleTestCase):\n+\n+    def test_valid(self):\n+        field = forms.JSONField()\n+        value = field.clean('{\"a\": \"b\"}')\n+        self.assertEqual(value, {'a': 'b'})\n+\n+    def test_valid_empty(self):\n+        field = forms.JSONField(required=False)\n+        value = field.clean('')\n+        self.assertIsNone(value)\n+\n+    def test_invalid(self):\n+        field = forms.JSONField()\n+        with self.assertRaisesMessage(exceptions.ValidationError, 'Enter a valid JSON value.'):\n+            field.clean('{some badly formed: json}')\n+\n+    def test_formfield_disabled(self):\n+        class JsonForm(forms.Form):\n+            name = forms.CharField()\n+            jfield = forms.JSONField(disabled=True)\n+\n+        form = JsonForm({'name': 'xyz', 'jfield': '[\"bar\"]'}, initial={'jfield': ['foo']})\n+        self.assertIn('[&quot;foo&quot;]</textarea>', form.as_p())\n+\n+    def test_prepare_value(self):\n+        field = forms.JSONField()\n+        self.assertEqual(field.prepare_value({'a': 'b'}), '{\"a\": \"b\"}')\n+        self.assertEqual(field.prepare_value(None), 'null')\n+        self.assertEqual(field.prepare_value('foo'), '\"foo\"')\n+\n+    def test_redisplay_wrong_input(self):\n+        \"\"\"\n+        When displaying a bound form (typically due to invalid input), the form\n+        should not overquote JSONField inputs.\n+        \"\"\"\n+        class JsonForm(forms.Form):\n+            name = forms.CharField(max_length=2)\n+            jfield = forms.JSONField()\n+\n+        # JSONField input is fine, name is too long\n+        form = JsonForm({'name': 'xyz', 'jfield': '[\"foo\"]'})\n+        self.assertNotIn('jfield', form.errors)\n+        self.assertIn('[&quot;foo&quot;]</textarea>', form.as_p())\n+\n+        # This time, the JSONField input is wrong\n+        form = JsonForm({'name': 'xy', 'jfield': '{\"foo\"}'})\n+        self.assertIn('jfield', form.errors)\n+        self.assertIn('{&quot;foo&quot;}</textarea>', form.as_p())\n+\n+    def test_widget(self):\n+        \"\"\"The default widget of a JSONField is a Textarea.\"\"\"\n+        field = forms.JSONField()\n+        self.assertIsInstance(field.widget, forms.widgets.Textarea)\n+\n+    def test_custom_widget_kwarg(self):\n+        \"\"\"The widget can be overridden with a kwarg.\"\"\"\n+        field = forms.JSONField(widget=forms.widgets.Input)\n+        self.assertIsInstance(field.widget, forms.widgets.Input)\n+\n+    def test_custom_widget_attribute(self):\n+        \"\"\"The widget can be overridden with an attribute.\"\"\"\n+        class CustomJSONField(forms.JSONField):\n+            widget = forms.widgets.Input\n+\n+        field = CustomJSONField()\n+        self.assertIsInstance(field.widget, forms.widgets.Input)\n+\n+    def test_already_converted_value(self):\n+        field = forms.JSONField(required=False)\n+        tests = [\n+            '[\"a\", \"b\", \"c\"]', '{\"a\": 1, \"b\": 2}', '1', '1.5', '\"foo\"',\n+            'true', 'false', 'null',\n+        ]\n+        for json_string in tests:\n+            with self.subTest(json_string=json_string):\n+                val = field.clean(json_string)\n+                self.assertEqual(field.clean(val), val)\n+\n+    def test_has_changed(self):\n+        field = forms.JSONField()\n+        self.assertIs(field.has_changed({'a': True}, '{\"a\": 1}'), True)\n+        self.assertIs(field.has_changed({'a': 1, 'b': 2}, '{\"b\": 2, \"a\": 1}'), False)\n+\n+    def test_custom_encoder_decoder(self):\n+        value = {'uuid': uuid.UUID('{12345678-1234-5678-1234-567812345678}')}\n+        field = forms.JSONField(encoder=DjangoJSONEncoder, decoder=CustomDecoder)\n+        self.assertEqual(field.prepare_value(value), '{\"uuid\": \"12345678-1234-5678-1234-567812345678\"}')\n+        self.assertEqual(field.clean('{\"uuid\": \"12345678-1234-5678-1234-567812345678\"}'), value)\ndiff --git a/tests/inspectdb/models.py b/tests/inspectdb/models.py\nindex 8a48031b2487..d0076ce94f99 100644\n--- a/tests/inspectdb/models.py\n+++ b/tests/inspectdb/models.py\n@@ -68,6 +68,17 @@ class ColumnTypes(models.Model):\n     uuid_field = models.UUIDField()\n \n \n+class JSONFieldColumnType(models.Model):\n+    json_field = models.JSONField()\n+    null_json_field = models.JSONField(blank=True, null=True)\n+\n+    class Meta:\n+        required_db_features = {\n+            'can_introspect_json_field',\n+            'supports_json_field',\n+        }\n+\n+\n class UniqueTogether(models.Model):\n     field1 = models.IntegerField()\n     field2 = models.CharField(max_length=10)\ndiff --git a/tests/inspectdb/tests.py b/tests/inspectdb/tests.py\nindex 6e3f4b8aa608..afe89e0dda6a 100644\n--- a/tests/inspectdb/tests.py\n+++ b/tests/inspectdb/tests.py\n@@ -85,6 +85,15 @@ def test_field_types(self):\n         elif not connection.features.interprets_empty_strings_as_nulls:\n             assertFieldType('uuid_field', \"models.CharField(max_length=32)\")\n \n+    @skipUnlessDBFeature('can_introspect_json_field', 'supports_json_field')\n+    def test_json_field(self):\n+        out = StringIO()\n+        call_command('inspectdb', 'inspectdb_jsonfieldcolumntype', stdout=out)\n+        output = out.getvalue()\n+        if not connection.features.interprets_empty_strings_as_nulls:\n+            self.assertIn('json_field = models.JSONField()', output)\n+        self.assertIn('null_json_field = models.JSONField(blank=True, null=True)', output)\n+\n     def test_number_field_types(self):\n         \"\"\"Test introspection of various Django field types\"\"\"\n         assertFieldType = self.make_field_type_asserter()\ndiff --git a/tests/invalid_models_tests/test_models.py b/tests/invalid_models_tests/test_models.py\nindex ec2d345d5a9c..e8a595f6e6dd 100644\n--- a/tests/invalid_models_tests/test_models.py\n+++ b/tests/invalid_models_tests/test_models.py\n@@ -1,4 +1,5 @@\n import unittest\n+from unittest import mock\n \n from django.conf import settings\n from django.core.checks import Error, Warning\n@@ -6,7 +7,7 @@\n from django.db import connection, connections, models\n from django.db.models.functions import Lower\n from django.db.models.signals import post_init\n-from django.test import SimpleTestCase\n+from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature\n from django.test.utils import isolate_apps, override_settings, register_lookup\n \n \n@@ -1211,6 +1212,42 @@ def dummy_function(*args, **kwargs):\n         ])\n \n \n+@isolate_apps('invalid_models_tests')\n+class JSONFieldTests(TestCase):\n+\n+    @skipUnlessDBFeature('supports_json_field')\n+    def test_ordering_by_json_field_value(self):\n+        class Model(models.Model):\n+            field = models.JSONField()\n+\n+            class Meta:\n+                ordering = ['field__value']\n+\n+        self.assertEqual(Model.check(), [])\n+\n+    def test_check_json_fields(self):\n+        class Model(models.Model):\n+            field = models.JSONField()\n+\n+        error = Error(\n+            '%s does not support JSONFields.' % connection.display_name,\n+            obj=Model,\n+            id='models.E036',\n+        )\n+        expected = [] if connection.features.supports_json_field else [error, error]\n+        self.assertEqual(Model.check(), expected)\n+\n+    def test_json_fields_required_db_features(self):\n+        class Model(models.Model):\n+            age = models.JSONField()\n+\n+            class Meta:\n+                required_db_features = {'supports_json_field'}\n+\n+        with mock.patch.object(connection.features, 'supports_json_field', False):\n+            self.assertEqual(Model.check(), [])\n+\n+\n @isolate_apps('invalid_models_tests')\n class ConstraintsTests(SimpleTestCase):\n     def test_check_constraints(self):\ndiff --git a/tests/model_fields/models.py b/tests/model_fields/models.py\nindex 0fd5910339ea..18620c404c7d 100644\n--- a/tests/model_fields/models.py\n+++ b/tests/model_fields/models.py\n@@ -335,6 +335,20 @@ class PersonTwoImages(models.Model):\n                                   width_field='headshot_width')\n \n \n+class JSONModel(models.Model):\n+    value = models.JSONField()\n+\n+    class Meta:\n+        required_db_features = {'supports_json_field'}\n+\n+\n+class NullableJSONModel(models.Model):\n+    value = models.JSONField(blank=True, null=True)\n+\n+    class Meta:\n+        required_db_features = {'supports_json_field'}\n+\n+\n class AllFieldsModel(models.Model):\n     big_integer = models.BigIntegerField()\n     binary = models.BinaryField()\ndiff --git a/tests/model_fields/test_jsonfield.py b/tests/model_fields/test_jsonfield.py\nnew file mode 100644\nindex 000000000000..12bb95899ec9\n--- /dev/null\n+++ b/tests/model_fields/test_jsonfield.py\n@@ -0,0 +1,691 @@\n+import json\n+import operator\n+import uuid\n+from unittest import skipIf\n+\n+from tests.forms_tests.field_tests.test_jsonfield import CustomDecoder\n+\n+from django import forms\n+from django.core import checks, serializers\n+from django.core.exceptions import ValidationError\n+from django.core.serializers.json import DjangoJSONEncoder\n+from django.db import (\n+    DataError, IntegrityError, OperationalError, connection, models,\n+)\n+from django.db.models import Count, F, OuterRef, Q, Subquery, Transform, Value\n+from django.db.models.expressions import RawSQL\n+from django.db.models.fields.json import (\n+    KeyTextTransform, KeyTransform, KeyTransformFactory,\n+    KeyTransformTextLookupMixin,\n+)\n+from django.db.models.functions import Cast\n+from django.db.utils import DatabaseError\n+from django.test import SimpleTestCase, TestCase, skipUnlessDBFeature\n+from django.test.utils import CaptureQueriesContext, isolate_apps\n+from django.utils.version import PY37\n+\n+from .models import JSONModel, NullableJSONModel\n+\n+\n+class StrEncoder(json.JSONEncoder):\n+    def encode(self, obj):\n+        return str(obj)\n+\n+\n+class SetEncoderDecoderMixin:\n+    def _set_encoder_decoder(self, encoder, decoder):\n+        field = JSONModel._meta.get_field('value')\n+        field.encoder, field.decoder = encoder, decoder\n+        return field.check()\n+\n+    def tearDown(self):\n+        self._set_encoder_decoder(None, None)\n+        return super().tearDown()\n+\n+\n+class TestFieldMeta(SetEncoderDecoderMixin, TestCase):\n+    def test_deconstruction(self):\n+        field = models.JSONField(\n+            'JSON data', 'data', default=list, encoder=DjangoJSONEncoder, decoder=CustomDecoder\n+        )\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertEqual(name, 'data')\n+        self.assertEqual(path, 'django.db.models.JSONField')\n+        self.assertEqual(args, [])\n+        self.assertEqual(kwargs, {\n+            'verbose_name': 'JSON data', 'default': list,\n+            'encoder': DjangoJSONEncoder, 'decoder': CustomDecoder\n+        })\n+\n+    def test_get_transforms(self):\n+        @models.JSONField.register_lookup\n+        class MyTransform(Transform):\n+            lookup_name = 'my_transform'\n+        field = models.JSONField()\n+        transform = field.get_transform('my_transform')\n+        self.assertIs(transform, MyTransform)\n+        models.JSONField._unregister_lookup(MyTransform)\n+        models.JSONField._clear_cached_lookups()\n+        transform = field.get_transform('my_transform')\n+        self.assertIsInstance(transform, KeyTransformFactory)\n+\n+    def test_key_transform_text_lookup_mixin_non_key_transform(self):\n+        transform = Transform('test')\n+        with self.assertRaisesMessage(\n+            TypeError,\n+            'Transform should be an instance of KeyTransform in order to use this lookup.'\n+        ):\n+            KeyTransformTextLookupMixin(transform)\n+\n+\n+class TestValidation(SetEncoderDecoderMixin, TestCase):\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.uuid_value = {'uuid': uuid.UUID('{12345678-1234-5678-1234-567812345678}')}\n+\n+    def test_validation_error(self):\n+        field = models.JSONField()\n+        with self.assertRaises(ValidationError) as err:\n+            field.clean(self.uuid_value, None)\n+        self.assertEqual(err.exception.code, 'invalid')\n+        self.assertEqual(err.exception.message % err.exception.params, 'Value must be valid JSON.')\n+\n+    def test_not_serializable(self):\n+        obj = JSONModel(value=self.uuid_value)\n+        if PY37:\n+            msg = 'Object of type UUID is not JSON serializable'\n+        else:\n+            msg = \"Object of type 'UUID' is not JSON serializable\"\n+        with self.assertRaisesMessage(TypeError, msg):\n+            obj.save()\n+\n+    @skipUnlessDBFeature('supports_json_field')\n+    def test_custom_encoder_decoder(self):\n+        self._set_encoder_decoder(DjangoJSONEncoder, CustomDecoder)\n+        obj = JSONModel(value=self.uuid_value)\n+        obj.clean_fields()\n+        obj.save()\n+        obj.refresh_from_db()\n+        self.assertEqual(obj.value, self.uuid_value)\n+\n+    @skipUnlessDBFeature('supports_json_field')\n+    def test_db_check_constraints(self):\n+        value = '{@!invalid json value 123 $!@#'\n+        self._set_encoder_decoder(StrEncoder, None)\n+        obj = JSONModel(value=value)\n+        with self.assertRaises((IntegrityError, DataError, OperationalError)):\n+            obj.save()\n+\n+\n+class TestModelFormField(SimpleTestCase):\n+    def test_formfield(self):\n+        model_field = models.JSONField()\n+        form_field = model_field.formfield()\n+        self.assertIsInstance(form_field, forms.JSONField)\n+\n+    def test_formfield_custom_encoder_decoder(self):\n+        model_field = models.JSONField(encoder=DjangoJSONEncoder, decoder=CustomDecoder)\n+        form_field = model_field.formfield()\n+        self.assertIs(form_field.encoder, DjangoJSONEncoder)\n+        self.assertIs(form_field.decoder, CustomDecoder)\n+\n+\n+@isolate_apps('model_fields.test_jsonfield')\n+@skipUnlessDBFeature('supports_json_field')\n+class TestChecks(TestCase):\n+    def test_invalid_default(self):\n+        class MyModel(models.Model):\n+            field = models.JSONField(default={})\n+\n+        model = MyModel()\n+        self.assertEqual(model.check(), [\n+            checks.Warning(\n+                msg=(\n+                    \"JSONField default should be a callable instead of an \"\n+                    \"instance so that it's not shared between all field \"\n+                    \"instances.\"\n+                ),\n+                hint='Use a callable instead, e.g., use `dict` instead of `{}`.',\n+                obj=MyModel._meta.get_field('field'),\n+                id='fields.E010',\n+            )\n+        ])\n+\n+    def test_valid_default(self):\n+        class MyModel(models.Model):\n+            field = models.JSONField(default=dict)\n+\n+        model = MyModel()\n+        self.assertEqual(model.check(), [])\n+\n+    def test_valid_default_none(self):\n+        class MyModel(models.Model):\n+            field = models.JSONField(default=None)\n+\n+        model = MyModel()\n+        self.assertEqual(model.check(), [])\n+\n+    def test_valid_callable_default(self):\n+        def callable_default():\n+            return {'it': 'works'}\n+\n+        class MyModel(models.Model):\n+            field = models.JSONField(default=callable_default)\n+\n+        model = MyModel()\n+        self.assertEqual(model.check(), [])\n+\n+\n+class TestSerialization(SimpleTestCase):\n+    test_data = (\n+        '[{\"fields\": {\"value\": %s}, '\n+        '\"model\": \"model_fields.jsonmodel\", \"pk\": null}]'\n+    )\n+    test_values = (\n+        # (Python value, serialized value),\n+        ({'a': 'b', 'c': None}, '{\"a\": \"b\", \"c\": null}'),\n+        ('abc', '\"abc\"'),\n+        ('{\"a\": \"a\"}', '\"{\\\\\"a\\\\\": \\\\\"a\\\\\"}\"'),\n+    )\n+\n+    def test_dumping(self):\n+        for value, serialized in self.test_values:\n+            with self.subTest(value=value):\n+                instance = JSONModel(value=value)\n+                data = serializers.serialize('json', [instance])\n+                self.assertJSONEqual(data, self.test_data % serialized)\n+\n+    def test_loading(self):\n+        for value, serialized in self.test_values:\n+            with self.subTest(value=value):\n+                instance = list(\n+                    serializers.deserialize('json', self.test_data % serialized)\n+                )[0].object\n+                self.assertEqual(instance.value, value)\n+\n+\n+@skipUnlessDBFeature('supports_json_field')\n+class TestSaveLoad(TestCase):\n+    def test_null(self):\n+        obj = NullableJSONModel(value=None)\n+        obj.save()\n+        obj.refresh_from_db()\n+        self.assertEqual(\n+            obj.value,\n+            '' if connection.features.interprets_empty_strings_as_nulls else None,\n+        )\n+\n+    @skipUnlessDBFeature('supports_primitives_in_json_field')\n+    def test_json_null_different_from_sql_null(self):\n+        json_null = NullableJSONModel.objects.create(value=Value('null'))\n+        json_null.refresh_from_db()\n+        sql_null = NullableJSONModel.objects.create(value=None)\n+        sql_null.refresh_from_db()\n+\n+        # They are different in the database ('null' vs NULL).\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value=Value('null')),\n+            [json_null]\n+        )\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value=None),\n+            [json_null]\n+        )\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__isnull=True),\n+            [sql_null]\n+        )\n+        # They are equal in Python (None).\n+        self.assertEqual(json_null.value, sql_null.value)\n+\n+    @skipUnlessDBFeature('supports_primitives_in_json_field')\n+    def test_primitives(self):\n+        values = [\n+            True,\n+            1,\n+            1.45,\n+            'String',\n+            '',\n+        ]\n+        for value in values:\n+            with self.subTest(value=value):\n+                obj = JSONModel(value=value)\n+                obj.save()\n+                obj.refresh_from_db()\n+                if value == Value('null'):\n+                    value = None\n+                self.assertEqual(obj.value, value)\n+\n+    def test_dict(self):\n+        values = [\n+            {},\n+            {'name': 'John', 'age': 20, 'height': 180.3},\n+            {'a': True, 'b': {'b1': False, 'b2': None}},\n+        ]\n+        for value in values:\n+            with self.subTest(value=value):\n+                obj = JSONModel.objects.create(value=value)\n+                obj.refresh_from_db()\n+                self.assertEqual(obj.value, value)\n+\n+    def test_list(self):\n+        values = [\n+            [],\n+            ['John', 20, 180.3],\n+            [True, [False, None]],\n+        ]\n+        for value in values:\n+            with self.subTest(value=value):\n+                obj = JSONModel.objects.create(value=value)\n+                obj.refresh_from_db()\n+                self.assertEqual(obj.value, value)\n+\n+    def test_realistic_object(self):\n+        value = {\n+            'name': 'John',\n+            'age': 20,\n+            'pets': [\n+                {'name': 'Kit', 'type': 'cat', 'age': 2},\n+                {'name': 'Max', 'type': 'dog', 'age': 1},\n+            ],\n+            'courses': [\n+                ['A1', 'A2', 'A3'],\n+                ['B1', 'B2'],\n+                ['C1'],\n+            ],\n+        }\n+        obj = JSONModel.objects.create(value=value)\n+        obj.refresh_from_db()\n+        self.assertEqual(obj.value, value)\n+\n+\n+@skipUnlessDBFeature('supports_json_field')\n+class TestQuerying(TestCase):\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.primitives = [True, False, 'yes', 7, 9.6]\n+        values = [\n+            None,\n+            [],\n+            {},\n+            {'a': 'b', 'c': 14},\n+            {\n+                'a': 'b',\n+                'c': 14,\n+                'd': ['e', {'f': 'g'}],\n+                'h': True,\n+                'i': False,\n+                'j': None,\n+                'k': {'l': 'm'},\n+            },\n+            [1, [2]],\n+            {'k': True, 'l': False},\n+            {\n+                'foo': 'bar',\n+                'baz': {'a': 'b', 'c': 'd'},\n+                'bar': ['foo', 'bar'],\n+                'bax': {'foo': 'bar'},\n+            },\n+        ]\n+        cls.objs = [\n+            NullableJSONModel.objects.create(value=value)\n+            for value in values\n+        ]\n+        if connection.features.supports_primitives_in_json_field:\n+            cls.objs.extend([\n+                NullableJSONModel.objects.create(value=value)\n+                for value in cls.primitives\n+            ])\n+\n+    def test_has_key_with_null_value(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__has_key='j'),\n+            [self.objs[4]]\n+        )\n+\n+    def test_has_key(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__has_key='a'),\n+            [self.objs[3], self.objs[4]]\n+        )\n+\n+    def test_has_keys(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__has_keys=['a', 'c', 'h']),\n+            [self.objs[4]]\n+        )\n+\n+    def test_has_any_keys(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__has_any_keys=['c', 'l']),\n+            [self.objs[3], self.objs[4], self.objs[6]],\n+        )\n+\n+    @skipUnlessDBFeature('supports_primitives_in_json_field')\n+    def test_contains_primitives(self):\n+        for value in self.primitives:\n+            with self.subTest(value=value):\n+                self.assertTrue(\n+                    NullableJSONModel.objects.filter(value__contains=value).exists()\n+                )\n+\n+    def test_contains_empty_dict(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__contains={}),\n+            self.objs[2:5] + self.objs[6:8],\n+        )\n+\n+    def test_contains_multiple(self):\n+        query = NullableJSONModel.objects.filter(value__contains={'k': True, 'l': False})\n+        self.assertSequenceEqual(\n+            query,\n+            [self.objs[6]]\n+        )\n+\n+    def test_contains_complex(self):\n+        query = NullableJSONModel.objects.filter(value__contains={'d': ['e', {'f': 'g'}]})\n+        self.assertSequenceEqual(\n+            query,\n+            [self.objs[4]]\n+        )\n+\n+    def test_contains_array(self):\n+        query = NullableJSONModel.objects.filter(value__contains=[1, [2]])\n+        self.assertSequenceEqual(\n+            query,\n+            [self.objs[5]]\n+        )\n+\n+    def test_contains_null(self):\n+        query = NullableJSONModel.objects.filter(value__contains={'i': False, 'j': None})\n+        self.assertSequenceEqual(\n+            query,\n+            [self.objs[4]]\n+        )\n+\n+    @skipIf(connection.vendor == 'oracle', \"Oracle does not support 'contained_by' lookup.\")\n+    def test_contained_by(self):\n+        query = NullableJSONModel.objects.filter(value__contained_by={'a': 'b', 'c': 14, 'h': True})\n+        self.assertSequenceEqual(\n+            query,\n+            [self.objs[2], self.objs[3]]\n+        )\n+\n+    def test_exact(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__exact={}),\n+            [self.objs[2]]\n+        )\n+\n+    def test_exact_complex(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__exact={'a': 'b', 'c': 14}),\n+            [self.objs[3]]\n+        )\n+\n+    def test_isnull(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__isnull=True),\n+            [self.objs[0]]\n+        )\n+\n+    def test_ordering_by_transform(self):\n+        objs = [\n+            NullableJSONModel.objects.create(value={'ord': 93, 'name': 'bar'}),\n+            NullableJSONModel.objects.create(value={'ord': 22.1, 'name': 'foo'}),\n+            NullableJSONModel.objects.create(value={'ord': -1, 'name': 'baz'}),\n+            NullableJSONModel.objects.create(value={'ord': 21.931902, 'name': 'spam'}),\n+            NullableJSONModel.objects.create(value={'ord': -100291029, 'name': 'eggs'}),\n+        ]\n+        query = NullableJSONModel.objects.filter(value__name__isnull=False).order_by('value__ord')\n+        if connection.vendor == 'mysql' and connection.mysql_is_mariadb or connection.vendor == 'oracle':\n+            # MariaDB and Oracle use string representation of the JSON values to sort the objects.\n+            self.assertSequenceEqual(query, [objs[2], objs[4], objs[3], objs[1], objs[0]])\n+        else:\n+            self.assertSequenceEqual(query, [objs[4], objs[2], objs[3], objs[1], objs[0]])\n+\n+    def test_ordering_grouping_by_key_transform(self):\n+        base_qs = NullableJSONModel.objects.filter(value__d__0__isnull=False)\n+        for qs in (\n+            base_qs.order_by('value__d__0'),\n+            base_qs.annotate(key=KeyTransform('0', KeyTransform('d', 'value'))).order_by('key'),\n+        ):\n+            self.assertSequenceEqual(qs, [self.objs[4]])\n+        qs = NullableJSONModel.objects.filter(value__isnull=False)\n+        if connection.vendor != 'oracle':\n+            # Oracle doesn't support direct COUNT on LOB fields.\n+            self.assertQuerysetEqual(\n+                qs.values('value__d__0').annotate(count=Count('value__d__0')).order_by('count'),\n+                [1, 11],\n+                operator.itemgetter('count'),\n+            )\n+        expected = [(None, 0), ('g', 1)] if connection.vendor != 'oracle' else [('', 0), ('g', 1)]\n+        self.assertQuerysetEqual(\n+            qs.filter(value__isnull=False).annotate(\n+                key=KeyTextTransform('f', KeyTransform('1', KeyTransform('d', 'value'))),\n+            ).values('key').annotate(count=Count('key')).order_by('count'),\n+            expected,\n+            operator.itemgetter('key', 'count'),\n+        )\n+\n+    def test_key_transform_raw_expression(self):\n+        if connection.vendor == 'postgresql':\n+            expr = RawSQL('%s::jsonb', ['{\"x\": \"bar\"}'])\n+        else:\n+            expr = RawSQL('%s', ['{\"x\": \"bar\"}'])\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__foo=KeyTransform('x', expr)),\n+            [self.objs[7]],\n+        )\n+\n+    def test_key_transform_expression(self):\n+        if connection.vendor == 'oracle' or connection.vendor == 'mysql' and connection.mysql_is_mariadb:\n+            expr = 'key'\n+        else:\n+            expr = Cast('key', models.JSONField())\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__d__0__isnull=False).annotate(\n+                key=KeyTransform('d', 'value'),\n+                chain=KeyTransform('0', 'key'),\n+                expr=KeyTransform('0', expr),\n+            ).filter(chain=F('expr')),\n+            [self.objs[4]],\n+        )\n+\n+    def test_nested_key_transform_raw_expression(self):\n+        if connection.vendor == 'postgresql':\n+            expr = RawSQL('%s::jsonb', ['{\"x\": {\"y\": \"bar\"}}'])\n+        else:\n+            expr = RawSQL('%s', ['{\"x\": {\"y\": \"bar\"}}'])\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__foo=KeyTransform('y', KeyTransform('x', expr))),\n+            [self.objs[7]],\n+        )\n+\n+    def test_nested_key_transform_expression(self):\n+        if connection.vendor == 'oracle' or connection.vendor == 'mysql' and connection.mysql_is_mariadb:\n+            expr = 'key'\n+        else:\n+            expr = Cast('key', models.JSONField())\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__d__0__isnull=False).annotate(\n+                key=KeyTransform('d', 'value'),\n+                chain=KeyTransform('f', KeyTransform('1', 'key')),\n+                expr=KeyTransform('f', KeyTransform('1', expr)),\n+            ).filter(chain=F('expr')),\n+            [self.objs[4]],\n+        )\n+\n+    def test_deep_values(self):\n+        query = NullableJSONModel.objects.values_list('value__k__l')\n+        empty = ('',) if connection.features.interprets_empty_strings_as_nulls else (None,)\n+        expected_objs = [empty] * len(self.objs)\n+        expected_objs[4] = ('m',)\n+        self.assertSequenceEqual(query, expected_objs)\n+\n+    @skipUnlessDBFeature('can_distinct_on_fields')\n+    def test_deep_distinct(self):\n+        query = NullableJSONModel.objects.distinct('value__k__l').values_list('value__k__l')\n+        self.assertSequenceEqual(query, [('m',), (None,)])\n+\n+    def test_isnull_key(self):\n+        # key__isnull=False works the same as has_key='key'.\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__a__isnull=True),\n+            self.objs[:3] + self.objs[5:]\n+        )\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__a__isnull=False),\n+            [self.objs[3], self.objs[4]]\n+        )\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__j__isnull=False),\n+            [self.objs[4]]\n+        )\n+\n+    def test_none_key(self):\n+        self.assertSequenceEqual(NullableJSONModel.objects.filter(value__j=None), [self.objs[4]])\n+\n+    def test_none_key_exclude(self):\n+        obj = NullableJSONModel.objects.create(value={'j': 1})\n+        if connection.vendor == 'oracle':\n+            # On Oracle, the query returns JSON objects and arrays that do not have a 'null' value\n+            # at the specified path, including those that do not have the key.\n+            self.assertSequenceEqual(\n+                NullableJSONModel.objects.exclude(value__j=None),\n+                self.objs[1:4] + self.objs[5:] + [obj]\n+            )\n+        else:\n+            self.assertSequenceEqual(NullableJSONModel.objects.exclude(value__j=None), [obj])\n+\n+    def test_isnull_key_or_none(self):\n+        obj = NullableJSONModel.objects.create(value={'a': None})\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(Q(value__a__isnull=True) | Q(value__a=None)),\n+            self.objs[:3] + self.objs[5:] + [obj]\n+        )\n+\n+    def test_shallow_list_lookup(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__0=1),\n+            [self.objs[5]]\n+        )\n+\n+    def test_shallow_obj_lookup(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__a='b'),\n+            [self.objs[3], self.objs[4]]\n+        )\n+\n+    def test_obj_subquery_lookup(self):\n+        qs = NullableJSONModel.objects.annotate(\n+            field=Subquery(NullableJSONModel.objects.filter(pk=OuterRef('pk')).values('value')),\n+        ).filter(field__a='b')\n+        self.assertSequenceEqual(qs, [self.objs[3], self.objs[4]])\n+\n+    def test_deep_lookup_objs(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__k__l='m'),\n+            [self.objs[4]]\n+        )\n+\n+    def test_shallow_lookup_obj_target(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__k={'l': 'm'}),\n+            [self.objs[4]]\n+        )\n+\n+    def test_deep_lookup_array(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__1__0=2),\n+            [self.objs[5]]\n+        )\n+\n+    def test_deep_lookup_mixed(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__d__1__f='g'),\n+            [self.objs[4]]\n+        )\n+\n+    def test_deep_lookup_transform(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__c__gt=2),\n+            [self.objs[3], self.objs[4]]\n+        )\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(value__c__lt=5),\n+            []\n+        )\n+\n+    def test_usage_in_subquery(self):\n+        self.assertSequenceEqual(\n+            NullableJSONModel.objects.filter(id__in=NullableJSONModel.objects.filter(value__c=14)),\n+            self.objs[3:5]\n+        )\n+\n+    def test_iexact(self):\n+        self.assertTrue(NullableJSONModel.objects.filter(value__foo__iexact='BaR').exists())\n+        self.assertFalse(NullableJSONModel.objects.filter(value__foo__iexact='\"BaR\"').exists())\n+\n+    def test_contains(self):\n+        self.assertTrue(NullableJSONModel.objects.filter(value__foo__contains='ar').exists())\n+\n+    def test_icontains(self):\n+        self.assertTrue(NullableJSONModel.objects.filter(value__foo__icontains='A').exists())\n+\n+    def test_startswith(self):\n+        self.assertTrue(NullableJSONModel.objects.filter(value__foo__startswith='b').exists())\n+\n+    def test_istartswith(self):\n+        self.assertTrue(NullableJSONModel.objects.filter(value__foo__istartswith='B').exists())\n+\n+    def test_endswith(self):\n+        self.assertTrue(NullableJSONModel.objects.filter(value__foo__endswith='r').exists())\n+\n+    def test_iendswith(self):\n+        self.assertTrue(NullableJSONModel.objects.filter(value__foo__iendswith='R').exists())\n+\n+    def test_regex(self):\n+        self.assertTrue(NullableJSONModel.objects.filter(value__foo__regex=r'^bar$').exists())\n+\n+    def test_iregex(self):\n+        self.assertTrue(NullableJSONModel.objects.filter(value__foo__iregex=r'^bAr$').exists())\n+\n+    def test_key_sql_injection(self):\n+        with CaptureQueriesContext(connection) as queries:\n+            query = NullableJSONModel.objects.filter(**{\"\"\"value__test' = '\"a\"') OR 1 = 1 OR ('d\"\"\": 'x', })\n+            if connection.vendor == 'oracle':\n+                with self.assertRaises(DatabaseError):\n+                    query.exists()\n+            else:\n+                self.assertFalse(query.exists())\n+        if connection.vendor == 'postgresql':\n+            self.assertIn(\n+                \"\"\".\"value\" -> 'test'' = ''\"a\"'') OR 1 = 1 OR (''d') = '\"x\"' \"\"\",\n+                queries[0]['sql'],\n+            )\n+\n+    def test_lookups_with_key_transform(self):\n+        sql = '%s::jsonb' if connection.vendor == 'postgresql' else '%s'\n+        tests = (\n+            ('value__d__contains', 'e'),\n+            ('value__baz__contained_by', {'a': 'b', 'c': 'd', 'e': 'f'}),\n+            ('value__baz__has_key', 'c'),\n+            ('value__baz__has_keys', ['a', 'c']),\n+            ('value__baz__has_any_keys', ['a', 'x']),\n+            ('value__contains', KeyTransform('bax', 'value')),\n+            (\n+                'value__contained_by',\n+                KeyTransform('x', RawSQL(sql, ['{\"x\": {\"a\": \"b\", \"c\": 1, \"d\": \"e\"}}'])),\n+            ),\n+            ('value__has_key', KeyTextTransform('foo', 'value')),\n+        )\n+        if connection.vendor == 'oracle':\n+            # contained_by is not supported in Oracle.\n+            tests = tests[0:1] + tests[2:6] + tests[7:]\n+        for lookup, value in tests:\n+            with self.subTest(lookup=lookup):\n+                self.assertTrue(NullableJSONModel.objects.filter(\n+                    **{lookup: value},\n+                ).exists())\ndiff --git a/tests/postgres_tests/fields.py b/tests/postgres_tests/fields.py\nindex 4ebc0ce7dc1a..a36c10c750e1 100644\n--- a/tests/postgres_tests/fields.py\n+++ b/tests/postgres_tests/fields.py\n@@ -10,7 +10,7 @@\n     from django.contrib.postgres.fields import (\n         ArrayField, BigIntegerRangeField, CICharField, CIEmailField,\n         CITextField, DateRangeField, DateTimeRangeField, DecimalRangeField,\n-        HStoreField, IntegerRangeField, JSONField,\n+        HStoreField, IntegerRangeField,\n     )\n     from django.contrib.postgres.search import SearchVectorField\n except ImportError:\n@@ -26,10 +26,6 @@ def deconstruct(self):\n             })\n             return name, path, args, kwargs\n \n-    class DummyJSONField(models.Field):\n-        def __init__(self, encoder=None, **kwargs):\n-            super().__init__(**kwargs)\n-\n     ArrayField = DummyArrayField\n     BigIntegerRangeField = models.Field\n     CICharField = models.Field\n@@ -40,7 +36,6 @@ def __init__(self, encoder=None, **kwargs):\n     DecimalRangeField = models.Field\n     HStoreField = models.Field\n     IntegerRangeField = models.Field\n-    JSONField = DummyJSONField\n     SearchVectorField = models.Field\n \n \ndiff --git a/tests/postgres_tests/migrations/0002_create_test_models.py b/tests/postgres_tests/migrations/0002_create_test_models.py\nindex 12d94e348a21..98c5ea34c9ab 100644\n--- a/tests/postgres_tests/migrations/0002_create_test_models.py\n+++ b/tests/postgres_tests/migrations/0002_create_test_models.py\n@@ -1,10 +1,9 @@\n-from django.core.serializers.json import DjangoJSONEncoder\n from django.db import migrations, models\n \n from ..fields import (\n     ArrayField, BigIntegerRangeField, CICharField, CIEmailField, CITextField,\n     DateRangeField, DateTimeRangeField, DecimalRangeField, EnumField,\n-    HStoreField, IntegerRangeField, JSONField, SearchVectorField,\n+    HStoreField, IntegerRangeField, SearchVectorField,\n )\n from ..models import TagField\n \n@@ -60,7 +59,7 @@ class Migration(migrations.Migration):\n                 ('uuids', ArrayField(models.UUIDField(), size=None, default=list)),\n                 ('decimals', ArrayField(models.DecimalField(max_digits=5, decimal_places=2), size=None, default=list)),\n                 ('tags', ArrayField(TagField(), blank=True, null=True, size=None)),\n-                ('json', ArrayField(JSONField(default={}), default=[])),\n+                ('json', ArrayField(models.JSONField(default={}), default=[])),\n                 ('int_ranges', ArrayField(IntegerRangeField(), null=True, blank=True)),\n                 ('bigint_ranges', ArrayField(BigIntegerRangeField(), null=True, blank=True)),\n             ],\n@@ -259,18 +258,6 @@ class Migration(migrations.Migration):\n             },\n             bases=(models.Model,),\n         ),\n-        migrations.CreateModel(\n-            name='JSONModel',\n-            fields=[\n-                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n-                ('field', JSONField(null=True, blank=True)),\n-                ('field_custom', JSONField(null=True, blank=True, encoder=DjangoJSONEncoder)),\n-            ],\n-            options={\n-                'required_db_vendor': 'postgresql',\n-            },\n-            bases=(models.Model,),\n-        ),\n         migrations.CreateModel(\n             name='ArrayEnumModel',\n             fields=[\ndiff --git a/tests/postgres_tests/models.py b/tests/postgres_tests/models.py\nindex 8528c59da1c0..d8cb3e00970f 100644\n--- a/tests/postgres_tests/models.py\n+++ b/tests/postgres_tests/models.py\n@@ -1,10 +1,9 @@\n-from django.core.serializers.json import DjangoJSONEncoder\n from django.db import models\n \n from .fields import (\n     ArrayField, BigIntegerRangeField, CICharField, CIEmailField, CITextField,\n     DateRangeField, DateTimeRangeField, DecimalRangeField, EnumField,\n-    HStoreField, IntegerRangeField, JSONField, SearchVectorField,\n+    HStoreField, IntegerRangeField, SearchVectorField,\n )\n \n \n@@ -63,15 +62,19 @@ class NestedIntegerArrayModel(PostgreSQLModel):\n     field = ArrayField(ArrayField(models.IntegerField()))\n \n \n-class OtherTypesArrayModel(PostgreSQLModel):\n+class OtherTypesArrayModel(models.Model):\n     ips = ArrayField(models.GenericIPAddressField(), default=list)\n     uuids = ArrayField(models.UUIDField(), default=list)\n     decimals = ArrayField(models.DecimalField(max_digits=5, decimal_places=2), default=list)\n     tags = ArrayField(TagField(), blank=True, null=True)\n-    json = ArrayField(JSONField(default=dict), default=list)\n+    json = ArrayField(models.JSONField(default=dict), default=list)\n     int_ranges = ArrayField(IntegerRangeField(), blank=True, null=True)\n     bigint_ranges = ArrayField(BigIntegerRangeField(), blank=True, null=True)\n \n+    class Meta:\n+        required_db_features = {'supports_json_field'}\n+        required_db_vendor = 'postgresql'\n+\n \n class HStoreModel(PostgreSQLModel):\n     field = HStoreField(blank=True, null=True)\n@@ -160,11 +163,6 @@ class RangeLookupsModel(PostgreSQLModel):\n     decimal_field = models.DecimalField(max_digits=5, decimal_places=2, blank=True, null=True)\n \n \n-class JSONModel(PostgreSQLModel):\n-    field = JSONField(blank=True, null=True)\n-    field_custom = JSONField(blank=True, null=True, encoder=DjangoJSONEncoder)\n-\n-\n class ArrayFieldSubclass(ArrayField):\n     def __init__(self, *args, **kwargs):\n         super().__init__(models.IntegerField())\ndiff --git a/tests/postgres_tests/test_bulk_update.py b/tests/postgres_tests/test_bulk_update.py\nindex 6dd7036a9bf2..7fa2a6a7db77 100644\n--- a/tests/postgres_tests/test_bulk_update.py\n+++ b/tests/postgres_tests/test_bulk_update.py\n@@ -2,7 +2,7 @@\n \n from . import PostgreSQLTestCase\n from .models import (\n-    HStoreModel, IntegerArrayModel, JSONModel, NestedIntegerArrayModel,\n+    HStoreModel, IntegerArrayModel, NestedIntegerArrayModel,\n     NullableIntegerArrayModel, OtherTypesArrayModel, RangesModel,\n )\n \n@@ -17,7 +17,6 @@ def test_bulk_update(self):\n         test_data = [\n             (IntegerArrayModel, 'field', [], [1, 2, 3]),\n             (NullableIntegerArrayModel, 'field', [1, 2, 3], None),\n-            (JSONModel, 'field', {'a': 'b'}, {'c': 'd'}),\n             (NestedIntegerArrayModel, 'field', [], [[1, 2, 3]]),\n             (HStoreModel, 'field', {}, {1: 2}),\n             (RangesModel, 'ints', None, NumericRange(lower=1, upper=10)),\ndiff --git a/tests/postgres_tests/test_introspection.py b/tests/postgres_tests/test_introspection.py\nindex 8ae5b80da11f..50cb9b282806 100644\n--- a/tests/postgres_tests/test_introspection.py\n+++ b/tests/postgres_tests/test_introspection.py\n@@ -19,12 +19,6 @@ def assertFieldsInModel(self, model, field_outputs):\n         for field_output in field_outputs:\n             self.assertIn(field_output, output)\n \n-    def test_json_field(self):\n-        self.assertFieldsInModel(\n-            'postgres_tests_jsonmodel',\n-            ['field = django.contrib.postgres.fields.JSONField(blank=True, null=True)'],\n-        )\n-\n     def test_range_fields(self):\n         self.assertFieldsInModel(\n             'postgres_tests_rangesmodel',\ndiff --git a/tests/postgres_tests/test_json.py b/tests/postgres_tests/test_json.py\ndeleted file mode 100644\nindex 0ffa05f98144..000000000000\n--- a/tests/postgres_tests/test_json.py\n+++ /dev/null\n@@ -1,579 +0,0 @@\n-import datetime\n-import operator\n-import uuid\n-from decimal import Decimal\n-\n-from django.core import checks, exceptions, serializers\n-from django.core.serializers.json import DjangoJSONEncoder\n-from django.db import connection\n-from django.db.models import Count, F, OuterRef, Q, Subquery\n-from django.db.models.expressions import RawSQL\n-from django.db.models.functions import Cast\n-from django.forms import CharField, Form, widgets\n-from django.test.utils import CaptureQueriesContext, isolate_apps\n-from django.utils.html import escape\n-\n-from . import PostgreSQLSimpleTestCase, PostgreSQLTestCase\n-from .models import JSONModel, PostgreSQLModel\n-\n-try:\n-    from django.contrib.postgres import forms\n-    from django.contrib.postgres.fields import JSONField\n-    from django.contrib.postgres.fields.jsonb import KeyTextTransform, KeyTransform\n-except ImportError:\n-    pass\n-\n-\n-class TestModelMetaOrdering(PostgreSQLSimpleTestCase):\n-    def test_ordering_by_json_field_value(self):\n-        class TestJSONModel(JSONModel):\n-            class Meta:\n-                ordering = ['field__value']\n-\n-        self.assertEqual(TestJSONModel.check(), [])\n-\n-\n-class TestSaveLoad(PostgreSQLTestCase):\n-    def test_null(self):\n-        instance = JSONModel()\n-        instance.save()\n-        loaded = JSONModel.objects.get()\n-        self.assertIsNone(loaded.field)\n-\n-    def test_empty_object(self):\n-        instance = JSONModel(field={})\n-        instance.save()\n-        loaded = JSONModel.objects.get()\n-        self.assertEqual(loaded.field, {})\n-\n-    def test_empty_list(self):\n-        instance = JSONModel(field=[])\n-        instance.save()\n-        loaded = JSONModel.objects.get()\n-        self.assertEqual(loaded.field, [])\n-\n-    def test_boolean(self):\n-        instance = JSONModel(field=True)\n-        instance.save()\n-        loaded = JSONModel.objects.get()\n-        self.assertIs(loaded.field, True)\n-\n-    def test_string(self):\n-        instance = JSONModel(field='why?')\n-        instance.save()\n-        loaded = JSONModel.objects.get()\n-        self.assertEqual(loaded.field, 'why?')\n-\n-    def test_number(self):\n-        instance = JSONModel(field=1)\n-        instance.save()\n-        loaded = JSONModel.objects.get()\n-        self.assertEqual(loaded.field, 1)\n-\n-    def test_realistic_object(self):\n-        obj = {\n-            'a': 'b',\n-            'c': 1,\n-            'd': ['e', {'f': 'g'}],\n-            'h': True,\n-            'i': False,\n-            'j': None,\n-        }\n-        instance = JSONModel(field=obj)\n-        instance.save()\n-        loaded = JSONModel.objects.get()\n-        self.assertEqual(loaded.field, obj)\n-\n-    def test_custom_encoding(self):\n-        \"\"\"\n-        JSONModel.field_custom has a custom DjangoJSONEncoder.\n-        \"\"\"\n-        some_uuid = uuid.uuid4()\n-        obj_before = {\n-            'date': datetime.date(2016, 8, 12),\n-            'datetime': datetime.datetime(2016, 8, 12, 13, 44, 47, 575981),\n-            'decimal': Decimal('10.54'),\n-            'uuid': some_uuid,\n-        }\n-        obj_after = {\n-            'date': '2016-08-12',\n-            'datetime': '2016-08-12T13:44:47.575',\n-            'decimal': '10.54',\n-            'uuid': str(some_uuid),\n-        }\n-        JSONModel.objects.create(field_custom=obj_before)\n-        loaded = JSONModel.objects.get()\n-        self.assertEqual(loaded.field_custom, obj_after)\n-\n-\n-class TestQuerying(PostgreSQLTestCase):\n-    @classmethod\n-    def setUpTestData(cls):\n-        cls.objs = JSONModel.objects.bulk_create([\n-            JSONModel(field=None),\n-            JSONModel(field=True),\n-            JSONModel(field=False),\n-            JSONModel(field='yes'),\n-            JSONModel(field=7),\n-            JSONModel(field=[]),\n-            JSONModel(field={}),\n-            JSONModel(field={\n-                'a': 'b',\n-                'c': 1,\n-            }),\n-            JSONModel(field={\n-                'a': 'b',\n-                'c': 1,\n-                'd': ['e', {'f': 'g'}],\n-                'h': True,\n-                'i': False,\n-                'j': None,\n-                'k': {'l': 'm'},\n-            }),\n-            JSONModel(field=[1, [2]]),\n-            JSONModel(field={\n-                'k': True,\n-                'l': False,\n-            }),\n-            JSONModel(field={\n-                'foo': 'bar',\n-                'baz': {'a': 'b', 'c': 'd'},\n-                'bar': ['foo', 'bar'],\n-                'bax': {'foo': 'bar'},\n-            }),\n-        ])\n-\n-    def test_exact(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__exact={}),\n-            [self.objs[6]]\n-        )\n-\n-    def test_exact_complex(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__exact={'a': 'b', 'c': 1}),\n-            [self.objs[7]]\n-        )\n-\n-    def test_isnull(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__isnull=True),\n-            [self.objs[0]]\n-        )\n-\n-    def test_ordering_by_transform(self):\n-        objs = [\n-            JSONModel.objects.create(field={'ord': 93, 'name': 'bar'}),\n-            JSONModel.objects.create(field={'ord': 22.1, 'name': 'foo'}),\n-            JSONModel.objects.create(field={'ord': -1, 'name': 'baz'}),\n-            JSONModel.objects.create(field={'ord': 21.931902, 'name': 'spam'}),\n-            JSONModel.objects.create(field={'ord': -100291029, 'name': 'eggs'}),\n-        ]\n-        query = JSONModel.objects.filter(field__name__isnull=False).order_by('field__ord')\n-        self.assertSequenceEqual(query, [objs[4], objs[2], objs[3], objs[1], objs[0]])\n-\n-    def test_ordering_grouping_by_key_transform(self):\n-        base_qs = JSONModel.objects.filter(field__d__0__isnull=False)\n-        for qs in (\n-            base_qs.order_by('field__d__0'),\n-            base_qs.annotate(key=KeyTransform('0', KeyTransform('d', 'field'))).order_by('key'),\n-        ):\n-            self.assertSequenceEqual(qs, [self.objs[8]])\n-        qs = JSONModel.objects.filter(field__isnull=False)\n-        self.assertQuerysetEqual(\n-            qs.values('field__d__0').annotate(count=Count('field__d__0')).order_by('count'),\n-            [1, 10],\n-            operator.itemgetter('count'),\n-        )\n-        self.assertQuerysetEqual(\n-            qs.filter(field__isnull=False).annotate(\n-                key=KeyTextTransform('f', KeyTransform('1', KeyTransform('d', 'field'))),\n-            ).values('key').annotate(count=Count('key')).order_by('count'),\n-            [(None, 0), ('g', 1)],\n-            operator.itemgetter('key', 'count'),\n-        )\n-\n-    def test_key_transform_raw_expression(self):\n-        expr = RawSQL('%s::jsonb', ['{\"x\": \"bar\"}'])\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__foo=KeyTransform('x', expr)),\n-            [self.objs[-1]],\n-        )\n-\n-    def test_key_transform_expression(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__d__0__isnull=False).annotate(\n-                key=KeyTransform('d', 'field'),\n-                chain=KeyTransform('0', 'key'),\n-                expr=KeyTransform('0', Cast('key', JSONField())),\n-            ).filter(chain=F('expr')),\n-            [self.objs[8]],\n-        )\n-\n-    def test_nested_key_transform_raw_expression(self):\n-        expr = RawSQL('%s::jsonb', ['{\"x\": {\"y\": \"bar\"}}'])\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__foo=KeyTransform('y', KeyTransform('x', expr))),\n-            [self.objs[-1]],\n-        )\n-\n-    def test_nested_key_transform_expression(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__d__0__isnull=False).annotate(\n-                key=KeyTransform('d', 'field'),\n-                chain=KeyTransform('f', KeyTransform('1', 'key')),\n-                expr=KeyTransform('f', KeyTransform('1', Cast('key', JSONField()))),\n-            ).filter(chain=F('expr')),\n-            [self.objs[8]],\n-        )\n-\n-    def test_deep_values(self):\n-        query = JSONModel.objects.values_list('field__k__l')\n-        self.assertSequenceEqual(\n-            query,\n-            [\n-                (None,), (None,), (None,), (None,), (None,), (None,),\n-                (None,), (None,), ('m',), (None,), (None,), (None,),\n-            ]\n-        )\n-\n-    def test_deep_distinct(self):\n-        query = JSONModel.objects.distinct('field__k__l').values_list('field__k__l')\n-        self.assertSequenceEqual(query, [('m',), (None,)])\n-\n-    def test_isnull_key(self):\n-        # key__isnull works the same as has_key='key'.\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__a__isnull=True),\n-            self.objs[:7] + self.objs[9:]\n-        )\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__a__isnull=False),\n-            [self.objs[7], self.objs[8]]\n-        )\n-\n-    def test_none_key(self):\n-        self.assertSequenceEqual(JSONModel.objects.filter(field__j=None), [self.objs[8]])\n-\n-    def test_none_key_exclude(self):\n-        obj = JSONModel.objects.create(field={'j': 1})\n-        self.assertSequenceEqual(JSONModel.objects.exclude(field__j=None), [obj])\n-\n-    def test_isnull_key_or_none(self):\n-        obj = JSONModel.objects.create(field={'a': None})\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(Q(field__a__isnull=True) | Q(field__a=None)),\n-            self.objs[:7] + self.objs[9:] + [obj]\n-        )\n-\n-    def test_contains(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__contains={'a': 'b'}),\n-            [self.objs[7], self.objs[8]]\n-        )\n-\n-    def test_contained_by(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__contained_by={'a': 'b', 'c': 1, 'h': True}),\n-            [self.objs[6], self.objs[7]]\n-        )\n-\n-    def test_has_key(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__has_key='a'),\n-            [self.objs[7], self.objs[8]]\n-        )\n-\n-    def test_has_keys(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__has_keys=['a', 'c', 'h']),\n-            [self.objs[8]]\n-        )\n-\n-    def test_has_any_keys(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__has_any_keys=['c', 'l']),\n-            [self.objs[7], self.objs[8], self.objs[10]]\n-        )\n-\n-    def test_shallow_list_lookup(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__0=1),\n-            [self.objs[9]]\n-        )\n-\n-    def test_shallow_obj_lookup(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__a='b'),\n-            [self.objs[7], self.objs[8]]\n-        )\n-\n-    def test_obj_subquery_lookup(self):\n-        qs = JSONModel.objects.annotate(\n-            value=Subquery(JSONModel.objects.filter(pk=OuterRef('pk')).values('field')),\n-        ).filter(value__a='b')\n-        self.assertSequenceEqual(qs, [self.objs[7], self.objs[8]])\n-\n-    def test_deep_lookup_objs(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__k__l='m'),\n-            [self.objs[8]]\n-        )\n-\n-    def test_shallow_lookup_obj_target(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__k={'l': 'm'}),\n-            [self.objs[8]]\n-        )\n-\n-    def test_deep_lookup_array(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__1__0=2),\n-            [self.objs[9]]\n-        )\n-\n-    def test_deep_lookup_mixed(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__d__1__f='g'),\n-            [self.objs[8]]\n-        )\n-\n-    def test_deep_lookup_transform(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__c__gt=1),\n-            []\n-        )\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(field__c__lt=5),\n-            [self.objs[7], self.objs[8]]\n-        )\n-\n-    def test_usage_in_subquery(self):\n-        self.assertSequenceEqual(\n-            JSONModel.objects.filter(id__in=JSONModel.objects.filter(field__c=1)),\n-            self.objs[7:9]\n-        )\n-\n-    def test_iexact(self):\n-        self.assertTrue(JSONModel.objects.filter(field__foo__iexact='BaR').exists())\n-        self.assertFalse(JSONModel.objects.filter(field__foo__iexact='\"BaR\"').exists())\n-\n-    def test_icontains(self):\n-        self.assertFalse(JSONModel.objects.filter(field__foo__icontains='\"bar\"').exists())\n-\n-    def test_startswith(self):\n-        self.assertTrue(JSONModel.objects.filter(field__foo__startswith='b').exists())\n-\n-    def test_istartswith(self):\n-        self.assertTrue(JSONModel.objects.filter(field__foo__istartswith='B').exists())\n-\n-    def test_endswith(self):\n-        self.assertTrue(JSONModel.objects.filter(field__foo__endswith='r').exists())\n-\n-    def test_iendswith(self):\n-        self.assertTrue(JSONModel.objects.filter(field__foo__iendswith='R').exists())\n-\n-    def test_regex(self):\n-        self.assertTrue(JSONModel.objects.filter(field__foo__regex=r'^bar$').exists())\n-\n-    def test_iregex(self):\n-        self.assertTrue(JSONModel.objects.filter(field__foo__iregex=r'^bAr$').exists())\n-\n-    def test_key_sql_injection(self):\n-        with CaptureQueriesContext(connection) as queries:\n-            self.assertFalse(\n-                JSONModel.objects.filter(**{\n-                    \"\"\"field__test' = '\"a\"') OR 1 = 1 OR ('d\"\"\": 'x',\n-                }).exists()\n-            )\n-        self.assertIn(\n-            \"\"\".\"field\" -> 'test'' = ''\"a\"'') OR 1 = 1 OR (''d') = '\"x\"' \"\"\",\n-            queries[0]['sql'],\n-        )\n-\n-    def test_lookups_with_key_transform(self):\n-        tests = (\n-            ('field__d__contains', 'e'),\n-            ('field__baz__contained_by', {'a': 'b', 'c': 'd', 'e': 'f'}),\n-            ('field__baz__has_key', 'c'),\n-            ('field__baz__has_keys', ['a', 'c']),\n-            ('field__baz__has_any_keys', ['a', 'x']),\n-            ('field__contains', KeyTransform('bax', 'field')),\n-            (\n-                'field__contained_by',\n-                KeyTransform('x', RawSQL('%s::jsonb', ['{\"x\": {\"a\": \"b\", \"c\": 1, \"d\": \"e\"}}'])),\n-            ),\n-            ('field__has_key', KeyTextTransform('foo', 'field')),\n-        )\n-        for lookup, value in tests:\n-            with self.subTest(lookup=lookup):\n-                self.assertTrue(JSONModel.objects.filter(\n-                    **{lookup: value},\n-                ).exists())\n-\n-\n-@isolate_apps('postgres_tests')\n-class TestChecks(PostgreSQLSimpleTestCase):\n-\n-    def test_invalid_default(self):\n-        class MyModel(PostgreSQLModel):\n-            field = JSONField(default={})\n-\n-        model = MyModel()\n-        self.assertEqual(model.check(), [\n-            checks.Warning(\n-                msg=(\n-                    \"JSONField default should be a callable instead of an \"\n-                    \"instance so that it's not shared between all field \"\n-                    \"instances.\"\n-                ),\n-                hint='Use a callable instead, e.g., use `dict` instead of `{}`.',\n-                obj=MyModel._meta.get_field('field'),\n-                id='fields.E010',\n-            )\n-        ])\n-\n-    def test_valid_default(self):\n-        class MyModel(PostgreSQLModel):\n-            field = JSONField(default=dict)\n-\n-        model = MyModel()\n-        self.assertEqual(model.check(), [])\n-\n-    def test_valid_default_none(self):\n-        class MyModel(PostgreSQLModel):\n-            field = JSONField(default=None)\n-\n-        model = MyModel()\n-        self.assertEqual(model.check(), [])\n-\n-\n-class TestSerialization(PostgreSQLSimpleTestCase):\n-    test_data = (\n-        '[{\"fields\": {\"field\": %s, \"field_custom\": null}, '\n-        '\"model\": \"postgres_tests.jsonmodel\", \"pk\": null}]'\n-    )\n-    test_values = (\n-        # (Python value, serialized value),\n-        ({'a': 'b', 'c': None}, '{\"a\": \"b\", \"c\": null}'),\n-        ('abc', '\"abc\"'),\n-        ('{\"a\": \"a\"}', '\"{\\\\\"a\\\\\": \\\\\"a\\\\\"}\"'),\n-    )\n-\n-    def test_dumping(self):\n-        for value, serialized in self.test_values:\n-            with self.subTest(value=value):\n-                instance = JSONModel(field=value)\n-                data = serializers.serialize('json', [instance])\n-                self.assertJSONEqual(data, self.test_data % serialized)\n-\n-    def test_loading(self):\n-        for value, serialized in self.test_values:\n-            with self.subTest(value=value):\n-                instance = list(serializers.deserialize('json', self.test_data % serialized))[0].object\n-                self.assertEqual(instance.field, value)\n-\n-\n-class TestValidation(PostgreSQLSimpleTestCase):\n-\n-    def test_not_serializable(self):\n-        field = JSONField()\n-        with self.assertRaises(exceptions.ValidationError) as cm:\n-            field.clean(datetime.timedelta(days=1), None)\n-        self.assertEqual(cm.exception.code, 'invalid')\n-        self.assertEqual(cm.exception.message % cm.exception.params, \"Value must be valid JSON.\")\n-\n-    def test_custom_encoder(self):\n-        with self.assertRaisesMessage(ValueError, \"The encoder parameter must be a callable object.\"):\n-            field = JSONField(encoder=DjangoJSONEncoder())\n-        field = JSONField(encoder=DjangoJSONEncoder)\n-        self.assertEqual(field.clean(datetime.timedelta(days=1), None), datetime.timedelta(days=1))\n-\n-\n-class TestFormField(PostgreSQLSimpleTestCase):\n-\n-    def test_valid(self):\n-        field = forms.JSONField()\n-        value = field.clean('{\"a\": \"b\"}')\n-        self.assertEqual(value, {'a': 'b'})\n-\n-    def test_valid_empty(self):\n-        field = forms.JSONField(required=False)\n-        value = field.clean('')\n-        self.assertIsNone(value)\n-\n-    def test_invalid(self):\n-        field = forms.JSONField()\n-        with self.assertRaises(exceptions.ValidationError) as cm:\n-            field.clean('{some badly formed: json}')\n-        self.assertEqual(cm.exception.messages[0], '“{some badly formed: json}” value must be valid JSON.')\n-\n-    def test_formfield(self):\n-        model_field = JSONField()\n-        form_field = model_field.formfield()\n-        self.assertIsInstance(form_field, forms.JSONField)\n-\n-    def test_formfield_disabled(self):\n-        class JsonForm(Form):\n-            name = CharField()\n-            jfield = forms.JSONField(disabled=True)\n-\n-        form = JsonForm({'name': 'xyz', 'jfield': '[\"bar\"]'}, initial={'jfield': ['foo']})\n-        self.assertIn('[&quot;foo&quot;]</textarea>', form.as_p())\n-\n-    def test_prepare_value(self):\n-        field = forms.JSONField()\n-        self.assertEqual(field.prepare_value({'a': 'b'}), '{\"a\": \"b\"}')\n-        self.assertEqual(field.prepare_value(None), 'null')\n-        self.assertEqual(field.prepare_value('foo'), '\"foo\"')\n-\n-    def test_redisplay_wrong_input(self):\n-        \"\"\"\n-        When displaying a bound form (typically due to invalid input), the form\n-        should not overquote JSONField inputs.\n-        \"\"\"\n-        class JsonForm(Form):\n-            name = CharField(max_length=2)\n-            jfield = forms.JSONField()\n-\n-        # JSONField input is fine, name is too long\n-        form = JsonForm({'name': 'xyz', 'jfield': '[\"foo\"]'})\n-        self.assertIn('[&quot;foo&quot;]</textarea>', form.as_p())\n-\n-        # This time, the JSONField input is wrong\n-        form = JsonForm({'name': 'xy', 'jfield': '{\"foo\"}'})\n-        # Appears once in the textarea and once in the error message\n-        self.assertEqual(form.as_p().count(escape('{\"foo\"}')), 2)\n-\n-    def test_widget(self):\n-        \"\"\"The default widget of a JSONField is a Textarea.\"\"\"\n-        field = forms.JSONField()\n-        self.assertIsInstance(field.widget, widgets.Textarea)\n-\n-    def test_custom_widget_kwarg(self):\n-        \"\"\"The widget can be overridden with a kwarg.\"\"\"\n-        field = forms.JSONField(widget=widgets.Input)\n-        self.assertIsInstance(field.widget, widgets.Input)\n-\n-    def test_custom_widget_attribute(self):\n-        \"\"\"The widget can be overridden with an attribute.\"\"\"\n-        class CustomJSONField(forms.JSONField):\n-            widget = widgets.Input\n-\n-        field = CustomJSONField()\n-        self.assertIsInstance(field.widget, widgets.Input)\n-\n-    def test_already_converted_value(self):\n-        field = forms.JSONField(required=False)\n-        tests = [\n-            '[\"a\", \"b\", \"c\"]', '{\"a\": 1, \"b\": 2}', '1', '1.5', '\"foo\"',\n-            'true', 'false', 'null',\n-        ]\n-        for json_string in tests:\n-            val = field.clean(json_string)\n-            self.assertEqual(field.clean(val), val)\n-\n-    def test_has_changed(self):\n-        field = forms.JSONField()\n-        self.assertIs(field.has_changed({'a': True}, '{\"a\": 1}'), True)\n-        self.assertIs(field.has_changed({'a': 1, 'b': 2}, '{\"b\": 2, \"a\": 1}'), False)\ndiff --git a/tests/postgres_tests/test_json_deprecation.py b/tests/postgres_tests/test_json_deprecation.py\nnew file mode 100644\nindex 000000000000..aba1828c66eb\n--- /dev/null\n+++ b/tests/postgres_tests/test_json_deprecation.py\n@@ -0,0 +1,54 @@\n+try:\n+    from django.contrib.postgres.fields import JSONField as ModelJSONField\n+    from django.contrib.postgres.fields.jsonb import KeyTransform, KeyTextTransform\n+    from django.contrib.postgres.forms import JSONField as FormJSONField\n+except ImportError:\n+    pass\n+\n+from django.utils.deprecation import RemovedInDjango40Warning\n+\n+from . import PostgreSQLSimpleTestCase\n+from .models import PostgreSQLModel\n+\n+\n+class DeprecationTests(PostgreSQLSimpleTestCase):\n+    def test_model_field_deprecation_message(self):\n+        warning = {\n+            'msg': (\n+                'django.contrib.postgres.fields.JSONField is deprecated '\n+                'and will be removed in Django 4.0.'\n+            ),\n+            'hint': 'Use django.db.models.JSONField instead.',\n+            'id': 'fields.W903',\n+        }\n+\n+        class PostgreSQLJSONModel(PostgreSQLModel):\n+            field = ModelJSONField()\n+        warnings = PostgreSQLJSONModel().check()\n+        self.assertEqual(warnings[0].msg, warning['msg'])\n+        self.assertEqual(warnings[0].hint, warning['hint'])\n+        self.assertEqual(warnings[0].id, warning['id'])\n+\n+    def test_form_field_deprecation_message(self):\n+        msg = (\n+            'django.contrib.postgres.forms.JSONField is deprecated in favor of '\n+            'django.forms.JSONField'\n+        )\n+        with self.assertWarnsMessage(RemovedInDjango40Warning, msg):\n+            FormJSONField()\n+\n+    def test_key_transform_deprecation_message(self):\n+        msg = (\n+            'django.contrib.postgres.fields.jsonb.KeyTransform is deprecated in favor of '\n+            'django.db.models.fields.json.KeyTransform'\n+        )\n+        with self.assertWarnsMessage(RemovedInDjango40Warning, msg):\n+            KeyTransform('foo', 'bar')\n+\n+    def test_key_text_transform_deprecation_message(self):\n+        msg = (\n+            'django.contrib.postgres.fields.jsonb.KeyTextTransform is deprecated in favor of '\n+            'django.db.models.fields.json.KeyTextTransform'\n+        )\n+        with self.assertWarnsMessage(RemovedInDjango40Warning, msg):\n+            KeyTextTransform('foo', 'bar')\ndiff --git a/tests/queries/models.py b/tests/queries/models.py\nindex e9eec5718dde..4ecad9ee9cc7 100644\n--- a/tests/queries/models.py\n+++ b/tests/queries/models.py\n@@ -747,3 +747,10 @@ class ReturningModel(models.Model):\n \n class NonIntegerPKReturningModel(models.Model):\n     created = CreatedField(editable=False, primary_key=True)\n+\n+\n+class JSONFieldNullable(models.Model):\n+    json_field = models.JSONField(blank=True, null=True)\n+\n+    class Meta:\n+        required_db_features = {'supports_json_field'}\ndiff --git a/tests/queries/test_bulk_update.py b/tests/queries/test_bulk_update.py\nindex e2e9a6147a4f..ec43c866912b 100644\n--- a/tests/queries/test_bulk_update.py\n+++ b/tests/queries/test_bulk_update.py\n@@ -3,11 +3,11 @@\n from django.core.exceptions import FieldDoesNotExist\n from django.db.models import F\n from django.db.models.functions import Lower\n-from django.test import TestCase\n+from django.test import TestCase, skipUnlessDBFeature\n \n from .models import (\n-    Article, CustomDbColumn, CustomPk, Detail, Individual, Member, Note,\n-    Number, Order, Paragraph, SpecialCategory, Tag, Valid,\n+    Article, CustomDbColumn, CustomPk, Detail, Individual, JSONFieldNullable,\n+    Member, Note, Number, Order, Paragraph, SpecialCategory, Tag, Valid,\n )\n \n \n@@ -228,3 +228,14 @@ def test_datetime_field(self):\n             article.created = point_in_time\n         Article.objects.bulk_update(articles, ['created'])\n         self.assertCountEqual(Article.objects.filter(created=point_in_time), articles)\n+\n+    @skipUnlessDBFeature('supports_json_field')\n+    def test_json_field(self):\n+        JSONFieldNullable.objects.bulk_create([\n+            JSONFieldNullable(json_field={'a': i}) for i in range(10)\n+        ])\n+        objs = JSONFieldNullable.objects.all()\n+        for obj in objs:\n+            obj.json_field = {'c': obj.json_field['a'] + 1}\n+        JSONFieldNullable.objects.bulk_update(objs, ['json_field'])\n+        self.assertCountEqual(JSONFieldNullable.objects.filter(json_field__has_key='c'), objs)\n",
    "diff_length": 150948
  },
  {
    "index": 10,
    "filtered_comments": [
      "I've made error message single-line so there is no short/long description separation. See https://github.com/chrismedrela/django/commit/1929a8c3565bdd6aa36b8ce3f578f34091105d59.\n",
      "It is great to see validation.py get replaced with something far more sane - and I think the overall approach is good.\n\nIn addition to my line level comments - here are some overall thoughts:\n\nThere are a number of places where related field checks are skipped if the the value is a string - I'm assuming for lazy resolution. Shouldn't we be in a position by the time checks are done to have all related fields connected? It seems that potential problems that are checked for are now deferred to runtime leaving users with \"why did this setup pass checks and now bombs?\"\n\nI wish there was a way to test this without the brittle problem of doing essentially string comparisons on the error messages. Any typo fixes or rewording means updating the docs. Unfortunately I don't have any bright ideas. When hitting a similar situation for SuspiciousOperation the solution was to create specific subclasses - but that seems like the wrong type of fix here.\n\nThere is a bit too much opaque use of **kwargs being passed around - it is fine for this, but if the design of this feature were to be much more complex than it is, it would be an ass-biting laying in wait.\n\nAs said in a comment, I think the \"check_all_models\" adds enough enhancement and exposes enough checking API for this feature without also adding the global \"registration\" of custom check functions.\n\nThe docs will need some more polish (I'm willing to help - left no comments yet), and actual deprecations need to be started.\n\nI'm NOT NOT NOT a coverage zealot but I did run my little diff coverage tool on the branch which found the following lines that were added/changed that are not tested:\n\nhttps://gist.github.com/ptone/fa491c101de3bc4fc5c7\nhttp://ptone.com/temp/checks-coverage/ (untested changes have block red line numbers)\n\n100% coverage should not be a blind objective, but it can be helpful for you to see any major untested areas, but overall the tests looked good.\n\nThanks for the tremendous amount of work during your GSOC.\n",
      "Thanks for the review, Preston -- much appreciated to have another set of eyes on the codebase.\n\nRegarding the string resolution of related field names -- that's mostly inherited from the old codebase -- Chris hasn't introduced anything new there. You're completely correct that at the point checks are performed, all the models _should_ be resolved. I'll stand corrected on this, but as I recall, the reason the string exclusions exist is so that when a bad model has been referenced, we can catch the fact that it hasn't been resolved, report that problem, and then perform any other checks that are appropriate. However, some checks will break hard if the foreign key reference hasn't been resolved, so you need to skip over those checks.\n\nRegarding the tests checking string content -- I agree that isn't ideal. A stretch goal for this project is to enable pyflakes-style warning/error suppression -- so you'll be able to register that you don't care about E115, and have errors of that type suppressed. This will also give us a simple constant against which we can perform tests. \n\nThe *_kwargs usage is a 'room for expansion' thing, much like the use of *_kwargs on save(). The idea is that you might be able to pass in specific qualifiers or modifiers to the checks; we don't know exactly what they will be -- one use at the moment is \"the app name\", but there could be others. Requiring **kwargs in the prototype for check methods means any future flags will be silently ignored, but can be specifically catered for when appropriate.\n\nAdding custom check functions was a specific goal for the project, with security checks being the use case validating the need for the feature. \n\nCompletely agreed on docs needing polish before this is merged -- that's true of any project, however. I'll certainly remember to call on you when we get to a merge point :-) \n\nThanks for the hit list on coverage, too. My validation to date has been a line-for-line comparison with the old validation checks; that means we should be at least as covered as we were previously, but doesn't account for previously existing testing holes.\n",
      "Am I correct that this issue implies that a default value should always be set, and that this could be a check added to BooleanField?\n\nhttps://github.com/django/django/pull/1466/files\n",
      "@loic, thank you for your input. I've had a look at these wiki pages, but I think that we will stay with \"system checks\" -- I cannot see any option that is _much_ better.\n",
      "One thing I'm curious about: how should we (whether that's Django or third-parties) decide what validation should be done by this checking process, and what should be done in `__init__()`? A number of fields do checks in `__init__()` and raise exceptions there - for example, `FileField` will raise a `TypeError` from `__init__()` if you try to pass it a `unique` argument, but it will not check `upload_to` until model checking.\n\nSince `__init__()` is always run, while model checking is generally only run in development, it would seem that this distinction matters most in a production environment. Since model checking is skipped there, under the assumption that problems have already been addressed in development, perhaps the distinction should be that `__init__()` only does the validation necessary to make the code actually run, while all correctness checks are done by the checking process.\n\nAny thoughts?\n",
      "@marfire I think you've found an unusual edge case of the old validation design.\n\nThe only examples of exceptions raised in `__init__()` that I can find are:\n- AutoField (rejecting `primary_key=False`), \n- FileField (rejecting `primary_key` and `unique` arguments). \n- ForeignKey/M2M (rejecting references to abstract models, and references that aren't a model or a string)\n\nHistorically, implementing these checks in validation.py would have meant extending the 'type specific' blocks in validation.py. Although these blocks already existed, it's not an especially good design pattern (putting all your validation logic in one place), so those three cases of localized validation have slipped in. \n\nI'm fairly certain that these checks could all be converted into system checks without any real change in behavior; and given that we're now moved to a 'check behavior stored on the field' archictecture, we can avoid the bad architecture. We also get slightly improved error reporting behavior as well -- under the current setup, if you have multiple ForeignKeys pointing to an abstract model, each one would be reported as an individual exception. Using a check-based approach, you'd get a summary of _all_ the bad references at once.\n\nAs for third party fields -- historically, they haven't had a choice. They've had to use assertions in `__init__`, because they didn't have access to validation.py. This is one of the reasons behind a move to a checking framework.\n\nSo - my advice for third parties (once this all lands in trunk) would be to use checks, rather than assertions in `__init__` checks -- and, for backwards compatibility, do both :-)\n",
      "@freakboy3742 Thanks for the clarification. That's good news - it's certainly nicer to do everything in system checks than it is to split the work with `__init__()`. \n",
      "I've rebased this branch. I've also improved documentation. I've also fixed the problem of compatibility checks -- I've added new `is_overridden` method to `Settings` and `UserSettingsHolder`. @ptone, do you have time to review documentation? This is the last thing we need to do in order to merge this branch.\n"
    ],
    "code_diff": "diff --git a/django/conf/__init__.py b/django/conf/__init__.py\nindex 7a915f1486bf..5a5a40519c01 100644\n--- a/django/conf/__init__.py\n+++ b/django/conf/__init__.py\n@@ -117,6 +117,7 @@ def __setattr__(self, name, value):\n \n class Settings(BaseSettings):\n     def __init__(self, settings_module):\n+\n         # update this dict from global settings (but only for ALL_CAPS settings)\n         for setting in dir(global_settings):\n             if setting == setting.upper():\n@@ -161,6 +162,9 @@ def __init__(self, settings_module):\n             os.environ['TZ'] = self.TIME_ZONE\n             time.tzset()\n \n+    def is_overridden(self, setting):\n+        return setting in self.__dict__\n+\n \n class UserSettingsHolder(BaseSettings):\n     \"\"\"\n@@ -194,4 +198,10 @@ def __delattr__(self, name):\n     def __dir__(self):\n         return list(self.__dict__) + dir(self.default_settings)\n \n+    def is_overridden(self, setting):\n+        if setting in self._deleted:\n+            return False\n+        else:\n+            return self.default_settings.is_overridden(setting)\n+\n settings = LazySettings()\ndiff --git a/django/conf/global_settings.py b/django/conf/global_settings.py\nindex 6dd25e18f9bb..0e0bddf911d3 100644\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -616,3 +616,13 @@\n \n # Migration module overrides for apps, by app label.\n MIGRATION_MODULES = {}\n+\n+#################\n+# SYSTEM CHECKS #\n+#################\n+\n+# List of all issues generated by system checks that should be silenced. Light\n+# issues like warnings, infos or debugs will not generate a message. Silencing\n+# serious issues like errors and criticals does not result in hiding the\n+# message, but Django will not stop you from e.g. running server.\n+SILENCED_SYSTEM_CHECKS = []\ndiff --git a/django/contrib/admin/__init__.py b/django/contrib/admin/__init__.py\nindex cba84cf80700..6f174e2538e1 100644\n--- a/django/contrib/admin/__init__.py\n+++ b/django/contrib/admin/__init__.py\n@@ -1,15 +1,19 @@\n # ACTION_CHECKBOX_NAME is unused, but should stay since its import from here\n # has been referenced in documentation.\n+from django.contrib.admin.checks import check_admin_app\n from django.contrib.admin.decorators import register\n from django.contrib.admin.helpers import ACTION_CHECKBOX_NAME\n from django.contrib.admin.options import ModelAdmin, HORIZONTAL, VERTICAL\n from django.contrib.admin.options import StackedInline, TabularInline\n-from django.contrib.admin.sites import AdminSite, site\n from django.contrib.admin.filters import (ListFilter, SimpleListFilter,\n     FieldListFilter, BooleanFieldListFilter, RelatedFieldListFilter,\n     ChoicesFieldListFilter, DateFieldListFilter, AllValuesFieldListFilter)\n+from django.contrib.admin.sites import AdminSite, site\n+from django.core import checks\n from django.utils.module_loading import autodiscover_modules\n \n \n def autodiscover():\n     autodiscover_modules('admin', register_to=site)\n+\n+checks.register(check_admin_app)\ndiff --git a/django/contrib/admin/checks.py b/django/contrib/admin/checks.py\nnew file mode 100644\nindex 000000000000..b70192ebce0b\n--- /dev/null\n+++ b/django/contrib/admin/checks.py\n@@ -0,0 +1,912 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from itertools import chain\n+\n+from django.contrib.admin.util import get_fields_from_path, NotRelationField\n+from django.core import checks\n+from django.db import models\n+from django.db.models.fields import FieldDoesNotExist\n+from django.forms.models import BaseModelForm, _get_foreign_key, BaseModelFormSet\n+\n+\n+@checks.register()\n+def check_admin_app(**kwargs):\n+    from django.contrib.admin.sites import site\n+\n+    return list(chain(*[\n+        model_admin.check(model, **kwargs)\n+        for model, model_admin in site._registry.items()\n+    ]))\n+\n+\n+class BaseModelAdminChecks(object):\n+\n+    def __init__(self):\n+        # Before we can introspect models, they need to be fully loaded so that\n+        # inter-relations are set up correctly. We force that here.\n+        models.get_apps()\n+\n+    def check(self, cls, model, **kwargs):\n+        errors = []\n+        errors.extend(self._check_raw_id_fields(cls, model))\n+        errors.extend(self._check_fields(cls, model))\n+        errors.extend(self._check_fieldsets(cls, model))\n+        errors.extend(self._check_exclude(cls, model))\n+        errors.extend(self._check_form(cls, model))\n+        errors.extend(self._check_filter_vertical(cls, model))\n+        errors.extend(self._check_filter_horizontal(cls, model))\n+        errors.extend(self._check_radio_fields(cls, model))\n+        errors.extend(self._check_prepopulated_fields(cls, model))\n+        errors.extend(self._check_ordering(cls, model))\n+        errors.extend(self._check_readonly_fields(cls, model))\n+        return errors\n+\n+    def _check_raw_id_fields(self, cls, model):\n+        \"\"\" Check that `raw_id_fields` only contains field names that are listed\n+        on the model. \"\"\"\n+\n+        if not isinstance(cls.raw_id_fields, (list, tuple)):\n+            return must_be('a list or tuple', option='raw_id_fields', obj=cls, id='admin.E001')\n+        else:\n+            return list(chain(*[\n+                self._check_raw_id_fields_item(cls, model, field_name, 'raw_id_fields[%d]' % index)\n+                for index, field_name in enumerate(cls.raw_id_fields)\n+            ]))\n+\n+    def _check_raw_id_fields_item(self, cls, model, field_name, label):\n+        \"\"\" Check an item of `raw_id_fields`, i.e. check that field named\n+        `field_name` exists in model `model` and is a ForeignKey or a\n+        ManyToManyField. \"\"\"\n+\n+        try:\n+            field = model._meta.get_field(field_name)\n+        except models.FieldDoesNotExist:\n+            return refer_to_missing_field(field=field_name, option=label,\n+                                          model=model, obj=cls, id='admin.E002')\n+        else:\n+            if not isinstance(field, (models.ForeignKey, models.ManyToManyField)):\n+                return must_be('a ForeignKey or ManyToManyField',\n+                               option=label, obj=cls, id='admin.E003')\n+            else:\n+                return []\n+\n+    def _check_fields(self, cls, model):\n+        \"\"\" Check that `fields` only refer to existing fields, doesn't contain\n+        duplicates. Check if at most one of `fields` and `fieldsets` is defined.\n+        \"\"\"\n+\n+        if cls.fields is None:\n+            return []\n+        elif not isinstance(cls.fields, (list, tuple)):\n+            return must_be('a list or tuple', option='fields', obj=cls, id='admin.E004')\n+        elif cls.fieldsets:\n+            return [\n+                checks.Error(\n+                    'Both \"fieldsets\" and \"fields\" are specified.',\n+                    hint=None,\n+                    obj=cls,\n+                    id='admin.E005',\n+                )\n+            ]\n+        elif len(cls.fields) != len(set(cls.fields)):\n+            return [\n+                checks.Error(\n+                    'There are duplicate field(s) in \"fields\".',\n+                    hint=None,\n+                    obj=cls,\n+                    id='admin.E006',\n+                )\n+            ]\n+        else:\n+            return list(chain(*[\n+                self._check_field_spec(cls, model, field_name, 'fields')\n+                for field_name in cls.fields\n+            ]))\n+\n+    def _check_fieldsets(self, cls, model):\n+        \"\"\" Check that fieldsets is properly formatted and doesn't contain\n+        duplicates. \"\"\"\n+\n+        if cls.fieldsets is None:\n+            return []\n+        elif not isinstance(cls.fieldsets, (list, tuple)):\n+            return must_be('a list or tuple', option='fieldsets', obj=cls, id='admin.E007')\n+        else:\n+            return list(chain(*[\n+                self._check_fieldsets_item(cls, model, fieldset, 'fieldsets[%d]' % index)\n+                for index, fieldset in enumerate(cls.fieldsets)\n+            ]))\n+\n+    def _check_fieldsets_item(self, cls, model, fieldset, label):\n+        \"\"\" Check an item of `fieldsets`, i.e. check that this is a pair of a\n+        set name and a dictionary containing \"fields\" key. \"\"\"\n+\n+        if not isinstance(fieldset, (list, tuple)):\n+            return must_be('a list or tuple', option=label, obj=cls, id='admin.E008')\n+        elif len(fieldset) != 2:\n+            return must_be('a pair', option=label, obj=cls, id='admin.E009')\n+        elif not isinstance(fieldset[1], dict):\n+            return must_be('a dictionary', option='%s[1]' % label, obj=cls, id='admin.E010')\n+        elif 'fields' not in fieldset[1]:\n+            return [\n+                checks.Error(\n+                    '\"%s[1]\" must contain \"fields\" key.' % label,\n+                    hint=None,\n+                    obj=cls,\n+                    id='admin.E011',\n+                )\n+            ]\n+        elif len(fieldset[1]['fields']) != len(set(fieldset[1]['fields'])):\n+            return [\n+                checks.Error(\n+                    'There are duplicate field(s) in \"%s[1]\".' % label,\n+                    hint=None,\n+                    obj=cls,\n+                    id='admin.E012',\n+                )\n+            ]\n+        else:\n+            return list(chain(*[\n+                self._check_field_spec(cls, model, fields, '%s[1][\\'fields\\']' % label)\n+                for fields in fieldset[1]['fields']\n+            ]))\n+\n+    def _check_field_spec(self, cls, model, fields, label):\n+        \"\"\" `fields` should be an item of `fields` or an item of\n+        fieldset[1]['fields'] for any `fieldset` in `fieldsets`. It should be a\n+        field name or a tuple of field names. \"\"\"\n+\n+        if isinstance(fields, tuple):\n+            return list(chain(*[\n+                self._check_field_spec_item(cls, model, field_name, \"%s[%d]\" % (label, index))\n+                for index, field_name in enumerate(fields)\n+            ]))\n+        else:\n+            return self._check_field_spec_item(cls, model, fields, label)\n+\n+    def _check_field_spec_item(self, cls, model, field_name, label):\n+        if field_name in cls.readonly_fields:\n+            # Stuff can be put in fields that isn't actually a model field if\n+            # it's in readonly_fields, readonly_fields will handle the\n+            # validation of such things.\n+            return []\n+        else:\n+            try:\n+                field = model._meta.get_field(field_name)\n+            except models.FieldDoesNotExist:\n+                # If we can't find a field on the model that matches, it could\n+                # be an extra field on the form.\n+                return []\n+            else:\n+                if (isinstance(field, models.ManyToManyField) and\n+                        not field.rel.through._meta.auto_created):\n+                    return [\n+                        checks.Error(\n+                            '\"%s\" cannot include the ManyToManyField \"%s\", '\n+                                'because \"%s\" manually specifies relationship model.'\n+                                % (label, field_name, field_name),\n+                            hint=None,\n+                            obj=cls,\n+                            id='admin.E013',\n+                        )\n+                    ]\n+                else:\n+                    return []\n+\n+    def _check_exclude(self, cls, model):\n+        \"\"\" Check that exclude is a sequence without duplicates. \"\"\"\n+\n+        if cls.exclude is None:  # default value is None\n+            return []\n+        elif not isinstance(cls.exclude, (list, tuple)):\n+            return must_be('a list or tuple', option='exclude', obj=cls, id='admin.E014')\n+        elif len(cls.exclude) > len(set(cls.exclude)):\n+            return [\n+                checks.Error(\n+                    '\"exclude\" contains duplicate field(s).',\n+                    hint=None,\n+                    obj=cls,\n+                    id='admin.E015',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def _check_form(self, cls, model):\n+        \"\"\" Check that form subclasses BaseModelForm. \"\"\"\n+\n+        if hasattr(cls, 'form') and not issubclass(cls.form, BaseModelForm):\n+            return must_inherit_from(parent='BaseModelForm', option='form',\n+                                     obj=cls, id='admin.E016')\n+        else:\n+            return []\n+\n+    def _check_filter_vertical(self, cls, model):\n+        \"\"\" Check that filter_vertical is a sequence of field names. \"\"\"\n+\n+        if not hasattr(cls, 'filter_vertical'):\n+            return []\n+        elif not isinstance(cls.filter_vertical, (list, tuple)):\n+            return must_be('a list or tuple', option='filter_vertical', obj=cls, id='admin.E017')\n+        else:\n+            return list(chain(*[\n+                self._check_filter_item(cls, model, field_name, \"filter_vertical[%d]\" % index)\n+                for index, field_name in enumerate(cls.filter_vertical)\n+            ]))\n+\n+    def _check_filter_horizontal(self, cls, model):\n+        \"\"\" Check that filter_horizontal is a sequence of field names. \"\"\"\n+\n+        if not hasattr(cls, 'filter_horizontal'):\n+            return []\n+        elif not isinstance(cls.filter_horizontal, (list, tuple)):\n+            return must_be('a list or tuple', option='filter_horizontal', obj=cls, id='admin.E018')\n+        else:\n+            return list(chain(*[\n+                self._check_filter_item(cls, model, field_name, \"filter_horizontal[%d]\" % index)\n+                for index, field_name in enumerate(cls.filter_horizontal)\n+            ]))\n+\n+    def _check_filter_item(self, cls, model, field_name, label):\n+        \"\"\" Check one item of `filter_vertical` or `filter_horizontal`, i.e.\n+        check that given field exists and is a ManyToManyField. \"\"\"\n+\n+        try:\n+            field = model._meta.get_field(field_name)\n+        except models.FieldDoesNotExist:\n+            return refer_to_missing_field(field=field_name, option=label,\n+                                          model=model, obj=cls, id='admin.E019')\n+        else:\n+            if not isinstance(field, models.ManyToManyField):\n+                return must_be('a ManyToManyField', option=label, obj=cls, id='admin.E020')\n+            else:\n+                return []\n+\n+    def _check_radio_fields(self, cls, model):\n+        \"\"\" Check that `radio_fields` is a dictionary. \"\"\"\n+\n+        if not hasattr(cls, 'radio_fields'):\n+            return []\n+        elif not isinstance(cls.radio_fields, dict):\n+            return must_be('a dictionary', option='radio_fields', obj=cls, id='admin.E021')\n+        else:\n+            return list(chain(*[\n+                self._check_radio_fields_key(cls, model, field_name, 'radio_fields') +\n+                self._check_radio_fields_value(cls, model, val, 'radio_fields[\\'%s\\']' % field_name)\n+                for field_name, val in cls.radio_fields.items()\n+            ]))\n+\n+    def _check_radio_fields_key(self, cls, model, field_name, label):\n+        \"\"\" Check that a key of `radio_fields` dictionary is name of existing\n+        field and that the field is a ForeignKey or has `choices` defined. \"\"\"\n+\n+        try:\n+            field = model._meta.get_field(field_name)\n+        except models.FieldDoesNotExist:\n+            return refer_to_missing_field(field=field_name, option=label,\n+                                          model=model, obj=cls, id='admin.E022')\n+        else:\n+            if not (isinstance(field, models.ForeignKey) or field.choices):\n+                return [\n+                    checks.Error(\n+                        '\"%s\" refers to \"%s\", which is neither an instance of ForeignKey nor does have choices set.'\n+                            % (label, field_name),\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E023',\n+                    )\n+                ]\n+            else:\n+                return []\n+\n+    def _check_radio_fields_value(self, cls, model, val, label):\n+        \"\"\" Check type of a value of `radio_fields` dictionary. \"\"\"\n+\n+        from django.contrib.admin.options import HORIZONTAL, VERTICAL\n+\n+        if val not in (HORIZONTAL, VERTICAL):\n+            return [\n+                checks.Error(\n+                    '\"%s\" is neither admin.HORIZONTAL nor admin.VERTICAL.' % label,\n+                    hint=None,\n+                    obj=cls,\n+                    id='admin.E024',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def _check_prepopulated_fields(self, cls, model):\n+        \"\"\" Check that `prepopulated_fields` is a dictionary containing allowed\n+        field types. \"\"\"\n+\n+        if not hasattr(cls, 'prepopulated_fields'):\n+            return []\n+        elif not isinstance(cls.prepopulated_fields, dict):\n+            return must_be('a dictionary', option='prepopulated_fields', obj=cls, id='admin.E025')\n+        else:\n+            return list(chain(*[\n+                self._check_prepopulated_fields_key(cls, model, field_name, 'prepopulated_fields') +\n+                self._check_prepopulated_fields_value(cls, model, val, 'prepopulated_fields[\\'%s\\']' % field_name)\n+                for field_name, val in cls.prepopulated_fields.items()\n+            ]))\n+\n+    def _check_prepopulated_fields_key(self, cls, model, field_name, label):\n+        \"\"\" Check a key of `prepopulated_fields` dictionary, i.e. check that it\n+        is a name of existing field and the field is one of the allowed types.\n+        \"\"\"\n+\n+        forbidden_field_types = (\n+            models.DateTimeField,\n+            models.ForeignKey,\n+            models.ManyToManyField\n+        )\n+\n+        try:\n+            field = model._meta.get_field(field_name)\n+        except models.FieldDoesNotExist:\n+            return refer_to_missing_field(field=field_name, option=label,\n+                                          model=model, obj=cls, id='admin.E026')\n+        else:\n+            if isinstance(field, forbidden_field_types):\n+                return [\n+                    checks.Error(\n+                        '\"%s\" refers to \"%s\", which must not be a DateTimeField, '\n+                            'ForeignKey or ManyToManyField.'\n+                            % (label, field_name),\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E027',\n+                    )\n+                ]\n+            else:\n+                return []\n+\n+    def _check_prepopulated_fields_value(self, cls, model, val, label):\n+        \"\"\" Check a value of `prepopulated_fields` dictionary, i.e. it's an\n+        iterable of existing fields. \"\"\"\n+\n+        if not isinstance(val, (list, tuple)):\n+            return must_be('a list or tuple', option=label, obj=cls, id='admin.E028')\n+        else:\n+            return list(chain(*[\n+                self._check_prepopulated_fields_value_item(cls, model, subfield_name, \"%s[%r]\" % (label, index))\n+                for index, subfield_name in enumerate(val)\n+            ]))\n+\n+    def _check_prepopulated_fields_value_item(self, cls, model, field_name, label):\n+        \"\"\" For `prepopulated_fields` equal to {\"slug\": (\"title\",)},\n+        `field_name` is \"title\". \"\"\"\n+\n+        try:\n+            model._meta.get_field(field_name)\n+        except models.FieldDoesNotExist:\n+            return refer_to_missing_field(field=field_name, option=label,\n+                                          model=model, obj=cls, id='admin.E029')\n+        else:\n+            return []\n+\n+    def _check_ordering(self, cls, model):\n+        \"\"\" Check that ordering refers to existing fields or is random. \"\"\"\n+\n+        # ordering = None\n+        if cls.ordering is None:  # The default value is None\n+            return []\n+        elif not isinstance(cls.ordering, (list, tuple)):\n+            return must_be('a list or tuple', option='ordering', obj=cls, id='admin.E030')\n+        else:\n+            return list(chain(*[\n+                self._check_ordering_item(cls, model, field_name, 'ordering[%d]' % index)\n+                for index, field_name in enumerate(cls.ordering)\n+            ]))\n+\n+    def _check_ordering_item(self, cls, model, field_name, label):\n+        \"\"\" Check that `ordering` refers to existing fields. \"\"\"\n+\n+        if field_name == '?' and len(cls.ordering) != 1:\n+            return [\n+                checks.Error(\n+                    '\"ordering\" has the random ordering marker \"?\", '\n+                        'but contains other fields as well.',\n+                    hint='Either remove the \"?\", or remove the other fields.',\n+                    obj=cls,\n+                    id='admin.E031',\n+                )\n+            ]\n+        elif field_name == '?':\n+            return []\n+        elif '__' in field_name:\n+            # Skip ordering in the format field1__field2 (FIXME: checking\n+            # this format would be nice, but it's a little fiddly).\n+            return []\n+        else:\n+            if field_name.startswith('-'):\n+                field_name = field_name[1:]\n+\n+            try:\n+                model._meta.get_field(field_name)\n+            except models.FieldDoesNotExist:\n+                return refer_to_missing_field(field=field_name, option=label,\n+                                              model=model, obj=cls, id='admin.E032')\n+            else:\n+                return []\n+\n+    def _check_readonly_fields(self, cls, model):\n+        \"\"\" Check that readonly_fields refers to proper attribute or field. \"\"\"\n+\n+        if cls.readonly_fields == ():\n+            return []\n+        elif not isinstance(cls.readonly_fields, (list, tuple)):\n+            return must_be('a list or tuple', option='readonly_fields', obj=cls, id='admin.E033')\n+        else:\n+            return list(chain(*[\n+                self._check_readonly_fields_item(cls, model, field_name, \"readonly_fields[%d]\" % index)\n+                for index, field_name in enumerate(cls.readonly_fields)\n+            ]))\n+\n+    def _check_readonly_fields_item(self, cls, model, field_name, label):\n+        if callable(field_name):\n+            return []\n+        elif hasattr(cls, field_name):\n+            return []\n+        elif hasattr(model, field_name):\n+            return []\n+        else:\n+            try:\n+                model._meta.get_field(field_name)\n+            except models.FieldDoesNotExist:\n+                return [\n+                    checks.Error(\n+                        '\"%s\" is neither a callable nor an attribute of \"%s\" nor found in the model %s.%s.'\n+                            % (label, cls.__name__, model._meta.app_label, model._meta.object_name),\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E034',\n+                    )\n+                ]\n+            else:\n+                return []\n+\n+\n+class ModelAdminChecks(BaseModelAdminChecks):\n+\n+    def check(self, cls, model, **kwargs):\n+        errors = super(ModelAdminChecks, self).check(cls, model=model, **kwargs)\n+        errors.extend(self._check_save_as(cls, model))\n+        errors.extend(self._check_save_on_top(cls, model))\n+        errors.extend(self._check_inlines(cls, model))\n+        errors.extend(self._check_list_display(cls, model))\n+        errors.extend(self._check_list_display_links(cls, model))\n+        errors.extend(self._check_list_filter(cls, model))\n+        errors.extend(self._check_list_select_related(cls, model))\n+        errors.extend(self._check_list_per_page(cls, model))\n+        errors.extend(self._check_list_max_show_all(cls, model))\n+        errors.extend(self._check_list_editable(cls, model))\n+        errors.extend(self._check_search_fields(cls, model))\n+        errors.extend(self._check_date_hierarchy(cls, model))\n+        return errors\n+\n+    def _check_save_as(self, cls, model):\n+        \"\"\" Check save_as is a boolean. \"\"\"\n+\n+        if not isinstance(cls.save_as, bool):\n+            return must_be('a boolean', option='save_as',\n+                           obj=cls, id='admin.E101')\n+        else:\n+            return []\n+\n+    def _check_save_on_top(self, cls, model):\n+        \"\"\" Check save_on_top is a boolean. \"\"\"\n+\n+        if not isinstance(cls.save_on_top, bool):\n+            return must_be('a boolean', option='save_on_top',\n+                           obj=cls, id='admin.E102')\n+        else:\n+            return []\n+\n+    def _check_inlines(self, cls, model):\n+        \"\"\" Check all inline model admin classes. \"\"\"\n+\n+        if not isinstance(cls.inlines, (list, tuple)):\n+            return must_be('a list or tuple', option='inlines', obj=cls, id='admin.E103')\n+        else:\n+            return list(chain(*[\n+                self._check_inlines_item(cls, model, item, \"inlines[%d]\" % index)\n+                for index, item in enumerate(cls.inlines)\n+            ]))\n+\n+    def _check_inlines_item(self, cls, model, inline, label):\n+        \"\"\" Check one inline model admin. \"\"\"\n+\n+        from django.contrib.admin.options import BaseModelAdmin\n+\n+        if not issubclass(inline, BaseModelAdmin):\n+            return must_inherit_from(parent='BaseModelAdmin', option=label,\n+                                     obj=cls, id='admin.E104')\n+        elif not inline.model:\n+            return [\n+                checks.Error(\n+                    '\"model\" is a required attribute of \"%s\".' % label,\n+                    hint=None,\n+                    obj=cls,\n+                    id='admin.E105',\n+                )\n+            ]\n+        elif not issubclass(inline.model, models.Model):\n+            return must_be('a Model', option='%s.model' % label,\n+                           obj=cls, id='admin.E106')\n+        else:\n+            return inline.check(model)\n+\n+    def _check_list_display(self, cls, model):\n+        \"\"\" Check that list_display only contains fields or usable attributes.\n+        \"\"\"\n+\n+        if not isinstance(cls.list_display, (list, tuple)):\n+            return must_be('a list or tuple', option='list_display', obj=cls, id='admin.E107')\n+        else:\n+            return list(chain(*[\n+                self._check_list_display_item(cls, model, item, \"list_display[%d]\" % index)\n+                for index, item in enumerate(cls.list_display)\n+            ]))\n+\n+    def _check_list_display_item(self, cls, model, item, label):\n+        if callable(item):\n+            return []\n+        elif hasattr(cls, item):\n+            return []\n+        elif hasattr(model, item):\n+            # getattr(model, item) could be an X_RelatedObjectsDescriptor\n+            try:\n+                field = model._meta.get_field(item)\n+            except models.FieldDoesNotExist:\n+                try:\n+                    field = getattr(model, item)\n+                except AttributeError:\n+                    field = None\n+\n+            if field is None:\n+                return [\n+                    checks.Error(\n+                        '\"%s\" refers to \"%s\" that is neither a field, method nor a property of model %s.%s.'\n+                            % label, item, model._meta.app_label, model._meta.object_name,\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E108',\n+                    )\n+                ]\n+            elif isinstance(field, models.ManyToManyField):\n+                return [\n+                    checks.Error(\n+                        '\"%s\" must not be a ManyToManyField.' % label,\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E109',\n+                    )\n+                ]\n+            else:\n+                return []\n+        else:\n+            try:\n+                model._meta.get_field(item)\n+            except models.FieldDoesNotExist:\n+                return [\n+                    checks.Error(\n+                        '\"%s\" is neither a callable nor an attribute of \"%s\" nor found in model %s.%s.'\n+                            % (label, cls.__name__, model._meta.app_label, model._meta.object_name),\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E110',\n+                    )\n+                ]\n+            else:\n+                return []\n+\n+    def _check_list_display_links(self, cls, model):\n+        \"\"\" Check that list_display_links is a unique subset of list_display.\n+        \"\"\"\n+\n+        if cls.list_display_links is None:\n+            return []\n+        elif not isinstance(cls.list_display_links, (list, tuple)):\n+            return must_be('a list or tuple or None', option='list_display_links', obj=cls, id='admin.E111')\n+        else:\n+            return list(chain(*[\n+                self._check_list_display_links_item(cls, model, field_name, \"list_display_links[%d]\" % index)\n+                for index, field_name in enumerate(cls.list_display_links)\n+            ]))\n+\n+    def _check_list_display_links_item(self, cls, model, field_name, label):\n+        if field_name not in cls.list_display:\n+            return [\n+                checks.Error(\n+                    '\"%s\" refers to \"%s\", which is not defined in \"list_display\".'\n+                        % (label, field_name),\n+                    hint=None,\n+                    obj=cls,\n+                    id='admin.E112',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def _check_list_filter(self, cls, model):\n+        if not isinstance(cls.list_filter, (list, tuple)):\n+            return must_be('a list or tuple', option='list_filter', obj=cls, id='admin.E113')\n+        else:\n+            return list(chain(*[\n+                self._check_list_filter_item(cls, model, item, \"list_filter[%d]\" % index)\n+                for index, item in enumerate(cls.list_filter)\n+            ]))\n+\n+    def _check_list_filter_item(self, cls, model, item, label):\n+        \"\"\"\n+        Check one item of `list_filter`, i.e. check if it is one of three options:\n+        1. 'field' -- a basic field filter, possibly w/ relationships (e.g.\n+           'field__rel')\n+        2. ('field', SomeFieldListFilter) - a field-based list filter class\n+        3. SomeListFilter - a non-field list filter class\n+        \"\"\"\n+\n+        from django.contrib.admin import ListFilter, FieldListFilter\n+\n+        if callable(item) and not isinstance(item, models.Field):\n+            # If item is option 3, it should be a ListFilter...\n+            if not issubclass(item, ListFilter):\n+                return must_inherit_from(parent='ListFilter', option=label,\n+                                         obj=cls, id='admin.E114')\n+            # ...  but not a FieldListFilter.\n+            elif issubclass(item, FieldListFilter):\n+                return [\n+                    checks.Error(\n+                        '\"%s\" must not inherit from FieldListFilter.' % label,\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E115',\n+                    )\n+                ]\n+            else:\n+                return []\n+        elif isinstance(item, (tuple, list)):\n+            # item is option #2\n+            field, list_filter_class = item\n+            if not issubclass(list_filter_class, FieldListFilter):\n+                return must_inherit_from(parent='FieldListFilter', option='%s[1]' % label,\n+                                         obj=cls, id='admin.E116')\n+            else:\n+                return []\n+        else:\n+            # item is option #1\n+            field = item\n+\n+            # Validate the field string\n+            try:\n+                get_fields_from_path(model, field)\n+            except (NotRelationField, FieldDoesNotExist):\n+                return [\n+                    checks.Error(\n+                        '\"%s\" refers to \"%s\", which does not refer to a Field.' % (label, field),\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E117',\n+                    )\n+                ]\n+            else:\n+                return []\n+\n+    def _check_list_select_related(self, cls, model):\n+        \"\"\" Check that list_select_related is a boolean, a list or a tuple. \"\"\"\n+\n+        if not isinstance(cls.list_select_related, (bool, list, tuple)):\n+            return must_be('a boolean, tuple or list', option='list_select_related',\n+                           obj=cls, id='admin.E118')\n+        else:\n+            return []\n+\n+    def _check_list_per_page(self, cls, model):\n+        \"\"\" Check that list_per_page is an integer. \"\"\"\n+\n+        if not isinstance(cls.list_per_page, int):\n+            return must_be('an integer', option='list_per_page', obj=cls, id='admin.E119')\n+        else:\n+            return []\n+\n+    def _check_list_max_show_all(self, cls, model):\n+        \"\"\" Check that list_max_show_all is an integer. \"\"\"\n+\n+        if not isinstance(cls.list_max_show_all, int):\n+            return must_be('an integer', option='list_max_show_all', obj=cls, id='admin.E120')\n+        else:\n+            return []\n+\n+    def _check_list_editable(self, cls, model):\n+        \"\"\" Check that list_editable is a sequence of editable fields from\n+        list_display without first element. \"\"\"\n+\n+        if not isinstance(cls.list_editable, (list, tuple)):\n+            return must_be('a list or tuple', option='list_editable', obj=cls, id='admin.E121')\n+        else:\n+            return list(chain(*[\n+                self._check_list_editable_item(cls, model, item, \"list_editable[%d]\" % index)\n+                for index, item in enumerate(cls.list_editable)\n+            ]))\n+\n+    def _check_list_editable_item(self, cls, model, field_name, label):\n+        try:\n+            field = model._meta.get_field_by_name(field_name)[0]\n+        except models.FieldDoesNotExist:\n+            return refer_to_missing_field(field=field_name, option=label,\n+                                          model=model, obj=cls, id='admin.E122')\n+        else:\n+            if field_name not in cls.list_display:\n+                return refer_to_missing_field(field=field_name, option=label,\n+                                              model=model, obj=cls, id='admin.E123')\n+            elif field_name in cls.list_display_links:\n+                return [\n+                    checks.Error(\n+                        '\"%s\" cannot be in both \"list_editable\" and \"list_display_links\".'\n+                            % field_name,\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E124',\n+                    )\n+                ]\n+            elif not cls.list_display_links and cls.list_display[0] in cls.list_editable:\n+                return [\n+                    checks.Error(\n+                        '\"%s\" refers to the first field in list_display (\"%s\"), '\n+                            'which cannot be used unless list_display_links is set.'\n+                            % (label, cls.list_display[0]),\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E125',\n+                    )\n+                ]\n+            elif not field.editable:\n+                return [\n+                    checks.Error(\n+                        '\"%s\" refers to field \"%s\", whih is not editable through the admin.'\n+                            % (label, field_name),\n+                        hint=None,\n+                        obj=cls,\n+                        id='admin.E126',\n+                    )\n+                ]\n+\n+    def _check_search_fields(self, cls, model):\n+        \"\"\" Check search_fields is a sequence. \"\"\"\n+\n+        if not isinstance(cls.search_fields, (list, tuple)):\n+            return must_be('a list or tuple', option='search_fields', obj=cls, id='admin.E127')\n+        else:\n+            return []\n+\n+    def _check_date_hierarchy(self, cls, model):\n+        \"\"\" Check that date_hierarchy refers to DateField or DateTimeField. \"\"\"\n+\n+        if cls.date_hierarchy is None:\n+            return []\n+        else:\n+            try:\n+                field = model._meta.get_field(cls.date_hierarchy)\n+            except models.FieldDoesNotExist:\n+                return refer_to_missing_field(option='date_hierarchy',\n+                                              field=cls.date_hierarchy,\n+                                              model=model, obj=cls, id='admin.E128')\n+            else:\n+                if not isinstance(field, (models.DateField, models.DateTimeField)):\n+                    return must_be('a DateField or DateTimeField', option='date_hierarchy',\n+                                   obj=cls, id='admin.E129')\n+                else:\n+                    return []\n+\n+\n+class InlineModelAdminChecks(BaseModelAdminChecks):\n+\n+    def check(self, cls, parent_model, **kwargs):\n+        errors = super(InlineModelAdminChecks, self).check(cls, model=cls.model, **kwargs)\n+        errors.extend(self._check_fk_name(cls, parent_model))\n+        errors.extend(self._check_exclude_of_parent_model(cls, parent_model))\n+        errors.extend(self._check_extra(cls))\n+        errors.extend(self._check_max_num(cls))\n+        errors.extend(self._check_formset(cls))\n+        return errors\n+\n+    def _check_exclude_of_parent_model(self, cls, parent_model):\n+        # Do not perform more specific checks if the base checks result in an\n+        # error.\n+        errors = super(InlineModelAdminChecks, self)._check_exclude(cls, parent_model)\n+        if errors:\n+            return []\n+\n+        # Skip if `fk_name` is invalid.\n+        if self._check_fk_name(cls, parent_model):\n+            return []\n+\n+        if cls.exclude is None:\n+            return []\n+\n+        fk = _get_foreign_key(parent_model, cls.model, fk_name=cls.fk_name)\n+        if fk.name in cls.exclude:\n+            return [\n+                checks.Error(\n+                    'Cannot exclude the field \"%s\", because it is the foreign key '\n+                        'to the parent model %s.%s.'\n+                        % (fk.name, parent_model._meta.app_label, parent_model._meta.object_name),\n+                    hint=None,\n+                    obj=cls,\n+                    id='admin.E201',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def _check_fk_name(self, cls, parent_model):\n+        try:\n+            _get_foreign_key(parent_model, cls.model, fk_name=cls.fk_name)\n+        except ValueError as e:\n+            return [checks.Error(e.args[0], hint=None, obj=cls, id='admin.E202')]\n+        else:\n+            return []\n+\n+    def _check_extra(self, cls):\n+        \"\"\" Check that extra is an integer. \"\"\"\n+\n+        if not isinstance(cls.extra, int):\n+            return must_be('an integer', option='extra', obj=cls, id='admin.E203')\n+        else:\n+            return []\n+\n+    def _check_max_num(self, cls):\n+        \"\"\" Check that max_num is an integer. \"\"\"\n+\n+        if cls.max_num is None:\n+            return []\n+        elif not isinstance(cls.max_num, int):\n+            return must_be('an integer', option='max_num', obj=cls, id='admin.E204')\n+        else:\n+            return []\n+\n+    def _check_formset(self, cls):\n+        \"\"\" Check formset is a subclass of BaseModelFormSet. \"\"\"\n+\n+        if not issubclass(cls.formset, BaseModelFormSet):\n+            return must_inherit_from(parent='BaseModelFormSet', option='formset',\n+                                     obj=cls, id='admin.E205')\n+        else:\n+            return []\n+\n+\n+def must_be(type, option, obj, id):\n+    return [\n+        checks.Error(\n+            '\"%s\" must be %s.' % (option, type),\n+            hint=None,\n+            obj=obj,\n+            id=id,\n+        ),\n+    ]\n+\n+\n+def must_inherit_from(parent, option, obj, id):\n+    return [\n+        checks.Error(\n+            '\"%s\" must inherit from %s.' % (option, parent),\n+            hint=None,\n+            obj=obj,\n+            id=id,\n+        ),\n+    ]\n+\n+\n+def refer_to_missing_field(field, option, model, obj, id):\n+    return [\n+        checks.Error(\n+            '\"%s\" refers to field \"%s\", which is missing from model %s.%s.'\n+                % (option, field, model._meta.app_label, model._meta.object_name),\n+            hint=None,\n+            obj=obj,\n+            id=id,\n+        ),\n+    ]\ndiff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 3b02ac020c9c..428a00f2c0ad 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -8,14 +8,17 @@\n from django.conf import settings\n from django.contrib import messages\n from django.contrib.admin import widgets, helpers\n-from django.contrib.admin.utils import (unquote, flatten_fieldsets, get_deleted_objects,\n-    model_format_dict, NestedObjects, lookup_needs_distinct)\n-from django.contrib.admin import validation\n+from django.contrib.admin.checks import (BaseModelAdminChecks, ModelAdminChecks,\n+    InlineModelAdminChecks)\n+from django.contrib.admin.utils import (unquote, flatten_fieldsets,\n+    get_deleted_objects, model_format_dict, NestedObjects,\n+    lookup_needs_distinct)\n from django.contrib.admin.templatetags.admin_static import static\n from django.contrib.admin.templatetags.admin_urls import add_preserved_filters\n from django.contrib.auth import get_permission_codename\n from django.contrib.contenttypes.models import ContentType\n-from django.core.exceptions import PermissionDenied, ValidationError, FieldError\n+from django.core import checks\n+from django.core.exceptions import PermissionDenied, ValidationError, FieldError, ImproperlyConfigured\n from django.core.paginator import Paginator\n from django.core.urlresolvers import reverse\n from django.db import models, transaction, router\n@@ -30,16 +33,17 @@\n from django.http.response import HttpResponseBase\n from django.shortcuts import get_object_or_404\n from django.template.response import SimpleTemplateResponse, TemplateResponse\n-from django.utils.decorators import method_decorator\n-from django.utils.html import escape, escapejs\n-from django.utils.safestring import mark_safe\n from django.utils import six\n+from django.utils.decorators import method_decorator\n from django.utils.deprecation import RenameMethodsBase\n+from django.utils.encoding import force_text\n+from django.utils.encoding import python_2_unicode_compatible\n+from django.utils.html import escape, escapejs\n from django.utils.http import urlencode\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import ugettext as _\n from django.utils.translation import ungettext\n-from django.utils.encoding import force_text\n+from django.utils.safestring import mark_safe\n from django.views.decorators.csrf import csrf_protect\n \n \n@@ -77,13 +81,18 @@ class IncorrectLookupParameters(Exception):\n csrf_protect_m = method_decorator(csrf_protect)\n \n \n+@python_2_unicode_compatible\n class RenameBaseModelAdminMethods(forms.MediaDefiningClass, RenameMethodsBase):\n     renamed_methods = (\n         ('queryset', 'get_queryset', DeprecationWarning),\n     )\n \n+    def __str__(cls):\n+        return '%s.%s' % (cls.__module__, cls.__name__)\n+\n \n-class BaseModelAdmin(six.with_metaclass(RenameBaseModelAdminMethods)):\n+class BaseModelAdmin(six.with_metaclass(RenameBaseModelAdminMethods),\n+                     BaseModelAdminChecks):\n     \"\"\"Functionality common to both ModelAdmin and InlineAdmin.\"\"\"\n \n     raw_id_fields = ()\n@@ -99,13 +108,7 @@ class BaseModelAdmin(six.with_metaclass(RenameBaseModelAdminMethods)):\n     readonly_fields = ()\n     ordering = None\n \n-    # validation\n-    validator_class = validation.BaseValidator\n-\n-    @classmethod\n-    def validate(cls, model):\n-        validator = cls.validator_class()\n-        validator.validate(cls, model)\n+    checks = BaseModelAdminChecks\n \n     def __init__(self):\n         self._orig_formfield_overrides = self.formfield_overrides\n@@ -416,7 +419,30 @@ def has_delete_permission(self, request, obj=None):\n         codename = get_permission_codename('delete', opts)\n         return request.user.has_perm(\"%s.%s\" % (opts.app_label, codename))\n \n+    @classmethod\n+    def check(cls, model, **kwargs):\n+        if hasattr(cls, 'validator'):\n+            warnings.warn(\n+                'ModelAdmin.validator is deprecated. Use \"checks\" instead.',\n+                PendingDeprecationWarning)\n+            validator = cls.validator()\n+            try:\n+                validator.validate(cls, model)\n+            except ImproperlyConfigured as e:\n+                return [\n+                    checks.Error(\n+                        e.args[0],\n+                        hint=None,\n+                        obj=cls,\n+                    )\n+                ]\n+            else:\n+                return []\n+        else:\n+            return cls.checks().check(cls, model, **kwargs)\n \n+\n+@python_2_unicode_compatible\n class ModelAdmin(BaseModelAdmin):\n     \"Encapsulates all admin options and functionality for a given model.\"\n \n@@ -450,8 +476,7 @@ class ModelAdmin(BaseModelAdmin):\n     actions_on_bottom = False\n     actions_selection_counter = True\n \n-    # validation\n-    validator_class = validation.ModelAdminValidator\n+    checks = ModelAdminChecks\n \n     def __init__(self, model, admin_site):\n         self.model = model\n@@ -1643,7 +1668,11 @@ def _create_formsets(self, request, obj):\n             inline_instances.append(inline)\n         return formsets, inline_instances\n \n+    def __str__(self):\n+        return \"%s.%s\" % (self.model._meta.app_label, self.__class__.__name__)\n+\n \n+@python_2_unicode_compatible\n class InlineModelAdmin(BaseModelAdmin):\n     \"\"\"\n     Options for inline editing of ``model`` instances.\n@@ -1662,8 +1691,7 @@ class InlineModelAdmin(BaseModelAdmin):\n     verbose_name_plural = None\n     can_delete = True\n \n-    # validation\n-    validator_class = validation.InlineValidator\n+    checks = InlineModelAdminChecks\n \n     def __init__(self, parent_model, admin_site):\n         self.admin_site = admin_site\ndiff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 2dac947fbce2..3f213a79e873 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -98,9 +98,6 @@ def register(self, model_or_iterable, admin_class=None, **options):\n                     options['__module__'] = __name__\n                     admin_class = type(\"%sAdmin\" % model.__name__, (admin_class,), options)\n \n-                if admin_class is not ModelAdmin and settings.DEBUG:\n-                    admin_class.validate(model)\n-\n                 # Instantiate the admin class to save in the registry\n                 self._registry[model] = admin_class(model, self)\n \ndiff --git a/django/contrib/admin/validation.py b/django/contrib/admin/validation.py\nindex e4a12211b52b..0d758fac4202 100644\n--- a/django/contrib/admin/validation.py\n+++ b/django/contrib/admin/validation.py\n@@ -1,8 +1,11 @@\n+# -*- encoding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n from django.core.exceptions import ImproperlyConfigured\n from django.db import models\n from django.db.models.fields import FieldDoesNotExist\n from django.forms.models import BaseModelForm, BaseModelFormSet, _get_foreign_key\n-from django.contrib.admin.utils import get_fields_from_path, NotRelationField\n+from django.contrib.admin.util import get_fields_from_path, NotRelationField\n \n \"\"\"\n Does basic ModelAdmin option validation. Calls custom validation\n@@ -257,10 +260,8 @@ def validate_list_display(self, cls, model):\n                                     % (cls.__name__, idx, field))\n \n     def validate_list_display_links(self, cls, model):\n-        \" Validate that list_display_links either is None or a unique subset of list_display.\"\n+        \" Validate that list_display_links is a unique subset of list_display. \"\n         if hasattr(cls, 'list_display_links'):\n-            if cls.list_display_links is None:\n-                return\n             check_isseq(cls, 'list_display_links', cls.list_display_links)\n             for idx, field in enumerate(cls.list_display_links):\n                 if field not in cls.list_display:\n@@ -346,16 +347,15 @@ def validate_list_editable(self, cls, model):\n                     raise ImproperlyConfigured(\"'%s.list_editable[%d]' refers to \"\n                         \"'%s' which is not defined in 'list_display'.\"\n                         % (cls.__name__, idx, field_name))\n-                if cls.list_display_links is not None:\n-                    if field_name in cls.list_display_links:\n-                        raise ImproperlyConfigured(\"'%s' cannot be in both '%s.list_editable'\"\n-                            \" and '%s.list_display_links'\"\n-                            % (field_name, cls.__name__, cls.__name__))\n-                    if not cls.list_display_links and cls.list_display[0] in cls.list_editable:\n-                        raise ImproperlyConfigured(\"'%s.list_editable[%d]' refers to\"\n-                            \" the first field in list_display, '%s', which can't be\"\n-                            \" used unless list_display_links is set.\"\n-                            % (cls.__name__, idx, cls.list_display[0]))\n+                if field_name in cls.list_display_links:\n+                    raise ImproperlyConfigured(\"'%s' cannot be in both '%s.list_editable'\"\n+                        \" and '%s.list_display_links'\"\n+                        % (field_name, cls.__name__, cls.__name__))\n+                if not cls.list_display_links and cls.list_display[0] in cls.list_editable:\n+                    raise ImproperlyConfigured(\"'%s.list_editable[%d]' refers to\"\n+                        \" the first field in list_display, '%s', which can't be\"\n+                        \" used unless list_display_links is set.\"\n+                        % (cls.__name__, idx, cls.list_display[0]))\n                 if not field.editable:\n                     raise ImproperlyConfigured(\"'%s.list_editable[%d]' refers to a \"\n                         \"field, '%s', which isn't editable through the admin.\"\n@@ -405,14 +405,17 @@ def check_type(cls, attr, type_):\n         raise ImproperlyConfigured(\"'%s.%s' should be a %s.\"\n                 % (cls.__name__, attr, type_.__name__ ))\n \n+\n def check_isseq(cls, label, obj):\n     if not isinstance(obj, (list, tuple)):\n         raise ImproperlyConfigured(\"'%s.%s' must be a list or tuple.\" % (cls.__name__, label))\n \n+\n def check_isdict(cls, label, obj):\n     if not isinstance(obj, dict):\n         raise ImproperlyConfigured(\"'%s.%s' must be a dictionary.\" % (cls.__name__, label))\n \n+\n def get_field(cls, model, label, field):\n     try:\n         return model._meta.get_field(field)\n@@ -420,6 +423,7 @@ def get_field(cls, model, label, field):\n         raise ImproperlyConfigured(\"'%s.%s' refers to field '%s' that is missing from model '%s.%s'.\"\n                 % (cls.__name__, label, field, model._meta.app_label, model.__name__))\n \n+\n def fetch_attr(cls, model, label, field):\n     try:\n         return model._meta.get_field(field)\ndiff --git a/django/contrib/auth/__init__.py b/django/contrib/auth/__init__.py\nindex 4ef5c0b2cd30..5c18c794fef4 100644\n--- a/django/contrib/auth/__init__.py\n+++ b/django/contrib/auth/__init__.py\n@@ -3,6 +3,7 @@\n \n from django.conf import settings\n from django.core.exceptions import ImproperlyConfigured, PermissionDenied\n+import django.contrib.auth.checks\n from django.utils.module_loading import import_by_path\n from django.middleware.csrf import rotate_token\n \ndiff --git a/django/contrib/auth/checks.py b/django/contrib/auth/checks.py\nnew file mode 100644\nindex 000000000000..1d5f022d85fb\n--- /dev/null\n+++ b/django/contrib/auth/checks.py\n@@ -0,0 +1,69 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from django.core import checks\n+\n+\n+@checks.register()\n+def check_user_model(**kwargs):\n+    from django.conf import settings\n+    from django.db import models\n+\n+    errors = []\n+    app_name, model_name = settings.AUTH_USER_MODEL.split('.')\n+\n+    cls = models.get_model(app_name, model_name)\n+\n+    # Check that REQUIRED_FIELDS is a list\n+    if not isinstance(cls.REQUIRED_FIELDS, (list, tuple)):\n+        errors.append(\n+            checks.Error(\n+                'The REQUIRED_FIELDS must be a list or tuple.',\n+                hint=None,\n+                obj=cls,\n+                id='auth.E001',\n+            )\n+        )\n+\n+    # Check that the USERNAME FIELD isn't included in REQUIRED_FIELDS.\n+    if cls.USERNAME_FIELD in cls.REQUIRED_FIELDS:\n+        errors.append(\n+            checks.Error(\n+                'The field named as the USERNAME_FIELD '\n+                    'must not be included in REQUIRED_FIELDS '\n+                    'on a custom user model.',\n+                hint=None,\n+                obj=cls,\n+                id='auth.E002',\n+            )\n+        )\n+\n+\n+    # Check that the username field is unique\n+    if not cls._meta.get_field(cls.USERNAME_FIELD).unique:\n+        if settings.AUTHENTICATION_BACKENDS == \\\n+                ('django.contrib.auth.backends.ModelBackend',):\n+            errors.append(\n+                checks.Error(\n+                    'The %s.%s field must be unique because it is '\n+                        'pointed to by USERNAME_FIELD.'\n+                        % (cls._meta.object_name, cls.USERNAME_FIELD),\n+                    hint=None,\n+                    obj=cls,\n+                    id='auth.E003',\n+                )\n+            )\n+        else:\n+            errors.append(\n+                checks.Warning(\n+                    'The %s.%s field is pointed to by USERNAME_FIELD, '\n+                        'but it is not unique.'\n+                        % (cls._meta.object_name, cls.USERNAME_FIELD),\n+                    hint='Ensure that your authentication backend can handle '\n+                        'non-unique usernames.',\n+                    obj=cls,\n+                    id='auth.W004',\n+                )\n+            )\n+\n+    return errors\ndiff --git a/django/contrib/auth/management/commands/changepassword.py b/django/contrib/auth/management/commands/changepassword.py\nindex 3240b0f99225..5b47cefd9a01 100644\n--- a/django/contrib/auth/management/commands/changepassword.py\n+++ b/django/contrib/auth/management/commands/changepassword.py\n@@ -13,7 +13,7 @@ class Command(BaseCommand):\n     )\n     help = \"Change a user's password for django.contrib.auth.\"\n \n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     def _get_pass(self, prompt=\"Password: \"):\n         p = getpass.getpass(prompt=prompt)\ndiff --git a/django/contrib/auth/tests/test_management.py b/django/contrib/auth/tests/test_management.py\nindex e56df0676b58..1eedc3eee033 100644\n--- a/django/contrib/auth/tests/test_management.py\n+++ b/django/contrib/auth/tests/test_management.py\n@@ -2,18 +2,18 @@\n from datetime import date\n \n from django.contrib.auth import models, management\n+from django.contrib.auth.checks import check_user_model\n from django.contrib.auth.management import create_permissions\n from django.contrib.auth.management.commands import changepassword\n from django.contrib.auth.models import User\n from django.contrib.auth.tests.custom_user import CustomUser\n from django.contrib.auth.tests.utils import skipIfCustomUser\n from django.contrib.contenttypes.models import ContentType\n+from django.core import checks\n from django.core.management import call_command\n from django.core.management.base import CommandError\n-from django.core.management.validation import get_validation_errors\n-from django.db.models.loading import get_app\n from django.test import TestCase\n-from django.test.utils import override_settings\n+from django.test.utils import override_settings, override_system_checks\n from django.utils import six\n from django.utils.six import StringIO\n \n@@ -144,7 +144,7 @@ def test_swappable_user(self):\n             email=\"joe@somewhere.org\",\n             date_of_birth=\"1976-04-01\",\n             stdout=new_io,\n-            skip_validation=True\n+            skip_checks=True\n         )\n         command_output = new_io.getvalue().strip()\n         self.assertEqual(command_output, 'Superuser created successfully.')\n@@ -167,7 +167,7 @@ def test_swappable_user_missing_required_field(self):\n                 username=\"joe@somewhere.org\",\n                 stdout=new_io,\n                 stderr=new_io,\n-                skip_validation=True\n+                skip_checks=True\n             )\n \n         self.assertEqual(CustomUser._default_manager.count(), 0)\n@@ -175,25 +175,81 @@ def test_swappable_user_missing_required_field(self):\n \n class CustomUserModelValidationTestCase(TestCase):\n     @override_settings(AUTH_USER_MODEL='auth.CustomUserNonListRequiredFields')\n+    @override_system_checks([check_user_model])\n     def test_required_fields_is_list(self):\n-        \"REQUIRED_FIELDS should be a list.\"\n-        new_io = StringIO()\n-        get_validation_errors(new_io, get_app('auth'))\n-        self.assertIn(\"The REQUIRED_FIELDS must be a list or tuple.\", new_io.getvalue())\n+        \"\"\" REQUIRED_FIELDS should be a list. \"\"\"\n+\n+        from .test_custom_user import CustomUserNonListRequiredFields\n+        errors = checks.run_checks()\n+        expected = [\n+            checks.Error(\n+                'The REQUIRED_FIELDS must be a list or tuple.',\n+                hint=None,\n+                obj=CustomUserNonListRequiredFields,\n+                id='auth.E001',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n \n     @override_settings(AUTH_USER_MODEL='auth.CustomUserBadRequiredFields')\n+    @override_system_checks([check_user_model])\n     def test_username_not_in_required_fields(self):\n-        \"USERNAME_FIELD should not appear in REQUIRED_FIELDS.\"\n-        new_io = StringIO()\n-        get_validation_errors(new_io, get_app('auth'))\n-        self.assertIn(\"The field named as the USERNAME_FIELD should not be included in REQUIRED_FIELDS on a swappable User model.\", new_io.getvalue())\n+        \"\"\" USERNAME_FIELD should not appear in REQUIRED_FIELDS. \"\"\"\n+\n+        from .test_custom_user import CustomUserBadRequiredFields\n+        errors = checks.run_checks()\n+        expected = [\n+            checks.Error(\n+                'The field named as the USERNAME_FIELD must not be included '\n+                    'in REQUIRED_FIELDS on a custom user model.',\n+                hint=None,\n+                obj=CustomUserBadRequiredFields,\n+                id='auth.E002',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n \n     @override_settings(AUTH_USER_MODEL='auth.CustomUserNonUniqueUsername')\n+    @override_system_checks([check_user_model])\n     def test_username_non_unique(self):\n-        \"A non-unique USERNAME_FIELD should raise a model validation error.\"\n-        new_io = StringIO()\n-        get_validation_errors(new_io, get_app('auth'))\n-        self.assertIn(\"The USERNAME_FIELD must be unique. Add unique=True to the field parameters.\", new_io.getvalue())\n+        \"\"\" A non-unique USERNAME_FIELD should raise an error. \"\"\"\n+\n+        from .test_custom_user import CustomUserNonUniqueUsername\n+        errors = checks.run_checks()\n+        expected = [\n+            checks.Error(\n+                'The CustomUserNonUniqueUsername.username field must be '\n+                    'unique because it is pointed to by USERNAME_FIELD.',\n+                hint=None,\n+                obj=CustomUserNonUniqueUsername,\n+                id='auth.E003',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    @override_settings(AUTH_USER_MODEL='auth.CustomUserNonUniqueUsername',\n+                       AUTHENTICATION_BACKENDS=[\n+                           'my.custom.backend',\n+                       ])\n+    @override_system_checks([check_user_model])\n+    def test_username_non_unique_with_custom_backend(self):\n+        \"\"\" A non-unique USERNAME_FIELD should raise an error only if we use the\n+        default authentication backend. Otherwise, an warning should be raised.\n+        \"\"\"\n+\n+        from .test_custom_user import CustomUserNonUniqueUsername\n+        errors = checks.run_checks()\n+        expected = [\n+            checks.Warning(\n+                'The CustomUserNonUniqueUsername.username field is pointed to '\n+                    'by USERNAME_FIELD, but it is not unique.',\n+                hint='Ensure that your authentication backend can handle '\n+                    'non-unique usernames.',\n+                obj=CustomUserNonUniqueUsername,\n+                id='auth.W004',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n \n \n class PermissionTestCase(TestCase):\ndiff --git a/django/contrib/contenttypes/__init__.py b/django/contrib/contenttypes/__init__.py\nindex e69de29bb2d1..0e47d28912b8 100644\n--- a/django/contrib/contenttypes/__init__.py\n+++ b/django/contrib/contenttypes/__init__.py\n@@ -0,0 +1,4 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+import django.contrib.contenttypes.checks\ndiff --git a/django/contrib/contenttypes/checks.py b/django/contrib/contenttypes/checks.py\nnew file mode 100644\nindex 000000000000..78454510aa5a\n--- /dev/null\n+++ b/django/contrib/contenttypes/checks.py\n@@ -0,0 +1,19 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from django.core import checks\n+\n+\n+@checks.register('models')\n+def check_generic_foreign_keys(**kwargs):\n+    from .generic import GenericForeignKey\n+    from django.db import models\n+\n+    errors = []\n+    fields = (obj\n+        for cls in models.get_models()\n+        for obj in vars(cls).itervalues()\n+        if isinstance(obj, GenericForeignKey))\n+    for field in fields:\n+        errors.extend(field.check())\n+    return errors\ndiff --git a/django/contrib/contenttypes/generic.py b/django/contrib/contenttypes/generic.py\nindex 51eed3f28bfb..b8b07555704f 100644\n--- a/django/contrib/contenttypes/generic.py\n+++ b/django/contrib/contenttypes/generic.py\n@@ -6,10 +6,12 @@\n from collections import defaultdict\n from functools import partial\n \n+from django.core import checks\n from django.core.exceptions import ObjectDoesNotExist\n from django.db import connection\n from django.db import models, router, DEFAULT_DB_ALIAS\n-from django.db.models import signals\n+from django.db.models import signals, FieldDoesNotExist\n+from django.db.models.base import ModelBase\n from django.db.models.fields.related import ForeignObject, ForeignObjectRel\n from django.db.models.related import PathInfo\n from django.db.models.sql.where import Constraint\n@@ -20,7 +22,7 @@\n from django.contrib.contenttypes.models import ContentType\n from django.utils import six\n from django.utils.deprecation import RenameMethodsBase\n-from django.utils.encoding import smart_text\n+from django.utils.encoding import smart_text, python_2_unicode_compatible\n \n \n class RenameGenericForeignKeyMethods(RenameMethodsBase):\n@@ -29,6 +31,7 @@ class RenameGenericForeignKeyMethods(RenameMethodsBase):\n     )\n \n \n+@python_2_unicode_compatible\n class GenericForeignKey(six.with_metaclass(RenameGenericForeignKeyMethods)):\n     \"\"\"\n     Provides a generic relation to any object through content-type/object-id\n@@ -150,6 +153,54 @@ def __set__(self, instance, value):\n         setattr(instance, self.fk_field, fk)\n         setattr(instance, self.cache_attr, value)\n \n+    def __str__(self):\n+        model = self.model\n+        app = model._meta.app_label\n+        return '%s.%s.%s' % (app, model._meta.object_name, self.name)\n+\n+    def check(self, **kwargs):\n+        errors = []\n+        errors.extend(self._check_content_type_field())\n+        errors.extend(self._check_object_id_field())\n+        errors.extend(self._check_field_name())\n+        return errors\n+\n+    def _check_content_type_field(self):\n+        return _check_content_type_field(\n+            model=self.model,\n+            field_name=self.ct_field,\n+            checked_object=self)\n+\n+    def _check_object_id_field(self):\n+        try:\n+            self.model._meta.get_field(self.fk_field)\n+        except FieldDoesNotExist:\n+            return [\n+                checks.Error(\n+                    'The field refers to \"%s\" field which is missing.'\n+                        % self.fk_field,\n+                    hint=None,\n+                    obj=self,\n+                    id='contenttypes.E001',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def _check_field_name(self):\n+        if self.name.endswith(\"_\"):\n+            return [\n+                checks.Error(\n+                    'Field names must not end with underscores.',\n+                    hint=None,\n+                    obj=self,\n+                    id='contenttypes.E002',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+\n class GenericRelation(ForeignObject):\n     \"\"\"Provides an accessor to generic related objects (e.g. comments)\"\"\"\n \n@@ -243,6 +294,114 @@ def bulk_related_objects(self, objs, using=DEFAULT_DB_ALIAS):\n                     [obj.pk for obj in objs]\n                 })\n \n+    def check(self, **kwargs):\n+        errors = super(GenericRelation, self).check(**kwargs)\n+        errors.extend(self._check_content_type_field())\n+        errors.extend(self._check_object_id_field())\n+        errors.extend(self._check_generic_foreign_key_existence())\n+        return errors\n+\n+    def _check_content_type_field(self):\n+        target = self.rel.to\n+        if isinstance(target, ModelBase):\n+            return _check_content_type_field(\n+                model=target,\n+                field_name=self.content_type_field_name,\n+                checked_object=self)\n+        else:\n+            return []\n+\n+    def _check_object_id_field(self):\n+        target = self.rel.to\n+        if isinstance(target, ModelBase):\n+            opts = target._meta\n+            try:\n+                opts.get_field(self.object_id_field_name)\n+            except FieldDoesNotExist:\n+                return [\n+                    checks.Error(\n+                        'The field refers to %s.%s field which is missing.'\n+                            % (opts.object_name, self.object_id_field_name),\n+                        hint=None,\n+                        obj=self,\n+                        id='contenttypes.E003',\n+                    )\n+                ]\n+            else:\n+                return []\n+        else:\n+            return []\n+\n+    def _check_generic_foreign_key_existence(self):\n+        target = self.rel.to\n+        if isinstance(target, ModelBase):\n+            # Using `vars` is very ugly approach, but there is no better one,\n+            # because GenericForeignKeys are not considered as fields and,\n+            # therefore, are not included in `target._meta.local_fields`.\n+            fields = target._meta.virtual_fields\n+            if any(isinstance(field, GenericForeignKey) and\n+                    field.ct_field == self.content_type_field_name and\n+                    field.fk_field == self.object_id_field_name\n+                    for field in fields):\n+                return []\n+            else:\n+                return [\n+                    checks.Warning(\n+                        'The field defines a generic relation with the model '\n+                            '%s.%s, but the model lacks GenericForeignKey.'\n+                            % (target._meta.app_label, target._meta.object_name),\n+                        hint=None,\n+                        obj=self,\n+                        id='contenttypes.E004',\n+                    )\n+                ]\n+        else:\n+            return []\n+\n+\n+def _check_content_type_field(model, field_name, checked_object):\n+    \"\"\" Check if field named `field_name` in model `model` exists and is\n+    valid content_type field (is a ForeignKey to ContentType). \"\"\"\n+\n+    try:\n+        field = model._meta.get_field(field_name)\n+    except FieldDoesNotExist:\n+        return [\n+            checks.Error(\n+                'The field refers to %s.%s field which is missing.'\n+                    % (model._meta.object_name, field_name),\n+                hint=None,\n+                obj=checked_object,\n+                id='contenttypes.E005',\n+            )\n+        ]\n+    else:\n+        if not isinstance(field, models.ForeignKey):\n+            return [\n+                checks.Error(\n+                    '\"%s\" field is used by a %s '\n+                        'as content type field and therefore it must be '\n+                        'a ForeignKey.'\n+                        % (field_name, checked_object.__class__.__name__),\n+                    hint=None,\n+                    obj=checked_object,\n+                    id='contenttypes.E006',\n+                )\n+            ]\n+        elif field.rel.to != ContentType:\n+            return [\n+                checks.Error(\n+                    '\"%s\" field is used by a %s '\n+                        'as content type field and therefore it must be '\n+                        'a ForeignKey to ContentType.'\n+                        % (field_name, checked_object.__class__.__name__),\n+                    hint=None,\n+                    obj=checked_object,\n+                    id='contenttypes.E007',\n+                )\n+            ]\n+        else:\n+            return []\n \n class ReverseGenericRelatedObjectsDescriptor(object):\n     \"\"\"\ndiff --git a/django/contrib/gis/management/commands/ogrinspect.py b/django/contrib/gis/management/commands/ogrinspect.py\nindex 238209123e1b..0b9f16a92243 100644\n--- a/django/contrib/gis/management/commands/ogrinspect.py\n+++ b/django/contrib/gis/management/commands/ogrinspect.py\n@@ -69,7 +69,7 @@ class Command(LabelCommand):\n                     help='Generate mapping dictionary for use with `LayerMapping`.')\n         )\n \n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     def handle(self, *args, **options):\n         try:\ndiff --git a/django/contrib/sites/managers.py b/django/contrib/sites/managers.py\nindex becb35b404cb..c792423a06e9 100644\n--- a/django/contrib/sites/managers.py\n+++ b/django/contrib/sites/managers.py\n@@ -1,41 +1,66 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n from django.conf import settings\n+from django.core import checks\n from django.db import models\n from django.db.models.fields import FieldDoesNotExist\n \n+\n class CurrentSiteManager(models.Manager):\n     \"Use this to limit objects to those associated with the current site.\"\n+\n     def __init__(self, field_name=None):\n         super(CurrentSiteManager, self).__init__()\n         self.__field_name = field_name\n-        self.__is_validated = False\n-        \n-    def _validate_field_name(self):\n-        field_names = self.model._meta.get_all_field_names()\n-        \n-        # If a custom name is provided, make sure the field exists on the model\n-        if self.__field_name is not None and self.__field_name not in field_names:\n-            raise ValueError(\"%s couldn't find a field named %s in %s.\" % \\\n-                (self.__class__.__name__, self.__field_name, self.model._meta.object_name))\n-        \n-        # Otherwise, see if there is a field called either 'site' or 'sites'\n-        else:\n-            for potential_name in ['site', 'sites']:\n-                if potential_name in field_names:\n-                    self.__field_name = potential_name\n-                    self.__is_validated = True\n-                    break\n-        \n-        # Now do a type check on the field (FK or M2M only)\n+\n+    def _get_field_name(self):\n+        \"\"\" Return self.__field_name or 'site' or 'sites'. \"\"\"\n+\n+        if not self.__field_name:\n+            try:\n+                self.model._meta.get_field('site')\n+            except FieldDoesNotExist:\n+                self.__field_name = 'sites'\n+            else:\n+                self.__field_name = 'site'\n+        return self.__field_name\n+\n+    def get_queryset(self):\n+        return super(CurrentSiteManager, self).get_queryset().filter(\n+            **{self._get_field_name() + '__id__exact': settings.SITE_ID})\n+\n+    def check(self, **kwargs):\n+        errors = super(CurrentSiteManager, self).check(**kwargs)\n+        errors.extend(self._check_field_name())\n+        return errors\n+\n+    def _check_field_name(self):\n+        field_name = self._get_field_name()\n         try:\n-            field = self.model._meta.get_field(self.__field_name)\n-            if not isinstance(field, (models.ForeignKey, models.ManyToManyField)):\n-                raise TypeError(\"%s must be a ForeignKey or ManyToManyField.\" %self.__field_name)\n+            field = self.model._meta.get_field(field_name)\n         except FieldDoesNotExist:\n-            raise ValueError(\"%s couldn't find a field named %s in %s.\" % \\\n-                    (self.__class__.__name__, self.__field_name, self.model._meta.object_name))\n-        self.__is_validated = True\n-    \n-    def get_queryset(self):\n-        if not self.__is_validated:\n-            self._validate_field_name()\n-        return super(CurrentSiteManager, self).get_queryset().filter(**{self.__field_name + '__id__exact': settings.SITE_ID})\n+            return [\n+                checks.Error(\n+                    'CurrentSiteManager could not find a field named \"%s\".'\n+                        % field_name,\n+                    hint='Ensure that you did not misspell the field name. '\n+                        'Does the field exist?',\n+                    obj=self,\n+                    id='sites.E001',\n+                )\n+            ]\n+\n+        if not isinstance(field, (models.ForeignKey, models.ManyToManyField)):\n+            return [\n+                checks.Error(\n+                    '%s.%s is used by a CurrentSiteManager and must be '\n+                        'a ForeignKey or ManyToManyField.'\n+                        % (self.model._meta.object_name, field_name),\n+                    hint=None,\n+                    obj=self,\n+                    id='sites.E002',\n+                )\n+            ]\n+\n+        return []\ndiff --git a/django/contrib/staticfiles/management/commands/collectstatic.py b/django/contrib/staticfiles/management/commands/collectstatic.py\nindex c1e9fa811ba9..d0412f038f3a 100644\n--- a/django/contrib/staticfiles/management/commands/collectstatic.py\n+++ b/django/contrib/staticfiles/management/commands/collectstatic.py\n@@ -45,7 +45,7 @@ class Command(NoArgsCommand):\n                 \"'.*' and '*~'.\"),\n     )\n     help = \"Collect static files in a single location.\"\n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     def __init__(self, *args, **kwargs):\n         super(NoArgsCommand, self).__init__(*args, **kwargs)\ndiff --git a/django/core/checks/__init__.py b/django/core/checks/__init__.py\nindex e69de29bb2d1..ecb10940d403 100644\n--- a/django/core/checks/__init__.py\n+++ b/django/core/checks/__init__.py\n@@ -0,0 +1,9 @@\n+# -*- coding: utf8 -*-\n+from __future__ import unicode_literals\n+\n+from .messages import (CheckMessage,\n+        Debug, Info, Warning, Error, Critical,\n+        DEBUG, INFO, WARNING, ERROR, CRITICAL)\n+from .registration import register, run_checks, tag_exists\n+import django.core.checks.compatibility.django_1_6_0\n+import django.core.checks.model_checks\ndiff --git a/django/core/checks/compatibility/base.py b/django/core/checks/compatibility/base.py\ndeleted file mode 100644\nindex 7fe52d2af965..000000000000\n--- a/django/core/checks/compatibility/base.py\n+++ /dev/null\n@@ -1,39 +0,0 @@\n-from __future__ import unicode_literals\n-import warnings\n-\n-from django.core.checks.compatibility import django_1_6_0\n-\n-\n-COMPAT_CHECKS = [\n-    # Add new modules at the top, so we keep things in descending order.\n-    # After two-three minor releases, old versions should get dropped.\n-    django_1_6_0,\n-]\n-\n-\n-def check_compatibility():\n-    \"\"\"\n-    Runs through compatibility checks to warn the user with an existing install\n-    about changes in an up-to-date Django.\n-\n-    Modules should be located in ``django.core.compat_checks`` (typically one\n-    per release of Django) & must have a ``run_checks`` function that runs\n-    all the checks.\n-\n-    Returns a list of informational messages about incompatibilities.\n-    \"\"\"\n-    messages = []\n-\n-    for check_module in COMPAT_CHECKS:\n-        check = getattr(check_module, 'run_checks', None)\n-\n-        if check is None:\n-            warnings.warn(\n-                \"The '%s' module lacks a \" % check_module.__name__ +\n-                \"'run_checks' method, which is needed to verify compatibility.\"\n-            )\n-            continue\n-\n-        messages.extend(check())\n-\n-    return messages\ndiff --git a/django/core/checks/compatibility/django_1_6_0.py b/django/core/checks/compatibility/django_1_6_0.py\nindex 96b29d6b77d9..098ee6091b2c 100644\n--- a/django/core/checks/compatibility/django_1_6_0.py\n+++ b/django/core/checks/compatibility/django_1_6_0.py\n@@ -1,62 +1,67 @@\n+# -*- encoding: utf-8 -*-\n from __future__ import unicode_literals\n \n-from django.db import models\n+from .. import Warning, register\n \n-def check_test_runner():\n-    \"\"\"\n-    Checks if the user has *not* overridden the ``TEST_RUNNER`` setting &\n-    warns them about the default behavior changes.\n \n-    If the user has overridden that setting, we presume they know what they're\n-    doing & avoid generating a message.\n-    \"\"\"\n+@register('compatibility')\n+def check_1_6_compatibility(**kwargs):\n+    errors = []\n+    errors.extend(_check_test_runner(**kwargs))\n+    errors.extend(_check_boolean_field_default_value(**kwargs))\n+    return errors\n+\n+\n+def _check_test_runner(apps=None, **kwargs):\n+    \"\"\" Warn an user if the user has *not* set explicitly the ``TEST_RUNNER``\n+    setting. \"\"\"\n+\n+    if apps is not None:\n+        return []\n+\n     from django.conf import settings\n-    new_default = 'django.test.runner.DiscoverRunner'\n-    test_runner_setting = getattr(settings, 'TEST_RUNNER', new_default)\n-\n-    if test_runner_setting == new_default:\n-        message = [\n-            \"Django 1.6 introduced a new default test runner ('%s')\" % new_default,\n-            \"You should ensure your tests are all running & behaving as expected. See\",\n-            \"https://docs.djangoproject.com/en/dev/releases/1.6/#discovery-of-tests-in-any-test-module\",\n-            \"for more information.\",\n+\n+    if not settings.is_overridden(\"TEST_RUNNER\"):\n+        return [\n+            Warning(\n+                'You have not explicitly set \"TEST_RUNNER\". In Django 1.6, '\n+                    'there is a new test runner (\"django.test.runner.DiscoverRunner\") '\n+                    'by default. You should ensure your tests are still all '\n+                    'running & behaving as expected. See '\n+                    'https://docs.djangoproject.com/en/dev/releases/1.6/#discovery-of-tests-in-any-test-module '\n+                    'for more information.',\n+                hint=None,\n+                obj=None,\n+                id='W047',\n+            )\n         ]\n-        return ' '.join(message)\n+    else:\n+        return []\n+\n \n-def check_boolean_field_default_value():\n+def _check_boolean_field_default_value(apps=None, **kwargs):\n     \"\"\"\n     Checks if there are any BooleanFields without a default value, &\n     warns the user that the default has changed from False to Null.\n     \"\"\"\n-    fields = []\n-    for cls in models.get_models():\n-        opts = cls._meta\n-        for f in opts.local_fields:\n-            if isinstance(f, models.BooleanField) and not f.has_default():\n-                fields.append(\n-                    '%s.%s: \"%s\"' % (opts.app_label, opts.object_name, f.name)\n-                )\n-    if fields:\n-        fieldnames = \", \".join(fields)\n-        message = [\n-            \"You have not set a default value for one or more BooleanFields:\",\n-            \"%s.\" % fieldnames,\n-            \"In Django 1.6 the default value of BooleanField was changed from\",\n-            \"False to Null when Field.default isn't defined. See\",\n-            \"https://docs.djangoproject.com/en/1.6/ref/models/fields/#booleanfield\"\n-            \"for more information.\"\n-        ]\n-        return ' '.join(message)\n \n+    from django.db import models\n \n-def run_checks():\n-    \"\"\"\n-    Required by the ``check`` management command, this returns a list of\n-    messages from all the relevant check functions for this version of Django.\n-    \"\"\"\n-    checks = [\n-        check_test_runner(),\n-        check_boolean_field_default_value(),\n-    ]\n-    # Filter out the ``None`` or empty strings.\n-    return [output for output in checks if output]\n+    invalid_fields = [field\n+        for model in models.get_models(**kwargs)\n+        if apps is None or model._meta.app_label in apps\n+        for field in model._meta.local_fields\n+        if isinstance(field, models.BooleanField) and not field.has_default()]\n+\n+    return [\n+        Warning(\n+            'The field has not set a default value. In Django 1.6 '\n+                'the default value of BooleanField was changed from '\n+                'False to Null when Field.default is not defined. '\n+                'See https://docs.djangoproject.com/en/1.6/ref/models/fields/#booleanfield '\n+                'for more information.',\n+            hint=None,\n+            obj=field,\n+            id='W048',\n+        )\n+        for field in invalid_fields]\ndiff --git a/django/core/checks/messages.py b/django/core/checks/messages.py\nnew file mode 100644\nindex 000000000000..c3a4428a7b18\n--- /dev/null\n+++ b/django/core/checks/messages.py\n@@ -0,0 +1,86 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from functools import partial\n+\n+from django.utils.encoding import python_2_unicode_compatible, force_str\n+\n+\n+# Levels\n+DEBUG = 10\n+INFO = 20\n+WARNING = 30\n+ERROR = 40\n+CRITICAL = 50\n+\n+\n+@python_2_unicode_compatible\n+class CheckMessage(object):\n+\n+    def __init__(self, level, msg, hint, obj=None, id=None):\n+        assert isinstance(level, int), \"The first argument should be level.\"\n+        self.level = level\n+        self.msg = msg\n+        self.hint = hint\n+        self.obj = obj\n+        self.id = id\n+\n+    def __eq__(self, other):\n+        return all(getattr(self, attr) == getattr(other, attr)\n+                   for attr in ['level', 'msg', 'hint', 'obj', 'id'])\n+\n+    def __ne__(self, other):\n+        return not (self == other)\n+\n+    def __str__(self):\n+        from django.db import models\n+\n+        if self.obj is None:\n+            obj = \"?\"\n+        elif isinstance(self.obj, models.base.ModelBase):\n+            # We need to hardcode ModelBase and Field cases because its __str__\n+            # method doesn't return \"applabel.modellabel\" and cannot be changed.\n+            model = self.obj\n+            app = model._meta.app_label\n+            obj = '%s.%s' % (app, model._meta.object_name)\n+        else:\n+            obj = force_str(self.obj)\n+        id = \"(%s) \" % self.id if self.id else \"\"\n+        hint = \"\\n\\tHINT: %s\" % self.hint if self.hint else ''\n+        return \"%s: %s%s%s\" % (obj, id, self.msg, hint)\n+\n+    def __repr__(self):\n+        return \"<%s: level=%r, msg=%r, hint=%r, obj=%r, id=%r>\" % \\\n+            (self.__class__.__name__, self.level, self.msg, self.hint, self.obj, self.id)\n+\n+    def is_serious(self):\n+        return self.level >= ERROR\n+\n+    def is_silenced(self):\n+        from django.conf import settings\n+        return self.id in settings.SILENCED_SYSTEM_CHECKS\n+\n+\n+class Debug(CheckMessage):\n+    def __init__(self, *args, **kwargs):\n+        return super(Debug, self).__init__(DEBUG, *args, **kwargs)\n+\n+\n+class Info(CheckMessage):\n+    def __init__(self, *args, **kwargs):\n+        return super(Info, self).__init__(INFO, *args, **kwargs)\n+\n+\n+class Warning(CheckMessage):\n+    def __init__(self, *args, **kwargs):\n+        return super(Warning, self).__init__(WARNING, *args, **kwargs)\n+\n+\n+class Error(CheckMessage):\n+    def __init__(self, *args, **kwargs):\n+        return super(Error, self).__init__(ERROR, *args, **kwargs)\n+\n+\n+class Critical(CheckMessage):\n+    def __init__(self, *args, **kwargs):\n+        return super(Critical, self).__init__(CRITICAL, *args, **kwargs)\ndiff --git a/django/core/checks/model_checks.py b/django/core/checks/model_checks.py\nnew file mode 100644\nindex 000000000000..8f55da8b4daa\n--- /dev/null\n+++ b/django/core/checks/model_checks.py\n@@ -0,0 +1,16 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from itertools import chain\n+\n+from . import Warning, register\n+\n+\n+@register('models')\n+def check_all_models(apps=None, **kwargs):\n+    from django.db import models\n+\n+    errors = [model.check(**kwargs)\n+        for model in models.get_models(**kwargs)\n+        if apps is None or model._meta.app_label in apps]\n+    return list(chain(*errors))\ndiff --git a/django/core/checks/registration.py b/django/core/checks/registration.py\nnew file mode 100644\nindex 000000000000..f053e5b74c40\n--- /dev/null\n+++ b/django/core/checks/registration.py\n@@ -0,0 +1,63 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from itertools import chain\n+\n+from django.utils.itercompat import is_iterable\n+\n+\n+class CheckFramework(object):\n+\n+    def __init__(self):\n+        self.registered_checks = []\n+\n+    def register(self, *tags):\n+        \"\"\"\n+        Decorator. Register given function `f` labeled with given `tags`. The\n+        function should receive **kwargs and return list of Errors and\n+        Warnings.\n+\n+        Example::\n+\n+            framework = CheckFramework()\n+            @framework.register('mytag', 'anothertag')\n+            def my_check(apps, **kwargs):\n+                # ... perform checks and collect `errors` ...\n+                return errors\n+\n+        \"\"\"\n+\n+        def inner(f):\n+            f.tags = tags\n+            self.registered_checks.append(f)\n+            return f\n+\n+        return inner\n+\n+    def run_checks(self, apps=None, tags=None):\n+        \"\"\" Run all registered checks and return list of Errors and Warnings.\n+        \"\"\"\n+        errors = []\n+        if tags is not None:\n+            checks = [check for check in self.registered_checks\n+                      if hasattr(check, 'tags') and set(check.tags) & set(tags)]\n+        else:\n+            checks = self.registered_checks\n+\n+        for f in checks:\n+            new_errors = f(apps=apps)\n+            assert is_iterable(new_errors), (\n+                \"The function %r did not return a list. All functions registered \"\n+                \"in checking framework must return a list.\" % f)\n+            errors.extend(new_errors)\n+        return errors\n+\n+    def tag_exists(self, tag):\n+        tags = chain(*[check.tags for check in self.registered_checks if hasattr(check, 'tags')])\n+        return tag in tags\n+\n+\n+framework = CheckFramework()\n+register = framework.register\n+run_checks = framework.run_checks\n+tag_exists = framework.tag_exists\ndiff --git a/django/core/management/base.py b/django/core/management/base.py\nindex 1aba53dd0148..e214ef2aac4b 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -1,3 +1,6 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n \"\"\"\n Base classes for writing management commands (named commands which can\n be executed through ``django-admin.py`` or ``manage.py``).\n@@ -5,14 +8,15 @@\n \"\"\"\n import os\n import sys\n+import warnings\n \n from optparse import make_option, OptionParser\n \n import django\n+from django.core import checks\n from django.core.exceptions import ImproperlyConfigured\n from django.core.management.color import color_style, no_style\n from django.utils.encoding import force_str\n-from django.utils.six import StringIO\n \n \n class CommandError(Exception):\n@@ -134,13 +138,18 @@ class BaseCommand(object):\n         wrapped with ``BEGIN;`` and ``COMMIT;``. Default value is\n         ``False``.\n \n+    ``requires_system_checks``\n+        A boolean; if ``True``, entire Django project will be checked for errors\n+        prior to executing the command. If it's missing, the value of\n+        ``requires_model_validation`` is used. If the latter flag is missing\n+        too, the default value (``True``) is used. Defining both\n+        ``requires_system_checks`` and ``requires_model_validation`` results in\n+        an error.\n+\n     ``requires_model_validation``\n-        A boolean; if ``True``, validation of installed models will be\n-        performed prior to executing the command. Default value is\n-        ``True``. To validate an individual application's models\n-        rather than all applications' models, call\n-        ``self.validate(app)`` from ``handle()``, where ``app`` is the\n-        application's Python module.\n+        A deprecated boolean. If ``requires_system_checks`` is missing, then\n+        this value is used. Defining both ``requires_system_checks`` and\n+        ``requires_model_validation`` results in an error.\n \n     ``leave_locale_alone``\n         A boolean indicating whether the locale set in settings should be\n@@ -179,13 +188,40 @@ class BaseCommand(object):\n \n     # Configuration shortcuts that alter various logic.\n     can_import_settings = True\n-    requires_model_validation = True\n     output_transaction = False  # Whether to wrap the output in a \"BEGIN; COMMIT;\"\n     leave_locale_alone = False\n \n+    # Uncomment the following line of code after deprecation plan for\n+    # requires_model_validation comes to completion:\n+    #\n+    # requires_system_checks = True\n+\n     def __init__(self):\n         self.style = color_style()\n \n+        # `requires_model_validation` is deprecated in favour of\n+        # `requires_system_checks`. If both options are present, an error is\n+        # raised. Otherwise the present option is used. If none of them is\n+        # defined, the default value (True) is used.\n+        has_old_option = hasattr(self, 'requires_model_validation')\n+        has_new_option = hasattr(self, 'requires_system_checks')\n+\n+        if has_old_option:\n+            warnings.warn(\n+                '\"requires_model_validation\" is deprecated '\n+                'in favour of \"requires_system_checks\".',\n+                PendingDeprecationWarning)\n+        if has_old_option and has_new_option:\n+            raise ImproperlyConfigured(\n+                'Command %s defines both \"requires_model_validation\" '\n+                'and \"requires_system_checks\", which is illegal. Use only '\n+                '\"requires_system_checks\".' % self.__class__.__name__)\n+\n+        self.requires_system_checks = (\n+            self.requires_system_checks if has_new_option else\n+            self.requires_model_validation if has_old_option else\n+            True)\n+\n     def get_version(self):\n         \"\"\"\n         Return the Django version, which should be correct for all\n@@ -251,8 +287,8 @@ def run_from_argv(self, argv):\n \n     def execute(self, *args, **options):\n         \"\"\"\n-        Try to execute this command, performing model validation if\n-        needed (as controlled by the attribute\n+        Try to execute this command, performing system checks if needed (as\n+        controlled by attributes ``self.requires_system_checks`` and\n         ``self.requires_model_validation``, except if force-skipped).\n         \"\"\"\n         self.stdout = OutputWrapper(options.get('stdout', sys.stdout))\n@@ -284,8 +320,10 @@ def execute(self, *args, **options):\n             translation.activate('en-us')\n \n         try:\n-            if self.requires_model_validation and not options.get('skip_validation'):\n-                self.validate()\n+            if (self.requires_system_checks and\n+                    not options.get('skip_validation') and  # This will be removed at the end of deprecation proccess for `skip_validation`.\n+                    not options.get('skip_checks')):\n+                self.check()\n             output = self.handle(*args, **options)\n             if output:\n                 if self.output_transaction:\n@@ -303,21 +341,63 @@ def execute(self, *args, **options):\n                 translation.activate(saved_locale)\n \n     def validate(self, app=None, display_num_errors=False):\n-        \"\"\"\n-        Validates the given app, raising CommandError for any errors.\n+        \"\"\" Deprecated. Delegates to ``check``. ``app`` argument is ignored. \"\"\"\n \n-        If app is None, then this will validate all installed apps.\n+        return self.check(display_num_errors)\n \n+    def check(self, apps=None, tags=None, display_num_errors=False):\n         \"\"\"\n-        from django.core.management.validation import get_validation_errors\n-        s = StringIO()\n-        num_errors = get_validation_errors(s, app)\n-        if num_errors:\n-            s.seek(0)\n-            error_text = s.read()\n-            raise CommandError(\"One or more models did not validate:\\n%s\" % error_text)\n+        Uses the system check framework to validate entire Django project.\n+        Raises CommandError for any serious message (error or critical errors).\n+        If there are only light messages (like warnings), they are printed to\n+        stderr and no exception is raised.\n+\n+        \"\"\"\n+\n+        all_issues = checks.run_checks(apps=apps, tags=tags)\n+\n+        msg = \"\"\n+        if all_issues:\n+            debugs = [e for e in all_issues if e.level < checks.INFO and not e.is_silenced()]\n+            infos = [e for e in all_issues if checks.INFO <= e.level < checks.WARNING and not e.is_silenced()]\n+            warnings = [e for e in all_issues if checks.WARNING <= e.level < checks.ERROR and not e.is_silenced()]\n+            errors = [e for e in all_issues if checks.ERROR <= e.level < checks.CRITICAL]\n+            criticals = [e for e in all_issues if checks.CRITICAL <= e.level]\n+            sorted_issues = [\n+                (criticals, 'CRITICALS'),\n+                (errors, 'ERRORS'),\n+                (warnings, 'WARNINGS'),\n+                (infos, 'INFOS'),\n+                (debugs, 'DEBUGS'),\n+            ]\n+\n+            for issues, group_name in sorted_issues:\n+                if issues:\n+                    formatted = (\n+                        color_style().ERROR(force_str(e))\n+                        if e.is_serious()\n+                        else color_style().WARNING(force_str(e))\n+                        for e in issues)\n+                    formatted = \"\\n\".join(sorted(formatted))\n+                    msg += '\\n%s:\\n%s\\n' % (group_name, formatted)\n+\n+            msg = \"There are some issues:\\n%s\" % msg\n+\n         if display_num_errors:\n-            self.stdout.write(\"%s error%s found\" % (num_errors, '' if num_errors == 1 else 's'))\n+            if msg:\n+                msg += '\\n'\n+            msg += \"System check identified %s.\" % (\n+                \"no problems\" if len(all_issues) == 0 else\n+                \"1 issue\" if len(all_issues) == 1 else\n+                \"%s issues\" % len(all_issues)\n+            )\n+\n+        if any(e.is_serious() and not e.is_silenced() for e in all_issues):\n+            raise CommandError(msg)\n+        elif msg and all_issues:\n+            self.stderr.write(msg)\n+        elif msg:\n+            self.stdout.write(msg)\n \n     def handle(self, *args, **options):\n         \"\"\"\ndiff --git a/django/core/management/commands/check.py b/django/core/management/commands/check.py\nindex 05f48c82bc48..9d181dc20aee 100644\n--- a/django/core/management/commands/check.py\n+++ b/django/core/management/commands/check.py\n@@ -1,14 +1,26 @@\n+# -*- coding: utf-8 -*-\n from __future__ import unicode_literals\n-import warnings\n \n-from django.core.checks.compatibility.base import check_compatibility\n-from django.core.management.base import NoArgsCommand\n+from optparse import make_option\n \n+from django.core import checks\n+from django.core.management.base import BaseCommand, CommandError\n \n-class Command(NoArgsCommand):\n-    help = \"Checks your configuration's compatibility with this version \" + \\\n-           \"of Django.\"\n \n-    def handle_noargs(self, **options):\n-        for message in check_compatibility():\n-            warnings.warn(message)\n+class Command(BaseCommand):\n+    help = \"Uses the system check framework to validate entire Django project.\"\n+\n+    requires_system_checks = False\n+\n+    option_list = BaseCommand.option_list + (\n+        make_option('--tag', '-t', action='append', dest='tags',\n+            help='Run only checks labeled with given tag.'),\n+    )\n+\n+    def handle(self, *apps, **options):\n+        apps = apps or None  # If apps is an empty list, replace with None\n+        tags = options.get('tags', None)\n+        if tags and any(not checks.tag_exists(tag) for tag in tags):\n+            invalid_tag = next(tag for tag in tags if not checks.tag_exists(tag))\n+            raise CommandError('There is no system check labeled with \"%s\" tag.' % invalid_tag)\n+        self.check(apps=apps, tags=tags, display_num_errors=True)\ndiff --git a/django/core/management/commands/compilemessages.py b/django/core/management/commands/compilemessages.py\nindex cb4149200412..16c6499c525a 100644\n--- a/django/core/management/commands/compilemessages.py\n+++ b/django/core/management/commands/compilemessages.py\n@@ -63,7 +63,7 @@ class Command(BaseCommand):\n     )\n     help = 'Compiles .po files to .mo files for use with builtin gettext support.'\n \n-    requires_model_validation = False\n+    requires_system_checks = False\n     leave_locale_alone = True\n \n     def handle(self, **options):\ndiff --git a/django/core/management/commands/createcachetable.py b/django/core/management/commands/createcachetable.py\nindex 27668f272d29..d945c95fe252 100644\n--- a/django/core/management/commands/createcachetable.py\n+++ b/django/core/management/commands/createcachetable.py\n@@ -19,7 +19,7 @@ class Command(LabelCommand):\n                 'Defaults to the \"default\" database.'),\n     )\n \n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     def handle_label(self, tablename, **options):\n         db = options.get('database')\ndiff --git a/django/core/management/commands/dbshell.py b/django/core/management/commands/dbshell.py\nindex 74659208d4fb..20047fb78f8a 100644\n--- a/django/core/management/commands/dbshell.py\n+++ b/django/core/management/commands/dbshell.py\n@@ -13,7 +13,7 @@ class Command(BaseCommand):\n                 'open a shell.  Defaults to the \"default\" database.'),\n     )\n \n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     def handle(self, **options):\n         connection = connections[options.get('database')]\ndiff --git a/django/core/management/commands/diffsettings.py b/django/core/management/commands/diffsettings.py\nindex 9e70e9ad8fdf..3155e6e648cd 100644\n--- a/django/core/management/commands/diffsettings.py\n+++ b/django/core/management/commands/diffsettings.py\n@@ -17,7 +17,7 @@ class Command(NoArgsCommand):\n                          'Default values are prefixed by \"###\".'),\n     )\n \n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     def handle_noargs(self, **options):\n         # Inspired by Postfix's \"postconf -n\".\ndiff --git a/django/core/management/commands/inspectdb.py b/django/core/management/commands/inspectdb.py\nindex 89549dc3c1bd..af560ae6e774 100644\n--- a/django/core/management/commands/inspectdb.py\n+++ b/django/core/management/commands/inspectdb.py\n@@ -18,7 +18,7 @@ class Command(NoArgsCommand):\n                 'introspect.  Defaults to using the \"default\" database.'),\n     )\n \n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     db_module = 'django.db'\n \ndiff --git a/django/core/management/commands/makemessages.py b/django/core/management/commands/makemessages.py\nindex 7ad1a8f3aacd..91629541856b 100644\n--- a/django/core/management/commands/makemessages.py\n+++ b/django/core/management/commands/makemessages.py\n@@ -195,7 +195,7 @@ class Command(NoArgsCommand):\n \"applications) directory.\\n\\nYou must run this command with one of either the \"\n \"--locale or --all options.\")\n \n-    requires_model_validation = False\n+    requires_system_checks = False\n     leave_locale_alone = True\n \n     def handle_noargs(self, *args, **options):\ndiff --git a/django/core/management/commands/runserver.py b/django/core/management/commands/runserver.py\nindex 402b3d342c1f..80fc5196e540 100644\n--- a/django/core/management/commands/runserver.py\n+++ b/django/core/management/commands/runserver.py\n@@ -32,7 +32,7 @@ class Command(BaseCommand):\n     args = '[optional port number, or ipaddr:port]'\n \n     # Validation is called explicitly each time the server is reloaded.\n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     def get_handler(self, *args, **options):\n         \"\"\"\n@@ -94,8 +94,8 @@ def inner_run(self, *args, **options):\n         shutdown_message = options.get('shutdown_message', '')\n         quit_command = 'CTRL-BREAK' if sys.platform == 'win32' else 'CONTROL-C'\n \n-        self.stdout.write(\"Validating models...\\n\\n\")\n-        self.validate(display_num_errors=True)\n+        self.stdout.write(\"Performing system checks...\\n\\n\")\n+        self.check(display_num_errors=True)\n         self.stdout.write((\n             \"%(started_at)s\\n\"\n             \"Django version %(version)s, using settings %(settings)r\\n\"\ndiff --git a/django/core/management/commands/shell.py b/django/core/management/commands/shell.py\nindex 00a6602c0bb7..0edc0e2826ef 100644\n--- a/django/core/management/commands/shell.py\n+++ b/django/core/management/commands/shell.py\n@@ -17,7 +17,7 @@ class Command(NoArgsCommand):\n \n     )\n     help = \"Runs a Python interactive interpreter. Tries to use IPython or bpython, if one of them is available.\"\n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     def _ipython_pre_011(self):\n         \"\"\"Start IPython pre-0.11\"\"\"\ndiff --git a/django/core/management/commands/test.py b/django/core/management/commands/test.py\nindex 5232c376467c..36dca9c27bee 100644\n--- a/django/core/management/commands/test.py\n+++ b/django/core/management/commands/test.py\n@@ -30,7 +30,7 @@ class Command(BaseCommand):\n     help = ('Discover and run tests in the specified modules or the current directory.')\n     args = '[path.to.modulename|path.to.modulename.TestCase|path.to.modulename.TestCase.test_method]...'\n \n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     def __init__(self):\n         self.test_runner = None\ndiff --git a/django/core/management/commands/testserver.py b/django/core/management/commands/testserver.py\nindex 97fc8ea8e1b9..b6d6da28f363 100644\n--- a/django/core/management/commands/testserver.py\n+++ b/django/core/management/commands/testserver.py\n@@ -15,7 +15,7 @@ class Command(BaseCommand):\n     help = 'Runs a development server with data from the given fixture(s).'\n     args = '[fixture ...]'\n \n-    requires_model_validation = False\n+    requires_system_checks = False\n \n     def handle(self, *fixture_labels, **options):\n         from django.core.management import call_command\ndiff --git a/django/core/management/commands/validate.py b/django/core/management/commands/validate.py\nindex 0dec3ea8b927..60fd2ce09318 100644\n--- a/django/core/management/commands/validate.py\n+++ b/django/core/management/commands/validate.py\n@@ -1,10 +1,17 @@\n-from django.core.management.base import NoArgsCommand\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n \n+import warnings\n \n-class Command(NoArgsCommand):\n-    help = \"Validates all installed models.\"\n+from django.core.management.commands.check import Command as CheckCommand\n \n-    requires_model_validation = False\n+\n+class Command(CheckCommand):\n+    help = 'Deprecated. Use \"check\" command instead. ' + CheckCommand.help\n \n     def handle_noargs(self, **options):\n-        self.validate(display_num_errors=True)\n+        warnings.warn('\"validate\" command is deprecated in favour of \"check\" '\n+            'command, which performs all system checks, including model '\n+            'validation and compatibility checks.',\n+            PendingDeprecationWarning)\n+        super(Command, self).handle_noargs(**options)\ndiff --git a/django/core/management/templates.py b/django/core/management/templates.py\nindex 164fd071e509..17a4d9cb0bcf 100644\n--- a/django/core/management/templates.py\n+++ b/django/core/management/templates.py\n@@ -52,7 +52,7 @@ class TemplateCommand(BaseCommand):\n                          'Separate multiple extensions with commas, or use '\n                          '-n multiple times.')\n         )\n-    requires_model_validation = False\n+    requires_system_checks = False\n     # Can't import settings during this command, because they haven't\n     # necessarily been created.\n     can_import_settings = False\ndiff --git a/django/core/management/validation.py b/django/core/management/validation.py\ndeleted file mode 100644\nindex 85897ee9e285..000000000000\n--- a/django/core/management/validation.py\n+++ /dev/null\n@@ -1,386 +0,0 @@\n-import collections\n-import sys\n-\n-from django.conf import settings\n-from django.core.management.color import color_style\n-from django.utils.encoding import force_str\n-from django.utils.itercompat import is_iterable\n-from django.utils import six\n-\n-\n-class ModelErrorCollection:\n-    def __init__(self, outfile=sys.stdout):\n-        self.errors = []\n-        self.outfile = outfile\n-        self.style = color_style()\n-\n-    def add(self, context, error):\n-        self.errors.append((context, error))\n-        self.outfile.write(self.style.ERROR(force_str(\"%s: %s\\n\" % (context, error))))\n-\n-\n-def get_validation_errors(outfile, app=None):\n-    \"\"\"\n-    Validates all models that are part of the specified app. If no app name is provided,\n-    validates all models of all installed apps. Writes errors, if any, to outfile.\n-    Returns number of errors.\n-    \"\"\"\n-    from django.db import models, connection\n-    from django.db.models.loading import get_app_errors\n-    from django.db.models.deletion import SET_NULL, SET_DEFAULT\n-\n-    e = ModelErrorCollection(outfile)\n-\n-    for (app_name, error) in get_app_errors().items():\n-        e.add(app_name, error)\n-\n-    for cls in models.get_models(app, include_swapped=True):\n-        opts = cls._meta\n-\n-        # Check swappable attribute.\n-        if opts.swapped:\n-            try:\n-                app_label, model_name = opts.swapped.split('.')\n-            except ValueError:\n-                e.add(opts, \"%s is not of the form 'app_label.app_name'.\" % opts.swappable)\n-                continue\n-            if not models.get_model(app_label, model_name):\n-                e.add(opts, \"Model has been swapped out for '%s' which has not been installed or is abstract.\" % opts.swapped)\n-            # No need to perform any other validation checks on a swapped model.\n-            continue\n-\n-        # If this is the current User model, check known validation problems with User models\n-        if settings.AUTH_USER_MODEL == '%s.%s' % (opts.app_label, opts.object_name):\n-            # Check that REQUIRED_FIELDS is a list\n-            if not isinstance(cls.REQUIRED_FIELDS, (list, tuple)):\n-                e.add(opts, 'The REQUIRED_FIELDS must be a list or tuple.')\n-\n-            # Check that the USERNAME FIELD isn't included in REQUIRED_FIELDS.\n-            if cls.USERNAME_FIELD in cls.REQUIRED_FIELDS:\n-                e.add(opts, 'The field named as the USERNAME_FIELD should not be included in REQUIRED_FIELDS on a swappable User model.')\n-\n-            # Check that the username field is unique\n-            if not opts.get_field(cls.USERNAME_FIELD).unique:\n-                e.add(opts, 'The USERNAME_FIELD must be unique. Add unique=True to the field parameters.')\n-\n-        # Store a list of column names which have already been used by other fields.\n-        used_column_names = []\n-\n-        # Model isn't swapped; do field-specific validation.\n-        for f in opts.local_fields:\n-            if f.name == 'id' and not f.primary_key and opts.pk.name == 'id':\n-                e.add(opts, '\"%s\": You can\\'t use \"id\" as a field name, because each model automatically gets an \"id\" field if none of the fields have primary_key=True. You need to either remove/rename your \"id\" field or add primary_key=True to a field.' % f.name)\n-            if f.name.endswith('_'):\n-                e.add(opts, '\"%s\": Field names cannot end with underscores, because this would lead to ambiguous queryset filters.' % f.name)\n-            if (f.primary_key and f.null and\n-                    not connection.features.interprets_empty_strings_as_nulls):\n-                # We cannot reliably check this for backends like Oracle which\n-                # consider NULL and '' to be equal (and thus set up\n-                # character-based fields a little differently).\n-                e.add(opts, '\"%s\": Primary key fields cannot have null=True.' % f.name)\n-\n-            # Column name validation.\n-            # Determine which column name this field wants to use.\n-            _, column_name = f.get_attname_column()\n-\n-            # Ensure the column name is not already in use.\n-            if column_name and column_name in used_column_names:\n-                e.add(opts, \"Field '%s' has column name '%s' that is already used.\" % (f.name, column_name))\n-            else:\n-                used_column_names.append(column_name)\n-\n-            if isinstance(f, models.CharField):\n-                try:\n-                    max_length = int(f.max_length)\n-                    if max_length <= 0:\n-                        e.add(opts, '\"%s\": CharFields require a \"max_length\" attribute that is a positive integer.' % f.name)\n-                except (ValueError, TypeError):\n-                    e.add(opts, '\"%s\": CharFields require a \"max_length\" attribute that is a positive integer.' % f.name)\n-            if isinstance(f, models.DecimalField):\n-                decimalp_ok, mdigits_ok = False, False\n-                decimalp_msg = '\"%s\": DecimalFields require a \"decimal_places\" attribute that is a non-negative integer.'\n-                try:\n-                    decimal_places = int(f.decimal_places)\n-                    if decimal_places < 0:\n-                        e.add(opts, decimalp_msg % f.name)\n-                    else:\n-                        decimalp_ok = True\n-                except (ValueError, TypeError):\n-                    e.add(opts, decimalp_msg % f.name)\n-                mdigits_msg = '\"%s\": DecimalFields require a \"max_digits\" attribute that is a positive integer.'\n-                try:\n-                    max_digits = int(f.max_digits)\n-                    if max_digits <= 0:\n-                        e.add(opts,  mdigits_msg % f.name)\n-                    else:\n-                        mdigits_ok = True\n-                except (ValueError, TypeError):\n-                    e.add(opts, mdigits_msg % f.name)\n-                invalid_values_msg = '\"%s\": DecimalFields require a \"max_digits\" attribute value that is greater than or equal to the value of the \"decimal_places\" attribute.'\n-                if decimalp_ok and mdigits_ok:\n-                    if decimal_places > max_digits:\n-                        e.add(opts, invalid_values_msg % f.name)\n-            if isinstance(f, models.FileField) and not f.upload_to:\n-                e.add(opts, '\"%s\": FileFields require an \"upload_to\" attribute.' % f.name)\n-            if isinstance(f, models.ImageField):\n-                try:\n-                    from django.utils.image import Image\n-                except ImportError:\n-                    e.add(opts, '\"%s\": To use ImageFields, you need to install Pillow. Get it at https://pypi.python.org/pypi/Pillow.' % f.name)\n-            if isinstance(f, models.BooleanField) and getattr(f, 'null', False):\n-                e.add(opts, '\"%s\": BooleanFields do not accept null values. Use a NullBooleanField instead.' % f.name)\n-            if isinstance(f, models.FilePathField) and not (f.allow_files or f.allow_folders):\n-                e.add(opts, '\"%s\": FilePathFields must have either allow_files or allow_folders set to True.' % f.name)\n-            if isinstance(f, models.GenericIPAddressField) and not getattr(f, 'null', False) and getattr(f, 'blank', False):\n-                e.add(opts, '\"%s\": GenericIPAddressField can not accept blank values if null values are not allowed, as blank values are stored as null.' % f.name)\n-            if f.choices:\n-                if isinstance(f.choices, six.string_types) or not is_iterable(f.choices):\n-                    e.add(opts, '\"%s\": \"choices\" should be iterable (e.g., a tuple or list).' % f.name)\n-                else:\n-                    for c in f.choices:\n-                        if isinstance(c, six.string_types) or not is_iterable(c) or len(c) != 2:\n-                            e.add(opts, '\"%s\": \"choices\" should be a sequence of two-item iterables (e.g. list of 2 item tuples).' % f.name)\n-            if f.db_index not in (None, True, False):\n-                e.add(opts, '\"%s\": \"db_index\" should be either None, True or False.' % f.name)\n-\n-            # Perform any backend-specific field validation.\n-            connection.validation.validate_field(e, opts, f)\n-\n-            # Check if the on_delete behavior is sane\n-            if f.rel and hasattr(f.rel, 'on_delete'):\n-                if f.rel.on_delete == SET_NULL and not f.null:\n-                    e.add(opts, \"'%s' specifies on_delete=SET_NULL, but cannot be null.\" % f.name)\n-                elif f.rel.on_delete == SET_DEFAULT and not f.has_default():\n-                    e.add(opts, \"'%s' specifies on_delete=SET_DEFAULT, but has no default value.\" % f.name)\n-\n-            # Check to see if the related field will clash with any existing\n-            # fields, m2m fields, m2m related objects or related objects\n-            if f.rel:\n-                if f.rel.to not in models.get_models():\n-                    # If the related model is swapped, provide a hint;\n-                    # otherwise, the model just hasn't been installed.\n-                    if not isinstance(f.rel.to, six.string_types) and f.rel.to._meta.swapped:\n-                        e.add(opts, \"'%s' defines a relation with the model '%s.%s', which has been swapped out. Update the relation to point at settings.%s.\" % (f.name, f.rel.to._meta.app_label, f.rel.to._meta.object_name, f.rel.to._meta.swappable))\n-                    else:\n-                        e.add(opts, \"'%s' has a relation with model %s, which has either not been installed or is abstract.\" % (f.name, f.rel.to))\n-                # it is a string and we could not find the model it refers to\n-                # so skip the next section\n-                if isinstance(f.rel.to, six.string_types):\n-                    continue\n-\n-                # Make sure the related field specified by a ForeignKey is unique\n-                if f.requires_unique_target:\n-                    if len(f.foreign_related_fields) > 1:\n-                        has_unique_field = False\n-                        for rel_field in f.foreign_related_fields:\n-                            has_unique_field = has_unique_field or rel_field.unique\n-                        if not has_unique_field:\n-                            e.add(opts, \"Field combination '%s' under model '%s' must have a unique=True constraint\" % (','.join(rel_field.name for rel_field in f.foreign_related_fields), f.rel.to.__name__))\n-                    else:\n-                        if not f.foreign_related_fields[0].unique:\n-                            e.add(opts, \"Field '%s' under model '%s' must have a unique=True constraint.\" % (f.foreign_related_fields[0].name, f.rel.to.__name__))\n-\n-                rel_opts = f.rel.to._meta\n-                rel_name = f.related.get_accessor_name()\n-                rel_query_name = f.related_query_name()\n-                if not f.rel.is_hidden():\n-                    for r in rel_opts.fields:\n-                        if r.name == rel_name:\n-                            e.add(opts, \"Accessor for field '%s' clashes with field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, rel_opts.object_name, r.name, f.name))\n-                        if r.name == rel_query_name:\n-                            e.add(opts, \"Reverse query name for field '%s' clashes with field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, rel_opts.object_name, r.name, f.name))\n-                    for r in rel_opts.local_many_to_many:\n-                        if r.name == rel_name:\n-                            e.add(opts, \"Accessor for field '%s' clashes with m2m field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, rel_opts.object_name, r.name, f.name))\n-                        if r.name == rel_query_name:\n-                            e.add(opts, \"Reverse query name for field '%s' clashes with m2m field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, rel_opts.object_name, r.name, f.name))\n-                    for r in rel_opts.get_all_related_many_to_many_objects():\n-                        if r.get_accessor_name() == rel_name:\n-                            e.add(opts, \"Accessor for field '%s' clashes with accessor for field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, r.model._meta.object_name, r.field.name, f.name))\n-                        if r.get_accessor_name() == rel_query_name:\n-                            e.add(opts, \"Reverse query name for field '%s' clashes with accessor for field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, r.model._meta.object_name, r.field.name, f.name))\n-                    for r in rel_opts.get_all_related_objects():\n-                        if r.field is not f:\n-                            if r.get_accessor_name() == rel_name:\n-                                e.add(opts, \"Accessor for field '%s' clashes with accessor for field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, r.model._meta.object_name, r.field.name, f.name))\n-                            if r.get_accessor_name() == rel_query_name:\n-                                e.add(opts, \"Reverse query name for field '%s' clashes with accessor for field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, r.model._meta.object_name, r.field.name, f.name))\n-\n-        seen_intermediary_signatures = []\n-        for i, f in enumerate(opts.local_many_to_many):\n-            # Check to see if the related m2m field will clash with any\n-            # existing fields, m2m fields, m2m related objects or related\n-            # objects\n-            if f.rel.to not in models.get_models():\n-                # If the related model is swapped, provide a hint;\n-                # otherwise, the model just hasn't been installed.\n-                if not isinstance(f.rel.to, six.string_types) and f.rel.to._meta.swapped:\n-                    e.add(opts, \"'%s' defines a relation with the model '%s.%s', which has been swapped out. Update the relation to point at settings.%s.\" % (f.name, f.rel.to._meta.app_label, f.rel.to._meta.object_name, f.rel.to._meta.swappable))\n-                else:\n-                    e.add(opts, \"'%s' has an m2m relation with model %s, which has either not been installed or is abstract.\" % (f.name, f.rel.to))\n-\n-                # it is a string and we could not find the model it refers to\n-                # so skip the next section\n-                if isinstance(f.rel.to, six.string_types):\n-                    continue\n-\n-            # Check that the field is not set to unique.  ManyToManyFields do not support unique.\n-            if f.unique:\n-                e.add(opts, \"ManyToManyFields cannot be unique.  Remove the unique argument on '%s'.\" % f.name)\n-\n-            if f.rel.through is not None and not isinstance(f.rel.through, six.string_types):\n-                from_model, to_model = cls, f.rel.to\n-                if from_model == to_model and f.rel.symmetrical and not f.rel.through._meta.auto_created:\n-                    e.add(opts, \"Many-to-many fields with intermediate tables cannot be symmetrical.\")\n-                seen_from, seen_to, seen_self = False, False, 0\n-                for inter_field in f.rel.through._meta.fields:\n-                    rel_to = getattr(inter_field.rel, 'to', None)\n-                    if from_model == to_model:  # relation to self\n-                        if rel_to == from_model:\n-                            seen_self += 1\n-                        if seen_self > 2:\n-                            e.add(opts, \"Intermediary model %s has more than \"\n-                                \"two foreign keys to %s, which is ambiguous \"\n-                                \"and is not permitted.\" % (\n-                                    f.rel.through._meta.object_name,\n-                                    from_model._meta.object_name\n-                                )\n-                            )\n-                    else:\n-                        if rel_to == from_model:\n-                            if seen_from:\n-                                e.add(opts, \"Intermediary model %s has more \"\n-                                    \"than one foreign key to %s, which is \"\n-                                    \"ambiguous and is not permitted.\" % (\n-                                        f.rel.through._meta.object_name,\n-                                         from_model._meta.object_name\n-                                     )\n-                                 )\n-                            else:\n-                                seen_from = True\n-                        elif rel_to == to_model:\n-                            if seen_to:\n-                                e.add(opts, \"Intermediary model %s has more \"\n-                                    \"than one foreign key to %s, which is \"\n-                                    \"ambiguous and is not permitted.\" % (\n-                                        f.rel.through._meta.object_name,\n-                                        rel_to._meta.object_name\n-                                    )\n-                                )\n-                            else:\n-                                seen_to = True\n-                if f.rel.through not in models.get_models(include_auto_created=True):\n-                    e.add(opts, \"'%s' specifies an m2m relation through model \"\n-                        \"%s, which has not been installed.\" % (f.name, f.rel.through)\n-                    )\n-                signature = (f.rel.to, cls, f.rel.through)\n-                if signature in seen_intermediary_signatures:\n-                    e.add(opts, \"The model %s has two manually-defined m2m \"\n-                        \"relations through the model %s, which is not \"\n-                        \"permitted. Please consider using an extra field on \"\n-                        \"your intermediary model instead.\" % (\n-                            cls._meta.object_name,\n-                            f.rel.through._meta.object_name\n-                        )\n-                    )\n-                else:\n-                    seen_intermediary_signatures.append(signature)\n-                if not f.rel.through._meta.auto_created:\n-                    seen_related_fk, seen_this_fk = False, False\n-                    for field in f.rel.through._meta.fields:\n-                        if field.rel:\n-                            if not seen_related_fk and field.rel.to == f.rel.to:\n-                                seen_related_fk = True\n-                            elif field.rel.to == cls:\n-                                seen_this_fk = True\n-                    if not seen_related_fk or not seen_this_fk:\n-                        e.add(opts, \"'%s' is a manually-defined m2m relation \"\n-                            \"through model %s, which does not have foreign keys \"\n-                            \"to %s and %s\" % (f.name, f.rel.through._meta.object_name,\n-                                f.rel.to._meta.object_name, cls._meta.object_name)\n-                        )\n-            elif isinstance(f.rel.through, six.string_types):\n-                e.add(opts, \"'%s' specifies an m2m relation through model %s, \"\n-                    \"which has not been installed\" % (f.name, f.rel.through)\n-                )\n-\n-            rel_opts = f.rel.to._meta\n-            rel_name = f.related.get_accessor_name()\n-            rel_query_name = f.related_query_name()\n-            # If rel_name is none, there is no reverse accessor (this only\n-            # occurs for symmetrical m2m relations to self). If this is the\n-            # case, there are no clashes to check for this field, as there are\n-            # no reverse descriptors for this field.\n-            if rel_name is not None:\n-                for r in rel_opts.fields:\n-                    if r.name == rel_name:\n-                        e.add(opts, \"Accessor for m2m field '%s' clashes with field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, rel_opts.object_name, r.name, f.name))\n-                    if r.name == rel_query_name:\n-                        e.add(opts, \"Reverse query name for m2m field '%s' clashes with field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, rel_opts.object_name, r.name, f.name))\n-                for r in rel_opts.local_many_to_many:\n-                    if r.name == rel_name:\n-                        e.add(opts, \"Accessor for m2m field '%s' clashes with m2m field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, rel_opts.object_name, r.name, f.name))\n-                    if r.name == rel_query_name:\n-                        e.add(opts, \"Reverse query name for m2m field '%s' clashes with m2m field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, rel_opts.object_name, r.name, f.name))\n-                for r in rel_opts.get_all_related_many_to_many_objects():\n-                    if r.field is not f:\n-                        if r.get_accessor_name() == rel_name:\n-                            e.add(opts, \"Accessor for m2m field '%s' clashes with accessor for m2m field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, r.model._meta.object_name, r.field.name, f.name))\n-                        if r.get_accessor_name() == rel_query_name:\n-                            e.add(opts, \"Reverse query name for m2m field '%s' clashes with accessor for m2m field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, r.model._meta.object_name, r.field.name, f.name))\n-                for r in rel_opts.get_all_related_objects():\n-                    if r.get_accessor_name() == rel_name:\n-                        e.add(opts, \"Accessor for m2m field '%s' clashes with accessor for field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, r.model._meta.object_name, r.field.name, f.name))\n-                    if r.get_accessor_name() == rel_query_name:\n-                        e.add(opts, \"Reverse query name for m2m field '%s' clashes with accessor for field '%s.%s'. Add a related_name argument to the definition for '%s'.\" % (f.name, r.model._meta.object_name, r.field.name, f.name))\n-\n-        # Check ordering attribute.\n-        if opts.ordering:\n-            for field_name in opts.ordering:\n-                if field_name == '?':\n-                    continue\n-                if field_name.startswith('-'):\n-                    field_name = field_name[1:]\n-                if opts.order_with_respect_to and field_name == '_order':\n-                    continue\n-                # Skip ordering in the format field1__field2 (FIXME: checking\n-                # this format would be nice, but it's a little fiddly).\n-                if '__' in field_name:\n-                    continue\n-                # Skip ordering on pk. This is always a valid order_by field\n-                # but is an alias and therefore won't be found by opts.get_field.\n-                if field_name == 'pk':\n-                    continue\n-                try:\n-                    opts.get_field(field_name, many_to_many=False)\n-                except models.FieldDoesNotExist:\n-                    e.add(opts, '\"ordering\" refers to \"%s\", a field that doesn\\'t exist.' % field_name)\n-\n-        # Check unique_together.\n-        for ut in opts.unique_together:\n-            validate_local_fields(e, opts, \"unique_together\", ut)\n-        if not isinstance(opts.index_together, collections.Sequence):\n-            e.add(opts, '\"index_together\" must a sequence')\n-        else:\n-            for it in opts.index_together:\n-                validate_local_fields(e, opts, \"index_together\", it)\n-\n-    return len(e.errors)\n-\n-\n-def validate_local_fields(e, opts, field_name, fields):\n-    from django.db import models\n-\n-    if not isinstance(fields, collections.Sequence):\n-        e.add(opts, 'all %s elements must be sequences' % field_name)\n-    else:\n-        for field in fields:\n-            try:\n-                f = opts.get_field(field, many_to_many=True)\n-            except models.FieldDoesNotExist:\n-                e.add(opts, '\"%s\" refers to %s, a field that doesn\\'t exist.' % (field_name, field))\n-            else:\n-                if isinstance(f.rel, models.ManyToManyRel):\n-                    e.add(opts, '\"%s\" refers to %s. ManyToManyFields are not supported in %s.' % (field_name, f.name, field_name))\n-                if f not in opts.local_fields:\n-                    e.add(opts, '\"%s\" refers to %s. This is not in the same model as the %s statement.' % (field_name, f.name, field_name))\ndiff --git a/django/db/backends/__init__.py b/django/db/backends/__init__.py\nindex 8dd15dfee133..07813b0c45fd 100644\n--- a/django/db/backends/__init__.py\n+++ b/django/db/backends/__init__.py\n@@ -1,5 +1,6 @@\n import datetime\n import time\n+from types import MethodType\n \n from django.db.utils import DatabaseError, ProgrammingError\n \n@@ -12,6 +13,7 @@\n from importlib import import_module\n \n from django.conf import settings\n+from django.core import checks\n from django.db import DEFAULT_DB_ALIAS\n from django.db.backends.signals import connection_created\n from django.db.backends import utils\n@@ -1405,5 +1407,24 @@ def __init__(self, connection):\n         self.connection = connection\n \n     def validate_field(self, errors, opts, f):\n-        \"By default, there is no backend-specific validation\"\n+        \"\"\"\n+        By default, there is no backend-specific validation.\n+\n+        This method has been deprecated by the new checks framework. New\n+        backends should implement check_field instead.\n+\n+        \"\"\"\n+\n         pass\n+\n+    def check_field(self, field, **kwargs):\n+        class ErrorList(list):\n+            def add(self, opts, error_message):\n+                self.append(checks.Error(error_message, hint=None, obj=field))\n+\n+        errors = ErrorList()\n+        # Some tests create fields in isolation -- the fields are not attached\n+        # to any model, so they have no `model` attribute.\n+        opts = field.model._meta if hasattr(field, 'model') else None\n+        self.validate_field(errors, field, opts)\n+        return list(errors)\ndiff --git a/django/db/backends/mysql/validation.py b/django/db/backends/mysql/validation.py\nindex 17b7cde75661..d4a4a0685be7 100644\n--- a/django/db/backends/mysql/validation.py\n+++ b/django/db/backends/mysql/validation.py\n@@ -1,17 +1,34 @@\n+from django.core import checks\n from django.db.backends import BaseDatabaseValidation\n \n \n class DatabaseValidation(BaseDatabaseValidation):\n-    def validate_field(self, errors, opts, f):\n+    def check_field(self, field, **kwargs):\n         \"\"\"\n         MySQL has the following field length restriction:\n         No character (varchar) fields can have a length exceeding 255\n         characters if they have a unique index on them.\n         \"\"\"\n-        from django.db import models\n-        varchar_fields = (models.CharField, models.CommaSeparatedIntegerField,\n-                models.SlugField)\n-        if (isinstance(f, varchar_fields) and f.unique\n-                and (f.max_length is None or int(f.max_length) > 255)):\n-            msg = '\"%(name)s\": %(cls)s cannot have a \"max_length\" greater than 255 when using \"unique=True\".'\n-            errors.add(opts, msg % {'name': f.name, 'cls': f.__class__.__name__})\n+        from django.db import connection\n+\n+        errors = super(DatabaseValidation, self).check_field(field, **kwargs)\n+        try:\n+            field_type = field.db_type(connection)\n+        except AttributeError:\n+            # If the field is a relative field and the target model is\n+            # missing, then field.rel.to is not a model and doesn't have\n+            # `_meta` attribute.\n+            field_type = ''\n+\n+        if (field_type.startswith('varchar') and field.unique\n+            and (field.max_length is None or int(field.max_length) > 255)):\n+            errors.append(\n+                checks.Error(\n+                    'Under mysql backend, the field cannot have a \"max_length\" '\n+                        'greated than 255 when it is unique.',\n+                    hint=None,\n+                    obj=field,\n+                    id='E047',\n+                )\n+            )\n+        return errors\ndiff --git a/django/db/models/base.py b/django/db/models/base.py\nindex a9d8695f211c..fadc0d850c02 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -7,6 +7,7 @@\n \n import django.db.models.manager  # Imported to register signal handler.\n from django.conf import settings\n+from django.core import checks\n from django.core.exceptions import (ObjectDoesNotExist,\n     MultipleObjectsReturned, FieldError, ValidationError, NON_FIELD_ERRORS)\n from django.db.models.fields import AutoField, FieldDoesNotExist\n@@ -1011,6 +1012,308 @@ def clean_fields(self, exclude=None):\n         if errors:\n             raise ValidationError(errors)\n \n+    @classmethod\n+    def check(cls, **kwargs):\n+        errors = []\n+        errors.extend(cls._check_swappable())\n+        errors.extend(cls._check_managers(**kwargs))\n+        if not cls._meta.swapped:\n+            errors.extend(cls._check_fields(**kwargs))\n+            errors.extend(cls._check_m2m_through_same_relationship())\n+            errors.extend(cls._check_id_field())\n+            errors.extend(cls._check_column_name_clashes())\n+            errors.extend(cls._check_index_together())\n+            errors.extend(cls._check_unique_together())\n+            errors.extend(cls._check_ordering())\n+        return errors\n+\n+    @classmethod\n+    def _check_swappable(cls):\n+        \"\"\" Check if the swapped model exists. \"\"\"\n+\n+        errors = []\n+        if cls._meta.swapped:\n+            try:\n+                app_label, model_name = cls._meta.swapped.split('.')\n+            except ValueError:\n+                errors.append(\n+                    checks.Error(\n+                        '\"%s\" is not of the form \"app_label.app_name\".'\n+                            % cls._meta.swappable,\n+                        hint=None,\n+                        obj=cls,\n+                        id='E002',\n+                    )\n+                )\n+            else:\n+                if not get_model(app_label, model_name):\n+                    errors.append(\n+                        checks.Error(\n+                            'The model has been swapped out for %s.%s '\n+                                'which has not been installed or is abstract.'\n+                                % (app_label, model_name),\n+                            hint='Ensure that you did not misspell the model '\n+                                'name and the app name as well as the model '\n+                                'is not abstract. Does your INSTALLED_APPS '\n+                                'setting contain the \"%s\" app?'\n+                                % app_label,\n+                            obj=cls,\n+                            id='E003',\n+                        )\n+                    )\n+        return errors\n+\n+    @classmethod\n+    def _check_managers(cls, **kwargs):\n+        \"\"\" Perform all manager checks. \"\"\"\n+\n+        errors = []\n+        managers = cls._meta.concrete_managers + cls._meta.abstract_managers\n+        for (_, _, manager) in managers:\n+            errors.extend(manager.check(**kwargs))\n+        return errors\n+\n+    @classmethod\n+    def _check_fields(cls, **kwargs):\n+        \"\"\" Perform all field checks. \"\"\"\n+\n+        errors = []\n+        for field in cls._meta.local_fields:\n+            errors.extend(field.check(**kwargs))\n+        for field in cls._meta.local_many_to_many:\n+            errors.extend(field.check(from_model=cls, **kwargs))\n+        return errors\n+\n+    @classmethod\n+    def _check_m2m_through_same_relationship(cls):\n+        \"\"\" Check if no relationship model is used by more than one m2m field.\n+        \"\"\"\n+\n+        errors = []\n+        seen_intermediary_signatures = []\n+\n+        fields = cls._meta.local_many_to_many\n+\n+        # Skip when the target model wasn't found.\n+        fields = (f for f in fields if isinstance(f.rel.to, ModelBase))\n+\n+        # Skip when the relationship model wasn't found.\n+        fields = (f for f in fields if isinstance(f.rel.through, ModelBase))\n+\n+        for f in fields:\n+            signature = (f.rel.to, cls, f.rel.through)\n+            if signature in seen_intermediary_signatures:\n+                errors.append(\n+                    checks.Error(\n+                        'The model has two many-to-many relations through '\n+                            'the intermediary %s model, which is not permitted.'\n+                            % f.rel.through._meta.object_name,\n+                        hint=None,\n+                        obj=cls,\n+                        id='E004',\n+                    )\n+                )\n+            else:\n+                seen_intermediary_signatures.append(signature)\n+        return errors\n+\n+    @classmethod\n+    def _check_id_field(cls):\n+        \"\"\" Check if `id` field is a primary key. \"\"\"\n+\n+        fields = list(f for f in cls._meta.local_fields\n+            if f.name == 'id' and f != cls._meta.pk)\n+        # fields is empty or consists of the invalid \"id\" field\n+        if fields and not fields[0].primary_key and cls._meta.pk.name == 'id':\n+            return [\n+                checks.Error(\n+                    'You cannot use \"id\" as a field name, because each model '\n+                        'automatically gets an \"id\" field if none '\n+                        'of the fields have primary_key=True.',\n+                    hint='Remove or rename \"id\" field '\n+                        'or add primary_key=True to a field.',\n+                    obj=cls,\n+                    id='E005',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    @classmethod\n+    def _check_column_name_clashes(cls):\n+        # Store a list of column names which have already been used by other fields.\n+        used_column_names = []\n+        errors = []\n+\n+        for f in cls._meta.local_fields:\n+            _, column_name = f.get_attname_column()\n+\n+            # Ensure the column name is not already in use.\n+            if column_name and column_name in used_column_names:\n+                errors.append(\n+                    checks.Error(\n+                        'Field \"%s\" has column name \"%s\" that is already used.'\n+                            % (f.name, column_name),\n+                        hint=None,\n+                        obj=cls,\n+                    )\n+                )\n+            else:\n+                used_column_names.append(column_name)\n+\n+        return errors\n+\n+    @classmethod\n+    def _check_index_together(cls):\n+        \"\"\" Check the value of \"index_together\" option. \"\"\"\n+\n+        if not isinstance(cls._meta.index_together, (tuple, list)):\n+            return [\n+                checks.Error(\n+                    '\"index_together\" must be a list or tuple.',\n+                    hint=None,\n+                    obj=cls,\n+                    id='E006',\n+                )\n+            ]\n+\n+        elif any(not isinstance(fields, (tuple, list))\n+                for fields in cls._meta.index_together):\n+            return [\n+                checks.Error(\n+                    'All \"index_together\" elements must be lists or tuples.',\n+                    hint=None,\n+                    obj=cls,\n+                    id='E007',\n+                )\n+            ]\n+\n+        else:\n+            errors = []\n+            for fields in cls._meta.index_together:\n+                errors.extend(cls._check_local_fields(fields, \"index_together\"))\n+            return errors\n+\n+    @classmethod\n+    def _check_unique_together(cls):\n+        \"\"\" Check the value of \"unique_together\" option. \"\"\"\n+\n+        if not isinstance(cls._meta.unique_together, (tuple, list)):\n+            return [\n+                checks.Error(\n+                    '\"unique_together\" must be a list or tuple.',\n+                    hint=None,\n+                    obj=cls,\n+                    id='E008',\n+                )\n+            ]\n+\n+        elif any(not isinstance(fields, (tuple, list))\n+                for fields in cls._meta.unique_together):\n+            return [\n+                checks.Error(\n+                    'All \"unique_together\" elements must be lists or tuples.',\n+                    hint=None,\n+                    obj=cls,\n+                    id='E009',\n+                )\n+            ]\n+\n+        else:\n+            errors = []\n+            for fields in cls._meta.unique_together:\n+                errors.extend(cls._check_local_fields(fields, \"unique_together\"))\n+            return errors\n+\n+    @classmethod\n+    def _check_local_fields(cls, fields, option):\n+        from django.db import models\n+\n+        errors = []\n+        for field_name in fields:\n+            try:\n+                field = cls._meta.get_field(field_name,\n+                    many_to_many=True)\n+            except models.FieldDoesNotExist:\n+                errors.append(\n+                    checks.Error(\n+                        '\"%s\" points to a missing field named \"%s\".'\n+                            % (option, field_name),\n+                        hint='Ensure that you did not misspell the field name.',\n+                        obj=cls,\n+                        id='E010',\n+                    )\n+                )\n+            else:\n+                if isinstance(field.rel, models.ManyToManyRel):\n+                    errors.append(\n+                        checks.Error(\n+                            '\"%s\" refers to a m2m \"%s\" field, but '\n+                                'ManyToManyFields are not supported in \"%s\".'\n+                                % (option, field_name, option),\n+                            hint=None,\n+                            obj=cls,\n+                            id='E011',\n+                        )\n+                    )\n+        return errors\n+\n+    @classmethod\n+    def _check_ordering(cls):\n+        \"\"\" Check \"ordering\" option -- is it a list of lists and do all fields\n+        exist? \"\"\"\n+\n+        from django.db.models import FieldDoesNotExist\n+\n+        if not cls._meta.ordering:\n+            return []\n+\n+        if not isinstance(cls._meta.ordering, (list, tuple)):\n+            return [\n+                checks.Error(\n+                    '\"ordering\" must be a tuple or list '\n+                        '(even if you want to order by only one field).',\n+                    hint=None,\n+                    obj=cls,\n+                    id='E012',\n+                )\n+            ]\n+\n+        errors = []\n+\n+        fields = cls._meta.ordering\n+\n+        # Skip '?' fields.\n+        fields = (f for f in fields if f != '?')\n+\n+        # Convert \"-field\" to \"field\".\n+        fields = ((f[1:] if f.startswith('-') else f) for f in fields)\n+\n+        fields = (f for f in fields if\n+            f != '_order' or not cls._meta.order_with_respect_to)\n+\n+        # Skip ordering in the format field1__field2 (FIXME: checking\n+        # this format would be nice, but it's a little fiddly).\n+        fields = (f for f in fields if '__' not in f)\n+\n+        # Skip ordering on pk. This is always a valid order_by field\n+        # but is an alias and therefore won't be found by opts.get_field.\n+        fields = (f for f in fields if f != 'pk')\n+\n+        for field_name in fields:\n+            try:\n+                cls._meta.get_field(field_name, many_to_many=False)\n+            except FieldDoesNotExist:\n+                errors.append(\n+                    checks.Error(\n+                        '\"ordering\" pointing to a missing \"%s\" field.' % field_name,\n+                        hint='Ensure that you did not misspell the field name.',\n+                        obj=cls,\n+                        id='E013',\n+                    )\n+                )\n+        return errors\n+\n \n ############################################\n # HELPER FUNCTIONS (CURRIED MODEL METHODS) #\ndiff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 254e6854dfce..b7fd565a88f2 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1,3 +1,4 @@\n+# -*- coding: utf-8 -*-\n from __future__ import unicode_literals\n \n import collections\n@@ -14,16 +15,18 @@\n from django.db.models.query_utils import QueryWrapper\n from django.conf import settings\n from django import forms\n-from django.core import exceptions, validators\n+from django.core import exceptions, validators, checks\n from django.utils.datastructures import DictWrapper\n from django.utils.dateparse import parse_date, parse_datetime, parse_time\n from django.utils.functional import curry, total_ordering, Promise\n from django.utils.text import capfirst\n from django.utils import timezone\n from django.utils.translation import ugettext_lazy as _\n-from django.utils.encoding import smart_text, force_text, force_bytes\n+from django.utils.encoding import (smart_text, force_text, force_bytes,\n+    python_2_unicode_compatible)\n from django.utils.ipv6 import clean_ipv6_address\n from django.utils import six\n+from django.utils.itercompat import is_iterable\n \n \n class Empty(object):\n@@ -68,6 +71,7 @@ def _empty(of_cls):\n \n \n @total_ordering\n+@python_2_unicode_compatible\n class Field(object):\n     \"\"\"Base class for all field types\"\"\"\n \n@@ -683,6 +687,101 @@ def value_from_object(self, obj):\n         \"\"\"\n         return getattr(obj, self.attname)\n \n+    def check(self, **kwargs):\n+        errors = []\n+        errors.extend(self._check_field_name())\n+        errors.extend(self._check_choices())\n+        errors.extend(self._check_db_index())\n+        errors.extend(self._check_null_allowed_for_primary_keys())\n+        errors.extend(self._check_backend_specific_checks(**kwargs))\n+        return errors\n+\n+    def _check_field_name(self):\n+        \"\"\" Check if field name is valid (i. e. not ending with an underscore).\n+        \"\"\"\n+        if self.name.endswith('_'):\n+            return [\n+                checks.Error(\n+                    'Field names must not end with underscores.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E001',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def _check_choices(self):\n+        if self.choices:\n+            if (isinstance(self.choices, six.string_types) or\n+                    not is_iterable(self.choices)):\n+                return [\n+                    checks.Error(\n+                        '\"choices\" must be an iterable (e.g., a list or tuple).',\n+                        hint=None,\n+                        obj=self,\n+                        id='E033',\n+                    )\n+                ]\n+            elif any(isinstance(choice, six.string_types) or\n+                     not is_iterable(choice) or len(choice) != 2\n+                     for choice in self.choices):\n+                return [\n+                    checks.Error(\n+                        'All \"choices\" elements must be a tuple of two '\n+                            'elements (the first one is the actual value '\n+                            'to be stored and the second element is '\n+                            'the human-readable name).',\n+                        hint=None,\n+                        obj=self,\n+                        id='E034',\n+                    )\n+                ]\n+            else:\n+                return []\n+        else:\n+            return []\n+\n+    def _check_db_index(self):\n+        if self.db_index not in (None, True, False):\n+            return [\n+                checks.Error(\n+                    '\"db_index\" must be either None, True or False.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E035',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def _check_null_allowed_for_primary_keys(self):\n+        if (self.primary_key and self.null and\n+                not connection.features.interprets_empty_strings_as_nulls):\n+            # We cannot reliably check this for backends like Oracle which\n+            # consider NULL and '' to be equal (and thus set up\n+            # character-based fields a little differently).\n+            return [\n+                checks.Error(\n+                    'Primary keys must not have null=True.',\n+                    hint='Set null=False on the field or '\n+                        'remove primary_key=True argument.',\n+                    obj=self,\n+                    id='E036',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def _check_backend_specific_checks(self, **kwargs):\n+        return connection.validation.check_field(self, **kwargs)\n+\n+    def __str__(self):\n+        \"\"\" Return \"app_label.model_label.field_name\". \"\"\"\n+        model = self.model\n+        app = model._meta.app_label\n+        return '%s.%s.%s' % (app, model._meta.object_name, self.name)\n+\n     def __repr__(self):\n         \"\"\"\n         Displays the module, class and name of the field.\n@@ -703,8 +802,6 @@ class AutoField(Field):\n     }\n \n     def __init__(self, *args, **kwargs):\n-        assert kwargs.get('primary_key', False) is True, \\\n-               \"%ss must have primary_key=True.\" % self.__class__.__name__\n         kwargs['blank'] = True\n         Field.__init__(self, *args, **kwargs)\n \n@@ -754,6 +851,24 @@ def contribute_to_class(self, cls, name):\n     def formfield(self, **kwargs):\n         return None\n \n+    def check(self, **kwargs):\n+        errors = super(AutoField, self).check(**kwargs)\n+        errors.extend(self._check_primary_key())\n+        return errors\n+\n+    def _check_primary_key(self):\n+        if not self.primary_key:\n+            return [\n+                checks.Error(\n+                    'The field must have primary_key=True, because it is an AutoField.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E048',\n+                ),\n+            ]\n+        else:\n+            return []\n+\n \n class BooleanField(Field):\n     empty_strings_allowed = False\n@@ -816,6 +931,24 @@ def formfield(self, **kwargs):\n         defaults.update(kwargs)\n         return super(BooleanField, self).formfield(**defaults)\n \n+    def check(self, **kwargs):\n+        errors = super(BooleanField, self).check(**kwargs)\n+        errors.extend(self._check_null(**kwargs))\n+        return errors\n+\n+    def _check_null(self, **kwargs):\n+        if getattr(self, 'null', False):\n+            return [\n+                checks.Error(\n+                    'BooleanFields do not acceps null values.',\n+                    hint='Use a NullBooleanField instead.',\n+                    obj=self,\n+                    id='E037',\n+                )\n+            ]\n+        else:\n+            return []\n+\n \n class CharField(Field):\n     description = _(\"String (up to %(max_length)s)\")\n@@ -844,6 +977,37 @@ def formfield(self, **kwargs):\n         defaults.update(kwargs)\n         return super(CharField, self).formfield(**defaults)\n \n+    def check(self, **kwargs):\n+        errors = super(CharField, self).check(**kwargs)\n+        errors.extend(self._check_max_length_attibute(**kwargs))\n+        return errors\n+\n+    def _check_max_length_attibute(self, **kwargs):\n+        try:\n+            max_length = int(self.max_length)\n+            if max_length <= 0:\n+                raise ValueError()\n+        except TypeError:\n+            return [\n+                checks.Error(\n+                    'The field must have \"max_length\" attribute.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E038',\n+                )\n+            ]\n+        except ValueError:\n+            return [\n+                checks.Error(\n+                    '\"max_length\" must be a positive integer.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E039',\n+                )\n+            ]\n+        else:\n+            return []\n+\n \n # TODO: Maybe move this into contrib, because it's specialized.\n class CommaSeparatedIntegerField(CharField):\n@@ -1148,6 +1312,77 @@ def formfield(self, **kwargs):\n         defaults.update(kwargs)\n         return super(DecimalField, self).formfield(**defaults)\n \n+    def check(self, **kwargs):\n+        errors = super(DecimalField, self).check(**kwargs)\n+        errors.extend(self._check_decimal_places_and_max_digits(**kwargs))\n+        return errors\n+\n+    def _check_decimal_places_and_max_digits(self, **kwargs):\n+        errors = self.__check_decimal_places()\n+        errors += self.__check_max_digits()\n+        if not errors and int(self.decimal_places) > int(self.max_digits):\n+            errors.append(\n+                checks.Error(\n+                    '\"max_digits\" must be greater or equal to \"decimal_places\".',\n+                    hint=None,\n+                    obj=self,\n+                    id='E040',\n+                )\n+            )\n+        return errors\n+\n+    def __check_decimal_places(self):\n+        try:\n+            decimal_places = int(self.decimal_places)\n+            if decimal_places < 0:\n+                raise ValueError()\n+        except TypeError:\n+            return [\n+                checks.Error(\n+                    'The field requires a \"decimal_places\" attribute.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E041',\n+                )\n+            ]\n+        except ValueError:\n+            return [\n+                checks.Error(\n+                    '\"decimal_places\" attribute must be a non-negative integer.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E042',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def __check_max_digits(self):\n+        try:\n+            max_digits = int(self.max_digits)\n+            if max_digits <= 0:\n+                raise ValueError()\n+        except TypeError:\n+            return [\n+                checks.Error(\n+                    'The field requires a \"max_digits\" attribute.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E043',\n+                )\n+            ]\n+        except ValueError:\n+            return [\n+                checks.Error(\n+                    '\"max_digits\" attribute must be a positive integer.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E044',\n+                )\n+            ]\n+        else:\n+            return []\n+\n \n class EmailField(CharField):\n     default_validators = [validators.validate_email]\n@@ -1217,6 +1452,23 @@ def formfield(self, **kwargs):\n     def get_internal_type(self):\n         return \"FilePathField\"\n \n+    def check(self, **kwargs):\n+        errors = super(FilePathField, self).check(**kwargs)\n+        errors.extend(self._check_allowing_files_or_folders(**kwargs))\n+        return errors\n+\n+    def _check_allowing_files_or_folders(self, **kwargs):\n+        if not self.allow_files and not self.allow_folders:\n+            return [\n+                checks.Error(\n+                    'The field must have either \"allow_files\" or \"allow_folders\" set to True.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E045',\n+                )\n+            ]\n+        return []\n+\n \n class FloatField(Field):\n     empty_strings_allowed = False\n@@ -1387,6 +1639,24 @@ def formfield(self, **kwargs):\n         defaults.update(kwargs)\n         return super(GenericIPAddressField, self).formfield(**defaults)\n \n+    def check(self, **kwargs):\n+        errors = super(GenericIPAddressField, self).check(**kwargs)\n+        errors.extend(self._check_blank_and_null_values(**kwargs))\n+        return errors\n+\n+    def _check_blank_and_null_values(self, **kwargs):\n+        if not getattr(self, 'null', False) and getattr(self, 'blank', False):\n+            return [\n+                checks.Error(\n+                    'The field cannot accept blank values if null values '\n+                        'are not allowed, as blank values are stored as null.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E046',\n+                )\n+            ]\n+        return []\n+\n \n class NullBooleanField(Field):\n     empty_strings_allowed = False\ndiff --git a/django/db/models/fields/files.py b/django/db/models/fields/files.py\nindex 557ec6ec8a2d..d4c18401b996 100644\n--- a/django/db/models/fields/files.py\n+++ b/django/db/models/fields/files.py\n@@ -3,6 +3,8 @@\n \n from django import forms\n from django.db.models.fields import Field\n+from django.core import checks\n+from django.core.exceptions import ImproperlyConfigured\n from django.core.files.base import File\n from django.core.files.storage import default_storage\n from django.core.files.images import ImageFile\n@@ -220,9 +222,8 @@ class FileField(Field):\n     description = _(\"File\")\n \n     def __init__(self, verbose_name=None, name=None, upload_to='', storage=None, **kwargs):\n-        for arg in ('primary_key', 'unique'):\n-            if arg in kwargs:\n-                raise TypeError(\"'%s' is not a valid argument for %s.\" % (arg, self.__class__))\n+        self._primary_key_set_explicitly = 'primary_key' in kwargs\n+        self._unique_set_explicitly = 'unique' in kwargs\n \n         self.storage = storage or default_storage\n         self.upload_to = upload_to\n@@ -304,6 +305,54 @@ def formfield(self, **kwargs):\n         defaults.update(kwargs)\n         return super(FileField, self).formfield(**defaults)\n \n+    def check(self, **kwargs):\n+        errors = super(FileField, self).check(**kwargs)\n+        errors.extend(self._check_upload_to())\n+        errors.extend(self._check_unique())\n+        errors.extend(self._check_primary_key())\n+        return errors\n+\n+    def _check_upload_to(self):\n+        if not self.upload_to:\n+            return [\n+                checks.Error(\n+                    'The field requires an \"upload_to\" attribute.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E031',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def _check_unique(self):\n+        if self._unique_set_explicitly:\n+            return [\n+                checks.Error(\n+                    '\"unique\" is not a valid argument for %s.'\n+                        % self.__class__.__name__,\n+                    hint=None,\n+                    obj=self,\n+                    id='E049',\n+                )\n+            ]\n+        else:\n+            return []\n+\n+    def _check_primary_key(self):\n+        if self._primary_key_set_explicitly:\n+            return [\n+                checks.Error(\n+                    '\"primary_key\" is not a valid argument for %s.'\n+                        % self.__class__.__name__,\n+                    hint=None,\n+                    obj=self,\n+                    id='E050',\n+                )\n+            ]\n+        else:\n+            return []\n+\n \n class ImageFileDescriptor(FileDescriptor):\n     \"\"\"\n@@ -422,3 +471,25 @@ def formfield(self, **kwargs):\n         defaults = {'form_class': forms.ImageField}\n         defaults.update(kwargs)\n         return super(ImageField, self).formfield(**defaults)\n+\n+    def check(self, **kwargs):\n+        errors = super(ImageField, self).check(**kwargs)\n+        errors.extend(self._check_image_library_installed())\n+        return errors\n+\n+    def _check_image_library_installed(self):\n+        try:\n+            from django.utils.image import Image\n+        except ImproperlyConfigured:\n+            return [\n+                checks.Error(\n+                    'To use ImageFields, Pillow must be installed.',\n+                    hint='Get Pillow at https://pypi.python.org/pypi/Pillow '\n+                        'or run command \"pip install pillow\".',\n+                    obj=self,\n+                    id='E032',\n+                )\n+            ]\n+        else:\n+            return []\n+\ndiff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 8252cce6726e..d757bc9d82f7 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1,13 +1,15 @@\n from operator import attrgetter\n \n+from django.core import checks\n from django.db import connection, connections, router, transaction\n from django.db.backends import utils\n from django.db.models import signals\n+from django.db.models.deletion import SET_NULL, SET_DEFAULT, CASCADE\n from django.db.models.fields import (AutoField, Field, IntegerField,\n     PositiveIntegerField, PositiveSmallIntegerField, FieldDoesNotExist)\n-from django.db.models.related import RelatedObject, PathInfo\n+from django.db.models.loading import get_models\n from django.db.models.query import QuerySet\n-from django.db.models.deletion import CASCADE\n+from django.db.models.related import RelatedObject, PathInfo\n from django.utils.encoding import smart_text\n from django.utils import six\n from django.utils.deprecation import RenameMethodsBase\n@@ -16,6 +18,7 @@\n from django.core import exceptions\n from django import forms\n \n+\n RECURSIVE_RELATIONSHIP_CONSTANT = 'self'\n \n def add_lazy_relation(cls, field, relation, operation):\n@@ -137,6 +140,167 @@ def related_query_name(self):\n         # \"related_name\" option.\n         return self.rel.related_query_name or self.rel.related_name or self.opts.model_name\n \n+    def check(self, **kwargs):\n+        errors = super(RelatedField, self).check(**kwargs)\n+        errors.extend(self._check_relation_model_exists())\n+        errors.extend(self._check_referencing_to_swapped_model())\n+        errors.extend(self._check_clashes())\n+        return errors\n+\n+    def _check_relation_model_exists(self):\n+        rel_is_missing = self.rel.to not in get_models()\n+        rel_is_string = isinstance(self.rel.to, six.string_types)\n+        model_name = self.rel.to if rel_is_string else self.rel.to._meta.object_name\n+        if rel_is_missing and (rel_is_string or not self.rel.to._meta.swapped):\n+            return [\n+                checks.Error(\n+                    'The field has a relation with model %s, which '\n+                        'has either not been installed or is abstract.'\n+                        % model_name,\n+                    hint='Ensure that you did not misspell the model name and '\n+                        'the model is not abstract. Does your INSTALLED_APPS '\n+                        'setting contain the app where %s is defined?'\n+                        % model_name,\n+                    obj=self,\n+                    id='E030',\n+                )\n+            ]\n+        return []\n+\n+    def _check_referencing_to_swapped_model(self):\n+        if (self.rel.to not in get_models() and\n+                not isinstance(self.rel.to, six.string_types) and\n+                self.rel.to._meta.swapped):\n+            model = \"%s.%s\" % (\n+                self.rel.to._meta.app_label,\n+                self.rel.to._meta.object_name\n+            )\n+            return [\n+                checks.Error(\n+                    'The field defines a relation with the model %s, '\n+                        'which has been swapped out.' % model,\n+                    hint='Update the relation to point at settings.%s'\n+                        % self.rel.to._meta.swappable,\n+                    obj=self,\n+                    id='E029',\n+                )\n+            ]\n+        return []\n+\n+    def _check_clashes(self):\n+        \"\"\" Check accessor and reverse query name clashes. \"\"\"\n+\n+        from django.db.models.base import ModelBase\n+\n+        errors = []\n+        opts = self.model._meta\n+\n+        # `f.rel.to` may be a string instead of a model. Skip if model name is\n+        # not resolved.\n+        if not isinstance(self.rel.to, ModelBase):\n+            return []\n+\n+        # If the field doesn't install backward relation on the target model (so\n+        # `is_hidden` returns True), then there are no clashes to check and we\n+        # can skip these fields.\n+        if self.rel.is_hidden():\n+            return []\n+\n+        try:\n+            self.related\n+        except AttributeError:\n+            return []\n+\n+        # Consider that we are checking field `Model.foreign` and the models\n+        # are:\n+        #\n+        #     class Target(models.Model):\n+        #         model = models.IntegerField()\n+        #         model_set = models.IntegerField()\n+        #\n+        #     class Model(models.Model):\n+        #         foreign = models.ForeignKey(Target)\n+        #         m2m = models.ManyToManyField(Target)\n+\n+        rel_opts = self.rel.to._meta\n+        # rel_opts.object_name == \"Target\"\n+        rel_name = self.related.get_accessor_name()  # i. e. \"model_set\"\n+        rel_query_name = self.related_query_name()  # i. e. \"model\"\n+        field_name = \"%s.%s\" % (opts.object_name,\n+            self.name)  # i. e. \"Model.field\"\n+\n+        # Check clashes between accessor or reverse query name of `field`\n+        # and any other field name -- i. e. accessor for Model.foreign is\n+        # model_set and it clashes with Target.model_set.\n+        potential_clashes = rel_opts.fields + rel_opts.local_many_to_many\n+        for clash_field in potential_clashes:\n+            clash_name = \"%s.%s\" % (rel_opts.object_name,\n+                clash_field.name)  # i. e. \"Target.model_set\"\n+            if clash_field.name == rel_name:\n+                errors.append(\n+                    checks.Error(\n+                        'Accessor for field %s clashes with field %s.'\n+                            % (field_name, clash_name),\n+                        hint='Rename field %s or add/change a related_name '\n+                            'argument to the definition for field %s.'\n+                            % (clash_name, field_name),\n+                        obj=self,\n+                        id='E014',\n+                    )\n+                )\n+\n+            if clash_field.name == rel_query_name:\n+                errors.append(\n+                    checks.Error(\n+                        'Reverse query name for field %s clashes with field %s.'\n+                            % (field_name, clash_name),\n+                        hint='Rename field %s or add/change a related_name '\n+                            'argument to the definition for field %s.'\n+                            % (clash_name, field_name),\n+                        obj=self,\n+                        id='E015',\n+                    )\n+                )\n+\n+        # Check clashes between accessors/reverse query names of `field` and\n+        # any other field accessor -- i. e. Model.foreign accessor clashes with\n+        # Model.m2m accessor.\n+        potential_clashes = rel_opts.get_all_related_many_to_many_objects()\n+        potential_clashes += rel_opts.get_all_related_objects()\n+        potential_clashes = (r for r in potential_clashes\n+            if r.field is not self)\n+        for clash_field in potential_clashes:\n+            clash_name = \"%s.%s\" % (  # i. e. \"Model.m2m\"\n+                clash_field.model._meta.object_name,\n+                clash_field.field.name)\n+            if clash_field.get_accessor_name() == rel_name:\n+                errors.append(\n+                    checks.Error(\n+                        'Clash between accessors for %s and %s.'\n+                            % (field_name, clash_name),\n+                        hint='Add or change a related_name argument '\n+                            'to the definition for %s or %s.'\n+                            % (field_name, clash_name),\n+                        obj=self,\n+                        id='E016',\n+                    )\n+                )\n+\n+            if clash_field.get_accessor_name() == rel_query_name:\n+                errors.append(\n+                    checks.Error(\n+                        'Clash between reverse query names for %s and %s.'\n+                            % (field_name, clash_name),\n+                        hint='Add or change a related_name argument '\n+                            'to the definition for %s or %s.'\n+                            % (field_name, clash_name),\n+                        obj=self,\n+                        id='E017',\n+                    )\n+                )\n+\n+        return errors\n+\n \n class RenameRelatedObjectDescriptorMethods(RenameMethodsBase):\n     renamed_methods = (\n@@ -1169,6 +1333,61 @@ def contribute_to_related_class(self, cls, related):\n             if self.rel.limit_choices_to:\n                 cls._meta.related_fkey_lookups.append(self.rel.limit_choices_to)\n \n+    def check(self, **kwargs):\n+        errors = super(ForeignObject, self).check(**kwargs)\n+        errors.extend(self._check_unique_target())\n+        return errors\n+\n+    def _check_unique_target(self):\n+        rel_is_string = isinstance(self.rel.to, six.string_types)\n+        if rel_is_string or not self.requires_unique_target:\n+            return []\n+\n+        # Skip if the\n+        try:\n+            self.foreign_related_fields\n+        except FieldDoesNotExist:\n+            return []\n+\n+        try:\n+            self.related\n+        except AttributeError:\n+            return []\n+\n+        has_unique_field = any(rel_field.unique\n+            for rel_field in self.foreign_related_fields)\n+        if not has_unique_field and len(self.foreign_related_fields) > 1:\n+            field_combination = ','.join(rel_field.name\n+                for rel_field in self.foreign_related_fields)\n+            model_name = self.rel.to.__name__\n+            return [\n+                checks.Error(\n+                    'No unique=True constraint '\n+                        'on field combination \"%s\" under model %s.'\n+                        % (field_combination, model_name),\n+                    hint='Set unique=True argument on any of the fields '\n+                        '\"%s\" under model %s.'\n+                        % (field_combination, model_name),\n+                    obj=self,\n+                    id='E018',\n+                )\n+            ]\n+        elif not has_unique_field:\n+            field_name = self.foreign_related_fields[0].name\n+            model_name = self.rel.to.__name__\n+            return [\n+                checks.Error(\n+                    '%s.%s must have unique=True '\n+                        'because it is referenced by a foreign key.'\n+                        % (model_name, field_name),\n+                    hint=None,\n+                    obj=self,\n+                    id='E019',\n+                )\n+            ]\n+        else:\n+            return []\n+\n \n class ForeignKey(ForeignObject):\n     empty_strings_allowed = False\n@@ -1184,7 +1403,6 @@ def __init__(self, to, to_field=None, rel_class=ManyToOneRel,\n         except AttributeError:  # to._meta doesn't exist, so it must be RECURSIVE_RELATIONSHIP_CONSTANT\n             assert isinstance(to, six.string_types), \"%s(%r) is invalid. First parameter to ForeignKey must be either a model, a model name, or the string %r\" % (self.__class__.__name__, to, RECURSIVE_RELATIONSHIP_CONSTANT)\n         else:\n-            assert not to._meta.abstract, \"%s cannot define a relation with abstract class %s\" % (self.__class__.__name__, to._meta.object_name)\n             # For backwards compatibility purposes, we need to *try* and set\n             # the to_field during FK construction. It won't be guaranteed to\n             # be correct until contribute_to_class is called. Refs #12190.\n@@ -1331,6 +1549,34 @@ def db_type(self, connection):\n     def db_parameters(self, connection):\n         return {\"type\": self.db_type(connection), \"check\": []}\n \n+    def check(self, **kwargs):\n+        errors = super(ForeignKey, self).check(**kwargs)\n+        errors.extend(self._check_on_delete())\n+        return errors\n+\n+    def _check_on_delete(self):\n+        on_delete = getattr(self.rel, 'on_delete', None)\n+        if on_delete == SET_NULL and not self.null:\n+            return [\n+                checks.Error(\n+                    'The field specifies on_delete=SET_NULL, but cannot be null.',\n+                    hint='Set null=True argument on the field.',\n+                    obj=self,\n+                    id='E020',\n+                )\n+            ]\n+        elif on_delete == SET_DEFAULT and not self.has_default():\n+            return [\n+                checks.Error(\n+                    'The field specifies on_delete=SET_DEFAULT, but has no default value.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E021',\n+                )\n+            ]\n+        else:\n+            return []\n+\n \n class OneToOneField(ForeignKey):\n     \"\"\"\n@@ -1414,7 +1660,7 @@ class ManyToManyField(RelatedField):\n \n     def __init__(self, to, db_constraint=True, **kwargs):\n         try:\n-            assert not to._meta.abstract, \"%s cannot define a relation with abstract class %s\" % (self.__class__.__name__, to._meta.object_name)\n+            to._meta\n         except AttributeError:  # to._meta doesn't exist, so it must be RECURSIVE_RELATIONSHIP_CONSTANT\n             assert isinstance(to, six.string_types), \"%s(%r) is invalid. First parameter to ManyToManyField must be either a model, a model name, or the string %r\" % (self.__class__.__name__, to, RECURSIVE_RELATIONSHIP_CONSTANT)\n             # Class names must be ASCII in Python 2.x, so we forcibly coerce it here to break early if there's a problem.\n@@ -1617,3 +1863,139 @@ def db_type(self, connection):\n \n     def db_parameters(self, connection):\n         return {\"type\": None, \"check\": None}\n+\n+    def check(self, **kwargs):\n+        errors = super(ManyToManyField, self).check(**kwargs)\n+        errors.extend(self._check_unique(**kwargs))\n+        errors.extend(self._check_relationship_model(**kwargs))\n+        return errors\n+\n+    def _check_unique(self, **kwargs):\n+        if self.unique:\n+            return [\n+                checks.Error(\n+                    'ManyToManyFields must not be unique.',\n+                    hint=None,\n+                    obj=self,\n+                    id='E022',\n+                )\n+            ]\n+        return []\n+\n+    def _check_relationship_model(self, from_model=None, **kwargs):\n+        errors = []\n+\n+        if self.rel.through not in get_models(include_auto_created=True):\n+            # The relationship model is not installed.\n+            errors.append(\n+                checks.Error(\n+                    'The field specifies a many-to-many relation through model '\n+                        '%s, which has not been installed.'\n+                        % self.rel.through,\n+                    hint='Ensure that you did not misspell the model name and '\n+                        'the model is not abstract. Does your INSTALLED_APPS '\n+                        'setting contain the app where %s is defined?'\n+                        % self.rel.through,\n+                    obj=self,\n+                    id='E023',\n+                )\n+            )\n+\n+        elif not isinstance(self.rel.through, six.string_types):\n+\n+            assert from_model is not None, \\\n+                \"ManyToManyField with intermediate \" \\\n+                \"tables cannot be checked if you don't pass the model \" \\\n+                \"where the field is attached to.\"\n+\n+            # Set some useful local variables\n+            to_model = self.rel.to\n+            from_model_name = from_model._meta.object_name\n+            if isinstance(to_model, six.string_types):\n+                to_model_name = to_model\n+            else:\n+                to_model_name = to_model._meta.object_name\n+            relationship_model_name = self.rel.through._meta.object_name\n+            self_referential = from_model == to_model\n+\n+            # Check symmetrical attribute.\n+            if (self_referential and self.rel.symmetrical and\n+                    not self.rel.through._meta.auto_created):\n+                errors.append(\n+                    checks.Error(\n+                        'Many-to-many fields with intermediate tables must not be symmetrical.',\n+                        hint=None,\n+                        obj=self,\n+                        id='E024',\n+                    )\n+                )\n+\n+            # Count foreign keys in intermediate model\n+            if self_referential:\n+                seen_self = sum(from_model == getattr(field.rel, 'to', None)\n+                    for field in self.rel.through._meta.fields)\n+\n+                if seen_self > 2:\n+                    errors.append(\n+                        checks.Error(\n+                            'The model is used as an intermediary model by '\n+                                '%s, but it has more than two foreign keys '\n+                                'to %s, which is ambiguous and is not permitted.'\n+                                % (self, from_model_name),\n+                            hint=None,\n+                            obj=self.rel.through,\n+                            id='E025',\n+                        )\n+                    )\n+\n+            else:\n+                # Count foreign keys in relationship model\n+                seen_from = sum(from_model == getattr(field.rel, 'to', None)\n+                    for field in self.rel.through._meta.fields)\n+                seen_to = sum(to_model == getattr(field.rel, 'to', None)\n+                    for field in self.rel.through._meta.fields)\n+\n+                if seen_from > 1:\n+                    errors.append(\n+                        checks.Error(\n+                            'The model is used as an intermediary model by '\n+                                '%s, but it has more than one foreign key '\n+                                'to %s, which is ambiguous and is not permitted.'\n+                                % (self, from_model_name),\n+                            hint='If you want to create a recursive relationship, '\n+                                'use ForeignKey(\"self\", symmetrical=False, '\n+                                'through=\"%s\").'\n+                                % relationship_model_name,\n+                            obj=self,\n+                            id='E026',\n+                        )\n+                    )\n+\n+                if seen_to > 1:\n+                    errors.append(\n+                        checks.Error(\n+                            'The model is used as an intermediary model by '\n+                                '%s, but it has more than one foreign key '\n+                                'to %s, which is ambiguous and is not permitted.'\n+                                % (self, to_model_name),\n+                            hint='If you want to create a recursive '\n+                                'relationship, use ForeignKey(\"self\", '\n+                                'symmetrical=False, through=\"%s\").'\n+                                % relationship_model_name,\n+                            obj=self,\n+                            id='E027',\n+                        )\n+                    )\n+\n+                if seen_from == 0 or seen_to == 0:\n+                    errors.append(\n+                        checks.Error(\n+                            'The model is used as an intermediary model by '\n+                                '%s, but it misses a foreign key to %s or %s.'\n+                                % (self, from_model_name, to_model_name),\n+                            hint=None,\n+                            obj=self.rel.through,\n+                            id='E028',\n+                        )\n+                    )\n+        return errors\ndiff --git a/django/db/models/loading.py b/django/db/models/loading.py\nindex 2858b8b6992d..d022964b6745 100644\n--- a/django/db/models/loading.py\n+++ b/django/db/models/loading.py\n@@ -47,9 +47,6 @@ def _initialize():\n         # May contain apps that are not installed.\n         app_models=ModelDict(),\n \n-        # Mapping of app_labels to errors raised when trying to import the app.\n-        app_errors = {},\n-\n         # Pending lookups for lazy relations\n         pending_lookups = {},\n \n@@ -233,11 +230,6 @@ def get_app(self, app_label, emptyOK=False):\n         finally:\n             imp.release_lock()\n \n-    def get_app_errors(self):\n-        \"Returns the map of known problems with the INSTALLED_APPS.\"\n-        self._populate()\n-        return self.app_errors\n-\n     def get_models(self, app_mod=None,\n                    include_auto_created=False, include_deferred=False,\n                    only_installed=True, include_swapped=False):\n@@ -383,7 +375,6 @@ def __init__(self):\n get_app_path = cache.get_app_path\n get_app_paths = cache.get_app_paths\n get_app = cache.get_app\n-get_app_errors = cache.get_app_errors\n get_models = cache.get_models\n get_model = cache.get_model\n register_models = cache.register_models\ndiff --git a/django/db/models/manager.py b/django/db/models/manager.py\nindex 48ad3db9cc04..140d71e4f1ec 100644\n--- a/django/db/models/manager.py\n+++ b/django/db/models/manager.py\n@@ -7,6 +7,7 @@\n from django.db.models.fields import FieldDoesNotExist\n from django.utils import six\n from django.utils.deprecation import RenameMethodsBase\n+from django.utils.encoding import python_2_unicode_compatible\n \n \n def ensure_default_manager(sender, **kwargs):\n@@ -58,6 +59,7 @@ class RenameManagerMethods(RenameMethodsBase):\n     )\n \n \n+@python_2_unicode_compatible\n class BaseManager(six.with_metaclass(RenameManagerMethods)):\n     # Tracks each time a Manager instance is created. Used to retain order.\n     creation_counter = 0\n@@ -155,6 +157,23 @@ def db_manager(self, using=None, hints=None):\n     def db(self):\n         return self._db or router.db_for_read(self.model, **self._hints)\n \n+    def check(self, **kwargs):\n+        return []\n+\n+    def __str__(self):\n+        \"\"\" Return \"app_label.model_label.manager_name\". \"\"\"\n+        model = self.model\n+        opts = model._meta\n+        app = model._meta.app_label\n+        manager_name = next(name for (_, name, manager)\n+            in opts.concrete_managers + opts.abstract_managers\n+            if manager == self)\n+        return '%s.%s.%s' % (app, model._meta.object_name, manager_name)\n+\n+    #######################\n+    # PROXIES TO QUERYSET #\n+    #######################\n+\n     def get_queryset(self):\n         \"\"\"\n         Returns a new QuerySet object.  Subclasses can override this method to\n@@ -171,6 +190,7 @@ def all(self):\n         # understanding of how this comes into play.\n         return self.get_queryset()\n \n+\n Manager = BaseManager.from_queryset(QuerySet, class_name='Manager')\n \n \ndiff --git a/django/forms/models.py b/django/forms/models.py\nindex c05c45238362..92077f15469a 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -901,13 +901,12 @@ def get_unique_error_message(self, unique_check):\n         return super(BaseInlineFormSet, self).get_unique_error_message(unique_check)\n \n \n-def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n+def _get_foreign_key(parent_model, model, fk_name=None):\n     \"\"\"\n     Finds and returns the ForeignKey from model to parent if there is one\n     (returns None if can_fail is True and no such field exists). If fk_name is\n-    provided, assume it is the name of the ForeignKey field. Unles can_fail is\n-    True, an exception is raised if there is no ForeignKey from model to\n-    parent_model.\n+    provided, assume it is the name of the ForeignKey field. An exception is\n+    raised if there is no ForeignKey from model to parent_model.\n     \"\"\"\n     # avoid circular import\n     from django.db.models import ForeignKey\n@@ -919,9 +918,13 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n             if not isinstance(fk, ForeignKey) or \\\n                     (fk.rel.to != parent_model and\n                      fk.rel.to not in parent_model._meta.get_parent_list()):\n-                raise Exception(\"fk_name '%s' is not a ForeignKey to %s\" % (fk_name, parent_model))\n+                raise ValueError(\n+                    '\"fk_name\" refers to \"%s\" field, which is not a ForeignKey to %s.%s.'\n+                    % (fk_name, parent_model._meta.app_label, parent_model._meta.object_name))\n         elif len(fks_to_parent) == 0:\n-            raise Exception(\"%s has no field named '%s'\" % (model, fk_name))\n+            raise ValueError(\n+                '\"fk_name\" refers to \"%s\" field, which is missing from model %s.%s.'\n+                % (fk_name, model._meta.app_label, model._meta.object_name))\n     else:\n         # Try to discover what the ForeignKey from model to parent_model is\n         fks_to_parent = [\n@@ -933,11 +936,13 @@ def _get_foreign_key(parent_model, model, fk_name=None, can_fail=False):\n         if len(fks_to_parent) == 1:\n             fk = fks_to_parent[0]\n         elif len(fks_to_parent) == 0:\n-            if can_fail:\n-                return\n-            raise Exception(\"%s has no ForeignKey to %s\" % (model, parent_model))\n+            raise ValueError(\n+                '\"fk_name\" must be explicitly defined, because there are no ForeignKey from %s.%s to %s.%s.'\n+                % (model._meta.app_label, model._meta.object_name, parent_model._meta.app_label, parent_model._meta.object_name))\n         else:\n-            raise Exception(\"%s has more than 1 ForeignKey to %s\" % (model, parent_model))\n+            raise ValueError(\n+                '\"fk_name\" must be explicitly defined, because %s.%s has more than one ForeignKey to %s.%s.'\n+                % (model._meta.app_label, model._meta.object_name, parent_model._meta.app_label, parent_model._meta.object_name))\n     return fk\n \n \ndiff --git a/django/test/testcases.py b/django/test/testcases.py\nindex 3f0046314e2e..7886e52aa411 100644\n--- a/django/test/testcases.py\n+++ b/django/test/testcases.py\n@@ -752,7 +752,7 @@ def _fixture_setup(self):\n                 # We have to use this slightly awkward syntax due to the fact\n                 # that we're using *args and **kwargs together.\n                 call_command('loaddata', *self.fixtures,\n-                             **{'verbosity': 0, 'database': db_name, 'skip_validation': True})\n+                             **{'verbosity': 0, 'database': db_name, 'skip_checks': True})\n \n     def _post_teardown(self):\n         \"\"\"Performs any post-test things. This includes:\n@@ -780,7 +780,7 @@ def _fixture_teardown(self):\n         # when flushing only a subset of the apps\n         for db_name in self._databases_names(include_mirrors=False):\n             call_command('flush', verbosity=0, interactive=False,\n-                         database=db_name, skip_validation=True,\n+                         database=db_name, skip_checks=True,\n                          reset_sequences=False,\n                          allow_cascade=self.available_apps is not None,\n                          inhibit_post_migrate=self.available_apps is not None)\n@@ -847,7 +847,7 @@ def _fixture_setup(self):\n                                     'verbosity': 0,\n                                     'commit': False,\n                                     'database': db_name,\n-                                    'skip_validation': True,\n+                                    'skip_checks': True,\n                                  })\n                 except Exception:\n                     self._fixture_teardown()\ndiff --git a/django/test/utils.py b/django/test/utils.py\nindex cd3e99d58b52..162341a9db56 100644\n--- a/django/test/utils.py\n+++ b/django/test/utils.py\n@@ -242,6 +242,26 @@ def disable(self):\n                                  setting=key, value=new_value, enter=False)\n \n \n+def override_system_checks(new_checks):\n+    \"\"\" Acts as a decorator. Overrides list of registered system checks.\n+    Useful when you override `INSTALLED_APPS`, e.g. if you exclude `auth` app,\n+    you also need to exclude its system checks. \"\"\"\n+\n+    from django.core.checks.registration import framework\n+\n+    def outer(test_func):\n+        @wraps(test_func)\n+        def inner(*args, **kwargs):\n+            old_checks = framework.registered_checks\n+            framework.registered_checks = new_checks\n+            try:\n+                return test_func(*args, **kwargs)\n+            finally:\n+                framework.registered_checks = old_checks\n+        return inner\n+    return outer\n+\n+\n def compare_xml(want, got):\n     \"\"\"Tries to do a 'xml-comparison' of want and got.  Plain string\n     comparison doesn't always work because, for example, attribute\ndiff --git a/django/utils/termcolors.py b/django/utils/termcolors.py\nindex 8c66e338de9a..acb1a7ff4a56 100644\n--- a/django/utils/termcolors.py\n+++ b/django/utils/termcolors.py\n@@ -74,6 +74,7 @@ def make_style(opts=(), **kwargs):\n PALETTES = {\n     NOCOLOR_PALETTE: {\n         'ERROR':        {},\n+        'WARNING':      {},\n         'NOTICE':       {},\n         'SQL_FIELD':    {},\n         'SQL_COLTYPE':  {},\n@@ -93,6 +94,7 @@ def make_style(opts=(), **kwargs):\n     },\n     DARK_PALETTE: {\n         'ERROR':        { 'fg': 'red', 'opts': ('bold',) },\n+        'WARNING':      { 'fg': 'yellow', 'opts': ('bold',) },\n         'NOTICE':       { 'fg': 'red' },\n         'SQL_FIELD':    { 'fg': 'green', 'opts': ('bold',) },\n         'SQL_COLTYPE':  { 'fg': 'green' },\n@@ -112,6 +114,7 @@ def make_style(opts=(), **kwargs):\n     },\n     LIGHT_PALETTE: {\n         'ERROR':        { 'fg': 'red', 'opts': ('bold',) },\n+        'WARNING':      { 'fg': 'yellow', 'opts':('bold',) },\n         'NOTICE':       { 'fg': 'red' },\n         'SQL_FIELD':    { 'fg': 'green', 'opts': ('bold',) },\n         'SQL_COLTYPE':  { 'fg': 'green' },\ndiff --git a/docs/howto/custom-management-commands.txt b/docs/howto/custom-management-commands.txt\nindex 2325e32ac2f3..918e048870ae 100644\n--- a/docs/howto/custom-management-commands.txt\n+++ b/docs/howto/custom-management-commands.txt\n@@ -227,13 +227,21 @@ All attributes can be set in your derived class and can be used in\n   wrapped with ``BEGIN;`` and ``COMMIT;``. Default value is\n   ``False``.\n \n+.. attribute:: BaseCommand.requires_system_checks\n+\n+  A boolean; if ``True``, entire Django project will be checked for errors\n+  prior to executing the command. If it's missing, the value of\n+  ``requires_model_validation`` is used. If the latter flag is missing too,\n+  the default value (``True``) is used. Defining both\n+  ``requires_system_checks`` and ``requires_model_validation`` results in an\n+  error.\n+\n .. attribute:: BaseCommand.requires_model_validation\n \n-  A boolean; if ``True``, validation of installed models will be\n-  performed prior to executing the command. Default value is\n-  ``True``. To validate an individual application's models\n-  rather than all applications' models, call\n-  :meth:`~BaseCommand.validate` from :meth:`~BaseCommand.handle`.\n+  A deprecated boolean. Use ``requires_system_checks`` instead. If\n+  ``requires_system_checks`` is missing, then this value is used. Defining\n+  both ``requires_system_checks`` and ``requires_model_validation`` results in\n+  an error.\n \n .. attribute:: BaseCommand.leave_locale_alone\n \n@@ -299,12 +307,22 @@ the :meth:`~BaseCommand.handle` method must be implemented.\n \n     The actual logic of the command. Subclasses must implement this method.\n \n-.. method:: BaseCommand.validate(app=None, display_num_errors=False)\n+.. method:: BaseCommand.check(apps=None, tags=None, display_num_errors=False)\n \n-    Validates the given app, raising :class:`CommandError` for any errors.\n+    Uses the system check framework to validate entire Django project. Yes,\n+    it's includes model validation and compatibility checks. For any serious\n+    issue (like an error or critical error), raises :class:`CommandError`. If\n+    there are only light issues (like warnings), does not raise any exception.\n+    In both cases, prints to stderr. When there are no issues, prints to\n+    stdout.\n \n-    If ``app`` is None, then all installed apps are validated.\n+    If `apps` and `tags` are both None, all system checks are performed.\n+    `tags` can be a list of check tags, like ``compatibility`` or ``models``.\n+\n+.. method:: BaseCommand.validate(app=None, display_num_errors=False)\n \n+    Deprecated. Use \"check\" instead. Delegates to \"check\". If ``app`` is None,\n+    then all installed apps are checked for errors.\n \n .. _ref-basecommand-subclasses:\n \ndiff --git a/docs/index.txt b/docs/index.txt\nindex df6861aa1c65..56c6c6d6418a 100644\n--- a/docs/index.txt\n+++ b/docs/index.txt\n@@ -286,6 +286,7 @@ Learn about some other core functionalities of the Django framework:\n * :doc:`Flatpages <ref/contrib/flatpages>`\n * :doc:`Redirects <ref/contrib/redirects>`\n * :doc:`Signals <topics/signals>`\n+* :doc:`System check framework <ref/checks>`\n * :doc:`The sites framework <ref/contrib/sites>`\n * :doc:`Unicode in Django <ref/unicode>`\n \ndiff --git a/docs/internals/deprecation.txt b/docs/internals/deprecation.txt\nindex 498f303daf72..595df65960d6 100644\n--- a/docs/internals/deprecation.txt\n+++ b/docs/internals/deprecation.txt\n@@ -461,6 +461,16 @@ these changes.\n   ``BaseMemcachedCache._get_memcache_timeout()`` method to\n   ``get_backend_timeout()``.\n \n+* ``BaseCommand.requires_model_validation`` will be removed in favour of\n+  ``requires_system_checks``. Admin validators will be replaced by admin\n+  checks.\n+\n+* ``ModelAdmin.validator`` will be removed in favour of new ``checks``\n+  attribute.\n+\n+* ``django.db.backends.DatabaseValidation.validate_field`` will be removed in\n+  favour of ``check_field`` method.\n+\n 2.0\n ---\n \ndiff --git a/docs/intro/tutorial01.txt b/docs/intro/tutorial01.txt\nindex 1c301c0cc213..5f28424843d1 100644\n--- a/docs/intro/tutorial01.txt\n+++ b/docs/intro/tutorial01.txt\n@@ -136,7 +136,7 @@ see the following output on the command line:\n \n .. parsed-literal::\n \n-    Validating models...\n+    Performing system checks...\n \n     0 errors found\n     |today| - 15:50:53\n@@ -475,8 +475,8 @@ Note the following:\n \n If you're interested, also run the following commands:\n \n-* :djadmin:`python manage.py validate <validate>` -- Checks for any errors\n-  in the construction of your models.\n+* :djadmin:`python manage.py check <check>` -- Checks for any errors\n+  in your project.\n \n * :djadmin:`python manage.py sqlcustom polls <sqlcustom>` -- Outputs any\n   :ref:`custom SQL statements <initial-sql>` (such as table modifications or\ndiff --git a/docs/ref/checks.txt b/docs/ref/checks.txt\nnew file mode 100644\nindex 000000000000..cfc09e3e8ddc\n--- /dev/null\n+++ b/docs/ref/checks.txt\n@@ -0,0 +1,204 @@\n+.. module:: django.core.checks\n+\n+.. _`system-check-framework`:\n+\n+======================\n+System check framework\n+======================\n+\n+System check framework is a set of static checks validating mainly apps and\n+models. It detects common problems and report them providing hints. The\n+framework is open-ended, so you can easily add your own checks.\n+\n+Checks can be triggered explicitly via :djadmin:`check` command. It's also\n+triggered implicitly before most command, including :djadmin:`runserver` and\n+:djadmin:`migrate`. For performance issues, the checks are not performed if\n+``DEBUG`` is set to False.\n+\n+Django will not allow you to run server if there is any serious message like\n+an error or critical error. If there are light messages like warnings, Django\n+won't stop you, but will issue the message. You can hide unwanted warnings or\n+force Django to run even if there are serious messages bu overriding\n+:setting:`SILENCED_SYSTEM_CHECKS` setting.\n+\n+Writing your own checks\n+=======================\n+\n+The framework is flexible and allow you to write functions (or other callable\n+objects like methods) performing any kind of checks. The function has to\n+receive ``**kwargs`` and return list of messages. If there are no message, you\n+still have to return an empty list. The function need to be `registered`_ or\n+called from another check.\n+\n+.. _`registered`: `registering-checks`_\n+\n+.. class:: django.core.checks.CheckMessage(level, msg, hint, obj=None, id=None)\n+\n+:class:`~django.core.checks.CheckMessage` is the key concept of\n+:mod:`django.core.checks` module and represents a single message, i.e. a\n+warning or an error. The concept is very similar to messages from `message\n+framework` or `logging framework`_. Messages are tagged with ``level``\n+indicating how serious the message is. They can have an unique identifier.\n+\n+.. _`logging framework`: http://docs.python.org/2/library/logging.html\n+\n+Constructor arguments are:\n+\n+``level``\n+    A positive integer. Determines how serious the message is. Use one of the\n+    predefined values: ``DEBUG``, ``INFO``, ``WARNING``, ``ERROR``,\n+    ``CRITICAL``. If the level is greater or equal to ``ERROR``, then Django\n+    stops everything and doesn't allow to i.e. run a server. Messages with\n+    level lower than ``ERROR`` (i. e. warnings) are still reported, but Django\n+    allows will not stop you.\n+\n+``msg``\n+    A required single-line string.\n+\n+``hint``\n+    A single-line string or ``None`` if you cannot provide any hint. Note that\n+    this argument is required even if you pass ``None``::\n+\n+        Error('error message') # bad\n+        Error('error message', None) # good\n+        Error('error message', hint=None) # good (preferable)\n+\n+``obj``\n+    Optional. Point to the invalid object. The object should be a model, field\n+    or manager or any other object that defines ``__unicode__`` method (on\n+    Python 3 you need to define ``__str__`` method). The method is used while\n+    reporting all messages and its result precedes the message.\n+\n+``id``\n+    Optional string. Short and unique name of an issue. Follow \"applabel.X001\"\n+    style, where ``X`` is one of ``CEWID`` letters depending on the message\n+    level (``C`` for criticals, ``E`` for errors and so on), i.e. a warning\n+    may have ``applabel.W001`` id and an error can be ``applabel.E002``. The\n+    message number must be unique amount an app, so ``applabel.E001`` and\n+    ``anotherapp.E001`` are OK. Do not reuse one number for more than one\n+    message, e.g. avoid ``applabel.E001`` and ``applabel.W001``.\n+\n+There are shortcuts to make creating messages with common levels easier. You can\n+omit ``level`` argument because the level is indicated by the class name.\n+\n+.. class:: django.core.checks.Debug(msg, hint, obj=None, id=None)\n+.. class:: django.core.checks.Info(msg, hint, obj=None, id=None)\n+.. class:: django.core.checks.Warning(msg, hint, obj=None, id=None)\n+.. class:: django.core.checks.Error(msg, hint, obj=None, id=None)\n+.. class:: django.core.checks.Critical(msg, hint, obj=None, id=None)\n+\n+Messages are comparable. That allows you to easily write tests::\n+\n+    from django.core.checks import Error\n+    errors = checked_object.check()\n+    expected_errors = [\n+        Error(\n+            'an error',\n+            hint=None,\n+            obj=checked_object,\n+            id='myapp.E001',\n+        )\n+    ]\n+    self.assertEqual(errors, expected_errors)\n+\n+.. _`registering-checks`:\n+\n+Registering and labeling checks\n+-------------------------------\n+\n+Your check function need to be registered explicitly in system check\n+framework.\n+\n+.. method:: register(*tags)(function)\n+\n+Note that checks are performed just after loading apps and you need to\n+register them earlier. It's recommended to use ``register`` function as a\n+decorator so your function will be registered at the the time of importing the\n+module.\n+\n+You can pass as many tags to ``register`` as you want in order to label your\n+check. Tagging checks is useful since it allows you to run only a certain\n+group of checks, i.e. compatibility checks::\n+\n+    from checks import register\n+\n+    @register('compatibility')\n+    def my_check(apps, **kwargs):\n+        # ... perform compatibility checks and collect errors\n+        return errors\n+\n+Note that registered checks not only have to take ``**kwargs`` and return list\n+of messages, they also accept ``apps`` argument. If ``apps`` is not ``None``,\n+only the given set of apps should be validated otherwise all apps should be\n+checked.\n+\n+.. _field-checking:\n+\n+Field checks\n+------------\n+\n+You do not need to register check function if it's called from another check\n+function. It's easy in the case of fields, managers and models checks.\n+\n+You need to override ``check`` method: it should call the superclass (1),\n+perform its own checks which may end in new messages (2) and eventually return\n+list of all errors and warnings (3). It's recommended to delegate checks to\n+separated methods named i.e. ``_check_min_max_values``.\n+\n+Consider an example where you are implementing ``RangedIntegerField``. It adds\n+``min`` and ``max`` arguments to the constructor. You want to check if min\n+value is smaller or equal to max value. Here is a snippet of code showing how\n+you can implement this check::\n+\n+    from django.core import checks\n+    from django.db import models\n+\n+    class RangedIntegerField(models.IntegerField):\n+        def __init__(self, min=None, max=None, **kwargs):\n+            super(RangedIntegerField, self).__init__(**kwargs)\n+            self.min = min\n+            self.max = max\n+\n+        def check(self, **kwargs):\n+            errors = super(RangedIntegerField, self).check(**kwargs) # (1) call the superclass\n+            # (2) Do some custom checks and add messages to `errors`:\n+            errors.extend(self._check_min_max_values(**kwargs))\n+            return errors # (3) return all errors and warnings\n+\n+        def _check_min_max_values(self, **kwargs):\n+            if (self.min is not None and\n+                    self.max is not None and\n+                    self.min > self.max):\n+                return [\n+                    checks.Error(\n+                        'min greated than max.',\n+                        hint='Lower min or upper max.',\n+                        obj=self,\n+                        id='myapp.E001',\n+                    )\n+                ]\n+            return [] # When no error, return an empty list\n+\n+Database backend specific checks are performed in\n+``DatabaseValidation.check_field`` method. The API of ``DatabaseValidation``\n+is not formally stable and may change in future.\n+\n+Manager checks\n+--------------\n+\n+Manager checks are very similar to :ref:`field checking <field-checking>`. The\n+only difference is that your class needs to inherit from ``models.Manager``.\n+\n+Model checks\n+------------\n+\n+It's possible to check Model classes. Note that the framework verifies the\n+class, not it's instances. It works exactly the same as field checks except that\n+you need to use classmethods::\n+\n+    class MyModel(models.Model):\n+        @classmethod\n+        def check(cls, **kwargs):\n+            errors = super(MyModel, cls).check(**kwargs)\n+            # ... your own checks ...\n+            return errors\ndiff --git a/docs/ref/django-admin.txt b/docs/ref/django-admin.txt\nindex 5bc9a2b83ec8..8aed77cd8142 100644\n--- a/docs/ref/django-admin.txt\n+++ b/docs/ref/django-admin.txt\n@@ -89,18 +89,36 @@ documentation for the :djadminopt:`--verbosity` option.\n Available commands\n ==================\n \n-check\n------\n+check <appname appname ...>\n+---------------------------\n \n .. django-admin:: check\n \n .. versionadded:: 1.6\n \n-Performs a series of checks to verify a given setup (settings/application code)\n-is compatible with the current version of Django.\n+Uses the :ref:`system check framework <system-check-framework>` to validate\n+entire Django project and prints any messages (mostly errors and warnings).\n+It's an extended version of old ``validate`` and ``check`` commands.\n+\n+System checks framework validate all installed models (according to the\n+:setting:`INSTALLED_APPS` setting) and perform compatibility checks (is your\n+setup and application code compatible with the current Django version?) as\n+well as custom checks.\n+\n+You can check some apps by listing them::\n+\n+    python manage.py auth admin myapp\n+\n+If you do not specify any app, all apps will be checked.\n \n-Upon finding things that are incompatible or require notifying the user, it\n-issues a series of warnings.\n+.. django-admin-option:: --tag <tagname>\n+\n+:ref:`System check framework <system-check-framework>` performs many different\n+types of checks, i.e. model checks and compatibility checks. If you want to\n+perform only a certain kind of checks, follow ``--tag`` (``-t``) keyword\n+argument with the name of the check group (``models`` or ``compatibility``)::\n+\n+    python manage.py --tag security -t compatibility\n \n compilemessages\n ---------------\n@@ -765,9 +783,9 @@ The development server automatically reloads Python code for each request, as\n needed. You don't need to restart the server for code changes to take effect.\n \n When you start the server, and each time you change Python code while the\n-server is running, the server will validate all of your installed models. (See\n-the ``validate`` command below.) If the validator finds errors, it will print\n-them to standard output, but it won't stop the server.\n+server is running, the server will check entire Django project for errors (see\n+the ``check`` command below). If there will be any error, it will be printed\n+to standard output, but it won't stop the server.\n \n You can run as many servers as you want, as long as they're on separate ports.\n Just execute ``django-admin.py runserver`` more than once.\n@@ -1259,14 +1277,6 @@ To run on 1.2.3.4:7000 with a ``test`` fixture::\n The :djadminopt:`--noinput` option may be provided to suppress all user\n prompts.\n \n-validate\n---------\n-\n-.. django-admin:: validate\n-\n-Validates all installed models (according to the :setting:`INSTALLED_APPS`\n-setting) and prints validation errors to standard output.\n-\n Commands provided by applications\n =================================\n \ndiff --git a/docs/ref/index.txt b/docs/ref/index.txt\nindex 1d71b62f41d1..94881b9778f4 100644\n--- a/docs/ref/index.txt\n+++ b/docs/ref/index.txt\n@@ -5,6 +5,7 @@ API Reference\n .. toctree::\n    :maxdepth: 1\n \n+   checks\n    class-based-views/index\n    clickjacking\n    contrib/index\ndiff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 4c46f3a8cdf9..52f457514f87 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -1733,6 +1733,20 @@ The backend used for signing cookies and other data.\n \n See also the :doc:`/topics/signing` documentation.\n \n+.. setting:: SILENCED_SYSTEM_CHECKS\n+\n+SILENCED_SYSTEM_CHECKS\n+----------------------\n+\n+Default: '[]'\n+\n+List of identificators of messages generated by the system check framework\n+(i.e. ``[\"E001\"]``). Silencing light messages like warnings results in hiding\n+them. Silencing serious messages like errors or criticals means that Django\n+will let you i.e. run server, but the messages will be still printed.\n+\n+See also the :doc:`/ref/checks` documentation.\n+\n .. setting:: TEMPLATE_CONTEXT_PROCESSORS\n \n TEMPLATE_CONTEXT_PROCESSORS\n@@ -2725,6 +2739,7 @@ Error reporting\n * :setting:`IGNORABLE_404_URLS`\n * :setting:`MANAGERS`\n * :setting:`SEND_BROKEN_LINK_EMAILS`\n+* :setting:`SILENCED_SYSTEM_CHECKS`\n \n File uploads\n ------------\ndiff --git a/docs/releases/1.7.txt b/docs/releases/1.7.txt\nindex 0f1a5de073e7..6ca98cb50daf 100644\n--- a/docs/releases/1.7.txt\n+++ b/docs/releases/1.7.txt\n@@ -92,11 +92,29 @@ The :meth:`QuerySet.as_manager() <django.db.models.query.QuerySet.as_manager>`\n class method has been added to :ref:`create Manager with QuerySet methods\n <create-manager-with-queryset-methods>`.\n \n+<<<<<<< HEAD\n Using a custom manager when traversing reverse relations\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n \n It is now possible to :ref:`specify a custom manager\n <using-custom-reverse-manager>` when traversing a reverse relationship.\n+=======\n+New system check framework\n+~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+:doc:`System check framework </ref/checks>` is a set of static checks\n+<<<<<<< HEAD\n+validating mainly apps and models. It detects common problems and report\n+them providing hints. The framework is extensible and it's possible to\n+write custom checks.\n+>>>>>>> deprecated BaseCommand.{requires_model_validation, validate}\n+=======\n+detecting common problems (like invalid models) and reporting them providing\n+hints. The framework is extensible and it's possible to write custom checks.\n+>>>>>>> improved docs\n+\n+To perform system checks, you need to run ``check`` command. ``validate``\n+command is deprecated now.\n \n Admin shortcuts support time zones\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n@@ -584,3 +602,27 @@ The :class:`django.db.models.IPAddressField` and\n The ``BaseMemcachedCache._get_memcache_timeout()`` method has been renamed to\n ``get_backend_timeout()``. Despite being a private API, it will go through the\n normal deprecation.\n+\n+``validate``\n+------------\n+\n+``validate`` command is deprecated in favour of ``check`` command.\n+\n+``django.core.management.BaseCommand``\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+``requires_model_validation`` is deprecated in favour of a new\n+``requires_system_checks`` flag. If the latter flag is missing, then the\n+former flag value is used. Defining both ``requires_system_checks`` and\n+``requires_model_validation`` results in an error.\n+\n+``check`` method has replaced old ``validate`` method.\n+\n+``ModelAdmin.validator``\n+~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+``ModelAdmin.validator`` is deprecated in favour of new ``checks`` attribute.\n+\n+``django.db.backends.DatabaseValidation.validate_field``\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+This method is deprecated in favour of a new ``check_field`` method.\ndiff --git a/docs/topics/db/models.txt b/docs/topics/db/models.txt\nindex b0011e1098ed..5c52f9fd174a 100644\n--- a/docs/topics/db/models.txt\n+++ b/docs/topics/db/models.txt\n@@ -153,8 +153,8 @@ ones:\n     <Field.blank>`, the field will be required.\n \n :attr:`~Field.choices`\n-    An iterable (e.g., a list or tuple) of 2-tuples to use as choices for\n-    this field. If this is given, the default form widget will be a select box\n+    An iterable (e.g., a list or tuple) of 2-tuples to use as choices for this\n+    field. If this is given, the default form widget will be a select box\n     instead of the standard text field and will limit choices to the choices\n     given.\n \n@@ -957,7 +957,7 @@ The reverse name of the ``common.ChildA.m2m`` field will be\n reverse name of the ``rare.ChildB.m2m`` field will be ``rare_childb_related``.\n It is up to you how you use the ``'%(class)s'`` and ``'%(app_label)s`` portion\n to construct your related name, but if you forget to use it, Django will raise\n-errors when you validate your models (or run :djadmin:`migrate`).\n+errors when you perform system checks (or run :djadmin:`migrate`).\n \n If you don't specify a :attr:`~django.db.models.ForeignKey.related_name`\n attribute for a field in an abstract base class, the default reverse name will\n@@ -1050,7 +1050,7 @@ are putting those types of relations on a subclass of another model,\n you **must** specify the\n :attr:`~django.db.models.ForeignKey.related_name` attribute on each\n such field. If you forget, Django will raise an error when you run\n-:djadmin:`validate` or :djadmin:`migrate`.\n+:djadmin:`check` or :djadmin:`migrate`.\n \n For example, using the above ``Place`` class again, let's create another\n subclass with a :class:`~django.db.models.ManyToManyField`::\ndiff --git a/tests/admin_validation/__init__.py b/tests/admin_checks/__init__.py\nsimilarity index 100%\nrename from tests/admin_validation/__init__.py\nrename to tests/admin_checks/__init__.py\ndiff --git a/tests/admin_validation/models.py b/tests/admin_checks/models.py\nsimilarity index 96%\nrename from tests/admin_validation/models.py\nrename to tests/admin_checks/models.py\nindex d23849a2a85f..5db1747a642e 100644\n--- a/tests/admin_validation/models.py\n+++ b/tests/admin_checks/models.py\n@@ -1,5 +1,5 @@\n \"\"\"\n-Tests of ModelAdmin validation logic.\n+Tests of ModelAdmin system checks logic.\n \"\"\"\n \n from django.db import models\ndiff --git a/tests/admin_checks/tests.py b/tests/admin_checks/tests.py\nnew file mode 100644\nindex 000000000000..bcbc928d5c00\n--- /dev/null\n+++ b/tests/admin_checks/tests.py\n@@ -0,0 +1,439 @@\n+from __future__ import unicode_literals\n+\n+from django import forms\n+from django.contrib import admin\n+from django.core import checks\n+from django.core.exceptions import ImproperlyConfigured\n+from django.test import TestCase\n+from django.test.utils import str_prefix\n+\n+from .models import Song, Book, Album, TwoAlbumFKAndAnE, City, State\n+\n+\n+class SongForm(forms.ModelForm):\n+    pass\n+\n+\n+class ValidFields(admin.ModelAdmin):\n+    form = SongForm\n+    fields = ['title']\n+\n+\n+class ValidFormFieldsets(admin.ModelAdmin):\n+    def get_form(self, request, obj=None, **kwargs):\n+        class ExtraFieldForm(SongForm):\n+            name = forms.CharField(max_length=50)\n+        return ExtraFieldForm\n+\n+    fieldsets = (\n+        (None, {\n+            'fields': ('name',),\n+        }),\n+    )\n+\n+\n+class SystemChecksTestCase(TestCase):\n+\n+    def test_checks_are_performed(self):\n+        class MyAdmin(admin.ModelAdmin):\n+            @classmethod\n+            def check(self, model, **kwargs):\n+                return ['error!']\n+\n+        admin.site.register(Song, MyAdmin)\n+        try:\n+            errors = checks.run_checks()\n+            expected = ['error!']\n+            self.assertEqual(errors, expected)\n+        finally:\n+            admin.site.unregister(Song)\n+\n+    def test_readonly_and_editable(self):\n+        class SongAdmin(admin.ModelAdmin):\n+            readonly_fields = [\"original_release\"]\n+            fieldsets = [\n+                (None, {\n+                    \"fields\": [\"title\", \"original_release\"],\n+                }),\n+            ]\n+\n+        errors = SongAdmin.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_custom_modelforms_with_fields_fieldsets(self):\n+        \"\"\"\n+        # Regression test for #8027: custom ModelForms with fields/fieldsets\n+        \"\"\"\n+\n+        errors = ValidFields.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_custom_get_form_with_fieldsets(self):\n+        \"\"\"\n+        Ensure that the fieldsets checks are skipped when the ModelAdmin.get_form() method\n+        is overridden.\n+        Refs #19445.\n+        \"\"\"\n+\n+        errors = ValidFormFieldsets.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_exclude_values(self):\n+        \"\"\"\n+        Tests for basic system checks of 'exclude' option values (#12689)\n+        \"\"\"\n+\n+        class ExcludedFields1(admin.ModelAdmin):\n+            exclude = 'foo'\n+\n+        errors = ExcludedFields1.check(model=Book)\n+        expected = [\n+            checks.Error(\n+                '\"exclude\" must be a list or tuple.',\n+                hint=None,\n+                obj=ExcludedFields1,\n+                id='admin.E014',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_exclude_duplicate_values(self):\n+        class ExcludedFields2(admin.ModelAdmin):\n+            exclude = ('name', 'name')\n+\n+        errors = ExcludedFields2.check(model=Book)\n+        expected = [\n+            checks.Error(\n+                '\"exclude\" contains duplicate field(s).',\n+                hint=None,\n+                obj=ExcludedFields2,\n+                id='admin.E015',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_exclude_in_inline(self):\n+        class ExcludedFieldsInline(admin.TabularInline):\n+            model = Song\n+            exclude = 'foo'\n+\n+        class ExcludedFieldsAlbumAdmin(admin.ModelAdmin):\n+            model = Album\n+            inlines = [ExcludedFieldsInline]\n+\n+        errors = ExcludedFieldsAlbumAdmin.check(model=Album)\n+        expected = [\n+            checks.Error(\n+                '\"exclude\" must be a list or tuple.',\n+                hint=None,\n+                obj=ExcludedFieldsInline,\n+                id='admin.E014',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_exclude_inline_model_admin(self):\n+        \"\"\"\n+        Regression test for #9932 - exclude in InlineModelAdmin should not\n+        contain the ForeignKey field used in ModelAdmin.model\n+        \"\"\"\n+\n+        class SongInline(admin.StackedInline):\n+            model = Song\n+            exclude = ['album']\n+\n+        class AlbumAdmin(admin.ModelAdmin):\n+            model = Album\n+            inlines = [SongInline]\n+\n+        errors = AlbumAdmin.check(model=Album)\n+        expected = [\n+            checks.Error(\n+                'Cannot exclude the field \"album\", because it is the foreign key '\n+                    'to the parent model admin_checks.Album.',\n+                hint=None,\n+                obj=SongInline,\n+                id='admin.E201',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_app_label_in_admin_checks(self):\n+        \"\"\"\n+        Regression test for #15669 - Include app label in admin system check messages\n+        \"\"\"\n+\n+        class RawIdNonexistingAdmin(admin.ModelAdmin):\n+            raw_id_fields = ('nonexisting',)\n+\n+        errors = RawIdNonexistingAdmin.check(model=Album)\n+        expected = [\n+            checks.Error(\n+                '\"raw_id_fields[0]\" refers to field \"nonexisting\", which is '\n+                    'missing from model admin_checks.Album.',\n+                hint=None,\n+                obj=RawIdNonexistingAdmin,\n+                id='admin.E002',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_fk_exclusion(self):\n+        \"\"\"\n+        Regression test for #11709 - when testing for fk excluding (when exclude is\n+        given) make sure fk_name is honored or things blow up when there is more\n+        than one fk to the parent model.\n+        \"\"\"\n+\n+        class TwoAlbumFKAndAnEInline(admin.TabularInline):\n+            model = TwoAlbumFKAndAnE\n+            exclude = (\"e\",)\n+            fk_name = \"album1\"\n+\n+        class MyAdmin(admin.ModelAdmin):\n+            inlines = [TwoAlbumFKAndAnEInline]\n+\n+        errors = MyAdmin.check(model=Album)\n+        self.assertEqual(errors, [])\n+\n+    def test_inline_self_check(self):\n+        class TwoAlbumFKAndAnEInline(admin.TabularInline):\n+            model = TwoAlbumFKAndAnE\n+\n+        class MyAdmin(admin.ModelAdmin):\n+            inlines = [TwoAlbumFKAndAnEInline]\n+\n+        errors = MyAdmin.check(model=Album)\n+        expected = [\n+            checks.Error(\n+                '\"fk_name\" must be explicitly defined, because '\n+                    'admin_checks.TwoAlbumFKAndAnE has more than one '\n+                    'ForeignKey to admin_checks.Album.',\n+                hint=None,\n+                obj=TwoAlbumFKAndAnEInline,\n+                id='admin.E202',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_inline_with_specified(self):\n+        class TwoAlbumFKAndAnEInline(admin.TabularInline):\n+            model = TwoAlbumFKAndAnE\n+            fk_name = \"album1\"\n+\n+        class MyAdmin(admin.ModelAdmin):\n+            inlines = [TwoAlbumFKAndAnEInline]\n+\n+        errors = MyAdmin.check(model=Album)\n+        self.assertEqual(errors, [])\n+\n+    def test_readonly(self):\n+        class SongAdmin(admin.ModelAdmin):\n+            readonly_fields = (\"title\",)\n+\n+        errors = SongAdmin.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_readonly_on_method(self):\n+        def my_function(obj):\n+            pass\n+\n+        class SongAdmin(admin.ModelAdmin):\n+            readonly_fields = (my_function,)\n+\n+        errors = SongAdmin.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_readonly_on_modeladmin(self):\n+        class SongAdmin(admin.ModelAdmin):\n+            readonly_fields = (\"readonly_method_on_modeladmin\",)\n+\n+            def readonly_method_on_modeladmin(self, obj):\n+                pass\n+\n+        errors = SongAdmin.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_readonly_method_on_model(self):\n+        class SongAdmin(admin.ModelAdmin):\n+            readonly_fields = (\"readonly_method_on_model\",)\n+\n+        errors = SongAdmin.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_nonexistant_field(self):\n+        class SongAdmin(admin.ModelAdmin):\n+            readonly_fields = (\"title\", \"nonexistant\")\n+\n+        errors = SongAdmin.check(model=Song)\n+        expected = [\n+            checks.Error(\n+                '\"readonly_fields[1]\" is neither a callable nor an attribute '\n+                    'of \"SongAdmin\" nor found in the model admin_checks.Song.',\n+                hint=None,\n+                obj=SongAdmin,\n+                id='admin.E034',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_nonexistant_field_on_inline(self):\n+        class CityInline(admin.TabularInline):\n+            model = City\n+            readonly_fields=['i_dont_exist']  # Missing attribute\n+\n+        errors = CityInline.check(State)\n+        expected = [\n+            checks.Error(\n+                '\"readonly_fields[0]\" is neither a callable nor an attribute '\n+                    'of \"CityInline\" nor found in the model admin_checks.City.',\n+                hint=None,\n+                obj=CityInline,\n+                id='admin.E034',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_extra(self):\n+        class SongAdmin(admin.ModelAdmin):\n+            def awesome_song(self, instance):\n+                if instance.title == \"Born to Run\":\n+                    return \"Best Ever!\"\n+                return \"Status unknown.\"\n+\n+        errors = SongAdmin.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_readonly_lambda(self):\n+        class SongAdmin(admin.ModelAdmin):\n+            readonly_fields = (lambda obj: \"test\",)\n+\n+        errors = SongAdmin.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_graceful_m2m_fail(self):\n+        \"\"\"\n+        Regression test for #12203/#12237 - Fail more gracefully when a M2M field that\n+        specifies the 'through' option is included in the 'fields' or the 'fieldsets'\n+        ModelAdmin options.\n+        \"\"\"\n+\n+        class BookAdmin(admin.ModelAdmin):\n+            fields = ['authors']\n+\n+        errors = BookAdmin.check(model=Book)\n+        expected = [\n+            checks.Error(\n+                '\"fields\" cannot include the ManyToManyField \"authors\", '\n+                    'because \"authors\" manually specifies relationship model.',\n+                hint=None,\n+                obj=BookAdmin,\n+                id='admin.E013',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_cannot_include_through(self):\n+        class FieldsetBookAdmin(admin.ModelAdmin):\n+            fieldsets = (\n+                ('Header 1', {'fields': ('name',)}),\n+                ('Header 2', {'fields': ('authors',)}),\n+            )\n+\n+        errors = FieldsetBookAdmin.check(model=Book)\n+        expected = [\n+            checks.Error(\n+                '\"fieldsets[1][1][\\'fields\\']\" cannot include the ManyToManyField '\n+                    '\"authors\", because \"authors\" manually specifies relationship model.',\n+                hint=None,\n+                obj=FieldsetBookAdmin,\n+                id='admin.E013',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_nested_fields(self):\n+        class NestedFieldsAdmin(admin.ModelAdmin):\n+            fields = ('price', ('name', 'subtitle'))\n+\n+        errors = NestedFieldsAdmin.check(model=Book)\n+        self.assertEqual(errors, [])\n+\n+    def test_nested_fieldsets(self):\n+        class NestedFieldsetAdmin(admin.ModelAdmin):\n+            fieldsets = (\n+                ('Main', {'fields': ('price', ('name', 'subtitle'))}),\n+            )\n+\n+        errors = NestedFieldsetAdmin.check(model=Book)\n+        self.assertEqual(errors, [])\n+\n+    def test_explicit_through_override(self):\n+        \"\"\"\n+        Regression test for #12209 -- If the explicitly provided through model\n+        is specified as a string, the admin should still be able use\n+        Model.m2m_field.through\n+        \"\"\"\n+\n+        class AuthorsInline(admin.TabularInline):\n+            model = Book.authors.through\n+\n+        class BookAdmin(admin.ModelAdmin):\n+            inlines = [AuthorsInline]\n+\n+        errors = BookAdmin.check(model=Book)\n+        self.assertEqual(errors, [])\n+\n+    def test_non_model_fields(self):\n+        \"\"\"\n+        Regression for ensuring ModelAdmin.fields can contain non-model fields\n+        that broke with r11737\n+        \"\"\"\n+\n+        class SongForm(forms.ModelForm):\n+            extra_data = forms.CharField()\n+\n+        class FieldsOnFormOnlyAdmin(admin.ModelAdmin):\n+            form = SongForm\n+            fields = ['title', 'extra_data']\n+\n+        errors = FieldsOnFormOnlyAdmin.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_non_model_first_field(self):\n+        \"\"\"\n+        Regression for ensuring ModelAdmin.field can handle first elem being a\n+        non-model field (test fix for UnboundLocalError introduced with r16225).\n+        \"\"\"\n+\n+        class SongForm(forms.ModelForm):\n+            extra_data = forms.CharField()\n+            class Meta:\n+                model = Song\n+                fields = '__all__'\n+\n+\n+        class FieldsOnFormOnlyAdmin(admin.ModelAdmin):\n+            form = SongForm\n+            fields = ['extra_data', 'title']\n+\n+        errors = FieldsOnFormOnlyAdmin.check(model=Song)\n+        self.assertEqual(errors, [])\n+\n+    def test_validator_compatibility(self):\n+        class MyValidator(object):\n+            def validate(self, cls, model):\n+                raise ImproperlyConfigured(\"error!\")\n+\n+        class MyModelAdmin(admin.ModelAdmin):\n+            validator = MyValidator\n+\n+        errors = MyModelAdmin.check(model=Song)\n+        expected = [\n+            checks.Error(\n+                'error!',\n+                hint=None,\n+                obj=MyModelAdmin,\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\ndiff --git a/tests/check/__init__.py b/tests/admin_scripts/app_raising_messages/__init__.py\nsimilarity index 100%\nrename from tests/check/__init__.py\nrename to tests/admin_scripts/app_raising_messages/__init__.py\ndiff --git a/tests/admin_scripts/app_raising_messages/models.py b/tests/admin_scripts/app_raising_messages/models.py\nnew file mode 100644\nindex 000000000000..aece8a81765a\n--- /dev/null\n+++ b/tests/admin_scripts/app_raising_messages/models.py\n@@ -0,0 +1,27 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from django.core import checks\n+from django.db import models\n+\n+\n+class ModelRaisingMessages(models.Model):\n+    @classmethod\n+    def check(self, **kwargs):\n+        return [\n+            checks.Warning(\n+                'First warning',\n+                hint='Hint',\n+                obj='obj'\n+            ),\n+            checks.Warning(\n+                'Second warning',\n+                hint=None,\n+                obj='a'\n+            ),\n+            checks.Error(\n+                'An error',\n+                hint='Error hint',\n+                obj=None,\n+            )\n+        ]\ndiff --git a/tests/invalid_models/invalid_models/__init__.py b/tests/admin_scripts/app_raising_warning/__init__.py\nsimilarity index 100%\nrename from tests/invalid_models/invalid_models/__init__.py\nrename to tests/admin_scripts/app_raising_warning/__init__.py\ndiff --git a/tests/admin_scripts/app_raising_warning/models.py b/tests/admin_scripts/app_raising_warning/models.py\nnew file mode 100644\nindex 000000000000..8f58abe12773\n--- /dev/null\n+++ b/tests/admin_scripts/app_raising_warning/models.py\n@@ -0,0 +1,16 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from django.core import checks\n+from django.db import models\n+\n+\n+class ModelRaisingMessages(models.Model):\n+    @classmethod\n+    def check(self, **kwargs):\n+        return [\n+            checks.Warning(\n+                'A warning',\n+                hint=None,\n+            ),\n+        ]\ndiff --git a/tests/admin_scripts/management/commands/app_command.py b/tests/admin_scripts/management/commands/app_command.py\nindex d26df1264297..ce97578f1981 100644\n--- a/tests/admin_scripts/management/commands/app_command.py\n+++ b/tests/admin_scripts/management/commands/app_command.py\n@@ -3,7 +3,7 @@\n \n class Command(AppCommand):\n     help = 'Test Application-based commands'\n-    requires_model_validation = False\n+    requires_system_checks = False\n     args = '[appname ...]'\n \n     def handle_app(self, app, **options):\ndiff --git a/tests/admin_scripts/management/commands/base_command.py b/tests/admin_scripts/management/commands/base_command.py\nindex 2701f32a056f..568a8c1521f4 100644\n--- a/tests/admin_scripts/management/commands/base_command.py\n+++ b/tests/admin_scripts/management/commands/base_command.py\n@@ -10,7 +10,7 @@ class Command(BaseCommand):\n         make_option('--option_c','-c', action='store', dest='option_c', default='3'),\n     )\n     help = 'Test basic commands'\n-    requires_model_validation = False\n+    requires_system_checks = False\n     args = '[labels ...]'\n \n     def handle(self, *labels, **options):\ndiff --git a/tests/admin_scripts/management/commands/label_command.py b/tests/admin_scripts/management/commands/label_command.py\nindex 3bce1305bcda..9bba413ff3d3 100644\n--- a/tests/admin_scripts/management/commands/label_command.py\n+++ b/tests/admin_scripts/management/commands/label_command.py\n@@ -3,7 +3,7 @@\n \n class Command(LabelCommand):\n     help = \"Test Label-based commands\"\n-    requires_model_validation = False\n+    requires_system_checks = False\n     args = '<label>'\n \n     def handle_label(self, label, **options):\ndiff --git a/tests/admin_scripts/management/commands/noargs_command.py b/tests/admin_scripts/management/commands/noargs_command.py\nindex 9652099f9bac..ecc394554f52 100644\n--- a/tests/admin_scripts/management/commands/noargs_command.py\n+++ b/tests/admin_scripts/management/commands/noargs_command.py\n@@ -3,7 +3,7 @@\n \n class Command(NoArgsCommand):\n     help = \"Test No-args commands\"\n-    requires_model_validation = False\n+    requires_system_checks = False\n \n \n     def handle_noargs(self, **options):\ndiff --git a/tests/admin_scripts/management/commands/validation_command.py b/tests/admin_scripts/management/commands/validation_command.py\nnew file mode 100644\nindex 000000000000..e9ba86dc6cb9\n--- /dev/null\n+++ b/tests/admin_scripts/management/commands/validation_command.py\n@@ -0,0 +1,11 @@\n+from django.core.management.base import NoArgsCommand\n+\n+\n+class InvalidCommand(NoArgsCommand):\n+    help = (\"Test raising an error if both requires_system_checks \"\n+            \"and requires_model_validation are defined.\")\n+    requires_system_checks = True\n+    requires_model_validation = True\n+\n+    def handle_noargs(self, **options):\n+        pass\ndiff --git a/tests/admin_scripts/tests.py b/tests/admin_scripts/tests.py\nindex 9f7c8d7b5422..ba23b38086d1 100644\n--- a/tests/admin_scripts/tests.py\n+++ b/tests/admin_scripts/tests.py\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n \"\"\"\n A series of tests to establish that the command-line managment tools work as\n advertised - especially with regards to the handling of the DJANGO_SETTINGS_MODULE\n@@ -18,13 +20,15 @@\n import django\n from django import conf, get_version\n from django.conf import settings\n+from django.core.exceptions import ImproperlyConfigured\n from django.core.management import BaseCommand, CommandError, call_command\n from django.db import connection\n-from django.test.runner import DiscoverRunner\n from django.utils.encoding import force_text\n from django.utils._os import upath\n+from django.utils import six\n from django.utils.six import StringIO\n from django.test import LiveServerTestCase\n+from django.test.runner import DiscoverRunner\n \n \n test_dir = os.path.realpath(os.path.join(os.environ['DJANGO_TEST_TEMP_DIR'], 'test_project'))\n@@ -51,6 +55,7 @@ def write_settings(self, filename, apps=None, is_dir=False, sdict=None):\n                 'DATABASES',\n                 'ROOT_URLCONF',\n                 'SECRET_KEY',\n+                'TEST_RUNNER',  # We need to include TEST_RUNNER, otherwise we get a compatibility warning.\n             ]\n             for s in exports:\n                 if hasattr(settings, s):\n@@ -921,21 +926,36 @@ def test_custom_command_with_settings(self):\n         \"alternate: manage.py can execute user commands if settings are provided as argument\"\n         args = ['noargs_command', '--settings=alternate_settings']\n         out, err = self.run_manage(args)\n-        self.assertOutput(out, \"EXECUTE:NoArgsCommand options=[('no_color', False), ('pythonpath', None), ('settings', 'alternate_settings'), ('traceback', None), ('verbosity', '1')]\")\n+        verbosity = \"'1'\" if six.PY3 else \"u'1'\"\n+        expected_out = (\"EXECUTE:NoArgsCommand \"\n+            \"options=[('no_color', False), ('pythonpath', None), \"\n+            \"('settings', 'alternate_settings'), ('traceback', None), \"\n+            \"('verbosity', %s)]\" % verbosity)\n+        self.assertOutput(out, expected_out)\n         self.assertNoOutput(err)\n \n     def test_custom_command_with_environment(self):\n         \"alternate: manage.py can execute user commands if settings are provided in environment\"\n         args = ['noargs_command']\n         out, err = self.run_manage(args, 'alternate_settings')\n-        self.assertOutput(out, \"EXECUTE:NoArgsCommand options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        verbosity = \"'1'\" if six.PY3 else \"u'1'\"\n+        expected_out = (\"EXECUTE:NoArgsCommand \"\n+            \"options=[('no_color', False), ('pythonpath', None), \"\n+            \"('settings', None), ('traceback', None), \"\n+            \"('verbosity', %s)]\" % verbosity)\n+        self.assertOutput(out, expected_out)\n         self.assertNoOutput(err)\n \n     def test_custom_command_output_color(self):\n         \"alternate: manage.py output syntax color can be deactivated with the `--no-color` option\"\n         args = ['noargs_command', '--no-color', '--settings=alternate_settings']\n         out, err = self.run_manage(args)\n-        self.assertOutput(out, \"EXECUTE:NoArgsCommand options=[('no_color', True), ('pythonpath', None), ('settings', 'alternate_settings'), ('traceback', None), ('verbosity', '1')]\")\n+        verbosity = \"'1'\" if six.PY3 else \"u'1'\"\n+        expected_out = (\"EXECUTE:NoArgsCommand \"\n+            \"options=[('no_color', True), ('pythonpath', None), \"\n+            \"('settings', 'alternate_settings'), ('traceback', None), \"\n+            \"('verbosity', %s)]\" % verbosity)\n+        self.assertOutput(out, expected_out)\n         self.assertNoOutput(err)\n \n \n@@ -1051,49 +1071,122 @@ def test_builtin_command_with_attribute_error(self):\n         self.assertOutput(err, \"AttributeError: 'list' object has no attribute 'crash'\")\n \n \n-class ManageValidate(AdminScriptTestCase):\n+class ManageCheck(AdminScriptTestCase):\n+\n     def tearDown(self):\n         self.remove_settings('settings.py')\n \n     def test_nonexistent_app(self):\n-        \"manage.py validate reports an error on a non-existent app in INSTALLED_APPS\"\n-        self.write_settings('settings.py', apps=['admin_scriptz.broken_app'], sdict={'USE_I18N': False})\n-        args = ['validate']\n+        \"\"\" manage.py check reports an error on a non-existent app in\n+        INSTALLED_APPS \"\"\"\n+\n+        self.write_settings('settings.py',\n+            apps=['admin_scriptz.broken_app'],\n+            sdict={'USE_I18N': False})\n+        args = ['check']\n         out, err = self.run_manage(args)\n         self.assertNoOutput(out)\n+        self.assertOutput(err, 'ImportError')\n         self.assertOutput(err, 'No module named')\n         self.assertOutput(err, 'admin_scriptz')\n \n     def test_broken_app(self):\n-        \"manage.py validate reports an ImportError if an app's models.py raises one on import\"\n+        \"\"\" manage.py check reports an ImportError if an app's models.py\n+        raises one on import \"\"\"\n+\n         self.write_settings('settings.py', apps=['admin_scripts.broken_app'])\n-        args = ['validate']\n+        args = ['check']\n         out, err = self.run_manage(args)\n         self.assertNoOutput(out)\n         self.assertOutput(err, 'ImportError')\n \n     def test_complex_app(self):\n-        \"manage.py validate does not raise an ImportError validating a complex app with nested calls to load_app\"\n-        self.write_settings('settings.py',\n-            apps=['admin_scripts.complex_app', 'admin_scripts.simple_app'],\n-            sdict={'DEBUG': True})\n-        args = ['validate']\n+        \"\"\" manage.py check does not raise an ImportError validating a\n+        complex app with nested calls to load_app \"\"\"\n+\n+        self.write_settings(\n+            'settings.py',\n+            apps=[\n+                'admin_scripts.complex_app',\n+                'admin_scripts.simple_app',\n+                'django.contrib.admin',\n+                'django.contrib.auth',\n+                'django.contrib.contenttypes',\n+            ],\n+            sdict={\n+                'DEBUG': True\n+            }\n+        )\n+        args = ['check']\n         out, err = self.run_manage(args)\n         self.assertNoOutput(err)\n-        self.assertOutput(out, '0 errors found')\n+        self.assertEqual(out, 'System check identified no problems.\\n')\n \n     def test_app_with_import(self):\n-        \"manage.py validate does not raise errors when an app imports a base class that itself has an abstract base\"\n+        \"\"\" manage.py check does not raise errors when an app imports a base\n+        class that itself has an abstract base. \"\"\"\n+\n         self.write_settings('settings.py',\n             apps=['admin_scripts.app_with_import',\n                   'django.contrib.auth',\n                   'django.contrib.contenttypes',\n                   'django.contrib.sites'],\n             sdict={'DEBUG': True})\n-        args = ['validate']\n+        args = ['check']\n         out, err = self.run_manage(args)\n         self.assertNoOutput(err)\n-        self.assertOutput(out, '0 errors found')\n+        self.assertEqual(out, 'System check identified no problems.\\n')\n+\n+    def test_output_format(self):\n+        \"\"\" All errors/warnings should be sorted by level and by message. \"\"\"\n+\n+        self.write_settings('settings.py',\n+            apps=['admin_scripts.app_raising_messages'],\n+            sdict={'DEBUG': True})\n+        args = ['check']\n+        out, err = self.run_manage(args)\n+        expected_err = (\n+            \"CommandError: There are some issues:\\n\"\n+            \"\\n\"\n+            \"ERRORS:\\n\"\n+            \"?: An error\\n\"\n+            \"\\tHINT: Error hint\\n\"\n+            \"\\n\"\n+            \"WARNINGS:\\n\"\n+            \"a: Second warning\\n\"\n+            \"obj: First warning\\n\"\n+            \"\\tHINT: Hint\\n\"\n+            \"\\n\"\n+            \"System check identified 3 issues.\\n\"\n+        )\n+        self.assertEqual(err, expected_err)\n+        self.assertNoOutput(out)\n+\n+    def test_warning_does_not_halt(self):\n+        \"\"\"\n+        When there are only warnings or less serious messages, then Django\n+        should not prevent user from launching their project, so `check`\n+        command should not raise `CommandError` exception.\n+\n+        In this test we also test output format.\n+\n+        \"\"\"\n+\n+        self.write_settings('settings.py',\n+            apps=['admin_scripts.app_raising_warning'],\n+            sdict={'DEBUG': True})\n+        args = ['check']\n+        out, err = self.run_manage(args)\n+        expected_err = (\n+            \"There are some issues:\\n\"  # No \"CommandError: \" part\n+            \"\\n\"\n+            \"WARNINGS:\\n\"\n+            \"?: A warning\\n\"\n+            \"\\n\"\n+            \"System check identified 1 issue.\\n\"\n+        )\n+        self.assertEqual(err, expected_err)\n+        self.assertNoOutput(out)\n \n \n class CustomTestRunner(DiscoverRunner):\n@@ -1288,37 +1381,44 @@ def test_no_color(self):\n     def test_base_command(self):\n         \"User BaseCommands can execute when a label is provided\"\n         args = ['base_command', 'testlabel']\n-        out, err = self.run_manage(args)\n-        self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:BaseCommand labels=('testlabel',), options=[('no_color', False), ('option_a', '1'), ('option_b', '2'), ('option_c', '3'), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        expected_labels = \"('testlabel',)\"\n+        self._test_base_command(args, expected_labels)\n \n     def test_base_command_no_label(self):\n         \"User BaseCommands can execute when no labels are provided\"\n         args = ['base_command']\n-        out, err = self.run_manage(args)\n-        self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:BaseCommand labels=(), options=[('no_color', False), ('option_a', '1'), ('option_b', '2'), ('option_c', '3'), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        expected_labels = \"()\"\n+        self._test_base_command(args, expected_labels)\n \n     def test_base_command_multiple_label(self):\n         \"User BaseCommands can execute when no labels are provided\"\n         args = ['base_command', 'testlabel', 'anotherlabel']\n-        out, err = self.run_manage(args)\n-        self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:BaseCommand labels=('testlabel', 'anotherlabel'), options=[('no_color', False), ('option_a', '1'), ('option_b', '2'), ('option_c', '3'), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        expected_labels = \"('testlabel', 'anotherlabel')\"\n+        self._test_base_command(args, expected_labels)\n \n     def test_base_command_with_option(self):\n         \"User BaseCommands can execute with options when a label is provided\"\n         args = ['base_command', 'testlabel', '--option_a=x']\n-        out, err = self.run_manage(args)\n-        self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:BaseCommand labels=('testlabel',), options=[('no_color', False), ('option_a', 'x'), ('option_b', '2'), ('option_c', '3'), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        expected_labels = \"('testlabel',)\"\n+        self._test_base_command(args, expected_labels, option_a=\"'x'\")\n \n     def test_base_command_with_options(self):\n         \"User BaseCommands can execute with multiple options when a label is provided\"\n         args = ['base_command', 'testlabel', '-a', 'x', '--option_b=y']\n+        expected_labels = \"('testlabel',)\"\n+        self._test_base_command(args, expected_labels, option_a=\"'x'\", option_b=\"'y'\")\n+\n+    def _test_base_command(self, args, labels, option_a=\"'1'\", option_b=\"'2'\"):\n         out, err = self.run_manage(args)\n+        verbosity = \"'1'\" if six.PY3 else \"u'1'\"\n+\n+        expected_out = (\"EXECUTE:BaseCommand labels=%s, \"\n+            \"options=[('no_color', False), ('option_a', %s), ('option_b', %s), \"\n+            \"('option_c', '3'), ('pythonpath', None), ('settings', None), \"\n+            \"('traceback', None), ('verbosity', %s)]\"\n+            % (labels, option_a, option_b, verbosity))\n         self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:BaseCommand labels=('testlabel',), options=[('no_color', False), ('option_a', 'x'), ('option_b', 'y'), ('option_c', '3'), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        self.assertOutput(out, expected_out)\n \n     def test_base_run_from_argv(self):\n         \"\"\"\n@@ -1363,8 +1463,9 @@ def test_noargs(self):\n         \"NoArg Commands can be executed\"\n         args = ['noargs_command']\n         out, err = self.run_manage(args)\n+        verbosity = \"'1'\" if six.PY3 else \"u'1'\"\n         self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:NoArgsCommand options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        self.assertOutput(out, \"EXECUTE:NoArgsCommand options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', %s)]\" % verbosity)\n \n     def test_noargs_with_args(self):\n         \"NoArg Commands raise an error if an argument is provided\"\n@@ -1376,10 +1477,11 @@ def test_app_command(self):\n         \"User AppCommands can execute when a single app name is provided\"\n         args = ['app_command', 'auth']\n         out, err = self.run_manage(args)\n+        verbosity = \"'1'\" if six.PY3 else \"u'1'\"\n         self.assertNoOutput(err)\n         self.assertOutput(out, \"EXECUTE:AppCommand app=<module 'django.contrib.auth.models'\")\n         self.assertOutput(out, os.sep.join(['django', 'contrib', 'auth', 'models.py']))\n-        self.assertOutput(out, \"'>, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        self.assertOutput(out, \"'>, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', %s)]\" % verbosity)\n \n     def test_app_command_no_apps(self):\n         \"User AppCommands raise an error when no app name is provided\"\n@@ -1391,13 +1493,14 @@ def test_app_command_multiple_apps(self):\n         \"User AppCommands raise an error when multiple app names are provided\"\n         args = ['app_command', 'auth', 'contenttypes']\n         out, err = self.run_manage(args)\n+        verbosity = \"'1'\" if six.PY3 else \"u'1'\"\n         self.assertNoOutput(err)\n         self.assertOutput(out, \"EXECUTE:AppCommand app=<module 'django.contrib.auth.models'\")\n         self.assertOutput(out, os.sep.join(['django', 'contrib', 'auth', 'models.py']))\n-        self.assertOutput(out, \"'>, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        self.assertOutput(out, \"'>, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', %s)]\" % verbosity)\n         self.assertOutput(out, \"EXECUTE:AppCommand app=<module 'django.contrib.contenttypes.models'\")\n         self.assertOutput(out, os.sep.join(['django', 'contrib', 'contenttypes', 'models.py']))\n-        self.assertOutput(out, \"'>, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        self.assertOutput(out, \"'>, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', %s)]\" % verbosity)\n \n     def test_app_command_invalid_appname(self):\n         \"User AppCommands can execute when a single app name is provided\"\n@@ -1415,8 +1518,9 @@ def test_label_command(self):\n         \"User LabelCommands can execute when a label is provided\"\n         args = ['label_command', 'testlabel']\n         out, err = self.run_manage(args)\n+        verbosity = \"'1'\" if six.PY3 else \"u'1'\"\n         self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:LabelCommand label=testlabel, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        self.assertOutput(out, \"EXECUTE:LabelCommand label=testlabel, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', %s)]\" % verbosity)\n \n     def test_label_command_no_label(self):\n         \"User LabelCommands raise an error if no label is provided\"\n@@ -1428,9 +1532,15 @@ def test_label_command_multiple_label(self):\n         \"User LabelCommands are executed multiple times if multiple labels are provided\"\n         args = ['label_command', 'testlabel', 'anotherlabel']\n         out, err = self.run_manage(args)\n+        verbosity = \"'1'\" if six.PY3 else \"u'1'\"\n         self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:LabelCommand label=testlabel, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n-        self.assertOutput(out, \"EXECUTE:LabelCommand label=anotherlabel, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', '1')]\")\n+        self.assertOutput(out, \"EXECUTE:LabelCommand label=testlabel, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', %s)]\" % verbosity)\n+        self.assertOutput(out, \"EXECUTE:LabelCommand label=anotherlabel, options=[('no_color', False), ('pythonpath', None), ('settings', None), ('traceback', None), ('verbosity', %s)]\" % verbosity)\n+\n+    def test_requires_model_validation_and_requires_system_checks_both_defined(self):\n+        from .management.commands.validation_command import InvalidCommand\n+        self.assertRaises(ImproperlyConfigured, InvalidCommand)\n+\n \n class ArgumentOrder(AdminScriptTestCase):\n     \"\"\"Tests for 2-stage argument parsing scheme.\n@@ -1450,39 +1560,40 @@ def tearDown(self):\n         self.remove_settings('alternate_settings.py')\n \n     def test_setting_then_option(self):\n-        \"Options passed after settings are correctly handled\"\n+        \"\"\" Options passed after settings are correctly handled. \"\"\"\n         args = ['base_command', 'testlabel', '--settings=alternate_settings', '--option_a=x']\n-        out, err = self.run_manage(args)\n-        self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:BaseCommand labels=('testlabel',), options=[('no_color', False), ('option_a', 'x'), ('option_b', '2'), ('option_c', '3'), ('pythonpath', None), ('settings', 'alternate_settings'), ('traceback', None), ('verbosity', '1')]\")\n+        self._test(args)\n \n     def test_setting_then_short_option(self):\n-        \"Short options passed after settings are correctly handled\"\n-        args = ['base_command', 'testlabel', '--settings=alternate_settings', '--option_a=x']\n-        out, err = self.run_manage(args)\n-        self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:BaseCommand labels=('testlabel',), options=[('no_color', False), ('option_a', 'x'), ('option_b', '2'), ('option_c', '3'), ('pythonpath', None), ('settings', 'alternate_settings'), ('traceback', None), ('verbosity', '1')]\")\n+        \"\"\" Short options passed after settings are correctly handled. \"\"\"\n+        args = ['base_command', 'testlabel', '--settings=alternate_settings', '-a', 'x']\n+        self._test(args)\n \n     def test_option_then_setting(self):\n-        \"Options passed before settings are correctly handled\"\n+        \"\"\" Options passed before settings are correctly handled. \"\"\"\n         args = ['base_command', 'testlabel', '--option_a=x', '--settings=alternate_settings']\n-        out, err = self.run_manage(args)\n-        self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:BaseCommand labels=('testlabel',), options=[('no_color', False), ('option_a', 'x'), ('option_b', '2'), ('option_c', '3'), ('pythonpath', None), ('settings', 'alternate_settings'), ('traceback', None), ('verbosity', '1')]\")\n+        self._test(args)\n \n     def test_short_option_then_setting(self):\n-        \"Short options passed before settings are correctly handled\"\n+        \"\"\" Short options passed before settings are correctly handled. \"\"\"\n         args = ['base_command', 'testlabel', '-a', 'x', '--settings=alternate_settings']\n-        out, err = self.run_manage(args)\n-        self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:BaseCommand labels=('testlabel',), options=[('no_color', False), ('option_a', 'x'), ('option_b', '2'), ('option_c', '3'), ('pythonpath', None), ('settings', 'alternate_settings'), ('traceback', None), ('verbosity', '1')]\")\n+        self._test(args)\n \n     def test_option_then_setting_then_option(self):\n-        \"Options are correctly handled when they are passed before and after a setting\"\n+        \"\"\" Options are correctly handled when they are passed before and after\n+        a setting. \"\"\"\n         args = ['base_command', 'testlabel', '--option_a=x', '--settings=alternate_settings', '--option_b=y']\n+        self._test(args, option_b=\"'y'\")\n+\n+    def _test(self, args, option_b=\"'2'\"):\n         out, err = self.run_manage(args)\n+        verbosity = \"'1'\" if six.PY3 else \"u'1'\"\n+        expected_out = (\"EXECUTE:BaseCommand labels=('testlabel',), \"\n+            \"options=[('no_color', False), ('option_a', 'x'), ('option_b', %s), \"\n+            \"('option_c', '3'), ('pythonpath', None), ('settings', 'alternate_settings'), \"\n+            \"('traceback', None), ('verbosity', %s)]\" % (option_b, verbosity))\n         self.assertNoOutput(err)\n-        self.assertOutput(out, \"EXECUTE:BaseCommand labels=('testlabel',), options=[('no_color', False), ('option_a', 'x'), ('option_b', 'y'), ('option_c', '3'), ('pythonpath', None), ('settings', 'alternate_settings'), ('traceback', None), ('verbosity', '1')]\")\n+        self.assertOutput(out, expected_out)\n \n \n class StartProject(LiveServerTestCase, AdminScriptTestCase):\ndiff --git a/tests/admin_validation/tests.py b/tests/admin_validation/tests.py\ndeleted file mode 100644\nindex 8096d486d38a..000000000000\n--- a/tests/admin_validation/tests.py\n+++ /dev/null\n@@ -1,304 +0,0 @@\n-from __future__ import unicode_literals\n-\n-from django import forms\n-from django.contrib import admin\n-from django.core.exceptions import ImproperlyConfigured\n-from django.test import TestCase\n-from django.test.utils import str_prefix\n-\n-from .models import Song, Book, Album, TwoAlbumFKAndAnE, State, City\n-\n-\n-class SongForm(forms.ModelForm):\n-    pass\n-\n-class ValidFields(admin.ModelAdmin):\n-    form = SongForm\n-    fields = ['title']\n-\n-class ValidFormFieldsets(admin.ModelAdmin):\n-    def get_form(self, request, obj=None, **kwargs):\n-        class ExtraFieldForm(SongForm):\n-            name = forms.CharField(max_length=50)\n-        return ExtraFieldForm\n-\n-    fieldsets = (\n-        (None, {\n-            'fields': ('name',),\n-        }),\n-    )\n-\n-class ValidationTestCase(TestCase):\n-\n-    def test_readonly_and_editable(self):\n-        class SongAdmin(admin.ModelAdmin):\n-            readonly_fields = [\"original_release\"]\n-            fieldsets = [\n-                (None, {\n-                    \"fields\": [\"title\", \"original_release\"],\n-                }),\n-            ]\n-        SongAdmin.validate(Song)\n-\n-    def test_custom_modelforms_with_fields_fieldsets(self):\n-        \"\"\"\n-        # Regression test for #8027: custom ModelForms with fields/fieldsets\n-        \"\"\"\n-        ValidFields.validate(Song)\n-\n-    def test_custom_get_form_with_fieldsets(self):\n-        \"\"\"\n-        Ensure that the fieldsets validation is skipped when the ModelAdmin.get_form() method\n-        is overridden.\n-        Refs #19445.\n-        \"\"\"\n-        ValidFormFieldsets.validate(Song)\n-\n-    def test_exclude_values(self):\n-        \"\"\"\n-        Tests for basic validation of 'exclude' option values (#12689)\n-        \"\"\"\n-        class ExcludedFields1(admin.ModelAdmin):\n-            exclude = ('foo')\n-        self.assertRaisesMessage(ImproperlyConfigured,\n-            \"'ExcludedFields1.exclude' must be a list or tuple.\",\n-            ExcludedFields1.validate,\n-            Book)\n-\n-    def test_exclude_duplicate_values(self):\n-        class ExcludedFields2(admin.ModelAdmin):\n-            exclude = ('name', 'name')\n-        self.assertRaisesMessage(ImproperlyConfigured,\n-            \"There are duplicate field(s) in ExcludedFields2.exclude\",\n-            ExcludedFields2.validate,\n-            Book)\n-\n-    def test_exclude_in_inline(self):\n-        class ExcludedFieldsInline(admin.TabularInline):\n-            model = Song\n-            exclude = ('foo')\n-\n-        class ExcludedFieldsAlbumAdmin(admin.ModelAdmin):\n-            model = Album\n-            inlines = [ExcludedFieldsInline]\n-\n-        self.assertRaisesMessage(ImproperlyConfigured,\n-            \"'ExcludedFieldsInline.exclude' must be a list or tuple.\",\n-            ExcludedFieldsAlbumAdmin.validate,\n-            Album)\n-\n-    def test_exclude_inline_model_admin(self):\n-        \"\"\"\n-        # Regression test for #9932 - exclude in InlineModelAdmin\n-        # should not contain the ForeignKey field used in ModelAdmin.model\n-        \"\"\"\n-        class SongInline(admin.StackedInline):\n-            model = Song\n-            exclude = ['album']\n-\n-        class AlbumAdmin(admin.ModelAdmin):\n-            model = Album\n-            inlines = [SongInline]\n-\n-        self.assertRaisesMessage(ImproperlyConfigured,\n-            \"SongInline cannot exclude the field 'album' - this is the foreign key to the parent model admin_validation.Album.\",\n-            AlbumAdmin.validate,\n-            Album)\n-\n-    def test_app_label_in_admin_validation(self):\n-        \"\"\"\n-        Regression test for #15669 - Include app label in admin validation messages\n-        \"\"\"\n-        class RawIdNonexistingAdmin(admin.ModelAdmin):\n-            raw_id_fields = ('nonexisting',)\n-\n-        self.assertRaisesMessage(ImproperlyConfigured,\n-            \"'RawIdNonexistingAdmin.raw_id_fields' refers to field 'nonexisting' that is missing from model 'admin_validation.Album'.\",\n-            RawIdNonexistingAdmin.validate,\n-            Album)\n-\n-    def test_fk_exclusion(self):\n-        \"\"\"\n-        Regression test for #11709 - when testing for fk excluding (when exclude is\n-        given) make sure fk_name is honored or things blow up when there is more\n-        than one fk to the parent model.\n-        \"\"\"\n-        class TwoAlbumFKAndAnEInline(admin.TabularInline):\n-            model = TwoAlbumFKAndAnE\n-            exclude = (\"e\",)\n-            fk_name = \"album1\"\n-        class MyAdmin(admin.ModelAdmin):\n-            inlines = [TwoAlbumFKAndAnEInline]\n-        MyAdmin.validate(Album)\n-\n-\n-    def test_inline_self_validation(self):\n-        class TwoAlbumFKAndAnEInline(admin.TabularInline):\n-            model = TwoAlbumFKAndAnE\n-        class MyAdmin(admin.ModelAdmin):\n-            inlines = [TwoAlbumFKAndAnEInline]\n-\n-        self.assertRaisesMessage(Exception,\n-            \"<class 'admin_validation.models.TwoAlbumFKAndAnE'> has more than 1 ForeignKey to <class 'admin_validation.models.Album'>\",\n-            MyAdmin.validate, Album)\n-\n-    def test_inline_with_specified(self):\n-        class TwoAlbumFKAndAnEInline(admin.TabularInline):\n-            model = TwoAlbumFKAndAnE\n-            fk_name = \"album1\"\n-\n-        class MyAdmin(admin.ModelAdmin):\n-            inlines = [TwoAlbumFKAndAnEInline]\n-        MyAdmin.validate(Album)\n-\n-    def test_readonly(self):\n-        class SongAdmin(admin.ModelAdmin):\n-            readonly_fields = (\"title\",)\n-\n-        SongAdmin.validate(Song)\n-\n-    def test_readonly_on_method(self):\n-        def my_function(obj):\n-            pass\n-\n-        class SongAdmin(admin.ModelAdmin):\n-            readonly_fields = (my_function,)\n-\n-        SongAdmin.validate(Song)\n-\n-    def test_readonly_on_modeladmin(self):\n-        class SongAdmin(admin.ModelAdmin):\n-            readonly_fields = (\"readonly_method_on_modeladmin\",)\n-\n-            def readonly_method_on_modeladmin(self, obj):\n-                pass\n-\n-        SongAdmin.validate(Song)\n-\n-    def test_readonly_method_on_model(self):\n-        class SongAdmin(admin.ModelAdmin):\n-            readonly_fields = (\"readonly_method_on_model\",)\n-\n-        SongAdmin.validate(Song)\n-\n-    def test_nonexistant_field(self):\n-        class SongAdmin(admin.ModelAdmin):\n-            readonly_fields = (\"title\", \"nonexistant\")\n-\n-        self.assertRaisesMessage(ImproperlyConfigured,\n-            str_prefix(\"SongAdmin.readonly_fields[1], %(_)s'nonexistant' is not a callable \"\n-                       \"or an attribute of 'SongAdmin' or found in the model 'Song'.\"),\n-            SongAdmin.validate,\n-            Song)\n-\n-    def test_nonexistant_field_on_inline(self):\n-        class CityInline(admin.TabularInline):\n-            model = City\n-            readonly_fields=['i_dont_exist'] # Missing attribute\n-\n-        self.assertRaisesMessage(ImproperlyConfigured,\n-            str_prefix(\"CityInline.readonly_fields[0], %(_)s'i_dont_exist' is not a callable \"\n-                       \"or an attribute of 'CityInline' or found in the model 'City'.\"),\n-            CityInline.validate,\n-            City)\n-\n-    def test_extra(self):\n-        class SongAdmin(admin.ModelAdmin):\n-            def awesome_song(self, instance):\n-                if instance.title == \"Born to Run\":\n-                    return \"Best Ever!\"\n-                return \"Status unknown.\"\n-        SongAdmin.validate(Song)\n-\n-    def test_readonly_lambda(self):\n-        class SongAdmin(admin.ModelAdmin):\n-            readonly_fields = (lambda obj: \"test\",)\n-\n-        SongAdmin.validate(Song)\n-\n-    def test_graceful_m2m_fail(self):\n-        \"\"\"\n-        Regression test for #12203/#12237 - Fail more gracefully when a M2M field that\n-        specifies the 'through' option is included in the 'fields' or the 'fieldsets'\n-        ModelAdmin options.\n-        \"\"\"\n-\n-        class BookAdmin(admin.ModelAdmin):\n-            fields = ['authors']\n-\n-        self.assertRaisesMessage(ImproperlyConfigured,\n-            \"'BookAdmin.fields' can't include the ManyToManyField field 'authors' because 'authors' manually specifies a 'through' model.\",\n-            BookAdmin.validate,\n-            Book)\n-\n-    def test_cannot_include_through(self):\n-        class FieldsetBookAdmin(admin.ModelAdmin):\n-            fieldsets = (\n-                ('Header 1', {'fields': ('name',)}),\n-                ('Header 2', {'fields': ('authors',)}),\n-            )\n-        self.assertRaisesMessage(ImproperlyConfigured,\n-            \"'FieldsetBookAdmin.fieldsets[1][1]['fields']' can't include the ManyToManyField field 'authors' because 'authors' manually specifies a 'through' model.\",\n-            FieldsetBookAdmin.validate,\n-            Book)\n-\n-    def test_nested_fields(self):\n-        class NestedFieldsAdmin(admin.ModelAdmin):\n-            fields = ('price', ('name', 'subtitle'))\n-        NestedFieldsAdmin.validate(Book)\n-\n-    def test_nested_fieldsets(self):\n-        class NestedFieldsetAdmin(admin.ModelAdmin):\n-            fieldsets = (\n-                ('Main', {'fields': ('price', ('name', 'subtitle'))}),\n-            )\n-        NestedFieldsetAdmin.validate(Book)\n-\n-    def test_explicit_through_override(self):\n-        \"\"\"\n-        Regression test for #12209 -- If the explicitly provided through model\n-        is specified as a string, the admin should still be able use\n-        Model.m2m_field.through\n-        \"\"\"\n-\n-        class AuthorsInline(admin.TabularInline):\n-            model = Book.authors.through\n-\n-        class BookAdmin(admin.ModelAdmin):\n-            inlines = [AuthorsInline]\n-\n-        # If the through model is still a string (and hasn't been resolved to a model)\n-        # the validation will fail.\n-        BookAdmin.validate(Book)\n-\n-    def test_non_model_fields(self):\n-        \"\"\"\n-        Regression for ensuring ModelAdmin.fields can contain non-model fields\n-        that broke with r11737\n-        \"\"\"\n-        class SongForm(forms.ModelForm):\n-            extra_data = forms.CharField()\n-\n-        class FieldsOnFormOnlyAdmin(admin.ModelAdmin):\n-            form = SongForm\n-            fields = ['title', 'extra_data']\n-\n-        FieldsOnFormOnlyAdmin.validate(Song)\n-\n-    def test_non_model_first_field(self):\n-        \"\"\"\n-        Regression for ensuring ModelAdmin.field can handle first elem being a\n-        non-model field (test fix for UnboundLocalError introduced with r16225).\n-        \"\"\"\n-        class SongForm(forms.ModelForm):\n-            extra_data = forms.CharField()\n-            class Meta:\n-                model = Song\n-                fields = '__all__'\n-\n-\n-        class FieldsOnFormOnlyAdmin(admin.ModelAdmin):\n-            form = SongForm\n-            fields = ['extra_data', 'title']\n-\n-        FieldsOnFormOnlyAdmin.validate(Song)\ndiff --git a/tests/check/tests.py b/tests/check/tests.py\ndeleted file mode 100644\nindex 19b3840a9aaf..000000000000\n--- a/tests/check/tests.py\n+++ /dev/null\n@@ -1,127 +0,0 @@\n-from django.core.checks.compatibility import base\n-from django.core.checks.compatibility import django_1_6_0\n-from django.core.management.commands import check\n-from django.core.management import call_command\n-from django.db.models.fields import NOT_PROVIDED\n-from django.test import TestCase\n-\n-from .models import Book\n-\n-class StubCheckModule(object):\n-    # Has no ``run_checks`` attribute & will trigger a warning.\n-    __name__ = 'StubCheckModule'\n-\n-\n-class FakeWarnings(object):\n-    def __init__(self):\n-        self._warnings = []\n-\n-    def warn(self, message):\n-        self._warnings.append(message)\n-\n-\n-class CompatChecksTestCase(TestCase):\n-    def setUp(self):\n-        super(CompatChecksTestCase, self).setUp()\n-\n-        # We're going to override the list of checks to perform for test\n-        # consistency in the future.\n-        self.old_compat_checks = base.COMPAT_CHECKS\n-        base.COMPAT_CHECKS = [\n-            django_1_6_0,\n-        ]\n-\n-    def tearDown(self):\n-        # Restore what's supposed to be in ``COMPAT_CHECKS``.\n-        base.COMPAT_CHECKS = self.old_compat_checks\n-        super(CompatChecksTestCase, self).tearDown()\n-\n-    def test_check_test_runner_new_default(self):\n-        with self.settings(TEST_RUNNER='django.test.runner.DiscoverRunner'):\n-            result = django_1_6_0.check_test_runner()\n-            self.assertTrue(\"Django 1.6 introduced a new default test runner\" in result)\n-\n-    def test_check_test_runner_overridden(self):\n-        with self.settings(TEST_RUNNER='myapp.test.CustomRunnner'):\n-            self.assertEqual(django_1_6_0.check_test_runner(), None)\n-\n-    def test_run_checks_new_default(self):\n-        with self.settings(TEST_RUNNER='django.test.runner.DiscoverRunner'):\n-            result = django_1_6_0.run_checks()\n-            self.assertEqual(len(result), 1)\n-            self.assertTrue(\"Django 1.6 introduced a new default test runner\" in result[0])\n-\n-    def test_run_checks_overridden(self):\n-        with self.settings(TEST_RUNNER='myapp.test.CustomRunnner'):\n-            self.assertEqual(len(django_1_6_0.run_checks()), 0)\n-\n-    def test_boolean_field_default_value(self):\n-        with self.settings(TEST_RUNNER='myapp.test.CustomRunnner'):\n-            # We patch the field's default value to trigger the warning\n-            boolean_field = Book._meta.get_field('is_published')\n-            old_default = boolean_field.default\n-            try:\n-                boolean_field.default = NOT_PROVIDED\n-                result = django_1_6_0.run_checks()\n-                self.assertEqual(len(result), 1)\n-                self.assertTrue(\"You have not set a default value for one or more BooleanFields\" in result[0])\n-                self.assertTrue('check.Book: \"is_published\"' in result[0])\n-                # We did not patch the BlogPost.is_published field so\n-                # there should not be a warning about it\n-                self.assertFalse('check.BlogPost' in result[0])\n-            finally:\n-                # Restore the ``default``\n-                boolean_field.default = old_default\n-\n-    def test_check_compatibility(self):\n-        with self.settings(TEST_RUNNER='django.test.runner.DiscoverRunner'):\n-            result = base.check_compatibility()\n-            self.assertEqual(len(result), 1)\n-            self.assertTrue(\"Django 1.6 introduced a new default test runner\" in result[0])\n-\n-        with self.settings(TEST_RUNNER='myapp.test.CustomRunnner'):\n-            self.assertEqual(len(base.check_compatibility()), 0)\n-\n-    def test_check_compatibility_warning(self):\n-        # First, we're patching over the ``COMPAT_CHECKS`` with a stub which\n-        # will trigger the warning.\n-        base.COMPAT_CHECKS = [\n-            StubCheckModule(),\n-        ]\n-\n-        # Next, we unfortunately have to patch out ``warnings``.\n-        old_warnings = base.warnings\n-        base.warnings = FakeWarnings()\n-\n-        self.assertEqual(len(base.warnings._warnings), 0)\n-\n-        with self.settings(TEST_RUNNER='myapp.test.CustomRunnner'):\n-            self.assertEqual(len(base.check_compatibility()), 0)\n-\n-        self.assertEqual(len(base.warnings._warnings), 1)\n-        self.assertTrue(\"The 'StubCheckModule' module lacks a 'run_checks'\" in base.warnings._warnings[0])\n-\n-        # Restore the ``warnings``.\n-        base.warnings = old_warnings\n-\n-    def test_management_command(self):\n-        # Again, we unfortunately have to patch out ``warnings``. Different\n-        old_warnings = check.warnings\n-        check.warnings = FakeWarnings()\n-\n-        self.assertEqual(len(check.warnings._warnings), 0)\n-\n-        # Should not produce any warnings.\n-        with self.settings(TEST_RUNNER='myapp.test.CustomRunnner'):\n-            call_command('check')\n-\n-        self.assertEqual(len(check.warnings._warnings), 0)\n-\n-        with self.settings(TEST_RUNNER='django.test.runner.DiscoverRunner'):\n-            call_command('check')\n-\n-        self.assertEqual(len(check.warnings._warnings), 1)\n-        self.assertTrue(\"Django 1.6 introduced a new default test runner\" in check.warnings._warnings[0])\n-\n-        # Restore the ``warnings``.\n-        base.warnings = old_warnings\ndiff --git a/tests/check_framework/__init__.py b/tests/check_framework/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/check/models.py b/tests/check_framework/models.py\nsimilarity index 61%\nrename from tests/check/models.py\nrename to tests/check_framework/models.py\nindex 212b01bdd2b9..da2bf0c58d23 100644\n--- a/tests/check/models.py\n+++ b/tests/check_framework/models.py\n@@ -1,9 +1,19 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n from django.db import models\n \n+\n+class SimpleModel(models.Model):\n+    field = models.IntegerField()\n+    manager = models.manager.Manager()\n+\n+\n class Book(models.Model):\n     title = models.CharField(max_length=250)\n     is_published = models.BooleanField(default=False)\n \n+\n class BlogPost(models.Model):\n     title = models.CharField(max_length=250)\n     is_published = models.BooleanField(default=False)\ndiff --git a/tests/check_framework/tests.py b/tests/check_framework/tests.py\nnew file mode 100644\nindex 000000000000..65e445015bff\n--- /dev/null\n+++ b/tests/check_framework/tests.py\n@@ -0,0 +1,216 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from StringIO import StringIO\n+import sys\n+\n+from django.conf import settings\n+from django.core import checks\n+from django.core.checks import Error\n+from django.core.checks.messages import CheckMessage\n+from django.core.checks.registration import CheckFramework\n+from django.core.checks.compatibility.django_1_6_0 import check_1_6_compatibility\n+from django.core.management.base import CommandError\n+from django.core.management import call_command\n+from django.db.models.fields import NOT_PROVIDED\n+from django.test import TestCase\n+from django.test.utils import override_settings, override_system_checks\n+from django.utils.encoding import force_text\n+\n+from .models import SimpleModel, Book\n+\n+\n+class DummyObj(object):\n+    def __repr__(self):\n+        return \"obj\"\n+\n+\n+class SystemCheckFrameworkTests(TestCase):\n+\n+    def test_register_and_run_checks(self):\n+        calls = [0]\n+\n+        framework = CheckFramework()\n+        @framework.register()\n+        def f(**kwargs):\n+            calls[0] += 1\n+            return [1, 2, 3]\n+        errors = framework.run_checks()\n+        self.assertEqual(errors, [1, 2, 3])\n+        self.assertEqual(calls[0], 1)\n+\n+\n+class MessageTests(TestCase):\n+\n+    def test_printing(self):\n+        e = Error(\"Message\", hint=\"Hint\", obj=DummyObj())\n+        expected = \"obj: Message\\n\\tHINT: Hint\"\n+        self.assertEqual(force_text(e), expected)\n+\n+    def test_printing_no_hint(self):\n+        e = Error(\"Message\", hint=None, obj=DummyObj())\n+        expected = \"obj: Message\"\n+        self.assertEqual(force_text(e), expected)\n+\n+    def test_printing_no_object(self):\n+        e = Error(\"Message\", hint=\"Hint\", obj=None)\n+        expected = \"?: Message\\n\\tHINT: Hint\"\n+        self.assertEqual(force_text(e), expected)\n+\n+    def test_printing_with_given_id(self):\n+        e = Error(\"Message\", hint=\"Hint\", obj=DummyObj(), id=\"ID\")\n+        expected = \"obj: (ID) Message\\n\\tHINT: Hint\"\n+        self.assertEqual(force_text(e), expected)\n+\n+    def test_printing_field_error(self):\n+        field = SimpleModel._meta.get_field('field')\n+        e = Error(\"Error\", hint=None, obj=field)\n+        expected = \"check_framework.SimpleModel.field: Error\"\n+        self.assertEqual(force_text(e), expected)\n+\n+    def test_printing_model_error(self):\n+        e = Error(\"Error\", hint=None, obj=SimpleModel)\n+        expected = \"check_framework.SimpleModel: Error\"\n+        self.assertEqual(force_text(e), expected)\n+\n+    def test_printing_manager_error(self):\n+        manager = SimpleModel.manager\n+        e = Error(\"Error\", hint=None, obj=manager)\n+        expected = \"check_framework.SimpleModel.manager: Error\"\n+        self.assertEqual(force_text(e), expected)\n+\n+\n+class Django_1_6_0_CompatibilityChecks(TestCase):\n+\n+    @override_settings(TEST_RUNNER='django.test.runner.DiscoverRunner')\n+    def test_test_runner_new_default(self):\n+        errors = check_1_6_compatibility()\n+        self.assertEqual(errors, [])\n+\n+    @override_settings(TEST_RUNNER='myapp.test.CustomRunner')\n+    def test_test_runner_overriden(self):\n+        errors = check_1_6_compatibility()\n+        self.assertEqual(errors, [])\n+\n+    def test_test_runner_not_set_explicitly(self):\n+        # We remove the TEST_RUNNER attribute from custom settings module.\n+        old_test_runner = settings._wrapped.TEST_RUNNER\n+        del settings._wrapped.TEST_RUNNER\n+\n+        try:\n+            errors = check_1_6_compatibility()\n+            expected = [\n+                checks.Warning(\n+                   'You have not explicitly set \"TEST_RUNNER\". In Django 1.6, '\n+                        'there is a new test runner (\"django.test.runner.DiscoverRunner\") '\n+                        'by default. You should ensure your tests are still all '\n+                        'running & behaving as expected. See '\n+                        'https://docs.djangoproject.com/en/dev/releases/1.6/#discovery-of-tests-in-any-test-module '\n+                        'for more information.',\n+                    hint=None,\n+                    obj=None,\n+                    id='W047',\n+                )\n+            ]\n+            self.assertEqual(errors, expected)\n+        finally:\n+            # Restore TEST_RUNNER value\n+            settings._wrapped.TEST_RUNNER = old_test_runner\n+\n+    def test_boolean_field_default_value(self):\n+        with self.settings(TEST_RUNNER='myapp.test.CustomRunnner'):\n+            # We patch the field's default value to trigger the warning\n+            boolean_field = Book._meta.get_field('is_published')\n+            old_default = boolean_field.default\n+            try:\n+                boolean_field.default = NOT_PROVIDED\n+                errors = check_1_6_compatibility()\n+                expected = [\n+                    checks.Warning(\n+                        'The field has not set a default value. In Django 1.6 '\n+                            'the default value of BooleanField was changed from '\n+                            'False to Null when Field.default is not defined. '\n+                            'See https://docs.djangoproject.com/en/1.6/ref/models/fields/#booleanfield '\n+                            'for more information.',\n+                        hint=None,\n+                        obj=boolean_field,\n+                        id='W048',\n+                    )\n+                ]\n+                self.assertEqual(errors, expected)\n+            finally:\n+                # Restore the ``default``\n+                boolean_field.default = old_default\n+\n+\n+def simple_system_check(**kwargs):\n+    simple_system_check.kwargs = kwargs\n+    return []\n+\n+\n+def tagged_system_check(**kwargs):\n+    tagged_system_check.kwargs = kwargs\n+    return []\n+tagged_system_check.tags = ['simpletag']\n+\n+\n+class CheckCommandTests(TestCase):\n+\n+    def setUp(self):\n+        simple_system_check.kwargs = None\n+        tagged_system_check.kwargs = None\n+        self.old_stdout, self.old_stderr = sys.stdout, sys.stderr\n+        sys.stdout, sys.stderr = StringIO(), StringIO()\n+\n+    def tearDown(self):\n+        sys.stdout, sys.stderr = self.old_stdout, self.old_stderr\n+\n+    @override_system_checks([simple_system_check, tagged_system_check])\n+    def test_simple_call(self):\n+        call_command('check')\n+        self.assertEqual(simple_system_check.kwargs, {'apps': None})\n+        self.assertEqual(tagged_system_check.kwargs, {'apps': None})\n+\n+    @override_system_checks([simple_system_check, tagged_system_check])\n+    def test_given_app(self):\n+        call_command('check', 'auth', 'admin')\n+        self.assertEqual(simple_system_check.kwargs, {'apps': ('auth', 'admin')})\n+        self.assertEqual(tagged_system_check.kwargs, {'apps': ('auth', 'admin')})\n+\n+    @override_system_checks([simple_system_check, tagged_system_check])\n+    def test_given_tag(self):\n+        call_command('check', tags=['simpletag'])\n+        self.assertEqual(simple_system_check.kwargs, None)\n+        self.assertEqual(tagged_system_check.kwargs, {'apps': None})\n+\n+    @override_system_checks([simple_system_check, tagged_system_check])\n+    def test_invalid_tag(self):\n+        self.assertRaises(CommandError, call_command, 'check', tags=['missingtag'])\n+\n+\n+def custom_system_check(apps, **kwargs):\n+    return [\n+        Error(\n+            'Error',\n+            hint=None,\n+            id='mycheck.E001',\n+        )\n+    ]\n+\n+\n+class SilencingCheckTests(TestCase):\n+\n+    def setUp(self):\n+        self.old_stdout, self.old_stderr = sys.stdout, sys.stderr\n+        sys.stdout, sys.stderr = StringIO(), StringIO()\n+\n+    def tearDown(self):\n+        sys.stdout, sys.stderr = self.old_stdout, self.old_stderr\n+\n+    @override_settings(SILENCED_SYSTEM_CHECKS=['mycheck.E001'])\n+    @override_system_checks([custom_system_check])\n+    def test_simple(self):\n+        try:\n+            call_command('check')\n+        except CommandError:\n+            self.fail(\"The mycheck.E001 check should be silenced.\")\ndiff --git a/tests/contenttypes_tests/tests.py b/tests/contenttypes_tests/tests.py\nindex 63f02697df1c..bffde1e25ef5 100644\n--- a/tests/contenttypes_tests/tests.py\n+++ b/tests/contenttypes_tests/tests.py\n@@ -1,10 +1,18 @@\n-from __future__ import unicode_literals\n+# -*- coding: utf-8 -*-\n+from __future__ import absolute_import, unicode_literals\n \n+from django.contrib.contenttypes import generic\n from django.contrib.contenttypes.models import ContentType\n+from django.core import checks\n+from django.db import models\n+from django.db.models.loading import cache\n from django.test import TestCase\n+from django.test.utils import override_settings\n+from django.utils.encoding import force_str\n \n from .models import Author, Article\n \n+\n class ContentTypesViewsTests(TestCase):\n     fixtures = ['testdata.json']\n     urls = 'contenttypes_tests.urls'\n@@ -45,3 +53,301 @@ def test_bad_content_type(self):\n         short_url = '/shortcut/%s/%s/' % (42424242, an_author.pk)\n         response = self.client.get(short_url)\n         self.assertEqual(response.status_code, 404)\n+\n+\n+class IsolatedModelsTestCase(TestCase):\n+\n+    def setUp(self):\n+        # If you create a model in a test, the model is accessible in other\n+        # tests. To avoid this, we need to mock list of all models created in\n+        # `contenttypes_tests` module.\n+        self._old_app_models_cache = cache.app_models['contenttypes_tests']\n+        cache.app_models['contenttypes_tests'] = {}\n+        self._old_models_cache = cache._get_models_cache\n+        cache._get_models_cache = {}\n+\n+    def tearDown(self):\n+        cache.app_models['contenttypes_tests'] = self._old_app_models_cache\n+        cache._get_models_cache = self._old_models_cache\n+\n+\n+class GenericForeignKeyTests(IsolatedModelsTestCase):\n+\n+    def test_str(self):\n+        class Model(models.Model):\n+            field = generic.GenericForeignKey()\n+        expected = \"contenttypes_tests.Model.field\"\n+        actual = force_str(Model.field)\n+        self.assertEqual(expected, actual)\n+\n+    def test_missing_content_type_field(self):\n+        class TaggedItem(models.Model):\n+            # no content_type field\n+            object_id = models.PositiveIntegerField()\n+            content_object = generic.GenericForeignKey()\n+\n+        errors = TaggedItem.content_object.check()\n+        expected = [\n+            checks.Error(\n+                'The field refers to TaggedItem.content_type field which is missing.',\n+                hint=None,\n+                obj=TaggedItem.content_object,\n+                id='contenttypes.E005',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_invalid_content_type_field(self):\n+        class Model(models.Model):\n+            content_type = models.IntegerField()  # should be ForeignKey\n+            object_id = models.PositiveIntegerField()\n+            content_object = generic.GenericForeignKey(\n+                'content_type', 'object_id')\n+\n+        errors = Model.content_object.check()\n+        expected = [\n+            checks.Error(\n+                '\"content_type\" field is used by a GenericForeignKey '\n+                    'as content type field and therefore it must be '\n+                    'a ForeignKey.',\n+                hint=None,\n+                obj=Model.content_object,\n+                id='contenttypes.E006',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_content_type_field_pointing_to_wrong_model(self):\n+        class Model(models.Model):\n+            content_type = models.ForeignKey('self')  # should point to ContentType\n+            object_id = models.PositiveIntegerField()\n+            content_object = generic.GenericForeignKey(\n+                'content_type', 'object_id')\n+\n+        errors = Model.content_object.check()\n+        expected = [\n+            checks.Error(\n+                '\"content_type\" field is used by a GenericForeignKey '\n+                    'as content type field and therefore it must be '\n+                    'a ForeignKey to ContentType.',\n+                hint=None,\n+                obj=Model.content_object,\n+                id='contenttypes.E007',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_missing_object_id_field(self):\n+        class TaggedItem(models.Model):\n+            content_type = models.ForeignKey(ContentType)\n+            # missing object_id field\n+            content_object = generic.GenericForeignKey()\n+\n+        errors = TaggedItem.content_object.check()\n+        expected = [\n+            checks.Error(\n+                'The field refers to \"object_id\" field which is missing.',\n+                hint=None,\n+                obj=TaggedItem.content_object,\n+                id='contenttypes.E001',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_field_name_ending_with_underscore(self):\n+        class Model(models.Model):\n+            content_type = models.ForeignKey(ContentType)\n+            object_id = models.PositiveIntegerField()\n+            content_object_ = generic.GenericForeignKey(\n+                'content_type', 'object_id')\n+\n+        errors = Model.content_object_.check()\n+        expected = [\n+            checks.Error(\n+                'Field names must not end with underscores.',\n+                hint=None,\n+                obj=Model.content_object_,\n+                id='contenttypes.E002',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_generic_foreign_key_checks_are_performed(self):\n+        class MyGenericForeignKey(generic.GenericForeignKey):\n+            def check(self, **kwargs):\n+                return ['performed!']\n+\n+        class Model(models.Model):\n+            content_object = MyGenericForeignKey()\n+\n+        errors = checks.run_checks()\n+        self.assertEqual(errors, ['performed!'])\n+\n+\n+class GenericRelationshipTests(IsolatedModelsTestCase):\n+\n+    def test_valid_generic_relationship(self):\n+        class TaggedItem(models.Model):\n+            content_type = models.ForeignKey(ContentType)\n+            object_id = models.PositiveIntegerField()\n+            content_object = generic.GenericForeignKey()\n+\n+        class Bookmark(models.Model):\n+            tags = generic.GenericRelation('TaggedItem')\n+\n+        errors = Bookmark.tags.field.check()\n+        self.assertEqual(errors, [])\n+\n+    def test_valid_generic_relationship_with_explicit_fields(self):\n+        class TaggedItem(models.Model):\n+            custom_content_type = models.ForeignKey(ContentType)\n+            custom_object_id = models.PositiveIntegerField()\n+            content_object = generic.GenericForeignKey(\n+                'custom_content_type', 'custom_object_id')\n+\n+        class Bookmark(models.Model):\n+            tags = generic.GenericRelation('TaggedItem',\n+                content_type_field='custom_content_type',\n+                object_id_field='custom_object_id')\n+\n+        errors = Bookmark.tags.field.check()\n+        self.assertEqual(errors, [])\n+\n+    def test_pointing_to_missing_model(self):\n+        class Model(models.Model):\n+            rel = generic.GenericRelation('MissingModel')\n+\n+        errors = Model.rel.field.check()\n+        expected = [\n+            checks.Error(\n+                'The field has a relation with model MissingModel, '\n+                    'which has either not been installed or is abstract.',\n+                hint='Ensure that you did not misspell the model name and '\n+                    'the model is not abstract. Does your INSTALLED_APPS '\n+                    'setting contain the app where MissingModel is defined?',\n+                obj=Model.rel.field,\n+                id='E030',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_valid_self_referential_generic_relationship(self):\n+        class Model(models.Model):\n+            rel = generic.GenericRelation('Model')\n+            content_type = models.ForeignKey(ContentType)\n+            object_id = models.PositiveIntegerField()\n+            content_object = generic.GenericForeignKey(\n+                'content_type', 'object_id')\n+\n+        errors = Model.rel.field.check()\n+        self.assertEqual(errors, [])\n+\n+    def test_missing_content_type_field(self):\n+        class TaggedItem(models.Model):\n+            # no content_type field\n+            object_id = models.PositiveIntegerField()\n+            content_object = generic.GenericForeignKey()\n+\n+        class Bookmark(models.Model):\n+            tags = generic.GenericRelation('TaggedItem')\n+\n+        errors = Bookmark.tags.field.check()\n+        expected = [\n+            checks.Error(\n+                'The field refers to TaggedItem.content_type field which is missing.',\n+                hint=None,\n+                obj=Bookmark.tags.field,\n+                id='contenttypes.E005',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_missing_object_id_field(self):\n+        class TaggedItem(models.Model):\n+            content_type = models.ForeignKey(ContentType)\n+            # missing object_id field\n+            content_object = generic.GenericForeignKey()\n+\n+        class Bookmark(models.Model):\n+            tags = generic.GenericRelation('TaggedItem')\n+\n+        errors = Bookmark.tags.field.check()\n+        expected = [\n+            checks.Error(\n+                'The field refers to TaggedItem.object_id field which is missing.',\n+                hint=None,\n+                obj=Bookmark.tags.field,\n+                id='contenttypes.E003',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_missing_generic_foreign_key(self):\n+        class TaggedItem(models.Model):\n+            content_type = models.ForeignKey(ContentType)\n+            object_id = models.PositiveIntegerField()\n+\n+        class Bookmark(models.Model):\n+            tags = generic.GenericRelation('TaggedItem')\n+\n+        errors = Bookmark.tags.field.check()\n+        expected = [\n+            checks.Warning(\n+                'The field defines a generic relation with the model '\n+                    'contenttypes_tests.TaggedItem, but the model lacks '\n+                    'GenericForeignKey.',\n+                hint=None,\n+                obj=Bookmark.tags.field,\n+                id='contenttypes.E004',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    @override_settings(TEST_SWAPPED_MODEL='contenttypes_tests.Replacement')\n+    def test_pointing_to_swapped_model(self):\n+        class Replacement(models.Model):\n+            pass\n+\n+        class SwappedModel(models.Model):\n+            content_type = models.ForeignKey(ContentType)\n+            object_id = models.PositiveIntegerField()\n+            content_object = generic.GenericForeignKey()\n+\n+            class Meta:\n+                swappable = 'TEST_SWAPPED_MODEL'\n+\n+        class Model(models.Model):\n+            rel = generic.GenericRelation('SwappedModel')\n+\n+        errors = Model.rel.field.check()\n+        expected = [\n+            checks.Error(\n+                'The field defines a relation with the model '\n+                    'contenttypes_tests.SwappedModel, '\n+                    'which has been swapped out.',\n+                hint='Update the relation to point at settings.TEST_SWAPPED_MODEL',\n+                obj=Model.rel.field,\n+                id='E029',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_field_name_ending_with_underscore(self):\n+        class TaggedItem(models.Model):\n+            content_type = models.ForeignKey(ContentType)\n+            object_id = models.PositiveIntegerField()\n+            content_object = generic.GenericForeignKey()\n+\n+        class InvalidBookmark(models.Model):\n+            tags_ = generic.GenericRelation('TaggedItem')\n+\n+        errors = InvalidBookmark.tags_.field.check()\n+        expected = [\n+            checks.Error(\n+                'Field names must not end with underscores.',\n+                hint=None,\n+                obj=InvalidBookmark.tags_.field,\n+                id='E001',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\ndiff --git a/tests/fixtures_model_package/tests.py b/tests/fixtures_model_package/tests.py\nindex 2fa1fd10ef10..6b95833f9aa8 100644\n--- a/tests/fixtures_model_package/tests.py\n+++ b/tests/fixtures_model_package/tests.py\n@@ -5,6 +5,7 @@\n from django.core import management\n from django.db import transaction\n from django.test import TestCase, TransactionTestCase\n+from django.test.utils import override_system_checks\n from django.utils.six import StringIO\n \n from .models import Article, Book\n@@ -30,6 +31,7 @@ class TestNoInitialDataLoading(TransactionTestCase):\n \n     available_apps = ['fixtures_model_package']\n \n+    @override_system_checks([])\n     def test_migrate(self):\n         with transaction.atomic():\n             Book.objects.all().delete()\n@@ -42,6 +44,7 @@ def test_migrate(self):\n             self.assertQuerysetEqual(Book.objects.all(), [])\n \n \n+    @override_system_checks([])\n     def test_flush(self):\n         # Test presence of fixture (flush called by TransactionTestCase)\n         self.assertQuerysetEqual(\ndiff --git a/tests/inline_formsets/tests.py b/tests/inline_formsets/tests.py\nindex a16488dc7930..0143d7ed9528 100644\n--- a/tests/inline_formsets/tests.py\n+++ b/tests/inline_formsets/tests.py\n@@ -123,8 +123,9 @@ def test_exception_on_unspecified_foreign_key(self):\n         Child has two ForeignKeys to Parent, so if we don't specify which one\n         to use for the inline formset, we should get an exception.\n         \"\"\"\n-        six.assertRaisesRegex(self, Exception,\n-            \"<class 'inline_formsets.models.Child'> has more than 1 ForeignKey to <class 'inline_formsets.models.Parent'>\",\n+        six.assertRaisesRegex(self, ValueError,\n+            '\"fk_name\" must be explicitly defined, because inline_formsets.Child '\n+                'has more than one ForeignKey to inline_formsets.Parent.',\n             inlineformset_factory, Parent, Child\n         )\n \n@@ -143,8 +144,8 @@ def test_non_foreign_key_field(self):\n         If the field specified in fk_name is not a ForeignKey, we should get an\n         exception.\n         \"\"\"\n-        six.assertRaisesRegex(self, Exception,\n-            \"<class 'inline_formsets.models.Child'> has no field named 'test'\",\n+        six.assertRaisesRegex(self, ValueError,\n+            '\"fk_name\" refers to \"test\" field, which is missing from model inline_formsets.Child.',\n             inlineformset_factory, Parent, Child, fk_name='test'\n         )\n \ndiff --git a/tests/invalid_models/__init__.py b/tests/invalid_models/__init__.py\nindex e69de29bb2d1..934589e0364a 100644\n--- a/tests/invalid_models/__init__.py\n+++ b/tests/invalid_models/__init__.py\n@@ -0,0 +1,17 @@\n+# -*- encoding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from django.db.models.loading import cache\n+from django.test import TestCase\n+\n+\n+class IsolatedModelsTestCase(TestCase):\n+\n+    def setUp(self):\n+        # If you create a model in a test, the model is accessible in other\n+        # tests. To avoid this, we need to clear list of all models created in\n+        # `invalid_models` module.\n+        cache.app_models['invalid_models'] = {}\n+        cache._get_models_cache = {}\n+\n+    tearDown = setUp\ndiff --git a/tests/invalid_models/invalid_models/models.py b/tests/invalid_models/invalid_models/models.py\ndeleted file mode 100644\nindex 1113c0c05690..000000000000\n--- a/tests/invalid_models/invalid_models/models.py\n+++ /dev/null\n@@ -1,537 +0,0 @@\n-#encoding=utf-8\n-\"\"\"\n-26. Invalid models\n-\n-This example exists purely to point out errors in models.\n-\"\"\"\n-\n-from __future__ import unicode_literals\n-\n-from django.db import connection, models\n-\n-\n-class FieldErrors(models.Model):\n-    charfield = models.CharField()\n-    charfield2 = models.CharField(max_length=-1)\n-    charfield3 = models.CharField(max_length=\"bad\")\n-    decimalfield = models.DecimalField()\n-    decimalfield2 = models.DecimalField(max_digits=-1, decimal_places=-1)\n-    decimalfield3 = models.DecimalField(max_digits=\"bad\", decimal_places=\"bad\")\n-    decimalfield4 = models.DecimalField(max_digits=9, decimal_places=10)\n-    decimalfield5 = models.DecimalField(max_digits=10, decimal_places=10)\n-    filefield = models.FileField()\n-    choices = models.CharField(max_length=10, choices='bad')\n-    choices2 = models.CharField(max_length=10, choices=[(1, 2, 3), (1, 2, 3)])\n-    index = models.CharField(max_length=10, db_index='bad')\n-    field_ = models.CharField(max_length=10)\n-    nullbool = models.BooleanField(null=True)\n-    generic_ip_notnull_blank = models.GenericIPAddressField(null=False, blank=True)\n-\n-\n-class Target(models.Model):\n-    tgt_safe = models.CharField(max_length=10)\n-    clash1 = models.CharField(max_length=10)\n-    clash2 = models.CharField(max_length=10)\n-\n-    clash1_set = models.CharField(max_length=10)\n-\n-\n-class Clash1(models.Model):\n-    src_safe = models.CharField(max_length=10)\n-\n-    foreign = models.ForeignKey(Target)\n-    m2m = models.ManyToManyField(Target)\n-\n-\n-class Clash2(models.Model):\n-    src_safe = models.CharField(max_length=10)\n-\n-    foreign_1 = models.ForeignKey(Target, related_name='id')\n-    foreign_2 = models.ForeignKey(Target, related_name='src_safe')\n-\n-    m2m_1 = models.ManyToManyField(Target, related_name='id')\n-    m2m_2 = models.ManyToManyField(Target, related_name='src_safe')\n-\n-\n-class Target2(models.Model):\n-    clash3 = models.CharField(max_length=10)\n-    foreign_tgt = models.ForeignKey(Target)\n-    clashforeign_set = models.ForeignKey(Target)\n-\n-    m2m_tgt = models.ManyToManyField(Target)\n-    clashm2m_set = models.ManyToManyField(Target)\n-\n-\n-class Clash3(models.Model):\n-    src_safe = models.CharField(max_length=10)\n-\n-    foreign_1 = models.ForeignKey(Target2, related_name='foreign_tgt')\n-    foreign_2 = models.ForeignKey(Target2, related_name='m2m_tgt')\n-\n-    m2m_1 = models.ManyToManyField(Target2, related_name='foreign_tgt')\n-    m2m_2 = models.ManyToManyField(Target2, related_name='m2m_tgt')\n-\n-\n-class ClashForeign(models.Model):\n-    foreign = models.ForeignKey(Target2)\n-\n-\n-class ClashM2M(models.Model):\n-    m2m = models.ManyToManyField(Target2)\n-\n-\n-class SelfClashForeign(models.Model):\n-    src_safe = models.CharField(max_length=10)\n-    selfclashforeign = models.CharField(max_length=10)\n-\n-    selfclashforeign_set = models.ForeignKey(\"SelfClashForeign\")\n-    foreign_1 = models.ForeignKey(\"SelfClashForeign\", related_name='id')\n-    foreign_2 = models.ForeignKey(\"SelfClashForeign\", related_name='src_safe')\n-\n-\n-class ValidM2M(models.Model):\n-    src_safe = models.CharField(max_length=10)\n-    validm2m = models.CharField(max_length=10)\n-\n-    # M2M fields are symmetrical by default. Symmetrical M2M fields\n-    # on self don't require a related accessor, so many potential\n-    # clashes are avoided.\n-    validm2m_set = models.ManyToManyField(\"self\")\n-\n-    m2m_1 = models.ManyToManyField(\"self\", related_name='id')\n-    m2m_2 = models.ManyToManyField(\"self\", related_name='src_safe')\n-\n-    m2m_3 = models.ManyToManyField('self')\n-    m2m_4 = models.ManyToManyField('self')\n-\n-\n-class SelfClashM2M(models.Model):\n-    src_safe = models.CharField(max_length=10)\n-    selfclashm2m = models.CharField(max_length=10)\n-\n-    # Non-symmetrical M2M fields _do_ have related accessors, so\n-    # there is potential for clashes.\n-    selfclashm2m_set = models.ManyToManyField(\"self\", symmetrical=False)\n-\n-    m2m_1 = models.ManyToManyField(\"self\", related_name='id', symmetrical=False)\n-    m2m_2 = models.ManyToManyField(\"self\", related_name='src_safe', symmetrical=False)\n-\n-    m2m_3 = models.ManyToManyField('self', symmetrical=False)\n-    m2m_4 = models.ManyToManyField('self', symmetrical=False)\n-\n-\n-class Model(models.Model):\n-    \"But it's valid to call a model Model.\"\n-    year = models.PositiveIntegerField()  # 1960\n-    make = models.CharField(max_length=10)  # Aston Martin\n-    name = models.CharField(max_length=10)  # DB 4 GT\n-\n-\n-class Car(models.Model):\n-    colour = models.CharField(max_length=5)\n-    model = models.ForeignKey(Model)\n-\n-\n-class MissingRelations(models.Model):\n-    rel1 = models.ForeignKey(\"Rel1\")\n-    rel2 = models.ManyToManyField(\"Rel2\")\n-\n-\n-class MissingManualM2MModel(models.Model):\n-    name = models.CharField(max_length=5)\n-    missing_m2m = models.ManyToManyField(Model, through=\"MissingM2MModel\")\n-\n-\n-class Person(models.Model):\n-    name = models.CharField(max_length=5)\n-\n-\n-class Group(models.Model):\n-    name = models.CharField(max_length=5)\n-    primary = models.ManyToManyField(Person, through=\"Membership\", related_name=\"primary\")\n-    secondary = models.ManyToManyField(Person, through=\"Membership\", related_name=\"secondary\")\n-    tertiary = models.ManyToManyField(Person, through=\"RelationshipDoubleFK\", related_name=\"tertiary\")\n-\n-\n-class GroupTwo(models.Model):\n-    name = models.CharField(max_length=5)\n-    primary = models.ManyToManyField(Person, through=\"Membership\")\n-    secondary = models.ManyToManyField(Group, through=\"MembershipMissingFK\")\n-\n-\n-class Membership(models.Model):\n-    person = models.ForeignKey(Person)\n-    group = models.ForeignKey(Group)\n-    not_default_or_null = models.CharField(max_length=5)\n-\n-\n-class MembershipMissingFK(models.Model):\n-    person = models.ForeignKey(Person)\n-\n-\n-class PersonSelfRefM2M(models.Model):\n-    name = models.CharField(max_length=5)\n-    friends = models.ManyToManyField('self', through=\"Relationship\")\n-    too_many_friends = models.ManyToManyField('self', through=\"RelationshipTripleFK\")\n-\n-\n-class PersonSelfRefM2MExplicit(models.Model):\n-    name = models.CharField(max_length=5)\n-    friends = models.ManyToManyField('self', through=\"ExplicitRelationship\", symmetrical=True)\n-\n-\n-class Relationship(models.Model):\n-    first = models.ForeignKey(PersonSelfRefM2M, related_name=\"rel_from_set\")\n-    second = models.ForeignKey(PersonSelfRefM2M, related_name=\"rel_to_set\")\n-    date_added = models.DateTimeField()\n-\n-\n-class ExplicitRelationship(models.Model):\n-    first = models.ForeignKey(PersonSelfRefM2MExplicit, related_name=\"rel_from_set\")\n-    second = models.ForeignKey(PersonSelfRefM2MExplicit, related_name=\"rel_to_set\")\n-    date_added = models.DateTimeField()\n-\n-\n-class RelationshipTripleFK(models.Model):\n-    first = models.ForeignKey(PersonSelfRefM2M, related_name=\"rel_from_set_2\")\n-    second = models.ForeignKey(PersonSelfRefM2M, related_name=\"rel_to_set_2\")\n-    third = models.ForeignKey(PersonSelfRefM2M, related_name=\"too_many_by_far\")\n-    date_added = models.DateTimeField()\n-\n-\n-class RelationshipDoubleFK(models.Model):\n-    first = models.ForeignKey(Person, related_name=\"first_related_name\")\n-    second = models.ForeignKey(Person, related_name=\"second_related_name\")\n-    third = models.ForeignKey(Group, related_name=\"rel_to_set\")\n-    date_added = models.DateTimeField()\n-\n-\n-class AbstractModel(models.Model):\n-    name = models.CharField(max_length=10)\n-\n-    class Meta:\n-        abstract = True\n-\n-\n-class AbstractRelationModel(models.Model):\n-    fk1 = models.ForeignKey('AbstractModel')\n-    fk2 = models.ManyToManyField('AbstractModel')\n-\n-\n-class UniqueM2M(models.Model):\n-    \"\"\" Model to test for unique ManyToManyFields, which are invalid. \"\"\"\n-    unique_people = models.ManyToManyField(Person, unique=True)\n-\n-\n-class NonUniqueFKTarget1(models.Model):\n-    \"\"\" Model to test for non-unique FK target in yet-to-be-defined model: expect an error \"\"\"\n-    tgt = models.ForeignKey('FKTarget', to_field='bad')\n-\n-\n-class UniqueFKTarget1(models.Model):\n-    \"\"\" Model to test for unique FK target in yet-to-be-defined model: expect no error \"\"\"\n-    tgt = models.ForeignKey('FKTarget', to_field='good')\n-\n-\n-class FKTarget(models.Model):\n-    bad = models.IntegerField()\n-    good = models.IntegerField(unique=True)\n-\n-\n-class NonUniqueFKTarget2(models.Model):\n-    \"\"\" Model to test for non-unique FK target in previously seen model: expect an error \"\"\"\n-    tgt = models.ForeignKey(FKTarget, to_field='bad')\n-\n-\n-class UniqueFKTarget2(models.Model):\n-    \"\"\" Model to test for unique FK target in previously seen model: expect no error \"\"\"\n-    tgt = models.ForeignKey(FKTarget, to_field='good')\n-\n-\n-class NonExistingOrderingWithSingleUnderscore(models.Model):\n-    class Meta:\n-        ordering = (\"does_not_exist\",)\n-\n-\n-class InvalidSetNull(models.Model):\n-    fk = models.ForeignKey('self', on_delete=models.SET_NULL)\n-\n-\n-class InvalidSetDefault(models.Model):\n-    fk = models.ForeignKey('self', on_delete=models.SET_DEFAULT)\n-\n-\n-class UnicodeForeignKeys(models.Model):\n-    \"\"\"Foreign keys which can translate to ascii should be OK, but fail if\n-    they're not.\"\"\"\n-    good = models.ForeignKey('FKTarget')\n-    also_good = models.ManyToManyField('FKTarget', related_name='unicode2')\n-\n-    # In Python 3 this should become legal, but currently causes unicode errors\n-    # when adding the errors in core/management/validation.py\n-    #bad = models.ForeignKey('★')\n-\n-\n-class PrimaryKeyNull(models.Model):\n-    my_pk_field = models.IntegerField(primary_key=True, null=True)\n-\n-\n-class OrderByPKModel(models.Model):\n-    \"\"\"\n-    Model to test that ordering by pk passes validation.\n-    Refs #8291\n-    \"\"\"\n-    name = models.CharField(max_length=100, blank=True)\n-\n-    class Meta:\n-        ordering = ('pk',)\n-\n-\n-class SwappableModel(models.Model):\n-    \"\"\"A model that can be, but isn't swapped out.\n-\n-    References to this model *shoudln't* raise any validation error.\n-    \"\"\"\n-    name = models.CharField(max_length=100)\n-\n-    class Meta:\n-        swappable = 'TEST_SWAPPABLE_MODEL'\n-\n-\n-class SwappedModel(models.Model):\n-    \"\"\"A model that is swapped out.\n-\n-    References to this model *should* raise a validation error.\n-    Requires TEST_SWAPPED_MODEL to be defined in the test environment;\n-    this is guaranteed by the test runner using @override_settings.\n-\n-    The foreign keys and m2m relations on this model *shouldn't*\n-    install related accessors, so there shouldn't be clashes with\n-    the equivalent names on the replacement.\n-    \"\"\"\n-    name = models.CharField(max_length=100)\n-\n-    foreign = models.ForeignKey(Target, related_name='swappable_fk_set')\n-    m2m = models.ManyToManyField(Target, related_name='swappable_m2m_set')\n-\n-    class Meta:\n-        swappable = 'TEST_SWAPPED_MODEL'\n-\n-\n-class ReplacementModel(models.Model):\n-    \"\"\"A replacement model for swapping purposes.\"\"\"\n-    name = models.CharField(max_length=100)\n-\n-    foreign = models.ForeignKey(Target, related_name='swappable_fk_set')\n-    m2m = models.ManyToManyField(Target, related_name='swappable_m2m_set')\n-\n-\n-class BadSwappableValue(models.Model):\n-    \"\"\"A model that can be swapped out; during testing, the swappable\n-    value is not of the format app.model\n-    \"\"\"\n-    name = models.CharField(max_length=100)\n-\n-    class Meta:\n-        swappable = 'TEST_SWAPPED_MODEL_BAD_VALUE'\n-\n-\n-class BadSwappableModel(models.Model):\n-    \"\"\"A model that can be swapped out; during testing, the swappable\n-    value references an unknown model.\n-    \"\"\"\n-    name = models.CharField(max_length=100)\n-\n-    class Meta:\n-        swappable = 'TEST_SWAPPED_MODEL_BAD_MODEL'\n-\n-\n-class HardReferenceModel(models.Model):\n-    fk_1 = models.ForeignKey(SwappableModel, related_name='fk_hardref1')\n-    fk_2 = models.ForeignKey('invalid_models.SwappableModel', related_name='fk_hardref2')\n-    fk_3 = models.ForeignKey(SwappedModel, related_name='fk_hardref3')\n-    fk_4 = models.ForeignKey('invalid_models.SwappedModel', related_name='fk_hardref4')\n-    m2m_1 = models.ManyToManyField(SwappableModel, related_name='m2m_hardref1')\n-    m2m_2 = models.ManyToManyField('invalid_models.SwappableModel', related_name='m2m_hardref2')\n-    m2m_3 = models.ManyToManyField(SwappedModel, related_name='m2m_hardref3')\n-    m2m_4 = models.ManyToManyField('invalid_models.SwappedModel', related_name='m2m_hardref4')\n-\n-\n-class BadIndexTogether1(models.Model):\n-    class Meta:\n-        index_together = [\n-            [\"field_that_does_not_exist\"],\n-        ]\n-\n-\n-class DuplicateColumnNameModel1(models.Model):\n-    \"\"\"\n-    A field (bar) attempts to use a column name which is already auto-assigned\n-    earlier in the class. This should raise a validation error.\n-    \"\"\"\n-    foo = models.IntegerField()\n-    bar = models.IntegerField(db_column='foo')\n-\n-    class Meta:\n-        db_table = 'foobar'\n-\n-\n-class DuplicateColumnNameModel2(models.Model):\n-    \"\"\"\n-    A field (foo) attempts to use a column name which is already auto-assigned\n-    later in the class. This should raise a validation error.\n-    \"\"\"\n-    foo = models.IntegerField(db_column='bar')\n-    bar = models.IntegerField()\n-\n-    class Meta:\n-        db_table = 'foobar'\n-\n-\n-class DuplicateColumnNameModel3(models.Model):\n-    \"\"\"Two fields attempt to use each others' names.\n-\n-    This is not a desirable scenario but valid nonetheless.\n-\n-    It should not raise a validation error.\n-    \"\"\"\n-    foo = models.IntegerField(db_column='bar')\n-    bar = models.IntegerField(db_column='foo')\n-\n-    class Meta:\n-        db_table = 'foobar3'\n-\n-\n-class DuplicateColumnNameModel4(models.Model):\n-    \"\"\"Two fields attempt to use the same db_column value.\n-\n-    This should raise a validation error.\n-    \"\"\"\n-    foo = models.IntegerField(db_column='baz')\n-    bar = models.IntegerField(db_column='baz')\n-\n-    class Meta:\n-        db_table = 'foobar'\n-\n-\n-model_errors = \"\"\"invalid_models.fielderrors: \"charfield\": CharFields require a \"max_length\" attribute that is a positive integer.\n-invalid_models.fielderrors: \"charfield2\": CharFields require a \"max_length\" attribute that is a positive integer.\n-invalid_models.fielderrors: \"charfield3\": CharFields require a \"max_length\" attribute that is a positive integer.\n-invalid_models.fielderrors: \"decimalfield\": DecimalFields require a \"decimal_places\" attribute that is a non-negative integer.\n-invalid_models.fielderrors: \"decimalfield\": DecimalFields require a \"max_digits\" attribute that is a positive integer.\n-invalid_models.fielderrors: \"decimalfield2\": DecimalFields require a \"decimal_places\" attribute that is a non-negative integer.\n-invalid_models.fielderrors: \"decimalfield2\": DecimalFields require a \"max_digits\" attribute that is a positive integer.\n-invalid_models.fielderrors: \"decimalfield3\": DecimalFields require a \"decimal_places\" attribute that is a non-negative integer.\n-invalid_models.fielderrors: \"decimalfield3\": DecimalFields require a \"max_digits\" attribute that is a positive integer.\n-invalid_models.fielderrors: \"decimalfield4\": DecimalFields require a \"max_digits\" attribute value that is greater than or equal to the value of the \"decimal_places\" attribute.\n-invalid_models.fielderrors: \"filefield\": FileFields require an \"upload_to\" attribute.\n-invalid_models.fielderrors: \"choices\": \"choices\" should be iterable (e.g., a tuple or list).\n-invalid_models.fielderrors: \"choices2\": \"choices\" should be a sequence of two-item iterables (e.g. list of 2 item tuples).\n-invalid_models.fielderrors: \"choices2\": \"choices\" should be a sequence of two-item iterables (e.g. list of 2 item tuples).\n-invalid_models.fielderrors: \"index\": \"db_index\" should be either None, True or False.\n-invalid_models.fielderrors: \"field_\": Field names cannot end with underscores, because this would lead to ambiguous queryset filters.\n-invalid_models.fielderrors: \"nullbool\": BooleanFields do not accept null values. Use a NullBooleanField instead.\n-invalid_models.fielderrors: \"generic_ip_notnull_blank\": GenericIPAddressField can not accept blank values if null values are not allowed, as blank values are stored as null.\n-invalid_models.clash1: Accessor for field 'foreign' clashes with field 'Target.clash1_set'. Add a related_name argument to the definition for 'foreign'.\n-invalid_models.clash1: Accessor for field 'foreign' clashes with accessor for field 'Clash1.m2m'. Add a related_name argument to the definition for 'foreign'.\n-invalid_models.clash1: Reverse query name for field 'foreign' clashes with field 'Target.clash1'. Add a related_name argument to the definition for 'foreign'.\n-invalid_models.clash1: Accessor for m2m field 'm2m' clashes with field 'Target.clash1_set'. Add a related_name argument to the definition for 'm2m'.\n-invalid_models.clash1: Accessor for m2m field 'm2m' clashes with accessor for field 'Clash1.foreign'. Add a related_name argument to the definition for 'm2m'.\n-invalid_models.clash1: Reverse query name for m2m field 'm2m' clashes with field 'Target.clash1'. Add a related_name argument to the definition for 'm2m'.\n-invalid_models.clash2: Accessor for field 'foreign_1' clashes with field 'Target.id'. Add a related_name argument to the definition for 'foreign_1'.\n-invalid_models.clash2: Accessor for field 'foreign_1' clashes with accessor for field 'Clash2.m2m_1'. Add a related_name argument to the definition for 'foreign_1'.\n-invalid_models.clash2: Reverse query name for field 'foreign_1' clashes with field 'Target.id'. Add a related_name argument to the definition for 'foreign_1'.\n-invalid_models.clash2: Reverse query name for field 'foreign_1' clashes with accessor for field 'Clash2.m2m_1'. Add a related_name argument to the definition for 'foreign_1'.\n-invalid_models.clash2: Accessor for field 'foreign_2' clashes with accessor for field 'Clash2.m2m_2'. Add a related_name argument to the definition for 'foreign_2'.\n-invalid_models.clash2: Reverse query name for field 'foreign_2' clashes with accessor for field 'Clash2.m2m_2'. Add a related_name argument to the definition for 'foreign_2'.\n-invalid_models.clash2: Accessor for m2m field 'm2m_1' clashes with field 'Target.id'. Add a related_name argument to the definition for 'm2m_1'.\n-invalid_models.clash2: Accessor for m2m field 'm2m_1' clashes with accessor for field 'Clash2.foreign_1'. Add a related_name argument to the definition for 'm2m_1'.\n-invalid_models.clash2: Reverse query name for m2m field 'm2m_1' clashes with field 'Target.id'. Add a related_name argument to the definition for 'm2m_1'.\n-invalid_models.clash2: Reverse query name for m2m field 'm2m_1' clashes with accessor for field 'Clash2.foreign_1'. Add a related_name argument to the definition for 'm2m_1'.\n-invalid_models.clash2: Accessor for m2m field 'm2m_2' clashes with accessor for field 'Clash2.foreign_2'. Add a related_name argument to the definition for 'm2m_2'.\n-invalid_models.clash2: Reverse query name for m2m field 'm2m_2' clashes with accessor for field 'Clash2.foreign_2'. Add a related_name argument to the definition for 'm2m_2'.\n-invalid_models.clash3: Accessor for field 'foreign_1' clashes with field 'Target2.foreign_tgt'. Add a related_name argument to the definition for 'foreign_1'.\n-invalid_models.clash3: Accessor for field 'foreign_1' clashes with accessor for field 'Clash3.m2m_1'. Add a related_name argument to the definition for 'foreign_1'.\n-invalid_models.clash3: Reverse query name for field 'foreign_1' clashes with field 'Target2.foreign_tgt'. Add a related_name argument to the definition for 'foreign_1'.\n-invalid_models.clash3: Reverse query name for field 'foreign_1' clashes with accessor for field 'Clash3.m2m_1'. Add a related_name argument to the definition for 'foreign_1'.\n-invalid_models.clash3: Accessor for field 'foreign_2' clashes with m2m field 'Target2.m2m_tgt'. Add a related_name argument to the definition for 'foreign_2'.\n-invalid_models.clash3: Accessor for field 'foreign_2' clashes with accessor for field 'Clash3.m2m_2'. Add a related_name argument to the definition for 'foreign_2'.\n-invalid_models.clash3: Reverse query name for field 'foreign_2' clashes with m2m field 'Target2.m2m_tgt'. Add a related_name argument to the definition for 'foreign_2'.\n-invalid_models.clash3: Reverse query name for field 'foreign_2' clashes with accessor for field 'Clash3.m2m_2'. Add a related_name argument to the definition for 'foreign_2'.\n-invalid_models.clash3: Accessor for m2m field 'm2m_1' clashes with field 'Target2.foreign_tgt'. Add a related_name argument to the definition for 'm2m_1'.\n-invalid_models.clash3: Accessor for m2m field 'm2m_1' clashes with accessor for field 'Clash3.foreign_1'. Add a related_name argument to the definition for 'm2m_1'.\n-invalid_models.clash3: Reverse query name for m2m field 'm2m_1' clashes with field 'Target2.foreign_tgt'. Add a related_name argument to the definition for 'm2m_1'.\n-invalid_models.clash3: Reverse query name for m2m field 'm2m_1' clashes with accessor for field 'Clash3.foreign_1'. Add a related_name argument to the definition for 'm2m_1'.\n-invalid_models.clash3: Accessor for m2m field 'm2m_2' clashes with m2m field 'Target2.m2m_tgt'. Add a related_name argument to the definition for 'm2m_2'.\n-invalid_models.clash3: Accessor for m2m field 'm2m_2' clashes with accessor for field 'Clash3.foreign_2'. Add a related_name argument to the definition for 'm2m_2'.\n-invalid_models.clash3: Reverse query name for m2m field 'm2m_2' clashes with m2m field 'Target2.m2m_tgt'. Add a related_name argument to the definition for 'm2m_2'.\n-invalid_models.clash3: Reverse query name for m2m field 'm2m_2' clashes with accessor for field 'Clash3.foreign_2'. Add a related_name argument to the definition for 'm2m_2'.\n-invalid_models.clashforeign: Accessor for field 'foreign' clashes with field 'Target2.clashforeign_set'. Add a related_name argument to the definition for 'foreign'.\n-invalid_models.clashm2m: Accessor for m2m field 'm2m' clashes with m2m field 'Target2.clashm2m_set'. Add a related_name argument to the definition for 'm2m'.\n-invalid_models.target2: Accessor for field 'foreign_tgt' clashes with accessor for field 'Target2.m2m_tgt'. Add a related_name argument to the definition for 'foreign_tgt'.\n-invalid_models.target2: Accessor for field 'foreign_tgt' clashes with accessor for field 'Target2.clashm2m_set'. Add a related_name argument to the definition for 'foreign_tgt'.\n-invalid_models.target2: Accessor for field 'foreign_tgt' clashes with accessor for field 'Target2.clashforeign_set'. Add a related_name argument to the definition for 'foreign_tgt'.\n-invalid_models.target2: Accessor for field 'clashforeign_set' clashes with accessor for field 'Target2.m2m_tgt'. Add a related_name argument to the definition for 'clashforeign_set'.\n-invalid_models.target2: Accessor for field 'clashforeign_set' clashes with accessor for field 'Target2.clashm2m_set'. Add a related_name argument to the definition for 'clashforeign_set'.\n-invalid_models.target2: Accessor for field 'clashforeign_set' clashes with accessor for field 'Target2.foreign_tgt'. Add a related_name argument to the definition for 'clashforeign_set'.\n-invalid_models.target2: Accessor for m2m field 'm2m_tgt' clashes with accessor for m2m field 'Target2.clashm2m_set'. Add a related_name argument to the definition for 'm2m_tgt'.\n-invalid_models.target2: Accessor for m2m field 'm2m_tgt' clashes with accessor for field 'Target2.foreign_tgt'. Add a related_name argument to the definition for 'm2m_tgt'.\n-invalid_models.target2: Accessor for m2m field 'm2m_tgt' clashes with accessor for field 'Target2.clashforeign_set'. Add a related_name argument to the definition for 'm2m_tgt'.\n-invalid_models.target2: Accessor for m2m field 'clashm2m_set' clashes with accessor for m2m field 'Target2.m2m_tgt'. Add a related_name argument to the definition for 'clashm2m_set'.\n-invalid_models.target2: Accessor for m2m field 'clashm2m_set' clashes with accessor for field 'Target2.foreign_tgt'. Add a related_name argument to the definition for 'clashm2m_set'.\n-invalid_models.target2: Accessor for m2m field 'clashm2m_set' clashes with accessor for field 'Target2.clashforeign_set'. Add a related_name argument to the definition for 'clashm2m_set'.\n-invalid_models.selfclashforeign: Accessor for field 'selfclashforeign_set' clashes with field 'SelfClashForeign.selfclashforeign_set'. Add a related_name argument to the definition for 'selfclashforeign_set'.\n-invalid_models.selfclashforeign: Reverse query name for field 'selfclashforeign_set' clashes with field 'SelfClashForeign.selfclashforeign'. Add a related_name argument to the definition for 'selfclashforeign_set'.\n-invalid_models.selfclashforeign: Accessor for field 'foreign_1' clashes with field 'SelfClashForeign.id'. Add a related_name argument to the definition for 'foreign_1'.\n-invalid_models.selfclashforeign: Reverse query name for field 'foreign_1' clashes with field 'SelfClashForeign.id'. Add a related_name argument to the definition for 'foreign_1'.\n-invalid_models.selfclashforeign: Accessor for field 'foreign_2' clashes with field 'SelfClashForeign.src_safe'. Add a related_name argument to the definition for 'foreign_2'.\n-invalid_models.selfclashforeign: Reverse query name for field 'foreign_2' clashes with field 'SelfClashForeign.src_safe'. Add a related_name argument to the definition for 'foreign_2'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'selfclashm2m_set' clashes with m2m field 'SelfClashM2M.selfclashm2m_set'. Add a related_name argument to the definition for 'selfclashm2m_set'.\n-invalid_models.selfclashm2m: Reverse query name for m2m field 'selfclashm2m_set' clashes with field 'SelfClashM2M.selfclashm2m'. Add a related_name argument to the definition for 'selfclashm2m_set'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'selfclashm2m_set' clashes with accessor for m2m field 'SelfClashM2M.m2m_3'. Add a related_name argument to the definition for 'selfclashm2m_set'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'selfclashm2m_set' clashes with accessor for m2m field 'SelfClashM2M.m2m_4'. Add a related_name argument to the definition for 'selfclashm2m_set'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'm2m_1' clashes with field 'SelfClashM2M.id'. Add a related_name argument to the definition for 'm2m_1'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'm2m_2' clashes with field 'SelfClashM2M.src_safe'. Add a related_name argument to the definition for 'm2m_2'.\n-invalid_models.selfclashm2m: Reverse query name for m2m field 'm2m_1' clashes with field 'SelfClashM2M.id'. Add a related_name argument to the definition for 'm2m_1'.\n-invalid_models.selfclashm2m: Reverse query name for m2m field 'm2m_2' clashes with field 'SelfClashM2M.src_safe'. Add a related_name argument to the definition for 'm2m_2'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'm2m_3' clashes with m2m field 'SelfClashM2M.selfclashm2m_set'. Add a related_name argument to the definition for 'm2m_3'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'm2m_3' clashes with accessor for m2m field 'SelfClashM2M.selfclashm2m_set'. Add a related_name argument to the definition for 'm2m_3'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'm2m_3' clashes with accessor for m2m field 'SelfClashM2M.m2m_4'. Add a related_name argument to the definition for 'm2m_3'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'm2m_4' clashes with m2m field 'SelfClashM2M.selfclashm2m_set'. Add a related_name argument to the definition for 'm2m_4'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'm2m_4' clashes with accessor for m2m field 'SelfClashM2M.selfclashm2m_set'. Add a related_name argument to the definition for 'm2m_4'.\n-invalid_models.selfclashm2m: Accessor for m2m field 'm2m_4' clashes with accessor for m2m field 'SelfClashM2M.m2m_3'. Add a related_name argument to the definition for 'm2m_4'.\n-invalid_models.selfclashm2m: Reverse query name for m2m field 'm2m_3' clashes with field 'SelfClashM2M.selfclashm2m'. Add a related_name argument to the definition for 'm2m_3'.\n-invalid_models.selfclashm2m: Reverse query name for m2m field 'm2m_4' clashes with field 'SelfClashM2M.selfclashm2m'. Add a related_name argument to the definition for 'm2m_4'.\n-invalid_models.missingrelations: 'rel1' has a relation with model Rel1, which has either not been installed or is abstract.\n-invalid_models.missingrelations: 'rel2' has an m2m relation with model Rel2, which has either not been installed or is abstract.\n-invalid_models.grouptwo: 'primary' is a manually-defined m2m relation through model Membership, which does not have foreign keys to Person and GroupTwo\n-invalid_models.grouptwo: 'secondary' is a manually-defined m2m relation through model MembershipMissingFK, which does not have foreign keys to Group and GroupTwo\n-invalid_models.missingmanualm2mmodel: 'missing_m2m' specifies an m2m relation through model MissingM2MModel, which has not been installed\n-invalid_models.group: The model Group has two manually-defined m2m relations through the model Membership, which is not permitted. Please consider using an extra field on your intermediary model instead.\n-invalid_models.group: Intermediary model RelationshipDoubleFK has more than one foreign key to Person, which is ambiguous and is not permitted.\n-invalid_models.personselfrefm2m: Many-to-many fields with intermediate tables cannot be symmetrical.\n-invalid_models.personselfrefm2m: Intermediary model RelationshipTripleFK has more than two foreign keys to PersonSelfRefM2M, which is ambiguous and is not permitted.\n-invalid_models.personselfrefm2mexplicit: Many-to-many fields with intermediate tables cannot be symmetrical.\n-invalid_models.abstractrelationmodel: 'fk1' has a relation with model AbstractModel, which has either not been installed or is abstract.\n-invalid_models.abstractrelationmodel: 'fk2' has an m2m relation with model AbstractModel, which has either not been installed or is abstract.\n-invalid_models.uniquem2m: ManyToManyFields cannot be unique.  Remove the unique argument on 'unique_people'.\n-invalid_models.nonuniquefktarget1: Field 'bad' under model 'FKTarget' must have a unique=True constraint.\n-invalid_models.nonuniquefktarget2: Field 'bad' under model 'FKTarget' must have a unique=True constraint.\n-invalid_models.nonexistingorderingwithsingleunderscore: \"ordering\" refers to \"does_not_exist\", a field that doesn't exist.\n-invalid_models.invalidsetnull: 'fk' specifies on_delete=SET_NULL, but cannot be null.\n-invalid_models.invalidsetdefault: 'fk' specifies on_delete=SET_DEFAULT, but has no default value.\n-invalid_models.hardreferencemodel: 'fk_3' defines a relation with the model 'invalid_models.SwappedModel', which has been swapped out. Update the relation to point at settings.TEST_SWAPPED_MODEL.\n-invalid_models.hardreferencemodel: 'fk_4' defines a relation with the model 'invalid_models.SwappedModel', which has been swapped out. Update the relation to point at settings.TEST_SWAPPED_MODEL.\n-invalid_models.hardreferencemodel: 'm2m_3' defines a relation with the model 'invalid_models.SwappedModel', which has been swapped out. Update the relation to point at settings.TEST_SWAPPED_MODEL.\n-invalid_models.hardreferencemodel: 'm2m_4' defines a relation with the model 'invalid_models.SwappedModel', which has been swapped out. Update the relation to point at settings.TEST_SWAPPED_MODEL.\n-invalid_models.badswappablevalue: TEST_SWAPPED_MODEL_BAD_VALUE is not of the form 'app_label.app_name'.\n-invalid_models.badswappablemodel: Model has been swapped out for 'not_an_app.Target' which has not been installed or is abstract.\n-invalid_models.badindextogether1: \"index_together\" refers to field_that_does_not_exist, a field that doesn't exist.\n-invalid_models.duplicatecolumnnamemodel1: Field 'bar' has column name 'foo' that is already used.\n-invalid_models.duplicatecolumnnamemodel2: Field 'bar' has column name 'bar' that is already used.\n-invalid_models.duplicatecolumnnamemodel4: Field 'bar' has column name 'baz' that is already used.\n-\"\"\"\n-\n-if not connection.features.interprets_empty_strings_as_nulls:\n-    model_errors += \"\"\"invalid_models.primarykeynull: \"my_pk_field\": Primary key fields cannot have null=True.\n-\"\"\"\ndiff --git a/tests/invalid_models/old_invalid_models/models.py b/tests/invalid_models/old_invalid_models/models.py\nnew file mode 100644\nindex 000000000000..c784591b6d17\n--- /dev/null\n+++ b/tests/invalid_models/old_invalid_models/models.py\n@@ -0,0 +1,141 @@\n+# -*- coding:utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from django.conf import settings\n+from django.db import models\n+\n+\n+class Target(models.Model):\n+    tgt_safe = models.CharField(max_length=10)\n+    clash1 = models.CharField(max_length=10)\n+    clash2 = models.CharField(max_length=10)\n+\n+    clash1_set = models.CharField(max_length=10)\n+\n+class ValidM2M(models.Model):\n+    src_safe = models.CharField(max_length=10)\n+    validm2m = models.CharField(max_length=10)\n+\n+    # M2M fields are symmetrical by default. Symmetrical M2M fields\n+    # on self don't require a related accessor, so many potential\n+    # clashes are avoided.\n+    validm2m_set = models.ManyToManyField(\"self\")\n+\n+    m2m_1 = models.ManyToManyField(\"self\", related_name='id')\n+    m2m_2 = models.ManyToManyField(\"self\", related_name='src_safe')\n+\n+    m2m_3 = models.ManyToManyField('self')\n+    m2m_4 = models.ManyToManyField('self')\n+\n+\n+class Model(models.Model):\n+    \"But it's valid to call a model Model.\"\n+    year = models.PositiveIntegerField()  # 1960\n+    make = models.CharField(max_length=10)  # Aston Martin\n+    name = models.CharField(max_length=10)  # DB 4 GT\n+\n+\n+class Person(models.Model):\n+    name = models.CharField(max_length=5)\n+\n+\n+class Group(models.Model):\n+    name = models.CharField(max_length=5)\n+    primary = models.ManyToManyField(Person, through=\"Membership\", related_name=\"primary\")\n+    secondary = models.ManyToManyField(Person, through=\"Membership\", related_name=\"secondary\")\n+\n+\n+class Membership(models.Model):\n+    person = models.ForeignKey(Person)\n+    group = models.ForeignKey(Group)\n+    not_default_or_null = models.CharField(max_length=5)\n+\n+\n+class UniqueFKTarget1(models.Model):\n+    \"\"\" Model to test for unique FK target in yet-to-be-defined model: expect no error \"\"\"\n+    tgt = models.ForeignKey('FKTarget', to_field='good')\n+\n+\n+class FKTarget(models.Model):\n+    good = models.IntegerField(unique=True)\n+\n+\n+class UniqueFKTarget2(models.Model):\n+    \"\"\" Model to test for unique FK target in previously seen model: expect no error \"\"\"\n+    tgt = models.ForeignKey(FKTarget, to_field='good')\n+\n+\n+class UnicodeForeignKeys(models.Model):\n+    \"\"\"Foreign keys which can translate to ascii should be OK, but fail if\n+    they're not.\"\"\"\n+    good = models.ForeignKey('FKTarget')\n+    also_good = models.ManyToManyField('FKTarget', related_name='unicode2')\n+\n+    # In Python 3 this should become legal, but currently causes unicode errors\n+    # when adding the errors in core/management/validation.py\n+    #bad = models.ForeignKey('★')\n+\n+\n+class OrderByPKModel(models.Model):\n+    \"\"\"\n+    Model to test that ordering by pk passes validation.\n+    Refs #8291\n+    \"\"\"\n+    name = models.CharField(max_length=100, blank=True)\n+\n+    class Meta:\n+        ordering = ('pk',)\n+\n+\n+class SwappedModel(models.Model):\n+    \"\"\"A model that is swapped out.\n+\n+    The foreign keys and m2m relations on this model *shouldn't*\n+    install related accessors, so there shouldn't be clashes with\n+    the equivalent names on the replacement.\n+    \"\"\"\n+    name = models.CharField(max_length=100)\n+\n+    foreign = models.ForeignKey(Target, related_name='swappable_fk_set')\n+    m2m = models.ManyToManyField(Target, related_name='swappable_m2m_set')\n+\n+    class Meta:\n+        swappable = 'TEST_SWAPPED_MODEL'\n+\n+\n+class ReplacementModel(models.Model):\n+    \"\"\"A replacement model for swapping purposes.\"\"\"\n+    name = models.CharField(max_length=100)\n+\n+    foreign = models.ForeignKey(Target, related_name='swappable_fk_set')\n+    m2m = models.ManyToManyField(Target, related_name='swappable_m2m_set')\n+\n+\n+class SwappingModel(models.Model):\n+    \"\"\" Uses SwappedModel. \"\"\"\n+\n+    foreign_key = models.ForeignKey(settings.TEST_SWAPPED_MODEL,\n+        related_name='swapping_foreign_key')\n+    m2m = models.ManyToManyField(settings.TEST_SWAPPED_MODEL,\n+        related_name='swapping_m2m')\n+\n+\n+model_errors = \"\"\"\n+old_invalid_models.group: The model Group has two manually-defined m2m relations through the model Membership, which is not permitted. Please consider using an extra field on your intermediary model instead.\n+old_invalid_models.duplicatecolumnnamemodel1: Field 'bar' has column name 'foo' that is already used.\n+old_invalid_models.duplicatecolumnnamemodel2: Field 'bar' has column name 'bar' that is already used.\n+old_invalid_models.duplicatecolumnnamemodel4: Field 'bar' has column name 'baz' that is already used.\n+\"\"\"\n+\n+# Space\n+\n+\"\"\"\n+# Error messages predated by a character:\n+# - 'x' -- the test was rewritten\n+# - 'm' -- the test is actually a model test, not a field test; not rewritten\n+\n+m invalid_models.group: The model Group has two manually-defined m2m relations through the model Membership, which is not permitted. Please consider using an extra field on your intermediary model instead.\n+m invalid_models.duplicatecolumnnamemodel1: Field 'bar' has column name 'foo' that is already used.\n+m invalid_models.duplicatecolumnnamemodel2: Field 'bar' has column name 'bar' that is already used.\n+m invalid_models.duplicatecolumnnamemodel4: Field 'bar' has column name 'baz' that is already used.\n+\"\"\"\ndiff --git a/tests/invalid_models/test_backend_specific.py b/tests/invalid_models/test_backend_specific.py\nnew file mode 100644\nindex 000000000000..54f173ea2aed\n--- /dev/null\n+++ b/tests/invalid_models/test_backend_specific.py\n@@ -0,0 +1,68 @@\n+# -*- encoding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from types import MethodType\n+\n+from django.core.checks import Error\n+from django.db import connection, models\n+\n+from . import IsolatedModelsTestCase\n+\n+\n+class BackendSpecificChecksTests(IsolatedModelsTestCase):\n+\n+    def test_check_field(self):\n+        \"\"\" Test if backend specific checks are performed. \"\"\"\n+\n+        error = Error('an error', hint=None)\n+\n+        def mock(self, field, **kwargs):\n+            return [error]\n+\n+        class Model(models.Model):\n+            field = models.IntegerField()\n+\n+        field = Model._meta.get_field('field')\n+\n+        # Mock connection.validation.check_field method.\n+        v = connection.validation\n+        old_check_field = v.check_field\n+        v.check_field = MethodType(mock, v)\n+        try:\n+            errors = field.check()\n+        finally:\n+            # Unmock connection.validation.check_field method.\n+            v.check_field = old_check_field\n+\n+        self.assertEqual(errors, [error])\n+\n+    def test_validate_field(self):\n+        \"\"\" Errors raised by deprecated `validate_field` method should be\n+        collected. \"\"\"\n+\n+        def mock(self, errors, opts, field):\n+            errors.add(opts, \"An error!\")\n+\n+        class Model(models.Model):\n+            field = models.IntegerField()\n+\n+        field = Model._meta.get_field('field')\n+        expected = [\n+            Error(\n+                \"An error!\",\n+                hint=None,\n+                obj=field,\n+            )\n+        ]\n+\n+        # Mock connection.validation.validate_field method.\n+        v = connection.validation\n+        old_validate_field = v.validate_field\n+        v.validate_field = MethodType(mock, v)\n+        try:\n+            errors = field.check()\n+        finally:\n+            # Unmock connection.validation.validate_field method.\n+            v.validate_field = old_validate_field\n+\n+        self.assertEqual(errors, expected)\ndiff --git a/tests/invalid_models/test_models.py b/tests/invalid_models/test_models.py\nnew file mode 100644\nindex 000000000000..48a441e91477\n--- /dev/null\n+++ b/tests/invalid_models/test_models.py\n@@ -0,0 +1,319 @@\n+# -*- encoding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from django.core.checks import Error\n+from django.db import models\n+from django.test.utils import override_settings\n+\n+from . import IsolatedModelsTestCase\n+\n+\n+class IndexTogetherTests(IsolatedModelsTestCase):\n+\n+    def test_non_iterable(self):\n+        class Model(models.Model):\n+            class Meta:\n+                index_together = 'not-a-list'\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                '\"index_together\" must be a list or tuple.',\n+                hint=None,\n+                obj=Model,\n+                id='E006',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_list_containing_non_iterable(self):\n+        class Model(models.Model):\n+            class Meta:\n+                index_together = [\n+                    'non-iterable',\n+                    'second-non-iterable',\n+                ]\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'All \"index_together\" elements must be lists or tuples.',\n+                hint=None,\n+                obj=Model,\n+                id='E007',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_pointing_to_missing_field(self):\n+        class Model(models.Model):\n+            class Meta:\n+                index_together = [\n+                    [\"missing_field\"],\n+                ]\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                '\"index_together\" points to a missing field named \"missing_field\".',\n+                hint='Ensure that you did not misspell the field name.',\n+                obj=Model,\n+                id='E010',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_pointing_to_m2m_field(self):\n+        class Model(models.Model):\n+            m2m = models.ManyToManyField('self')\n+\n+            class Meta:\n+                index_together = [\n+                    [\"m2m\"],\n+                ]\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                '\"index_together\" refers to a m2m \"m2m\" field, but '\n+                    'ManyToManyFields are not supported in \"index_together\".',\n+                hint=None,\n+                obj=Model,\n+                id='E011',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+# unique_together tests are very similar to index_together tests.\n+class UniqueTogetherTests(IsolatedModelsTestCase):\n+\n+    def test_non_iterable(self):\n+        class Model(models.Model):\n+            class Meta:\n+                unique_together = 0\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                '\"unique_together\" must be a list or tuple.',\n+                hint=None,\n+                obj=Model,\n+                id='E008',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_list_containing_non_iterable(self):\n+        class Model(models.Model):\n+            one = models.IntegerField()\n+            two = models.IntegerField()\n+\n+            class Meta:\n+                unique_together = [('a', 'b'), 'not-a-list']\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'All \"unique_together\" elements must be lists or tuples.',\n+                hint=None,\n+                obj=Model,\n+                id='E009',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_valid_model(self):\n+        class Model(models.Model):\n+            one = models.IntegerField()\n+            two = models.IntegerField()\n+\n+            class Meta:\n+                # unique_together can be a simple tuple\n+                unique_together = ('one', 'two')\n+\n+        errors = Model.check()\n+        self.assertEqual(errors, [])\n+\n+    def test_pointing_to_missing_field(self):\n+        class Model(models.Model):\n+            class Meta:\n+                unique_together = [\n+                    [\"missing_field\"],\n+                ]\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                '\"unique_together\" points to a missing field named \"missing_field\".',\n+                hint='Ensure that you did not misspell the field name.',\n+                obj=Model,\n+                id='E010',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_pointing_to_m2m(self):\n+        class Model(models.Model):\n+            m2m = models.ManyToManyField('self')\n+\n+            class Meta:\n+                unique_together = [\n+                    [\"m2m\"],\n+                ]\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                '\"unique_together\" refers to a m2m \"m2m\" field, but '\n+                'ManyToManyFields are not supported in \"unique_together\".',\n+                hint=None,\n+                obj=Model,\n+                id='E011',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class OtherModelTests(IsolatedModelsTestCase):\n+\n+    def test_unique_primary_key(self):\n+        class Model(models.Model):\n+            id = models.IntegerField(primary_key=False)\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'You cannot use \"id\" as a field name, because each model '\n+                    'automatically gets an \"id\" field if none of the fields '\n+                    'have primary_key=True.',\n+                hint='Remove or rename \"id\" field or '\n+                    'add primary_key=True to a field.',\n+                obj=Model,\n+                id='E005',\n+            ),\n+            Error(\n+                'Field \"id\" has column name \"id\" that is already used.',\n+                hint=None,\n+                obj=Model,\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_field_names_ending_with_underscore(self):\n+        class Model(models.Model):\n+            field_ = models.CharField(max_length=10)\n+            m2m_ = models.ManyToManyField('self')\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Field names must not end with underscores.',\n+                hint=None,\n+                obj=Model._meta.get_field('field_'),\n+                id='E001',\n+            ),\n+            Error(\n+                'Field names must not end with underscores.',\n+                hint=None,\n+                obj=Model._meta.get_field('m2m_'),\n+                id='E001',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_ordering_non_iterable(self):\n+        class Model(models.Model):\n+            class Meta:\n+                ordering = \"missing_field\"\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                '\"ordering\" must be a tuple or list '\n+                    '(even if you want to order by only one field).',\n+                hint=None,\n+                obj=Model,\n+                id='E012',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_ordering_pointing_to_missing_field(self):\n+        class Model(models.Model):\n+            class Meta:\n+                ordering = (\"missing_field\",)\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                '\"ordering\" pointing to a missing \"missing_field\" field.',\n+                hint='Ensure that you did not misspell the field name.',\n+                obj=Model,\n+                id='E013',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    @override_settings(TEST_SWAPPED_MODEL_BAD_VALUE='not-a-model')\n+    def test_swappable_missing_app_name(self):\n+        class Model(models.Model):\n+            class Meta:\n+                swappable = 'TEST_SWAPPED_MODEL_BAD_VALUE'\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                '\"TEST_SWAPPED_MODEL_BAD_VALUE\" is not of the form \"app_label.app_name\".',\n+                hint=None,\n+                obj=Model,\n+                id='E002',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    @override_settings(TEST_SWAPPED_MODEL_BAD_MODEL='not_an_app.Target')\n+    def test_swappable_missing_app(self):\n+        class Model(models.Model):\n+            class Meta:\n+                swappable = 'TEST_SWAPPED_MODEL_BAD_MODEL'\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'The model has been swapped out for not_an_app.Target '\n+                    'which has not been installed or is abstract.',\n+                hint='Ensure that you did not misspell the model name and '\n+                    'the app name as well as the model is not abstract. Does '\n+                    'your INSTALLED_APPS setting contain the \"not_an_app\" app?',\n+                obj=Model,\n+                id='E003',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_two_m2m_through_same_relationship(self):\n+        class Person(models.Model):\n+            pass\n+\n+        class Group(models.Model):\n+            primary = models.ManyToManyField(Person,\n+                through=\"Membership\", related_name=\"primary\")\n+            secondary = models.ManyToManyField(Person, through=\"Membership\",\n+                related_name=\"secondary\")\n+\n+        class Membership(models.Model):\n+            person = models.ForeignKey(Person)\n+            group = models.ForeignKey(Group)\n+\n+        errors = Group.check()\n+        expected = [\n+            Error(\n+                'The model has two many-to-many relations through '\n+                    'the intermediary Membership model, which is not permitted.',\n+                hint=None,\n+                obj=Group,\n+                id='E004',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\ndiff --git a/tests/invalid_models/test_ordinary_fields.py b/tests/invalid_models/test_ordinary_fields.py\nnew file mode 100644\nindex 000000000000..09248832bc51\n--- /dev/null\n+++ b/tests/invalid_models/test_ordinary_fields.py\n@@ -0,0 +1,414 @@\n+# -*- encoding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from django.core.checks import Error\n+from django.db import models\n+\n+from . import IsolatedModelsTestCase\n+\n+\n+class AutoFieldTests(IsolatedModelsTestCase):\n+\n+    def test_valid_case(self):\n+        class Model(models.Model):\n+            id = models.AutoField(primary_key=True)\n+\n+        field = Model._meta.get_field('id')\n+        errors = field.check()\n+        expected = []\n+        self.assertEqual(errors, expected)\n+\n+    def test_primary_key(self):\n+        class Model(models.Model):\n+            field = models.AutoField(primary_key=False)\n+\n+            # Prevent Django from autocreating `id` AutoField, which would\n+            # result in an error, because a model must have exactly one\n+            # AutoField.\n+            another = models.IntegerField(primary_key=True)\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'The field must have primary_key=True, because it is an AutoField.',\n+                hint=None,\n+                obj=field,\n+                id='E048',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class BooleanFieldTests(IsolatedModelsTestCase):\n+\n+    def test_nullable_boolean_field(self):\n+        class Model(models.Model):\n+            field = models.BooleanField(null=True)\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'BooleanFields do not acceps null values.',\n+                hint='Use a NullBooleanField instead.',\n+                obj=field,\n+                id='E037',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class CharFieldTests(IsolatedModelsTestCase):\n+\n+    def test_valid_field(self):\n+        class Model(models.Model):\n+            field = models.CharField(\n+                max_length=255,\n+                choices=[\n+                    ('1', 'item1'),\n+                    ('2', 'item2'),\n+                ],\n+                db_index=True)\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = []\n+        self.assertEqual(errors, expected)\n+\n+    def test_missing_max_length(self):\n+        class Model(models.Model):\n+            field = models.CharField()\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'The field must have \"max_length\" attribute.',\n+                hint=None,\n+                obj=field,\n+                id='E038',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_negative_max_length(self):\n+        class Model(models.Model):\n+            field = models.CharField(max_length=-1)\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                '\"max_length\" must be a positive integer.',\n+                hint=None,\n+                obj=field,\n+                id='E039',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_bad_max_length_value(self):\n+        class Model(models.Model):\n+            field = models.CharField(max_length=\"bad\")\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                '\"max_length\" must be a positive integer.',\n+                hint=None,\n+                obj=field,\n+                id='E039',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_non_iterable_choices(self):\n+        class Model(models.Model):\n+            field = models.CharField(max_length=10, choices='bad')\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                '\"choices\" must be an iterable (e.g., a list or tuple).',\n+                hint=None,\n+                obj=field,\n+                id='E033',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_choices_containing_non_pairs(self):\n+        class Model(models.Model):\n+            field = models.CharField(max_length=10, choices=[(1, 2, 3), (1, 2, 3)])\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'All \"choices\" elements must be a tuple of two elements '\n+                    '(the first one is the actual value to be stored '\n+                    'and the second element is the human-readable name).',\n+                hint=None,\n+                obj=field,\n+                id='E034',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_bad_db_index_value(self):\n+        class Model(models.Model):\n+            field = models.CharField(max_length=10, db_index='bad')\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                '\"db_index\" must be either None, True or False.',\n+                hint=None,\n+                obj=field,\n+                id='E035',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_too_long_char_field_under_mysql(self):\n+        from django.db.backends.mysql.validation import DatabaseValidation\n+\n+        class Model(models.Model):\n+            field = models.CharField(unique=True, max_length=256)\n+\n+        field = Model._meta.get_field('field')\n+        validator = DatabaseValidation(connection=None)\n+        errors = validator.check_field(field)\n+        expected = [\n+            Error(\n+                'Under mysql backend, the field cannot have a \"max_length\" '\n+                    'greated than 255 when it is unique.',\n+                hint=None,\n+                obj=field,\n+                id='E047',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class DecimalFieldTests(IsolatedModelsTestCase):\n+\n+    def test_required_attributes(self):\n+        class Model(models.Model):\n+            field = models.DecimalField()\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'The field requires a \"decimal_places\" attribute.',\n+                hint=None,\n+                obj=field,\n+                id='E041',\n+            ),\n+            Error(\n+                'The field requires a \"max_digits\" attribute.',\n+                hint=None,\n+                obj=field,\n+                id='E043',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_negative_max_digits_and_decimal_places(self):\n+        class Model(models.Model):\n+            field = models.DecimalField(max_digits=-1, decimal_places=-1)\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                '\"decimal_places\" attribute must be a non-negative integer.',\n+                hint=None,\n+                obj=field,\n+                id='E042',\n+            ),\n+            Error(\n+                '\"max_digits\" attribute must be a positive integer.',\n+                hint=None,\n+                obj=field,\n+                id='E044',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_bad_values_of_max_digits_and_decimal_places(self):\n+        class Model(models.Model):\n+            field = models.DecimalField(max_digits=\"bad\", decimal_places=\"bad\")\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                '\"decimal_places\" attribute must be a non-negative integer.',\n+                hint=None,\n+                obj=field,\n+                id='E042',\n+            ),\n+            Error(\n+                '\"max_digits\" attribute must be a positive integer.',\n+                hint=None,\n+                obj=field,\n+                id='E044',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_decimal_places_greater_than_max_digits(self):\n+        class Model(models.Model):\n+            field = models.DecimalField(max_digits=9, decimal_places=10)\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                '\"max_digits\" must be greater or equal to \"decimal_places\".',\n+                hint=None,\n+                obj=field,\n+                id='E040',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_valid_field(self):\n+        class Model(models.Model):\n+            field = models.DecimalField(max_digits=10, decimal_places=10)\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = []\n+        self.assertEqual(errors, expected)\n+\n+\n+class FileFieldTests(IsolatedModelsTestCase):\n+\n+    def test_valid_case(self):\n+        class Model(models.Model):\n+            field = models.FileField(upload_to='somewhere')\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = []\n+        self.assertEqual(errors, expected)\n+\n+    def test_missing_upload_to(self):\n+        class Model(models.Model):\n+            field = models.FileField()\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'The field requires an \"upload_to\" attribute.',\n+                hint=None,\n+                obj=field,\n+                id='E031',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_unique(self):\n+        class Model(models.Model):\n+            field = models.FileField(unique=False, upload_to='somewhere')\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                '\"unique\" is not a valid argument for FileField.',\n+                hint=None,\n+                obj=field,\n+                id='E049',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_primary_key(self):\n+        class Model(models.Model):\n+            field = models.FileField(primary_key=False, upload_to='somewhere')\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                '\"primary_key\" is not a valid argument for FileField.',\n+                hint=None,\n+                obj=field,\n+                id='E050',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class FilePathFieldTests(IsolatedModelsTestCase):\n+\n+    def test_forbidden_files_and_folders(self):\n+        class Model(models.Model):\n+            field = models.FilePathField(allow_files=False, allow_folders=False)\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'The field must have either \"allow_files\" or \"allow_folders\" set to True.',\n+                hint=None,\n+                obj=field,\n+                id='E045',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class GenericIPAddressFieldTests(IsolatedModelsTestCase):\n+\n+    def test_non_nullable_blank(self):\n+        class Model(models.Model):\n+            field = models.GenericIPAddressField(null=False, blank=True)\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'The field cannot accept blank values if null values '\n+                    'are not allowed, as blank values are stored as null.',\n+                hint=None,\n+                obj=field,\n+                id='E046',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+class ImageFieldTests(IsolatedModelsTestCase):\n+\n+    def test_pillow_installed(self):\n+        try:\n+            import django.utils.image\n+        except ImproperlyConfigured:\n+            pillow_installed = False\n+        else:\n+            pillow_installed = True\n+\n+        class Model(models.Model):\n+            field = models.ImageField(upload_to='somewhere')\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [] if pillow_installed else [\n+            Error(\n+                'To use ImageFields, Pillow must be installed.',\n+                hint='Get Pillow at https://pypi.python.org/pypi/Pillow '\n+                    'or run command \"pip install pillow\".',\n+                obj=field,\n+                id='E032',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\ndiff --git a/tests/invalid_models/test_relative_fields.py b/tests/invalid_models/test_relative_fields.py\nnew file mode 100644\nindex 000000000000..7f3ea6cf0e60\n--- /dev/null\n+++ b/tests/invalid_models/test_relative_fields.py\n@@ -0,0 +1,1036 @@\n+# -*- encoding: utf-8 -*-\n+from __future__ import unicode_literals\n+\n+from django.core.checks import Error\n+from django.db import models\n+from django.test.utils import override_settings\n+from django.test.testcases import skipIfDBFeature\n+\n+from . import IsolatedModelsTestCase\n+\n+\n+class RelativeFieldTests(IsolatedModelsTestCase):\n+\n+    def test_valid_foreign_key_without_accessor(self):\n+        class Target(models.Model):\n+            # There would be a clash if Model.field installed an accessor.\n+            model = models.IntegerField()\n+\n+        class Model(models.Model):\n+            field = models.ForeignKey(Target, related_name='+')\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        self.assertEqual(errors, [])\n+\n+    def test_foreign_key_to_missing_model(self):\n+        # Model names are resolved when a model is being created, so we cannot\n+        # test relative fields in isolation and we need to attach them to a\n+        # model.\n+        class Model(models.Model):\n+            foreign_key = models.ForeignKey('Rel1')\n+\n+        field = Model._meta.get_field('foreign_key')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'The field has a relation with model Rel1, '\n+                    'which has either not been installed or is abstract.',\n+                hint='Ensure that you did not misspell the model name and '\n+                    'the model is not abstract. Does your INSTALLED_APPS '\n+                    'setting contain the app where Rel1 is defined?',\n+                obj=field,\n+                id='E030',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_many_to_many_to_missing_model(self):\n+        class Model(models.Model):\n+            m2m = models.ManyToManyField(\"Rel2\")\n+\n+        field = Model._meta.get_field('m2m')\n+        errors = field.check(from_model=Model)\n+        expected = [\n+            Error(\n+                'The field has a relation with model Rel2, '\n+                    'which has either not been installed or is abstract.',\n+                hint='Ensure that you did not misspell the model name and '\n+                    'the model is not abstract. Does your INSTALLED_APPS '\n+                    'setting contain the app where Rel2 is defined?',\n+                obj=field,\n+                id='E030',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_ambiguous_relationship_model(self):\n+\n+        class Person(models.Model):\n+            pass\n+\n+        class Group(models.Model):\n+            field = models.ManyToManyField('Person',\n+                through=\"AmbiguousRelationship\", related_name='tertiary')\n+\n+        class AmbiguousRelationship(models.Model):\n+            # Too much foreign keys to Person.\n+            first_person = models.ForeignKey(Person, related_name=\"first\")\n+            second_person = models.ForeignKey(Person, related_name=\"second\")\n+            second_model = models.ForeignKey(Group)\n+\n+        field = Group._meta.get_field('field')\n+        errors = field.check(from_model=Group)\n+        expected = [\n+            Error(\n+                'The model is used as an intermediary model by '\n+                    'invalid_models.Group.field, but it has more than one '\n+                    'foreign key to Person, '\n+                    'which is ambiguous and is not permitted.',\n+                hint='If you want to create a recursive relationship, use '\n+                    'ForeignKey(\"self\", symmetrical=False, '\n+                    'through=\"AmbiguousRelationship\").',\n+                obj=field,\n+                id='E027',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_relationship_model_with_foreign_key_to_wrong_model(self):\n+        class WrongModel(models.Model):\n+            pass\n+\n+        class Person(models.Model):\n+            pass\n+\n+        class Group(models.Model):\n+            members = models.ManyToManyField('Person',\n+                through=\"InvalidRelationship\")\n+\n+        class InvalidRelationship(models.Model):\n+            person = models.ForeignKey(Person)\n+            wrong_foreign_key = models.ForeignKey(WrongModel)\n+            # The last foreign key should point to Group model.\n+\n+        field = Group._meta.get_field('members')\n+        errors = field.check(from_model=Group)\n+        expected = [\n+            Error(\n+                'The model is used as an intermediary model by '\n+                    'invalid_models.Group.members, but it misses '\n+                    'a foreign key to Group or Person.',\n+                hint=None,\n+                obj=InvalidRelationship,\n+                id='E028',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_relationship_model_missing_foreign_key(self):\n+        class Person(models.Model):\n+            pass\n+\n+        class Group(models.Model):\n+            members = models.ManyToManyField('Person',\n+                through=\"InvalidRelationship\")\n+\n+        class InvalidRelationship(models.Model):\n+            group = models.ForeignKey(Group)\n+            # No foreign key to Person\n+\n+        field = Group._meta.get_field('members')\n+        errors = field.check(from_model=Group)\n+        expected = [\n+            Error(\n+                'The model is used as an intermediary model by '\n+                    'invalid_models.Group.members, but it misses '\n+                    'a foreign key to Group or Person.',\n+                hint=None,\n+                obj=InvalidRelationship,\n+                id='E028',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_missing_relationship_model(self):\n+        class Person(models.Model):\n+            pass\n+\n+        class Group(models.Model):\n+            members = models.ManyToManyField('Person',\n+                through=\"MissingM2MModel\")\n+\n+        field = Group._meta.get_field('members')\n+        errors = field.check(from_model=Group)\n+        expected = [\n+            Error(\n+                'The field specifies a many-to-many relation through model '\n+                    'MissingM2MModel, which has not been installed.',\n+                hint='Ensure that you did not misspell the model name and '\n+                    'the model is not abstract. Does your INSTALLED_APPS '\n+                    'setting contain the app where MissingM2MModel is defined?',\n+                obj=field,\n+                id='E023',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_symmetrical_self_referential_field(self):\n+        class Person(models.Model):\n+            # Implicit symmetrical=False.\n+            friends = models.ManyToManyField('self', through=\"Relationship\")\n+\n+        class Relationship(models.Model):\n+            first = models.ForeignKey(Person, related_name=\"rel_from_set\")\n+            second = models.ForeignKey(Person, related_name=\"rel_to_set\")\n+\n+        field = Person._meta.get_field('friends')\n+        errors = field.check(from_model=Person)\n+        expected = [\n+            Error(\n+                'Many-to-many fields with intermediate tables must not be symmetrical.',\n+                hint=None,\n+                obj=field,\n+                id='E024',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_too_many_foreign_keys_in_self_referential_model(self):\n+        class Person(models.Model):\n+            friends = models.ManyToManyField('self',\n+                through=\"InvalidRelationship\", symmetrical=False)\n+\n+        class InvalidRelationship(models.Model):\n+            first = models.ForeignKey(Person, related_name=\"rel_from_set_2\")\n+            second = models.ForeignKey(Person, related_name=\"rel_to_set_2\")\n+            third = models.ForeignKey(Person, related_name=\"too_many_by_far\")\n+\n+        field = Person._meta.get_field('friends')\n+        errors = field.check(from_model=Person)\n+        expected = [\n+            Error(\n+                'The model is used as an intermediary model by '\n+                    'invalid_models.Person.friends, but it has more than two '\n+                    'foreign keys to Person, which is ambiguous and '\n+                    'is not permitted.',\n+                hint=None,\n+                obj=InvalidRelationship,\n+                id='E025',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_symmetric_self_reference_with_intermediate_table(self):\n+        class Person(models.Model):\n+            # Explicit symmetrical=True.\n+            friends = models.ManyToManyField('self',\n+                through=\"Relationship\", symmetrical=True)\n+\n+        class Relationship(models.Model):\n+            first = models.ForeignKey(Person, related_name=\"rel_from_set\")\n+            second = models.ForeignKey(Person, related_name=\"rel_to_set\")\n+\n+        field = Person._meta.get_field('friends')\n+        errors = field.check(from_model=Person)\n+        expected = [\n+            Error(\n+                'Many-to-many fields with intermediate tables must not be symmetrical.',\n+                hint=None,\n+                obj=field,\n+                id='E024',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_foreign_key_to_abstract_model(self):\n+        class Model(models.Model):\n+            foreign_key = models.ForeignKey('AbstractModel')\n+\n+        class AbstractModel(models.Model):\n+            class Meta:\n+                abstract = True\n+\n+        field = Model._meta.get_field('foreign_key')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'The field has a relation with model AbstractModel, '\n+                    'which has either not been installed or is abstract.',\n+                hint='Ensure that you did not misspell the model name and '\n+                    'the model is not abstract. Does your INSTALLED_APPS '\n+                    'setting contain the app where AbstractModel is defined?',\n+                obj=field,\n+                id='E030',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_m2m_to_abstract_model(self):\n+        class AbstractModel(models.Model):\n+            class Meta:\n+                abstract = True\n+\n+        class Model(models.Model):\n+            m2m = models.ManyToManyField('AbstractModel')\n+\n+        field = Model._meta.get_field('m2m')\n+        errors = field.check(from_model=Model)\n+        expected = [\n+            Error(\n+                'The field has a relation with model AbstractModel, '\n+                    'which has either not been installed or is abstract.',\n+                hint='Ensure that you did not misspell the model name and '\n+                    'the model is not abstract. Does your INSTALLED_APPS '\n+                    'setting contain the app where AbstractModel is defined?',\n+                obj=field,\n+                id='E030',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_unique_m2m(self):\n+        class Person(models.Model):\n+            name = models.CharField(max_length=5)\n+\n+        class Group(models.Model):\n+            members = models.ManyToManyField('Person', unique=True)\n+\n+        field = Group._meta.get_field('members')\n+        errors = field.check(from_model=Group)\n+        expected = [\n+            Error(\n+                'ManyToManyFields must not be unique.',\n+                hint=None,\n+                obj=field,\n+                id='E022',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_foreign_key_to_non_unique_field(self):\n+        class Target(models.Model):\n+            bad = models.IntegerField()  # No unique=True\n+\n+        class Model(models.Model):\n+            foreign_key = models.ForeignKey('Target', to_field='bad')\n+\n+        field = Model._meta.get_field('foreign_key')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'Target.bad must have unique=True because it is referenced by a foreign key.',\n+                hint=None,\n+                obj=field,\n+                id='E019',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_foreign_key_to_non_unique_field_under_explicit_model(self):\n+        class Target(models.Model):\n+            bad = models.IntegerField()\n+\n+        class Model(models.Model):\n+            field = models.ForeignKey(Target, to_field='bad')\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'Target.bad must have unique=True because it is referenced by a foreign key.',\n+                hint=None,\n+                obj=field,\n+                id='E019',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_foreign_object_to_non_unique_fields(self):\n+        class Person(models.Model):\n+            # Note that both fields are not unique.\n+            country_id = models.IntegerField()\n+            city_id = models.IntegerField()\n+\n+        class MMembership(models.Model):\n+            person_country_id = models.IntegerField()\n+            person_city_id = models.IntegerField()\n+\n+            person = models.ForeignObject(Person,\n+                from_fields=['person_country_id', 'person_city_id'],\n+                to_fields=['country_id', 'city_id'])\n+\n+        field = MMembership._meta.get_field('person')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'No unique=True constraint on field combination '\n+                    '\"country_id,city_id\" under model Person.',\n+                hint='Set unique=True argument on any of the fields '\n+                    '\"country_id,city_id\" under model Person.',\n+                obj=field,\n+                id='E018',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_on_delete_set_null_on_non_nullable_field(self):\n+        class Person(models.Model):\n+            pass\n+\n+        class Model(models.Model):\n+            foreign_key = models.ForeignKey('Person',\n+                on_delete=models.SET_NULL)\n+\n+        field = Model._meta.get_field('foreign_key')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'The field specifies on_delete=SET_NULL, but cannot be null.',\n+                hint='Set null=True argument on the field.',\n+                obj=field,\n+                id='E020',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_on_delete_set_default_without_default_value(self):\n+        class Person(models.Model):\n+            pass\n+\n+        class Model(models.Model):\n+            foreign_key = models.ForeignKey('Person',\n+                on_delete=models.SET_DEFAULT)\n+\n+        field = Model._meta.get_field('foreign_key')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'The field specifies on_delete=SET_DEFAULT, but has no default value.',\n+                hint=None,\n+                obj=field,\n+                id='E021',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    @skipIfDBFeature('interprets_empty_strings_as_nulls')\n+    def test_nullable_primary_key(self):\n+        class Model(models.Model):\n+            field = models.IntegerField(primary_key=True, null=True)\n+\n+        field = Model._meta.get_field('field')\n+        errors = field.check()\n+        expected = [\n+            Error(\n+                'Primary keys must not have null=True.',\n+                hint='Set null=False on the field or remove primary_key=True argument.',\n+                obj=field,\n+                id='E036',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_not_swapped_model(self):\n+        class SwappableModel(models.Model):\n+            # A model that can be, but isn't swapped out. References to this\n+            # model should *not* raise any validation error.\n+            class Meta:\n+                swappable = 'TEST_SWAPPABLE_MODEL'\n+\n+        class Model(models.Model):\n+            explicit_fk = models.ForeignKey(SwappableModel,\n+                related_name='explicit_fk')\n+            implicit_fk = models.ForeignKey('invalid_models.SwappableModel',\n+                related_name='implicit_fk')\n+            explicit_m2m = models.ManyToManyField(SwappableModel,\n+                related_name='explicit_m2m')\n+            implicit_m2m = models.ManyToManyField(\n+                'invalid_models.SwappableModel',\n+                related_name='implicit_m2m')\n+\n+        explicit_fk = Model._meta.get_field('explicit_fk')\n+        self.assertEqual(explicit_fk.check(), [])\n+\n+        implicit_fk = Model._meta.get_field('implicit_fk')\n+        self.assertEqual(implicit_fk.check(), [])\n+\n+        explicit_m2m = Model._meta.get_field('explicit_m2m')\n+        self.assertEqual(explicit_m2m.check(from_model=Model), [])\n+\n+        implicit_m2m = Model._meta.get_field('implicit_m2m')\n+        self.assertEqual(implicit_m2m.check(from_model=Model), [])\n+\n+    @override_settings(TEST_SWAPPED_MODEL='invalid_models.Replacement')\n+    def test_referencing_to_swapped_model(self):\n+        class Replacement(models.Model):\n+            pass\n+\n+        class SwappedModel(models.Model):\n+            class Meta:\n+                swappable = 'TEST_SWAPPED_MODEL'\n+\n+        class Model(models.Model):\n+            explicit_fk = models.ForeignKey(SwappedModel,\n+                related_name='explicit_fk')\n+            implicit_fk = models.ForeignKey('invalid_models.SwappedModel',\n+                related_name='implicit_fk')\n+            explicit_m2m = models.ManyToManyField(SwappedModel,\n+                related_name='explicit_m2m')\n+            implicit_m2m = models.ManyToManyField(\n+                'invalid_models.SwappedModel',\n+                related_name='implicit_m2m')\n+\n+        fields = [\n+            Model._meta.get_field('explicit_fk'),\n+            Model._meta.get_field('implicit_fk'),\n+            Model._meta.get_field('explicit_m2m'),\n+            Model._meta.get_field('implicit_m2m'),\n+        ]\n+\n+        expected_error = Error(\n+            'The field defines a relation with the model '\n+                'invalid_models.SwappedModel, which has been swapped out.',\n+            hint='Update the relation to point at settings.TEST_SWAPPED_MODEL',\n+            id='E029',\n+        )\n+\n+        for field in fields:\n+            expected_error.obj = field\n+            errors = field.check(from_model=Model)\n+            self.assertEqual(errors, [expected_error])\n+\n+\n+class AccessorClashTests(IsolatedModelsTestCase):\n+\n+    def test_fk_to_integer(self):\n+        self._test_accessor_clash(\n+            target=models.IntegerField(),\n+            relative=models.ForeignKey('Target'))\n+\n+    def test_fk_to_fk(self):\n+        self._test_accessor_clash(\n+            target=models.ForeignKey('Another'),\n+            relative=models.ForeignKey('Target'))\n+\n+    def test_fk_to_m2m(self):\n+        self._test_accessor_clash(\n+            target=models.ManyToManyField('Another'),\n+            relative=models.ForeignKey('Target'))\n+\n+    def test_m2m_to_integer(self):\n+        self._test_accessor_clash(\n+            target=models.IntegerField(),\n+            relative=models.ManyToManyField('Target'))\n+\n+    def test_m2m_to_fk(self):\n+        self._test_accessor_clash(\n+            target=models.ForeignKey('Another'),\n+            relative=models.ManyToManyField('Target'))\n+\n+    def test_m2m_to_m2m(self):\n+        self._test_accessor_clash(\n+            target=models.ManyToManyField('Another'),\n+            relative=models.ManyToManyField('Target'))\n+\n+    def _test_accessor_clash(self, target, relative):\n+        class Another(models.Model):\n+            pass\n+\n+        class Target(models.Model):\n+            model_set = target\n+\n+        class Model(models.Model):\n+            rel = relative\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Accessor for field Model.rel clashes with field Target.model_set.',\n+                hint='Rename field Target.model_set or add/change '\n+                    'a related_name argument to the definition '\n+                    'for field Model.rel.',\n+                obj=Model._meta.get_field('rel'),\n+                id='E014',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_clash_between_accessors(self):\n+        class Target(models.Model):\n+            pass\n+\n+        class Model(models.Model):\n+            foreign = models.ForeignKey(Target)\n+            m2m = models.ManyToManyField(Target)\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Clash between accessors for Model.foreign and Model.m2m.',\n+                hint='Add or change a related_name argument to the definition '\n+                    'for Model.foreign or Model.m2m.',\n+                obj=Model._meta.get_field('foreign'),\n+                id='E016',\n+            ),\n+            Error(\n+                'Clash between accessors for Model.m2m and Model.foreign.',\n+                hint='Add or change a related_name argument to the definition '\n+                    'for Model.m2m or Model.foreign.',\n+                obj=Model._meta.get_field('m2m'),\n+                id='E016',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class ReverseQueryNameClashTests(IsolatedModelsTestCase):\n+\n+    def test_fk_to_integer(self):\n+        self._test_reverse_query_name_clash(\n+            target=models.IntegerField(),\n+            relative=models.ForeignKey('Target'))\n+\n+    def test_fk_to_fk(self):\n+        self._test_reverse_query_name_clash(\n+            target=models.ForeignKey('Another'),\n+            relative=models.ForeignKey('Target'))\n+\n+    def test_fk_to_m2m(self):\n+        self._test_reverse_query_name_clash(\n+            target=models.ManyToManyField('Another'),\n+            relative=models.ForeignKey('Target'))\n+\n+    def test_m2m_to_integer(self):\n+        self._test_reverse_query_name_clash(\n+            target=models.IntegerField(),\n+            relative=models.ManyToManyField('Target'))\n+\n+    def test_m2m_to_fk(self):\n+        self._test_reverse_query_name_clash(\n+            target=models.ForeignKey('Another'),\n+            relative=models.ManyToManyField('Target'))\n+\n+    def test_m2m_to_m2m(self):\n+        self._test_reverse_query_name_clash(\n+            target=models.ManyToManyField('Another'),\n+            relative=models.ManyToManyField('Target'))\n+\n+    def _test_reverse_query_name_clash(self, target, relative):\n+        class Another(models.Model):\n+            pass\n+\n+        class Target(models.Model):\n+            model = target\n+\n+        class Model(models.Model):\n+            rel = relative\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Reverse query name for field Model.rel clashes with field Target.model.',\n+                hint='Rename field Target.model or add/change '\n+                    'a related_name argument to the definition '\n+                    'for field Model.rel.',\n+                obj=Model._meta.get_field('rel'),\n+                id='E015',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class ExplicitRelatedNameClashTests(IsolatedModelsTestCase):\n+\n+    def test_fk_to_integer(self):\n+        self._test_explicit_related_name_clash(\n+            target=models.IntegerField(),\n+            relative=models.ForeignKey('Target', related_name='clash'))\n+\n+    def test_fk_to_fk(self):\n+        self._test_explicit_related_name_clash(\n+            target=models.ForeignKey('Another'),\n+            relative=models.ForeignKey('Target', related_name='clash'))\n+\n+    def test_fk_to_m2m(self):\n+        self._test_explicit_related_name_clash(\n+            target=models.ManyToManyField('Another'),\n+            relative=models.ForeignKey('Target', related_name='clash'))\n+\n+    def test_m2m_to_integer(self):\n+        self._test_explicit_related_name_clash(\n+            target=models.IntegerField(),\n+            relative=models.ManyToManyField('Target', related_name='clash'))\n+\n+    def test_m2m_to_fk(self):\n+        self._test_explicit_related_name_clash(\n+            target=models.ForeignKey('Another'),\n+            relative=models.ManyToManyField('Target', related_name='clash'))\n+\n+    def test_m2m_to_m2m(self):\n+        self._test_explicit_related_name_clash(\n+            target=models.ManyToManyField('Another'),\n+            relative=models.ManyToManyField('Target', related_name='clash'))\n+\n+    def _test_explicit_related_name_clash(self, target, relative):\n+        class Another(models.Model):\n+            pass\n+\n+        class Target(models.Model):\n+            clash = target\n+\n+        class Model(models.Model):\n+            rel = relative\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Accessor for field Model.rel clashes with field Target.clash.',\n+                hint='Rename field Target.clash or add/change '\n+                    'a related_name argument to the definition '\n+                    'for field Model.rel.',\n+                obj=Model._meta.get_field('rel'),\n+                id='E014',\n+            ),\n+            Error('Reverse query name for field Model.rel clashes with field Target.clash.',\n+                hint='Rename field Target.clash or add/change '\n+                    'a related_name argument to the definition '\n+                    'for field Model.rel.',\n+                obj=Model._meta.get_field('rel'),\n+                id='E015',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class ExplicitRelatedQueryNameClashTests(IsolatedModelsTestCase):\n+\n+    def test_fk_to_integer(self):\n+        self._test_explicit_related_query_name_clash(\n+            target=models.IntegerField(),\n+            relative=models.ForeignKey('Target',\n+                related_query_name='clash'))\n+\n+    def test_fk_to_fk(self):\n+        self._test_explicit_related_query_name_clash(\n+            target=models.ForeignKey('Another'),\n+            relative=models.ForeignKey('Target',\n+                related_query_name='clash'))\n+\n+    def test_fk_to_m2m(self):\n+        self._test_explicit_related_query_name_clash(\n+            target=models.ManyToManyField('Another'),\n+            relative=models.ForeignKey('Target',\n+                related_query_name='clash'))\n+\n+    def test_m2m_to_integer(self):\n+        self._test_explicit_related_query_name_clash(\n+            target=models.IntegerField(),\n+            relative=models.ManyToManyField('Target',\n+                related_query_name='clash'))\n+\n+    def test_m2m_to_fk(self):\n+        self._test_explicit_related_query_name_clash(\n+            target=models.ForeignKey('Another'),\n+            relative=models.ManyToManyField('Target',\n+                related_query_name='clash'))\n+\n+    def test_m2m_to_m2m(self):\n+        self._test_explicit_related_query_name_clash(\n+            target=models.ManyToManyField('Another'),\n+            relative=models.ManyToManyField('Target',\n+                related_query_name='clash'))\n+\n+    def _test_explicit_related_query_name_clash(self, target, relative):\n+        class Another(models.Model):\n+            pass\n+\n+        class Target(models.Model):\n+            clash = target\n+\n+        class Model(models.Model):\n+            rel = relative\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Reverse query name for field Model.rel clashes with field Target.clash.',\n+                hint='Rename field Target.clash or add/change a related_name '\n+                    'argument to the definition for field Model.rel.',\n+                obj=Model._meta.get_field('rel'),\n+                id='E015',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class SelfReferentialM2MClashTests(IsolatedModelsTestCase):\n+\n+    def test_clash_between_accessors(self):\n+        class Model(models.Model):\n+            first_m2m = models.ManyToManyField('self', symmetrical=False)\n+            second_m2m = models.ManyToManyField('self', symmetrical=False)\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Clash between accessors for Model.first_m2m and Model.second_m2m.',\n+                hint=u'Add or change a related_name argument to the definition '\n+                    'for Model.first_m2m or Model.second_m2m.',\n+                obj=Model._meta.get_field('first_m2m'),\n+                id='E016',\n+            ),\n+            Error(\n+                'Clash between accessors for Model.second_m2m and Model.first_m2m.',\n+                hint=u'Add or change a related_name argument to the definition '\n+                    'for Model.second_m2m or Model.first_m2m.',\n+                obj=Model._meta.get_field('second_m2m'),\n+                id='E016',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_accessor_clash(self):\n+        class Model(models.Model):\n+            model_set = models.ManyToManyField(\"self\", symmetrical=False)\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Accessor for field Model.model_set clashes with field Model.model_set.',\n+                hint='Rename field Model.model_set or add/change '\n+                    'a related_name argument to the definition '\n+                    'for field Model.model_set.',\n+                obj=Model._meta.get_field('model_set'),\n+                id='E014',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_reverse_query_name_clash(self):\n+        class Model(models.Model):\n+            model = models.ManyToManyField(\"self\", symmetrical=False)\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Reverse query name for field Model.model clashes with field Model.model.',\n+                hint='Rename field Model.model or add/change a related_name '\n+                    'argument to the definition for field Model.model.',\n+                obj=Model._meta.get_field('model'),\n+                id='E015',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_clash_under_explicit_related_name(self):\n+        class Model(models.Model):\n+            clash = models.IntegerField()\n+            m2m = models.ManyToManyField(\"self\",\n+                symmetrical=False, related_name='clash')\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Accessor for field Model.m2m clashes with field Model.clash.',\n+                hint='Rename field Model.clash or add/change a related_name '\n+                    'argument to the definition for field Model.m2m.',\n+                obj=Model._meta.get_field('m2m'),\n+                id='E014',\n+            ),\n+            Error(\n+                'Reverse query name for field Model.m2m clashes with field Model.clash.',\n+                hint='Rename field Model.clash or add/change a related_name '\n+                    'argument to the definition for field Model.m2m.',\n+                obj=Model._meta.get_field('m2m'),\n+                id='E015',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_valid_model(self):\n+        class Model(models.Model):\n+            first = models.ManyToManyField(\"self\",\n+                symmetrical=False, related_name='first_accessor')\n+            second = models.ManyToManyField(\"self\",\n+                symmetrical=False, related_name='second_accessor')\n+\n+        errors = Model.check()\n+        self.assertEqual(errors, [])\n+\n+\n+class SelfReferentialFKClashTests(IsolatedModelsTestCase):\n+\n+    def test_accessor_clash(self):\n+        class Model(models.Model):\n+            model_set = models.ForeignKey(\"Model\")\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Accessor for field Model.model_set clashes with field Model.model_set.',\n+                hint='Rename field Model.model_set or add/change '\n+                    'a related_name argument to the definition '\n+                    'for field Model.model_set.',\n+                obj=Model._meta.get_field('model_set'),\n+                id='E014',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_reverse_query_name_clash(self):\n+        class Model(models.Model):\n+            model = models.ForeignKey(\"Model\")\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Reverse query name for field Model.model clashes with field Model.model.',\n+                hint='Rename field Model.model or add/change '\n+                    'a related_name argument to the definition '\n+                    'for field Model.model.',\n+                obj=Model._meta.get_field('model'),\n+                id='E015',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def test_clash_under_explicit_related_name(self):\n+        class Model(models.Model):\n+            clash = models.CharField(max_length=10)\n+            foreign = models.ForeignKey(\"Model\", related_name='clash')\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Accessor for field Model.foreign clashes with field Model.clash.',\n+                hint='Rename field Model.clash or add/change '\n+                    'a related_name argument to the definition '\n+                    'for field Model.foreign.',\n+                obj=Model._meta.get_field('foreign'),\n+                id='E014',\n+            ),\n+            Error(\n+                'Reverse query name for field Model.foreign clashes with field Model.clash.',\n+                hint='Rename field Model.clash or add/change '\n+                    'a related_name argument to the definition '\n+                    'for field Model.foreign.',\n+                obj=Model._meta.get_field('foreign'),\n+                id='E015',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+\n+class ComplexClashTests(IsolatedModelsTestCase):\n+\n+    # New tests should not be included here, because this is a single,\n+    # self-contained sanity check, not a test of everything.\n+    def test_complex_clash(self):\n+        class Target(models.Model):\n+            tgt_safe = models.CharField(max_length=10)\n+            clash = models.CharField(max_length=10)\n+            model = models.CharField(max_length=10)\n+\n+            clash1_set = models.CharField(max_length=10)\n+\n+        class Model(models.Model):\n+            src_safe = models.CharField(max_length=10)\n+\n+            foreign_1 = models.ForeignKey(Target, related_name='id')\n+            foreign_2 = models.ForeignKey(Target, related_name='src_safe')\n+\n+            m2m_1 = models.ManyToManyField(Target, related_name='id')\n+            m2m_2 = models.ManyToManyField(Target, related_name='src_safe')\n+\n+        errors = Model.check()\n+        expected = [\n+            Error(\n+                'Accessor for field Model.foreign_1 clashes with field Target.id.',\n+                hint='Rename field Target.id or add/change a related_name '\n+                    'argument to the definition for field Model.foreign_1.',\n+                obj=Model._meta.get_field('foreign_1'),\n+                id='E014',\n+            ),\n+            Error(\n+                'Reverse query name for field Model.foreign_1 clashes with field Target.id.',\n+                hint='Rename field Target.id or add/change a related_name '\n+                    'argument to the definition for field Model.foreign_1.',\n+                obj=Model._meta.get_field('foreign_1'),\n+                id='E015',\n+            ),\n+            Error(\n+                'Clash between accessors for Model.foreign_1 and Model.m2m_1.',\n+                hint='Add or change a related_name argument to '\n+                    'the definition for Model.foreign_1 or Model.m2m_1.',\n+                obj=Model._meta.get_field('foreign_1'),\n+                id='E016',\n+            ),\n+            Error(\n+                'Clash between reverse query names for Model.foreign_1 and Model.m2m_1.',\n+                hint='Add or change a related_name argument to '\n+                    'the definition for Model.foreign_1 or Model.m2m_1.',\n+                obj=Model._meta.get_field('foreign_1'),\n+                id='E017',\n+            ),\n+\n+            Error(\n+                'Clash between accessors for Model.foreign_2 and Model.m2m_2.',\n+                hint='Add or change a related_name argument '\n+                    'to the definition for Model.foreign_2 or Model.m2m_2.',\n+                obj=Model._meta.get_field('foreign_2'),\n+                id='E016',\n+            ),\n+            Error(\n+                'Clash between reverse query names for Model.foreign_2 and Model.m2m_2.',\n+                hint='Add or change a related_name argument to '\n+                    'the definition for Model.foreign_2 or Model.m2m_2.',\n+                obj=Model._meta.get_field('foreign_2'),\n+                id='E017',\n+            ),\n+\n+            Error(\n+                'Accessor for field Model.m2m_1 clashes with field Target.id.',\n+                hint='Rename field Target.id or add/change a related_name '\n+                    'argument to the definition for field Model.m2m_1.',\n+                obj=Model._meta.get_field('m2m_1'),\n+                id='E014',\n+            ),\n+            Error(\n+                'Reverse query name for field Model.m2m_1 clashes with field Target.id.',\n+                hint='Rename field Target.id or add/change a related_name '\n+                    'argument to the definition for field Model.m2m_1.',\n+                obj=Model._meta.get_field('m2m_1'),\n+                id='E015',\n+            ),\n+            Error(\n+                'Clash between accessors for Model.m2m_1 and Model.foreign_1.',\n+                hint='Add or change a related_name argument to the definition '\n+                    'for Model.m2m_1 or Model.foreign_1.',\n+                obj=Model._meta.get_field('m2m_1'),\n+                id='E016',\n+            ),\n+            Error(\n+                'Clash between reverse query names for Model.m2m_1 and Model.foreign_1.',\n+                hint='Add or change a related_name argument to '\n+                    'the definition for Model.m2m_1 or Model.foreign_1.',\n+                obj=Model._meta.get_field('m2m_1'),\n+                id='E017',\n+            ),\n+\n+            Error(\n+                'Clash between accessors for Model.m2m_2 and Model.foreign_2.',\n+                hint='Add or change a related_name argument to the definition '\n+                    'for Model.m2m_2 or Model.foreign_2.',\n+                obj=Model._meta.get_field('m2m_2'),\n+                id='E016',\n+            ),\n+            Error(\n+                'Clash between reverse query names for Model.m2m_2 and Model.foreign_2.',\n+                hint='Add or change a related_name argument to the definition '\n+                    'for Model.m2m_2 or Model.foreign_2.',\n+                obj=Model._meta.get_field('m2m_2'),\n+                id='E017',\n+            ),\n+        ]\n+        self.assertEqual(errors, expected)\ndiff --git a/tests/invalid_models/tests.py b/tests/invalid_models/tests.py\ndeleted file mode 100644\nindex 9c9db91da9dd..000000000000\n--- a/tests/invalid_models/tests.py\n+++ /dev/null\n@@ -1,58 +0,0 @@\n-import copy\n-import sys\n-import unittest\n-\n-from django.core.management.validation import get_validation_errors\n-from django.db.models.loading import cache, load_app\n-from django.test.utils import override_settings\n-from django.utils.six import StringIO\n-\n-\n-class InvalidModelTestCase(unittest.TestCase):\n-    \"\"\"Import an appliation with invalid models and test the exceptions.\"\"\"\n-\n-    def setUp(self):\n-        # Make sure sys.stdout is not a tty so that we get errors without\n-        # coloring attached (makes matching the results easier). We restore\n-        # sys.stderr afterwards.\n-        self.old_stdout = sys.stdout\n-        self.stdout = StringIO()\n-        sys.stdout = self.stdout\n-\n-        # This test adds dummy applications to the app cache. These\n-        # need to be removed in order to prevent bad interactions\n-        # with the flush operation in other tests.\n-        self.old_app_models = copy.deepcopy(cache.app_models)\n-        self.old_app_store = copy.deepcopy(cache.app_store)\n-\n-    def tearDown(self):\n-        cache.app_models = self.old_app_models\n-        cache.app_store = self.old_app_store\n-        cache._get_models_cache = {}\n-        sys.stdout = self.old_stdout\n-\n-    # Technically, this isn't an override -- TEST_SWAPPED_MODEL must be\n-    # set to *something* in order for the test to work. However, it's\n-    # easier to set this up as an override than to require every developer\n-    # to specify a value in their test settings.\n-    @override_settings(\n-        TEST_SWAPPED_MODEL='invalid_models.ReplacementModel',\n-        TEST_SWAPPED_MODEL_BAD_VALUE='not-a-model',\n-        TEST_SWAPPED_MODEL_BAD_MODEL='not_an_app.Target',\n-    )\n-    def test_invalid_models(self):\n-        try:\n-            module = load_app(\"invalid_models.invalid_models\")\n-        except Exception:\n-            self.fail('Unable to load invalid model module')\n-\n-        get_validation_errors(self.stdout, module)\n-        self.stdout.seek(0)\n-        error_log = self.stdout.read()\n-        actual = error_log.split('\\n')\n-        expected = module.model_errors.split('\\n')\n-\n-        unexpected = [err for err in actual if err not in expected]\n-        missing = [err for err in expected if err not in actual]\n-        self.assertFalse(unexpected, \"Unexpected Errors: \" + '\\n'.join(unexpected))\n-        self.assertFalse(missing, \"Missing Errors: \" + '\\n'.join(missing))\ndiff --git a/tests/logging_tests/tests.py b/tests/logging_tests/tests.py\nindex ef9f979e7eea..02b84f01e4e7 100644\n--- a/tests/logging_tests/tests.py\n+++ b/tests/logging_tests/tests.py\n@@ -335,7 +335,7 @@ def test_circular_dependency(self):\n         # validate is just an example command to trigger settings configuration\n         out, err = self.run_manage(['validate'])\n         self.assertNoOutput(err)\n-        self.assertOutput(out, \"0 errors found\")\n+        self.assertOutput(out, \"System check identified no problems.\")\n \n \n def dictConfig(config):\ndiff --git a/tests/migrate_signals/tests.py b/tests/migrate_signals/tests.py\nindex 9daa7ae3766a..8b5f5bd56e9e 100644\n--- a/tests/migrate_signals/tests.py\n+++ b/tests/migrate_signals/tests.py\n@@ -1,6 +1,7 @@\n+from django.core import management\n from django.db.models import signals\n from django.test import TestCase\n-from django.core import management\n+from django.test.utils import override_system_checks\n from django.utils import six\n \n from . import models\n@@ -63,6 +64,9 @@ class MigrateSignalTests(TestCase):\n     def test_pre_migrate_call_time(self):\n         self.assertEqual(pre_migrate_receiver.call_counter, 1)\n \n+    # `auth` app is imported, but not installed in this test, so we need to\n+    # exclude checks registered by this app.\n+    @override_system_checks([])\n     def test_pre_migrate_args(self):\n         r = PreMigrateReceiver()\n         signals.pre_migrate.connect(r, sender=models)\ndiff --git a/tests/migrations/test_commands.py b/tests/migrations/test_commands.py\nindex 01d11e2c0c71..9baae683bd44 100644\n--- a/tests/migrations/test_commands.py\n+++ b/tests/migrations/test_commands.py\n@@ -6,7 +6,7 @@\n \n from django.core.management import call_command\n from django.db.models.loading import cache\n-from django.test.utils import override_settings\n+from django.test.utils import override_settings, override_system_checks\n from django.utils import six\n from django.utils._os import upath\n from django.utils.encoding import force_text\n@@ -20,11 +20,13 @@ class MigrateTests(MigrationTestBase):\n     Tests running the migrate command.\n     \"\"\"\n \n+    # `auth` app is imported, but not installed in these tests (thanks to\n+    # MigrationTestBase), so we need to exclude checks registered by this app.\n+\n+    @override_system_checks([])\n     @override_settings(MIGRATION_MODULES={\"migrations\": \"migrations.test_migrations\"})\n     def test_migrate(self):\n-        \"\"\"\n-        Tests basic usage of the migrate command.\n-        \"\"\"\n+        \"\"\" Tests basic usage of the migrate command. \"\"\"\n         # Make sure no tables are created\n         self.assertTableNotExists(\"migrations_author\")\n         self.assertTableNotExists(\"migrations_tribble\")\n@@ -48,6 +50,7 @@ def test_migrate(self):\n         self.assertTableNotExists(\"migrations_tribble\")\n         self.assertTableNotExists(\"migrations_book\")\n \n+    @override_system_checks([])\n     @override_settings(MIGRATION_MODULES={\"migrations\": \"migrations.test_migrations\"})\n     def test_migrate_list(self):\n         \"\"\"\n@@ -70,6 +73,7 @@ def test_migrate_list(self):\n         # Cleanup by unmigrating everything\n         call_command(\"migrate\", \"migrations\", \"zero\", verbosity=0)\n \n+    @override_system_checks([])\n     @override_settings(MIGRATION_MODULES={\"migrations\": \"migrations.test_migrations\"})\n     def test_sqlmigrate(self):\n         \"\"\"\n@@ -108,6 +112,9 @@ def _rmrf(self, dname):\n             return\n         shutil.rmtree(dname)\n \n+    # `auth` app is imported, but not installed in this test (thanks to\n+    # MigrationTestBase), so we need to exclude checks registered by this app.\n+    @override_system_checks([])\n     def test_files_content(self):\n         self.assertTableNotExists(\"migrations_unicodemodel\")\n         cache.register_models('migrations', UnicodeModel)\ndiff --git a/tests/model_fields/tests.py b/tests/model_fields/tests.py\nindex ac7dd0252f73..9d266f529566 100644\n--- a/tests/model_fields/tests.py\n+++ b/tests/model_fields/tests.py\n@@ -85,6 +85,11 @@ def test_choices_form_class(self):\n         klass = forms.TypedMultipleChoiceField\n         self.assertIsInstance(field.formfield(choices_form_class=klass), klass)\n \n+    def test_field_str(self):\n+        from django.utils.encoding import force_str\n+        f = Foo._meta.get_field('a')\n+        self.assertEqual(force_str(f), \"model_fields.Foo.a\")\n+\n \n class DecimalFieldTests(test.TestCase):\n     def test_to_python(self):\ndiff --git a/tests/modeladmin/tests.py b/tests/modeladmin/tests.py\nindex f7d78677c334..2042976bb030 100644\n--- a/tests/modeladmin/tests.py\n+++ b/tests/modeladmin/tests.py\n@@ -1,22 +1,22 @@\n from __future__ import unicode_literals\n \n from datetime import date\n-import unittest\n \n from django import forms\n-from django.conf import settings\n from django.contrib.admin.options import (ModelAdmin, TabularInline,\n      HORIZONTAL, VERTICAL)\n from django.contrib.admin.sites import AdminSite\n from django.contrib.admin.widgets import AdminDateWidget, AdminRadioSelect\n+from django.contrib.admin.validation import ModelAdminValidator\n from django.contrib.admin import (SimpleListFilter,\n      BooleanFieldListFilter)\n+from django.core.checks import Error\n from django.core.exceptions import ImproperlyConfigured\n from django.forms.models import BaseModelFormSet\n from django.forms.widgets import Select\n from django.test import TestCase\n-from django.test.utils import str_prefix\n-from django.utils import six\n+from django.utils.encoding import force_text\n+\n \n from .models import Band, Concert, ValidationTestModel, ValidationTestInlineModel\n \n@@ -43,6 +43,19 @@ def setUp(self):\n         )\n         self.site = AdminSite()\n \n+    def test_str_on_model_admin_class(self):\n+        got = force_text(ModelAdmin)\n+        expected = \"django.contrib.admin.options.ModelAdmin\"\n+        self.assertEqual(got, expected)\n+\n+    def test_str_on_inline_model_admin_class(self):\n+        class MyInline(TabularInline):\n+            model = ValidationTestInlineModel\n+\n+        got = force_text(MyInline)\n+        expected = \"modeladmin.tests.MyInline\"\n+        self.assertEqual(got, expected)\n+\n     # form/fields/fieldsets interaction ##############################\n \n     def test_default_fields(self):\n@@ -537,181 +550,190 @@ class BandAdmin(ModelAdmin):\n             ['extra', 'transport', 'id', 'DELETE', 'main_band'])\n \n \n-class ValidationTests(unittest.TestCase):\n-    def test_validation_only_runs_in_debug(self):\n-        # Ensure validation only runs when DEBUG = True\n-        try:\n-            settings.DEBUG = True\n+class CheckTestCase(TestCase):\n \n-            class ValidationTestModelAdmin(ModelAdmin):\n-                raw_id_fields = 10\n-\n-            site = AdminSite()\n-\n-            six.assertRaisesRegex(self,\n-                ImproperlyConfigured,\n-                \"'ValidationTestModelAdmin.raw_id_fields' must be a list or tuple.\",\n-                site.register,\n-                ValidationTestModel,\n-                ValidationTestModelAdmin,\n+    def assertIsInvalid(self, model_admin, model, msg,\n+            id=None, hint=None, invalid_obj=None):\n+        invalid_obj = invalid_obj or model_admin\n+        errors = model_admin.check(model=model)\n+        expected = [\n+            Error(\n+                msg,\n+                hint=hint,\n+                obj=invalid_obj,\n+                id=id,\n             )\n-        finally:\n-            settings.DEBUG = False\n+        ]\n+        self.assertEqual(errors, expected)\n+\n+    def assertIsValid(self, model_admin, model):\n+        errors = model_admin.check(model=model)\n+        expected = []\n+        self.assertEqual(errors, expected)\n \n-        site = AdminSite()\n-        site.register(ValidationTestModel, ValidationTestModelAdmin)\n \n-    def test_raw_id_fields_validation(self):\n+class RawIdCheckTests(CheckTestCase):\n \n+    def test_not_iterable(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             raw_id_fields = 10\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.raw_id_fields' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"raw_id_fields\" must be a list or tuple.',\n+            'admin.E001')\n \n+    def test_missing_field(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             raw_id_fields = ('non_existent_field',)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.raw_id_fields' refers to field 'non_existent_field' that is missing from model 'modeladmin.ValidationTestModel'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"raw_id_fields[0]\" refers to field \"non_existent_field\", '\n+                'which is missing from model modeladmin.ValidationTestModel.',\n+            'admin.E002')\n \n+    def test_invalid_field_type(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             raw_id_fields = ('name',)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.raw_id_fields\\[0\\]', 'name' must be either a ForeignKey or ManyToManyField.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"raw_id_fields[0]\" must be a ForeignKey or ManyToManyField.',\n+            'admin.E003')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             raw_id_fields = ('users',)\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n+\n+\n+class FieldsetsCheckTests(CheckTestCase):\n+\n+    def test_valid_case(self):\n+        class ValidationTestModelAdmin(ModelAdmin):\n+            fieldsets = ((\"General\", {\"fields\": (\"name\",)}),)\n+\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_fieldsets_validation(self):\n+    def test_not_iterable(self):\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             fieldsets = 10\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.fieldsets' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"fieldsets\" must be a list or tuple.',\n+            'admin.E007')\n \n+    def test_non_iterable_item(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             fieldsets = ({},)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.fieldsets\\[0\\]' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"fieldsets[0]\" must be a list or tuple.',\n+            'admin.E008')\n \n+    def test_item_not_a_pair(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             fieldsets = ((),)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.fieldsets\\[0\\]' does not have exactly two elements.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"fieldsets[0]\" must be a pair.',\n+            'admin.E009')\n \n+    def test_second_element_of_item_not_a_dict(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             fieldsets = ((\"General\", ()),)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.fieldsets\\[0\\]\\[1\\]' must be a dictionary.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"fieldsets[0][1]\" must be a dictionary.',\n+            'admin.E010')\n \n+    def test_missing_fields_key(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             fieldsets = ((\"General\", {}),)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'fields' key is required in ValidationTestModelAdmin.fieldsets\\[0\\]\\[1\\] field options dict.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n-\n-        class ValidationTestModelAdmin(ModelAdmin):\n-            fieldsets = ((\"General\", {\"fields\": (\"name\",)}),)\n-\n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"fieldsets[0][1]\" must contain \"fields\" key.',\n+            'admin.E011')\n \n+    def test_specified_both_fields_and_fieldsets(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             fieldsets = ((\"General\", {\"fields\": (\"name\",)}),)\n             fields = [\"name\",]\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"Both fieldsets and fields are specified in ValidationTestModelAdmin.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+             'Both \"fieldsets\" and \"fields\" are specified.',\n+             'admin.E005')\n \n+    def test_duplicate_fields(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             fieldsets = [(None, {'fields': ['name', 'name']})]\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"There are duplicate field\\(s\\) in ValidationTestModelAdmin.fieldsets\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+             'There are duplicate field(s) in \"fieldsets[0][1]\".',\n+             'admin.E012')\n+\n+    def test_fieldsets_with_custom_form_validation(self):\n+        class BandAdmin(ModelAdmin):\n+            fieldsets = (\n+                ('Band', {\n+                    'fields': ('name',)\n+                }),\n+            )\n+\n+        self.assertIsValid(BandAdmin, Band)\n+\n \n+class FieldsCheckTests(CheckTestCase):\n+\n+    def test_duplicate_fields_in_fields(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             fields = [\"name\", \"name\"]\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"There are duplicate field\\(s\\) in ValidationTestModelAdmin.fields\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            'There are duplicate field(s) in \"fields\".',\n+            'admin.E006')\n+\n+    def test_inline(self):\n+        class ValidationTestInline(TabularInline):\n+            model = ValidationTestInlineModel\n+            fields = 10\n+\n+        class ValidationTestModelAdmin(ModelAdmin):\n+            inlines = [ValidationTestInline]\n+\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"fields\" must be a list or tuple.',\n+            'admin.E004',\n+            invalid_obj=ValidationTestInline)\n \n-    def test_form_validation(self):\n \n+class FormCheckTests(CheckTestCase):\n+\n+    def test_invalid_type(self):\n         class FakeForm(object):\n             pass\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             form = FakeForm\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"ValidationTestModelAdmin.form does not inherit from BaseModelForm.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n-\n-    def test_fieldsets_with_custom_form_validation(self):\n-\n-        class BandAdmin(ModelAdmin):\n-            fieldsets = (\n-                ('Band', {\n-                    'fields': ('name',)\n-                }),\n-            )\n-\n-        BandAdmin.validate(Band)\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"form\" must inherit from BaseModelForm.',\n+            'admin.E016')\n \n+    def test_valid_case(self):\n         class AdminBandForm(forms.ModelForm):\n             delete = forms.BooleanField()\n \n@@ -724,208 +746,212 @@ class BandAdmin(ModelAdmin):\n                 }),\n             )\n \n-        BandAdmin.validate(Band)\n+        self.assertIsValid(BandAdmin, Band)\n \n-    def test_filter_vertical_validation(self):\n \n+class FilterVerticalCheckTests(CheckTestCase):\n+\n+    def test_not_iterable(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             filter_vertical = 10\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.filter_vertical' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"filter_vertical\" must be a list or tuple.',\n+            'admin.E017')\n \n+    def test_missing_field(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             filter_vertical = (\"non_existent_field\",)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.filter_vertical' refers to field 'non_existent_field' that is missing from model 'modeladmin.ValidationTestModel'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"filter_vertical[0]\" refers to field \"non_existent_field\", '\n+                'which is missing from model modeladmin.ValidationTestModel.',\n+            'admin.E019')\n \n+    def test_invalid_field_type(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             filter_vertical = (\"name\",)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.filter_vertical\\[0\\]' must be a ManyToManyField.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"filter_vertical[0]\" must be a ManyToManyField.',\n+            'admin.E020')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             filter_vertical = (\"users\",)\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n+\n \n-    def test_filter_horizontal_validation(self):\n+class FilterHorizontalCheckTests(CheckTestCase):\n \n+    def test_not_iterable(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             filter_horizontal = 10\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.filter_horizontal' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"filter_horizontal\" must be a list or tuple.',\n+            'admin.E018')\n \n+    def test_missing_field(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             filter_horizontal = (\"non_existent_field\",)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.filter_horizontal' refers to field 'non_existent_field' that is missing from model 'modeladmin.ValidationTestModel'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"filter_horizontal[0]\" refers to field \"non_existent_field\", '\n+                'which is missing from model modeladmin.ValidationTestModel.',\n+            'admin.E019')\n \n+    def test_invalid_field_type(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             filter_horizontal = (\"name\",)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.filter_horizontal\\[0\\]' must be a ManyToManyField.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"filter_horizontal[0]\" must be a ManyToManyField.',\n+            'admin.E020')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             filter_horizontal = (\"users\",)\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n+\n+\n+class RadioFieldsCheckTests(CheckTestCase):\n \n-    def test_radio_fields_validation(self):\n+    def test_not_dictionary(self):\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             radio_fields = ()\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.radio_fields' must be a dictionary.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"radio_fields\" must be a dictionary.',\n+            'admin.E021')\n \n+    def test_missing_field(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n-            radio_fields = {\"non_existent_field\": None}\n+            radio_fields = {\"non_existent_field\": VERTICAL}\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.radio_fields' refers to field 'non_existent_field' that is missing from model 'modeladmin.ValidationTestModel'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"radio_fields\" refers to field \"non_existent_field\", '\n+                'which is missing from model modeladmin.ValidationTestModel.',\n+            'admin.E022')\n \n+    def test_invalid_field_type(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n-            radio_fields = {\"name\": None}\n+            radio_fields = {\"name\": VERTICAL}\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.radio_fields\\['name'\\]' is neither an instance of ForeignKey nor does have choices set.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"radio_fields\" refers to \"name\", which is neither an instance '\n+                'of ForeignKey nor does have choices set.',\n+            'admin.E023')\n \n+    def test_invalid_value(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             radio_fields = {\"state\": None}\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.radio_fields\\['state'\\]' is neither admin.HORIZONTAL nor admin.VERTICAL.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"radio_fields[\\'state\\']\" is neither admin.HORIZONTAL nor admin.VERTICAL.',\n+            'admin.E024')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             radio_fields = {\"state\": VERTICAL}\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n+\n \n-    def test_prepopulated_fields_validation(self):\n+class PrepopulatedFieldsCheckTests(CheckTestCase):\n+\n+    def test_not_dictionary(self):\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             prepopulated_fields = ()\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.prepopulated_fields' must be a dictionary.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"prepopulated_fields\" must be a dictionary.',\n+            'admin.E025')\n \n+    def test_missing_field(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n-            prepopulated_fields = {\"non_existent_field\": None}\n+            prepopulated_fields = {\"non_existent_field\": (\"slug\",)}\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.prepopulated_fields' refers to field 'non_existent_field' that is missing from model 'modeladmin.ValidationTestModel'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"prepopulated_fields\" refers to field \"non_existent_field\", '\n+                'which is missing from model modeladmin.ValidationTestModel.',\n+            'admin.E026')\n \n+    def test_missing_field_again(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             prepopulated_fields = {\"slug\": (\"non_existent_field\",)}\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.prepopulated_fields\\['slug'\\]\\[0\\]' refers to field 'non_existent_field' that is missing from model 'modeladmin.ValidationTestModel'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"prepopulated_fields[\\'slug\\'][0]\" refers to field \"non_existent_field\", '\n+                'which is missing from model modeladmin.ValidationTestModel.',\n+            'admin.E029')\n \n+    def test_invalid_field_type(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             prepopulated_fields = {\"users\": (\"name\",)}\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.prepopulated_fields\\['users'\\]' is either a DateTimeField, ForeignKey or ManyToManyField. This isn't allowed.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"prepopulated_fields\" refers to \"users\", which must not be '\n+                'a DateTimeField, ForeignKey or ManyToManyField.',\n+            'admin.E027')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             prepopulated_fields = {\"slug\": (\"name\",)}\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_list_display_validation(self):\n+\n+class ListDisplayTests(CheckTestCase):\n+\n+    def test_not_iterable(self):\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             list_display = 10\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_display' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_display\" must be a list or tuple.',\n+            'admin.E107')\n \n+    def test_missing_field(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_display = ('non_existent_field',)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            str_prefix(\"ValidationTestModelAdmin.list_display\\[0\\], %(_)s'non_existent_field' is not a callable or an attribute of 'ValidationTestModelAdmin' or found in the model 'ValidationTestModel'.\"),\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_display[0]\" is neither a callable nor an attribute '\n+                'of \"ValidationTestModelAdmin\" nor found in model modeladmin.ValidationTestModel.',\n+            'admin.E110')\n \n+    def test_invalid_field_type(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_display = ('users',)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_display\\[0\\]', 'users' is a ManyToManyField which is not supported.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_display[0]\" must not be a ManyToManyField.',\n+            'admin.E109')\n \n+    def test_valid_case(self):\n         def a_callable(obj):\n             pass\n \n@@ -934,40 +960,39 @@ def a_method(self, obj):\n                 pass\n             list_display = ('name', 'decade_published_in', 'a_method', a_callable)\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_list_display_links_validation(self):\n \n+class ListDisplayLinksCheckTests(CheckTestCase):\n+\n+    def test_not_iterable(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_display_links = 10\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_display_links' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_display_links\" must be a list or tuple or None.',\n+            'admin.E111')\n \n+    def test_missing_field(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_display_links = ('non_existent_field',)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_display_links\\[0\\]' refers to 'non_existent_field' which is not defined in 'list_display'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_display_links[0]\" refers to \"non_existent_field\", which is not defined in \"list_display\".',\n+            'admin.E112')\n \n+    def test_missing_in_list_display(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_display_links = ('name',)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_display_links\\[0\\]' refers to 'name' which is not defined in 'list_display'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_display_links[0]\" refers to \"name\", which is not defined in \"list_display\".',\n+            'admin.E112')\n \n+    def test_valid_case(self):\n         def a_callable(obj):\n             pass\n \n@@ -977,58 +1002,60 @@ def a_method(self, obj):\n             list_display = ('name', 'decade_published_in', 'a_method', a_callable)\n             list_display_links = ('name', 'decade_published_in', 'a_method', a_callable)\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n+    def test_None_is_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_display_links = None\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_list_filter_validation(self):\n \n+class ListFilterTests(CheckTestCase):\n+\n+    def test_list_filter_validation(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_filter = 10\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_filter' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_filter\" must be a list or tuple.',\n+            'admin.E113')\n \n+    def test_missing_field(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_filter = ('non_existent_field',)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_filter\\[0\\]' refers to 'non_existent_field' which does not refer to a Field.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_filter[0]\" refers to \"non_existent_field\", which does not refer to a Field.',\n+            'admin.E117')\n \n+    def test_not_filter(self):\n         class RandomClass(object):\n             pass\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             list_filter = (RandomClass,)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_filter\\[0\\]' is 'RandomClass' which is not a descendant of ListFilter.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_filter[0]\" must inherit from ListFilter.',\n+            'admin.E114')\n+\n+    def test_not_filter_again(self):\n+        class RandomClass(object):\n+            pass\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             list_filter = (('is_active', RandomClass),)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_filter\\[0\\]\\[1\\]' is 'RandomClass' which is not of type FieldListFilter.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_filter[0][1]\" must inherit from FieldListFilter.',\n+            'admin.E116')\n \n+    def test_not_filter_again_again(self):\n         class AwesomeFilter(SimpleListFilter):\n             def get_title(self):\n                 return 'awesomeness'\n@@ -1040,240 +1067,255 @@ def get_queryset(self, cl, qs):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_filter = (('is_active', AwesomeFilter),)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_filter\\[0\\]\\[1\\]' is 'AwesomeFilter' which is not of type FieldListFilter.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_filter[0][1]\" must inherit from FieldListFilter.',\n+            'admin.E116')\n \n+    def test_not_associated_with_field_name(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_filter = (BooleanFieldListFilter,)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_filter\\[0\\]' is 'BooleanFieldListFilter' which is of type FieldListFilter but is not associated with a field name.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_filter[0]\" must not inherit from FieldListFilter.',\n+            'admin.E115')\n \n-        # Valid declarations below -----------\n+    def test_valid_case(self):\n+        class AwesomeFilter(SimpleListFilter):\n+            def get_title(self):\n+                return 'awesomeness'\n+            def get_choices(self, request):\n+                return (('bit', 'A bit awesome'), ('very', 'Very awesome'), )\n+            def get_queryset(self, cl, qs):\n+                return qs\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             list_filter = ('is_active', AwesomeFilter, ('is_active', BooleanFieldListFilter), 'no')\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_list_per_page_validation(self):\n \n+class ListPerPageCheckTests(CheckTestCase):\n+\n+    def test_not_integer(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_per_page = 'hello'\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_per_page' should be a int.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_per_page\" must be an integer.',\n+            'admin.E119')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_per_page = 100\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_max_show_all_allowed_validation(self):\n \n+class ListMaxShowAllCheckTests(CheckTestCase):\n+\n+    def test_not_integer(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_max_show_all = 'hello'\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_max_show_all' should be a int.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_max_show_all\" must be an integer.',\n+            'admin.E120')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_max_show_all = 200\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n+\n \n-    def test_search_fields_validation(self):\n+class SearchFieldsCheckTests(CheckTestCase):\n+\n+    def test_not_iterable(self):\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             search_fields = 10\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.search_fields' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"search_fields\" must be a list or tuple.',\n+            'admin.E127')\n \n-    def test_date_hierarchy_validation(self):\n+\n+class DateHierarchyCheckTests(CheckTestCase):\n+\n+    def test_missing_field(self):\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             date_hierarchy = 'non_existent_field'\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.date_hierarchy' refers to field 'non_existent_field' that is missing from model 'modeladmin.ValidationTestModel'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"date_hierarchy\" refers to field \"non_existent_field\", which '\n+                'is missing from model modeladmin.ValidationTestModel.',\n+            'admin.E128')\n \n+    def test_invalid_field_type(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             date_hierarchy = 'name'\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.date_hierarchy is neither an instance of DateField nor DateTimeField.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"date_hierarchy\" must be a DateField or DateTimeField.',\n+            'admin.E129')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             date_hierarchy = 'pub_date'\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n+\n \n-    def test_ordering_validation(self):\n+class OrderingCheckTests(CheckTestCase):\n \n+    def test_not_iterable(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             ordering = 10\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.ordering' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"ordering\" must be a list or tuple.',\n+            'admin.E030')\n \n+    def test_missing_field(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             ordering = ('non_existent_field',)\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.ordering\\[0\\]' refers to field 'non_existent_field' that is missing from model 'modeladmin.ValidationTestModel'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"ordering[0]\" refers to field \"non_existent_field\", '\n+                'which is missing from model modeladmin.ValidationTestModel.',\n+            'admin.E032')\n \n+    def test_random_marker_not_alone(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             ordering = ('?', 'name')\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.ordering' has the random ordering marker '\\?', but contains other fields as well. Please either remove '\\?' or the other fields.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"ordering\" has the random ordering marker \"?\", but contains '\n+                'other fields as well.',\n+            'admin.E031',\n+            hint='Either remove the \"?\", or remove the other fields.')\n \n+    def test_valid_random_marker_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             ordering = ('?',)\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n+    def test_valid_complex_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             ordering = ('band__name',)\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             ordering = ('name',)\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_list_select_related_validation(self):\n \n+class ListSelectRelatedCheckTests(CheckTestCase):\n+\n+    def test_invalid_type(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_select_related = 1\n \n-        six.assertRaisesRegex(\n-            self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.list_select_related' should be either a \"\n-            \"bool, a tuple or a list\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(ValidationTestModelAdmin, ValidationTestModel,\n+            '\"list_select_related\" must be a boolean, tuple or list.',\n+            'admin.E118')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             list_select_related = False\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_save_as_validation(self):\n \n+class SaveAsCheckTests(CheckTestCase):\n+\n+    def test_not_boolean(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             save_as = 1\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.save_as' should be a bool.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"save_as\" must be a boolean.',\n+            'admin.E101')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             save_as = True\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n+\n \n-    def test_save_on_top_validation(self):\n+class SaveOnTopCheckTests(CheckTestCase):\n \n+    def test_not_boolean(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             save_on_top = 1\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.save_on_top' should be a bool.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"save_on_top\" must be a boolean.',\n+            'admin.E102')\n \n+    def test_valid_case(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             save_on_top = True\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n+\n \n-    def test_inlines_validation(self):\n+class InlinesCheckTests(CheckTestCase):\n \n+    def test_not_iterable(self):\n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = 10\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.inlines' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"inlines\" must be a list or tuple.',\n+            'admin.E103')\n \n+    def test_not_model_admin(self):\n         class ValidationTestInline(object):\n             pass\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.inlines\\[0\\]' does not inherit from BaseModelAdmin.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"inlines[0]\" must inherit from BaseModelAdmin.',\n+            'admin.E104')\n \n+    def test_missing_model_field(self):\n         class ValidationTestInline(TabularInline):\n             pass\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'model' is a required attribute of 'ValidationTestModelAdmin.inlines\\[0\\]'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"model\" is a required attribute of \"inlines[0]\".',\n+            'admin.E105')\n+\n+    def test_invalid_model_type(self):\n+        \"\"\" Test if `model` attribute on inline model admin is a models.Model.\n+        \"\"\"\n \n         class SomethingBad(object):\n             pass\n@@ -1284,39 +1326,24 @@ class ValidationTestInline(TabularInline):\n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestModelAdmin.inlines\\[0\\].model' does not inherit from models.Model.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"inlines[0].model\" must be a Model.',\n+            'admin.E106')\n \n+    def test_valid_case(self):\n         class ValidationTestInline(TabularInline):\n             model = ValidationTestInlineModel\n \n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_fields_validation(self):\n \n-        class ValidationTestInline(TabularInline):\n-            model = ValidationTestInlineModel\n-            fields = 10\n-\n-        class ValidationTestModelAdmin(ModelAdmin):\n-            inlines = [ValidationTestInline]\n-\n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestInline.fields' must be a list or tuple.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n-\n-    def test_fk_name_validation(self):\n+class FkNameCheckTests(CheckTestCase):\n \n+    def test_missing_field(self):\n         class ValidationTestInline(TabularInline):\n             model = ValidationTestInlineModel\n             fk_name = \"non_existent_field\"\n@@ -1324,13 +1351,14 @@ class ValidationTestInline(TabularInline):\n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestInline.fk_name' refers to field 'non_existent_field' that is missing from model 'modeladmin.ValidationTestInlineModel'.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"fk_name\" refers to \"non_existent_field\" field, which '\n+                'is missing from model modeladmin.ValidationTestInlineModel.',\n+            'admin.E202',\n+            invalid_obj=ValidationTestInline)\n \n+    def test_valid_case(self):\n         class ValidationTestInline(TabularInline):\n             model = ValidationTestInlineModel\n             fk_name = \"parent\"\n@@ -1338,10 +1366,12 @@ class ValidationTestInline(TabularInline):\n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n+\n \n-    def test_extra_validation(self):\n+class ExtraCheckTests(CheckTestCase):\n \n+    def test_not_integer(self):\n         class ValidationTestInline(TabularInline):\n             model = ValidationTestInlineModel\n             extra = \"hello\"\n@@ -1349,13 +1379,13 @@ class ValidationTestInline(TabularInline):\n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestInline.extra' should be a int.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"extra\" must be an integer.',\n+            'admin.E203',\n+            invalid_obj=ValidationTestInline)\n \n+    def test_valid_case(self):\n         class ValidationTestInline(TabularInline):\n             model = ValidationTestInlineModel\n             extra = 2\n@@ -1363,10 +1393,12 @@ class ValidationTestInline(TabularInline):\n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_max_num_validation(self):\n \n+class MaxNumCheckTests(CheckTestCase):\n+\n+    def test_not_integer(self):\n         class ValidationTestInline(TabularInline):\n             model = ValidationTestInlineModel\n             max_num = \"hello\"\n@@ -1374,13 +1406,13 @@ class ValidationTestInline(TabularInline):\n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestInline.max_num' should be a int.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"max_num\" must be an integer.',\n+            'admin.E204',\n+            invalid_obj=ValidationTestInline)\n \n+    def test_valid_case(self):\n         class ValidationTestInline(TabularInline):\n             model = ValidationTestInlineModel\n             max_num = 2\n@@ -1388,9 +1420,12 @@ class ValidationTestInline(TabularInline):\n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n \n-    def test_formset_validation(self):\n+\n+class FormsetCheckTests(CheckTestCase):\n+\n+    def test_invalid_type(self):\n \n         class FakeFormSet(object):\n             pass\n@@ -1402,13 +1437,13 @@ class ValidationTestInline(TabularInline):\n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        six.assertRaisesRegex(self,\n-            ImproperlyConfigured,\n-            \"'ValidationTestInline.formset' does not inherit from BaseModelFormSet.\",\n-            ValidationTestModelAdmin.validate,\n-            ValidationTestModel,\n-        )\n+        self.assertIsInvalid(\n+            ValidationTestModelAdmin, ValidationTestModel,\n+            '\"formset\" must inherit from BaseModelFormSet.',\n+            'admin.E205',\n+            invalid_obj=ValidationTestInline)\n \n+    def test_valid_case(self):\n         class RealModelFormSet(BaseModelFormSet):\n             pass\n \n@@ -1419,4 +1454,18 @@ class ValidationTestInline(TabularInline):\n         class ValidationTestModelAdmin(ModelAdmin):\n             inlines = [ValidationTestInline]\n \n-        ValidationTestModelAdmin.validate(ValidationTestModel)\n+        self.assertIsValid(ValidationTestModelAdmin, ValidationTestModel)\n+\n+\n+class CustomModelAdminTests(CheckTestCase):\n+\n+    def test_deprecation(self):\n+\n+        class CustomValidator(ModelAdminValidator):\n+            def validate_me(self, model_admin, model):\n+                raise ImproperlyConfigured('error!')\n+\n+        class CustomModelAdmin(ModelAdmin):\n+            validator = CustomValidator\n+\n+        self.assertIsInvalid(CustomModelAdmin, ValidationTestModel, 'error!')\ndiff --git a/tests/proxy_model_inheritance/tests.py b/tests/proxy_model_inheritance/tests.py\nindex 9941506303b4..edbf7ffbf810 100644\n--- a/tests/proxy_model_inheritance/tests.py\n+++ b/tests/proxy_model_inheritance/tests.py\n@@ -4,10 +4,11 @@\n import sys\n \n from django.conf import settings\n+from django.core.checks.registration import framework as check_framework\n from django.core.management import call_command\n from django.db.models.loading import cache, load_app\n from django.test import TestCase, TransactionTestCase\n-from django.test.utils import override_settings\n+from django.test.utils import override_settings, override_system_checks\n from django.utils._os import upath\n \n from .models import (ConcreteModel, ConcreteModelSubclass,\n@@ -39,6 +40,9 @@ def tearDown(self):\n         del cache.app_models['app1']\n         del cache.app_models['app2']\n \n+    # `auth` app is imported, but not installed in this test, so we need to\n+    # exclude checks registered by this app.\n+    @override_system_checks([])\n     def test_table_exists(self):\n         try:\n             cache.set_available_apps(settings.INSTALLED_APPS)\ndiff --git a/tests/sites_framework/models.py b/tests/sites_framework/models.py\nindex 55c4f4992e2a..334acc6b5c7c 100644\n--- a/tests/sites_framework/models.py\n+++ b/tests/sites_framework/models.py\n@@ -27,12 +27,3 @@ class CustomArticle(AbstractArticle):\n \n     objects = models.Manager()\n     on_site = CurrentSiteManager(\"places_this_article_should_appear\")\n-\n-class InvalidArticle(AbstractArticle):\n-    site = models.ForeignKey(Site)\n-\n-    objects = models.Manager()\n-    on_site = CurrentSiteManager(\"places_this_article_should_appear\")\n-\n-class ConfusedArticle(AbstractArticle):\n-    site = models.IntegerField()\ndiff --git a/tests/sites_framework/tests.py b/tests/sites_framework/tests.py\nindex 7860394aa2c7..6e030752fd37 100644\n--- a/tests/sites_framework/tests.py\n+++ b/tests/sites_framework/tests.py\n@@ -1,18 +1,35 @@\n from django.conf import settings\n+from django.contrib.sites.managers import CurrentSiteManager\n from django.contrib.sites.models import Site\n+from django.core import checks\n+from django.db.models.loading import cache\n from django.test import TestCase\n \n from .models import (SyndicatedArticle, ExclusiveArticle, CustomArticle,\n-    InvalidArticle, ConfusedArticle)\n+    AbstractArticle)\n \n \n class SitesFrameworkTestCase(TestCase):\n     def setUp(self):\n-        Site.objects.get_or_create(id=settings.SITE_ID, domain=\"example.com\", name=\"example.com\")\n-        Site.objects.create(id=settings.SITE_ID+1, domain=\"example2.com\", name=\"example2.com\")\n+        Site.objects.get_or_create(id=settings.SITE_ID,\n+            domain=\"example.com\", name=\"example.com\")\n+        Site.objects.create(id=settings.SITE_ID+1,\n+            domain=\"example2.com\", name=\"example2.com\")\n+        self._clear_app_cache()\n+\n+    def tearDown(self):\n+        self._clear_app_cache()\n+\n+    def _clear_app_cache(self):\n+        # If you create a model in a test, the model is accessible in other\n+        # tests. To avoid this, we need to clear list of all models created in\n+        # `sites_framework` module.\n+        cache.app_models['sites_framework'] = {}\n+        cache._get_models_cache = {}\n \n     def test_site_fk(self):\n-        article = ExclusiveArticle.objects.create(title=\"Breaking News!\", site_id=settings.SITE_ID)\n+        article = ExclusiveArticle.objects.create(title=\"Breaking News!\",\n+            site_id=settings.SITE_ID)\n         self.assertEqual(ExclusiveArticle.on_site.all().get(), article)\n \n     def test_sites_m2m(self):\n@@ -24,13 +41,46 @@ def test_sites_m2m(self):\n         self.assertEqual(SyndicatedArticle.on_site.all().get(), article)\n \n     def test_custom_named_field(self):\n-        article = CustomArticle.objects.create(title=\"Tantalizing News!\", places_this_article_should_appear_id=settings.SITE_ID)\n+        article = CustomArticle.objects.create(title=\"Tantalizing News!\",\n+            places_this_article_should_appear_id=settings.SITE_ID)\n         self.assertEqual(CustomArticle.on_site.all().get(), article)\n \n     def test_invalid_name(self):\n-        article = InvalidArticle.objects.create(title=\"Bad News!\", site_id=settings.SITE_ID)\n-        self.assertRaises(ValueError, InvalidArticle.on_site.all)\n+        from django.db import models\n+\n+        class InvalidArticle(AbstractArticle):\n+            site = models.ForeignKey(Site)\n+\n+            objects = models.Manager()\n+            on_site = CurrentSiteManager(\"places_this_article_should_appear\")\n+\n+        errors = InvalidArticle.check()\n+        expected = [\n+            checks.Error(\n+                'CurrentSiteManager could not find a field named '\n+                    '\"places_this_article_should_appear\".',\n+                hint='Ensure that you did not misspell the field name. '\n+                    'Does the field exist?',\n+                obj=InvalidArticle.on_site,\n+                id='sites.E001',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\n \n     def test_invalid_field_type(self):\n-        article = ConfusedArticle.objects.create(title=\"More Bad News!\", site=settings.SITE_ID)\n-        self.assertRaises(TypeError, ConfusedArticle.on_site.all)\n+        from django.db import models\n+\n+        class ConfusedArticle(AbstractArticle):\n+            site = models.IntegerField()\n+\n+        errors = ConfusedArticle.check()\n+        expected = [\n+            checks.Error(\n+                'ConfusedArticle.site is used by a CurrentSiteManager '\n+                    'and must be a ForeignKey or ManyToManyField.',\n+                hint=None,\n+                obj=ConfusedArticle.on_site,\n+                id='sites.E002',\n+            )\n+        ]\n+        self.assertEqual(errors, expected)\ndiff --git a/tests/test_runner/tests.py b/tests/test_runner/tests.py\nindex 00b5e9c978ce..d7f784a4e45d 100644\n--- a/tests/test_runner/tests.py\n+++ b/tests/test_runner/tests.py\n@@ -5,7 +5,6 @@\n \n from importlib import import_module\n from optparse import make_option\n-import sys\n import unittest\n \n from django.core.exceptions import ImproperlyConfigured\n@@ -13,7 +12,7 @@\n from django import db\n from django.test import runner, TestCase, TransactionTestCase, skipUnlessDBFeature\n from django.test.testcases import connections_support_transactions\n-from django.test.utils import IgnoreAllDeprecationWarningsMixin\n+from django.test.utils import IgnoreAllDeprecationWarningsMixin, override_system_checks\n \n from admin_scripts.tests import AdminScriptTestCase\n from .models import Person\n@@ -247,6 +246,9 @@ class Sqlite3InMemoryTestDbs(TestCase):\n \n     @unittest.skipUnless(all(db.connections[conn].vendor == 'sqlite' for conn in db.connections),\n                          \"This is an sqlite-specific issue\")\n+    # `setup_databases` triggers system check framework, but we do not want to\n+    # perform checks.\n+    @override_system_checks([])\n     def test_transaction_support(self):\n         \"\"\"Ticket #16329: sqlite3 in-memory test databases\"\"\"\n         old_db_connections = db.connections\ndiff --git a/tests/test_sqlite.py b/tests/test_sqlite.py\nindex 6bce452c79c0..3e846376f918 100644\n--- a/tests/test_sqlite.py\n+++ b/tests/test_sqlite.py\n@@ -27,3 +27,5 @@\n PASSWORD_HASHERS = (\n     'django.contrib.auth.hashers.MD5PasswordHasher',\n )\n+\n+TEST_RUNNER = \"django.test.runner.DiscoverRunner\"\ndiff --git a/tests/user_commands/management/commands/dance.py b/tests/user_commands/management/commands/dance.py\nindex 911530d223d8..7297568f0603 100644\n--- a/tests/user_commands/management/commands/dance.py\n+++ b/tests/user_commands/management/commands/dance.py\n@@ -6,7 +6,7 @@\n class Command(BaseCommand):\n     help = \"Dance around like a madman.\"\n     args = ''\n-    requires_model_validation = True\n+    requires_system_checks = True\n \n     option_list = BaseCommand.option_list + (\n         make_option(\"-s\", \"--style\", default=\"Rock'n'Roll\"),\ndiff --git a/tests/validation/test_error_messages.py b/tests/validation/test_error_messages.py\nindex aa01db6007a6..be41cdd07a2d 100644\n--- a/tests/validation/test_error_messages.py\n+++ b/tests/validation/test_error_messages.py\n@@ -19,10 +19,6 @@ def test_autofield_field_raises_error_message(self):\n         f = models.AutoField(primary_key=True)\n         self._test_validation_messages(f, 'fõo',\n             [\"'fõo' value must be an integer.\"])\n-        # primary_key must be True. Refs #12467.\n-        with six.assertRaisesRegex(self, AssertionError,\n-                \"AutoFields must have primary_key=True.\"):\n-            models.AutoField(primary_key=False)\n \n     def test_integer_field_raises_error_message(self):\n         f = models.IntegerField()\n",
    "diff_length": 467197
  },
  {
    "index": 11,
    "filtered_comments": [
      "Hey @carltongibson! \r\nSo I was going trying to work on the coverages of each backend. However, one tests keeps failing. \r\n`cache.tests.CreateCacheTableForDBCacheTests.test_createcachetable_observes_database_router`\r\n```\r\n======================================================================\r\nFAIL: test_createcachetable_observes_database_router (cache.tests.CreateCacheTableForDBCacheTests)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/daniyal/Desktop/django/django/test/utils.py\", line 430, in inner\r\n    return func(*args, **kwargs)\r\n  File \"/home/daniyal/Desktop/django/tests/cache/tests.py\", line 1238, in test_createcachetable_observes_database_router\r\n    management.call_command('createcachetable', database='other', verbosity=0)\r\n  File \"/home/daniyal/Desktop/django/django/test/testcases.py\", line 86, in __exit__\r\n    self.test_case.assertEqual(\r\nAssertionError: 1 != 5 : 1 queries executed, 5 expected\r\nCaptured queries were:\r\n1. \r\n            SELECT c.relname,\r\n            CASE WHEN c.relispartition THEN 'p' WHEN c.relkind IN ('m', 'v') THEN 'v' ELSE 't' END\r\n            FROM pg_catalog.pg_class c\r\n            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace\r\n            WHERE c.relkind IN ('f', 'm', 'p', 'r', 'v')\r\n                AND n.nspname NOT IN ('pg_catalog', 'pg_toast')\r\n                AND pg_catalog.pg_table_is_visible(c.oid)\r\n        \r\n\r\n----------------------------------------------------------------------\r\n```\r\n\r\nI did not completely understand the reason for this. \r\nMy test settings were\r\n```\r\nDATABASES = {\r\n    'default': {\r\n        'ENGINE': 'django.db.backends.postgresql',\r\n        'NAME': 'mydb_default',\r\n        'USER': 'myuser',\r\n        'PASSWORD': 'password',\r\n        'HOST': 'localhost',\r\n        'PORT': '5432',\r\n    },\r\n    'other': {\r\n        'ENGINE': 'django.db.backends.postgresql',\r\n        'NAME': 'mydb_other',\r\n        'USER': 'myuser',\r\n        'PASSWORD': 'password',\r\n        'HOST': 'localhost',\r\n        'PORT': '5432',\r\n    }\r\n}\r\n\r\nCACHES = {\r\n    \"default\": {\r\n        \"BACKEND\": \"django.core.cache.backends.db.DatabaseCache\",\r\n        \"LOCATION\": \"my_cache_table\",\r\n    },\r\n}\r\n```\r\nTried and tested with SQLite as well, and got the same results. \r\nError with SQLite\r\n```\r\n======================================================================\r\nFAIL: test_createcachetable_observes_database_router (cache.tests.CreateCacheTableForDBCacheTests)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/daniyal/Desktop/django/django/test/utils.py\", line 430, in inner\r\n    return func(*args, **kwargs)\r\n  File \"/home/daniyal/Desktop/django/tests/cache/tests.py\", line 1238, in test_createcachetable_observes_database_router\r\n    management.call_command('createcachetable', database='other', verbosity=0)\r\n  File \"/home/daniyal/Desktop/django/django/test/testcases.py\", line 86, in __exit__\r\n    self.test_case.assertEqual(\r\nAssertionError: 1 != 5 : 1 queries executed, 5 expected\r\nCaptured queries were:\r\n1. \r\n            SELECT name, type FROM sqlite_master\r\n            WHERE type in ('table', 'view') AND NOT name='sqlite_sequence'\r\n            ORDER BY name\r\n\r\n----------------------------------------------------------------------\r\n```\r\n\r\nHowever, when I comment out this line, which call `createcachetable`, the test passes.\r\nhttps://github.com/django/django/blob/d270dd584e0af12fe6229fb712d0704c232dc7e5/django/db/backends/base/creation.py#L92\r\n",
      "Hey @carltongibson !\r\nI've just pushed the lastest update that I have. I've adapted the existsing tests for the new backend. The tests are failing at two instance\r\n- Culling\r\n- zero and negative timeout handling : Redis-py does not support 0 or negative timeouts. I have implemented the `get_backend_timeout` similar to the memcache backend but I'm still not sure about how to handle 0 timeout. Ideally it should not store the key in the first place.",
      "> Hey @carltongibson!\r\n> So I was going trying to work on the coverages of each backend. However, one tests keeps failing.\r\n> `cache.tests.CreateCacheTableForDBCacheTests.test_createcachetable_observes_database_router`\r\n> \r\n> ```\r\n> ======================================================================\r\n> FAIL: test_createcachetable_observes_database_router (cache.tests.CreateCacheTableForDBCacheTests)\r\n> ----------------------------------------------------------------------\r\n> Traceback (most recent call last):\r\n>   File \"/home/daniyal/Desktop/django/django/test/utils.py\", line 430, in inner\r\n>     return func(*args, **kwargs)\r\n>   File \"/home/daniyal/Desktop/django/tests/cache/tests.py\", line 1238, in test_createcachetable_observes_database_router\r\n>     management.call_command('createcachetable', database='other', verbosity=0)\r\n>   File \"/home/daniyal/Desktop/django/django/test/testcases.py\", line 86, in __exit__\r\n>     self.test_case.assertEqual(\r\n> AssertionError: 1 != 5 : 1 queries executed, 5 expected\r\n> Captured queries were:\r\n> 1. \r\n>             SELECT c.relname,\r\n>             CASE WHEN c.relispartition THEN 'p' WHEN c.relkind IN ('m', 'v') THEN 'v' ELSE 't' END\r\n>             FROM pg_catalog.pg_class c\r\n>             LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace\r\n>             WHERE c.relkind IN ('f', 'm', 'p', 'r', 'v')\r\n>                 AND n.nspname NOT IN ('pg_catalog', 'pg_toast')\r\n>                 AND pg_catalog.pg_table_is_visible(c.oid)\r\n>         \r\n> \r\n> ----------------------------------------------------------------------\r\n> ```\r\n> \r\n> I did not completely understand the reason for this.\r\n> My test settings were\r\n> \r\n> ```\r\n> DATABASES = {\r\n>     'default': {\r\n>         'ENGINE': 'django.db.backends.postgresql',\r\n>         'NAME': 'mydb_default',\r\n>         'USER': 'myuser',\r\n>         'PASSWORD': 'password',\r\n>         'HOST': 'localhost',\r\n>         'PORT': '5432',\r\n>     },\r\n>     'other': {\r\n>         'ENGINE': 'django.db.backends.postgresql',\r\n>         'NAME': 'mydb_other',\r\n>         'USER': 'myuser',\r\n>         'PASSWORD': 'password',\r\n>         'HOST': 'localhost',\r\n>         'PORT': '5432',\r\n>     }\r\n> }\r\n> \r\n> CACHES = {\r\n>     \"default\": {\r\n>         \"BACKEND\": \"django.core.cache.backends.db.DatabaseCache\",\r\n>         \"LOCATION\": \"my_cache_table\",\r\n>     },\r\n> }\r\n> ```\r\n> \r\n> Tried and tested with SQLite as well, and got the same results.\r\n> Error with SQLite\r\n> \r\n> ```\r\n> ======================================================================\r\n> FAIL: test_createcachetable_observes_database_router (cache.tests.CreateCacheTableForDBCacheTests)\r\n> ----------------------------------------------------------------------\r\n> Traceback (most recent call last):\r\n>   File \"/home/daniyal/Desktop/django/django/test/utils.py\", line 430, in inner\r\n>     return func(*args, **kwargs)\r\n>   File \"/home/daniyal/Desktop/django/tests/cache/tests.py\", line 1238, in test_createcachetable_observes_database_router\r\n>     management.call_command('createcachetable', database='other', verbosity=0)\r\n>   File \"/home/daniyal/Desktop/django/django/test/testcases.py\", line 86, in __exit__\r\n>     self.test_case.assertEqual(\r\n> AssertionError: 1 != 5 : 1 queries executed, 5 expected\r\n> Captured queries were:\r\n> 1. \r\n>             SELECT name, type FROM sqlite_master\r\n>             WHERE type in ('table', 'view') AND NOT name='sqlite_sequence'\r\n>             ORDER BY name\r\n> \r\n> ----------------------------------------------------------------------\r\n> ```\r\n> \r\n> However, when I comment out this line, which call `createcachetable`, the test passes.\r\n> https://github.com/django/django/blob/d270dd584e0af12fe6229fb712d0704c232dc7e5/django/db/backends/base/creation.py#L92\r\n\r\n@carltongibson I was able to figure this one out. I was following the [documentation](https://docs.djangoproject.com/en/3.2/topics/cache/#database-caching) to setup the DatabaseCache.\r\n```\r\nCACHES = {\r\n    \"default\": {\r\n        \"BACKEND\": \"django.core.cache.backends.db.DatabaseCache\",\r\n        \"LOCATION\": \"my_cache_table\",\r\n    },\r\n}\r\n```\r\nHowever, I believe `my_cache_table` was conflicting with this\r\nhttps://github.com/django/django/blob/225d96533a8e05debd402a2bfe566487cc27d95f/tests/cache/tests.py#L1213-L1220\r\n\r\nSetting the \"LOCATION\" to some other table name leads to the test passing. \r\n\r\nMaybe we could mention it in the docs somewhere or update the test to check if duplicate table names exists? This is a little off-topic from this PR. Should I create a separate ticket for this? Or should we let it be for now?\r\n",
      "Hey!\r\nI've made the changes suggested by @pope1ni. I've updated the tests and added\r\n```\r\nredis_excluded_caches = {'cull', 'zero_cull'}\r\n...\r\n@override_settings(CACHES=caches_setting_for_tests(\r\n    base=RedisCache_params,\r\n    exclude=redis_excluded_caches\r\n))\r\nclass RedisCacheTests(BaseCacheTests, TestCase):\r\n    ...\r\n```\r\nNow only on test fails. Handling zero timeout. Redis-py does not support it natively and django expects to no set a key with zero timeout. I'm not sure at which level should this be handled. I was wondering if we perform the check in `get_backend_timeout` method and return a value (eg: None) or raise a suitable exception. \r\n",
      "> If `redis-py` isn't installed, or if Redis isn't running we get a couple of errors:\r\n> \r\n> ```\r\n> django.core.cache.backends.base.InvalidCacheBackendError: Could not find backend 'django.core.cache.backends.redis.RedisCache': No module named 'redis'\r\n> ```\r\n> \r\n\r\nShould I move the `import redis` line inside the `__init__` method of the RedisCache class? All memcache backend do that and the error raised when a binding is not installed is like this\r\n```\r\nModuleNotFoundError: No module named 'pymemcache'\r\n```\r\nIncluding `import redis` at the top leads to an error message as you mentioned above.\r\nI wanted to move the import command like this\r\n```\r\nclass RedisCache(BaseCache):\r\n    def __init__(self, server, params):\r\n        import redis\r\n        super().__init__(params)\r\n        if isinstance(server, str):\r\n            self._servers = re.split('[;,]', server)\r\n        else:\r\n            self._servers = server\r\n\r\n        self._class = RedisCacheClient\r\n        self._options = params.get('OPTIONS') or {}\r\n```\r\nHowever, this would lead to some refactoring of code where `redis.ConnectionPool` etc are used.\r\nWhat do you think about this?\r\n",
      "> Should I move the `import redis` line inside the `__init__` method of the RedisCache class? All memcache backend do that and the error raised when a binding is not installed is like this\r\n\r\nYes, we should do something like this. Although with `pymemcache` it is done in `PyMemcacheCache.__init__()` because `pymemcache` provides the client class. We're writing the client class ourselves, so we want `import redis` in `RedisCacheClient.__init__()`.",
      "Hey @pope1ni and @carltongibson \r\n\r\nAccording to the comments https://github.com/django/django/pull/14437#pullrequestreview-691776531, if we want to use the `redis.incr` or `redis.decr`, we would need to stop serializing the valus which are integers. I think this will create a mess as there would be too much to manual handling of values based on their types. As we are pickling the values, we can not directly use the `redis.incr` or `redis.decr` methods.\r\n\r\nI'm not sure how useful it is to support milli-second timeouts. `django-redis` has migrated to an approach which supports both seconds and milliseconds ( [refs](https://github.com/jazzband/django-redis/pull/508/files) ). \r\n\r\nWe can make the logical databases configurable via the url as well as a parameter in the options. I'll work on it.\r\n\r\n",
      "While using the `from_url` method, we can not provide `username` and `password` in the `OPTIONS`. Even if we pass them in the kwargs, [kwargs.update(...)](https://redis-py.readthedocs.io/en/stable/_modules/redis/connection.html#ConnectionPool.from_url) overrides it with the `username` and `password` from the URL, else it sets it to None. One solution is that we only allow username and password to be set using the \"LOCATION\" key only. Let me know what you feel. @pope1ni @carltongibson ",
      "The master branch of redis-py has updated the implementation of the `from_url` method. \r\nhttps://github.com/andymccurdy/redis-py/blob/627db540acd1f1f36db88290d74cbcd75f6bda0c/redis/connection.py#L951-L955\r\n\r\nHowever, the latest stable branch (3.5.3) still uses the old implementation.\r\n```\r\nif decode_components:\r\n    username = unquote(url.username) if url.username else None\r\n    password = unquote(url.password) if url.password else None\r\n    path = unquote(url.path) if url.path else None\r\n    hostname = unquote(url.hostname) if url.hostname else None\r\nelse:\r\n    username = url.username or None\r\n    password = url.password or None\r\n    path = url.path\r\n    hostname = url.hostname\r\n\r\nif url.scheme == 'unix':\r\n    url_options.update({\r\n                'username': username,\r\n                'password': password,\r\n                'path': path,\r\n                'connection_class': UnixDomainSocketConnection,    \r\n})\r\n\r\nelif url.scheme in ('redis', 'rediss'):\r\n    url_options.update({\r\n                'host': hostname,\r\n                'port': int(url.port or 6379),\r\n                'username': username,\r\n                'password': password,\r\n            })\r\n...\r\nkwargs.update(url_options)\r\n```\r\nThis will always override the username and password in the kwargs. I think for now, we can only support giving the `username` and `password` via the url and once redis-py's latest implementation is stable, we can add supplying  `username` and `password` via the `OPTIONS`.\r\n",
      "Hey @smithdc1! Thank you for the review.\r\n\r\n\r\n> I'm not so confident to comment on the main part with all the different options. I think my main observation there is about the structure, I find it a little hard to follow. There's many options here but here's one idea of how it could be structured.\r\n> \r\n> * Required settings\r\n> * settings which are available to all backends\r\n> * Redis specific items (optional)\r\n\r\nYes we could do that but that'll require restructing the whole documentation as there are some memcached specific items that are currently laid out in the examples section. In the future, I think such a restructuring would be nice where we can talk about cache specific arguements in a separate section.\r\n"
    ],
    "code_diff": "diff --git a/django/core/cache/backends/redis.py b/django/core/cache/backends/redis.py\nnew file mode 100644\nindex 000000000000..16556b1ded5c\n--- /dev/null\n+++ b/django/core/cache/backends/redis.py\n@@ -0,0 +1,224 @@\n+\"\"\"Redis cache backend.\"\"\"\n+\n+import random\n+import re\n+\n+from django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache\n+from django.core.serializers.base import PickleSerializer\n+from django.utils.functional import cached_property\n+from django.utils.module_loading import import_string\n+\n+\n+class RedisSerializer(PickleSerializer):\n+    def dumps(self, obj):\n+        if isinstance(obj, int):\n+            return obj\n+        return super().dumps(obj)\n+\n+    def loads(self, data):\n+        try:\n+            return int(data)\n+        except ValueError:\n+            return super().loads(data)\n+\n+\n+class RedisCacheClient:\n+    def __init__(\n+        self,\n+        servers,\n+        serializer=None,\n+        db=None,\n+        pool_class=None,\n+        parser_class=None,\n+    ):\n+        import redis\n+\n+        self._lib = redis\n+        self._servers = servers\n+        self._pools = {}\n+\n+        self._client = self._lib.Redis\n+\n+        if isinstance(pool_class, str):\n+            pool_class = import_string(pool_class)\n+        self._pool_class = pool_class or self._lib.ConnectionPool\n+\n+        if isinstance(serializer, str):\n+            serializer = import_string(serializer)\n+        if callable(serializer):\n+            serializer = serializer()\n+        self._serializer = serializer or RedisSerializer()\n+\n+        if isinstance(parser_class, str):\n+            parser_class = import_string(parser_class)\n+        parser_class = parser_class or self._lib.connection.DefaultParser\n+\n+        self._pool_options = {'parser_class': parser_class, 'db': db}\n+\n+    def _get_connection_pool_index(self, write):\n+        # Write to the first server. Read from other servers if there are more,\n+        # otherwise read from the first server.\n+        if write or len(self._servers) == 1:\n+            return 0\n+        return random.randint(1, len(self._servers) - 1)\n+\n+    def _get_connection_pool(self, write):\n+        index = self._get_connection_pool_index(write)\n+        if index not in self._pools:\n+            self._pools[index] = self._pool_class.from_url(\n+                self._servers[index], **self._pool_options,\n+            )\n+        return self._pools[index]\n+\n+    def get_client(self, key=None, *, write=False):\n+        # key is used so that the method signature remains the same and custom\n+        # cache client can be implemented which might require the key to select\n+        # the server, e.g. sharding.\n+        pool = self._get_connection_pool(write)\n+        return self._client(connection_pool=pool)\n+\n+    def add(self, key, value, timeout):\n+        client = self.get_client(key, write=True)\n+        value = self._serializer.dumps(value)\n+\n+        if timeout == 0:\n+            if ret := bool(client.set(key, value, nx=True)):\n+                client.delete(key)\n+            return ret\n+        else:\n+            return bool(client.set(key, value, ex=timeout, nx=True))\n+\n+    def get(self, key, default):\n+        client = self.get_client(key)\n+        value = client.get(key)\n+        return default if value is None else self._serializer.loads(value)\n+\n+    def set(self, key, value, timeout):\n+        client = self.get_client(key, write=True)\n+        value = self._serializer.dumps(value)\n+        if timeout == 0:\n+            client.delete(key)\n+        else:\n+            client.set(key, value, ex=timeout)\n+\n+    def touch(self, key, timeout):\n+        client = self.get_client(key, write=True)\n+        if timeout is None:\n+            return bool(client.persist(key))\n+        else:\n+            return bool(client.expire(key, timeout))\n+\n+    def delete(self, key):\n+        client = self.get_client(key, write=True)\n+        return bool(client.delete(key))\n+\n+    def get_many(self, keys):\n+        client = self.get_client(None)\n+        ret = client.mget(keys)\n+        return {\n+            k: self._serializer.loads(v) for k, v in zip(keys, ret) if v is not None\n+        }\n+\n+    def has_key(self, key):\n+        client = self.get_client(key)\n+        return bool(client.exists(key))\n+\n+    def incr(self, key, delta):\n+        client = self.get_client(key)\n+        if not client.exists(key):\n+            raise ValueError(\"Key '%s' not found.\" % key)\n+        return client.incr(key, delta)\n+\n+    def set_many(self, data, timeout):\n+        client = self.get_client(None, write=True)\n+        pipeline = client.pipeline()\n+        pipeline.mset({k: self._serializer.dumps(v) for k, v in data.items()})\n+\n+        if timeout is not None:\n+            # Setting timeout for each key as redis does not support timeout\n+            # with mset().\n+            for key in data:\n+                pipeline.expire(key, timeout)\n+        pipeline.execute()\n+\n+    def delete_many(self, keys):\n+        client = self.get_client(None, write=True)\n+        client.delete(*keys)\n+\n+    def clear(self):\n+        client = self.get_client(None, write=True)\n+        return bool(client.flushdb())\n+\n+\n+class RedisCache(BaseCache):\n+    def __init__(self, server, params):\n+        super().__init__(params)\n+        if isinstance(server, str):\n+            self._servers = re.split('[;,]', server)\n+        else:\n+            self._servers = server\n+\n+        self._class = RedisCacheClient\n+        self._options = params.get('OPTIONS', {})\n+\n+    @cached_property\n+    def _cache(self):\n+        return self._class(self._servers, **self._options)\n+\n+    def get_backend_timeout(self, timeout=DEFAULT_TIMEOUT):\n+        if timeout == DEFAULT_TIMEOUT:\n+            timeout = self.default_timeout\n+        # The key will be made persistent if None used as a timeout.\n+        # Non-positive values will cause the key to be deleted.\n+        return None if timeout is None else max(0, int(timeout))\n+\n+    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n+        key = self.make_and_validate_key(key, version=version)\n+        return self._cache.add(key, value, self.get_backend_timeout(timeout))\n+\n+    def get(self, key, default=None, version=None):\n+        key = self.make_and_validate_key(key, version=version)\n+        return self._cache.get(key, default)\n+\n+    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n+        key = self.make_and_validate_key(key, version=version)\n+        self._cache.set(key, value, self.get_backend_timeout(timeout))\n+\n+    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):\n+        key = self.make_and_validate_key(key, version=version)\n+        return self._cache.touch(key, self.get_backend_timeout(timeout))\n+\n+    def delete(self, key, version=None):\n+        key = self.make_and_validate_key(key, version=version)\n+        return self._cache.delete(key)\n+\n+    def get_many(self, keys, version=None):\n+        key_map = {self.make_and_validate_key(key, version=version): key for key in keys}\n+        ret = self._cache.get_many(key_map.keys())\n+        return {key_map[k]: v for k, v in ret.items()}\n+\n+    def has_key(self, key, version=None):\n+        key = self.make_and_validate_key(key, version=version)\n+        return self._cache.has_key(key)\n+\n+    def incr(self, key, delta=1, version=None):\n+        key = self.make_and_validate_key(key, version=version)\n+        return self._cache.incr(key, delta)\n+\n+    def set_many(self, data, timeout=DEFAULT_TIMEOUT, version=None):\n+        safe_data = {}\n+        for key, value in data.items():\n+            key = self.make_and_validate_key(key, version=version)\n+            safe_data[key] = value\n+        self._cache.set_many(safe_data, self.get_backend_timeout(timeout))\n+        return []\n+\n+    def delete_many(self, keys, version=None):\n+        safe_keys = []\n+        for key in keys:\n+            key = self.make_and_validate_key(key, version=version)\n+            safe_keys.append(key)\n+        self._cache.delete_many(safe_keys)\n+\n+    def clear(self):\n+        return self._cache.clear()\ndiff --git a/docs/internals/contributing/writing-code/unit-tests.txt b/docs/internals/contributing/writing-code/unit-tests.txt\nindex 6a5bd5ab8f05..9bba72c451af 100644\n--- a/docs/internals/contributing/writing-code/unit-tests.txt\n+++ b/docs/internals/contributing/writing-code/unit-tests.txt\n@@ -285,6 +285,7 @@ dependencies:\n *  PyYAML_\n *  pytz_ (required)\n *  pywatchman_\n+*  redis_\n *  setuptools_\n *  memcached_, plus a :ref:`supported Python binding <memcached>`\n *  gettext_ (:ref:`gettext_on_windows`)\n@@ -308,8 +309,9 @@ encounter.\n You can also install the database adapter(s) of your choice using\n ``oracle.txt``, ``mysql.txt``, or ``postgres.txt``.\n \n-If you want to test the memcached cache backend, you'll also need to define\n-a :setting:`CACHES` setting that points at your memcached instance.\n+If you want to test the memcached or Redis cache backends, you'll also need to\n+define a :setting:`CACHES` setting that points at your memcached or Redis\n+instance respectively.\n \n To run the GeoDjango tests, you will need to :doc:`set up a spatial database\n and install the Geospatial libraries</ref/contrib/gis/install/index>`.\n@@ -332,6 +334,7 @@ service.\n .. _PyYAML: https://pyyaml.org/wiki/PyYAML\n .. _pytz: https://pypi.org/project/pytz/\n .. _pywatchman: https://pypi.org/project/pywatchman/\n+.. _redis: https://pypi.org/project/redis/\n .. _setuptools: https://pypi.org/project/setuptools/\n .. _memcached: https://memcached.org/\n .. _gettext: https://www.gnu.org/software/gettext/manual/gettext.html\ndiff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 12d89142d103..0c5b3fe3072d 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -153,6 +153,7 @@ The cache backend to use. The built-in cache backends are:\n * ``'django.core.cache.backends.locmem.LocMemCache'``\n * ``'django.core.cache.backends.memcached.PyMemcacheCache'``\n * ``'django.core.cache.backends.memcached.PyLibMCCache'``\n+* ``'django.core.cache.backends.redis.RedisCache'``\n \n You can use a cache backend that doesn't ship with Django by setting\n :setting:`BACKEND <CACHES-BACKEND>` to a fully-qualified path of a cache\n@@ -162,6 +163,10 @@ backend class (i.e. ``mypackage.backends.whatever.WhateverCache``).\n \n     The ``PyMemcacheCache`` backend was added.\n \n+.. versionchanged:: 4.0\n+\n+    The ``RedisCache`` backend was added.\n+\n .. setting:: CACHES-KEY_FUNCTION\n \n ``KEY_FUNCTION``\ndiff --git a/docs/releases/4.0.txt b/docs/releases/4.0.txt\nindex 709363a08f76..540500af4734 100644\n--- a/docs/releases/4.0.txt\n+++ b/docs/releases/4.0.txt\n@@ -65,6 +65,16 @@ The new :ref:`scrypt password hasher <scrypt-usage>` is more secure and\n recommended over PBKDF2. However, it's not the default as it requires OpenSSL\n 1.1+ and more memory.\n \n+Redis cache backend\n+-------------------\n+\n+The new ``django.core.cache.backends.redis.RedisCache`` cache backend provides\n+built-in support for caching with Redis. `redis-py`_ 3.0.0 or higher is\n+required. For more details, see the :ref:`documentation on caching with Redis\n+in Django <redis>`.\n+\n+.. _`redis-py`: https://pypi.org/project/redis/\n+\n Minor features\n --------------\n \ndiff --git a/docs/spelling_wordlist b/docs/spelling_wordlist\nindex bd8785cf67f6..8d9b17a43d1b 100644\n--- a/docs/spelling_wordlist\n+++ b/docs/spelling_wordlist\n@@ -423,6 +423,7 @@ recomputation\n recursed\n redeclare\n redirections\n+redis\n redisplay\n redisplayed\n redisplaying\ndiff --git a/docs/topics/cache.txt b/docs/topics/cache.txt\nindex 0f25260672ce..3bc35fd51d06 100644\n--- a/docs/topics/cache.txt\n+++ b/docs/topics/cache.txt\n@@ -62,7 +62,6 @@ settings file. Here's an explanation of all available values for\n Memcached\n ---------\n \n-The fastest, most efficient type of cache supported natively by Django,\n Memcached__ is an entirely memory-based cache server, originally developed\n to handle high loads at LiveJournal.com and subsequently open-sourced by\n Danga Interactive. It is used by sites such as Facebook and Wikipedia to\n@@ -169,6 +168,71 @@ particularly temporary.\n     some problems and seems to be unmaintained. Use ``PyMemcacheCache`` or\n     ``PyLibMCCache`` instead.\n \n+.. _redis:\n+\n+Redis\n+-----\n+\n+.. versionadded:: 4.0\n+\n+Redis__ is an in-memory database that can be used for caching. To begin you'll\n+need a Redis server running either locally or on a remote machine.\n+\n+__ https://redis.io/\n+\n+After setting up the Redis server, you'll need to install Python bindings for\n+Redis. `redis-py`_ is the binding supported natively by Django. Installing the\n+additional `hiredis-py`_ package is also recommended.\n+\n+.. _`redis-py`: https://pypi.org/project/redis/\n+.. _`hiredis-py`: https://pypi.org/project/hiredis/\n+\n+To use Redis as your cache backend with Django:\n+\n+* Set :setting:`BACKEND <CACHES-BACKEND>` to\n+  ``django.core.cache.backends.redis.RedisCache``.\n+\n+* Set :setting:`LOCATION <CACHES-LOCATION>` to the URL pointing to your Redis\n+  instance, using the appropriate scheme. See the ``redis-py`` docs for\n+  `details on the available schemes\n+  <https://redis-py.readthedocs.io/en/stable/#redis.ConnectionPool.from_url>`_.\n+\n+For example, if Redis is running on localhost (127.0.0.1) port 6379::\n+\n+    CACHES = {\n+        'default': {\n+            'BACKEND': 'django.core.cache.backends.redis.RedisCache',\n+            'LOCATION': 'redis://127.0.0.1:6379',\n+        }\n+    }\n+\n+Often Redis servers are protected with authentication. In order to supply a\n+username and password, add them in the ``LOCATION`` along with the URL::\n+\n+    CACHES = {\n+        'default': {\n+            'BACKEND': 'django.core.cache.backends.redis.RedisCache',\n+            'LOCATION': 'redis://username:password@127.0.0.1:6379',\n+        }\n+    }\n+\n+If you have multiple Redis servers set up in the replication mode, you can\n+specify the servers either as a semicolon or comma delimited string, or as a\n+list. While using multiple servers, write operations are performed on the first\n+server (leader). Read operations are performed on the other servers (replicas)\n+chosen at random::\n+\n+    CACHES = {\n+        'default': {\n+            'BACKEND': 'django.core.cache.backends.redis.RedisCache',\n+            'LOCATION': [\n+                'redis://127.0.0.1:6379', # leader\n+                'redis://127.0.0.1:6378', # read-replica 1\n+                'redis://127.0.0.1:6377', # read-replica 2\n+            ],\n+        }\n+    }\n+\n .. _database-caching:\n \n Database caching\n@@ -422,9 +486,9 @@ behavior. These arguments are provided as additional keys in the\n     On some backends (``database`` in particular) this makes culling *much*\n     faster at the expense of more cache misses.\n \n-  Memcached backends pass the contents of :setting:`OPTIONS <CACHES-OPTIONS>`\n-  as keyword arguments to the client constructors, allowing for more advanced\n-  control of client behavior. For example usage, see below.\n+  The Memcached and Redis backends pass the contents of :setting:`OPTIONS\n+  <CACHES-OPTIONS>` as keyword arguments to the client constructors, allowing\n+  for more advanced control of client behavior. For example usage, see below.\n \n * :setting:`KEY_PREFIX <CACHES-KEY_PREFIX>`: A string that will be\n   automatically included (prepended by default) to all cache keys\n@@ -496,6 +560,27 @@ flag on the connection's socket::\n         }\n     }\n \n+Here's an example configuration for a ``redis`` based backend that selects\n+database ``10`` (by default Redis ships with 16 logical databases), specifies a\n+`parser class`_ (``redis.connection.HiredisParser`` will be used by default if\n+the ``hiredis-py`` package is installed), and sets a custom `connection pool\n+class`_ (``redis.ConnectionPool`` is used by default)::\n+\n+    CACHES = {\n+        'default': {\n+            'BACKEND': 'django.core.cache.backends.redis.RedisCache',\n+            'LOCATION': 'redis://127.0.0.1:6379',\n+            'OPTIONS': {\n+                'db': '10',\n+                'parser_class': 'redis.connection.PythonParser',\n+                'pool_class': 'redis.BlockingConnectionPool',\n+            }\n+        }\n+    }\n+\n+.. _`parser class`: https://github.com/andymccurdy/redis-py#parsers\n+.. _`connection pool class`: https://github.com/andymccurdy/redis-py#connection-pools\n+\n .. _the-per-site-cache:\n \n The per-site cache\ndiff --git a/tests/cache/tests.py b/tests/cache/tests.py\nindex 0e2f5f7d1f04..b88066285801 100644\n--- a/tests/cache/tests.py\n+++ b/tests/cache/tests.py\n@@ -22,6 +22,7 @@\n     caches,\n )\n from django.core.cache.backends.base import InvalidCacheBackendError\n+from django.core.cache.backends.redis import RedisCacheClient\n from django.core.cache.utils import make_template_fragment_key\n from django.db import close_old_connections, connection, connections\n from django.db.backends.utils import CursorWrapper\n@@ -1373,10 +1374,9 @@ def test_lru_incr(self):\n         self.assertEqual(cache.get(9), 9)\n \n \n-# memcached backend isn't guaranteed to be available.\n-# To check the memcached backend, the test settings file will\n-# need to contain at least one cache backend setting that points at\n-# your memcache server.\n+# memcached and redis backends aren't guaranteed to be available.\n+# To check the backends, the test settings file will need to contain at least\n+# one cache backend setting that points at your cache server.\n configured_caches = {}\n for _cache_params in settings.CACHES.values():\n     configured_caches[_cache_params['BACKEND']] = _cache_params\n@@ -1387,6 +1387,11 @@ def test_lru_incr(self):\n # The memcached backends don't support cull-related options like `MAX_ENTRIES`.\n memcached_excluded_caches = {'cull', 'zero_cull'}\n \n+RedisCache_params = configured_caches.get('django.core.cache.backends.redis.RedisCache')\n+\n+# The redis backend does not support cull-related options like `MAX_ENTRIES`.\n+redis_excluded_caches = {'cull', 'zero_cull'}\n+\n \n class BaseMemcachedTests(BaseCacheTests):\n \n@@ -1727,6 +1732,60 @@ def test_empty_cache_file_considered_expired(self):\n             self.assertIs(cache._is_expired(fh), True)\n \n \n+@unittest.skipUnless(RedisCache_params, \"Redis backend not configured\")\n+@override_settings(CACHES=caches_setting_for_tests(\n+    base=RedisCache_params,\n+    exclude=redis_excluded_caches,\n+))\n+class RedisCacheTests(BaseCacheTests, TestCase):\n+\n+    def setUp(self):\n+        import redis\n+        super().setUp()\n+        self.lib = redis\n+\n+    @property\n+    def incr_decr_type_error(self):\n+        return self.lib.ResponseError\n+\n+    def test_cache_client_class(self):\n+        self.assertIs(cache._class, RedisCacheClient)\n+        self.assertIsInstance(cache._cache, RedisCacheClient)\n+\n+    def test_get_backend_timeout_method(self):\n+        positive_timeout = 10\n+        positive_backend_timeout = cache.get_backend_timeout(positive_timeout)\n+        self.assertEqual(positive_backend_timeout, positive_timeout)\n+\n+        negative_timeout = -5\n+        negative_backend_timeout = cache.get_backend_timeout(negative_timeout)\n+        self.assertEqual(negative_backend_timeout, 0)\n+\n+        none_timeout = None\n+        none_backend_timeout = cache.get_backend_timeout(none_timeout)\n+        self.assertIsNone(none_backend_timeout)\n+\n+    def test_get_connection_pool_index(self):\n+        pool_index = cache._cache._get_connection_pool_index(write=True)\n+        self.assertEqual(pool_index, 0)\n+        pool_index = cache._cache._get_connection_pool_index(write=False)\n+        if len(cache._cache._servers) == 1:\n+            self.assertEqual(pool_index, 0)\n+        else:\n+            self.assertGreater(pool_index, 0)\n+            self.assertLess(pool_index, len(cache._cache._servers))\n+\n+    def test_get_connection_pool(self):\n+        pool = cache._cache._get_connection_pool(write=True)\n+        self.assertIsInstance(pool, self.lib.ConnectionPool)\n+\n+        pool = cache._cache._get_connection_pool(write=False)\n+        self.assertIsInstance(pool, self.lib.ConnectionPool)\n+\n+    def test_get_client(self):\n+        self.assertIsInstance(cache._cache.get_client(), self.lib.Redis)\n+\n+\n class FileBasedCachePathLibTests(FileBasedCacheTests):\n     def mkdtemp(self):\n         tmp_dir = super().mkdtemp()\ndiff --git a/tests/requirements/py3.txt b/tests/requirements/py3.txt\nindex af06c4e5f620..893e47a914a7 100644\n--- a/tests/requirements/py3.txt\n+++ b/tests/requirements/py3.txt\n@@ -15,6 +15,7 @@ python-memcached >= 1.59\n pytz\n pywatchman; sys.platform != 'win32'\n PyYAML\n+redis >= 3.0.0\n selenium\n sqlparse >= 0.2.2\n tblib >= 1.5.0\n",
    "diff_length": 20570
  }
]