[
  {
    "index": 1,
    "pr_title": "feat(block): Add Ayrshare integration for social media posting",
    "pr_body": "This PR implements a comprehensive Ayrshare social media integration for AutoGPT Platform, enabling users to post content across multiple social media platforms through a unified interface. Ayrshare provides a single API to manage posts across Facebook, Twitter/X, LinkedIn, Instagram, YouTube, TikTok, Pinterest, Reddit, Telegram, Google My Business, Bluesky, Snapchat, and Threads.\r\n\r\nThe integration addresses the need for social media automation and content distribution workflows within AutoGPT ",
    "pr_number": 9946,
    "comments": [
      "Note I have only added loading the profile key on the first post block, whilst I check im doing it the correct way.\r\n\r\nI need to add the frontend button next as well.",
      "plz follow template with bot, once the ai reviewer is back online it'll deny the pr for this",
      "Thank you for this thorough Ayrshare integration PR! The code looks well-structured with comprehensive implementation across both frontend and backend components.\n\nBefore this PR can be merged, there are a few items that need to be addressed:\n\n1. **Missing Checklist**: Please add the standard PR checklist from our template and check off the relevant items. Since this is a significant code change introducing new functionality, we need to ensure you've tested the implementation thoroughly.\n\n2. **Merge Conflicts**: The PR has the 'conflicts' label, indicating there are merge conflicts that need to be resolved before merging.\n\n3. **PR Title Scope**: Consider updating the PR title to use 'platform/blocks' as the scope instead of just 'block' to better align with our conventional commit format and labeled scopes.\n\n4. **Test Plan**: Please provide a test plan detailing how you've verified this integration works correctly. For example:\n   - Connecting to different social media platforms via Ayrshare\n   - Posting content to each supported platform\n   - Handling error cases (e.g., when profile key is missing)\n\nThe implementation itself looks solid, with proper security considerations and a clean architecture. Once the above items are addressed, this PR should be ready for final review.",
      "‚ùå **Preview Environment Deployment Failed**\n\nüö® The preview environment deployment encountered critical errors and has been rolled back.\n\n**Cleanup Completed:**\n- ‚ò∏Ô∏è Kubernetes namespace deleted\n- üóÉÔ∏è Database schema dropped\n- üîå All services terminated\n\n*Please check the workflow logs for details and try again.*",
      "Thanks for this comprehensive PR adding Ayrshare integration for social media posting! The implementation looks solid with good support across multiple platforms.\n\nI've reviewed your changes and have a couple of items that need addressing before this can be merged:\n\n1. **PR Title Format**: The scope in your title should be `blocks` instead of `block` to match our conventional commit format standards. Please update to: `feat(blocks): Added Ayrshare integration for social media posting`\n\n2. **Missing Checklist**: Your PR description is very detailed, which is great, but it's missing the required checklist section. Please add the standard PR checklist that includes items like:\n   - Confirming you've tested your changes\n   - Your test plan\n   - Any configuration changes\n\nThe code implementation itself looks well-structured with comprehensive support for various social media platforms. I particularly like how you've organized the different posting blocks with platform-specific options and validations.\n\nOnce you've addressed these two items, this PR should be ready for another review.",
      "Thanks for the comprehensive Ayrshare integration PR! The implementation looks well-designed and thoroughly documented.\n\n### What Looks Good\n- Great PR description with detailed explanations of all components\n- Clean implementation of both backend and frontend components\n- Good separation of concerns with platform-specific posting blocks\n- Environment variables correctly added to `.env.example`\n- Proper handling of user_id in credential store operations\n- The new AYRSHARE block type is added in the correct alphabetical location\n\n### What Needs Addressing\n- **Missing checklist**: Please add the required checklist to the PR description. As this is a code change, we need a complete checklist including a test plan to verify the functionality works correctly.\n\n### Testing Considerations\nSince this is a complex integration, please ensure your test plan includes:\n- Creating and connecting to Ayrshare accounts\n- Posting to various social media platforms\n- Handling error cases (e.g., invalid credentials, failed posts)\n- Verifying the SSO flow works correctly\n\nOnce you've added the checklist with a proper test plan, this PR should be ready for final review.",
      "Waiting on preview envs to be fixed before this can be comprehensively tested. \r\nAlso there is difficulty testing all platforms as I don't have all the different social account.",
      "‚úÖ **Preview Environment Deployed Successfully**\n\nüìä **Deployment Summary**\n| Service | Status |\n|---------|--------|\n| Redis | ‚úÖ Success |\n| RabbitMQ | ‚úÖ Success |\n| Backend Server | ‚úÖ Success |\n| WebSocket Server | ‚úÖ Success |\n| Scheduler Server | ‚úÖ Success |\n| Frontend Builder | ‚úÖ Success |\n\nüîî Please check Discord for the preview environment URLs and details.\n\n*The deployment status and URLs will be posted in the AutoGPT Discord server.*",
      "![Screenshot 2025-06-16 at 11 57 40](https://github.com/user-attachments/assets/3bba19c2-4983-47e8-88f5-9f5a6c6da32f)\r\n![Screenshot 2025-06-16 at 11 55 17](https://github.com/user-attachments/assets/55e3e80c-8106-4b36-8a15-11f86536ac2e)\r\n\r\nI've tested linkedin and twitter both work. The others need testing",
      "‚úÖ **Preview Environment Deployed Successfully**\n\nüìä **Deployment Summary**\n| Service | Status |\n|---------|--------|\n| Redis | ‚úÖ Success |\n| RabbitMQ | ‚úÖ Success |\n| Backend Server | ‚úÖ Success |\n| WebSocket Server | ‚úÖ Success |\n| Scheduler Server | ‚úÖ Success |\n| Frontend Builder | ‚úÖ Success |\n\nüîî Please check Discord for the preview environment URLs and details.\n\n*The deployment status and URLs will be posted in the AutoGPT Discord server.*",
      "‚úÖ **Preview Environment Deployed Successfully**\n\nüìä **Deployment Summary**\n| Service | Status |\n|---------|--------|\n| Redis | ‚úÖ Success |\n| RabbitMQ | ‚úÖ Success |\n| Backend Server | ‚úÖ Success |\n| WebSocket Server | ‚úÖ Success |\n| Scheduler Server | ‚úÖ Success |\n| Frontend Builder | ‚úÖ Success |\n\nüîî Please check Discord for the preview environment URLs and details.\n\n*The deployment status and URLs will be posted in the AutoGPT Discord server.*"
    ],
    "num_comments": 11,
    "repository": "Significant-Gravitas/AutoGPT",
    "diff_length": 164852
  },
  {
    "index": 2,
    "pr_title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "pr_body": "## Summary\r\n\r\nThis PR introduces a Redesigned Block Menu for the builder and all the relevant backend changes. The implementation includes a complete set of reusable UI components, state management, pagination hooks, and search/filter functionality to enhance the user experience when selecting and adding blocks and agents to their workflows.\r\n\r\n## Screenshot\r\n\r\n![Screenshot 2025-06-06 at 7 15 04‚ÄØPM](https://github.com/user-attachments/assets/90476084-1996-4653-bcc1-d41e09a9dd84)\r\n\r\n## Design fil",
    "pr_number": 9956,
    "comments": [
      "The PR fails to meet some basic requirements but shows a good effort. Issues:\n1. The PR template is not properly filled out - missing test plan and checklist items\n2. While the scope is clear (frontend) and shown in the title correctly, documentation of changes could be clearer\n3. No clear explanation in PR body about 'why' these changes were needed\n4. No test plan or testing notes provided for such a large UI change\n\nHowever, the code itself looks well-structured with clear component organization and documentation. The TODO comments also show good forward planning.",
      "## Feedback for PR Improvement\n\n### Missing PR Template & Checklist\nPlease fill out the complete PR template, including the checklist section. This is required for all PRs and helps reviewers understand what's being changed and how it's been tested.\n\n### Scope Mismatch\nYour PR title mentions only frontend changes (`feat(frontend)`), but the diff shows significant backend additions including:\n- New API routes in `/api/builder/`\n- New DB functions and models\n- Changes to store routes\n\nPlease update your title to reflect both frontend and backend changes, or better explain in the description why backend changes were needed for this frontend redesign.\n\n### User ID Validation\nSome of the new backend functions in `backend/server/v2/builder/db.py` don't appear to validate user permissions via user_id. Please review these functions to ensure proper authorization is in place or provide an explanation for why user_id checks aren't needed.\n\n### Merge Conflicts\nThis PR has merge conflicts that need to be resolved before it can be merged.\n\n### Testing\nPlease include information about how you've tested these changes, particularly since they span both frontend and backend components.\n\nOnce you've addressed these issues, the PR should be ready for re-review.",
      "Thank you for your work on redesigning the block menu. This looks like a substantial change that will improve the builder page experience. \n\nHowever, there are a few things that need to be addressed before this PR can be merged:\n\n1. **Missing checklist**: Please complete the PR template checklist. For code changes like these, we need to know that you've tested your changes with a clear test plan.\n\n2. **Scope discrepancy**: Your PR title mentions only frontend changes, but the diff includes significant backend changes - new routes, endpoints, and database access functions. Please update your PR title to reflect that this is both a frontend and backend feature, perhaps something like `feat(frontend,backend): Redesign block menu on builder page`.\n\n3. **Implementation details**: Your PR description lists the components you've added but doesn't explain how they work together or what specific improvements they bring. Please enhance the description with more details about the implementation and how it improves upon the previous design.\n\n4. **Test plan**: Please add a test plan to your PR description explaining how you've tested these changes.\n\nThe code itself looks well-structured with proper authentication handling and user_id checks. I particularly like how you've organized the new components and the backend routes to support them. Once you address the above points, this PR should be ready for another review.",
      "Thank you for your work on redesigning the block menu! I have a few comments before this can be merged:\n\n## Description and Checklist\n- Please update your PR description to include a more detailed explanation of the changes you've made\n- The required PR checklist is missing. Please add the checklist from the PR template and check off the appropriate items\n\n## Scope Mismatch\nYour PR title indicates this is a frontend feature (`feat(frontend)`), but the changes include substantial backend code, including:\n- New backend routes in `/api/builder`\n- New database functions in `backend/server/v2/builder/db.py`\n- New models in `backend/server/v2/builder/model.py`\n\nConsider updating your PR title to reflect that this involves both frontend and backend changes, perhaps something like `feat(platform): Redesign block menu on builder page with backend support`\n\n## Test Plan\nPlease include a test plan in your PR description to explain how you've tested these changes.\n\nOnce these items are addressed, we can proceed with reviewing the technical aspects of the implementation. The component list and structure looks well-organized!",
      "Thank you for your work on redesigning the block menu! I have a few concerns about this PR that need to be addressed before it can be merged:\n\n1. **PR Description:** While you've listed the components you've added, the PR description should explain why these changes are needed and provide more context about the redesign goals.\n\n2. **Missing Checklist:** Your PR description is missing the required checklist section that outlines your test plan and confirms you've tested the changes appropriately. Please update your PR description to include the complete checklist.\n\n3. **Scope Mismatch:** The PR title indicates this is a frontend change, but the diff shows substantial backend changes including:\n   - New backend routes in `/api/builder`\n   - New database functions and models\n   - Changes to the store API\n\n   Please update either the PR title to reflect the full scope of changes (e.g., `feat(frontend,backend): Redesign block menu and add builder API endpoints`) or separate the backend changes into a different PR.\n\n4. **Dependencies:** You've added several new dependencies (`react-timeago`, `tailwind-scrollbar`, `tailwind-scrollbar-hide`). Please ensure these are necessary and document their purpose in the PR description.\n\n5. **Testing:** Please describe how you've tested these changes, especially the new backend routes and functionality.\n\nAdditionally, I see there's a conflicts label on this PR. Please resolve any merge conflicts before this can be approved.\n\nOnce you've addressed these issues, I'll be happy to review the PR again.",
      "Thank you for your PR to redesign the block menu! The component list you provided is helpful for understanding what's been added. I have some feedback to help get this PR ready for merging:\n\n1. **Missing checklist**: This PR contains significant code changes but is missing the required checklist. Please add the checklist from the PR template and ensure you've tested all changes appropriately.\n\n2. **Scope mismatch**: While your title mentions frontend changes, a significant portion of this PR adds backend functionality (new routes, models, and database operations for the builder). Please update your PR title to reflect both frontend and backend changes, e.g., `feat(frontend,backend): Redesign block menu and add builder API endpoints`.\n\n3. **PR description improvements**: Consider expanding your description to mention the backend API endpoints you've added to support the block menu functionality.\n\nOnce you've addressed these items, we'll be able to review your PR again. The code changes themselves look good - I like the organized approach with the reusable components and the proper handling of user_id in the backend routes.",
      "Thanks for the PR to redesign the block menu! The implementation looks comprehensive with both frontend components and backend support.\n\n### Feedback\n\n1. **PR Description Improvements**:\n   - The PR description is missing the required checklist from the template. Please add the checklist sections for code changes and make sure all items are checked off.\n   - While you've described the frontend components well, please also mention the significant backend changes (new API routes in `/api/builder`, pagination model extensions, etc.) that support this feature.\n\n2. **Implementation Notes**:\n   - The changes include backend routes and models to support the block menu functionality, which is good but should be mentioned in the PR description.\n   - I notice you've added several new npm packages (`react-timeago`, `tailwind-scrollbar`, etc.) - please include these in your description of changes.\n\n3. **Code Quality**:\n   - The backend implementation looks solid with well-structured endpoints and models.\n   - Good job on the TODO markers for future work.\n\nPlease update the PR description to include the missing checklist and mention the backend changes that support this feature. Once these items are addressed, the PR will be ready for another review.",
      "Thank you for your PR to redesign the block menu! I've identified a few issues that need to be addressed before this can be merged:\n\n1. **Scope mismatch**: While your PR title indicates this is a frontend change, approximately half of the changes are backend-related (new API endpoints, models, database functions). The PR title and description should accurately reflect all major components being changed.\n\n2. **Missing checklist**: For substantial code changes like this, the PR template checklist needs to be completed to ensure proper testing and quality checks. Please add the checklist and check off the appropriate items.\n\n3. **Backend changes documentation**: The PR description doesn't mention any of the backend changes. Please update the description to include details about the new backend/server/v2/builder files and endpoints you're adding.\n\nAdditionally, I notice you've marked some items with \"BLOCK MENU TODO:\" for future work. If these are part of this redesign effort but will be addressed in separate PRs, that's fine, but please make that clear in the description.\n\nOnce you've updated the PR title to accurately reflect both frontend and backend changes, completed the required checklist, and expanded the description to cover all major components being changed, we can proceed with the review process.",
      "Thanks for your PR on redesigning the block menu. I noticed a few things that need to be addressed before this can be merged:\n\n1. **Missing Checklist**: Please include the complete PR checklist in your description. Since your changes include significant code modifications, you'll need to add the checklist with appropriate test plans.\n\n2. **Scope Mismatch**: Your PR title only mentions frontend changes (`feat(frontend)`), but the diff shows substantial backend additions including:\n   - New API routes in `/api/builder`\n   - New database functionality\n   - New models and response types\n\n   Please update your PR title to reflect both the frontend and backend changes, perhaps something like `feat(frontend,backend): Redesign block menu on builder page`.\n\n3. **PR Description**: Consider enhancing your description to explain more about the purpose of the backend changes and how they relate to the frontend block menu redesign.\n\nThe changes themselves look promising, but we need to ensure the PR follows our submission guidelines before proceeding with the review of the actual implementation. Please make these updates so we can move forward with the review.",
      "Thank you for your work on redesigning the block menu! I have a few concerns that need to be addressed before this PR can be merged:\n\n1. **Missing Checklist**: The PR description is missing the required checklist. Please update your description to include the standard checklist and fill it out completely.\n\n2. **Scope Mismatch**: The PR title mentions only frontend changes (`feat(frontend)`), but the diff shows significant backend changes as well. Please update the PR title to accurately reflect the scope of your changes. Something like `feat(platform): Redesign block menu on builder page` or `feat(platform/frontend,platform/backend): Redesign block menu on builder page` would be more appropriate.\n\n3. **Backend Changes**: The PR includes substantial backend additions:\n   - New builder routes and endpoints\n   - New database functions and models\n   - Changes to the store API\n\nPlease make sure to include these backend changes in your test plan when you add the checklist.\n\nOnce these items are addressed, we can proceed with the review of the code itself. The overall direction of the redesign looks promising!",
      "Thank you for working on redesigning the block menu. I see you've created several reusable components for this feature.\n\nI have two main concerns with this PR:\n\n1. **Missing Checklist**: Your PR description is missing the required checklist that should cover testing plan and other verification steps. Please update your description to include the standard checklist and fill it out appropriately.\n\n2. **Scope Mismatch**: Your PR title mentions only a frontend redesign, but the changes include significant backend work. I see new backend files for a builder API, including routes, models, and database functionality. The PR title should reflect both frontend and backend changes, something like: `feat(frontend,backend): Redesign block menu and add builder API`\n\nPlease update your PR to address these issues so we can proceed with the review. The code changes themselves look well-structured, but we need to ensure the PR follows our process requirements.\n\nAlso, I noticed you've marked some items with `BLOCK MENU TODO:` for future work. That's a good approach for tracking remaining tasks.",
      "Hi @Abhi1992002, thanks for your work on redesigning the block menu. I have some feedback to help get this PR ready for merging:\n\n## Required Changes\n\n1. **PR Description & Checklist**\n   - Please include the complete PR checklist from our template, including your test plan\n   - The description should explain both the frontend and backend changes\n\n2. **PR Scope**\n   - Your PR title mentions only frontend changes, but there are significant backend changes\n   - Please update the title to reflect both (e.g., `feat(frontend,backend): Redesign block menu on builder page`)\n\n3. **Backend Testing**\n   - The new API endpoints should have proper testing documentation\n   - Please describe how you've tested the new endpoints\n\n4. **User ID Security**\n   - For the new backend routes, please confirm that user_id checks are properly implemented\n\n## Questions\n\n1. What testing have you done for both the frontend components and backend endpoints?\n2. Are there any configuration changes needed for these new components?\n3. How do the new endpoints interact with the redesigned block menu?\n\nOnce these items are addressed, I'd be happy to re-review the PR. Thanks!",
      "Thanks for working on redesigning the block menu for the builder page! This is an important improvement that will enhance the user experience. However, there are a couple of issues that need to be addressed before we can merge this PR:\n\n1. **Missing Checklist**: The PR template requires a filled-out checklist for all code changes. Please update your PR description to include the checklist from the template with all applicable items checked.\n\n2. **Scope Mismatch**: Your PR title indicates this is a frontend change, but the diff contains significant backend changes including:\n   - Adding new backend routes under `/api/builder`\n   - Creating new backend models and database functions\n   - Modifying the store API\n\n   Please either:\n   - Update the PR title to something like `feat(platform): Redesign block menu with backend support` to accurately reflect both frontend and backend changes, or\n   - Split this into separate PRs for frontend and backend changes\n\nAdditionally, while your PR description lists the components you've added, it would be helpful to include a brief explanation of the backend changes as well.\n\nOnce these items are addressed, we can proceed with the review of the implementation details. The component organization looks good, and I appreciate your marking future tasks with the `BLOCK MENU TODO:` tag for easy reference.",
      "Thanks for working on the block menu redesign! This PR adds important components and functionality for the builder page.\n\n### Key Issues to Address\n\n1. **Missing Checklist:** Please add the required checklist to your PR description. This is mandatory for code changes and should include details about your test plan.\n\n2. **Scope Clarification:** Your PR title focuses on frontend changes, but includes significant backend changes (new endpoints, models, DB functions). While these backend changes appear necessary to support the frontend redesign, consider either:\n   - Updating the PR title to reflect both frontend and backend changes (e.g., `feat(platform): Redesign block menu on builder page with supporting API`)  \n   - OR splitting the PR into separate frontend and backend PRs if that makes sense\n\n3. **PR Conflicts:** There's a conflicts label on your PR - please resolve these merge conflicts.\n\n### Additional Notes\n\n- The TODO comments you've marked with `BLOCK MENU TODO:` are fine as placeholders for future work.\n- Good job properly implementing auth middleware on the new API routes.\n- Consider adding more details about what the redesigned block menu includes and what improvements it brings.\n\nOnce you've addressed these issues, particularly adding the required checklist, the PR should be ready for another review.",
      "Thank you for your PR to redesign the block menu! The implementation looks thorough with many new components created for the builder page.\n\nHowever, I've noticed a couple of issues that need to be addressed before this can be merged:\n\n1. **Missing checklist**: The PR description is missing the required checklist from our PR template. Since this is a significant code change, please update your PR description to include a completed checklist with items like:\n   - Confirmation that you've tested your changes\n   - A test plan outlining how you verified your implementation works correctly\n\n2. **Scope mismatch**: Your PR title mentions only frontend changes, but the PR includes substantial backend implementations including:\n   - A new backend/server/v2/builder module with model, db, and routes files\n   - New API endpoints\n   - Modifications to existing store functionality\n\n   Please update your PR title to reflect both frontend and backend changes, perhaps something like: `feat(frontend,backend): Redesign block menu and add builder API endpoints`\n\nOnce these issues are addressed, we can proceed with the review of your implementation. The code itself looks well-structured with appropriate user_id handling in the backend functions.",
      "Thanks for your PR on redesigning the block menu! There are a few items that need to be addressed before this can be merged:\n\n## Missing Required Information\n\n1. **Checklist**: Your PR is missing the required checklist section. Since this PR involves significant code changes, we need to ensure all necessary checks have been completed.\n\n2. **Test Plan**: Please include details on how you've tested these changes.\n\n## Scope Clarification\n\nYour PR title mentions frontend redesign, but includes significant backend changes (new API endpoints, models, etc.). While these backend changes appear to support the frontend redesign, it would be helpful to:\n\n- Update your PR title to reflect both frontend and backend changes, e.g., `feat(platform): Redesign block menu with supporting backend APIs`\n- OR clarify in your description how the backend changes are necessary for the frontend redesign\n\n## Documentation\n\nPlease add some brief documentation on the new backend endpoints you've created to help other developers understand their purpose and how they relate to the block menu redesign.\n\nThe code itself looks good - I see you've properly protected all routes with auth middleware and correctly handle user_id passing where needed. Once you've addressed these items, we can proceed with the review.",
      "Thank you for working on redesigning the block menu! This is an important improvement for the builder page UI. I've identified a couple of issues that need to be addressed before this PR can be merged:\n\n1. The PR description is missing the required checklist. Please update your description to include the checklist from our template, with all applicable items checked off.\n\n2. The PR title mentions only frontend changes (`feat(frontend)`), but the PR includes significant backend additions (new routes, models, and DB functions in `/backend/server/v2/builder/`). Either:\n   - Update the PR title to reflect both frontend and backend changes (e.g., `feat(platform): Redesign block menu with backend support`)\n   - Or split this into separate PRs for frontend and backend changes\n\nYour implementation looks good overall - I can see you've built reusable components and made sure the backend functions properly handle user_id for authentication. Please address the issues above so we can proceed with the review.\n\nNote: There's also a conflict label on this PR that will need to be resolved before merging.",
      "Thank you for your PR to redesign the block menu on the builder page! This looks like a substantial piece of work that adds many components and backend support.  \n\nHowever, I've noticed a few issues that need to be addressed before this can be merged:\n\n1. **Missing Checklist**: Your PR is missing the required checklist. Please add the complete checklist from the PR template and check off the items you've completed. Given the scope of your changes, the checklist is necessary to ensure everything has been properly tested.\n\n2. **PR Title/Scope Mismatch**: Your PR title only mentions frontend changes, but there are significant backend changes as well (new API routes, database functions, models). Please update your PR title to reflect both aspects, perhaps something like: `feat(frontend,backend): Redesign block menu on builder page with API support`\n\n3. **Test Plan**: Please provide a test plan detailing how you've verified that both the frontend components and backend API routes work correctly.\n\n4. **PR Description**: Consider expanding your description to briefly explain the purpose of the backend changes and how they support the frontend redesign.\n\nYour component organization looks good, and I appreciate that you've marked future tasks with `BLOCK MENU TODO:`. Once you address these items, we'll be able to move forward with the review process.",
      "Thanks for your contribution to redesign the block menu! This is a substantial PR with changes across both frontend and backend.\n\n### Missing Required Checklist\n\nPlease add the standard PR checklist to your description and complete it. This is required for all PRs with material code changes. The checklist helps ensure you've tested your changes appropriately and considered all necessary factors.\n\n### Scope Consideration\n\nYour PR title mentions frontend changes, but there are significant backend changes as well (new API endpoints, database functions, models). Consider either:\n1. Updating the PR title to reflect both frontend and backend changes, or\n2. Splitting this into two PRs if the changes are separable (one for backend support, one for frontend implementation)\n\n### TODOs in Code\n\nYou mentioned \"Some tasks are planned for the near future. I've marked them with `BLOCK MENU TODO:` so they can be found easily.\" Please ensure that these TODOs are addressed before the PR is merged, or create follow-up issues to track them.\n\n### Other Notes\n\n- The new backend endpoints look well-structured with appropriate auth middleware\n- The implementation seems comprehensive with search functionality, filtering, and pagination\n- Good job on adding new dependencies in package.json for the enhanced UI components\n\nPlease update your PR description with the required checklist and consider the scope recommendation.",
      "Thank you for your PR! I noticed a few issues that need to be addressed before this can be merged:\n\n## Missing Checklist\nYour PR contains significant code changes but doesn't include the required checklist. Please add the standard checklist to your PR description and ensure all items are checked off.\n\n## Scope Mismatch\nYour PR title mentions only frontend changes (`feat(frontend): Redesign block menu on builder page`), but the actual changes include extensive backend work:\n- New backend routes in `/api/builder/`\n- New database functions and models for builder functionality\n- Changes to store and library endpoints\n\nPlease update your PR title to reflect both frontend and backend changes, for example: `feat(frontend,backend): Redesign block menu and add builder API endpoints`\n\n## PR Description Needs Expansion\nPlease provide more details in your PR description:\n- What problem does this redesign solve?\n- What are the key changes in both frontend and backend?\n- How should reviewers test these changes?\n\nThe current description lists small components but doesn't explain the overall architecture or the backend additions.\n\nOnce these issues are addressed, I'll be happy to review this PR again. Let me know if you need any clarification!",
      "Thanks for your PR on redesigning the block menu! I have a couple of important issues that need to be addressed before this can be merged:\n\n## Required Changes\n\n1. **Missing Checklist**: The PR template requires a checklist to be completed for code changes. Please update your PR description to include the standard checklist and complete it.\n\n2. **PR Title/Scope Mismatch**: Your PR title indicates this is a frontend change (`feat(frontend)`), but the vast majority of changes are actually backend-related. The PR adds several new backend files (db.py, model.py, routes.py) and modifies existing backend code.\n\n   Please update your PR title to accurately reflect the scope of changes, such as `feat(platform): Redesign block menu with backend support` or similar that reflects both the frontend and backend work.\n\n3. **PR Description**: Consider expanding your PR description to explain why this redesign was needed and how it improves the current implementation. \n\n## Additional Notes\n\n- Your backend code changes look good from a security perspective - the functions properly use user_id for access control.\n- I noticed you've added a TODO comment \"BLOCK MENU TODO:\" for future work. Make sure these are tracked separately if they won't be addressed in this PR.\n- You've added some new dependencies in package.json (tailwind-scrollbar, react-timeago, etc.) - it would be helpful to mention these in the PR description.\n\nPlease update your PR with these changes so we can proceed with the review process. Let me know if you need any clarification!",
      "Thanks for your work on redesigning the block menu! I noticed a few issues that need to be addressed before this PR can be merged:\n\n## Description and Scope\n\n- Your PR title indicates only frontend changes, but there are significant backend changes (new API routes, models, etc.). The scope in the title should reflect all areas being modified, such as `feat(platform)` or both frontend and backend.\n- The PR description focuses on frontend components but doesn't mention the backend API work. Please update your description to include details about all changes made.\n\n## Missing Required Checklist\n\n- The PR is missing the required checklist that should be filled out completely. Since this includes substantial code changes, please add the checklist and check off all applicable items.\n- Please include a test plan detailing how you've verified the changes work correctly.\n\n## Suggested Changes\n\n1. Update the PR title to correctly represent the scope of changes (e.g., `feat(platform): Redesign block menu on builder page`)\n2. Expand the PR description to include details about the backend API changes\n3. Add the required checklist template and fill it out completely\n4. Include a test plan that describes how you've tested these changes\n\nOnce these issues are addressed, we can proceed with reviewing the code changes in detail.",
      "Thank you for your PR to redesign the block menu! I've reviewed your changes and have a few concerns that need to be addressed before this can be merged:\n\n## Missing Checklist\nThe PR description is missing the required checklist for code changes. Please update your description to include the standard checklist that confirms you've tested your changes properly.\n\n## Scope Mismatch\nYour PR title indicates this is a frontend change (`feat(frontend): Redesign block menu on builder page`), but the changes include significant backend additions:\n- New builder API endpoints\n- New database functions\n- New models and data structures\n\nThese backend changes appear to be more than 20% of the total changes, which exceeds our scope guidelines. You have two options:\n\n1. Split this into two PRs: one for frontend and one for backend changes\n2. Update the PR title to reflect both areas (e.g., `feat(frontend,backend): Redesign block menu with supporting API endpoints`)\n\nThe new backend code looks good in terms of security and user_id handling, but we need to ensure the PR accurately represents the work being done.\n\nPlease update your PR accordingly, and let me know if you need any help or clarification!",
      "Thanks for the PR to redesign the block menu! The components structure you've listed looks well organized.\n\nI noticed a couple of issues that need to be addressed before this can be merged:\n\n1. **Missing checklist**: The PR template requires a checklist section to be completed for code changes. Please add the checklist from the template and fill it out appropriately, especially including your test plan.\n\n2. **Scope mismatch**: Your PR title indicates this is purely a frontend change (`feat(frontend)`), but the PR contains substantial backend changes including:\n   - New backend API routes in `/api/builder`\n   - New backend models and database methods\n   - Changes to existing backend services\n\nPlease update either:\n   - The PR title to reflect both frontend and backend changes (e.g., `feat(platform): Redesign block menu and add builder API endpoints`)\n   - OR split this into separate PRs for frontend and backend changes\n\nAlso, I notice you've marked some tasks with \"BLOCK MENU TODO\" for future work. It would be helpful to clarify in the PR description which parts are complete in this PR and which parts are planned for future PRs.\n\nLet me know if you need any help with these changes!",
      "Thank you for your work on redesigning the block menu for the builder page. However, there are a couple of issues that need to be addressed before this PR can be merged:\n\n1. **Missing Checklist**: Your PR is missing the required checklist section. Please update your PR description to include the standard checklist and fill it out completely. This helps ensure all necessary steps have been completed before merging.\n\n2. **Scope Mismatch**: Your PR title mentions only frontend changes (`feat(frontend): Redesign block menu on builder page`), but the PR includes extensive backend changes as well. I see new backend routes, models, and database functions being added in:\n   - `backend/server/v2/builder/db.py`\n   - `backend/server/v2/builder/model.py`\n   - `backend/server/v2/builder/routes.py`\n   - And modifications to several other backend files\n\nYou have two options to address this:\n   - Update your PR title to reflect both frontend and backend changes, such as `feat(platform): Redesign block menu with supporting backend APIs`\n   - Or split this into separate PRs - one for frontend and one for backend changes\n\nPlease make these adjustments so we can proceed with the review. The changes themselves look valuable, but we need to ensure the PR follows our standards."
    ],
    "num_comments": 25,
    "repository": "Significant-Gravitas/AutoGPT",
    "diff_length": 314421
  },
  {
    "index": 3,
    "pr_title": "feat(platform): Add Block Development SDK with auto-registration system",
    "pr_body": "## Block Development SDK - Simplifying Block Creation\n\n### Problem\nCurrently, creating a new block requires manual updates to **5+ files** scattered across the codebase:\n- `backend/data/block_cost_config.py` - Manually add block costs\n- `backend/integrations/credentials_store.py` - Add default credentials  \n- `backend/integrations/providers.py` - Register new providers\n- `backend/integrations/oauth/__init__.py` - Register OAuth handlers\n- `backend/integrations/webhooks/__init__.py` - Register we",
    "pr_number": 10074,
    "comments": [
      "‚úÖ **Preview Environment Deployed Successfully**\n\nüìä **Deployment Summary**\n| Service | Status |\n|---------|--------|\n| Redis | ‚úÖ Success |\n| RabbitMQ | ‚úÖ Success |\n| Backend Server | ‚úÖ Success |\n| WebSocket Server | ‚úÖ Success |\n| Scheduler Server | ‚úÖ Success |\n| Frontend Builder | ‚úÖ Success |\n\nüîî Please check Discord for the preview environment URLs and details.\n\n*The deployment status and URLs will be posted in the AutoGPT Discord server.*",
      "FYI I deleted all the comments with a script to clean up all the deployment testing",
      "üßπ **Preview Environment Cleaned Up**\n\nAll resources for PR #10074 have been removed:\n- ‚ò∏Ô∏è Kubernetes namespace deleted\n- üóÉÔ∏è Database schema `pr10074` dropped\n\n*Cleanup completed successfully.*",
      "‚úÖ **Preview Environment Deployed Successfully**\n\nüìä **Deployment Summary**\n| Service | Status |\n|---------|--------|\n| Redis | ‚úÖ Success |\n| RabbitMQ | ‚úÖ Success |\n| Backend Server | ‚úÖ Success |\n| WebSocket Server | ‚úÖ Success |\n| Scheduler Server | ‚úÖ Success |\n| Frontend Builder | ‚úÖ Success |\n\nüîî Please check Discord for the preview environment URLs and details.\n\n*The deployment status and URLs will be posted in the AutoGPT Discord server.*",
      "‚ùå **Preview Environment Deployment Failed**\n\nüö® The preview environment deployment encountered critical errors and has been rolled back.\n\n**Cleanup Completed:**\n- ‚ò∏Ô∏è Kubernetes namespace deleted\n- üóÉÔ∏è Database schema dropped\n- üîå All services terminated\n\n*Please check the workflow logs for details and try again.*",
      "Note: I've only reviewed the backend side of this\r\n\r\nFor tests, I'd like to see the full extent of the builder implications tested. \r\nEX: we can do with API key, with OAuth, with extra config, etc, all in one go. It shouldn't be too bad to keep up with due to Claude\r\n\r\nIt's also not clear to me if the builder is order-dependent or if it contains its own internal state machine for stepping through the order as it decides. Do the two examples below behave the same?\r\n```\r\nblah\r\n.withOAuth()\r\n.withApiKey()\r\n.build()\r\n\r\nvs \r\n\r\nblah\r\n.withApiKey()\r\n.withOAuth()\r\n.build()\r\n```\r\n\r\nAlso suggested a few things that I think can make it easier for people / AI to work with",
      "> Note: I've only reviewed the backend side of this\r\n> \r\n> For tests, I'd like to see the full extent of the builder implications tested. EX: we can do with API key, with OAuth, with extra config, etc, all in one go. It shouldn't be too bad to keep up with due to Claude\r\n> \r\n> It's also not clear to me if the builder is order-dependent or if it contains its own internal state machine for stepping through the order as it decides. Do the two examples below behave the same?\r\n> \r\n> ```\r\n> blah\r\n> .withOAuth()\r\n> .withApiKey()\r\n> .build()\r\n> \r\n> vs \r\n> \r\n> blah\r\n> .withApiKey()\r\n> .withOAuth()\r\n> .build()\r\n> ```\r\n> \r\n> Also suggested a few things that I think can make it easier for people / AI to work with\r\n\r\nThe order of builder functions does not matter other than build going at the end",
      "üßπ **Preview Environment Cleaned Up**\n\nAll resources for PR #10074 have been removed:\n- ‚ò∏Ô∏è Kubernetes namespace deleted\n- üóÉÔ∏è Database schema `pr_10074` dropped\n\n*Cleanup completed successfully.*"
    ],
    "num_comments": 8,
    "repository": "Significant-Gravitas/AutoGPT",
    "diff_length": 298181
  },
  {
    "index": 4,
    "pr_title": "feat(platform/library): Scheduling UX",
    "pr_body": "Complete the implementation of the Agent Run Scheduling UX in the Library.\r\n\r\nDemo:\r\n\r\nhttps://github.com/user-attachments/assets/701adc63-452c-4d37-aeea-51788b2774f2\r\n\r\n### Changes üèóÔ∏è\r\n\r\nFrontend:\r\n- Add \"Schedule\" button + dialog + logic to `AgentRunDraftView`\r\n  - Update corresponding logic on `AgentRunsPage`\r\n  - Add schedule name field to `CronSchedulerDialog`\r\n    - Amend Builder components `useAgentGraph`, `FlowEditor`, `RunnerUIWrapper` to also handle schedule name input\r\n    - Split `Cr",
    "pr_number": 10246,
    "comments": [
      "Thank you for your contribution to improve the scheduling UX in the platform library! I see that you've added several important features like API+backend data paths for scheduling, buttons for creating/deleting schedules, and updated the scheduling API.\n\nHowever, I cannot approve this PR yet because:\n\n1. **The checklist is incomplete** - Please check off all the items or remove sections that aren't applicable. At minimum, we need to see that you've:\n   - Clearly listed your changes (which you have)  \n   - Made and executed a test plan\n\n2. **Missing test plan** - Please add details about how you've tested these scheduling features. For example:\n   - Creating a schedule for an agent\n   - Verifying the schedule executes correctly\n   - Deleting a schedule\n   - Testing the UI components for scheduling\n\nOnce you've addressed these items, we can proceed with the review. The changes themselves look appropriate for the scope described in the PR title.",
      "if you read this, it works! :rocket:",
      "if you read this, it works! :rocket:",
      "if you read this, it works! :rocket:",
      "if you read this, it works! :rocket:",
      "if you read this, it works! :rocket:",
      "if you read this, it works! :rocket:",
      "if you read this, it works! :rocket:",
      "Thank you for working on the scheduling feature implementation! There are a few things that need to be addressed before this PR can be merged:\n\n### Missing Information\n\n1. **Checklist**: Please complete the checklist in the PR description. All items need to be checked off to indicate you've verified them.\n\n2. **Test Plan**: Please add a test plan explaining how you've tested these changes.\n\n3. **Backend Data Changes**: Since there are modifications to backend/data files, please explain how user_id checking is handled in the new/modified functions.\n\n### Scope Alignment\n\nThe PR title mentions \"platform/library\" but the changes span both frontend and backend components (which is also reflected in the PR labels). Consider updating the title to better reflect the scope of changes, perhaps something like: `feat(platform): Scheduling UX implementation`\n\n### Description Enhancements\n\nConsider expanding the description to better capture all the changes made. For example:\n- What specific API endpoints were updated/added?\n- How does the new scheduling flow work from a user perspective?\n- Are there any database changes or migrations needed?\n\nOnce these items are addressed, we'll be happy to review this PR again for merging. Thanks for your contribution to improving the scheduling feature!",
      "Thank you for working on completing the scheduling feature implementation in the Library. There are a few items that need to be addressed before this PR can be merged:\n\n1. **Checklist Completion**: Please complete the checklist in the PR description. Each item needs to be checked off to confirm you've verified these aspects of your changes.\n\n2. **Test Plan**: Include a specific test plan that outlines how you've tested the scheduling functionality. This should cover creating schedules, deleting schedules, and verifying that scheduled runs execute as expected.\n\n3. **PR Scope**: The title mentions only 'platform/library' but your changes span across both frontend and backend components (as evidenced by the file changes and labels). Consider updating the title to better reflect the full scope of changes, such as 'feat(platform): Complete scheduling implementation in Library'.\n\n4. **More Detailed Description**: While your description lists the changes, it would be helpful to provide a bit more context about how these changes improve the scheduling UX and what the expected user experience will be after these changes.\n\nOnce these items are addressed, your PR will be ready for another review.",
      "Thank you for your PR implementing scheduling features in the Library. I have a few points of feedback to help get this ready for merging:\n\n1. **Checklist not completed**: None of the checkboxes in the PR description are checked. Please complete the checklist by checking off all items or removing sections that are not applicable.\n\n2. **Scope in title doesn't match changes**: Your PR title indicates `feat(platform/library)`, but the changes span both frontend and backend components. Consider updating the title to better reflect the scope, perhaps something like `feat(platform): Scheduling UX` or `feat(platform/library,backend): Scheduling UX`.\n\n3. **Backend data modifications**: Since you're modifying files in `backend/data/`, please ensure that any added/changed functions pass the user_id and compare it correctly, or provide an explanation for why this isn't needed.\n\n4. **Test plan**: Please include a test plan that describes how you've tested these scheduling features.\n\nOnce you address these points, we can proceed with the review of the actual code changes.",
      "Thank you for your detailed PR on enhancing the scheduling UX! The description and implementation plan look thorough and well-organized.\n\nHowever, I notice your checklist indicates you haven't completed testing according to your test plan yet. Before this PR can be merged, please:\n\n1. Complete the testing steps you've outlined in your checklist\n2. Check the box to confirm testing has been completed\n\nYour test plan looks comprehensive, covering schedule creation, execution, deletion, and UI state management. Once you've verified all these aspects work correctly, please update the PR.\n\nThe changes themselves look appropriate for the scope defined in your PR title (platform/library scheduling UX improvements), covering both frontend and backend components needed for this feature.",
      "Thanks for this comprehensive PR improving the scheduling functionality! The changes look well-organized and clearly documented.\n\nHowever, I noticed that many of your test plan items are not checked off:\n- You've verified that newly created schedules appear in the list\n- But you haven't confirmed that scheduled runs execute successfully\n- You also haven't verified the deletion functionality works properly\n- And you haven't tested the UI behavior when the last schedule is deleted\n\nBefore we can merge this PR, please complete the testing according to your test plan and update the checklist to reflect the completed tests. This will ensure that all the functionality you've implemented works as expected.\n\nLet me know if you encounter any issues during testing that need to be addressed!",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)",
      "If you read this, the demo works 8)"
    ],
    "num_comments": 26,
    "repository": "Significant-Gravitas/AutoGPT",
    "diff_length": 91656
  },
  {
    "index": 5,
    "pr_title": "feat(platform, blocks): Webhook-triggered blocks",
    "pr_body": "- Resolves #8352\r\n\r\n## Changes üèóÔ∏è\r\n\r\n- feat(blocks): Add GitHub Pull Request Trigger block\r\n\r\n### feat(platform): Add support for Webhook-triggered blocks\r\n- ‚ö†Ô∏è Add `PLATFORM_BASE_URL` setting\r\n\r\n- Add webhook config option and `BlockType.WEBHOOK` to `Block`\r\n  - Add check to `Block.__init__` to enforce type and shape of webhook event filter\r\n  - Add check to `Block.__init__` to enforce `payload` input on webhook blocks\r\n  - Add check to `Block.__init__` to disable webhook blocks if `PLATFORM_BA",
    "pr_number": 8358,
    "comments": [
      "Ready for review while I iron out the last few details",
      "Convert this to an issue plz?\r\n> Nice-to-have: make a button on webhook blocks to trigger a ping and check its result. The API endpoints for this is already implemented.",
      "![image](https://github.com/user-attachments/assets/f1d2b2a2-7550-456e-af11-1754fe3d1a5a)\r\ncredentials seems non compatible with #8516 \r\n\r\nAlso hit this issue \r\n```\r\nINFO:     127.0.0.1:64414 - \"POST /api/graphs HTTP/1.1\" 400 Bad Request\r\n2024-11-12 19:01:02,046 ERROR  POST /api/graphs failed: Failed to create GitHub webhook: Validation Failed\r\n* url is missing a scheme\r\nTraceback (most recent call last):\r\n  File \"/Users/ntindle/Library/Caches/pypoetry/virtualenvs/autogpt-platform-backend-LOXRIHzA-py3.12/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\r\n    await app(scope, receive, sender)\r\n  File \"/Users/ntindle/Library/Caches/pypoetry/virtualenvs/autogpt-platform-backend-LOXRIHzA-py3.12/lib/python3.12/site-packages/starlette/routing.py\", line 73, in app\r\n    response = await f(request)\r\n               ^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/Library/Caches/pypoetry/virtualenvs/autogpt-platform-backend-LOXRIHzA-py3.12/lib/python3.12/site-packages/sentry_sdk/integrations/fastapi.py\", line 143, in _sentry_app\r\n    return await old_app(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/Library/Caches/pypoetry/virtualenvs/autogpt-platform-backend-LOXRIHzA-py3.12/lib/python3.12/site-packages/fastapi/routing.py\", line 301, in app\r\n    raw_response = await run_endpoint_function(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/Library/Caches/pypoetry/virtualenvs/autogpt-platform-backend-LOXRIHzA-py3.12/lib/python3.12/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\r\n    return await dependant.call(**values)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/server/routers/v1.py\", line 186, in create_new_graph\r\n    return await do_create_graph(create_graph, is_template=False, user_id=user_id)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/server/routers/v1.py\", line 221, in do_create_graph\r\n    graph = await on_graph_activate(\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/integrations/webhooks/graph_lifecycle_hooks.py\", line 43, in on_graph_activate\r\n    updated_node = await on_node_activate(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/integrations/webhooks/graph_lifecycle_hooks.py\", line 140, in on_node_activate\r\n    new_webhook = await webhooks_manager.get_suitable_webhook(\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/integrations/webhooks/base.py\", line 40, in get_suitable_webhook\r\n    return await self._create_webhook(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/integrations/webhooks/base.py\", line 138, in _create_webhook\r\n    provider_webhook_id, config = await self._register_webhook(\r\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/integrations/webhooks/github.py\", line 122, in _register_webhook\r\n    raise ValueError(f\"Failed to create GitHub webhook: {error_msg}\")\r\nValueError: Failed to create GitHub webhook: Validation Failed\r\n* url is missing a scheme\r\nINFO:     127.0.0.1:64466 - \"POST /api/graphs HTTP/1.1\" 400 Bad Request\r\n```\r\n\r\n![image](https://github.com/user-attachments/assets/ebd92341-5b65-4221-8c79-837e8eb934ef)\r\n\r\n\r\nWe should probably have a better error message than that for saying \"set your .env correctly\"",
      "\r\nhttps://github.com/user-attachments/assets/d9a71e7f-f6ae-4483-a770-9e6cf87d045f\r\n\r\nrunning this agent gets me the following \r\n\r\nNote the weird credentials fields",
      "Not sure if related but also can't delete creds",
      "> running this agent gets me the following\r\n> \r\n> [video demonstrating error on run]\r\n\r\nGood catch. I'm not sure how to deal with this. The graph can't be run manually because it relies on a webhook to trigger it. Should we hide the \"Run\" button if a graph can't be run manually? Should it just do nothing?\r\n\r\n> Note the weird credentials fields\r\n\r\nDo you mean it still shows the field title **Credentials** while hiding the actual input? That is a bug, possibly improperly resolved merge conflict. I'll look into it.",
      "Github PR review split the convos, im sorry <3",
      "> Good catch. I'm not sure how to deal with this. The graph can't be run manually because it relies on a webhook to trigger it. Should we hide the \"Run\" button if a graph can't be run manually? Should it just do nothing?\r\n\r\nwhat's toran and john think",
      "> The graph can't be run manually because it relies on a webhook to trigger it. Should we hide the \"Run\" button if a graph can't be run manually? Should it just do nothing?\r\n\r\nSo there needs to be a way of saying that you want your Agent to be \"Running\" - in this case listening for a webhook - or \"Stopped\" - i.e not listening on a webhook. I was thinking the run button would do that here.\r\n\r\nWhat's the current UX for this? Let's sync on this one @Pwuts as it's a lot for a comment.\r\n",
      "Created follow-up ticket #8671",
      "> The advanced button here does nothing?\r\n\r\nThat's because the block has no \"advanced\" inputs, and the toggle doesn't hide when there is nothing to toggle.\r\n\r\n> We probably want these to be able to trivially link\r\n\r\nYes, there are a few ways to do that but most of those are out of scope for this PR and the rest not a sustainable fix imo. We should do a QOL improvement on all of the GitHub blocks to address stuff like this.\r\n\r\n> How do I pass a variable to this block [picture of GitHub webhook trigger block]\r\n\r\nYou don't. Due to the system's architecture, the webhook trigger block can't accept input links and must be the starting node.\r\n\r\n> Why is the output not number type for number\r\n\r\nBecause `NodeHandle` doesn't know what an `integer` is apparently:\r\nhttps://github.com/Significant-Gravitas/AutoGPT/blob/86535b5811f8d1cc0bdde2232693919c4b1115e3/autogpt_platform/frontend/src/components/NodeHandle.tsx#L22-L29\r\n\r\n- [ ] Add `integer` type to `NodeHandle` type list\r\n\r\n> we should probably allow the block to output the repo, URL, etc too for the trigger if its not taking in inputs\r\n\r\nMy idea for a sustainable and scalable fix for that is: allow directly connecting links to nested properties of object outputs. That's way out of scope for this PR.\r\n\r\nDue to the block layout, I don't want to add a large number of outputs because that just fills up the screen very quickly.\r\n\r\n> We need to clarify Payload, Sender and Pull request for normal people\r\n\r\nIf you don't know what a pull request is, why would you be using this block?\r\n\r\n- [x] Improve description of `payload` output\r\n\r\n> I'm not sure the diff in pull request and Payload\r\n\r\ncan't parse, come again?\r\n\r\n> I assume sender is creator?\r\n\r\nSender already has the description *\"Object representing the user who triggered the event\"*. Do you think that output also needs a better name, and if so what?\r\n\r\n> I have no idea (as a dev, not even user) how to debug this via UI. As a dev, I checked the raw output of the block in the logs. It just \"didn't work\" but succeeded from the UI perspective\r\n\r\nI also just debug by looking at the backend logs. Suggestions welcome.\r\n\r\nWe could store all incoming webhook payloads and add a view for that, but that's a significant feature addition. WDYT?\r\n\r\n> If a user does a bad design (ex: leaving out a value on a comparison) the webhook rejects but they should probably know that when saving because it will be an issue they won't be able to diagnose.\r\n\r\nYeah the node needs an indicator for whether a webhook is attached or not. Determining why can usually be done client-side, because it depends directly on whether the user filled out all the required inputs on the node.\r\n\r\n- [x] Create issue for webhook status indicator on webhook-triggered nodes\r\n\r\n> The Run button throws an error when you run (this is better than crashing tho)\r\n\r\nWould you rather hide the button? I'm not sure how to properly fix this.\r\n\r\n> We may want to do something to require platform base URL to be set if someone uses a trigger because currently it just doesn't do anything.\r\n\r\n- [x] Disable webhook-triggered blocks if `PLATFORM_BASE_URL` is not set\r\n- [x] Raise error in `BaseWebhooksManager` on attempt to create webhook if `PLATFORM_BASE_URL` is not set\r\n\r\n> we currently don't actually check platform base URL on inbound webhooks so we just execute from anything lol.\r\n> \r\n> > Replicate by running ngrok and disabling the line in your .env\r\n\r\nWhy would we need to check it on inbound webhook payloads? If it arrives, that's a job done. The `PLATFORM_BASE_URL` is only necessary to configure the webhook in the first place."
    ],
    "num_comments": 11,
    "repository": "Significant-Gravitas/AutoGPT",
    "diff_length": 179892
  },
  {
    "index": 6,
    "pr_title": "Plugin Support",
    "pr_body": "### Background\r\n\r\nAdds basic plugin support.\r\n\r\n### Changes\r\n\r\nAdd plugins.py which handles scanning plugins folder for zipfiles and check for modules to import.\r\n\r\nIn main.py on startup it will load the plugins into the config file.\r\n\r\nIn LLM utils it will iterate the plugins on each response.\r\n\r\n### Documentation\r\n\r\nDocstrings and README updated.\r\n\r\n### Test Plan\r\n\r\nI tested this code here: https://github.com/BillSchumacher/Auto-Vicuna\r\n\r\nI have an example plugin for that project here: https:/",
    "pr_number": 757,
    "comments": [
      "This is pretty similar to #350 ",
      "> This is pretty similar to #350\r\n\r\nNot really this loads external repos as zipfiles.",
      "If anyone has suggestions on other ways to hook certain points in the Auto-GPT flow don't hestitate to speak up.",
      "> If anyone has suggestions on other ways to hook certain points in the Auto-GPT flow don't hesitate to speak up.\r\n\r\nThis is a key point we need to work out, lots of different ways to do this, and we want to focus on enabling as many types of plugins as possible!",
      "> Not really this loads external repos as zipfiles.\r\n\r\nI'm just curious as to how plugins would function differently than commands. ",
      "Plugins can implement new commands, or change functionality of existing ones.\r\nThe difference is that they will allow Auto-GPT to be hooked up to _anything_.\r\n\r\nThere are plenty of use-cases that people have requested that don't make sense being in the core repo for everyone.\r\n\r\nSpecific niche integrations. This is useful because people wont want AutoGPT to come with tons of bloat pre-installed.",
      "> > Not really this loads external repos as zipfiles.\r\n> \r\n> I'm just curious as to how plugins would function differently than commands.\r\n\r\nIt would keep this codebase clean, allowing for faster reviews and more flexibility for people to add functionality they think other people would like without having to wait for a merge.",
      "Ah, yeah I get it. I didn't really consider bloat being a possible concern, but it's a valid point.",
      "Would some kind of \"plugin marketplace\" be needed to support this?",
      "> Would some kind of \"plugin marketplace\" be needed to support this?\r\n\r\nThe current implementation allows for any repo that uses the template to be downloaded as zip and dropped into the plugins folder.\r\n\r\nI would imagine a plugins channel in discord to start with.\r\n\r\nToran might get rich with a 30% cut from the marketplace though ü§î ",
      "Just thinking through the plugin whitelist and possibility for any abuse.  It only checks by name.  I think the caveat emptor in the readme is probably the best we'll get.  \r\nPossible improvement - we're only checking by name, and we don't check if we've already loaded a whitelisted plugin by that name - which might be worth adding?",
      "> Just thinking through the plugin whitelist and possibility for any abuse. It only checks by name. I think the caveat emptor in the readme is probably the best we'll get. Possible improvement - we're only checking by name, and we don't check if we've already loaded a whitelisted plugin by that name - which might be worth adding?\r\n\r\nThat's a fair point this implementation is actually quite bad.\r\n\r\nWe would probably want some md5 hashes or sha256 of the zip.\r\n\r\nI also didn't take into account external dependencies, which might be a good thing but probably to result in complaints.",
      "@BillSchumacher There are conflicts now",
      "@richbeales @BillSchumacher is there a way to do it where they're added as python packages in requirements.txt? The README could recommend specifying the specific commit like this:\r\n\r\n```\r\ngit+https://github.com/random-dev/example-auto-gpt-plugin@42b95dc=example-auto-gpt-plugin\r\n```\r\n\r\nWhatever package delivery option you pick; I'd recommend, to keep the feature simple for now, that users have to manually authorise each plugin every time the application boots, unless an environment variable `SKIP_PLUGIN_AUTH=true`. If that env var is set then the UI should display a clear warning and list the plugins that are registered.",
      "> Whatever package delivery option you pick; I'd recommend, to keep the feature simple for now, that users have to manually authorise each plugin every time the application boots, unless an environment variable `SKIP_PLUGIN_AUTH=true`. If that env var is set then the UI should display a clear warning and list the plugins that are registered.\r\n\r\nI agree in that asking to manually authorise every plugin and accept the risks every time the application boots is probably the most pragmatic approach. This will also keep this PR simple. Further refinement to the security model can be piled on after observations from the community use. \r\n\r\nThis PR seems quite important to help the community focus on extending Auto-GPT while this repo can focus on quality of the core.",
      "@BillSchumacher does this seem like a reasonable API to land on? \r\n![image](https://user-images.githubusercontent.com/39720479/232123556-ef3f7622-7794-4246-b782-0d3b5f3df9b4.png)\r\n\r\n```python\r\nPromptName = str\r\nPromptRole = str\r\nPromptGoals = List[str]\r\nPrompt = tuple[PromptName, PromptRole, PromptGoals]\r\n\r\npost_prompt(prompt: Prompt) -> Prompt\r\n\r\non_planning(prompt: Prompt, messages: List[str]) -> Optional[str]\r\npost_planning(response: str) -> str\r\n\r\npre_instruction(messages: List[str]) -> List[str]\r\non_instruction(messages: List[str]) -> Optional[str]\r\n# TODO: Better JSON type\r\npost_instruction(response: str) -> str\r\n\r\npre_command(instruction: str) -> str\r\npost_command(messages: List[str]) -> List[str]\r\n```",
      "Where every hook is optional, and it `on_planning`/`on_instruction` allow you to leave the default OpenAI calls by simply returning `None`",
      "As an example for this kind of architecture, the guy on discord who swapped out JSON instructions with YAML could override `pre_instruction` to ask for YAML instead of JSON, then override `pre_command` to convert the YAML back to json so that existing commands still work unchanged",
      "Also allows adding more commands via a `custom_commands` field that you can throw in",
      "Btw, I have no idea how Figma deals with people collaborating for free in FigJam files, but in case it's allowed, here's the link to that FigJam: https://www.figma.com/file/KpX21VXXmyXDZhTOfBH1sL/AutoGPT-Plugin-Architecture?node-id=0%3A1&t=vzGe8FlrCbMMvl4R-1",
      "> @BillSchumacher does this seem like a reasonable API to land on? ![image](https://user-images.githubusercontent.com/39720479/232123556-ef3f7622-7794-4246-b782-0d3b5f3df9b4.png)\r\n> \r\n> ```python\r\n> PromptName = str\r\n> PromptRole = str\r\n> PromptGoals = List[str]\r\n> Prompt = tuple[PromptName, PromptRole, PromptGoals]\r\n> \r\n> post_prompt(prompt: Prompt) -> Prompt\r\n> \r\n> on_planning(prompt: Prompt, messages: List[str]) -> Optional[str]\r\n> post_planning(response: str) -> str\r\n> \r\n> pre_instruction(messages: List[str]) -> List[str]\r\n> on_instruction(messages: List[str]) -> Optional[str]\r\n> # TODO: Better JSON type\r\n> post_instruction(response: str) -> str\r\n> \r\n> pre_command(instruction: str) -> str\r\n> post_command(messages: List[str]) -> List[str]\r\n> ```\r\n\r\nYeah I like it =)",
      "I'll be implementing this shortly.",
      "Implementation note, instead of the prompt tuple I'm passing a PromptGenerator object, which is what we use to contruct the full system prompt. \r\n\r\nIf you change something in post_prompt, it will alter the system_prompt. Something we've been thinking about doing with the assistants.\r\n\r\n```\r\npost_prompt(prompt: PromptGenerator) -> PromptGenerator\r\n```\r\n\r\nplugin ordering may affect output, something to beware of.",
      "Another note, when creating an AI config you can now pass a `PromptGenerator` object.\r\n\r\nThe prompt generator now also has a goals property that is assigned from the `AIConfig` object when construct_full_prompt is called.",
      "I guess I need to move the name and role into the prompt generator as well...",
      "@BillSchumacher no worries! Those were just types I'd thought of that might make sense from my black box view. I will update the Figma diagram! I'm going to work on some documentation for all of this as you work on implementation to help the community write/read plug-ins, so please lmk if anything else needs to change like a different name or anything like that! ",
      "Implementation note, even though we are passing a PromptGenerator object to the on_planning method of the plugin changing it's values will not change the prompt. It should be used to come up with additional context to send to the chat completion function.\r\n\r\n```\r\non_planning(prompt: PromptGenerator, messages: List[str]) -> Optional[str]\r\n```\r\n\r\nIf the response is None or an empty string it will be skipped, otherwise it will be added to the context *if* there are enough send tokens available, if there are not the plugin processing loop stops early and the context is not added.",
      "I'm not sure if the order of the context matters for getting the correct result back, also this is added as a \"system\" role, we might want to change that, unsure.",
      "It's also noteworthy that if you wanted, since this is python you could technically alter the context and that updated context would remain, if you wanted to remove certain messages, add new ones or whatever. Kind of a hack but it would work.\r\n\r\nWhen I refer to `context` I mean the second argument, the `messages`. If you do decide to do something like this, you should track the total cost in tokens.",
      "Our workflow doesn't quite work like this so I'm going to try to update the diagram, the sub-agents are not called every loop but rather by command."
    ],
    "num_comments": 30,
    "repository": "Significant-Gravitas/AutoGPT",
    "diff_length": 109915
  },
  {
    "index": 7,
    "pr_title": "feat(platform/library): Triggered-agent support",
    "pr_body": "This pull request adds support for setting up (webhook-)triggered agents in the Library. It contains changes throughout the entire stack to make everything work in the various phases of a triggered agent's lifecycle: setup, execution, updates, deletion.\r\n\r\nSetting up agents with webhook triggers was previously only possible in the Builder, limiting their use to the agent's creator only. To make it work in the Library, this change uses the previously introduced `AgentPreset` to store information ",
    "pr_number": 10167,
    "comments": [
      "Thank you for your PR implementing webhook-triggered agent support. The code changes look good, but since this is marked as WIP, there are a few things to address before it can be merged:\n\n1. Please expand the PR description with more details about what this feature does and the specific changes you've made. While the reference to issue #10111 is helpful, a summary of the implementation would provide better context.\n\n2. None of the checklist items are checked off. Please complete the checklist, particularly:\n   - Clearly listing your changes in the PR description\n   - Creating and documenting a test plan\n   - Confirming you've tested according to that plan\n\n3. If there are any configuration changes needed for this feature, please document them.\n\nYour code changes look solid - I especially appreciate how you've maintained the user_id checks in the webhook-related functions and updated the database schema appropriately. Once you've completed the PR description and checklist, this should be ready for further review.",
      "Thank you for your work on adding webhook-triggered agent support to the platform. Since this is marked as a Work in Progress (WIP), I understand it's not yet ready for full review, but here are some points to address before this can be merged:\n\n1. **PR Description**: Please provide a comprehensive description of the changes you've made. Currently, it only says \"WIP\". Even for a work-in-progress PR, it's important to document what you've done so far and what still needs to be completed.\n\n2. **Checklist**: None of the items in the checklist are checked off. Please update the checklist to reflect the current status of your work, checking off completed items.\n\n3. **Test Plan**: Develop and document a test plan for this feature. Since this involves webhook triggers, consider including specific test cases for various webhook scenarios.\n\n4. **Documentation**: Consider adding comments or documentation about how the webhook-triggered agent support works, especially for the new API endpoint `/setup_webhook_trigger`.\n\n5. **Configuration Changes**: If there are any configuration changes needed (especially for webhook handling), make sure `.env.example` and `docker-compose.yml` are updated accordingly.\n\nThe changes look promising and address an important feature, but they need more documentation and testing before they can be merged. Please update the PR with these items when you're ready for a more thorough review.",
      "Thank you for your PR working on webhook-triggered agent support! \n\nI see this is marked as a Work in Progress (WIP), which explains the current state of the PR. Before this can be merged, you'll need to address the following:\n\n1. Please expand the PR description with details about the specific changes you're making. Just marking it as \"WIP\" isn't sufficient - explain what webhook-triggered agent support means and how your implementation works.\n\n2. Complete the checklist in the PR description. All applicable items need to be checked off.\n\n3. Consider whether the scope in your PR title is accurate. Your changes span both frontend and backend components (as indicated by the labels and the files changed), but the title only mentions 'platform/library'.\n\n4. Since you're modifying files in `backend/data/`, please ensure that any added or modified functions properly handle user_id checks, and note this in your description.\n\n5. Include a test plan that explains how you've verified your changes work correctly.\n\nPlease update the PR when it's no longer a work in progress and all these items have been addressed. Looking forward to seeing the completed implementation!",
      "Thank you for your PR on webhook-triggered agent support! I notice this is marked as WIP, but there are a few things that need attention before this can be merged:\n\n1. **PR Description**: Please provide a detailed description of what this feature does and how it works. The current description only mentions it's WIP and references an issue number.\n\n2. **Checklist**: None of the items in the checklist have been checked off. Please complete the checklist or mark which items are still in progress.\n\n3. **Scope**: Your PR title specifies `platform/library`, but the changes span across backend, frontend, and database schema. Consider whether the scope in the title accurately reflects the breadth of changes.\n\n4. **User ID Verification**: Since you're modifying files in `backend/data/`, please ensure that any added/changed functions properly handle user_id verification, or explain why it's not needed.\n\n5. **Test Plan**: Please outline how you've tested or plan to test this webhook functionality.\n\nWhen you're ready to move this PR out of WIP status, please update the description with these details and complete the checklist. This will help reviewers understand the purpose and impact of your changes.",
      "Thank you for your PR adding webhook-triggered agent support! I notice this is marked as a Work in Progress, so here's some feedback to help guide you toward completion:\n\n1. Please complete the PR description with details about the specific changes you're making. The \"Changes\" section currently only contains \"WIP\" but should explain what functionality you're adding and how it works.\n\n2. There appears to be a mismatch between your PR title scope (platform/library) and the actual changes, which include both frontend and backend components (as indicated by the labels and file changes). Consider updating your PR title to better reflect the scope of changes.\n\n3. None of the checklist items are checked off yet. Please complete the checklist before requesting review, including:\n   - Adding a clear test plan\n   - Ensuring you've tested the changes\n   - Checking that configuration files are updated if needed\n\n4. Since you're modifying files in backend/data/, please ensure any new or modified functions properly check user_id permissions where appropriate.\n\nPlease update your PR when it's ready for review, completing the description and checklist. Feel free to remove the WIP marker at that point.",
      "Thank you for your PR on adding Webhook-triggered Agent support. Since this is marked as a work in progress (WIP), I'm providing initial feedback before you finalize it:\n\n1. **Complete the PR description**: Please provide a detailed description of the changes you've made when this PR is ready for review. This should include what Webhook-triggered Agent support is, how it works, and the key components you've implemented.\n\n2. **Fill out the checklist**: None of the checklist items are currently checked. Please complete this when your PR is ready for review.\n\n3. **Add a test plan**: Include specific tests you've performed to verify the webhook functionality works as expected.\n\n4. **Configuration changes**: If your implementation requires any configuration changes (which seems likely for webhook integration), please document these in the PR description.\n\n5. **Scope alignment**: Your PR touches both frontend and backend code. Make sure all changes are related to the webhook-triggered agent support feature mentioned in the title.\n\nPlease update the PR when it's no longer a work in progress and ready for a thorough review. Looking forward to seeing the completed implementation.",
      "Thank you for your PR implementing webhook-triggered agent support. Since this is marked as a Work in Progress (WIP), I understand it's not ready for final review yet. Here's what you'll need to address before this can be merged:\n\n1. **Complete the PR description**: \n   - Provide a detailed explanation of what changes you've made\n   - Describe how webhook-triggered agent support works\n   - List any configuration changes required\n\n2. **Fill out the checklist**:\n   - All items in the checklist need to be checked off\n   - Add a test plan specific to testing webhook functionality\n\n3. **Configuration documentation**:\n   - Ensure any new environment variables are documented in `.env.example`\n   - Update `docker-compose.yml` if needed\n\nWhen you're ready for review, please mark the PR as ready and update the description accordingly. If you need any help or have questions during development, feel free to ask!\n\nLooking forward to seeing the completed implementation of webhook-triggered agent support.",
      "Thank you for starting work on webhook-triggered agent support. I notice this PR is marked as WIP, which is fine, but there are several items that need to be addressed before it can be considered for merging:\n\n1. Please expand the PR description to include more details about the specific changes you're making. Even for a WIP PR, it's helpful to outline what you've implemented so far and what's still pending.\n\n2. None of the checklist items have been completed yet. Please check them off as you progress through the implementation.\n\n3. Since you're modifying files in `backend/data/`, please ensure any new or modified functions properly handle user_id checks for security purposes.\n\n4. Consider adding a test plan specific to webhook functionality to demonstrate how you'll verify the implementation works as expected.\n\n5. If you've added any new environment variables or configuration requirements for the webhook functionality, please document these in the PR description.\n\nI'm marking this as a failure not because there's anything wrong with the code itself (which I haven't reviewed in detail), but because the PR as currently submitted is explicitly a work in progress and not ready for final review. Please feel free to update the PR when you're further along, and I'll be happy to review it again.",
      "Thank you for your PR on webhook-triggered Agent support! I notice this is marked as a work in progress, which is fine, but there are several items that will need to be addressed before this can be merged:\n\n1. **PR Description**: Please provide a more detailed description of the changes when you're ready to merge. The current description only references an issue number and states \"WIP\".\n\n2. **Checklist**: None of the checklist items have been checked off. Please complete the checklist when the PR is ready for review.\n\n3. **PR Scope and Labels**: Your PR title specifies platform/library, but you have both platform/frontend and platform/backend labels. Make sure the scope in your title accurately reflects all the components you're modifying.\n\n4. **User ID Checks**: Since you're modifying files in backend/data/, please ensure that any changed or added functions correctly handle user_id validation, or provide an explanation of why this isn't necessary.\n\n5. **Frontend Route Protection**: If you're adding any new base routes to the frontend that require protection, make sure to update the protections in lib/supabase/middleware.ts.\n\nPlease continue your work on this PR, and when you're ready for a full review, update the description with detailed information about your changes and complete the checklist. Feel free to request reviews when you're ready.",
      "Thank you for your work on implementing webhook-triggered agent support. I notice this PR is marked as WIP, which explains why some aspects aren't complete yet. Before this can be merged, please address the following:\n\n1. Complete the PR description with details about all the changes you've made. The current description only references an issue without explaining what's being implemented.\n\n2. Fill out the checklist completely. Every item needs to be checked off before the PR can be merged.\n\n3. Provide a test plan that explains how you've tested the webhook functionality.\n\n4. Since you're modifying files in backend/data/ (graph.py and integrations.py), please ensure user_id is properly passed and verified in any added or modified functions.\n\n5. Update the \"Changes\" section to list all the significant modifications you're making to implement webhook-triggered agent support.\n\n6. If your implementation adds any new configuration requirements, please document them in the PR description.\n\nWhen you're ready to move this out of WIP status, please update the PR accordingly, and we'll be happy to review it again.",
      "Thank you for your work on implementing webhook-triggered agent support! I notice this is marked as a Work in Progress (WIP), which explains the current state of the PR.\n\nBefore this can be merged, you'll need to:\n\n1. Complete the PR description with a clear explanation of the changes and their purpose\n2. Fill out the checklist completely\n3. Provide a test plan that shows how you've verified the functionality\n4. Ensure any configuration changes are documented\n\nI see the changes span both frontend and backend components, which makes sense for this feature. When you're ready for a full review, please:\n\n- Verify that any modified functions in the backend/data directory correctly handle user_id validation\n- Confirm that any new frontend routes have appropriate middleware protections\n- Make sure the scope in the PR title accurately reflects the breadth of changes\n\nPlease update the PR when it's ready for a comprehensive review. Looking forward to seeing this feature completed!",
      "Thank you for starting work on webhook-triggered agent support! I notice this PR is marked as a work in progress, which is fine for early collaboration, but it's not ready for final review yet.\n\nBefore this can be considered for merging, please:\n\n1. Complete the PR description with detailed information about what changes you're making and why\n2. Fill out the \"Changes\" section with a concise summary of all modifications\n3. Complete the checklist items, particularly:\n   - Clearly listing your changes\n   - Creating and documenting a test plan\n   - Testing according to that plan\n   - Addressing any configuration changes needed\n\n4. If you're modifying files in backend/data/, please ensure proper user_id checks are in place or explain why they aren't needed\n\n5. Since this appears to touch both frontend and backend components, the labels should include platform/library (which aligns with your PR title) rather than just the individual components\n\nI see you've referenced issue #10111, which helps provide context, but more details in the PR itself would be helpful for reviewers.\n\nPlease update the PR when it's ready for a more thorough review. Looking forward to seeing the completed implementation!",
      "Thank you for your work on webhook-triggered Agent support! This appears to be a significant feature addition spanning multiple components of the platform.\n\nHowever, I notice this PR is currently marked as \"WIP\" (Work in Progress) and doesn't have:\n\n- A complete description of the changes\n- Any checked items in the checklist\n- A test plan\n\nBefore this PR can be considered for merging, please:\n\n1. Complete the description with details about what this webhook-triggered Agent support feature does and how it works\n2. List all the changes you've made across the various components (backend, frontend, blocks)\n3. Fill out and check off the appropriate items in the checklist\n4. Provide a test plan that explains how to verify this feature works correctly\n5. Update the PR title if needed to accurately reflect the scope of changes (the current scope is platform/library, but the changes seem broader based on the modified files)\n\nOnce the PR is no longer a work in progress and these items are addressed, we'll be happy to review it again.",
      "Thank you for your PR implementing webhook-triggered agent support. Since this is marked as a Work in Progress (WIP), I understand it's not ready for final review, but I'd like to provide some guidance to help you prepare for when it is ready:\n\n1. **PR Description**: Please expand the description to explain:\n   - What webhook-triggered agent support is and why it's needed\n   - A summary of the key changes you're making\n   - Any architectural decisions that reviewers should be aware of\n\n2. **Checklist**: The checklist items need to be completed before the PR can be merged. This includes:\n   - Clearly listing your changes\n   - Creating and following a test plan\n   - Ensuring configuration changes are documented\n\n3. **PR Scope**: Your changes touch multiple areas including backend, frontend, and blocks components, but your PR title only mentions platform/library. Consider updating the title to better reflect the scope of changes or split this into multiple PRs if appropriate.\n\n4. **Data Files**: Since you're modifying files in backend/data/, please ensure that any added/changed functions properly pass and check the user_id parameter where required.\n\nPlease update the PR when it's ready for review with these items addressed. If you need any clarification or help with any of these points, feel free to ask!",
      "Thank you for your PR implementing webhook-triggered agent support. Since this is marked as a Work in Progress (WIP), I understand it's not ready for final review yet, but I wanted to provide some early feedback:\n\n1. **PR Description**: Please expand the description to explain the purpose and scope of these changes once you're ready for review. While you've referenced issue #10111, a brief summary of what webhook-triggered agent support entails would be helpful.\n\n2. **Checklist**: None of the items are currently checked off. Please complete the relevant items before requesting final review.\n\n3. **Scope**: Your PR title specifies `platform/library`, but the changes span across backend, frontend, blocks, and include database migrations. Consider whether the scope in the title accurately reflects the breadth of changes.\n\n4. **Data Functions**: Since there are changes to files in `backend/data/`, please ensure any new or modified functions properly check user_id where appropriate.\n\n5. **Test Plan**: Be sure to include a specific test plan for testing webhook functionality when you're ready for review.\n\nFeel free to keep iterating on this PR and update the description and checklist when you're closer to completion. Let us know if you need any help or clarification!",
      "Thank you for your PR on webhook-triggered agent support. Since this is marked as Work in Progress, here's some guidance to help move it toward a mergeable state:\n\n1. **PR Description**: Please update your description with a clear explanation of what this webhook-triggered agent support feature does and why it's needed. While you've referenced issue #10111, a brief summary would be helpful.\n\n2. **Changes Section**: The \"Changes\" section currently only says \"WIP\". When you're ready for review, please provide a concise description of all the changes made in this PR.\n\n3. **Checklist**: None of the checklist items are currently checked. Before requesting a review, please complete the checklist by testing your changes according to a test plan.\n\n4. **Configuration Changes**: Your PR includes changes to `schema.prisma` and adds a migration file. Please update the checklist to confirm that `.env.example` and `docker-compose.yml` are compatible with these changes.\n\nI see this is implementing webhook functionality across multiple parts of the platform. When you're ready for a proper review, we'll need to ensure that any data access functions properly validate user_id where required.\n\nLet us know when this PR is ready for a thorough review!",
      "Thank you for submitting this PR for Webhook-triggered Agent support. I notice this is marked as a Work in Progress (WIP) and none of the checklist items have been completed yet.\n\nBefore this PR can be considered for merging, please:\n\n1. Complete the PR description with details about the changes being made\n2. Check off the relevant items in the checklist after completing them\n3. Provide a test plan for your changes\n4. Ensure any configuration changes are properly documented\n\nThe scope of changes appears substantial, touching both frontend and backend components, which aligns with the cross-cutting nature of adding webhook support. \n\nPlease update the PR when it's ready for a full review. I'd be happy to take another look once the WIP status is removed and the checklist items are addressed.",
      "Hi @Pwuts, thank you for your PR on webhook-triggered Agent support. \n\nThis PR is currently marked as a Work in Progress, and I notice that:\n\n- The description only mentions \"WIP\" under changes without detailing what modifications are being made\n- None of the checklist items are checked off\n- The PR title refers to platform/library, but the changes appear to span backend, frontend, and blocks components\n\nBefore this can proceed to review, please:\n\n1. Complete the description with details about what webhook-triggered Agent support entails and how you've implemented it\n2. Fill out the checklist completely (or remove sections that aren't applicable)\n3. Consider updating the PR title to better reflect the scope of changes if they go beyond just the platform/library component\n4. Ensure any backend/data changes properly handle user_id permissions\n5. Document your test plan and results\n\nI see this is linked to issue #10111, so once you've completed the implementation and updated the PR details, we'll be happy to review it. Let us know if you need any guidance or clarification on the requirements.",
      "Thank you for your PR on Webhook-triggered Agent support! Since this is marked as a Work in Progress (WIP), I understand that not everything is complete yet. However, there are several items that will need to be addressed before this can be considered ready for merging:\n\n1. **Description needs to be completed**: Please provide a clear and detailed explanation of what this feature does and the changes you've made when you're ready to finalize the PR.\n\n2. **Checklist needs to be completed**: All items in the checklist need to be checked off, including your test plan.\n\n3. **Scope alignment**: Your PR title mentions 'platform/library', but the changes span across frontend, backend, and blocks components. Consider either adjusting the title to better reflect the scope or explaining why these broader changes are necessary for the library feature.\n\n4. **Data layer security**: There appear to be changes to backend/data files - make sure any new or modified functions properly check user_id where appropriate.\n\n5. **Configuration changes**: Your PR includes schema.prisma changes and a new migration - please document these in the 'Changes' section when finalizing the PR.\n\nPlease complete these items when you're ready to move this PR from WIP status to ready for review. Let us know if you need any assistance with any of these points!",
      "Thank you for your PR on webhook-triggered agent support! This seems like an important feature, but there are a few things that need to be addressed before this can be considered for merging:\n\n1. **Complete the PR description**: \n   - Please replace the \"WIP\" with a clear explanation of what webhook-triggered agent support entails\n   - Describe the specific changes you've made across the various components\n\n2. **Complete the checklist**:\n   - All items in the checklist need to be checked off\n   - Include your test plan with specific steps you've taken to verify the functionality\n\n3. **Configuration changes**:\n   - Document any changes to environment variables in `.env.example`\n   - Ensure `docker-compose.yml` is updated if needed\n   - List the configuration changes in your PR description\n\n4. **Security considerations**:\n   - Since you're modifying files in `backend/data/`, please ensure proper user_id handling\n   - For webhook endpoints, ensure appropriate authentication and authorization mechanisms\n\n5. **Scope clarification**:\n   - Your PR touches backend, frontend, and blocks components, which is broader than just \"platform/library\" in the title\n   - Consider updating the PR title to better reflect the full scope of changes\n\nPlease update your PR when it's no longer a work in progress and all these items have been addressed. The feature looks promising, and I'm looking forward to reviewing the completed implementation!",
      "Hi @Pwuts,\n\nThank you for your work on webhook-triggered Agent support. I see this is marked as a work in progress (WIP), so my feedback is based on what would be needed to make this PR ready for review and merging.\n\n### What needs attention:\n\n1. **PR Description**: Please complete the description with detailed information about the changes you're making. What does webhook-triggered Agent support entail? What problem does it solve?\n\n2. **Changes Section**: The \"Changes\" section is currently marked as WIP. Please provide a concise list of all the changes made in this PR.\n\n3. **Checklist**: None of the checklist items are checked. Please complete the checklist, including your test plan.\n\n4. **Scope Mismatch**: Your PR title mentions 'platform/library', but the changes appear to span backend, frontend, and blocks components (as indicated by the file changes and PR labels). Consider updating the PR title to better reflect the scope of changes.\n\n5. **Configuration Changes**: Since you've added migrations and modified the schema, please document any configuration changes needed.\n\n6. **Testing**: Ensure you've tested the webhook functionality and document your test plan.\n\nThis looks like an exciting feature addition! When you've completed your work and addressed these points, please remove the WIP marker and request a review.\n\nLooking forward to seeing the completed implementation!",
      "Thank you for working on webhook-triggered agent support! This PR appears to be a work in progress, which is fine, but there are several things that need to be addressed before it can be considered for merging:\n\n1. **PR Description**: Please provide a detailed description of the changes you're making. Explain what webhook-triggered agent support is, how it works, and why it's being added.\n\n2. **Checklist Completion**: None of the checklist items have been checked off. Before this PR can be merged, you'll need to complete the checklist.\n\n3. **Test Plan**: Please create a test plan specific to the webhook functionality you're implementing. What scenarios should be tested? How can reviewers verify the functionality works correctly?\n\n4. **Configuration Changes**: If your webhook implementation requires any configuration changes (environment variables, etc.), please document these in the PR description.\n\n5. **Scope Alignment**: The PR title specifies platform/library, but the changes span across frontend, backend, and blocks. Consider updating the title to better reflect the scope of changes.\n\nThe implementation itself spans multiple components of the platform, which makes sense for a feature like webhook integration. Once you've completed your work and addressed the points above, this PR will be ready for a more thorough review.\n\nLet us know if you need any help or have questions as you continue developing this feature!",
      "Hi @Pwuts,\n\nThanks for submitting this PR for Webhook-triggered Agent support. I see this is marked as a Work in Progress and builds on a previous PR.\n\nBefore this can be considered for merging, you'll need to:\n\n1. Complete the PR description with details about the changes being made\n2. Fill out the checklist in the PR description\n3. Create and document a test plan\n4. Consider updating the PR title to better reflect the broad scope of changes - the current title mentions platform/library but the changes span backend, frontend, and database components\n\nThe PR contains significant changes across multiple areas of the codebase, so a comprehensive description and test plan will be particularly important.\n\nPlease update the PR when it's ready for a full review. Looking forward to seeing this feature develop!",
      "Thank you for your PR submission! I noticed this is marked as a Work in Progress (WIP), which explains why the description and checklist are incomplete.\n\nBefore this can be merged, you'll need to:\n\n1. Complete the PR description with details about all changes made\n2. Fill out the checklist completely\n3. Consider updating the PR title to better reflect the scope of changes - the current title mentions platform/library but your changes affect backend, frontend, and include database migrations\n4. If you've modified any functions in backend/data/*.py files, ensure they properly handle user_id checks\n\nThe webhook-triggered agent support looks like a substantial feature addition! When you're ready to finalize this PR, please update the description with details about:\n- What problem this feature solves\n- How it works at a high level\n- Any configuration changes needed\n- Testing you've performed\n\nPlease let us know when this is ready for review by removing the WIP status and completing the required sections.",
      "Thank you for your PR implementing webhook-triggered Agent support! I see this is marked as a Work in Progress and builds on PR #9786.\n\nBefore this can be merged, there are several items that need to be addressed:\n\n1. **Description needs to be completed**: Please provide a detailed description of what changes are being made and how they implement webhook-triggered Agent support. \n\n2. **Checklist is incomplete**: None of the checklist items are checked off. Please ensure you complete all the relevant items before requesting review.\n\n3. **Test plan**: Add a specific test plan for this feature, especially focusing on how to test the webhook triggering functionality.\n\n4. **Scope verification**: Your PR affects multiple areas (backend, frontend, blocks) which is reflected in the labels. Please ensure all changes are relevant to the webhook-triggered Agent support feature.\n\n5. **Backend data changes**: Since you've modified files in backend/data/, please ensure any new/changed functions properly check user_id where appropriate.\n\n6. **Configuration changes**: If there are any configuration changes needed for webhook support, please document them.\n\nLooking forward to seeing this completed! This appears to be a valuable addition to the platform.",
      "Thank you for submitting this PR for webhook-triggered agent support! I can see this is marked as a work in progress, which is great for early feedback, but there are several items that need to be addressed before this can be considered for merging:\n\n1. **PR Description**: Please provide a more detailed description of the changes you're making. The current description just says \"WIP\" under the Changes section. A clear explanation of what webhook-triggered agent support entails and how you've implemented it would be helpful.\n\n2. **Checklist**: None of the checklist items are currently checked. Please complete the checklist when you're ready for this PR to be reviewed for merging.\n\n3. **Scope**: While your PR title mentions platform/library, the changes span across backend, frontend, and blocks (as indicated by the labels). Please ensure the PR title accurately reflects the scope of changes.\n\n4. **Security Considerations**: \n   - For changes to backend/data/*.py files, please ensure that user_id checks are properly implemented\n   - For any new frontend routes, ensure that appropriate protections are in place\n\n5. **Test Plan**: When you're ready to move this out of WIP status, please include a detailed test plan showing how you've verified the webhook functionality works correctly.\n\nI'm looking forward to seeing this develop further. The webhook-triggered agent support sounds like a valuable addition to the platform!"
    ],
    "num_comments": 26,
    "repository": "Significant-Gravitas/AutoGPT",
    "diff_length": 163563
  },
  {
    "index": 8,
    "pr_title": "Add settings for custom base url",
    "pr_body": "Making the openai base url and embedding dimension configurable, these are useful to integrate AutoGPT with other models, like LLaMA\r\n\r\n### Background\r\nThis makes AutoGPT capable of connecting to custom openai-like APIs like [[keldenl](https://github.com/keldenl)](https://github.com/keldenl/gpt-llama.cpp), and use other models, like LLaMA and derivates.\r\n\r\nsee also #25 #567  #2158\r\n\r\n### Changes\r\nAdded OPENAI_API_BASE_URL ~~and EMBED_DIM~~ to .env_template and loaded them in config.py, making su",
    "pr_number": 2594,
    "comments": [
      "A name like `LLM_API_BASE_URL` instead of `OPENAI_API_BASE_URL` might be more fitting since it allows us to not always use OpenAI's API",
      "It's still using the OpenAI API, just not their endpoint, even if the model behind it isn't an OpenAI model.",
      "Thanks so much for building this @DGdev91 and delivering the required documentation. Really awesome job!\r\n\r\nFor the ones struggling to implement this, it took me a while finding the right model for the job. Eventually I got it to work with ggml-vicuna-13b-1.1-q4_2.bin (from huggingface).\r\n\r\nmy .env.: \r\n- OPENAI_API_BASE_URL=http://localhost:443/v1\r\n- EMBED_DIM=5120\r\n- OPENAI_API_KEY=M:\\AI\\llama.cpp\\models\\ggml-vicuna-13b-1.1-q4_2.bin\r\n\r\nI do have to say, it's incredibally slow on my machine. While I have a decent processor and 32G of ram (and a geforce RTX 3070ti) and am running the model from a fast SSD, it will not utilize my full machine. It will actually timeout (600 seconds) every request unless I put the TIMEOUT_SECS = 6000 in the api_requestor.py file of autoGPT. The 7B models were a bit faster, but weren't able to respond in the way that allows autoGPT to actually work. I'm thinking of trying to get it to work with my videocard, since it is the most high end part of my pc, but am not quite sure yet where to start. Will let you know if I make it :) ",
      "Sorry for such a long back and forth. Want to make sure this is abstracted just enough that we don't have to redo it and break it all",
      "I haven't tested it AT ALL but there's some context for what I'm referring to by the requested changes in the branch: base-url-and-embeddings. Obv non working but should get the point across",
      "> I'm thinking of trying to get it to work with my videocard, since it is the most high end part of my pc, but am not quite sure yet where to start. Will let you know if I make it :)\r\n\r\nCompile your local api provider with CUBLAS eg for llama-cpp-python \r\n`LLAMA_CUBLAS=1 pip install llama-cpp-python[server]`\r\n",
      "> > I'm thinking of trying to get it to work with my videocard, since it is the most high end part of my pc, but am not quite sure yet where to start. Will let you know if I make it :)\r\n> \r\n> Compile your local api provider with CUBLAS eg for llama-cpp-python `LLAMA_CUBLAS=1 pip install llama-cpp-python[server]`\r\n\r\nI guess he's using keldenl's gpt-llama.cpp\r\n\r\nbut it can be applied also there. it uses ggerganov's llama.cpp\r\n\r\ngit clone https://github.com/ggerganov/llama.cpp.git\r\ncd llama.cpp.git\r\nmake LLAMA_CUBLAS=1\r\n\r\nOf course you need to have CUDA sdk installed for doing that",
      "> > > I'm thinking of trying to get it to work with my videocard, since it is the most high end part of my pc, but am not quite sure yet where to start. Will let you know if I make it :)\r\n> > \r\n> > \r\n> > Compile your local api provider with CUBLAS eg for llama-cpp-python `LLAMA_CUBLAS=1 pip install llama-cpp-python[server]`\r\n> \r\n> I guess he's using keldenl's gpt-llama.cpp\r\n> \r\n> but it can be applied also there. it uses ggerganov's llama.cpp\r\n> \r\n> git clone https://github.com/ggerganov/llama.cpp.git cd llama.cpp.git make LLAMA_CUBLAS=1\r\n> \r\n> Of course you need to have CUDA sdk installed for doing that\r\n\r\nThanks both! I'm indeed using keldenl's gpt-llama.cpp currently, but will try your suggestion! I hope I can just direct the OPENAI_API_BASE_URL to the llama-cpp-python[server].\r\n(PS: today autoGPT actually reached my 6000 second request timeout as well, so need to find a better solution xD)",
      "> Thanks both! I'm indeed using keldenl's gpt-llama.cpp currently, but will try your suggestion! I hope I can just direct the OPENAI_API_BASE_URL to the llama-cpp-python[server]. (PS: today autoGPT actually reached my 6000 second request timeout as well, so need to find a better solution xD)\r\n\r\ndon't get confused, keldenl's project uses the standard llama.cpp binary, wich is written in cpp. llama-cpp-python is a different proect (python bindings for llama.cpp)\r\n\r\nI suggest you to run llama.ccp alone to verify it's compiled correctly and it's actually using the cpu. if it's using cuBLAS, you should see \"blas=1\" after it loaded the model.\r\nIf you are using the same projects you were using the first time, you most likely need to run \"make clean\" before building it with cuBLAS support.",
      "This PR conflicts with #3222 and is not atomic. Please fix that so we can review it.",
      "> This PR conflicts with #3222 and is not atomic. Please fix that so we can review it.\r\n\r\nWhy are you saying that? the hardcoded embedding dimension using in memory-related classes and those settings wich he's adding are different things. there are no conflicts.\r\nWe also modified different files, only .env.template  and config.py are in common",
      "> > This PR conflicts with #3222 and is not atomic. Please fix that so we can review it.\r\n> \r\n> Why are you saying that? the hardcoded embedding dimension using in memory-related classes and those settings wich he's adding are different things. there are no conflicts. We also modified different files, only .env.template and config.py are in common\r\n\r\nSorry, I could have been more clear, see the comment above. Unrelated changes should not be submitted together, since that makes it harder to review and pick PRs that we want to process.",
      "Can I get a test to coverage this \r\n",
      "> Sorry, I could have been more clear, see the comment above. Unrelated changes should not be submitted together, since that makes it harder to review and pick PRs that we want to process.\r\n\r\nThose change are all about new configurations wich aim to make possible the use of different LLMs, as long as they use an API compliant to OpenAI's, so it made sense to me to put them together.\r\n\r\nBut if you prefer, i can keep this PR only for EMBED_DIM and put OPENAI_API_BASE_URL in another one.\r\n\r\nBut without the ability to modify openai.api_base (that's what OPENAI_API_BASE_URL does), we cannot test if different EMBED_DIM values work (on OpenAI's model that value is always 1536)",
      "> Can I get a test to coverage this\r\n\r\nIf you are referring to the automatic tests wich are making codeconv/patch to fail, most of the uncovered lines are from pinecone and redis integrations, wich don't have tests at all. they never had one even before my changes.\r\n\r\nThe milvus test resulted uncovered  because i forced the type for the cfg argument in init_collection. made a commit wich should fix that (at least, i hope).\r\n\r\nthere's also an uncovered line in config.py because (of course) we never set openai.api_base unless we have OPENAI_API_BASE_URL set. Should i add a definition in test_config.py just fot that?",
      "My last attempt on fixing the milvus_memory_test.py test didn't really had the desired result and CodeCov still marks it as uncovered (the test itself still runs fine). But i'm sure it actually is covered, that code is in the __init__ method and the class is initilized in both milvus_memory_tests.py files.\r\nI guess it's because of that MockConfig object in tests/milvus_memory_test.py\r\nIsn't it better to just initialize a new Config() class like the test under the integration folder already does?\r\n\r\n\r\n",
      "This is a mass message from the AutoGPT core team.\nOur apologies for the ongoing delay in processing PRs.\nThis is because we are re-architecting the AutoGPT core!\n\nFor more details (and for infor on joining our Discord), please refer to:\n  https://github.com/Significant-Gravitas/Auto-GPT/wiki/Architecting\n",
      "> This is a mass message from the AutoGPT core team. Our apologies for the ongoing delay in processing PRs. This is because we are re-architecting the AutoGPT core!\r\n> \r\n> For more details (and for infor on joining our Discord), please refer to: [Significant-Gravitas/Auto-GPT/wiki/Architecting](https://github.com/Significant-Gravitas/Auto-GPT/wiki/Architecting)\r\n\r\nPlease merge this PR to master before re-integration. CC @Significant-Gravitas, @Torantulino, @p-i-, @Pwuts \r\n  \r\nLots of work has gone into it, it's working great in a fork, and it is a very significant upgrade to the base Auto-GPT; providing functionality which is important to the \"core\" of Auto-GPT going forward.",
      "I don't think you quite understand why they aren't merging. The reason for it is the re-arch is going to invalidate all current PRs, because it is going to introduce massive breaking changes to how AutoGPT works. Also not a good idea to beg for merge IMO.",
      "> I don't think you quite understand why they aren't merging. The reason for it is the re-arch is going to invalidate all current PRs, because it is going to introduce massive breaking changes to how AutoGPT works. Also not a good idea to beg for merge IMO.\r\n\r\nWell, in the wiki it's also written that it can be a good idea to merge before the re-integration\r\nhttps://github.com/Significant-Gravitas/Auto-GPT/wiki/Architecting#2-push-for-your-pr-to-be-merged-into-master-before-re-integration\r\n\r\nBut i understand that there are many changes wich are way more complex and critical than mine, and i'm perfectly ok to wait and eventually rewrite something if the mantainers require that.\r\n\r\nAlso... @ntindle asked for a test to coverage the new code.\r\nI don't really know what can be a good way to make an unit test for this, since this is meant to connect to any external openai-compliant API.\r\nIt still uses all the core functions used for interacting with GPT3.5 and GPT4, is it really needed/useful?",
      "> Also not a good idea to beg for merge IMO.\r\n\r\nI understand it's strange. But the linked Wiki article basically says to do exactly that. \"[2. push for your PR to be merged into master before re-integration.](https://github.com/Significant-Gravitas/Auto-GPT/wiki/Architecting#2-push-for-your-pr-to-be-merged-into-master-before-re-integration)\"\r\n\r\nIt's not my PR, but it does satisfy the Issues I've been advocating for since the early days of Auto-GPT. So I'm advocating for it to be merged before re-integration, per the linked wiki instructions."
    ],
    "num_comments": 21,
    "repository": "Significant-Gravitas/AutoGPT",
    "diff_length": 1267
  },
  {
    "index": 9,
    "pr_title": "New rule: fix missing `git clone` when given a URL",
    "pr_body": "Often when I'm trying to `git clone` a project, I'll paste the URL into my terminal expecting it to also contain the `git clone` part. This rule should allow `thefuck` to detect the missing `git clone` and suggest it when someone pastes an SSH or HTTP/HTTP url that ends in `.git`.\r\n\r\nA rule for correcting for double `git clone git clone [repo]` already exists. This rule addresses the opposite problem.\r\n\r\n![image](https://user-images.githubusercontent.com/31365175/169957706-14e2c30d-5f84-4fb1-b59",
    "pr_number": 1302,
    "comments": [
      "@djh82 would appreciate a re-review. I think I've fixed up all the issues",
      "@scorphus thanks for your feedback! I believe that this rule would be worthwhile as I encountered it enough times to choose to spend my time on creating a rule for it. I tutor a computer science class where we teach git and have observed that I'm far from the only person to make this mistake. Since there's a rule for handling `git clone git clone`, which is useful when I type `git clone` then paste the URL, only for it to include its own `git clone` (Bitbucket does this), I'd say that this particular rule is reasonable enough, since it handles the opposite case.\r\n\r\nRE: your feedback on output matching, it does seem to be a little pointless. If you're interested in merging this PR at some point then I'll absolutely get rid of it.\r\n\r\nPerhaps it could search for `'git'` within the URL as an additional measure to avoid false positives? This would still work for all most of the popular git servers I'm aware of, at least using SSH. Would that change make the addition be worthwhile? Can you think of any other methods I could use to reduce the number of false positives?",
      "Thanks for sharing your testimonial. Let's get this merged.\r\n\r\nRegarding matching the output, I thought about disregarding output altogether and caring only about `output.script` or `output.script_parts`.\r\n\r\nAsserting `git` in the URL would blacklist bitbucket repos.",
      "Thanks again for the feedback! I fixed up things as per your suggestion, and also removed the code that checked the output.\r\n\r\nDouble checking, since I'm not entirely sure, should it check the URL for the presence of `git` somewhere? The only case I can think of that wouldn't work would be cloning using HTTPS on Bitbucket where `.git` has been manually removed from the end of their copied URL. Their SSH username is `git`, and their copy clone button copies the `git clone` part anyway. It would be helpful for preventing false positives such as [YouTube videos](https://www.youtube.com/watch?v=dQw4w9WgXcQ) (I apologise in advance).\r\n\r\n",
      "Pretty sure I've got everything fixed up now! Let me know if there's anything else you'd like me to do!",
      "Just bumping this one again @scorphus \r\nIs there anything else you want me to do on it?",
      "@MiguelGuthridge, please let me know your thoughts about the last change I submitted.",
      "@MiguelGuthridge, thanks for the complete patch! Much appreciated! üôå "
    ],
    "num_comments": 8,
    "repository": "nvbn/thefuck",
    "diff_length": 4096
  },
  {
    "index": 10,
    "pr_title": "Run flake8 in Travis, fix some errors",
    "pr_body": "",
    "pr_number": 563,
    "comments": [
      "[![Coverage Status](https://coveralls.io/builds/8199300/badge)](https://coveralls.io/builds/8199300)\n\nCoverage decreased (-2.8%) to 90.289% when pulling **01c0e800cd2a236d2e00454937409278a8f26d82 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8199300/badge)](https://coveralls.io/builds/8199300)\n\nCoverage decreased (-2.8%) to 90.289% when pulling **01c0e800cd2a236d2e00454937409278a8f26d82 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8199300/badge)](https://coveralls.io/builds/8199300)\n\nCoverage decreased (-2.8%) to 90.289% when pulling **01c0e800cd2a236d2e00454937409278a8f26d82 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8199743/badge)](https://coveralls.io/builds/8199743)\n\nCoverage increased (+0.08%) to 93.2% when pulling **b97830f6f743f7d03839a8e771e2018726692961 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8199743/badge)](https://coveralls.io/builds/8199743)\n\nCoverage increased (+0.08%) to 93.2% when pulling **b97830f6f743f7d03839a8e771e2018726692961 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8199743/badge)](https://coveralls.io/builds/8199743)\n\nCoverage increased (+0.08%) to 93.2% when pulling **b97830f6f743f7d03839a8e771e2018726692961 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8199743/badge)](https://coveralls.io/builds/8199743)\n\nCoverage increased (+0.08%) to 93.2% when pulling **b97830f6f743f7d03839a8e771e2018726692961 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8199743/badge)](https://coveralls.io/builds/8199743)\n\nCoverage increased (+0.08%) to 93.2% when pulling **b97830f6f743f7d03839a8e771e2018726692961 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "Cheers @scorphus! It was your comments on #561 that inspired me to do this. I figured it might save some effort going forward.\n",
      "Thanks again for the comments, @scorphus! I made some more changes addressing them :)\n",
      "[![Coverage Status](https://coveralls.io/builds/8215085/badge)](https://coveralls.io/builds/8215085)\n\nCoverage increased (+0.08%) to 93.2% when pulling **31e127da1d47f290c81eac6aa82cddd0b8190ba4 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "Awesome, @josephfrazier!\n\nWell, I feel I can push this even further üòÉ  As you're in the process of fixing these issues and changes haven't yet made into master, what would you say if I suggested you to remove a couple of commits and squash those which are logically similar/related?\n\nCommit 85a3e34 is a revert of 4d9f177, both could be removed. Also, all EXYZ-related commits could be joined together, leaving one single commit per violation ‚Äì¬†E123, E225, E231, E265, E302, E402, E711 and E731.\n\nWhat do you think about getting a cleaner history?\n",
      "Good call @scorphus, I did a lot more error-fixing and cleaned up the history :D \n",
      "[![Coverage Status](https://coveralls.io/builds/8221807/badge)](https://coveralls.io/builds/8221807)\n\nCoverage increased (+0.08%) to 93.2% when pulling **df8e5ecb40e3e2efa4d2004ad7d54ac6e54652ad on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8221807/badge)](https://coveralls.io/builds/8221807)\n\nCoverage increased (+0.08%) to 93.2% when pulling **df8e5ecb40e3e2efa4d2004ad7d54ac6e54652ad on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8243763/badge)](https://coveralls.io/builds/8243763)\n\nCoverage increased (+0.08%) to 93.232% when pulling **dda9d55989cd6c499624388ba55f900d0f42d892 on josephfrazier:flake8** into **4d714994a38d8b2f4342ab4f5e331b9db254076b on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8243763/badge)](https://coveralls.io/builds/8243763)\n\nCoverage decreased (-2.8%) to 90.335% when pulling **dda9d55989cd6c499624388ba55f900d0f42d892 on josephfrazier:flake8** into **4d714994a38d8b2f4342ab4f5e331b9db254076b on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/8243763/badge)](https://coveralls.io/builds/8243763)\n\nCoverage decreased (-2.8%) to 90.335% when pulling **dda9d55989cd6c499624388ba55f900d0f42d892 on josephfrazier:flake8** into **4d714994a38d8b2f4342ab4f5e331b9db254076b on nvbn:master**.\n",
      "@nvbn, do you have any thoughts on this? Is there anything else that needs to be done to land it (other than fixing files that have been changed on the `master` branch)?",
      "@josephfrazier, ooops, sorry, I just forgot about this pr.\r\n\r\nI'll check it in the nearest time and will merge it.\r\n\r\nThansk.",
      "Great, thanks! I just pushed some changes that fix the files that had been updated on the master branch, but haven't rebased them yet. If everything looks good to you, let me know and I can `git rebase -i --autosquash master` to combine the `fixup!` commits with their referents and get rid of that `Merge branch 'master' into flake8` commit.",
      "Cheers, hopefully this will make it easier to ensure future contributions adhere to the code style."
    ],
    "num_comments": 22,
    "repository": "nvbn/thefuck",
    "diff_length": 44347
  },
  {
    "index": 11,
    "pr_title": "Adding devcontainer for easy Python development",
    "pr_body": "Love the tool, wanted to contribute and here is the result :)\r\n\r\n- Added a [VSCode devcontainer](https://code.visualstudio.com/docs/remote/containers) to help people get up and running with the repo quicker without needing to install any tooling or do any setup of venv\r\n- Added a new rule to help when some repositories use `main` and some use `master` as the primary integration branch\r\n\r\nFeedback welcome and thanks for the great tooling",
    "pr_number": 1184,
    "comments": [
      "Also, the fix for Python 2.7 tests is already on current `master`, would you please rebase on top of that? üôÇ ",
      "Howdy @storey247! Thanks for contributing. I'd really love to read your comments on my suggestions/questions above. I understand that you're probably busy with many stuff. But I thought I'd ping you üôÇ ",
      "hi @scorphus thanks for all the feedback, yes I will action and get this PR split into two :smile: apologies for the delayed response, work is a bit crazy atm",
      "Awesome! I already split the commit into three, so no need to create another PR, I can merge the changes regarding the new rule and we leave this PR for the devcontainer addition. What do you think?",
      "Amazing! Nice work! üëèüëèüëè\r\n\r\nsounds like a plan, I‚Äôll rebase this on Monday when the work is merged and I‚Äôll tidy up the container so it‚Äôs nice and trim. \r\n\r\nThanks @scorphus ",
      "There you go, @storey247. Sorry for the extra noise. To continue your work, I'd suggest you force-resetting to the `main_master` branch on your remote, that way you'll have exactly what this PR currently has. Please don't hesitate to ask me for help with that.",
      "@scorphus I have now rebased my work from latest `master` and cleaned up the comments as discussed.\r\n\r\nI also added some notes into the `Contribute.md` to help people get up and running with the devcontainer setup if required.\r\n\r\nHopefully now this work can be merged in too. Let me know if there is anything else you need me to look at",
      "> Thats super, @storey247! Thanks so much for hanging in! Please consider my suggestion below.\r\n\r\nFeedback actioned, just waiting on the builds and then should be good to merge üëç "
    ],
    "num_comments": 8,
    "repository": "nvbn/thefuck",
    "diff_length": 4374
  },
  {
    "index": 12,
    "pr_title": "#1282 git misspelled",
    "pr_body": "The function git_support can not be useful if a command has the word \"git\" misspelled.\r\nThe purpose of this rule is to unfuck the commands like: gti commit -m 'message'.\r\nWithout this rule, for example, if you try to unfuck this command the result will be:\r\ngit commit -m message. This means that the quotation marks do not return. #1282\r\n\r\nThis rule is generally useful for every git command, in which the word git is misspelled.\r\n\r\nI have also run some tests!",
    "pr_number": 1292,
    "comments": [
      "I made test_not_match fucntion. I hope that now it is better!",
      "It feels like rather than solving this specifically for the git command, it might be prudent to try and solve the issue in the no_command rule?\r\n\r\nThe underlying issue is that https://github.com/nvbn/thefuck/blob/master/thefuck/shells/generic.py#L87 shlex removes the quotes when operating in posix mode (the default).\r\n\r\nWhat really needs to happen, is we need to use quote for each element of the new command, before calling join, i.e. we need to re-quote the split command.  So something like this:\r\n\r\n```python\r\n    return [' '.join(shell.quote(a) for a in [new_command] + command.script_parts[1:])\r\n            for new_command in new_cmds]\r\n```\r\n\r\nWhere quote is obtained from the current shell (`from thefuck.shells import shell`).  (Also, make my code less ugly, double list comprehension is unsightly!)",
      "Thank you a lot for the review! Is this commit satisfying for the project?",
      "You'll probably want to revert the readme change and add some further tests for no_command? ",
      "Sorry for the too many commits. Is it now okay?\r\nThank you a lot!",
      "@djh82 \r\nIs there any problem with the Ubuntu version 3.9 and what the reason why is not running properly?\r\nIs this PR okay for merging?",
      "Regarding the failure, please check #1310.",
      "@djh82 @scorphus\r\nAre there any other mistakes or missing cases?",
      "I believe that now it is correct!",
      "@NikosKakonas, could you please rebase this on top of current `master`? Thanks!",
      "@scorphus  Is it now okay? Thanks!",
      "@scorphus Is it okay for merging?",
      "@nkakonas does this justify a new release? This has been bugging me for a while.",
      "@scorphus could you cut a new release for this?"
    ],
    "num_comments": 14,
    "repository": "nvbn/thefuck",
    "diff_length": 1668
  },
  {
    "index": 13,
    "pr_title": "Globalize pyenv rule ",
    "pr_body": "Getting pyenv_no_such_command.py rule as base, I created an env_no_such_command.py script able to hanlde all env related commands. Transforming, in this way, the pyenv rule in a more global one. \r\n\r\nThis commit was originated and fixes #1074 ",
    "pr_number": 1100,
    "comments": [
      "@scorphus Is everything good with my pr, would you like me to enhance anything? :smile: ",
      "Yes I totally agree with all your points. My only thoughts lie on the matter of the global rule. Due to the almost identical commands of the env packages, my solution seemed really convenient. Though, if you think is better to make separate files for each command, I will work on it for sure. Probably the testing process will be more efficient in this way as well. ",
      "The identical parts of the rules could be kept in a single, separate ‚Äú`devenv`‚Äù submodule imported by all of the rules. Such submodule would reside under `thefuck/specific` along with other specific ones. This way there‚Äôs less repetition. What do you think?",
      "Yes, that' s a great idea! I will work on it, as well as the requested changes and come up with a new pr.",
      "Need to check why the tests fail, otherwise I think I managed to fullfill the requested changes and they seem really great!",
      "@scorphus Hello again, everything seems to work pretty great! Unfortunately, your idea of integrating some of the common code of the rules to specific/devenv.py was making the tests to fail, so I decided to simplify it. Hope I find some extra time and manage to integrade more of the common code of the rules in a couple of weeks.\r\n\r\nThank you for your help!",
      "You're on fire! üî• I hope I soon have time to review it more thoroughly. Thanks!",
      "Hello @scorphus I didn't have any time to enhance this commit, as I can understand you haven't found any time to review it in order to merge it as well. Let me know about your status :sunglasses: ",
      "Hey @scorphus,\r\n\r\nIt's okay don't worry! Let me know if you need any help, I will be glad to help üòÉ ",
      "I'd love if you could spare a review üôå",
      "Sorry guys I was pretty busy and saw the updates just now, cheers @divykj for the review! Glad to help @scorphus üôå"
    ],
    "num_comments": 11,
    "repository": "nvbn/thefuck",
    "diff_length": 4841
  },
  {
    "index": 14,
    "pr_title": "config.fish: improve documentation on creating Fish functions",
    "pr_body": "How about this as solution to #128? Please review and comment. Thanks!\n",
    "pr_number": 130,
    "comments": [
      "This solution works great, thanks.\n",
      "Glad it works for you! It depends on `sed`, though. But I believe it's certain to be available.\n",
      "Can it also include [solution for stdin](https://github.com/nvbn/thefuck/issues/76#issuecomment-96103809)?\n",
      "@nvbn do you mean adopting the workaround as mentioned in https://github.com/nvbn/thefuck/issues/76#issuecomment-96103809?\n",
      "@nvbn nice, 52f4852 does just that. Let's wait and see if anyone confirms it solves #76.\n",
      "@scorphus, it solves both bugs for me. \n",
      "@scorphus One thing on the `$TMPDIR` thing, a lot of Linux distributions don't appear to have it set by default. OS X does but not every Linux distro does so there should be a fallback there to `/tmp` if it's not set.\n",
      "Yeah, absolutely. First I read http://en.wikipedia.org/wiki/TMPDIR and changed it. But then I thought it over and decided to `vagrant up` Ubuntu 14.04, CentOS 6.4 and Debian 7 to test it and, no surprise. Now I'm testing with `mktemp` and it's working just fine in all cases.\n",
      "Ouch, no... too bad. `mktemp`'s implementations differ amongst Linux and OS X\n",
      "So, how about this:\n\n``` fish\nfunction __thefuck_repl --description 'Replace operators into fish-compatible'\n    set -l tmp (echo $argv | sed 's/ && / ; and /g')\n    echo $tmp | sed 's/ || / ; or /g'\nend\n\nfunction fuck --description 'Correct your previous console command'\n    set -l eval_script (mktemp 2>/dev/null ; or mktemp -t 'thefuck')\n    thefuck $history[1] > $eval_script\n    eval (__thefuck_repl (cat $eval_script))\n    rm $eval_script\nend\n```\n",
      "Can I merge it? Or it's not a final solution?\n",
      "I moved aliases to [wiki](https://github.com/nvbn/thefuck/wiki/Shell-aliases), it will be faster to change them there.\n",
      "I think it's good to go. Ping, @daenney, what do you think?\nEm 27/04/2015 02:58, \"Vladimir Iakovlev\" notifications@github.com\nescreveu:\n\n> I moved aliases to wiki\n> https://github.com/nvbn/thefuck/wiki/Shell-aliases, it will be faster\n> to change them there.\n> \n> ‚Äî\n> Reply to this email directly or view it on GitHub\n> https://github.com/nvbn/thefuck/pull/130#issuecomment-96514751.\n",
      "Ya, I think this should work. Needs a rebase though since Github thinks it has a merge conflict.\n",
      "Thanks for the input, @daenney!\n\nThe part of the README.md file regarding shell aliases and/or functions was move over to the wiki, that's why this is conflicting with master. I'll move the solution to the wiki too.\n",
      "One thing to remind ourselves of, though, is that from now on, every single rule that involves logical operators (`&&` and `||` for instance) should enclose them in blank spaces, like the following: `cmd_x && cmd_y` or `cmd_x || cmd_z`.\n"
    ],
    "num_comments": 16,
    "repository": "nvbn/thefuck",
    "diff_length": 658
  },
  {
    "index": 15,
    "pr_title": "Rule for branch dash 0",
    "pr_body": "fixes fat-fingering `git branch -0` instead of `git branch -v`",
    "pr_number": 942,
    "comments": [
      "Nice idea, maybe it will be a good thing to make that more generic? To just replace any argument that starts with `0` if it appears in `stderr`.",
      "@nvbn When I quickly read your comment on my phone, I thought making this fix more generic sounded like a good idea, but upon reflection, I'm not so sure.\r\n\r\nIn the specific case I coded up, the argument needs to turn into a flag. Would making that assumption more generic (i.e. convert all arguments starting with `0` to `-`) make sense?\r\n\r\nFor that matter, what would the \"undo\" action look like, or would there even need to be an \"undo\" action? (In the specific example here, I need to delete a branch that was just accidentally created...what should the proper response be if `git branch 0v` wasn't the command?",
      "@ProfessorTom you're right, initially I thought that `git branch 0v` prints something, but it just creates a branch.\r\n\r\nI guess the only way to generalize this rule is to also support cases like `git branch 0l`, `git branch 0a` and etc, so just check that the argument after `branch` starts with `0`.",
      "Do you still want me to generalize this feature turning the `0` into a `-` and deleting the branch just created in all cases?\r\n\r\nIs there a case where this would cause more harm than good?",
      "bumping to get a review and hopefully a merge.",
      "@scorphus @nvbn Can I get a review on my latest changes?",
      "What will it take to get this new approach reviewed and merged? cc @nvbn @scorphus @jamtur01 ",
      "Thank you for contributing, @ProfessorTom üëç \r\n\r\nPlease check a new PR, which is probably going to be #1212."
    ],
    "num_comments": 8,
    "repository": "nvbn/thefuck",
    "diff_length": 2935
  },
  {
    "index": 16,
    "pr_title": "Fix Issue #959: breaks after composer require with single package, revamp composer rules",
    "pr_body": "Hello! I'm a day late for Hacktoberfest but I hope you find this PR useful.\r\n\r\nThis pull request aims to fix #959 and add better integration with the [composer](https://getcomposer.org) tool. It turns out the issue of the crash was not because \"there was only one suggestion\" as suggested in the Issue, but rather that the matcher erroneously matches __package not found__ errors instead of just __command not found__ errors. Since the output of the two varies significantly, I have created two separ",
    "pr_number": 1007,
    "comments": [
      "If only GitHub would show the comments in line-number order, other than chronological. Sorry if the review is confusing, please let me know if something is not clear.",
      "wow, thanks for the comprehensive code review! i'm currently occupied with midterm examinations at the moment so it'll take some time for me to follow up on your comments, i'll push my changes at the end of this week.",
      "Sorry for the delay. I've added in your requested changes, and also adopted Black as my code formatter.\r\n\r\nExcept for one problem: Black triggers `E203 whitespace before :` in line 31 of `composer_not_package.py`:\r\n\r\n\r\n```\r\nversion_constraint = offending_script_param[len(wrong_package_name) :]\r\n```\r\n\r\nAccording to [Black themselves](https://github.com/psf/black#slices), E203 should be ignored by flake. Perhaps we should check in a flake8 configuration file that follows their recommendation?",
      "Hey, thanks for keeping up! üëç \r\n\r\nI'm happy that you adopted Black. But maybe we're going too far with it. Like changing lines that are not part of the fix ‚Äì¬†which I've just noticed. Things such as formatting that should be part of a different PR ‚Äì¬†I know it was in the middle of one or two of my suggestions, I didn't notice it back then, sorry for that.\r\n\r\nAlso, I've just noticed that this PR fixes a rule and introduces another. These should be at least two separate commits.\r\n\r\nDo you think you can split the changes in separate commits, undo the lines that are not part of the fix/feature and update this PR? Otherwise, I could do that, if you don't mind. Authorship would be maintained, of course.",
      "This is my first code/feature related PR on a public repository so admittedly I'm not very familiar with best practices ‚Äì are you saying I should add more commits that reverses (removes) the `composer_not_package` rule, then open another PR (perhaps I refork `nvbn:master` and rebase), and then re-add `composer_not_package` and open a separate PR?\r\n\r\nI'm not very sure how to go about reversing selective lines of commits too; I don't use any Git GUI applications that can offer such a functionality.",
      "Sorry for the late reply, @chesnutcase.\r\n\r\nSplitting into two different PRs would be ideal, but as we've come this far, splitting changes into two different commits is more than enough.\r\n\r\nRegarding the changes introduced by the use of Black... On one hand, Black is great because it leaves no space for discussions about how to format code ‚Äì it does it for you. Out of a sudden, you stop wasting time with everything related to code formatting. On the other hand, when it comes to a codebase that's not previously formatted by it, that may generate undesirable noise, such as some parts of this pull request. So it's up to the developer to include only the relevant changes.\r\n\r\nPlease LMK if I can make myself any clearer. (I often fail at that)\r\n\r\nThanks again for contributing and for sticking to it!"
    ],
    "num_comments": 6,
    "repository": "nvbn/thefuck",
    "diff_length": 17954
  },
  {
    "index": 17,
    "pr_title": "feat: new rule for `nix-shell`",
    "pr_body": "Implementation is similar to the one explained in https://github.com/nvbn/thefuck/issues/912#issue-441679613.\r\n\r\nIn a nutshell, it tries to wrap the user's failed command in a nix-shell call.\r\n\r\n```\r\n$ ponysay moo\r\nThe program 'ponysay' is not in your PATH. You can make it available in an\r\nephemeral shell by typing:\r\n  nix-shell -p ponysay\r\n\r\n$ fuck\r\nnix-shell -p ponysay --run \"ponysay moo\" [enter/‚Üë/‚Üì/ctrl+c]\r\n```\r\n\r\nFurther info on nix-shell: https://thiagowfx.github.io/2022/02/nix-shell-in-a-n",
    "pr_number": 1393,
    "comments": [
      "Been loving this. Hope it gets reviewed and upstreamed for all. Thanks for making this!",
      "I've just discovered `thefuck` and I can't imagine how I didn't stumble into it earlier.\r\n\r\nThis PR would fit like a glove for me that just switched to nixos and haven't yet grown the muscle memory of typing the `nix-shell` whenever my command fails.",
      "i would love to see this merged as well",
      "looks like you [can use this already](https://github.com/NixOS/nixpkgs/compare/master...KiaraGrouwstra:nixpkgs:thefuck-nix-shell) using e.g. an overlay, altho i had a bit of trouble getting it to work out of the box.\r\nspecifically, without adding `doCheck = false;`, i would run into this error:\r\n\r\n```\r\nerror: builder for '/nix/store/rl44gb6qd4x2myclj9i8cpkfrvw6ysqa-thefuck-3.32.drv' failed with exit code 2;\r\n       last 10 log lines:\r\n       > thefuck/system/unix.py:6\r\n       >   /build/source/thefuck/system/unix.py:6: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\r\n       >     from distutils.spawn import find_executable\r\n       >\r\n       > -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n       > =========================== short test summary info ============================\r\n       > ERROR  - ModuleNotFoundError: No module named 'pytest_docker_pexpect'\r\n       > !!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\r\n       > ========================= 1 warning, 1 error in 0.09s ==========================\r\n       > /nix/store/bknngadwym46j65qs14ic2w79rpav888-stdenv-linux/setup: line 1582: pop_var_context: head of shell_variables not a function context\r\n```\r\n\r\ni had tried removing the added test, altho that appeared not to resolve the issue.\r\n",
      "it would seem cool to similarly get an approach using `nix run`, i.e. go from suggesting `nix-shell -p ponysay --run \"ponysay moo\"` to `nix run nixpkgs#ponysay -- moo` - this might eventually help extend beyond just `nixpkgs`.\r\n\r\nedit: https://github.com/KiaraGrouwstra/thefuck/commit/81d6786c80b86f2cc80b3ea90adc214df8266643\r\n",
      "I've been using a custom rule that supports the new [unified CLI](https://zero-to-nix.com/concepts/nix#unified-cli) for a while, and was planning on opening a PR once this one has been merged (I hesitate to update this current PR as it's already tested and ready to be merged). I don't know if that will happen soon, so in the meantime I've pushed the changes to [this](https://github.com/thenbe/thefuck/tree/nix-shell-new) new branch instead, which [builds](https://github.com/thenbe/thefuck/compare/nix-shell...thenbe:thefuck:nix-shell-new) on this here PR. You can use the updated rule by adding it as a [custom rule](https://github.com/nvbn/thefuck?tab=readme-ov-file#creating-your-own-rules) to your config.\r\n\r\nIn the new rule, three variants are suggested. Assuming I run `cowsay hello world`, I am presented with the following:\r\n\r\n1. `nix run nixpkgs#cowsay -- hello world`: This runs my command in a non-interactive shell. Uses the nix unified CLI.\r\n1. `nix shell nixpkgs#cowsay`: This enters an interactive shell with `cowsay` available, but does not run any command. This is useful if you'd rather run the command yourself after entering the shell because your command requires delicate massaging (e.g. running it with `sudo`, prefixing it with environment variable, juggling quote variants, etc).\r\n1. `nix-shell -p cowsay --run \"cowsay hello world\"`. This runs my command in a non-interactive shell. Uses the nix original CLI.\r\n1. `nix shell nixpkgs#cowsay --command cowsay hello world`: Very similar to the first one so I've personally disabled this one.\r\n\r\n### Thoughts on future updates:\r\n\r\n\r\n\r\n- It'd be nice if there was a variant that runs my command and then _keeps me_ in the shell.\r\n  - For the original CLI, we [can](https://nix.dev/manual/nix/2.19/command-ref/nix-shell#options) add a `--command \"echo hello; return\"` to our `nix-shell` invocation.\r\n  - For the unified CLI: not sure yet, we might need to do something like this example from the [docs](https://nix.dev/manual/nix/2.19/command-ref/new-cli/nix3-shell): ` nix shell nixpkgs#gnumake --command sh -c \"cd src && make\"`\r\n- We should expose a couple of flags for users to configure this.\r\n  - `disable_unified_cli` (boolean)\r\n  - `disable_original_cli` (boolean)\r\n- As far as I can tell, the `command-not-found` db doesn't really play nice if you use flakes to configure your system and might return stale results (unless you update it manually?). [`nix-index`](https://github.com/nix-community/nix-index) seems to be the go-to alternative. It'd be great if we could optionally use that instead (perhaps behind a flag `enable_nix_index` for users who have installed `nix-index` (`programs.nix-index.enable = true;` in home manager).",
      "@thenbe i agree integrating with `nix-index`'s `command-not-found` replacement seems cool, as a flake user.\r\ni kinda wish we could have `command-not-found` (and this `thefuck` integration) [extend to flake inputs beyond nixpkgs](https://github.com/nix-community/nix-index/issues/244) as well, such as to packages from NUR for example. preferably this should be dynamic based on your inputs rather than hardcoded to specific ones like nixpkgs, or NUR for that matter.\r\ni'll admit i haven't really figured out how that might work tho.",
      "just tried these with a command like `program_i_have | program_i_dont_have`, seems that may complicate the suggestions a bit",
      "I'm not sure if `thefuck` can handle piping.\r\n\r\nIf I make a typo `git statis` it will correct me to `git status`. But if I do `echo hello | git statis` it does not correct my typo. `thefuck` seems to work mostly on single commands AFAICT.\r\n",
      "@thenbe hm, i'm not sure.\r\n\r\n```\r\nfortune | cowsay\r\nThe program 'cowsay' is not in your PATH. It is provided by several packages.\r\nYou can make it available in an ephemeral shell by typing one of the following:\r\n  nix-shell -p cowsay\r\n  nix-shell -p neo-cowsay\r\n$ fuck\r\nnix run nixpkgs#fortune | cowsay\r\n```\r\n\r\nfeels like it knows about the whole command given it's reproducing it?\r\n",
      "another common nix thing we might be able to address from `thefuck` would be errors about packages being unfree\r\n\r\nedit: https://github.com/KiaraGrouwstra/thefuck/commit/16d838bf6f63117b161a2f1e6572e06108b007eb\r\n",
      "@thenbe what was the argument to favor `nix run` over `nix shell` again? i guess the latter seems a bit more generic in case of handling non-standard binaries at least",
      "If I'm only looking to execute a program (and don't need to be dropped into a shell) then I prefer `nix run` over `nix shell` as the [documentation](https://nix.dev/manual/nix/2.19/command-ref/new-cli/nix3-run) suggests `nix run` specifically for this use case.\r\n\r\nI also recall `nix run` being more performant (perhaps because we forego the overhead of launching a shell?). This last point is not derived from benchmarks, only anecdotal evidence.\r\n\r\n> i guess the latter seems a bit more generic in case of handling non-standard binaries at least\r\n\r\nI've added this variant (the 4th one in my [previous post](https://github.com/nvbn/thefuck/pull/1393#issuecomment-1961487094)), but disabled it after a while when I realized that I never reach for it. Do you find that you still need it over `nix run` (the 1st variant in my previous post)?",
      "> another common nix thing we might be able to address from `thefuck` would be errors about packages being unfree\r\n> \r\n> edit: [KiaraGrouwstra@16d838b](https://github.com/KiaraGrouwstra/thefuck/commit/16d838bf6f63117b161a2f1e6572e06108b007eb)\r\n\r\nThis would be useful. Does it still complain about the `--impure` flag? Or do you use a workaround for that?",
      "i've been using `thefuck` mostly thru its [`zsh` plugin](https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/thefuck), which just gets you the top suggestion. i found that failed for me for e.g. `poppler_utils`, which bundles multiple binaries.\r\nto be fair tho, i'm not sure that accounts for a large portion of its invocations, so maybe it could make sense to just actually type out `fuck` in those cases.\r\n\r\nwhat was the `--impure` error? i'm not sure i'd run into that.\r\n\r\nby the way, had you managed to also package your branch for nix? considering i seemed to need that `doCheck = false;` to get our branches to build thru nix.\r\n",
      "I just have it aliased to `f` for extra convenience.\r\n\r\nI opted not to package it for nix separately since `fuck` already exposes a method for easily adding custom rules. Instead, I placed the rule in `~/mydotfiles/thefuck/rules/nix-shell.py` then told home-manager to symlink it to the appropriate place in `.config`:\r\n\r\n```nix\r\n# home.nix\r\nhome.file.\".config/thefuck/rules/nix-shell.py\".source = config.lib.file.mkOutOfStoreSymlink \"${config.home.homeDirectory}/mydotfiles/thefuck/rules/nix-shell.py\";\r\n```\r\n\r\nThis way I don't need to rebuild every time I tweak the rule.\r\n\r\n> what was the --impure error?\r\n\r\nThe unified CLI commands (`nix shell`, `nix run`, etc) will not acknowledge environment variables unless the `--impure` flag is used.\r\n\r\n<details>\r\n  <summary> output </summary>\r\n\r\n```\r\n$ NIXPKGS_ALLOW_UNFREE=1 nix shell nixpkgs#github-copilot-cli\r\n\r\nerror:\r\n       ‚Ä¶ in the condition of the assert statement\r\n\r\n         at /nix/store/xwc3zfc544jg6zhr0wi6k8253s7mwlhi-source/lib/customisation.nix:267:17:\r\n\r\n          266|     in commonAttrs // {\r\n          267|       drvPath = assert condition; drv.drvPath;\r\n             |                 ^\r\n          268|       outPath = assert condition; drv.outPath;\r\n\r\n       ‚Ä¶ while evaluating the attribute 'handled'\r\n\r\n         at /nix/store/xwc3zfc544jg6zhr0wi6k8253s7mwlhi-source/pkgs/stdenv/generic/check-meta.nix:490:7:\r\n\r\n          489|       # or, alternatively, just output a warning message.\r\n          490|       handled =\r\n             |       ^\r\n          491|         (\r\n\r\n       (stack trace truncated; use '--show-trace' to show the full trace)\r\n\r\n       error: Package ‚Äògithub-copilot-cli-0.1.36‚Äô in /nix/store/xwc3zfc544jg6zhr0wi6k8253s7mwlhi-source/pkgs/tools/misc/github-copilot-cli/default.nix:21 has\r\n an unfree license (‚Äòunfree‚Äô), refusing to evaluate.\r\n\r\n       a) To temporarily allow unfree packages, you can use an environment variable\r\n          for a single invocation of the nix tools.\r\n\r\n            $ export NIXPKGS_ALLOW_UNFREE=1\r\n\r\n          Note: When using `nix shell`, `nix build`, `nix develop`, etc with a flake,\r\n                then pass `--impure` in order to allow use of environment variables.\r\n\r\n       b) For `nixos-rebuild` you can set\r\n         { nixpkgs.config.allowUnfree = true; }\r\n       in configuration.nix to override this.\r\n\r\n       Alternatively you can configure a predicate to allow specific packages:\r\n         { nixpkgs.config.allowUnfreePredicate = pkg: builtins.elem (lib.getName pkg) [\r\n             \"github-copilot-cli-0.1.36\"\r\n           ];\r\n         }\r\n\r\n       c) For `nix-env`, `nix-build`, `nix-shell` or any other Nix command you can add\r\n         { allowUnfree = true; }\r\n       to ~/.config/nixpkgs/config.nix.\r\n\r\n\r\n```\r\n```bash\r\n# it wants this instead:\r\n$ NIXPKGS_ALLOW_UNFREE=1 nix shell nixpkgs#github-copilot-cli --impure\r\n```\r\n\r\n</details>\r\n",
      "aah i see! i'd yet to take that into account. üôà\r\n\r\nspecifying the rules rather than doing overlays makes sense - thanks!\r\n"
    ],
    "num_comments": 17,
    "repository": "nvbn/thefuck",
    "diff_length": 6305
  },
  {
    "index": 18,
    "pr_title": "start work on -y",
    "pr_body": "Fixes #531 \n\n[WIP]\n\n@scorphus:  I have never programmed in Python before, is this where I add the option, or is it somewhere else?\n\nTODO\n- [ ] add flag\n- [ ] make flag set `settings.require_confirmation: False`\n- [ ] make flag execute the rest of the command\n- [ ] add tests\n",
    "pr_number": 532,
    "comments": [
      "To have it implemented the way we discussed earlier ‚Äì at shell alias/function level ‚Äì it would involve rewriting the shell alias ‚Äì i.e. [`Fish.app_alias()`](https://github.com/nvbn/thefuck/blob/51415a5cb1ca6955fb99908e7d0e7bf012a66312/thefuck/shells/fish.py#L21) ‚Äì¬†in order to make it conditionally set `THEFUCK_REQUIRE_CONFIRMATION` to `0` prior to calling `thefuck ...`.\n",
      "Aha, it's there, I interpreted your comment differently!\n",
      "Great!\n\nps.: I'm pondering how this could be done in the Bash alias, for instance.\n",
      "Okay, so @scorphus, I found how to add a fish argument, but where should this be documented, tested?\n\ncontains in `fish`: https://fishshell.com/docs/current/commands.html#contains-example\n",
      "[![Coverage Status](https://coveralls.io/builds/7153857/badge)](https://coveralls.io/builds/7153857)\n\nCoverage remained the same at 92.304% when pulling **ff5372e288c370efd17d8f968daa847e933f23fe on Haroenv:feat/option-y-override-verification** into **51415a5cb1ca6955fb99908e7d0e7bf012a66312 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/7153857/badge)](https://coveralls.io/builds/7153857)\n\nCoverage remained the same at 92.304% when pulling **ff5372e288c370efd17d8f968daa847e933f23fe on Haroenv:feat/option-y-override-verification** into **51415a5cb1ca6955fb99908e7d0e7bf012a66312 on nvbn:master**.\n",
      "For powershell, something like [switch](https://social.technet.microsoft.com/Forums/windowsserver/en-US/2961ae65-d7d9-4c1d-bdf2-505273925ccc/advanced-functions-flags?forum=winserverpowershell) could be used (but I don't know how it finds out what the name of the flag is\n",
      "In `bash` (probably the other shells as well, seeing they're aliases instead of functions too) it'll need to be replaced by a [function](http://apple.stackexchange.com/a/51010/98431)\n",
      "> [‚Ä¶] I found how to add a fish argument, but where should this be documented, tested? [‚Ä¶]\n\nThere are some [funcitonal tests ](https://github.com/nvbn/thefuck/tree/51415a5cb1ca6955fb99908e7d0e7bf012a66312/tests/functional) that could include tests for the new `-y` functionality.\n\n> For powershell, something like [switch](https://social.technet.microsoft.com/Forums/windowsserver/en-US/2961ae65-d7d9-4c1d-bdf2-505273925ccc/advanced-functions-flags?forum=winserverpowershell) could be used (but I don't know how it finds out what the name of the flag is\n\nLooks like it'll work. Maybe @MattKotsenas could chime in and shed some light on the matter?\n\n> In `bash` (probably the other shells as well, seeing they're aliases instead of functions too) it'll need to be replaced by a [function](http://apple.stackexchange.com/a/51010/98431)\n\nYeah, that's the critical change, I think. Not sure how much it impacts on the way TheFuck is set up by users and [tools](https://github.com/Bash-it/bash-it/blob/7415134878b8b01015c9a9fdbc66b784db02ff65/aliases/available/fuck.aliases.bash) alike.\n\nPerhaps there should be a `--function` argument that always creates a `function`. Then we can leave `--alias` functionality untouched. What do you think?\n",
      "I just realised that this would unset the confirmation for everything after once `-y`, will need `else` and setting it back to the default. (or setting it to the default at the end of the command maybe?)\n",
      "Here's [another example](https://github.com/robbyrussell/oh-my-zsh/blob/a7e30b26baa94bac99d9d05cf642bd1942ae1787/plugins/thefuck/thefuck.plugin.zsh#L7) of a tool that uses TheFuck.\n\nThinking it again, on most cases there won't be any problems creating a `function` instead of an `alias`. Let me recall how users used to set them.\n",
      "> [‚Ä¶] setting it back to the default [‚Ä¶]\n\nThat might be unnecessary. It should be an _in-command-variable_, something like:\n\n``` fish\n# middle of Fish alias\nif dash_y\n  env THEFUCK_REQUIRE_CONFIRMATION=0 TF_ALIAS=fuck PYTHONIOENCODING=utf-8 thefuck <cmd>\nelse\n  env TF_ALIAS=fuck PYTHONIOENCODING=utf-8 thefuck <cmd>\nend\n# ‚Ä¶\n```\n",
      "Since [aliases changed in 1.34](https://github.com/nvbn/thefuck#update) and are defined with `eval \"$(thefuck --alias)\"` I think we might be okay changing it to a `function`.\n\n/cc @nvbn any concerns?\n",
      "Oh-My-Fish [TheFuck plugin](https://github.com/oh-my-fish/plugin-thefuck/blob/86f7e1b720f8395964f348f601b4b8fd9a1cf671/functions/fuck.fish), for example, will need to be updated to support this feature, although it would continue to work nonetheless.\n",
      "[![Coverage Status](https://coveralls.io/builds/7156314/badge)](https://coveralls.io/builds/7156314)\n\nCoverage decreased (-0.5%) to 91.828% when pulling **a97416272c65f4fa7aa5a8b4e81e7d77756c1de3 on Haroenv:feat/option-y-override-verification** into **51415a5cb1ca6955fb99908e7d0e7bf012a66312 on nvbn:master**.\n",
      "[![Coverage Status](https://coveralls.io/builds/7161601/badge)](https://coveralls.io/builds/7161601)\n\nCoverage remained the same at 92.304% when pulling **c02357c58f3386dc272f19b55efcfedd57e25756 on Haroenv:feat/option-y-override-verification** into **51415a5cb1ca6955fb99908e7d0e7bf012a66312 on nvbn:master**.\n",
      "@Haroenv: the condition can be written like this:\n\n``` fish\ncontains -- \"-y\" $argv; and set -lx THEFUCK_REQUIRE_CONFIRMATION 0\n```\n- `l`: sets the variable locally ‚Äì it is bound to the funciton scope only\n- `x`: exports the variable to sibling processes ‚Äì¬†`thefuck` will be able to read it\n",
      "[![Coverage Status](https://coveralls.io/builds/7167243/badge)](https://coveralls.io/builds/7167243)\n\nCoverage remained the same at 92.304% when pulling **190db9407cb55a3a40c3a892ba7893cc94d10e37 on Haroenv:feat/option-y-override-verification** into **51415a5cb1ca6955fb99908e7d0e7bf012a66312 on nvbn:master**.\n",
      "Maybe it can be a bit simpler, just a different alias like:\n\n``` bash\nalias fuckit='THEFUCK_REQUIRE_CONFIRMATION=0 fuck'\n```\n\n?\n",
      "That seems like a great idea, should need to check if that saves the variable or if it uses it just once though. Using fuckit as a new alias makes sense\n"
    ],
    "num_comments": 20,
    "repository": "nvbn/thefuck",
    "diff_length": 674
  },
  {
    "index": 19,
    "pr_title": "Create `cat_dir` rule for replacing `cat` with `ls`",
    "pr_body": "Examples\r\n\r\n```sh\r\n$ cat /etc\r\ncat: /etc: Is a directory\r\n$ fuck\r\nls /etc  [enter/‚Üë/‚Üì/ctrl+c]\r\n*snip*\r\n$ cat tests\r\ncat: tests: Is a directory\r\n$ fuck\r\nls tests [enter/‚Üë/‚Üì/ctrl+c]\r\n*snip*\r\n```",
    "pr_number": 823,
    "comments": [
      "Hi @scolby33, thanks for contributing to TheFuck.\r\n\r\nIn Python, we should always try to solve the problem with [string methods](https://docs.python.org/3/library/stdtypes.html#string-methods) ‚Äì such as `endswith`, `startswith`, `lstrip`, `rstrip`, etc. ‚Äì before resorting to regular expressions, which are slower most of times.\r\n\r\nSo, I'll add a few line comments in order to suggest some changes to your PR regarding the above.",
      "Thanks for the feedback! I've made the changes you requested and I'll push once tox finishes running. Let me know if you see anything else.\r\n\r\nI've tested the output of `cat` on macOS, Debian, and Arch. If someone out there is running a more esoteric system, it'd be interesting to check if all `cat`'s respond the same way.",
      "> Or maybe we're better off with just `... endswith(': Is a\n> directory\\n')` and those who use a `cat` that doesn't follow ‚Äúdefault‚Äù\n> implementation are ‚Äùin a state of sin and deserve whatever happens to\n> them.‚Äù We can still have ` ... or endswith(': Is a directory')` if we\n> ever need to, after all.\n\nMy sin is on an other kind of state :\n\n\tromain@dulix:~/Musique/White_Cowbell_Oklahoma$ cat ..\n\tcat: ..: est un dossier\n\t\n\nOne more time, I miss a test (-:\n\n> I wonder what your thoughts on this are.\n\n++\n    Romain\n-- \nCeux qui ne savent pas o√π ils vont sont surpris d'arriver ailleurs.\n\t-+- Pierre Dac -+-\n",
      "I‚Äôm not super familiar with internationalization, but a bit of digging brought me to `gettext`. I think the string we‚Äôre seeing, ‚ÄúIs a directory‚Äù, comes from glibc‚Äôs `sysdeps/gnu/errlist.c`, which is translated to ‚Äúest un dossier‚Äù on [the translation project](https://translationproject.org/domain/libc.html). I suppose we could parse out the messages from the files there or perhaps the python `gettext` library is what we want.",
      "I‚Äôm on mobile so can‚Äôt try it right now, and I probably should be asleep, but from a quick look at the docs, it might be as simple as `gettext.translation(domain=‚Äòlibc‚Äô).gettext(‚ÄòIs a directory‚Äô)`",
      "@Rom1deTroyes could you post the output of `locale` and the values of the environment variables `LANGAUGE`, `LC_ALL`, `LC_MESSAGES`, and `LANG` from your system?",
      "I've opened #826 to add localization to this rule.",
      "@Rom1deTroyes are you using experimental instant mode or shell logger? Otherwise thefuck should rerun the command with `LANG=C` and get error message in English.",
      "Le mardi 10 juil. 2018 √† 11:40:38 (-0700), Scott Colby a √©crit :\n> @Rom1deTroyes could you post the output of `locale` and the values of\n> the environment variables `LANGAUGE`, `LC_ALL`, `LC_MESSAGES`, and\n> `LANG` from your system?\n\n$ locale\nLANG=fr_FR.UTF-8\nLANGUAGE=\nLC_CTYPE=\"fr_FR.UTF-8\"\nLC_NUMERIC=\"fr_FR.UTF-8\"\nLC_TIME=\"fr_FR.UTF-8\"\nLC_COLLATE=\"fr_FR.UTF-8\"\nLC_MONETARY=\"fr_FR.UTF-8\"\nLC_MESSAGES=\"fr_FR.UTF-8\"\nLC_PAPER=\"fr_FR.UTF-8\"\nLC_NAME=\"fr_FR.UTF-8\"\nLC_ADDRESS=\"fr_FR.UTF-8\"\nLC_TELEPHONE=\"fr_FR.UTF-8\"\nLC_MEASUREMENT=\"fr_FR.UTF-8\"\nLC_IDENTIFICATION=\"fr_FR.UTF-8\"\nLC_ALL=\n\n\nBTW, there is no C or C.utf8 locales on this system (I don't know why :\nthis is an old eepc used as a personal assistant) :\n\n$ locale -a\nfr_FR.utf8\nPOSIX\n\n++\n    Romain\n-- \nCe qu'on fait n'est jamais compris mais seulement lou√© ou bl√¢m√©.\n\t-+- Friedrich Nietzsche, Le gai savoir -+-\n"
    ],
    "num_comments": 9,
    "repository": "nvbn/thefuck",
    "diff_length": 2232
  },
  {
    "index": 20,
    "pr_title": "Fix corrected command not being saved into fish history",
    "pr_body": "This should fix #1027 ",
    "pr_number": 1028,
    "comments": [
      "Changes look good for me, but it seems like it breaks e2e tests - https://travis-ci.org/nvbn/thefuck/jobs/630646284#L3756",
      "Yes, I need to get round to fixing those. Having trouble running the end to end tests locally atm. ",
      "@scorphus happy for you to suggest further changes; or reject this entirely if it doesn't fit with your future changes.  This is what I'm currently using at work, since the currently implemented method for updating the fish history simply doesn't work, and it's a bit frustrating, so thought I'd share! ",
      "Let me have a look at this again.",
      "So, there are two reasons I think we should avoid changing the shell function. The main one is backward compatibility. A considerable number of users have the function hardcoded either in their `config.fish` or in some `functions/fuck.fish`. I've seen a lot of cases like that. Even some issues have that as a suggestion to improve the loading time of the shell.\r\n\r\nAnother reason is that it does not support a new feature I'm bringing together, which is the ‚Äúedit command.‚Äù For that, I'd like to avoid having the `commandline` instruction added to the history.\r\n\r\nThat said, I think the `commandline` part of this PR should be moved into `shell`. I already have a working CL, which I'll submit shortly afterward as a new commit on top of yours. Then, you can review it.\r\n\r\nSounds good?",
      "Hey, @davidhart82! I went ahead ‚Äì as we usually squash commits by the same author that represent one single, ‚Äúatomic‚Äù change ‚Äì and squashed the two commits you had. So, authorship is preserved.\r\n\r\nI'm looking forward to reading your thoughts on my proposed changes.\r\n\r\nThanks!",
      "Hey @scorphus, changes look good to me!  Much neater given I had no idea folk hardcode the function directly in `config.fish` (I'm clearly spoiled with the power of my workstation ;)).\r\n\r\nI'll give it a test and let you know how I get on...",
      "This only appears to have failed since the coverage has dropped by 0.01%...\r\n\r\nThough, having tested this, although it works, it still stores the call to 'fuck' in the history.  I wonder whether we want to search and delete those too?",
      "Looking good! I'll have time to review it over the weekend. Super!",
      "Sorry to be the thread necromancer. Wondering if there is a reason 3.31 was never released?\r\nThere are a couple things I've been waiting a long while for and this one I've been desperate for since the issue was raised.",
      "Thanks for the reminder, @tonytamps! There're a few more issues/PRs that need to be solved/merged. All of the issues are already WIP. We're getting there!",
      "BTW, I'm not entirely happy with how we managed to solve this issue, I guess I'll try some other approach(es).",
      "Is there anything that can be done to push this forward? The issue is still present. I've read the diff but I am not sure what the exact problem was.",
      "I am not sure since when this issue exists but it also occured to me that fish complaints because the `history merge` command does not take any arguments so I would be very glad if this could be merged soon as it looks like a good fix to me",
      "@septatrix: that issue (#1215) is fixed and released in [3.32](https://github.com/nvbn/thefuck/releases/tag/3.32). This PR addresses another issue."
    ],
    "num_comments": 15,
    "repository": "nvbn/thefuck",
    "diff_length": 2868
  },
  {
    "index": 21,
    "pr_title": "Fix the fuck for Python 3.12",
    "pr_body": "The imp module has been long deprecated and has been removed entirely in Python 3.12.\r\n\r\nThis solution is what was suggested in the release notes: https://docs.python.org/3.12/whatsnew/3.12.html#imp",
    "pr_number": 1415,
    "comments": [
      "> finally someone gave a fuck\r\n\r\nI'd say I even gave \"the fuck\" ü§™ ",
      "oh wow cool thanks was about to check it out but yeah u got the job done :+1: ",
      "Waiting for the pull request to be merged üòé",
      "This ~bit~ fucked me after upgrading to Fedora 39.\r\n\r\nInstalling from fork worked for me\r\n\r\n```sh\r\ncd /tmp\r\ngit clone https://github.com/mbridon/thefuck.git\r\npip uninstall thefuck\r\npip install -e ./thefuck\r\n```",
      "> This ~bit~ fucked me after upgrading to Fedora 39.\r\n\r\nlmao same still hasn't been merged :confused: ",
      "Just FYI due to this bug my terminal is fucked up since the upgrade:\r\n\r\n![image](https://github.com/nvbn/thefuck/assets/35342116/d13f638a-22f0-418a-9d58-9b03b2a4a1dd)\r\n\r\nNo, I am not going to comment the fuck out of my zshrc. ",
      "Adding my +1 to get this merged soon!",
      "I don't have Python 2.7 any more, so I'll be happy if you can help fix this issue so the fix I provided works on both 2.7 and 3.12 :grin: ",
      "As a workaround, while we wait for this PR to be merged, if anyone wants to install this fork the quickest way is:\r\n```\r\npip uninstall thefuck\r\npip install https://github.com/mbridon/thefuck/archive/main.zip\r\n```",
      "I've just learned that there is an imp compatibility package called `python3-zombie-imp` on most distros (e.g. https://packages.fedoraproject.org/pkgs/python-zombie-imp/python3-zombie-imp/) that patches around this.",
      "> I've just learned that there is an imp compatibility package called `python3-zombie-imp` on most distros (e.g. https://packages.fedoraproject.org/pkgs/python-zombie-imp/python3-zombie-imp/) that patches around this.\r\n\r\nSure, that's a potential crutch, but fixing the issue is better üòâ ",
      "Bump.\r\nI also ran into this issue after updating to ubuntu 24.04 (and by extension to python 3.12.3), and fixed it by installing from the fork. Seems like this is super duper ready to merge :)",
      "Well, I guess the original author @nvbn seems to have disappeared, so all it would take is for someone to fork the repo and merge this PR and then assume maintenance of the project.\r\n\r\nI won't do it for health reasons, so if someone who commented on this PR wants to have a go at it then go ahead. ü§∑ \r\n\r\nAnd when @nvbn comes back eventually, assume joint maintenance all together.\r\n\r\nFree Software sometimes loses maintainers and find new ones, that's how it sometimes evolves and continues.",
      "I believe this pull request could be closed.\r\nA fix for this is already in the master branch.",
      "Ah great, so the maintainer fixed the issue but didn't merge the PR which could have given me the credit...\r\n\r\nWell, all that matters is that it's fixed. :shrug: ",
      "> Ah great, so the maintainer fixed the issue but didn't merge the PR which could have given me the credit...\r\n> \r\n> Well, all that matters is that it's fixed. ü§∑\r\n\r\nHello.\r\n\r\nI am running the same issue on Ubuntu 24.04. However, your archive on your repository is no longer there. Is there any work-around to install this, system-wide?\r\n\r\nThank you.",
      "> Ah great, so the maintainer fixed the issue but didn't merge the PR which could have given me the credit...\r\n> \r\n> Well, all that matters is that it's fixed. ü§∑\r\n\r\nSorry to necro, but it appears the fix was made 3 months before your PR was opened Jul 2023 vs Nov 2023: https://github.com/nvbn/thefuck/commit/0420442e778dd7bc53bdbdb50278eea2c207dc74\r\n\r\nThe diff looks pretty similar to your PR diff [`904693a` (#1415)](https://github.com/nvbn/thefuck/pull/1415/commits/904693a496c5371bb8eb2d57698b720770c52f14)",
      "if linux wont let you install thefuck using pip, just clone the repo and install it using setup script"
    ],
    "num_comments": 18,
    "repository": "nvbn/thefuck",
    "diff_length": 1603
  },
  {
    "index": 22,
    "pr_title": "Add excluded_search_path_prefixes setting - improves perf in WSL",
    "pr_body": "Allows filtering the paths used to search for commands\r\nCan be useful to filter out `/mnt/` in WSL for performance\r\n\r\nRunning in WSL with default config:\r\n```\r\nDEBUG: Total took: 0:00:10.213128\r\n```\r\n\r\nRunning in WSL with `excluded_search_path_prefixes = ['/mnt/']` in `settings.py`:\r\n\r\n```\r\nDEBUG: Total took: 0:00:00.617300\r\n```\r\n\r\nThis provides an approach to solving #1036 without having to remove Windows paths from `PATH` (which breaks various WSL use-cases)",
    "pr_number": 1165,
    "comments": [
      "Just checking back to see whether there is anything I can do to help make this easier to review? Thanks!",
      "What would it take to get this pulled in?",
      "Thanks for the review @scorphus! I've included your suggestions and rebased on latest `master`\r\n\r\nHowever, I notice that the automated checks are failing on python 2.7 at what looks to be the install stage. I'm not sure how the changes made would have caused this and have just tested installing on 2.7.17 locally and it seemed to work fine (unit and functional tests pass locally on 2.7.17, too). If you have any pointers for investigating further that would be greatly appreciated!",
      "Glad you're still on it, @stuartleeks. Sorry for the delay.\r\n\r\nI wonder why `pip` is installing decorator 5.x for Python 2.7. It should install 4.4.2 instead. Anyway, I didn't investigate too much into that issue. Instead came up with #1187 that forces `decorator<5` for Python <= 2.7. Once 3.31 is released, this and other makeshifts will be removed.\r\n\r\nI'll get #1187 merged soon. Then you're free to rebase on top of master again. Thanks in advance!",
      "Ok, cool. I'll rebase again once #1187 is merged and hopefully this will be ready to go üòÅ\nThanks!",
      "Rebased now that #1187 is merged and the tests are now passing - thanks @scorphus !",
      "can't wait to update with these changes implemented with 3.31. I can't believe me commenting here kicked off the attention this needed to finally get merged and now I don't have to worry about manually building these changes into every new release haha",
      "Thanks for the update, @stuartleeks! I'll be merging this shortly!\r\n\r\n@mjohnson159 Thanks for commenting and bringing it to my attention. We really need to get 3.31 out, right!? It's been a long time since the last release. Would you be willing to help me confirming fixes for some other Windows-related issues? That would be super helpful!",
      "Thanks for contributing, @stuartleeks! :heart: "
    ],
    "num_comments": 9,
    "repository": "nvbn/thefuck",
    "diff_length": 6018
  },
  {
    "index": 23,
    "pr_title": "üåê Add Ukrainian translation for `docs/uk/docs/index.md`",
    "pr_body": "",
    "pr_number": 5178,
    "comments": [
      "üåê Add Ukrainian translation for docs/uk/docs/index.md",
      "> –î—É–∂–µ –∫—Ä—É—Ç–æ, —Ç—ñ–ª—å–∫–∏ —Ö–æ—Ç—ñ–≤ —Å—ñ—Å—Ç–∏ –∑–∞ –ø–µ—Ä–µ–∫–ª–∞–¥ —è–∫ –±–∞—á—É –≤–∏ –≤–∂–µ –ø–æ—á–∞–ª–∏. –î–æ–¥–∞–≤ –∫—ñ–ª—å–∫–∞ –∞–π—Ç–µ–º—ñ–≤ —Å—Ç–æ—Å–æ–≤–Ω–æ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É. –ù–∞–¥—ñ—é—Å—è –≤–æ–Ω–∏ –±—É–ª–∏ –∫–æ—Ä–∏—Å–Ω–∏–º–∏ —ñ –≤–∏ –ø–æ–≥–æ–¥–∂—É—î—Ç–µ—Å—è. –©–µ —Ä–∞–∑ –¥—è–∫—É—é –∑–∞ –ø—Ä–æ—Ä–æ–±–ª–µ–Ω—É —Ä–æ–±–æ—Ç—É\r\n\r\n–î—è–∫—É—é –∑–∞ –¥–æ–ø–æ–º–æ–≥—É! –ü–æ–≥–æ–¥–∂—É—é—Å—å –∑ –í–∞—à–∏–º–∏ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è–º–∏. –Ø–∫—â–æ –±–∞–∂–∞—î—Ç–µ –ø—Ä–∏—î–¥–Ω–∞—Ç–∏—Å—è –¥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É - —Ü–µ —Å—É–ø–µ—Ä, –º–æ–∂–µ–º–æ —Ä–æ–∑–¥—ñ–ª–∏—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—é –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏ —ñ —Ä–æ–±–∏—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥ —Ä–∞–∑–æ–º.",
      "> > –î—É–∂–µ –∫—Ä—É—Ç–æ, —Ç—ñ–ª—å–∫–∏ —Ö–æ—Ç—ñ–≤ —Å—ñ—Å—Ç–∏ –∑–∞ –ø–µ—Ä–µ–∫–ª–∞–¥ —è–∫ –±–∞—á—É –≤–∏ –≤–∂–µ –ø–æ—á–∞–ª–∏. –î–æ–¥–∞–≤ –∫—ñ–ª—å–∫–∞ –∞–π—Ç–µ–º—ñ–≤ —Å—Ç–æ—Å–æ–≤–Ω–æ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É. –ù–∞–¥—ñ—é—Å—è –≤–æ–Ω–∏ –±—É–ª–∏ –∫–æ—Ä–∏—Å–Ω–∏–º–∏ —ñ –≤–∏ –ø–æ–≥–æ–¥–∂—É—î—Ç–µ—Å—è. –©–µ —Ä–∞–∑ –¥—è–∫—É—é –∑–∞ –ø—Ä–æ—Ä–æ–±–ª–µ–Ω—É —Ä–æ–±–æ—Ç—É\r\n> \r\n> –î—è–∫—É—é –∑–∞ –¥–æ–ø–æ–º–æ–≥—É! –ü–æ–≥–æ–¥–∂—É—é—Å—å –∑ –í–∞—à–∏–º–∏ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è–º–∏. –Ø–∫—â–æ –±–∞–∂–∞—î—Ç–µ –ø—Ä–∏—î–¥–Ω–∞—Ç–∏—Å—è –¥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É - —Ü–µ —Å—É–ø–µ—Ä, –º–æ–∂–µ–º–æ —Ä–æ–∑–¥—ñ–ª–∏—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—é –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏ —ñ —Ä–æ–±–∏—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥ —Ä–∞–∑–æ–º.\r\n\r\n–ó–≤—ñ—Å–Ω–æ —è —Ç—ñ–ª—å–∫–∏ –∑–∞. –î–∞–≤–∞–π—Ç–µ –∑–≤—è–∂–µ–º–æ—Å—è —ñ —Ä–æ–∑–¥—ñ–ª–∏–º–æ –ø–µ—Ä–µ–∫–ª–∞–¥. @python4eg –º—ñ–π –Ω—ñ–∫ –≤ —Ç–µ–ª–µ–≥—Ä–∞–º—ñ",
      "@ilkuzmenko Hey, you made a huge work there, are you able to finish this? I could approve this after fixing the comments that were left by reviewers. Or if you are not able or don't want to work on it anymore can I do my own based on your?\r\nP.S. Hope you are okay now",
      "@rostik1410 let me know if you need any help ",
      "As this PR had requested changes to be applied but has been inactive for a while, it's now going to be closed. But if there's anyone interested, feel free to create a new PR."
    ],
    "num_comments": 6,
    "repository": "fastapi/fastapi",
    "diff_length": 26567
  },
  {
    "index": 24,
    "pr_title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "pr_body": "Kafami karistiran bir iki farkli yaklasimi ceviri icerisinde denedim, ornegin orijinal dokumanlarda `abbr` tag'ini bazi kavramlar icin bir kac defa kullanip sonrasinda kullanmayi birakiyordu, ben de buna benzer bir yaklasim sergilemeye calistim. Bunun disinda haddimden fazla yerellestirme yapmis olabilirim, incelemenizde lutfen acimayin ki ortaya duzgun bir sey ciksin üòÑ ",
    "pr_number": 10502,
    "comments": [
      "üìù Docs preview for commit 121e6d6a9ed2176615b308489cc8953790ab72ff at: https://88cd7bfd.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 88c6d84911a4bc17f7fe3723ff57e9f692ddf492 at: https://8d96dfce.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit ced982a7a3f540bbad91a844e4b55bf9b220294f at: https://8e3e519d.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 03e7b2dfda6779e5c4db649dd11bd52439ae0152 at: https://fd75c3b9.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 49c0ceb5a3704f6c06b4df44385abc0d0fcda15b at: https://2cdb64e8.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 7b9dfc3be6b7180d1ead298b4df5030869b7c8d7 at: https://b36663fa.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit add6aa7b5cf12e2d9ba722eb3e84363c13e07309 at: https://8d3d0eae.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit dca64ba1cd69184188f2898bc0aabeb43122cff1 at: https://04ac286b.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit ada79e684085b8f762522a9def6039de04510030 at: https://0140430d.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 4c871702a100bfe668513ebd1c24762f53c8f910 at: https://01de0dd0.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 4b2019ee4a07accf2746394cb3f5b16fba011b3d at: https://eef7d8e2.fastapitiangolo.pages.dev",
      "Nice! Thanks @alperiox ü§ìüöÄ \r\n\r\nAnd thanks for your help @hasansezertasan ü•≥üíØ "
    ],
    "num_comments": 12,
    "repository": "fastapi/fastapi",
    "diff_length": 28460
  },
  {
    "index": 25,
    "pr_title": "üåê Update Turkish translation for `docs/tr/docs/python-types.md`",
    "pr_body": "Fixes mistranslations and updates outdated doc",
    "pr_number": 10445,
    "comments": [
      "üìù Docs preview for commit 018703a41b7236195f10c1bdefa04b228f387071 at: https://149a3713.fastapitiangolo.pages.dev",
      "Geri d√∂n√º≈üler i√ßin te≈üekk√ºrler.",
      "üìù Docs preview for commit 574596ceaae7cbb1447a4868e518111dab393a15 at: https://6b65633d.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit aba7b4cb9f46728322e1d84f78563990f670ee9a at: https://461f92ef.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 1a6ae53e896e361c456c19dc8395861c130024f4 at: https://3aad993a.fastapitiangolo.pages.dev",
      "As this PR had requested changes to be applied but has been inactive for a while, it's now going to be closed. But if there's anyone interested, feel free to create a new PR."
    ],
    "num_comments": 6,
    "repository": "fastapi/fastapi",
    "diff_length": 23285
  },
  {
    "index": 26,
    "pr_title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "pr_body": "",
    "pr_number": 9675,
    "comments": [
      "üìù Docs preview for commit 1ad46b67e6dc33ffb1178d18a86c922aae69b44a at: https://6489918cc356c5078c7143d3--fastapi.netlify.app",
      "üìù Docs preview for commit cb8277b848f98da3dca93934efbf2e9afcee516a at: https://6489a1b7cb6e8811f92dc3e4--fastapi.netlify.app",
      "üìù Docs preview for commit 40c1afec5cf87a49b12596d35a282d182d679c90 at: https://648c2ed97897085123307603--fastapi.netlify.app",
      "üìù Docs preview for commit e8137f6f049b9b0580269782f05339ef99be56ad at: https://648c39c1546bc455bcbe061a--fastapi.netlify.app",
      "üìù Docs preview for commit 481e4826b1222d63127d1a49cbee546163e6e22e at: https://648c3d3362aae25b60aaa027--fastapi.netlify.app",
      "üìù Docs preview for commit 6aabbb641b1cf022cb863ccb90dbe29dd57edb0c at: https://648c41322c8d36602e0da830--fastapi.netlify.app",
      "üìù Docs preview for commit 7e008fbad029c8948821cdae7cf08889c299d868 at: https://64905a8944734c66b54f1453--fastapi.netlify.app",
      "üìù Docs preview for commit 3159e9fe77a6880746e306c69697e4bc6f6eb63d at: https://64905c2c44734c676c4f14dd--fastapi.netlify.app",
      "üìù Docs preview for commit aa88cafcf0ce37179d67c54413b803e896ec7f03 at: https://64905d8e72e8806ce36e030c--fastapi.netlify.app",
      "üìù Docs preview for commit 410e5a4eb9c1fbdabdebc01c6f010987975e0ac0 at: https://649472f6b121c94bf1ab2b91--fastapi.netlify.app",
      "üìù Docs preview for commit 55b6d628fb9b975c60311c61dc4311c28fd724f8 at: https://649a3167b8e96720081c1f8a--fastapi.netlify.app",
      "Awesome, thanks @glsglsgls! üöÄ \r\n\r\nAnd thanks for the reviews @ivan-abc and @Alexandrhub üôá ‚òï "
    ],
    "num_comments": 12,
    "repository": "fastapi/fastapi",
    "diff_length": 21221
  },
  {
    "index": 27,
    "pr_title": "üåê Initialize translations for Traditional Chinese",
    "pr_body": "",
    "pr_number": 10505,
    "comments": [
      "üìù Docs preview for commit 3a0d3836b5a53cc11b6946e60eb9b5d7ef3d75f0 at: https://15e5624d.fastapitiangolo.pages.dev",
      "Hello, @tiangolo \r\n\r\nWe want to create the language for zh-hant (Mandarin), but the language will be limited to 2 letters. What are your recommended approaches for handling languages that have more than two letters?",
      "Thanks @hsuanchi! Up to now, I've avoided language localizations as there aren't yet enough translations of the first language, for example, for `pt-PT`.\r\n\r\nThe first question would be, how different is it from `zh`? Would `zh` not be understandable by people who speak `zh-hant`?\r\n\r\nThe second question is, are there others (at least other two, in total with you at least three) that are willing to help with those translations to `zh-hant`? Because I need to get 2 approvals to merge, and if there are now two variants of `zh`, it's probably gonna be even more difficult to get approvals for both.\r\n\r\nThere are currently 63 PRs for `zh` awaiting for reviewers: https://github.com/tiangolo/fastapi/pulls?q=is%3Apr+is%3Aopen+sort%3Aupdated-desc+label%3Alang-zh\r\n\r\nLet me know what you think!",
      "Hello @tiangolo ,\r\n\r\nThank you for your swift reply. To address your first question, zh is generally considered to be Simplified Chinese (zh-hans), while zh-hant refers to Traditional Chinese. Although the two variants share similarities, they differ significantly in terms of characters and some terminology. People from regions such as Taiwan, Hong Kong, and Macau typically use zh-hant and may find zh less intuitive to read.\r\n\r\nAs for your second question, we have a robust team of over 10 developers who use FastAPI on a daily basis. Some of our members have also contributed to the Traditional Chinese translation of Python documentation ([python-docs-zh-tw](https://github.com/python/python-docs-zh-tw)). We're confident that we'll be able to efficiently review and contribute to the zh-hant localization for FastAPI.\r\n\r\nThank you once again, and looking forward to your reply.",
      "Hi @tiangolo ,\r\n\r\nI would like to kindly inform you that I am part of the same team as @hsuanchi , and we are wholeheartedly dedicated to supporting the translation of the content into `zh-hant`. Let's collaborate to make it even more exceptional!",
      "I'm an avid user of FastAPI and would be thrilled to review @hsuanchi  's translation. Additionally, I'd be honored to contribute to the translation efforts for FastAPI, aiming to make it even more accessible and developer-friendly for the Chinese-speaking community.\"",
      "Fastapi basically consists of my day-to-day life and I'm confident that I can dedicate myself to contributing to the translations to zh-hant as zh-hant is my first language.\r\nIt'd be my pleasure to review @hsuanchi's translation and make the development of Fastapi more friendly to the Chinese-speaking community.",
      "Hello @tiangolo,\r\n\r\nI am in the same team as @hsuanchi. I am very eager to assist in the zh-hant localization to make FastAPI more accessible for the Traditional Chinese community. Looking forward to hearing from you!",
      "I am a user of FastAPI from Taiwan, and I am very eager to promote FastAPI among Traditional Chinese-speaking users. This way, more users can read the documentation in their native language, which would lower the barrier to entry.",
      "Hi @tiangolo,\r\n\r\nIf I could contribute to the translation efforts of FastAPI, making community documents more clear and intuitive for developers using the zh-hant language, I find it highly meaningful.",
      "Dear @tiangolo,\r\n\r\nI am extremely excited and looking forward to seeing FastAPI in Traditional Chinese. The purpose of this initiative is to assist developers in Taiwan in using and understanding FastAPI more easily. We are committed to continuing to support and contribute to FastAPI.",
      "As a software engineer from Hong Kong and Taiwan, I can tell that FastAPI is important for Traditional Chinese software community, we have a large community here working on Python with FastAPI in Taiwan.\r\n\r\nCan't wait to see more Traditional Chinese resources and contributions so FastAPI can be widely promoted.",
      "Traditional Chinese (`zh_hant`) and Simplified Chinese (`zh_hans`) are different *writing systems* of Chinese. Both are categorized under the `zh` code in ISO 639-1, and using this two-character code alone is insufficient to differentiate between the two. (Similarly, I'd say the term \"Mandarin\" in the PR title is not accurate enough.) They have different histories and cultures. Both are official in their regions and are widely used with rich literature and media. Their users generally have a strong preference for one writing system over the other based on their background. Though Mandarin is mostly spoken in both regions that use Traditional and Simplified Chinese characters, regional variations exist between both systems.\r\n\r\nIn the field of software technical document translation, many prominent resources offer both Traditional and Simplified Chinese versions simultaneously. Examples include [Python docs](https://docs.python.org/zh-tw/3/), [MDN docs](https://developer.mozilla.org/zh-TW/), [Microsoft docs](https://learn.microsoft.com/zh-tw/docs/), [AWS docs](https://docs.aws.amazon.com/zh_tw/), [React docs](https://zh-hant.legacy.reactjs.org/), [Angular docs](https://angular.tw/), and more. Although the momentum for zh_hant translation might not be as extensive as zh_hans, it's undeniable that Traditional Chinese is a legitimate and important language version for software documents.\r\n\r\nAs a Python backend engineer and a member of the Python document translation community, I'm more than willing to help with translating the FastAPI doc or reviewing for the translation PRs. (Actually, [I tried once before](https://github.com/tiangolo/fastapi/discussions/9758) lol).\r\n",
      "Hi @tiangolo , \r\n\r\nI am a software engineer who works with @hsuanchi. I understand your concern about the use of Traditional Chinese (`zh-Hant`) for translations. Here's a more detailed explanation of why it's essential to consider using `zh-Hant` for FastAPI translations:\r\n\r\n`zh-Hant`, which represents Traditional Chinese, is crucial for ensuring the accessibility and readability of FastAPI content for a specific audience. Traditional Chinese characters are primarily used in regions like Taiwan, Hong Kong, and among overseas Chinese communities. If your project has users in these areas or if your goal is to be inclusive of these regions, providing translations in `zh-Hant` is a necessity.\r\n\r\nHere's why `zh-Hant` matters:\r\n1. **Cultural Sensitivity**: Using Traditional Chinese characters is a matter of cultural sensitivity and respect. Some users in regions where Traditional Chinese is the norm may find it more comfortable and culturally appropriate when content is presented in `zh-Hant`.\r\n\r\n2. **Audience Reach**: Including `zh-Hant` extends your reach and ensures that FastAPI is accessible to a broader audience. It allows you to engage users who may prefer or are more familiar with Traditional Chinese characters.\r\n\r\n3. **User Experience**: Users tend to have a better user experience when content is in their preferred language variant. It enhances user satisfaction and encourages adoption.\r\n\r\nIn summary, providing translations in `zh-Hant` alongside `zh` is a strategic move to make FastAPI more inclusive, culturally sensitive, and user-friendly for a wider audience. It demonstrates your commitment to engaging with users from different regions and respecting their language and cultural preferences.\r\n\r\nWe hope you consider the importance of using `zh-Hant` as part of the translation efforts for FastAPI. Thank you for your understanding and support.",
      "Hi @tiangolo,  are there any updates? Are we ready to begin work on the Traditional Chinese version?\r\n\r\n\r\n\r\n\r\n\r\n",
      "üìù Docs preview for commit 84b953ba9a18cb60f296ae9bdbdada60937e7562 at: https://3397a9ff.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 953ad1489ace9cae73f2fdcf3dfa1df4e94aec20 at: https://b5531961.fastapitiangolo.pages.dev",
      "> Here is the initial review of the translation part.\r\n\r\nThanks for helping with the review ü´°ü´°ü´°, all amendments are now complete.",
      "üìù Docs preview for commit 73e95a72238dfc79c8d895ced60692e6fd8839a9 at: https://d5229374.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 66cba69728d587ee07cbb3b08168e0c252f9e50f at: https://c9489c35.fastapitiangolo.pages.dev",
      "Amazing! If you all work together you could have all the FastAPI docs translated to Traditional Chinese in no time! üéâ \r\n\r\nI updated the script to handle docs to take this into account, and I added this discussion: https://github.com/tiangolo/fastapi/discussions/10949\r\n\r\nWhen there's a new PR for Traditional Chinese and I add the label, it will be automatically posted there. You could subscribe to that discussion to get notified when there's a new PR to review. ü§ì \r\n\r\nThank you all for your help!\r\n\r\nOnce this PR is ready and has two approving reviews I'll merge it. The same with the next future PRs. üöÄ ",
      "üìù Docs preview for commit efc2197589ec94dda13015d4a17d80d9bc4b6334 at: https://be6f65a0.fastapitiangolo.pages.dev",
      "Awesome, thank you @hsuanchi ! üç∞ \r\n\r\nAnd thanks for the reviews @SonnyYou, @mattwang44 ‚òï üç™ "
    ],
    "num_comments": 23,
    "repository": "fastapi/fastapi",
    "diff_length": 16402
  },
  {
    "index": 28,
    "pr_title": "üåê Add Russian translation for `docs/ru/docs/tutorial/security/simple-oauth2.md`",
    "pr_body": "",
    "pr_number": 10599,
    "comments": [
      "Do you happen to know three Russian developers you can ask a [PR review](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/requesting-a-pull-request-review) from? [This](https://github.com/tiangolo/fastapi/pulls?q=is%3Apr+is%3Aopen+Russian) might help.",
      "@Xewus, @s111d –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å —Å —Ä–µ–≤—å—é. –ü–æ–¥–∫–ª—é—á–∞–π—Ç–µ—Å—å!\r\n:wave: :blush: ",
      "Hi @AlertRED, I have updated the documentation with the latest syntax for `includes`.\r\nI will wait for you to review the changes suggested by @alv2017 before merging the PR. \r\nThanks to both of you for the help! :rocket: ",
      "@alejsdev: Thank you for your help! \r\n\r\n@AlertRED: I think we are ready with PR, aren't we? \r\n\r\n:smiley: ",
      "> @alejsdev: Thank you for your help! \n> \n> @AlertRED: I think we are ready with PR, aren't we? \n> \n> :smiley: \n\nYes, we are :)",
      "–ü—Ä–æ–±–ª–µ–º–∞ —Ä–µ—à–µ–Ω–∞, —É –º–µ–Ω—è –Ω–∏–∫–∞–∫–∏—Ö –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π –±–æ–ª—å—à–µ –Ω–µ—Ç :smiley:",
      "Great! Thanks for your work @AlertRED @Xewus @alv2017 :rocket: :sparkles: "
    ],
    "num_comments": 7,
    "repository": "fastapi/fastapi",
    "diff_length": 10975
  },
  {
    "index": 29,
    "pr_title": "üåê Add Polish translation for `docs/pl/docs/help-fastapi.md`",
    "pr_body": "Relates to https://github.com/tiangolo/fastapi/discussions/9195\r\n\r\nThis PR is a translation of docs/pl/docs/help-fastapi.md\r\n\r\nThis is my first PR to this repository. I would appreciate a code review. Please let me know if it has any problems.",
    "pr_number": 10121,
    "comments": [
      "üìù Docs preview for commit 52aa0996bc44750c87305f91d2c0a9736c4c7f42 at: https://2c51a7d2.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 679878ab3fc9f77e34afe2a2ceea4b11f836c7b3 at: https://1e5494a5.fastapitiangolo.pages.dev",
      "@isulim Thanks for your review, really appreciate",
      "üìù Docs preview for commit 026faf5b27f2a788b4dea303093ca91c30ed6ceb at: https://fc058b53.fastapitiangolo.pages.dev",
      "Hello @tiangolo \r\nWhy does smokeshow/coverage fail on file `tests/test_openapi_examples.py`?\r\nI never changed this file.",
      "> Hello @tiangolo Why does smokeshow/coverage fail on file `tests/test_openapi_examples.py`? I never changed this file.\r\n\r\nSame here",
      "It seems it was a line in a dummy test I left uncovered and I probably didn't notice while Smokeshow was having errors. But now I added it, and updating the branch here should solve it. ü§ì ",
      "üìù Docs preview for commit 5c4fcabcdf9a38e4599f365a4fa0cf473c1c981f at: https://ae496c77.fastapitiangolo.pages.dev",
      "@isulim @bluefish6 Thanks for your review and suggestions!",
      "üìù Docs preview for commit 6788ebc57082506be903ded2970aec2fa64bdb39 at: https://e8b63855.fastapitiangolo.pages.dev",
      "@tiangolo Looks like we have 2 approves there",
      "üìù Docs preview for commit 2d2e7118091427640281bf3c189ac92f482f2d03 at: https://17f45cfb.fastapitiangolo.pages.dev",
      "Thanks @romabozhanovgithub! üôá \r\n\r\nAnd thanks for the reviews @bluefish6 and @isulim üç∞ "
    ],
    "num_comments": 13,
    "repository": "fastapi/fastapi",
    "diff_length": 15126
  },
  {
    "index": 30,
    "pr_title": "üåê Add Ukrainian translation for `docs/uk/docs/features.md` and `docs/uk/docs/index.md`",
    "pr_body": "The pull request creates Ukrainian translation for online documentation of FastAPI. \r\nCan be part of the Pull Request #1790 (We can combine the best parts of translations to one perfect).\r\nRelates to issue #1748 ",
    "pr_number": 1791,
    "comments": [
      "Thanks for your work! :globe_with_meridians: \r\n\r\nI just created a new PR with just the setup for the language, without the translations, so that you and others can continue to translate other pages while waiting for others to review the ones that are ready.\r\n\r\nMaybe @ArcLightSlavik could review this?",
      "> Thanks for your work! üåê\r\n> \r\n> I just created a new PR with just the setup for the language, without the translations, so that you and others can continue to translate other pages while waiting for others to review the ones that are ready.\r\n> \r\n> Maybe @ArcLightSlavik could review this?\r\n\r\nSorry, I accidentally closed it)\r\nI've merged your language setup to this branch, is it ok?",
      "This commit https://github.com/tiangolo/fastapi/pull/1791/commits/d8d6289585290187d836fc8f675c003b6accbf91 introduced conflicts, i assume docs preview on netlify does not work because of it",
      "> This commit [d8d6289](https://github.com/tiangolo/fastapi/commit/d8d6289585290187d836fc8f675c003b6accbf91) introduced conflicts, i assume docs preview on netlify does not work because of it\r\n\r\nOh, yes\r\nI will try to fix it soon as possible, Thanks",
      "@ArcLightSlavik I've fixed the merge conflict, now documentation is shown correctly",
      "It would probably be better to split this into two PRs, one for each file. It would make it easier to review. Also, once one file is ready, others can approve the PR for that file, even if the other file is not ready yet.\r\n\r\nAlso, as @shidenko97 is probably busy and hasn't been able to continue with this, maybe others can continue the work in independent PRs. ‚òï ",
      "As this has been quiet for a long time, I'm gonna close this one, if anyone wants to tackle any of these files you can create a new PR, feel free to copy things from this one or start from scratch. ‚òï "
    ],
    "num_comments": 7,
    "repository": "fastapi/fastapi",
    "diff_length": 39291
  },
  {
    "index": 31,
    "pr_title": "üåê Add Russian translation for  `docs/ru/docs/tutorial/middleware.md`",
    "pr_body": "",
    "pr_number": 13412,
    "comments": [
      "@Rishat-F, @Yarous, @Xewus, @Stepakinoyan, @gitgernit \r\n \r\n—Å–¥–µ–ª–∞–π—Ç–µ review –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ :blush:",
      "@Rishat-F : –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ–ø—Ä–∞–≤–∫–∏ —É–¥–æ–±–Ω–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∑–¥–µ—Å—å: https://github.com/fastapi/fastapi/pull/13412/commits/bb4077a21c01ee3174f652fb09c3dfe5cc0241d0",
      "—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è middleware :smile:\r\n\r\n```python\r\nfrom fastapi import FastAPI, Request\r\n\r\napp = FastAPI()\r\n\r\n\r\n@app.get(\"/\")\r\ndef hello():\r\n    return {\"message\": \"Hello from GET\"}\r\n\r\n\r\n@app.post(\"/\")\r\ndef hello():\r\n    return {\"message\": \"Hello from POST\"}\r\n\r\n\r\n@app.middleware(\"http\")\r\nasync def add_demo_middleware(request: Request, call_next):\r\n    if request.scope[\"method\"] == \"GET\":\r\n        request.scope[\"method\"] = \"POST\"\r\n    elif request.scope[\"method\"] == \"POST\":\r\n        request.scope[\"method\"] = \"GET\"\r\n\r\n    response = await call_next(request)\r\n    response.headers[\"X-Method\"] = f\"Request method: {request.method}\"\r\n    return response\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    import uvicorn\r\n    uvicorn.run(app, host=\"localhost\", port=8080, lifespan=\"on\")\r\n```",
      "@Yarous, @Rishat-F: –¥–æ–±–∞–≤–∏–ª–∞ –ø–æ–ø—Ä–∞–≤–∫–∏ –∏ —É—Ç–æ—á–Ω–∏–ª–∞ –ø–µ—Ä–µ–≤–æ–¥  :innocent:",
      "@Yarous, —É–∂–µ –≤—Å—ë –ø–æ–ø—Ä–∞–≤–∏–ª–∏, –∂–¥—ë–º —Ç–µ–±—è :smile:",
      "Great, thank you for your contribution! @alv2017 :rocket: \r\nAnd thanks for your reviews @Rishat-F @Yarous :sparkles: ",
      "@alv2017 , –º–æ–ª–æ–¥—á–∏–Ω–∞! –û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞!",
      "@Rishat-F, –Ω–∞—Ä–æ–¥–Ω–æ–µ —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ! :smile:"
    ],
    "num_comments": 8,
    "repository": "fastapi/fastapi",
    "diff_length": 3512
  },
  {
    "index": 32,
    "pr_title": "üåê Add German translation for `docs/de/docs/tutorial/path-params.md`",
    "pr_body": "There is an accidental overlap with #10281 by DevSpace88.\r\n\r\n‚Üê `async.md` (#10449)\r\n‚Üí `tutorial/query-params.md` (#10293)\r\n\r\n[German translation progress](https://github.com/tiangolo/fastapi/discussions/10582)",
    "pr_number": 10290,
    "comments": [
      "üìù Docs preview for commit 0252f0b2e433a3bb647fbfba335741962b2bceaf at: https://8488bdff.fastapitiangolo.pages.dev",
      "@tiangolo The German translation for the specific page is missing from most of these commit previews. I am sorry if I missed something. Do I have to update any global index file?\r\n\r\nI have the same issue in the local dev server in these branches. But it works in my [work-branch](https://github.com/nilslindemann/fastapi/tree/deutsche-uebersetzung-arbeitsbranch), which has all the commits applied.",
      "@nilslindemann \r\nThat's because you forgot to put path-params.md in the directory ```tutorial```\r\nIn your commit your path is  ```docs/de/docs/path-params.md```\r\nit should be:\r\n```docs/de/docs/tutorial/path-params.md```\r\n\r\nBut, I actually did this exact [PR](https://github.com/tiangolo/fastapi/pull/10281)  yesterday evening or tonight. I also noticed, that you did other PR's that were for files that also already had a PR. \r\nPlease check the open [PR's](https://github.com/tiangolo/fastapi/pulls) before starting a new one. ",
      "üìù Docs preview for commit 3809f5beab9741b9ca4f16f2171bd74694fcdcb3 at: https://aa1ff140.fastapitiangolo.pages.dev",
      "> @nilslindemann That's because you forgot to put path-params.md in the directory `tutorial` In your commit your path is `docs/de/docs/path-params.md` it should be: `docs/de/docs/tutorial/path-params.md`\r\n\r\nSorry, my mistake. Fixed.\r\n\r\n> But, I actually did this exact [PR](https://github.com/tiangolo/fastapi/pull/10281) yesterday evening or tonight. I also noticed, that you did other PR's that were for files that also already had a PR. Please check the open [PR's](https://github.com/tiangolo/fastapi/pulls) before starting a new one.\r\n\r\nI checked all PRs on Monday (23-9-18). Unfortunately, that was before you made your PR. Shit :-(\r\n\r\n**I will from now on post [here](https://github.com/tiangolo/fastapi/discussions/9203?sort=old) before I start a new translation.** I would be grateful if others could do so too, so that this does not happen anymore.\r\n\r\nRegarding the other commits, there were a few errors, and some translations were not in sync or just partially translated. [The authors did not respond in their PRs](https://github.com/tiangolo/fastapi/pull/3631#issuecomment-1722542037). So I decided to take them as base and create a bunch of new PRs.\r\n\r\n**I am planning to go through the whole docs, document by document. If you are interested, we can join our forces.**\r\n",
      "> **I will from now on post [here](https://github.com/tiangolo/fastapi/discussions/9203?sort=old) before I start a new translation.** I would be grateful if others could do so too, so that this does not happen anymore.\r\n\r\nSounds like a good idea. I will do the same then. ",
      "üìù Docs preview for commit 3495486c605d629ff3fdeca0e858c295a615f7be at: https://09da0811.fastapitiangolo.pages.dev",
      "Hallo @GeorchW,\r\n\r\nDanke f√ºr deine vielen guten Vorschl√§ge.\r\n\r\n> 2. Komposita werden im Deutschen grunds√§tzlich nicht mit Leerzeichen geschrieben, sondern entweder am St√ºck oder mit Bindestrich, z.B. \"Pfad-Parameter\" oder \"Pfadparameter\", aber nicht \"Pfad Parameter\".\r\n\r\nDa stimme ich zu. Allerdings scheint das seit der neuen Rechtschreibung optional zu sein, zumindest hat LanguageTool nicht gen√∂rgelt. Deswegen ist es mir auch bei der Rechtschreibpr√ºfung durch die Finger geflutscht. In sp√§teren √úbersetzungen verwende ich, wenn m√∂glich (hoffentlich) den Bindestrich. Danke f√ºr diese Korrekturen.\r\n\r\n> 1. Ich w√ºrde etwas weniger aggressiv eindeutschen. Z.B. die √úbersetzungen \"performance\" => \"Performanz\" und \"client\" => \"Klient\" lassen einen als Deutschen eher stolpern. Ich bin mir recht sicher, dass ich in deutschsprachigen IT-Magazinen auch keine √úbersetzungen daf√ºr finden w√ºrde.\r\n\r\nJa, das ist ein schwieriges Problem, was √ºbersetzen und was nicht. Ich √ºbersetze mittlerweile auch weniger (beispielsweise belasse ich \"Request-Body\" und \"Response-Body\") und f√ºge notfalls eine deutsche √úbersetzung in Klammern oder als Hover-Info hinzu. Bin hier wohl zu weit gegangen.\r\n",
      "üìù Docs preview for commit e9baaf6ff64ed88c628fe1febafa1b05ff5428c0 at: https://be6b5bd0.fastapitiangolo.pages.dev",
      "Danke f√ºr das Review, @GeorchW",
      "üìù Docs preview for commit 19a6b8cff569ca6d810d139a61b0526e7d830702 at: https://ac5c0ef3.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 94b9d7288fcb9d5be7bc2384ff092894442c1e67 at: https://e496d152.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit cbb3bd5da7b17120edce2f6e132ffec06840671d at: https://f7d2588b.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 9ce41eb3257e4ba6e89ffe69a748cba773161830 at: https://7cd6099b.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 75039d9bd0a1f964b42e96c18742703a3e2f802d at: https://5fe9b3b4.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 09663bfd419bf5940d116fa734f7a7360f0c0d4f at: https://7b9e2f9a.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit aded33c6d8f4f671a7cbbd6ecf54418877450b6e at: https://8ed79103.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 9877b60c1a8575bd38ead78f77912039c0b6cd7e at: https://39c8ba41.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 5a5cd418862afe99ae86b78de3886733243ded0a at: https://87d86527.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 5d762315f5b24fbcad89883f47dfd8414be8e3df at: https://2cfdaec1.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 9b2ecaf749b34ef8e35cd4dc3899d436d48fa0de at: https://d9ad5278.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit e2401db32ae4590a9860a9047ab016727a186545 at: https://3ac99c13.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 32caf4d1b0221691a41f2330eea5ad15c5253828 at: https://f8f184fa.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit b51bb2655fef1528386ae979e271db3088cdb642 at: https://01cdbfb0.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 7914f22d4d7f420d2bf5e35e293739f09b206a62 at: https://11c8d0b3.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit b1a4077982c03741d67be59d6253408ba1c586d5 at: https://78ca0b12.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 0be5693a237f611c35783012b59ec2c530b33e89 at: https://9bb2c91b.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 3e61988f32284d7b0798391b5655779c031e3180 at: https://e7396ada.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 73e9e3b2c423069b460d095b235c7610e7aa5c3c at: https://d973e473.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 7117666fc0f598bccfa0fb045dcb38794657523b at: https://f36b4a0a.fastapitiangolo.pages.dev"
    ],
    "num_comments": 30,
    "repository": "fastapi/fastapi",
    "diff_length": 10896
  },
  {
    "index": 33,
    "pr_title": "üåê Update Russian translations for deployments docs",
    "pr_body": "Correction of spelling and punctuation errors in Russian documentation.",
    "pr_number": 11271,
    "comments": [
      "üìù Docs preview for commit 89cd255336f8c5cdd5c7b47a5993f81cf82541af at: https://f06c65b9.fastapitiangolo.pages.dev",
      "–£ –¢–∏–∞–Ω–æ–≥–æ–ª–æ –ø–æ –≤—Å–µ–º –¥–æ–∫–∞–º –ø—Ä–æ—Å—Ç–æ–π, —Ç–æ–≤–∞—Ä–∏—â–µ—Å–∫–∏–π —Ç–æ–Ω, –±–µ–∑–æ –≤—Å—è–∫–∏–π –≤–∑–≤–∏–≤–∞–Ω–∏–π –∏ –≤–æ–∑–≤—ã—à–µ–Ω–∏–π, –æ–± —ç—Ç–æ–º –≤–∞–∂–Ω–æ –ø–æ–º–Ω–∏—Ç—å –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ. ",
      "üìù Docs preview for commit 51762798d1780a2fb5ad9b4f33629bbd426c3419 at: https://995dd47e.fastapitiangolo.pages.dev",
      "I agree with some comments, edits have been made",
      "üìù Docs preview for commit b5db82e74b026abb7ee3ead3edd2538d5c873772 at: https://172e7cd5.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit e1c6f1517ed5c1945946cc4665e619d34a890f94 at: https://e9a042f1.fastapitiangolo.pages.dev",
      "üìù Docs preview for commit 66bbb0d339b677f0930e4a80130323cf39d8e380 at: https://dda441bd.fastapitiangolo.pages.dev",
      "Since @Lufa1u made the requested changes, we will merge this. If anyone finds something that should be updated here, feel free to create a new PR. :nerd_face: \r\n\r\nThank you all for the help! @Lufa1u @s111d @wisderfin @alex-pobeditel-2004 :nerd_face: :rocket: "
    ],
    "num_comments": 8,
    "repository": "fastapi/fastapi",
    "diff_length": 70115
  },
  {
    "index": 34,
    "pr_title": "üåê Add Korean translation for `docs/ko/docs/tutorial/middleware.md`",
    "pr_body": "related issue -> #2017 \r\nI'm Happy to contribute to this repository by translate eng to ko.\r\nif have any error or suggestion in my pr, please comment to in this pr :)\r\nthanks for reviewer\r\n\r\nThis PR translates tutorial/middleware.md in Korean.\r\nrelated: #2017 @",
    "pr_number": 2829,
    "comments": [
      "thanks for your review @hard-coders \r\nThere are many mistranslation in this PR. Because this pr is first pr in my carrer. :)\r\n\r\nI learn a lot at this PR :)\r\n\r\ni will reflect all of your comment within 3days",
      "@hard-coders \r\ni accepted your reviews and modified this pr at 3/2\r\ncan i request re-review this pr?\r\nthank you",
      "i accepted your review :) thanks @hard-coders! \r\nbut i have some questionmark at above.\r\n\r\ni think, we uaually use \"request\", \"response\" in english at our daily work.\r\nso i suggest that the word \"request\", \"response\" use english in our translate contribution",
      "@JeongHyeongKim \r\nI sincerely understand what you mean, but I usually use \"ÏöîÏ≤≠\", \"ÏùëÎãµ\" in work. I'm not lying :)\r\nBy your logic, I also can claim we should use \"ÏöîÏ≤≠\". It's ambiguous. So we need a rule, official Python Korean docs.\r\nIn addition, backtick(`) is used to represent a code in markdown, however.",
      "thanks you for review this pr @hard-coders ! \r\ncan i write a comment at #3167 about the rule that we talked today?\r\nit can be a good reference to another contributer :)",
      "Thanks for your review. I will check your review and apply soon. \r\n@0417taehyun ",
      "@0417taehyun\r\nyour translation is better than my translation. i check your translation and accept your review :)\r\nthank for your review",
      "üìù Docs preview for commit 9e0718c1378b6a650da0621eeaed80a176822445 at: https://649a1585acd72b10c561eaad--fastapi.netlify.app",
      "Nice, thanks for the help! @JeongHyeongKim ü§ìüöÄ\r\n\r\nAnd thanks for the reviews @hard-coders @0417taehyun üéâ "
    ],
    "num_comments": 9,
    "repository": "fastapi/fastapi",
    "diff_length": 2303
  },
  {
    "index": 35,
    "pr_title": "Uses MPS (Mac acceleration) by default when available",
    "pr_body": "Currently, Whisper defaults to using the CPU on MacOS devices despite the fact that PyTorch has introduced Metal Performance Shaders framework for Apple devices in the nightly release ([more info](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)).\r\n\r\nWith my changes to __init__.py, torch checks in MPS is available if torch.device has not been specified. If it is, and CUDA is not available, then Whisper defaults to MPS.\r\n\r\nThis way, Mac users can experience speedups from",
    "pr_number": 382,
    "comments": [
      "@dwarkeshsp have you measured any speedups compared to using the CPU?",
      "Doesn't this also require switching FP16 off?",
      "I'm getting this error when try to use MPS\r\n\r\n/Users/diego/.pyenv/versions/3.10.6/lib/python3.10/site-packages/whisper-1.0-py3.10.egg/whisper/decoding.py:629: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/diego/Projects/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/2d9b4df9-4b93-11ed-b0fc-2e32217d8374/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 23200 bytes\r\n'\r\nAbort trap: 6\r\n/Users/diego/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n\r\nany clues?",
      "@DiegoGiovany Not an expert on this but It looks like PyTorch itself is missing some operators for MPS. See for example\r\nhttps://github.com/pytorch/pytorch/issues/77764#issuecomment-1254352628\r\n(which refers to repeat_interleave)\r\n\r\nand\r\nhttps://github.com/pytorch/pytorch/issues/87219\r\n",
      "Thanks for your work. I just tried this. Unfortunately, it didn't work for me on my m1 max with 32GB.\r\nHere is what I did:\r\npip install git+https://github.com/openai/whisper.git@refs/pull/382/head\r\n\r\nNo errors on install and it works fine when run without mps: whisper audiofile_name --model medium \r\n\r\nWhen I run: whisper audiofile_name --model medium --device mps\r\n\r\nHere is the error I get:\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/810eba08-405a-11ed-86e9-6af958a02716/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1024x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s). \r\n\r\nWhen I run:  whisper audiofile_name --model medium --device mps --fp16 False\r\n\r\nHere is the error I get:\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nDetected language: English\r\n/anaconda3/lib/python3.9/site-packages/whisper/decoding.py:633: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/f0468ab4-4115-11ed-8edc-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 1007280 bytes\r\n\r\nBasically, same error as @DiegoGiovany.\r\n\r\nAny ideas on how to fix?",
      "+1 for me!  I'm actually using an Intel Mac with Radeon Pro 560X 4 GB...",
      "Related\r\nhttps://github.com/pytorch/pytorch/issues/87351",
      "@dwarkeshsp \r\n\r\nnot workÔºåwith mbp2015 pytorch 1.3 stableÔºåegpu RX580, MacOS 12.3.\r\n\r\nchanged the code as the same as yours.\r\n\r\nchanged  to use --device mps but show error, maybe there is still somewhere to change or modify.\r\n\r\nuse --device cpu, it works.\r\n\r\nwith other pytorch-metal project, MPS works.",
      "I also see the same errors as others mentioned above, on an M1 Mac running arm64 Python. ",
      "On an M1 16\" MBP with 16GB running MacOS 13.0.1, I'm seeing the following with `openai-whisper-20230117`:\r\n\r\nUsing this command:\r\n```(venv) whisper_ai_playground % whisper './test_file.mp3' --model tiny.en --output_dir ./output --device mps```\r\n\r\nI'm encountering the following errors:\r\n\r\n```loc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/810eba08-405a-11ed-86e9-6af958a02716/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x384x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible```\r\n\r\n```LLVM ERROR: Failed to infer result type(s).```\r\n\r\n```zsh: abort      whisper  --model tiny.en --output_dir ./output --device mps```\r\n\r\n```/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '```",
      "Is there any update on this, or did anyone figure out how to get it to work? ",
      "Same problem with osx 13.2 in MacBook Pro M2 max:\r\n\r\n```\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1280x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\nzsh: abort      whisper audio.wav --language en --model large\r\nm2@Render ~ % /opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
      "I'm getting the same error as @renderpci using the M1 Base Model\r\n```bash\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x512x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\n[1]    3746 abort      python3 test.py\r\n```\r\n**test.py:**\r\n```py\r\nimport whisper\r\n\r\nmodel = whisper.load_model(\"base\")\r\nresult = model.transcribe(\"audio.mp3\")\r\nprint(result[\"text\"])\r\n```",
      "FWIW I switched to the C++ port https://github.com/ggerganov/whisper.cpp/ and got a ~15x speedup compared to CPU pytorch on my M1 Pro. (But note that it doesn't have all the features/flags from the official whisper repo.)",
      "> FWIW I switched to the C++ port https://github.com/ggerganov/whisper.cpp/ \r\n\r\nFor us whisper.cpp is not an option:\r\n\r\n> **Should I use whisper.cpp in my project?**\r\n> \r\n> whisper.cpp is a hobby project. It does not strive to provide a production ready implementation. The main goals of the implementation is to be educational, minimalistic, portable, hackable and performant. There are no guarantees that the implementation is correct and bug-free and stuff can break at any point in the future. Support and updates will depend mostly on contributions, since with time I will move on and won't dedicate too much time on the project.\r\n> \r\n> If you plan to use whisper.cpp in your own project, keep in mind the above.\r\n> My advice is to not put all your eggs into the whisper.cpp basket.",
      "The same error as @renderpci using the M2\r\n\r\n\r\nwhisper interview.mp4 --language en --model large --device mps\r\n\r\n```\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1280x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\nzsh: abort      whisper interview.mp4 --language en --model large --device mps\r\npac@dd ~ % /opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
      "Hey @devpacdd  - this should be fixed in latest pytorch nightly (pip3 install --pre --force-reinstall torch --index-url https://download.pytorch.org/whl/nightly/cpu). Let me know if you still see any issues. Thanks",
      "Still have the same error after updating\r\n\r\nEdit: After adding `--fp16 False` to the command, I now get a new error, as well as the old one:\r\n```\r\n/opt/homebrew/lib/python3.10/site-packages/whisper/decoding.py:633: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/5b8a32f9-5db2-11ed-8aeb-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 1007280 bytes\r\n'\r\nzsh: abort      whisper --model large --language de --task transcribe  --device mps --fp16\r\n/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
      "i was able to get it to kinda work: https://github.com/davabase/whisper_real_time/issues/5#issue-1596258783",
      "> The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n>   audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n\r\n@manuthebyte could you please make sure you are on a recent nightly? `repeat_interleave` should be natively supported. If you could try grabbing today's nightly and give a try that would be awesome! (You can get today's nightly with `pip3 install --pre --force-reinstall torch==2.0.0.dev20230224 --index-url https://download.pytorch.org/whl/nightly/cpu`)\r\n\r\n",
      "Wow! \r\n\r\nwhen running:\r\n`Python3 transcribe_demo.py --model medium` (from https://github.com/davabase/whisper_real_time)\r\n\r\nwith the following packages in my pipenv's requirements.txt\r\n```\r\ncertifi==2022.12.7\r\ncharset-normalizer==3.0.1\r\nffmpeg-python==0.2.0\r\nfilelock==3.9.0\r\nfuture==0.18.3\r\nhuggingface-hub==0.12.1\r\nidna==3.4\r\nmore-itertools==9.0.0\r\nmpmath==1.2.1\r\nnetworkx==3.0rc1\r\nnumpy==1.24.2\r\nopenai-whisper @ git+https://github.com/openai/whisper.git@51c785f7c91b8c032a1fa79c0e8f862dea81b860\r\npackaging==23.0\r\nPillow==9.4.0\r\nPyAudio==0.2.13\r\nPyYAML==6.0\r\nregex==2022.10.31\r\nrequests==2.28.2\r\nSpeechRecognition==3.9.0\r\nsympy==1.11.1\r\ntokenizers==0.13.2\r\ntorch==2.0.0.dev20230224\r\ntorchaudio==0.13.1\r\ntorchvision==0.14.1\r\ntqdm==4.64.1\r\ntransformers==4.26.1\r\ntyping_extensions==4.4.0\r\nurllib3==1.26.14\r\n```\r\n\r\nit gets every word! while i was singing! in realtime, with maybe 50%~ gpu usage on the apple M2 Pro Max.",
      "> > The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n> > audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n> \r\n> @manuthebyte could you please make sure you are on a recent nightly? `repeat_interleave` should be natively supported. If you could try grabbing today's nightly and give a try that would be awesome! (You can get today's nightly with `pip3 install --pre --force-reinstall torch==2.0.0.dev20230224 --index-url https://download.pytorch.org/whl/nightly/cpu`)\r\n\r\nWith my pip3 freeze being:\r\n```\r\nbeautifulsoup4==4.11.2\r\ncertifi==2022.12.7\r\ncharset-normalizer==3.0.1\r\ncolorama==0.4.6\r\ndnspython==2.3.0\r\nffmpeg-python==0.2.0\r\nfilelock==3.9.0\r\nfuture==0.18.3\r\nhuggingface-hub==0.12.1\r\nidna==3.4\r\nmore-itertools==9.0.0\r\nmpmath==1.2.1\r\nnetworkx==3.0rc1\r\nnumpy==1.24.2\r\nopenai-whisper @ git+https://github.com/openai/whisper.git@7858aa9c08d98f75575035ecd6481f462d66ca27\r\npackaging==23.0\r\nprotobuf==4.21.12\r\nPyYAML==6.0\r\nregex==2022.10.31\r\nrequests==2.28.2\r\nsix==1.16.0\r\nsoupsieve==2.4\r\nsympy==1.11.1\r\ntokenizers==0.13.2\r\ntorch==2.0.0.dev20230224\r\ntqdm==4.64.1\r\ntransformers==4.26.1\r\ntyping_extensions==4.4.0\r\nurllib3==1.26.14\r\n```\r\n\r\nIt now seems to use the GPU but I now get these errors:\r\n```\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:636: UserWarning: 0MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:443: UserWarning: 1MPS: no support for int64 reduction ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:143.)\r\n  timestamp_logprob = logprobs[k, self.tokenizer.timestamp_begin :].logsumexp(dim=-1)\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:444: UserWarning: 1MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:1269.)\r\n  max_text_token_logprob = logprobs[k, : self.tokenizer.timestamp_begin].max()\r\nTraceback (most recent call last):\r\n  File \"/opt/homebrew/bin/whisper\", line 8, in <module>\r\n    sys.exit(cli())\r\n             ^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 314, in cli\r\n    result = transcribe(model, audio_path, temperature=temperature, **args)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 183, in transcribe\r\n    result: DecodingResult = decode_with_fallback(segment)\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 118, in decode_with_fallback\r\n    decode_result = model.decode(segment, options)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 707, in decode\r\n    result = DecodingTask(model, options).run(mel)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 640, in run\r\n    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\r\n                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 609, in _main_loop\r\n    tokens, completed = self.decoder.update(tokens, logits, sum_logprobs)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 258, in update\r\n    next_tokens = Categorical(logits=logits / self.temperature).sample()\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/distributions/categorical.py\", line 66, in __init__\r\n    super().__init__(batch_shape, validate_args=validate_args)\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/distributions/distribution.py\", line 62, in __init__\r\n    raise ValueError(\r\nValueError: Expected parameter logits (Tensor of shape (5, 51865)) of distribution Categorical(logits: torch.Size([5, 51865])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\r\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan]], device='mps:0')\r\n```\r\n\r\nWhen running the command `whisper --model small --language en --task transcribe ***.wav --device mps`",
      "> Hey @devpacdd - this should be fixed in latest pytorch nightly (pip3 install --pre --force-reinstall torch --index-url https://download.pytorch.org/whl/nightly/cpu). Let me know if you still see any issues. Thanks\r\n\r\nGeart! it works!\r\nBut.. In my test the GPU is slow than CPU... ??? \r\n\r\nAudio to transcribe: 1 minute with model large, language catalan\r\n\r\nCPU  : 2m : 33 s\r\nGPU (--device mps): 4m : 54 s\r\n\r\nI tried with different files and the result was the same; +/- double time with GPU enable.\r\n\r\nIt's normal? I expected less time for GPU than CPU.\r\n\r\nBest",
      "I get this error while trying to use MPS\r\n\r\nHere is the command I am running: `whisper --model large --language en --task transcribe test.mp3 --device mps`\r\n\r\n```\r\n$ whisper --model large --language en --task transcribe test.mp3 --device mps\r\nTraceback (most recent call last):\r\n  File \"/Users/mukul/miniconda3/envs/ml/bin/whisper\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/whisper/transcribe.py\", line 433, in cli\r\n    model = load_model(model_name, device=device, download_root=model_dir)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/whisper/__init__.py\", line 159, in load_model\r\n    return model.to(device)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1170, in to\r\n    return self._apply(convert)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 869, in _apply\r\n    self._buffers[key] = fn(buf)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1168, in convert\r\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\r\nNotImplementedError: Could not run 'aten::empty.memory_format' with arguments from the 'SparseMPS' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty.memory_format' is only available for these backends: [CPU, MPS, Meta, QuantizedCPU, QuantizedMeta, MkldnnCPU, SparseCPU, SparseMeta, SparseCsrCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\r\n\r\nCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterCPU.cpp:31085 [kernel]\r\nMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMPS.cpp:24065 [kernel]\r\nMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26824 [kernel]\r\nQuantizedCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\r\nQuantizedMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterQuantizedMeta.cpp:105 [kernel]\r\nMkldnnCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMkldnnCPU.cpp:507 [kernel]\r\nSparseCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseCPU.cpp:1379 [kernel]\r\nSparseMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\r\nSparseCsrCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseCsrCPU.cpp:1128 [kernel]\r\nBackendSelect: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterBackendSelect.cpp:734 [kernel]\r\nPython: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\r\nFuncTorchDynamicLayerBackMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\r\nFunctionalize: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:290 [backend fallback]\r\nNamed: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\r\nConjugate: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\r\nNegative: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/NegateFallback.cpp:23 [kernel]\r\nZeroTensor: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:90 [kernel]\r\nADInplaceOrView: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\r\nAutogradOther: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradCUDA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradHIP: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradXLA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradIPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradXPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradHPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradVE: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradLazy: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMTIA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse1: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse2: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse3: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradNestedTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nTracer: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:16872 [kernel]\r\nAutocastCPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\r\nAutocastCUDA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\r\nFuncTorchBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:815 [backend fallback]\r\nFuncTorchVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\r\nBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1073 [backend fallback]\r\nVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\nFuncTorchGradWrapper: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\r\nPythonTLSSnapshot: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\r\nFuncTorchDynamicLayerFrontMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\r\nPythonDispatcher: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\r\n```",
      "> pytorch/pytorch#87351\r\n\r\nI'd love to hear a clear update too. It looks like there will be a lot of demand for this. (Mac M2 myself) Thank you OpenAI people!",
      "@mukulpatnaik \r\nMy device is M1 MacBook Pro, I got the same error with the latest version of whisper([v20230314](https://github.com/openai/whisper/releases/tag/v20230314)), then I switch to [v20230124](https://github.com/openai/whisper/releases/tag/v20230124), every thing works fine. (torch nightly version)\r\n\r\nBut, seems like mps is slower than cpu like @renderpci reported, for my task\r\n* cpu 3.26 s\r\n* mps 5.25 s\r\n* cpu+torch2 compile 3.31 s\r\n* mps+torch2 compile 4.94 s\r\n\r\nü´†",
      "@HFrost0, what's your macOS, PyTorch and Python version? Some versions support different operations, and PyTorch defaults to CPU on those. "
    ],
    "num_comments": 27,
    "repository": "openai/whisper",
    "diff_length": 1323
  },
  {
    "index": 36,
    "pr_title": "word-level timestamps in `transcribe()`",
    "pr_body": "",
    "pr_number": 869,
    "comments": [
      "This DTW dependency introduces a licence incompatibility, but an alternative was suggested earlier in the discussions from memory.\r\n\r\nEdit: Alternative library recommended in https://github.com/openai/whisper/discussions/813#discussioncomment-4617447",
      "Hi!\r\nI tried out this branch with ```kwargs['word_level_timestamps'] = True``` but the model performed very slowly. In addition (or rather because of) it started to hallucinate like mad. \r\nIm using chunks of short (couple of seconds) audio data in german produced by a VAD for live transcription.\r\n\r\nMaybe its a problem on my side, maybe anyone can try to reproduce?",
      "Thanks for the comments, all -- this is work in progress and not quite ready for merging. I'm trying to address both hallucination and performance concerns.",
      "Yet another DTW implementation, fyi. Can't vouch for it other than to say that it is Apache licensed, recently updated, has both pure Python and C implementations.\r\n\r\nhttps://github.com/wannesm/dtaidistance",
      "Hi, thanks for the great work! \r\n\r\nI would like to ask if it is safe to swap to a smaller model (e.g. tiny) for world-level alignment to compute attention scores instead of using the same model (e.g. medium or large ) used to generate transcription. I suspect it could improve performance in terms of inference speed if this option would be supported. ",
      "I found an interesting edge case with the `small` model where enabling the word-level timestamps option causes it to repeat the prompt at the end of the audio while also failing to infer the last word.\r\n\r\n```bash\r\n$ ffmpeg -t 29 -i https://audio2.redcircle.com/episodes/6b196013-8672-43d9-be52-4332b3207d93/stream.mp3 test.mp3\r\n\r\n$ whisper --model small test.mp3\r\n.../whisper/transcribe.py:98: UserWarning: FP16 is not supported on CPU; using FP32 instead\r\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nDetected language: English\r\n[00:00.000 --> 00:15.920]  Military veteran Eric Weinstein began 69 Whiskey as a college radio show on 107.7 The\r\n[00:15.920 --> 00:21.720]  Bronx, located on the campus of Ryder University in Lawrenceville, New Jersey.\r\n[00:21.720 --> 00:27.560]  A show once restrained by rules and boundaries now comes straight to you raw, uncensored and\r\n[00:27.560 --> 00:28.960]  unapologetic.\r\n\r\n$ whisper --model small --output_format json --word_timestamps True test.mp3\r\n.../whisper/transcribe.py:98: UserWarning: FP16 is not supported on CPU; using FP32 instead\r\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nDetected language: English\r\n[00:08.040 --> 00:15.940]  Military veteran Eric Weinstein began 69 Whiskey as a college radio show on 107.7 The\r\n[00:15.940 --> 00:21.320]  Bronx, located on the campus of Ryder University in Lawrenceville, New Jersey.\r\n[00:21.720 --> 00:28.980]  A show once restrained by rules and boundaries now comes straight to you raw, uncensored and\r\n[00:28.960 --> 00:28.960]  Military veteran Eric Weinstein began 69 Whiskey as a college radio show on 107.7 The\r\n[00:28.960 --> 00:28.960]  Bronx, located on the campus of Ryder University in Lawrenceville, New Jersey.\r\n[00:28.960 --> 00:28.960]  A show once restrained by rules and boundaries now comes straight to you raw, uncensored and\r\n[00:28.960 --> 00:28.960]  Military veteran Eric Weinstein began 69 Whiskey as a college radio show on 107.7 The\r\n[00:28.960 --> 00:28.960]  Bronx, located on the campus of Ryder University in Lawrenceville, New Jersey.\r\n```",
      "Hi @jongwook ,\r\nSince you first release the notebook to obtain word-level timestamps I've been working on this to add to whisper process. And I've tried to test other alingment methods than DTW. Have you tried something else and found out that it works better?\r\n\r\nAlso, I've been struggling a lot with alucinations, specially for spanish content. I've create a cleaner function at segmet level, is there any smarter way?",
      "is there any chance to have word level timestamps in Whisper API?",
      "Hi @IgnacioSan22, the custom DTW implementation in this PR was for the license issue as noted by others and also for the speed. An alternative is to use the timestamp predictions from the model, but we found that it's less reliable than using the attention patterns like in this PR. If you have solutions using any other algorithms for alignment, please let me know!\r\n\r\nThe community had some success handling hallucinations by preprocessing the inputs with VAD, like:\r\n\r\n- #679\r\n- #397\r\n- https://github.com/m-bain/whisperX\r\n\r\n---\r\n\r\nHi @ioskevinshah, this feature is still experimental but we do plan to add it to the API as an option, once we're sure that it's reliable enough.",
      "@jongwook is there a way to access it via a beta flag for instance? How can we know when something is/isn't added to the API?",
      "For the API, the [speech-to-text guide](https://platform.openai.com/docs/guides/speech-to-text) and the [audio API reference](https://platform.openai.com/docs/api-reference/audio) provide the full documentation of the available features. These documents will be updated accordingly as we roll out new features.",
      "> Hi @IgnacioSan22, the custom DTW implementation in this PR was for the license issue as noted by others and also for the speed. An alternative is to use the timestamp predictions from the model, but we found that it's less reliable than using the attention patterns like in this PR. If you have solutions using any other algorithms for alignment, please let me know!\r\n> \r\n> The community had some success handling hallucinations by preprocessing the inputs with VAD, like:\r\n> \r\n> * [A possible solution to Whisper hallucination¬†#679](https://github.com/openai/whisper/discussions/679)\r\n> * [Whisper WebUI with a VAD for more accurate non-English transcripts (Japanese)¬†#397](https://github.com/openai/whisper/discussions/397)\r\n> * https://github.com/m-bain/whisperX\r\n> \r\n> Hi @ioskevinshah, this feature is still experimental but we do plan to add it to the API as an option, once we're sure that it's reliable enough.\r\n\r\nHi @jongwook, I've tried the hungarian algorithm and in some cases the results are better, however due to the lack of resources I'm not capable to perform a proper study to find the best alingment algorithm. For hallucinations I've developed a postprocess functions that cleans the segments. It improves quite a lot, but I'll check those references. \r\n\r\nThanks",
      "> For the API, the [speech-to-text guide](https://platform.openai.com/docs/guides/speech-to-text) and the [audio API reference](https://platform.openai.com/docs/api-reference/audio) provide the full documentation of the available features. These documents will be updated accordingly as we roll out new features.\r\n\r\nOne more question: when will this new feature be rolled out?",
      "> Hi @IgnacioSan22, the custom DTW implementation in this PR was for the license issue as noted by others and also for the speed. An alternative is to use the timestamp predictions from the model, but we found that it's less reliable than using the attention patterns like in this PR. If you have solutions using any other algorithms for alignment, please let me know!\r\n> \r\n> The community had some success handling hallucinations by preprocessing the inputs with VAD, like:\r\n> \r\n> * [A possible solution to Whisper hallucination¬†#679](https://github.com/openai/whisper/discussions/679)\r\n> * [Whisper WebUI with a VAD for more accurate non-English transcripts (Japanese)¬†#397](https://github.com/openai/whisper/discussions/397)\r\n> * https://github.com/m-bain/whisperX\r\n> \r\n> Hi @ioskevinshah, this feature is still experimental but we do plan to add it to the API as an option, once we're sure that it's reliable enough.\r\n\r\nany workaround or logic after the API response?",
      "This is awesome! Is there a way to pass in pre-transcribed text that whisper can use for more accurate alignment?"
    ],
    "num_comments": 15,
    "repository": "openai/whisper",
    "diff_length": 43620
  },
  {
    "index": 37,
    "pr_title": "Skip silence around hallucinations",
    "pr_body": "This PR introduces a heuristic that determines if a segment is probably a hallucination. If that \"probable\" hallucination occurs after a period of silence (specified by `--hallucination_silence_threshold` in seconds), then we seek past the silence and reprocess from that point. Eliminating the silence before a hallucination improves the likelihood of getting a correct inference, but since this also requires extra processing time, we only do this when a probable hallucination is detected.\r\n\r\nThe ",
    "pr_number": 1838,
    "comments": [
      "Testing on another example from https://github.com/openai/whisper/discussions/679#discussioncomment-7649183\r\n\r\n<details>\r\n<summary>Output</summary>\r\n\r\n```\r\nv2 runs:\r\n\r\n[00:00.000 --> 00:05.660]  spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo\r\nDETECTED HALLUCINATION:  non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho\r\nDETECTED HALLUCINATION:  no\r\nDETECTED HALLUCINATION:  no\r\n\r\n\r\n\r\n[00:00.000 --> 00:05.660]  spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo\r\nDETECTED HALLUCINATION:  non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho\r\nDETECTED HALLUCINATION:  .....\r\nDETECTED HALLUCINATION:  .....\r\n\r\n\r\n\r\n[00:00.000 --> 00:05.660]  spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo\r\nDETECTED HALLUCINATION:  non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho\r\nDETECTED HALLUCINATION:  uh\r\nDETECTED HALLUCINATION:  uh\r\n\r\n\r\n\r\nv3 run:\r\n\r\n[00:00.000 --> 00:04.240]  Spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo.\r\nDETECTED HALLUCINATION:  Grazie a tutti.\r\nDETECTED HALLUCINATION:  E' un attimo che non dovevo.\r\n[00:54.440 --> 00:55.700]  Ehm, ehm.\r\n```",
      "When using `--clip_timestamps`, is there a need to pad before and after the clip? If so, what would be a recommended value for pad duration? ",
      "It should work without padding, but if the VAD is inaccurate then padding might help compensate for that.",
      "Will this PR included in the next release? If so, when it it planned?",
      "Related PR: #2005 (fixes a bug in `--clip_timestamps` if you pass an end timestamp that is after the audio end.)",
      "Just tested out hallucination_silence_threshold and it worked for me\r\nthanks!",
      "@ryanheise Can you show me your transcribe.py with debug stuff?",
      "I don't have the exact code anymore, but you could try temporarily inserting these two lines:\r\n\r\n```python\r\n                if score >= 3 or score + 0.01 >= len(words):\r\n                    print(f\"DETECTED HALLUCINATION: {segment['text']}\")\r\n```\r\n\r\nbefore the return in this function:\r\n\r\n```python\r\n            def is_segment_anomaly(segment: Optional[dict]) -> bool:\r\n                if segment is None or not segment[\"words\"]:\r\n                    return False\r\n                words = [w for w in segment[\"words\"] if w[\"word\"] not in punctuation]\r\n                words = words[:8]\r\n                score = sum(word_anomaly_score(w) for w in words)\r\n                return score >= 3 or score + 0.01 >= len(words)\r\n```",
      "@ryanheise\r\nSometimes `--hallucination_silence_threshold` makes whole non-hallucinating segments or part of segments disappear.\r\n\r\nBelow is example with disappeared `orange pigmentation.` segment.\r\n\r\nI'm using faster-whisper, but you should be able to reproduce it with whisper too as implementation is same.\r\nAudio file -> https://we.tl/t-U5a6Al5bRs\r\n\r\n\r\n`--language en --model=base --beam_size=5 --word_timestamps=True --hallucination_silence_threshold=None`:\r\n\r\n```\r\n[02:06.620 --> 02:11.120]  White tigers carry a mutated version of this gene, which prevents them from producing\r\n  Processing segment at 02:11.120\r\n[02:11.120 --> 02:12.460]  orange pigmentation.\r\n[02:15.360 --> 02:18.340]  Fewer than 4,000 tigers remain in the wild.\r\n```\r\n\r\n`--language en --model=base --beam_size=5 --word_timestamps=True --hallucination_silence_threshold=2`:\r\n\r\n```\r\n[02:06.620 --> 02:11.120]  White tigers carry a mutated version of this gene, which prevents them from producing\r\n  Processing segment at 02:12.380\r\n* HST_1: Skipping silence before possible hallucinations.\r\n* HST_3: DETECTED HALLUCINATION:  oxygen.\r\n  Processing segment at 02:13.380\r\n* HST_1: Skipping silence before possible hallucinations.\r\n[02:14.680 --> 02:18.360]  fewer than 4,000 tigers remain in the wild.\r\n```\r\n\r\nEDIT:\r\nfloat32 was in use",
      "I think, I've noticed a pattern, it happens when `if remaining_duration > threshold:` is not triggered, in there:\r\n`seek = previous_seek + segment_size`\r\n\r\nThen chunk go exactly by 30 secs cutting off the word.\r\n\r\nChunking when `--hallucination_silence_threshold=None`:\r\n\r\n```\r\n  Processing segment at 00:00.000\r\n  Processing segment at 00:26.040\r\n  Processing segment at 00:48.280\r\n  Processing segment at 01:14.400\r\n  Processing segment at 01:42.380\r\n  Processing segment at 02:11.120\r\n  Processing segment at 02:35.400\r\n  Processing segment at 03:05.400\r\n```\r\nChunking by setting high threshold `--hallucination_silence_threshold=40`:\r\n```\r\n  Processing segment at 00:00.000\r\n  Processing segment at 00:30.000\r\n  Processing segment at 01:00.000\r\n  Processing segment at 01:30.000\r\n  Processing segment at 02:00.000\r\n  Processing segment at 02:30.000\r\n  Processing segment at 03:00.000\r\n```",
      "Another thing, this PR affects transcription even if both new parameters are not enabled, I meant comparing vs without this PR.\r\n\r\nThis happens sometimes, but when it happens the discrepancy is always in the last chunk.\r\n\r\nAnd sometimes when discrepancy happens it tries to process additional micro chunk after it which produces some hallucination or fails because no-speech threshold is met, not sure if this is related to PR or to a discrepancy.\r\n\r\nExample of such discrepancy [audio is `05:05.877` long]:\r\n\r\nWithout this PR [perfect transcription]:\r\n```\r\nProcessing segment at 04:48.000\r\n[04:58.120 --> 05:05.260]  I just...\r\n[05:05.260 --> 05:05.760]  I...\r\n```\r\n\r\nWith this PR [all goes exactly same till the last chunk]:\r\n\r\n```\r\n  Processing segment at 04:48.000\r\n* Compression ratio threshold is not met with temperature 0.0 (3.523810 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.2 (3.523810 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.4 (8.038462 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.6 (3.523810 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.8 (2.423077 > 2.400000)\r\n[05:01.940 --> 05:02.900]  Okay.\r\n[05:02.900 --> 05:04.000]  I just-\r\n[05:04.940 --> 05:05.740]  I-\r\n[05:05.740 --> 05:05.840]  I-\r\n* Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000\r\n  Processing segment at 05:05.840\r\n* Log probability threshold is not met with temperature 0.0 (-1.105777 < -1.000000)\r\n* No speech threshold is met (0.772002 > 0.600000)\r\n```",
      "> Sometimes `--hallucination_silence_threshold` makes whole non-hallucinating segments or part of segments disappear.\r\n\r\nThis logic is part of the original Whisper strategy of advancing by the full 30 seconds to the next window whenever the current segment is unfinished. So basically, if the segment finishes before the end of the 30 second window, then Whisper will crop the window to the exact end timestamp of the last word in that segment. But if the segment does not finish by the end of the 30 second window, the window is not cropped, the speech is assumed to run all the way to the end of the window.\r\n\r\nThis logic exists whether or not the `hallucination_silence_threshold` is enabled, and I have seen it cause problems in both cases, however the larger models tend to be better at picking up the words across the window boundary.\r\n\r\nIn your case, the sentence in question is:\r\n\r\n> White tigers carry a mutated version of this gene, which prevents them from producing orange pigmentation.\r\n\r\nThis sentence does not fit within the 30 second window, and the word \"orange\" is right on the boundary. In fact, the word \"orange\" is slightly before the boundary and the human ear can pick it up (as can the larger models) but the smaller models fail to pick it up.\r\n\r\nAnd given Whisper's logic in this case, it will assume the speech went right up to the end of the 30 second window and will resume the next window from there.\r\n\r\nSo although yes the large models would probably resolve this, I think it would still be better to change Whisper's strategy and crop the window to the end timestamp of the last word even in this case where we have an unfinished segment.",
      "> This logic is part of the original Whisper strategy of advancing by the full 30 seconds to the next window whenever the current segment is unfinished.\r\n\r\nI can't connect the dots...\r\nThen why it's \"unfinished\" when using `hallucination_silence_threshold` and it's \"finished\" without it?\r\n\r\nHow `remaining_duration <= hallucination_silence_threshold` means an \"unfinished\" segment? The option doesn't read as \"finished/unfinished segment threshold\"....\r\n",
      "Apologies, my explanation of that was around the wrong way. The original Whisper behaviour was that if the last segment in the window is \"complete\", THEN it skips to the end of the full 30 second window. If the last segment is incomplete, then it crops the window to end timestamp of the last word.\r\n\r\nBut when `hallucination_silence_threshold` is set, it still applies this logic in most cases except that it also includes a misfired heuristic that skips to the end of the full 30 second window if the end of the speech is close enough to the end of the window:\r\n\r\n```python\r\n                # skip silence before possible hallucinations\r\n                if hallucination_silence_threshold is not None:\r\n                    threshold = hallucination_silence_threshold\r\n                    if not single_timestamp_ending:\r\n                        last_word_end = get_end(current_segments)\r\n                        if last_word_end is not None and last_word_end > time_offset:\r\n                            remaining_duration = window_end_time - last_word_end\r\n                            if remaining_duration > threshold:  # <--- misfired heuristic\r\n                                seek = round(last_word_end * FRAMES_PER_SECOND)\r\n                            else:\r\n                                seek = previous_seek + segment_size\r\n````\r\n\r\nThe goal was to skip over as much silence as safely possible.\r\n\r\nHowever, in hindsight, this was a bit opportunistic, since after all `single_timestamp_ending` was `False` for good reason. You should find your example will work if you remove that heuristic. i.e. Delete this entire section:\r\n\r\n```python\r\n                    if not single_timestamp_ending:\r\n                        last_word_end = get_end(current_segments)\r\n                        if last_word_end is not None and last_word_end > time_offset:\r\n                            remaining_duration = window_end_time - last_word_end\r\n                            if remaining_duration > threshold:  # <--- misfired heuristic\r\n                                seek = round(last_word_end * FRAMES_PER_SECOND)\r\n                            else:\r\n                                seek = previous_seek + segment_size\r\n```\r\n\r\n(It's OK, the other parts of this code block are already handled elsewhere.)",
      "I've created a PR #2043 incorporating the above fix based on your counter example.",
      "Thanks for explanation, now this part of code makes sense.\r\nDo you have idea why seek in the last window can be affected by PR? -> https://github.com/openai/whisper/pull/1838#issuecomment-1960581637\r\n\r\n> The goal was to skip over as much silence as safely possible.\r\n\r\nImho, skipping to full 30s window is pretty unsafe.  üòÜ\r\nAnd it contradicted the description: \"skip silent periods longer than this threshold (in seconds) **when a possible hallucination is detected**\"",
      "> Do you have idea why seek in the last window can be affected by PR? -> https://github.com/openai/whisper/pull/1838#issuecomment-1960581637\r\n\r\nDo you have an audio file to reproduce?",
      "> Do you have an audio file to reproduce?\r\n\r\nThis file has discrepancy in the last window/chunk:\r\nt-001.mka -> https://we.tl/t-ecd6U1QaZp\r\n`--language en --model=base --beam_size 1 --word_timestamps=True`\r\n\r\nWhisper without this PR:\r\n```\r\n[01:53.920 --> 01:54.500]  I'll give you some advice.\r\n[01:59.500 --> 02:00.080]  I'll give you some advice.\r\n[02:00.080 --> 02:00.080]  I'll give you some advice.\r\n[02:00.080 --> 02:00.980]  Say the word, General.\r\n[02:02.300 --> 02:03.320]  Let him go.\r\n```\r\nWhisper with this PR:\r\n```\r\n[01:53.920 --> 01:55.200]  I'll give you some advice.\r\n[01:59.500 --> 02:00.980]  Say the word, General.\r\n[02:02.280 --> 02:03.320]  Let him go.\r\n```\r\n",
      "I'll test tomorrow, but does this also happen on PR https://github.com/openai/whisper/pull/2043 ?",
      "> I'll test tomorrow, but does this also happen on PR #2043 ?\r\n\r\nYes, because `hallucination_silence_threshold` option is not relevant for the issue.\r\n\r\nCulprit affecting only the last window is found. it happens because of this:\r\n```python\r\n            mel_segment = mel[:, seek : seek + segment_size]\r\n```\r\n\r\nThis is the fix [that's how it was before this PR]:\r\n```python\r\n            mel_segment = mel[:, seek : seek + N_FRAMES]\r\n```\r\n\r\nNot sure why you changed it, on my observation it makes more hallucinations [probably it's random].\r\nAnyway, the fix brings back the previous behavior.",
      "That is changed for `--cilp_timestamps` because parts of the audio that are clipped out should not be included in the mel spectrogram. I'll take a look at your test scenario to see what's going on.",
      "I've confirmed the discrepancy, which seems to be a consequence of slightly different mel spectrograms. Although in the two examples you gave (only the latter of which I have tested with the supplied audio file), the PR actually removed a hallucination on one example and introduced a hallucination on the other example. So on balance, it's hard to say whether this discrepancy it better or worse or about the same.\r\n\r\nSo if it's not clear whether it's better or worse, do you see anything incorrect in the clipping logic? I think the difference is that I am always clipping exactly to the stretch of audio being examined, and then padding it. But originally, there was padding on the end that was added immediately when the mel spectrogram was first generated, and then (in the original code), it is also possible that due to the dynamic shifting of the window starts, it could end up padding the last part of the audio twice, because there is no guarantee that that initial padding Whisper added at the start of the process was enough to reflect where this last window ended up actually starting.\r\n\r\nBut it's possible I've done something wrong which I can't see, so let me know if you do spot something incorrect in the logic.",
      "After plotting the mel spectrograms, I noticed the padding when the audio is first loaded (as a whole) contains all -1.0's, while the padding in the main loop for each 30 second window contains all 0.0's. Not sure why that is, but there are two different padding algorithms in the code, and weirdly they are producing different padding results.\r\n\r\nSo in your example, the PR ends up always using the padding algorithm that pads to 0.0's whereas originally the end of file padding had -1.0's. ",
      "There's still a chance that a hallucination will be produced.\r\nFor me it was:\r\n```\r\n[02:15:58.100 --> 02:16:05.380]  —è –≤–∞–º –≤—ã—à–ª—é. –í—Å–µ–≥–æ –¥–æ–±—Ä–æ–≥–æ, –¥–æ —Å–≤–∏–¥–∞–Ω–∏—è.\r\n[02:16:28.100 --> 02:16:30.100]  –†–µ–¥–∞–∫—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –ò.–ë–æ–π–∫–æ–≤–∞\r\n```\r\ni. e.\r\n```\r\n....\r\n[02:16:28.100 --> 02:16:30.100] Subtitle Editor I. Boykova\r\n```\r\nNotably, this timestamp belongs to the end of the audio.\r\n\r\nModel size: small. Also there are some results in google, if you search for this phrase. One of them:\r\n```\r\n[24:26.800 --> 24:30.160]  –°–º–æ—Ç—Ä–∏—Ç–µ —Ç–µ–ª–µ–±–∞—Ä–æ–º–µ—Ç—Ä –Ω–∞ –Ω–∞—à–µ–º —Ç–µ–ª–µ–∫–∞–Ω–∞–ª–µ.\r\n[24:30.160 --> 24:32.160]  –†–µ–¥–∞–∫—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –ò.–ë–æ–π–∫–æ–≤–∞\r\n[24:32.160 --> 24:39.160]  –ö–æ—Ä—Ä–µ–∫—Ç–æ—Ä –ê.–ö—É–ª–∞–∫–æ–≤–∞\r\n```\r\nfrom https://storage.googleapis.com/data.gdeltproject.org/blog/2022-tv-news-whisperasr/BELARUSTV_20221005_161500.small.transcribe.run1.txt",
      "That's certainly possible, and unfortunately there is no single choice of parameters that will be perfect in all scenarios. You can tweak the silence threshold, which is exposed on the command line. You can also try tweaking the other thresholds that were built into the code (like how long a word must be before it is flagged as an abnormality). If we can gather a large enough dataset of audio samples that produce hallucinations, we should be able to come up with better default settings that work well across a variety of scenarios and languages.",
      "@ryanheise \r\nI was using a bit tweaked segment anomaly heuristics to reduce false-positives, didn't noticed increase of false-negatives:\r\n\r\nchanged\r\n `if duration < 0.133:`\r\nto:\r\n`if duration < 0.133 and probability < 0.8:`\r\n\r\nchanged\r\n`return score >= 3 or score + 0.01 >= len(words)`\r\nto:\r\n`return score >= 3 or score + 0.001 >= len(words)`\r\n\r\nWhat you think about this tweak?",
      "Unfortunately I'm between computers right now (my old computer died 2 weeks ago, and I'm just in the process of installing everything on the recently arrived replacement...)\r\n\r\n>  return score >= 3 or score + 0.001 >= len(words)\r\n\r\nI don't see any problem with that change.\r\n\r\n>  `if duration < 0.133 and probability < 0.8:`\r\n\r\nDo you have an example audio for this one? I'd be interested to analyse this correlation between duration < 0.133 and probability < 0.8.\r\n\r\nThe alternative is to take into account more observations (like your audio example) and try to fit a new curve to the data. I initially fitted a simple linear curve, and maybe exponential could help because it could model a slower initial gradient."
    ],
    "num_comments": 27,
    "repository": "openai/whisper",
    "diff_length": 13328
  },
  {
    "index": 38,
    "pr_title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "pr_body": "Obviously not meant to land, this RP is representative of what it would take to get dynamo working.\r\n\r\ntest_me.py takes 4.4 seconds on main branch\r\ntest_me.py takes 3.2 seconds in this PR\r\n\r\n**Overview:**\r\n1) I took some free audio book of chapter 1 of Charles Dickens' David Copperfield\r\n2) I used an mp3 splitting tool to split it into 8 parts, and then used the util in the model to get 10 chunks of 30 seconds each\r\n3) I \"preheated\" the model with audio part 0, and then ran inference on the othe",
    "pr_number": 43,
    "comments": [
      "For those who haven't heard of [TorchDynamo/TorchInductor](https://github.com/pytorch/torchdynamo), it is automatically fusing and mapping PyTorch to [Triton](https://github.com/openai/triton).",
      "This sounds great! I was also wondering how fast it'd be if [Triton's flash attention](https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py) was integrated, but unfortunately it's A100 only.\r\n\r\nImplementation-wise, I think we could subclass the class `PyTorchInference(Inference):` and monkey-patch the attention layers only when TorchDynamo is available, so that the code is still usable in the older PyTorch versions.",
      "> This sounds great! I was also wondering how fast it'd be if [Triton's flash attention](https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py) was integrated, but unfortunately it's A100 only.\r\n> \r\n> Implementation-wise, I think we could subclass the class `PyTorchInference(Inference):` and monkey-patch the attention layers only when TorchDynamo is available, so that the code is still usable in the older PyTorch versions.\r\n\r\nThat sounds awesome. I'd love to do that. I'm in the pytorch slack and the triton slack - would you like to chat there? I also have further questions on getting a little bit of realistic inference data so we can setup a benchmark on our end (As well as to better measure accuracy). The adhoc free audiobook approach isn't scaling super well, hah. ",
      "do you have more benchmarks? for example, on cpu.",
      "> do you have more benchmarks? for example, on cpu.\r\n\r\nNo, I am sorry, I do not. I plan on working with @jongwook to benchmark this properly :) ",
      "This is the RFC - The implementation PR will be here: https://github.com/openai/whisper/pull/115",
      "@voznesenskym I am curious why you guys started with \"torchdynamo\" instead of more widely-adopted \"torchscript\". We are in the process of making this torch.jit compatible, so I was wondering whether torchscript is slower in comparison.",
      "> @voznesenskym I am curious why you guys started with \"torchdynamo\" instead of more widely-adopted \"torchscript\". We are in the process of making this torch.jit compatible, so I was wondering whether torchscript is slower in comparison.\r\n\r\nTorchDynamo and torchscript are fundamentally different projects, and we are investing in TorchDynamo as a next gen core component of our stack. While their surface levels goals (in this case, speed) align, they are rather different. I am happy to go into it more, but the ReadMe in the TorchDynamo project goes into great depths about what the project is. Have you had a chance to read that yet? ",
      "@taylorchu I definitely recommend in going the torchdynamo route than `torch.jit`. it's more aligned with our future plans.",
      "@soumith @voznesenskym  is the torch team plan for torchdynamo or torch.jit written some where? \r\n\r\nI am interested in whether one will choose one over the other in certain use cases. ",
      "not written down anywhere concretely, we'll talk about it in a few months.\r\nBut about dynamo itself, we have quite a few posts here with various updates: https://dev-discuss.pytorch.org/",
      "Just in case. I can provide a large set of data transcribed by whisper so that you guys can validate whether the change affects the text output. ",
      "@voznesenskym I am trying to benchmark your approach with torchdynamo but got some error modules.  do you know which version torchinductor, torchdynamo and triton are used to make your modification work?  ",
      "> @voznesenskym I am trying to benchmark your approach with torchdynamo but got some error modules. do you know which version torchinductor, torchdynamo and triton are used to make your modification work?\r\n\r\nHey, dynamo migrated to latest triton, so we maybe have some new errors here, but the torchdynamo Makefile https://github.com/pytorch/torchdynamo/blob/main/Makefile has the versions of all our deps (usually cutting edge nightlies).\r\n\r\nI plan to revisit this shortly, and will fix up any errors I find. ",
      "Thanks, I'll close this for now, since it doesn't quite yet work \"out of the box\" and relying on nightly versions makes things difficult for me to maintain. I'm hoping to get an easier integration with the stable PyTorch 2 interface once it's out."
    ],
    "num_comments": 15,
    "repository": "openai/whisper",
    "diff_length": 30214
  },
  {
    "index": 39,
    "pr_title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "pr_body": "",
    "pr_number": 1052,
    "comments": [
      "Hi @jongwook Not sure if you saw the comment below, but it includes a reproduction case which might be useful:\r\n\r\nhttps://github.com/openai/whisper/pull/869#issuecomment-1445024980\r\n\r\nThe repetition persists with this PR.",
      "@ryanheise thanks! will look into it...",
      "The problem triggered by the test data from @ryanheise is model sensitive. I see the problem with `small` but using either `small.en` or `medium.en` looks ok although the timing of the last few words is off. Below is the mp3 fragment converted to video to show the English subtitles.\r\n\r\nhttps://user-images.githubusercontent.com/3035114/223597998-74a8ec7f-da0b-4948-9f6a-75712820eb15.mp4\r\n\r\n\r\n",
      "Thanks all! The incorrect zero-padding of Mel spectrograms as identified in #730 and #838 was contributing to this error. The fix in 477f0be appears to fix the repetition issue.",
      "> The fix in https://github.com/openai/whisper/commit/477f0befc76456c37b2d2f484095f803592c90fa appears to fix the repetition issue.\r\n\r\nI can confirm this fixed my example, thanks! :+1:\r\n\r\n> Below is the mp3 fragment converted to video to show the English subtitles.\r\n\r\n@glangford FYI the subtitles didn't show in your video.",
      "@ryanheise Inline, (on Mac at least) you may need to click on the >> on the right to turn on subtitles. Or download and view with VLC, Quicktime, or whatever and enable subtitles in the viewer.",
      "Ah, I see, Firefox doesn't show any options, but downloading it and opening in VLC works. You can also do hard subs this way https://github.com/openai/whisper/discussions/435#discussioncomment-4238872\r\n\r\n> using either `small.en` or `medium.en` looks ok although the timing of the last few words is off.\r\n\r\nHere is the `base` model for comparison, which appears more accurate on the last few words:\r\n\r\nhttps://user-images.githubusercontent.com/19899190/223708621-c4b53230-171c-4e92-871f-4c5f390425a1.mp4",
      "Btw have you guys tried with longer audio, e.g. 5 mins long? I am still getting a lot of repetition even with this fix.\r\nE.g. on the TEDLIUM test set \"AimeeMullins_2009P.wav\"\r\n>[02:10.440 --> 02:14.720]  and needless to say, thank God, I wasn't using a thesaurus back then.\r\n[02:14.720 --> 02:14.720]  and needless to say, thank God, I wasn't using a thesaurus back then.\r\n[02:15.460 --> 02:18.580]  I mean from this entry, it would seem that\r\n[02:18.580 --> 02:22.800]  I was born into a world that perceived someone like me\r\n[02:22.800 --> 02:23.340]  I was born into a world that perceived someone like me\r\n[02:23.340 --> 02:27.540]  to have nothing positive, whatsoever, going for them\r\n[02:27.540 --> 02:27.540]  to have nothing positive, whatsoever, going for them\r\n[02:27.540 --> 02:35.340]  When in fact today, I'm celebrated for the opportunities and adventures my life has procured\r\n[02:35.340 --> 02:35.960]  When in fact today, I'm celebrated for the opportunities and adventures my life has procured\r\n[02:35.960 --> 02:42.140]  So I immediately went to look up the 2009 online edition\r\n[02:42.140 --> 02:42.160]  So I immediately went to look up the 2009 online edition\r\n[02:42.160 --> 02:42.160]  So I immediately went to look up the 2009 online edition\r\n\r\nI was hoping to update word segmentation results for whisper-only word timestamps in our paper https://arxiv.org/abs/2303.00747\r\n\r\nBut currently i am getting better results with our implementation which is similar to https://github.com/linto-ai/whisper-timestamped\r\n",
      "> Btw have you guys tried with longer audio, e.g. 5 mins long? I am still getting a lot of repetition even with this fix.\r\n\r\nI am testing a longer audio now (running on CPU, larger model, transcript+transcribe so it is taking a while). For clarity,\r\n* are you running the 20230307 release version? with, or without `--word_timestamps`?\r\n* the repetitions from \"AimeeMullins_2009P.wav\" above, are they from verbose print to the console? \r\n\r\nIt seems like there are different possible sources of error, in all the different discussions\r\n* model hallucination\r\n* new repetition introduced or magnified by `--word_timestamps True`\r\n* (hand waving) segmentation issues",
      "> are you running the 20230307 release version? with, or without --word_timestamps?\r\n\r\nyes\r\n\r\n> the repetitions from \"AimeeMullins_2009P.wav\" above, are they from verbose print to the console?\r\n\r\nyes\r\n\r\n",
      "@jongwook Note from @m-bain example above the repetition occurring with verbose print. The repetitions in this example are all \"instantaneous\" ; eg same start and end time\r\n> [02:14.720 --> 02:14.720] and needless to say, thank God, I wasn't using a thesaurus back then.\r\n\r\nthey are printed but then immediately cleared by this code, which looks like a bug unique to `--verbose True`\r\n\r\nhttps://github.com/openai/whisper/blob/aac47c98349b98cec5ca7b1be53960fb59f4436b/whisper/transcribe.py#L345",
      "@m-bain Given this could you maybe rerun and see if the formal output formats are messed up or not, using `--verbose False`?",
      "This is not a verbose error, and the start times and end times of repetition are not always instantaneous, see output for the .srt file without verbose:\r\n\r\n271\r\n00:02:14,440 --> 00:02:14,720\r\nand needless to say, thank God, I wasn't using a thesaurus back<u> then.</u>\r\n\r\n272\r\n00:02:14,720 --> 00:02:14,720\r\n\r\n\r\n273\r\n00:02:15,460 --> 00:02:16,180\r\n<u>I</u> mean from this entry, it would seem that\r\n\r\n274\r\n00:02:16,180 --> 00:02:16,360\r\nI<u> mean</u> from this entry, it would seem that\r\n\r\n275\r\n00:02:16,360 --> 00:02:16,960\r\nI mean<u> from</u> this entry, it would seem that\r\n\r\n276\r\n00:02:16,960 --> 00:02:17,220\r\nI mean from<u> this</u> entry, it would seem that\r\n\r\n277\r\n00:02:17,220 --> 00:02:17,620\r\nI mean from this<u> entry,</u> it would seem that\r\n\r\n278\r\n00:02:17,620 --> 00:02:17,800\r\nI mean from this entry, it would seem that\r\n>",
      "So there are at least two problems then\r\n* verbose mode can print cleared segments\r\n* something else triggered by word_timestamps\r\n\r\nGiven how close the start/end times are it feels like something related to `seek_shift` is still off\r\nhttps://github.com/openai/whisper/blob/aac47c98349b98cec5ca7b1be53960fb59f4436b/whisper/transcribe.py#L337\r\n\r\n@m-bain Do the same repetitions happen with `word_timestamps False` or no? ",
      "Update, I realise there is some specific underline formatting in the word_timestamps, was able to get it working in the end. See here for comparison on word-level timestamp accuracy\r\n\r\n![image](https://user-images.githubusercontent.com/36994049/224011580-4782f2ad-a178-4b2d-80c3-4baa8ca54ab9.png)\r\n\r\n@jongwook could you share the evaluation for long-form transcription WER? I am unable to reproduce whisper results, right now I report in the vanilla setting -- greedy/beam5 decoding without the heuristic tricks\r\n"
    ],
    "num_comments": 15,
    "repository": "openai/whisper",
    "diff_length": 6338
  },
  {
    "index": 40,
    "pr_title": "Per Token Confidence + Color terminal example",
    "pr_body": "Hello!\r\nI implemented per-token confidence scores and also added a little example under examples/confidence_per_token.py, where you get a fancy colored text output resembling the confidence score of each token:\r\n\r\n\r\n(image incorrect, look at last commented image)\r\n![image](https://user-images.githubusercontent.com/43215895/226175988-e18657f4-589a-422d-a93c-6f3139648eaf.png)\r\nExample WAV: https://www.voiptroubleshooter.com/open_speech/american/OSR_us_000_0010_8k.wav\r\n\r\n\r\nI am aware of the work of",
    "pr_number": 1119,
    "comments": [
      "EDIT: Done\r\n\r\nTODO: correct propability display when supplying prompts (prompt tokens seem to get assigned prob of 0, if anyone can please help, I'd appreciate it)",
      "Fixed probs offset (and prompt offset)\r\n\r\nNew (correct) output:\r\n![image](https://user-images.githubusercontent.com/43215895/227074244-58d15f24-2a25-4302-a1f9-068bd8d01d6f.png)\r\n",
      "This can be really useful for proofing the output via something like Subtitle Edit.  \r\n\r\nWould really need an command line option to output an additional subtitle though, right?  \r\n\r\nI get the impression @jongwook doesn't want to stuff too many features in though, so how does such a useful feature get added without having a fork?",
      "> I get the impression @jongwook doesn't want to stuff too many features in\r\n\r\nAlthough the colour terminal stuff might be questionable, I think adding per-token timestamps and confidence to the raw JSON results could itself be useful to a wider range of use cases. Exposing the raw data from Whisper would then make it possible to write your own external script on top of that to do the colour terminal staff.\r\n\r\nOne example of the wider potential uses of per-token data is that German is known to have very long compound words, and if you wanted to break them up (e.g. to compute a line break timestamp, or for sub-word highlighting, etc.), it would be helpful to have access to the raw data per token.",
      "Hello!\r\n\r\n> Although the colour terminal stuff might be questionable\r\n\r\nI implemented the per-token confidence as is and implemented the colorful CLI output only in an example.\r\nThe main whisper code does not contain anything with color\r\n\r\n@jongwook is there anything I should modify or change for you to accept the PR? ",
      "I'm hesitant to add this because the incremental utility of this compared to the probabilities returned by `word_timestamps=True` is quite niche, versus the added complexity & latency due to the additional GPU operations. The decoding logic is already taking as much as the forward pass, and I'm hoping to reduce this overhead. The subword token probabilities are not very useful anyway, because it's usually influenced more by language modeling than from speech recognition.\r\n\r\nFor the case you need per-token probs, you can add another forward pass without modifying decoding.py (similar to how it's done in [timing.py](https://github.com/openai/whisper/blob/76c901ab8d4558992c44138479c4d69eb52fadcb/whisper/timing.py#L197)) without incurring too much additional latency. It may even be faster than adding GPU operations for every autoregressive step.\r\n\r\nThe example script looks nifty, but i'd prefer it in the [show and tell](https://github.com/openai/whisper/discussions/categories/show-and-tell) section.",
      "I see, thank you for the comprehensive response!",
      "@SinanAkkoyun thanks for your contribution. Not sure, but seems it works incorrect, \r\nI made distorted speech example https://drive.google.com/file/d/12zGWllJg6edftcnwuHX_ZHMuwk7PlVjg/view?usp=sharing .\r\nIf I don't set the language of decoding i.e. `options = whisper.DecodingOptions() `,  the output is correct in terms of locating mispronounce (I can read this slavic) though it translates it to random language.\r\n![Screenshot from 2023-08-09 10-58-49](https://github.com/openai/whisper/assets/54935496/cf45eaab-1799-45d0-a386-2fc2e3076b1a)\r\n\r\nBut if I set 'en' for decoding  `options = whisper.DecodingOptions(language=\"en\")` the picture is wrong.\r\n![Screenshot from 2023-08-09 10-58-53](https://github.com/openai/whisper/assets/54935496/8c009a46-ec4d-4a47-abe3-786408580857)\r\n The rest of the code is the same as in your PR except I used \"small\" model.\r\n",
      "@Rtut654 Hi, I don't quite understand the issue you are having, the \"I like to play badminton and football.\" seems to be correct, the football especially sounds vague in the audio you provided. Could you please tell me more about your issue?\r\n\r\nDespite that, the PR is not going to get merged, so I stopped working on it and use that modification in my own work which does not include translation\r\n\r\nIf the random translation is the problem you are referring to, I believe that my PR did not modify nor change the output prediction by any means, it just grabbed the logits and displays them as confidence",
      "@SinanAkkoyun \r\nThe issue is in the accuracy of token_probs. The first version (with translation to Ukrainian) gives very accurate result since \"like\" was also mispronounced very much. Also the word \"football \" was mispronounced in the last part which is correctly shown in the first picture. \r\n\r\nI did the same test with other audio, setting language of decoding to English.  The picture was same. Somehow it is lowering the prob of the last word even when it is pronounced correctly. At the same time probs of mispronounciations were high which is strange. So something is wrong in the way it predicts probs when language is set to English.",
      "Hello, @jongwook ! Could you please look at the issue?",
      "@Rtut654 Ah I see, I am sorry but in my testing I was not able to reproduce that behaviour, for me it seemed very fine in regards to unclear spoken words and clearly spoken words, even in german transcriptions.\r\nTo me, the football sounded unclearer than the rest, my code does not do much except that it takes the unmodified logits. Maybe the model has a different sense of misspronunciation than you? It has been trained on many accents.\r\n\r\nI currently am working on other projects, you can take a look at the file changes yourself and work your way through, if you have a question feel free to ask and I will give my best to clarify",
      "In case it's of interest, I created a small web component to view the Whisper JSON file when `--word_timestamps` has been used. Ideas for improving it would be welcome!\r\n\r\nhttps://edsu.github.io/whisper-transcript/"
    ],
    "num_comments": 13,
    "repository": "openai/whisper",
    "diff_length": 9839
  },
  {
    "index": 41,
    "pr_title": "add always_use_initial_prompt",
    "pr_body": "    always_use_initial_prompt: bool\r\n        if True, the initial_prompt will be used to all windows, and condition_on_previous_text\r\n        will be ignored. Enabling this may make the text more consistent if the audio is long\r\n        and you set the initial_prompt properly.",
    "pr_number": 1040,
    "comments": [
      "I think some variation on this idea might help it to remember your prompting in long audio, but when a window boundary occurs mid sentence, I think it's also important to have the previous text as the prompt.\r\n\r\nAs a compromise, have you thought about truncating the previous text at a sentence boundary and then prepending the initial prompt before that? It might be the best of both worlds.",
      "> I think some variation on this idea might help it to remember your prompting in long audio, but when a window boundary occurs mid sentence, I think it's also important to have the previous text as the prompt.\r\n> \r\n> As a compromise, have you thought about truncating the previous text at a sentence boundary and then prepending the initial prompt before that? It might be the best of both worlds.\r\n\r\nI agree, but I don't know how to do that.",
      "A really cheap modification might be to add a check here:\r\n\r\n```python\r\n            if not condition_on_previous_text or result.temperature > 0.5:\r\n                # do not feed the prompt tokens if a high temperature was used\r\n                prompt_reset_since = len(all_tokens)\r\n```\r\n\r\nso that you also check if your option is enabled and if the latest token ends with one of these characters `\".„ÄÇ!ÔºÅ?Ôºü\"`, effectively resetting the prompt after every sentence boundary. Then when feeding the prompt:\r\n\r\n```python\r\n            decode_options[\"prompt\"] = all_tokens[prompt_reset_since:]\r\n```\r\n\r\nIf your option is enabled you could prepend the initial prompt here.\r\n\r\nBUT, I think it might be more useful to parameterise how many previous sentences back to include in the prompt. For that the code would be a bit more complicated. But you could keep a FIFO buffer, e.g. to remember the last 3 sentences, you have a FIFO of size 3 containing the last 3 sentence boundary positions, which you put into the FIFO under the same condition as that first block of code above. The oldest sentence boundary gets popped out so you never have more than the last 3 in there.",
      "I use whisper ai for audio transcription and translation but since 25 February  it is not transcribing and Translating clearly !!!               I would be happy if anybody help me. plz ",
      "@ryanheise note that this code in `decoding.py:594` truncates the list of all prompt tokens (from the beginning), not the end. That means that simply prepending without checking for prompt window length will not always work. Truncation size depends on the model config.\r\n\r\n`tokens = ( [self.tokenizer.sot_prev] + prompt_tokens[-(self.n_ctx // 2 - 1) :] + tokens )`",
      "the output after this is just amazing\r\n\r\ni dont get why this is still not implemented ",
      "@mercury233 it is hallucinating significantly after this change. anyway to prevent it? other than that it works great. you found a solution for hallucination ? I can use very big beam size and best of but they didnt help. ",
      "> ```python\r\n>  not condition_on_previous_text or result.temperature > 0.5\r\n> ```\r\n\r\ncan you share modified file like this? i would like to test. currently it is having problems ",
      "yes with this way it is skipping 30 second blocks sometimes. we need optimization.  @mercury233 @ryanheise @radurevutchi ",
      "> @mercury233 it is hallucinating significantly after this change. anyway to prevent it? \r\n\r\nSorry, I didn't",
      "I have used the same basic idea of applying the initial prompt to every window to supply a dictionary of obscure words that might be in the transcript. It's very effective at boosting recognition of some words. However, I don't see it as in opposition to condition_on_previous text; the basic idea of using context from the end of the previous window to influence understanding of the beginning of the next window is still valuable."
    ],
    "num_comments": 11,
    "repository": "openai/whisper",
    "diff_length": 3029
  },
  {
    "index": 42,
    "pr_title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "pr_body": "The 'no' language code is a obsolete language code that is the union of language codes 'nb' (Norwegian Bokm√•l) and 'nn' (Norwegian Nynorsk), the two written variants in use in Norway.  As 'no' is misleading, and seem to be used by Whisper to mean Norwegian Bokm√•l, I recommend replacing it with 'nb' and using the full names for both of the norwegian written forms.\r\n\r\nUseful references:\r\n\r\n * https://linguistics.stackexchange.com/questions/36784/norwegian-translation-codes-no-nn-nb-which-to-use-on",
    "pr_number": 1250,
    "comments": [
      "From my understanding, this may be similar to Chinese which also has multiple written variants, although Chinese also has multiple spoken dialects. The way Whisper was trained, it was trained on all of these written and spoken variants under the umbrella of \"Chinese\", and so ultimately a single language code has to describe all of these. Since there is only one language code for Chinese, the way you get it to transcribe for a particular variant is therefore not by specifying a different language but by using the same language code and then using a prompt to get it off on the right foot with the variant. It may not be a strictly correct use of language codes, but the training is already done that way.\r\n\r\nI haven't tried transcribing Norwegian, but is it similar in that Whisper contains training data for both writing systems under a single umbrella of \"no\" which can be accessed by using a prompt to set it off in one of those two directions? If so, I'm not sure if changing it to \"nb\" would make sense.",
      "[ryanheise]\n> From my understanding, this may be similar to Chinese which also has\n> multiple written variants, although Chinese also has multiple spoken\n> dialects.\n\nI believed China had several distinct languages with their own written\nlanguage as well as the written Mandarin standardized across the\ncountry, in addition to a lot of dialects of the different languages.\n\n> I haven't tried transcribing Norwegian, but is it similar in that\n> Whisper contains training data for both writing systems under a single\n> umbrella of \"no\" which can be accessed by using a prompt to set it off\n> in one of those two directions? If so, I'm not sure if changing it to\n> \"nb\" would make sense.\n\nThe transcribing I have tested so far gave me Norwegian Bokm√•l.  Not\nsure how to to prompt it to switch to Norwegian Nynorsk.\n\n-- \nHappy hacking\nPetter Reinholdtsen\n",
      "You can try using `--initial_prompt \"Some introductory pre-sentence written in the Norwegian Nynorsk script.\"`\r\n\r\nSo you just write a made-up sentence in the script you want, and you might get better results if it is a sentence that you could plausibly imagine as having been spoken before the first actual sentence in the audio you're transcribing.",
      "The rest of the world uses no and doing this change would result in numerous posts all over the world asking why -no doesn't work. Not to mention the hundreds of guides and copies of documentation the uses -no\r\n\r\nAs a minimum -no should be kept for legacy support and nn and nb should only be implemented if whisper actually knows the difference.",
      "There are for sure quite a few using the Norwegian language codes incorrectly, or confuse the country and language code.  Because of this it is a good idea to keep the incorrect 'no' language code still working as an alias, probably for the W3C recommended 'nb' code.\r\n\r\nIn any case, if Whisper is unable to know the difference between Nynorsk and Bokm√•l, I guess the entire question is moot.",
      "> You can try using `--initial_prompt \"Some introductory pre-sentence written in the Norwegian Nynorsk script.\"`\r\n\r\nBy the way, did you get around to trying this?",
      "\n[ryanheise]\n> By the way, did you get around to trying this?\n\nI did, running this using a random nynorsk piece on youtube,\n<URL: https://yewtu.be/watch?v=s7olTWEIwAI >.\n\n  whisper --model medium Are\\ Kalv√∏\\ -\\ K√•seri\\ om\\ nynorsk\\ \\[s7olTWEIwAI\\].webm --language Nynorsk --initial_prompt \"eg heitar\"\n\nSadly the resulting transcription is of very low quality:\n\n  Den st√∏rste fordelen me √• bruke ny norsk er at det gj√¶r det lett √•\n  framst√• som langt meir intresang enn du faktisk er.  For oss som\n  koserer er det for eksempel helt opplagt enn fordel √• bruke ny norsk.\n\nThere are several typos and inaccuracies here at the start of the\nrecording. :)\n\n-- \nHappy hacking\nPetter Reinholdtsen\n",
      "Normally I would say that \"eg heitar\" isn't actually a pre-sentence, it's only two words, no full stop at the end, etc. and probably not a great prompt to teach Whisper what style to continue in. Although that being said, I don't hold out any hopes that it will work well if you're getting typos. That feels like there's limited training data for that script.",
      "We originally collected the language tags from the [VoxLingua107](https://bark.phon.ioc.ee/voxlingua107/) dataset, but 100% of the transcription data had `no`, and no `nn` label. We had some `nn` labels in the translation data, but I guess that's less relevant when the input is spoken Norwegian and output is English.\r\n\r\nSo the labeling was a bit haphazard, but I think it still makes sense to keep the macrolanguage label `no`, considering that that labels would've contained a mixture of Bokm√•l and Nynorsk. (It appears that most were in Bokm√•l though, as the Nynorsk prompting example above didn't work very well unfortunately.)",
      "\n[Jong Wook Kim]\n> We originally collected the language tags from the\n> [VoxLingua107](https://bark.phon.ioc.ee/voxlingua107/) dataset, but\n> 100% of the transcription data had `no`, and no `nn` label. We had\n> some `nn` labels in the translation data, but I guess that's less\n> relevant when the input is spoken Norwegian and output is English.\n\nThis is not really surprising that Voxlingual07 used 'no', given that it\nstates \"VoxLingua107 is a speech dataset for training spoken language\nidentification models.\"  There is a difference between language codes\nfor spoken language and written language in Norway.  The Norwegian\nBokm√•l and Nynorsk are written languages, while the spoken language is a\ndialect of Norwegian.  So all written Norwegian should use either 'nb'\nor 'nn', and spoken language could use 'no'.  If you only found 'no' in\ntranscription data, the transcriptions are misclassified, and most\nlikely should have been classified as 'nb', the written variant used by\nmost people in Norway.\n\n> So the labeling was a bit haphazard, but I think it still makes sense\n> to keep the macrolanguage label `no`, considering that that labels\n> would've contained a mixture of Bokm√•l and Nynorsk. (It appears that\n> most were in Bokm√•l though, as the Nynorsk prompting example above\n> didn't work very well unfortunately.)\n\nYeah.  Hope someone can do a better job at training a system to write\nNorwegian Bokm√•l and Nynorsk with the correct classicication in the\nfuture.  At least the issue is better known in the Whisper community\nnow.\n\nNote, there are ways to fairly accurately detect if the written text is\nNynorsk or Bokm√•l by looking for marker words like 'jeg'(nb) vs 'eg'(nn)\nog 'en'(nb) vs 'ein'(nn).\n\n-- \nHappy hacking\nPetter Reinholdtsen\n",
      "I was looking into this recently and one approach to work around Whisper's inclination toward Bokm√•l (based on its training data for `no`) would be to just use a separate tool to convert Whisper's Bokm√•l output into Nynorsk in post processing.\r\n\r\nFor example, [Apertium](https://www.apertium.org/) can be used, and can be installed locally (making it also helpful for automated pipelines).\r\n\r\nThe specific Bokm√•l/Nynorsk module for Apertium is [here](https://github.com/apertium/apertium-nno-nob), including some examples of its output.\r\n\r\nFor timestamps, the two scripts are at least textually similar enough to match them up (e.g. [Diff Match Patch](https://neil.fraser.name/software/diff_match_patch/demos/diff.html)). An easier way might be to just embed timestamps of the form 00:24:07 into the source text and see if Apertium preserves them in place without disrupting the translation process. It seems to work, but I haven't fully tested that.",
      "[ryanheise]\r\n> I was looking into this recently and one approach to work around\r\n> Whisper's inclination toward Bokm√•l (based on its training data for\r\n> `no`) would be to just use a separate tool to convert Whisper's Bokm√•l\r\n> output into Nynorsk in post processing.\r\n\r\nThis is a good point, and Apertium is doing a very good job as\r\nconverting Bokm√•l to Nynorsk.  But sadly it also require seriuos proof\r\nreading as it is far from perfect, according to the creator of the\r\nnb->nn Apertium transformer. :)\r\n\r\nIn any case, the main takeaway here is that the 'no' language code is\r\nfor a spoken language, while the 'nb' and 'nn' language codes are for\r\nwritten languages.\r\n\r\n-- \r\nHappy hacking\r\nPetter Reinholdtsen\r\n"
    ],
    "num_comments": 12,
    "repository": "openai/whisper",
    "diff_length": 744
  },
  {
    "index": 43,
    "pr_title": "Add support for AMD GPU (ROCm Platform)",
    "pr_body": "PyPI name of openAI Triton for ROCm Platform is pytorch-triton-rocm, so that modify setup.py to install correct Triton package for ROCm platform. Also modify README.md to add instruction to install on ROCm Platform. Tested on ROCm Platform with AMD GPUs.",
    "pr_number": 1473,
    "comments": [
      "Instead of using environment variable, i suggest to use `extras_require` as could be see in [here](https://setuptools.pypa.io/en/latest/userguide/dependency_management.html#optional-dependencies). Another option is to automatically detect if it is using ROCm platform.",
      "Based on the suggestion, remove environmental variable and add function to detect ROCm Platform automatically.",
      "Will this work with generic AMD gpus, ie newer integrated gpus?",
      "> Will this work with generic AMD gpus, ie newer integrated gpus?\r\n\r\n@x86Gr This is the list of supported GPUs\r\n\r\nhttps://rocm.docs.amd.com/en/latest/release/gpu_os_support.html",
      "@x86Gr @glangford \r\nThis link should work: https://rocm.docs.amd.com/en/latest/release/gpu_os_support.html#linux-supported-gpus\r\n",
      "Any particular reason the PR only selected a subset of supported AMD GPUs? \r\n\r\ngfx1030 or gfx1100 appear to be missing",
      "@vadimkantorov  @Reviewer  of this PR. Is there any update about review to merge  this PR? Is there  anything I can help to speed up the process?  Thanks!",
      "running `pip install .` on that branch shows me \r\n```\r\n% pip install .            \r\nProcessing <snip>whisper/whisper\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nINFO: pip is looking at multiple versions of openai-whisper to determine which version is compatible with other requirements. This could take a while.\r\nERROR: Could not find a version that satisfies the requirement pytorch-triton-rocm>=2.0.1 (from openai-whisper) (from versions: 0.0.1)\r\nERROR: No matching distribution found for pytorch-triton-rocm>=2.0.1\r\n```\r\nwhat am i missing here?\r\n\r\n--\r\nEdit:\r\nNevermind, `pip install --upgrade --no-deps torch pytorch-triton-rocm --index-url https://download.pytorch.org/whl/rocm6.2` solved it. Maybe we should add that to the readme?"
    ],
    "num_comments": 8,
    "repository": "openai/whisper",
    "diff_length": 404882
  },
  {
    "index": 44,
    "pr_title": "Add CSV formatted output in transcript, using integer start/end times in milliseconds.",
    "pr_body": "This PR adds CSV output to Whisper transcription similar to the way #102 added SRT subtitle formatted output.\r\n\r\nEach line of the resulting CSV file is formatted like:\r\n` <startTime-in-integer-milliseconds>, <endTime-in-integer-milliseconds>, \"<transcript-including-commas>\"`\r\n\r\nOne of the reasons for using integer millisecond timings is to avoid regional incompatibilities with writing and reading floating point timings across language regions which use different characters - either \".\" or \",\" - ",
    "pr_number": 228,
    "comments": [
      "The CSV seems to just multiply the range by 1000 to get ms resolution.  Could we please have actual ms resolution for the speakers?  If doing text-to-speech of a natural conversation, and trying to combine it with speaker recognition (pytorch for example), two persons may speak in the same second.  We don't know who said what.  Therefore, if we had ms resolution out of whisper, we could easily know who said what sentence in a natural conversation.",
      "To use Whisper for subtitles, Millisecond resolution would be a big plus. ",
      "@ksn-systems that is precisely why I made this change. See #233 for details.",
      "@jongwook  would it be possible to \"approve the workflow\" as I see this PR is stuck at \"1 workflow awaiting approval\".\r\n\r\nIs there anything I should change or clarify in order to get this PR merged or get the \"workflow awaiting approval\" to be satisfied?\r\n\r\nPlease note a similar PR was merged for whisper.cpp  ( https://github.com/ggerganov/whisper.cpp/pull/340 ). Having this functionality in place for whisper allows for easier comparison of results between implementations, via easier importing into spreadsheets and databases supporting the CSV format.",
      "@NielsMayer Thanks for the PR! Would it work for you if I make this `write_tsv` instead? CSV format is not standardized and `csv.reader` and `pandas.read_csv` often create headache parsing quotes.\r\n\r\nI should probably merge #333 first with some modifications as the number of output files is becoming unwieldly.",
      "> @NielsMayer Thanks for the PR! Would it work for you if I make this `write_tsv` instead? CSV format is not standardized and `csv.reader` and `pandas.read_csv` often create headache parsing quotes.\r\n> \r\n> I should probably merge #333 first with some modifications as the number of output files is becoming unwieldly.\r\n\r\nYes, merging #333 makes sense. If you do that first, I will update this PR to conform to the changes made, e.g. add additional csv (or tsv) output format keyword.\r\n\r\nW/r/t changing from CSV to TSV, that is fine by me as it would require a trivial change on my end. The reason why I chose CSV is that it seems more \"standard\";  although most of the programs automatically importing from CSV just as easily handle TSV. \r\n\r\nI'm not familiar with the comma issues you mention in csv.reader or pandas.read_csv, however, do note that I updated the code for compatibility with importing into, e.g. openoffice, where string type is automatically recognized if delimited by '\"' character.  To prevent issues, Internal `\"` in each CSV text line  is replaced by two consecutive single quotes `''` ... Note: ` print('\"' + segment['text'].strip().replace('\"', \"''\") + '\"'`\r\n\r\nChances are, such formatting and lack of special escape character means the existing solution would work with the readers you mention, @jongwook .\r\n\r\nPS: I updated my repo for this PR to the latest head of repository from whisper, so once again, there is a \"workflow awaiting approval\" message...",
      "FYI here's a whisper CSV file read into libreoffice on a linux desktop. Note the \" replaced by '' \r\n(orig source: https://rumble.com/v2619vq-bills-proliferate-to-criminalize-speech-darren-beattie-on-lex-and-brazil-fa.html )\r\n```\r\n3171020 | 3172820 | and he is up right now.\r\n3172820 | 3176820 | [''System Updates,'' main theme music playing.]\r\n3182620 | 3183760 | Great to be here.\r\n```\r\n\r\n@jongwook how on earth did whisper figure out that ` [''System Updates,'' main theme music playing.]` -- I mean how did it figure out the name of the show (\"remembered\" the announcement of the show name at the beginning, sometimes an hour earlier?) \r\n\r\nSometimes however it gets the theme music wrong on the same show, but different episode: ( https://rumble.com/v24mywg-what-really-happened-in-brazil-yesterday-system-update-18.html )\r\n`\"[''The Daily Show Theme'']\"\r\n\r\nLikewise how is whisper figuring out where quotes start and end? It's kind of spooky actually! :-)",
      "Thanks for accommodating the TSV suggestion! I merged a refactored version of #333 and edited this PR accordingly.\r\n\r\nThe issue about CSV is that, although CSV is more widely used and well known, even the simplest possible case like:\r\n\r\n```csv\r\nstart, end, text\r\n1234, 12345, \"hello, world!\"\r\n```\r\n\r\nresults in very inconsistent user experience according to the program because of the lack of standardization around the quotation marks:\r\n\r\n**Apple Quick Look:**\r\n<img width=\"176\" alt=\"image\" src=\"https://user-images.githubusercontent.com/266841/213907134-61c0790b-f92b-4a5b-bdfb-f714835aac50.png\">\r\n\r\n**Apple Numbers:**\r\n<img width=\"200\" alt=\"image\" src=\"https://user-images.githubusercontent.com/266841/213907251-577c1a5b-83b4-47dc-a3dd-25ccff3c69da.png\">\r\n\r\n**`csv.reader()`:**\r\n<img width=\"568\" alt=\"image\" src=\"https://user-images.githubusercontent.com/266841/213907278-ce67bbc7-0331-4ef2-bafd-e1b7860c58a6.png\">\r\n\r\n**pandas.read_csv()**\r\n<img width=\"229\" alt=\"image\" src=\"https://user-images.githubusercontent.com/266841/213907322-a997810e-3a72-4e34-9e0d-0371b83f988c.png\">\r\n\r\nThe latter two are the most common way to read CSV files in Python -- there are some combination of options to read the file as intended, but it's inconvenient and not practical to expect the users to use the \"correct\" configuration for all reader implementations.\r\n\r\n\r\nMeanwhile, TSV doesn't need to deal with quoting because the field values are not allowed to contain tab characters.\r\n\r\n---\r\n\r\nRe: the second comment, because of the way that Whisper was trained, the model must have encountered the exact music and the text `[\"System Updates\" main theme music playing.]` multiple times during training. It's usually an undesired behavior, and we tried to mitigate this (rather hackily) by suppressing the `[` character by default.\r\n"
    ],
    "num_comments": 8,
    "repository": "openai/whisper",
    "diff_length": 2955
  },
  {
    "index": 45,
    "pr_title": "Drop ffmpeg-python dependency and call ffmpeg directly.",
    "pr_body": "The last ffmpeg-python module release was in 2019[1], upstream seem to be unavailable[2] and the project development seem to have stagnated[3].  As the features it provide is trivial to replace using the Python native subprocess module, drop the dependency.\r\n\r\n [1] <URL: https://github.com/kkroening/ffmpeg-python/tags >\r\n [2] <URL: https://github.com/kkroening/ffmpeg-python/issues/760 >\r\n [3] <URL: https://openhub.net/p/ffmpeg-python >",
    "pr_number": 1242,
    "comments": [
      "[Glenn Langford]\n> Good idea, but should this use `run()` rather than `Popen()`?\n\nI went with Popen because I need the pipe and knew how to use it.  What\nwould be the advantage of using run()?\n\n-- \nHappy hacking\nPetter Reinholdtsen\n",
      "I added a commit to switch from Popen() to run().  Feel free to use the approach you like.",
      "We're running into some issues with ffmpeg-python when running on FIPS environment, it'd be good to have the ffmpeg-python removed. Any word on when this PR can be merged?",
      "[szelenka]\n> We're running into some issues with ffmpeg-python when running on FIPS\n> environment, it'd be good to have the ffmpeg-python removed. Any word\n> on when this PR can be merged?\n\nI have not heard anything about it. I do not know the evaluation process\nused by this project, so no idea who could make any reliable statement\nabout it.\n\nI've included the patch in the Debian packages I am working on, to avoid\nintroducing and depending on what appear to be unmaintained software\ninto Debian.\n\n-- \nHappy hacking\nPetter Reinholdtsen\n",
      "@petterreinholdtsen do we have any method to contact the maintainers of openai/whisper to merge this PR?\r\n\r\n@glangford is this PR good to go now?",
      "[szelenka]\n> @petterreinholdtsen do we have any method to contact the maintainers\n> of openai/whisper to merge this PR?\n\nNot besides nagging here, no.\n\n-- \nHappy hacking\nPetter Reinholdtsen\n",
      "Thanks! Other than tidying up the dependencies, did you have any missing features or security concerns from ffmpeg-python?",
      "[Jong Wook Kim]\n> Thanks! Other than tidying up the dependencies, did you have any\n> missing features or security concerns from ffmpeg-python?\n\nMy concern were mostly from a maintenance point of view.  There seem to\nbe no active maintainer nor any active maintenance of the library, so\ndepending on it seem like a fairly high risk for no gain.  I wanted to\nget Whisper into Debian and did not feel like introducing an upstream\norphaned ffmpeg-python as a package in Debian, were one is expected to\nkeep it working well for 3-4 years.\n\nHow do the Whisper developers evaluate ffmpeg-python sustainability?\n\n-- \nHappy hacking\nPetter Reinholdtsen\n",
      "@jongwook `ffmpeg-python` is not a FIPS compatible library, due to it's use of `md5` without the `usedforsecurity` parameter introduced in Python 3.9, which means you cannot run it (or whisper) on FIPS hardware.\r\n\r\nIt'd be an easy fix to ffmpeg-python, but as @petterreinholdtsen mentioned, this is an abandoned project .. so nobody can merge the PRs there."
    ],
    "num_comments": 9,
    "repository": "openai/whisper",
    "diff_length": 3101
  },
  {
    "index": 46,
    "pr_title": "Update `setup.py` to accommodate `Python3.13.0`",
    "pr_body": "*Changes made*\r\n\r\n- Update `setup.py` to pass in a local dictionary to `exec` to capture the `locals()` in `_version.py` for package version reporting.\r\n\r\n*Motivation*\r\n\r\n- `Python3.13.0` enforces stricter safety standards on `locals()` with PEP 667 (see [here](https://github.com/python/cpython/issues/118888#issuecomment-2104944287))\r\n\r\n- This causes the following error upon attempting to install with `python3.13 -m pip install openai-whisper`:\r\n\r\n```bash\r\nCollecting openai-whisper\r\n  Using cach",
    "pr_number": 2409,
    "comments": [
      "Would it be a more intuitive and durable solution to replace the deprecated `pkg_resources` with [packaging](https://pypi.org/project/packaging)?\r\n\r\nThe error message contained\r\n> DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\r\n>> Use of pkg_resources is deprecated in favor of [importlib.resources](https://docs.python.org/3.11/library/importlib.resources.html#module-importlib.resources), [importlib.metadata](https://docs.python.org/3.11/library/importlib.metadata.html#module-importlib.metadata) and their backports ([importlib_resources](https://pypi.org/project/importlib_resources), [importlib_metadata](https://pypi.org/project/importlib_metadata)). Some useful APIs are also provided by [packaging](https://pypi.org/project/packaging) (e.g. requirements and version parsing). Users should refrain from new usage of pkg_resources and should work to port to importlib-based solutions.\r\n\r\n* #2431",
      "Yes, #2435 merge would be great! But there's an issue with numba <-> llvmlite",
      "Problem is on Python version 3.13.1\r\n```\r\nCollecting openai-whisper\r\n  Using cached openai-whisper-20240930.tar.gz (800 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  √ó Getting requirements to build wheel did not run successfully.\r\n  ‚îÇ exit code: 1\r\n  ‚ï∞‚îÄ> [25 lines of output]\r\n      <string>:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\r\n      Traceback (most recent call last):\r\n        File \"C:\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\r\n          main()\r\n          ~~~~^^\r\n        File \"C:\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\r\n          json_out['return_val'] = hook(**hook_input['kwargs'])\r\n                                   ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\r\n          return hook(config_settings)\r\n        File \"C:\\Users\\Anton\\AppData\\Local\\Temp\\pip-build-env-jkd8x0ic\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 334, in get_requires_for_build_wheel\r\n          return self._get_build_requires(config_settings, requirements=[])\r\n                 ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\Anton\\AppData\\Local\\Temp\\pip-build-env-jkd8x0ic\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 304, in _get_build_requires\r\n          self.run_setup()\r\n          ~~~~~~~~~~~~~~^^\r\n        File \"C:\\Users\\Anton\\AppData\\Local\\Temp\\pip-build-env-jkd8x0ic\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 522, in run_setup\r\n          super().run_setup(setup_script=setup_script)\r\n          ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\Anton\\AppData\\Local\\Temp\\pip-build-env-jkd8x0ic\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 320, in run_setup\r\n          exec(code, locals())\r\n          ~~~~^^^^^^^^^^^^^^^^\r\n        File \"<string>\", line 21, in <module>\r\n        File \"<string>\", line 11, in read_version\r\n      KeyError: '__version__'\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n√ó Getting requirements to build wheel did not run successfully.\r\n‚îÇ exit code: 1\r\n‚ï∞‚îÄ> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n```\r\n",
      "@yakovlevway Does this merely repeat what is in the commit message above or is it different?",
      "> @yakovlevway Does this merely repeat what is in the commit message above or is it different?\r\n\r\nThis is a different error, it looks it is missing `__version__` somewhere in the source files.\r\n```\r\n        File \"<string>\", line 11, in read_version\r\n      KeyError: '__version__'\r\n```\r\n",
      "https://github.com/openai/whisper/pull/2435#issuecomment-2564481283 might still be a problem although their release candidates now seem to support Python 3.13... https://pypi.org/project/numba/0.60.0/#history",
      "thanks all for reporting compatibility issues with 3.13. this PR was closed automatically by #2435. Hoping their upcoming release can fix the remaining compat issue!",
      "Nice progress‚Ä¶ It would be great to have some pull requests that contain tests that fail because of the remaining compatibility issues.  When they pass we would have confidence to make the next release.  These tests would also help to avoid future regressions.",
      "Python 3.13 is blocked by both `numba` and `triton`.\r\n* #2487 "
    ],
    "num_comments": 9,
    "repository": "openai/whisper",
    "diff_length": 491
  },
  {
    "index": 47,
    "pr_title": "Add option to carry initial_prompt with the sliding window",
    "pr_body": "**Background**\r\nWhisper's `transcribe()` struggles with contextual proper nouns if they appear after the initial prompt has been consumed; see some experimental results [here](https://github.com/openai/whisper/discussions/1824#discussioncomment-7631300). This solves that issue by allowing the initial \"context\" prompt to be carried as the sliding window moves through the audio.\r\n\r\n**Changes**\r\nAdd an option `carry_initial_prompt = False` to `whisper.transcribe()`.\r\n\r\nWhen `carry_initial_prompt` i",
    "pr_number": 2343,
    "comments": [
      "There are outstanding issues with this PR:\r\n1. I have not found the definition of the 224 context token length.\r\n2. It prepends the `initial_prompt` to itself before enough tokens have been generated, resulting in a predilection toward looping.\r\n3. I have not written tests.\r\n\r\nClosing this PR since I can't find a way to move it to draft.",
      "> Closing this PR since I can't find a way to move it to draft.\r\n\r\nHow to: https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/changing-the-stage-of-a-pull-request",
      "Also a relevant discussion here: https://github.com/openai/whisper/pull/1040#issuecomment-1457651898\r\n\r\n> I have not found the definition of the 224 context token length.\r\n\r\nIt's part of the model dimensions itself, actually 448 tokens total, and half that for the prompt. The logic is in decoding.py if you look for `self.n_ctx: int = model.dims.n_text_ctx` and look for the references to it.",
      "@ryanheise Thank you for your input; it was helpful. Do you mind providing any additional feedback?\r\n\r\n---\r\n\r\nAside: I did find the left-slice in the code, and it turns out that the docs are wrong, as [actually the maximum prompt length is `223`!](https://github.com/openai/whisper/blob/main/whisper/decoding.py#L609)\r\n\r\nConfirming with the `medium.en` model...\r\n```python\r\n>>> medium = torch.load('/home/kittsil/.cache/whisper/medium.en.pt')\r\n>>> medium['dims']\r\n{'n_mels': 80, 'n_vocab': 51864, 'n_audio_ctx': 1500, 'n_audio_state': 1024, 'n_audio_head': 16, 'n_audio_layer': 24, 'n_text_ctx': 448, 'n_text_state': 1024, 'n_text_head': 16, 'n_text_layer': 24}\r\n>>> medium['dims']['n_text_ctx'] // 2 - 1\r\n223\r\n```",
      "hello if i locally merge this what do i add command to prevent whisper losing punctuation  during transcription? \r\n\r\ncan you also update here so i can directly install it : https://github.com/kittsil/whisper/tree/patch-1\r\n\r\n@kittsil  ",
      "why this very important feature is still not merged @jongwook ? ",
      "@kittsil i use CLI so adding --carry_initial_prompt will work right?",
      "I am transcribing a 3 hours video working awesome so far\r\n\r\nhow errors like this can be fixed?\r\n\r\n![image](https://github.com/user-attachments/assets/877a41d6-8da7-4c19-bece-2ddbd91bde9c)\r\n",
      "> how errors like this can be fixed?\r\n> \r\n> ![image](https://private-user-images.githubusercontent.com/19240467/378769017-877a41d6-8da7-4c19-bece-2ddbd91bde9c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk2NTExNjcsIm5iZiI6MTcyOTY1MDg2NywicGF0aCI6Ii8xOTI0MDQ2Ny8zNzg3NjkwMTctODc3YTQxZDYtOGRhNy00YzE5LWJlY2UtMmRkYmQ5MWJkZTljLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEwMjMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMDIzVDAyMzQyN1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWU5MTk0YzM1YjM0NWIyMmYxODM2ZGZiMDBiZmM1NzVkYzI3N2FlZDUyNjQ0OWJlM2U2MTM3MjVmOGIzODRkN2YmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.BnlPKr6YoEypvhm0ZiH_SJod76TFrhREYZaUZ59mRhc)\r\n\r\n@FurkanGozukara, that's an issue with `whisper`, not with your prompt. You can try setting `compression_ratio_threshold` lower; I have found some success with `1.7` (as opposed to the default `2.4`).\r\n\r\nIn general, though, I wouldn't comment on a PR for debugging help; it's best to keep PRs focused on the request / review process.",
      "@kittsil thank you so much your PR saved me so much\r\n\r\nI transcribed this 3 hours video and without your PR I would be devastated because YouTube auto timing also failed :D\r\n\r\nhttps://youtu.be/FvpWy1x5etM"
    ],
    "num_comments": 10,
    "repository": "openai/whisper",
    "diff_length": 3370
  },
  {
    "index": 48,
    "pr_title": "Add --progress_bar flag to control progress bar visibility",
    "pr_body": "This pull request adds a new optional CLI flag --progress_bar to the Whisper transcription script.\r\nThe flag gives users control over whether or not the progress bar is displayed during transcription.",
    "pr_number": 2600,
    "comments": [
      "Out of curiosity, what is the use case for disabling the progress bar?",
      "> Out of curiosity, what is the use case for disabling the progress bar?\r\n\r\nThanks for the question! The main use case is for automated or non-interactive environments ‚Äî like CI/CD pipelines, scripts, or log files ‚Äî where a dynamic progress bar can clutter the output or break formatting. This flag gives users control to disable the progress bar and keep output clean in those scenarios.\r\n",
      "I see, although wouldn't the transcript progress also be noisy in the output, not only the progress bar?",
      "> I see, although wouldn't the transcript progress also be noisy in the output, not only the progress bar?\r\n\r\nThat's a great point ‚Äî yes, the transcript output can also be noisy in certain contexts. That‚Äôs why the design separates both controls: --verbose governs whether transcripts are printed, while --progress_bar handles the visual progress bar. This gives users fine-grained control ‚Äî for example, they can suppress both for clean logs, or enable just one depending on their use case.",
      "That is exactly why I was curious about your use case - what is your context in which you want to hide the progress bar, but you don't want to hide the transcript progress, both of which is progress? If you have a dependency on parts of the progress, this would seem fragile, so I wondered what your use case is.",
      "> That is exactly why I was curious about your use case - what is your context in which you want to hide the progress bar, but you don't want to hide the transcript progress, both of which is progress? If you have a dependency on parts of the progress, this would seem fragile, so I wondered what your use case is.\r\n\r\nThat‚Äôs a great question ‚Äî I really appreciate the thoughtful follow-up. The idea behind separating --progress_bar from --verbose is to give users more granular control over output formatting. Not all environments treat ‚Äúprogress‚Äù the same way.\r\n\r\nFor instance, someone might want to log only the transcript (e.g., piping it to a file or post-processing it), while suppressing the live progress bar ‚Äî which can cause artifacts in logs or break formatting in non-TTY environments.\r\n\r\nThe goal isn't to rely on progress bar data itself, but to keep output clean and compatible in scripting scenarios, where the transcript is the primary deliverable and the progress bar is purely visual.\r\n\r\nThat said, I completely agree ‚Äî using both flags together (--verbose and --progress_bar) provides the clearest and most robust behavior.",
      "> The goal isn't to rely on progress bar data itself, but to keep output clean and compatible in scripting scenarios, where the transcript is the primary deliverable and the progress bar is purely visual.\r\n\r\nAs mentioned above,  the progress bar and the transcript progress are both progress and hence both purely visual. These are both intended for human eyes, and it would be fragile for a script to depend on their format. I am still interested therefore to know what your own use case, i.e. the use case that specifically motivates you to depend on the transcript progress output, as there may be a better way to tackle it. Are you post-processing the transcript progress display? If so, what specifically are you using the transcript progress for that you can't otherwise get directly from the transcript output rather than the transcript progress display? Knowing that, this could lead to an idea about a lacking feature that could be added to the API.",
      "> As mentioned above, the progress bar and the transcript progress are both progress and hence both purely visual. These are both intended for human eyes, and it would be fragile for a script to depend on their format. I am still interested therefore to know what your own use case, i.e. the use case that specifically motivates you to depend on the transcript progress output, as there may be a better way to tackle it. Are you post-processing the transcript progress display? If so, what specifically are you using the transcript progress for that you can't otherwise get directly from the transcript output rather than the transcript progress display? Knowing that, this could lead to an idea about a lacking feature that could be added to the API.\r\n\r\n\r\nThanks again for the follow-up ‚Äî I really appreciate how you're thinking through this. To clarify: I‚Äôm not parsing the transcript progress output or relying on it structurally. My motivation was primarily to keep logs clean in scripting and automation contexts.\r\nIn those cases, the transcript output is still useful for later review or post-processing, but the dynamic progress bar can clutter logs or break formatting when output is redirected ‚Äî especially in non-TTY environments. So the goal was simply to allow toggling it independently, without introducing any reliance on visual output.\r\nThat said, I completely agree that parsing visual output is fragile, and I appreciate you pointing that out. My intention was just to give users a bit more flexibility to control cosmetic output where clarity matters.\r\nOut of curiosity ‚Äî I‚Äôd definitely be interested in a cleaner API-level way to access intermediate transcript progress, if that‚Äôs something worth exploring in the future.\r\n",
      "> In those cases, the transcript output is still useful for later review or post-processing\r\n\r\nThat is actually what I was asking about - do you have a use case for post-processing the transcript progress display?",
      "> That is actually what I was asking about - do you have a use case for post-processing the transcript progress display?\r\n\r\nGot it ‚Äî thanks for clarifying! No, I'm not doing any post-processing on the transcript progress display. I‚Äôm only aiming to suppress the visual progress bar to keep logs clean, while still allowing the transcript output to appear as usual. I'm not relying on its structure or parsing it in any way.\r\nThat said, I‚Äôd definitely be interested in a cleaner API-level way to access intermediate transcript updates in the future, especially for cases where partial results might be useful for streaming or early feedback.\r\n\r\n"
    ],
    "num_comments": 10,
    "repository": "openai/whisper",
    "diff_length": 2401
  },
  {
    "index": 49,
    "pr_title": "Use PyTorch as logits transpose for ONNX support",
    "pr_body": "Because Numpy was used for the final transpose for the logits output, `torch.onnx.export` would fail\r\n```\r\n/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py in _run_symbolic_function(g, block, n, inputs, env, operator_export_type)\r\n   1420         else:\r\n   1421             raise symbolic_registry.UnsupportedOperatorError(\r\n-> 1422                 domain, op_name, opset_version\r\n   1423             )\r\n   1424     except RuntimeError:\r\nUnsupportedOperatorError: Exporting the operator ::n",
    "pr_number": 141,
    "comments": [
      "`[[50258, 50259, 50359]]`\r\n@mgoin May I know where did you obtain these shapes from?",
      "Thanks for checking! I haven't tried ONNX but the change seems benign.",
      "> `[[50258, 50259, 50359]]` @mgoin May I know where did you obtain these shapes from?\r\n\r\n@Y-T-G those shapes were taken just from some sample audio I ran through, printed the tensor shapes, and use them to make the dummy inputs.\r\n\r\nThanks for the accept!\r\n",
      "Hi!\r\n\r\nIt's not shapes, but it's `sot_tokens`:\r\n\r\n- `50258` - sot_token\r\n- `50259` - language token\r\n- `50359` - task token (50359 - just for trunscribe)\r\n\r\nThis 3 tokens formed here:\r\nhttps://github.com/openai/whisper/blob/8cf36f3508c9acd341a45eb2364239a3d81458b9/whisper/tokenizer.py#L324-L331",
      "But i have problems with speed of overall model, as mentioned here #134 \r\n\r\n@mgoin If you can run ONNX version of model without botlenecks, it's would very go to see your inference code (or just know, that you has not problems with it, and all running good).",
      "@ArtyomZemlyak ,can you please share the code to run inference on onnx files",
      "@mgoin I see. So I am assuming it would be a different values for different size of models.",
      "> But i have problems with speed of overall model, as mentioned here #134\r\n> \r\n> @mgoin If you can run ONNX version of model without botlenecks, it's would very go to see your inference code (or just know, that you has not problems with it, and all running good).\r\n\r\ndo u have the codes for running the onnx model file?  coz i came across a problem how to convert logits to tokens we need. ",
      "> Because Numpy was used for the final transpose for the logits output, `torch.onnx.export` would fail\r\n> \r\n> ```\r\n> /usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py in _run_symbolic_function(g, block, n, inputs, env, operator_export_type)\r\n>    1420         else:\r\n>    1421             raise symbolic_registry.UnsupportedOperatorError(\r\n> -> 1422                 domain, op_name, opset_version\r\n>    1423             )\r\n>    1424     except RuntimeError:\r\n> UnsupportedOperatorError: Exporting the operator ::numpy_T to ONNX opset version 13 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.\r\n> ```\r\n> \r\n> If this line at whisper/model.py:L192 is changed from `logits = (x @ self.token_embedding.weight.to(x.dtype).T).float()` to `logits = (x @ torch.transpose(self.token_embedding.weight.to(x.dtype), 0, 1)).float()` then the export succeeds!\r\n> \r\n> Code to test export:\r\n> \r\n> ```\r\n> import whisper\r\n> import torch\r\n> \r\n> tiny_model = whisper.load_model(\"tiny\")\r\n> torch.onnx.export(tiny_model.encoder, torch.randn(1,80,3000).to(\"cuda\"), \"tiny/whisper-encoder.onnx\")\r\n> torch.onnx.export(tiny_model.decoder, (torch.tensor([[50258]]).to(\"cuda\"), torch.randn(1,384,384).to(\"cuda\")), \"tiny/whisper-decoder_main.onnx\")\r\n> torch.onnx.export(tiny_model.decoder, (torch.tensor([[50258, 50259, 50359]]).to(\"cuda\"), torch.randn(1, 384, 384).to(\"cuda\")), \"tiny/whisper-decoder_language.onnx\")\r\n> ```\r\nHi, thank you for your contribution. I am a novice who has just come into contact with whisper model. I would like to ask whether I can save the entire whisper input pt as pth and then convert it to an onnx model. I made simple attempts, but they didn't seem to succeed\r\n"
    ],
    "num_comments": 9,
    "repository": "openai/whisper",
    "diff_length": 511
  },
  {
    "index": 50,
    "pr_title": "GitHub Actions: Add Python 3.13 to the testing",
    "pr_body": "Python 3.13 was blocked waiting on\r\n`numba>=0.61.0` -- https://pypi.org/project/numba/#history and\r\n`triton>3.1.0` -- https://pypi.org/project/triton/#history\r\nbut now the PyPI releases of both are compatible with Python 3.13.\r\n* https://github.com/triton-lang/triton/issues/5215\r\n",
    "pr_number": 2487,
    "comments": [
      "Hey,\r\nwhat is the current state here?\r\ntriton 3.2.0 is available.\r\nI am asking because the flatpak of kdenlive ships with python 3.13 and installing whisper inside fails building wheel.",
      "@jongwook Tests on Python 3.13 now pass with the new versions of `numba` and `triton`.\r\n\r\n@rdinkel When you think a pull request is useful and is ready to be merged, ___please consider giving it a positive review___.\r\n\r\nEvery check mark ‚úîÔ∏è at the top right of this page gives project maintainers confidence that the proposed changes have been read through and deemed both useful and safe to merge into the codebase.  Lots of üëç and \"_what is the ETA?_\" comments are easier for maintainers to ignore than ‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è from several different reviewers.\r\n\r\nAnyone can review a pull request on GitHub.  To do so here:\r\n1. Scroll to the top of this page.\r\n2. Click the `Files changed` tab and read through each file carefully looking for potential issues.\r\n3. Click the `Review changes` button.\r\n4. Click `Approve` (or one of the other options) and add comments only if they have not already been stated in the PR.\r\n5. Click `Submit review` so that your ‚úîÔ∏è will be added to the list.",
      "@cclauss \r\nI just want to let you know that not everybody can approve because \"Only users with explicit access to this repository may approve pull requests.\" ",
      "You are correct in this case. `code_review_limits` has been set to ___restrict___ on this repo but most repos keep the default.\r\nhttps://github.com/owner/repo/settings/code_review_limits",
      "How will this issue be proceeded going forward to get it done?",
      "Can this be merged, please? Python 3.13 has been out for a while now.",
      "For anyone testing things out, Python 3.13 does not work for me with installation until I make this change to `v20240930` :\r\n\r\n```diff\r\ndiff --git a/setup.py b/setup.py\r\nindex 73c4eb8..eab80ed 100644\r\n--- a/setup.py\r\n+++ b/setup.py\r\n@@ -7,8 +7,11 @@ from setuptools import find_packages, setup\r\n\r\n\r\n def read_version(fname=\"whisper/version.py\"):\r\n-    exec(compile(open(fname, encoding=\"utf-8\").read(), fname, \"exec\"))\r\n-    return locals()[\"__version__\"]\r\n+    local_vars = {}\r\n+    global_vars = {}  # unused\r\n+    with open(fname, encoding=\"utf-8\") as f:\r\n+        exec(compile(f.read(), fname, \"exec\"), global_vars, local_vars)\r\n+    return local_vars[\"__version__\"]\r\n\r\n\r\n requirements = []\r\n ```\r\n\r\n[locals()](https://docs.python.org/3.13/library/functions.html#locals) docs describe the history of changes. With the above patch the `v20240930` can do simple transcriptions (which was the limit of my smoke test)",
      "Python 3.14 beta 1 is now available too,"
    ],
    "num_comments": 8,
    "repository": "openai/whisper",
    "diff_length": 780
  },
  {
    "index": 51,
    "pr_title": "fix: transcribe verbosity",
    "pr_body": "I've hidden \"Detected langauge: \" massage behind `verbose` flag.\r\nAlso fixed the flag usage with tqdm",
    "pr_number": 140,
    "comments": [
      "I actually intended the two to be displayed even when `--verbose` is False, thinking it'd help the user notice any language detection errors and show the progress/ETA without flooding the console.",
      "@jongwook well, ETA is disabled when `verbose=True`, which is misleading as it seem to me. Also, the language tag is returned as a part of the result. Do you really need to print it if you return it?",
      "The language tag is returned in the result, but for those calling `whisper` in the command line (as it seems to be a popular use case) the detail is lost.\r\n\r\nRegarding ETA: that's true; it's not the most intuitively named options but I thought both formats have merits (like below) and thought it'd be nice to have these verbose/concise output options, but probably better not mix up those two.\r\n\r\n<img width=\"585\" alt=\"image\" src=\"https://user-images.githubusercontent.com/266841/192348709-e7e5f34a-c63c-438b-ac0d-9dc06fa1bcfe.png\">\r\n\r\nWe can maybe make it an integer level for verbosity if a totally silent output is desired by many ..",
      "@jongwook \r\nHow about str verbosity like \"full\", \"minimal\" and \"silent\"? I might add it real quick\r\n- full being equivalent to `verbosity=True`\r\n- minimal being equivalent to `verbosity=False`\r\n- silent being equivalent to `verbosity=False` from current PR",
      "I'd like to avoid magic string if possible. It's a bit unorthodox but I'm inclined to making it an `Optional[bool]` and use `None`/`False`/`True` so `verbose=None` (i.e. silent) is the default in `transcribe()` but from the command line it selects either `True` or `False`.\r\n\r\nI can make these edits on this PR if you'd like/don't mind.",
      "Don't bother yourself, I have nothing to do at the moment"
    ],
    "num_comments": 6,
    "repository": "openai/whisper",
    "diff_length": 2015
  },
  {
    "index": 52,
    "pr_title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "pr_body": "The docs and some tests contain references to a master/slave db configuration.\nWhile this terminology has been used for a long time, those terms may carry racially charged meanings to users.\nThis patch replaces all occurrences of master and slave with 'leader' and 'follower'\n",
    "pr_number": 2692,
    "comments": [
      "Thanks for taking the time to do this!\n",
      "Are you serious ?\nThe meaning of a word is defined by its use, by the context.\nIn this case, _master_/_slave_ is used by every database server, in every documentation ([redis](http://redis.io/topics/replication), [mysql](http://dev.mysql.com/doc/refman/5.0/en/replication-howto.html) ‚Ä¶)\n\nNB: I don't say I'm against this change. Just that I don't see the point of changing two words with two others just because they have been used somewhere else.\nFor example, your avatar is red. Red, like communism. You should use a black and white color. Oh no, that's linked to racism too. Well. Let's remove colors, too, then ? ;)\n",
      "As you can see from https://github.com/django/django/commit/beec05686ccc3bee8461f9a5a02c607a02352ae1 the terminology we have actually used is \"primary/replica\". So thank you for your interest, but there's nothing to see here and you can move along now.\n",
      "Before the flood of white male HN dwellers truly kicks off and obliterates all reasonable discussion, I'd like to thank the Django team for taking the time to do this.\n",
      "i'm just here for the laughs. is IT becoming too stupid? has science gone too far?\n",
      "Discussion on the ticket: https://code.djangoproject.com/ticket/22667\n\"Primary\" and \"Replica\" aren't especially bad choices, but they're also wrong. The correct terms are `master` and `slave`. They've been used in databases, hardware setups, server setups and god knows what else for god knows how long.\n\nI cannot f_ing believe this PR made it through and was given actual man hours when there are massive outstanding PRs and patches on trac that need real attention. And don't be surprised that this does make it on HN and probably later on the usual slashdot/phoronix and what not. This is stupid *and_ controversial which is exactly what tech media loves.\n\nAnd to the HN/whatever crowd, don't post stupid memes here. This isn't the place.\n\nHelp yourselves and revert this, guys. Django docs, or docs in general are not the place to make up new terms for stuff that already exists.\n\nPS: Quick heads up: This made it to 4chan and various other troll places. Do not be surprised if there's suddenly an influx of .. weird comments.\n",
      "This is silly.\nNext we will remove all mention og objects because some people might feel objectified.\nOr classes, because of the poor people that feels they are being discriminated against.\n\nSure, I understand that the use of words can hurt, but words themselves carry no meaning outside of it's use. Saying a car is yellow and calling a person yellow are two very different statements. We seem to have a new round of book burnings going on today...\n",
      "Guys, just ignore this. These are bots who do this automatically for projects, which have been circling around on Github lately. There are also ones about feminism etc. The Linux kernel also had a PR like this a few months ago with a massive amount of responses on it.\n\nDon't feed the trolls, and just continue to use `master` and `slave`.\n",
      "Faith in humanity restored. Thank you guys. I just want to add, that this will also be bad for django itself, since almost every developer who is no aware of this will be confused, and trust me - he will be expecting that this is some bizarre django thing, not the well known pattern. Peace.\n",
      "Thanks so much Django for doing this thing! <3\n",
      "Excellent stuff. Thanks for doing that.\n",
      "I'm very glad for this change because as a PoC I felt very uncomfortable seeing and using this terminology in my code\n",
      "glad to see big projects taking this seriously\n",
      "Thanks Django for making this important change to be more welcoming and inclusive to more members of the tech community. <3 \n",
      "\"they've always been called that\" is a dumb reason to keep doing something, especially something that is hurtful or alienating. Kudos to Django for making this change! \n",
      "The use of the terms `master` and `slave` in relation to databases (and hardware configurations) has always made me uncomfortable. I think the terms `leader` and `follower` are much more appropriate, and are actually more expressive. :heart: to the Django team for making this change!\n",
      "These terms have been in use forever, but that doesn't make them good. Fixing them has to start somewhere; good for Django for taking the lead.\n",
      ":+1: \nGreat job @fcurella, thank you @alex & Django.\n",
      "Awesome change, thanks @fcurella! \"Primary/replica\" sounds much better.\n",
      "Good. The old terminology should be made obsolete.\n",
      "Thank you so much for making this change!\n",
      "Awesome change. Another reason to love the Django project :)\n"
    ],
    "num_comments": 22,
    "repository": "django/django",
    "diff_length": 23188
  },
  {
    "index": 53,
    "pr_title": "Fixed #373 -- Added CompositePrimaryKey.",
    "pr_body": "# Trac ticket number\r\n\r\nticket-373\r\n\r\n# Branch description\r\n\r\nThis branch adds the `CompositePrimaryKey` field. If present, Django will create a composite primary key.\r\n\r\nPlease refer to the [docs](https://github.com/django/django/pull/18056/files#diff-cca8870fcaec19104d999f61553ba925c72e2eb19b4933068c4849f2ce58a6f6) for a more in-depth explanation.\r\n\r\n[Proposal](https://forum.djangoproject.com/t/gsoc-2024-proposal-django-orm-support-for-composite-primary-keys/29146)\r\n[Previous PR](https://githu",
    "pr_number": 18056,
    "comments": [
      "I was trying out this exciting branch and ran into this error when running a test:\r\n```\r\n<...>/lib/python3.12/site-packages/django/db/models/lookups.py:30: in __init__\r\n    self.rhs = self.get_prep_lookup()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = TupleIn(<django.db.models.fields.composite.Cols object at 0x107560980>, <django.db.models.sql.query.Query object at 0x1074e23f0>)\r\n\r\n    def get_prep_lookup(self):\r\n        if not isinstance(self.lhs, Cols):\r\n            raise ValueError(\r\n                \"The left-hand side of the 'in' lookup must be an instance of Cols\"\r\n            )\r\n        if not isinstance(self.rhs, Iterable):\r\n>           raise ValueError(\r\n                \"The right-hand side of the 'in' lookup must be an iterable\"\r\n            )\r\nE           ValueError: The right-hand side of the 'in' lookup must be an iterable\r\n```\r\n\r\nThe issue stems from the use of `isnull` like so:\r\n\r\n```\r\nMyModel.objects.filter(\r\n    type_override__severity__isnull=False\r\n).update(severity=\"high\")\r\n```\r\n\r\nCurious if anyone ran into this as well.\r\n\r\nEdited for traceback:\r\n\r\n```\r\n<...>\r\nlib/python3.12/site-packages/django/db/models/sql/compiler.py:2080: in pre_sql_setup\r\n    self.query.add_filter(\"pk__in\", query)\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1601: in add_filter\r\n    self.add_q(Q((filter_lhs, filter_rhs)))\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1617: in add_q\r\n    clause, _ = self._add_q(q_object, self.used_aliases)\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1649: in _add_q\r\n    child_clause, needed_inner = self.build_filter(\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1563: in build_filter\r\n    condition = self.build_lookup(lookups, col, value)\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1393: in build_lookup\r\n    lookup = lookup_class(lhs, rhs)\r\nlib/python3.12/site-packages/django/db/models/lookups.py:30: in __init__\r\n    self.rhs = self.get_prep_lookup()\r\n```\r\n\r\nSo, this is part of `SQLUpdateCompiler` and is coming from the `update` code path.",
      "Thanks for testing and reporting the issue @grjones! Indeed, I forgot to handle this use case. I'll look into it this week.",
      "@grjones, FYI I pushed the fix",
      "> @grjones, FYI I pushed the fix\r\n\r\nNice! I hope this gets merged in soon. Your branch has been working great for me.",
      "I may have found one other small issue. When adding a regular `primary_key=True` on a single field, a unique constraint is added. But when using this branch, it becomes an `IntegrityError` instead. Adding a `UniqueConstraint` on the composite fields is a work-a-round but ideally would be captured in this PR. Imo, this PR is sooooo close. I'm excited for it to be merged in.",
      "@grjones , thanks, I appreciate the feedback, I'll look into it. If a model defines `Meta.primary_key`, defining `primary_key=True` on a field should not be possible - could you give me a code example so I know how to reproduce the issue? I didn't know Django added unique constraints to primary keys, I'll check, but isn't that redundant?",
      "> @grjones , thanks, I appreciate the feedback, I'll look into it. If a model defines `Meta.primary_key`, defining `primary_key=True` on a field should not be possible - could you give me a code example so I know how to reproduce the issue? I didn't know Django added unique constraints to primary keys, I'll check, but isn't that redundant?\r\n\r\nI'll see if I can give you a solid failing test. My \"unique constraint\" phrasing might not be exactly right. But ultimately, I believe Django queries the DB first to see if the new object's PK already exists and throws a validation error. The composite key logic doesn't seem to be doing that and so an unhandled IntegrityError is raised instead.",
      "@grjones , sorry for the late reply, I've been busy last week. Could you give me more specifics? What's the error message you expect?",
      "> @grjones , sorry for the late reply, I've been busy last week. Could you give me more specifics? What's the error message you expect?\r\n\r\nActually, I think it's mostly ok. I was using [Django Spanner](https://github.com/googleapis/python-spanner-django) and it's just not quite working with composite keys and will need to be fixed there. I wrote this and it passed. It probably shouldn't say `Id` though?\r\n\r\n```\r\nfrom django.core.exceptions import ValidationError\r\nfrom django.test import TestCase\r\n\r\nfrom .models import Tenant, User\r\n\r\n\r\nclass CompositePKCleanTests(TestCase):\r\n    \"\"\"\r\n    Test the .clean() method of composite_pk models.\r\n    \"\"\"\r\n\r\n    @classmethod\r\n    def setUpTestData(cls):\r\n        cls.tenant = Tenant.objects.create()\r\n\r\n    def test_validation_error_is_raised_when_pk_already_exists(self):\r\n        test_cases = [\r\n            {\"tenant\": self.tenant, \"id\": 2412, \"email\": \"user2412@example.com\"},\r\n            {\"tenant_id\": self.tenant.id, \"id\": 5316, \"email\": \"user5316@example.com\"},\r\n            {\"pk\": (self.tenant.id, 7424), \"email\": \"user7424@example.com\"},\r\n        ]\r\n        expected = \"{'id': ['User with this Id already exists.']}\"\r\n        for fields in test_cases:\r\n            User.objects.create(**fields)\r\n            with self.assertRaisesMessage(ValidationError, expected):\r\n                User(**fields).clean()\r\n```",
      "Thank you so much for taking the time to review my changes @LilyFoote !\r\nI have two questions:\r\n\r\n1. If `Meta.primary_key` is defined, this PR will automatically add a composite field called `primary_key` to the model. What do you think about this approach? I felt like it was easier to handle the composite primary keys this way as we can run checks against the meta class instead of traversing the model's fields for a composite field.\r\n2. I wrote a lot of tests testing the underlying queries made by the ORM. It makes a lot of sense to me, but I haven't seen this type of tests that much in the Django source code - do these tests look okay to you?",
      " \r\n> If `Meta.primary_key` is defined, this PR will automatically add a composite field called `primary_key` to the model. What do you think about this approach?\r\n\r\nI don't feel strongly that this is better or worse than another option here, so happy to go with what you think is best.\r\n\r\n> I wrote a lot of tests testing the underlying queries made by the ORM. It makes a lot of sense to me, but I haven't seen this type of tests that much in the Django source code - do these tests look okay to you?\r\n\r\nI like your tests quite a bit - they're pretty readable and comprehensive. The main issue I have with them is that they're written for specific databases instead of for generic database features. Where possible Django strongly prefers to test based on features because then the tests apply to as many databases as possible (including third party database libraries). I think the asserts of the actual SQL might be a bit tricky to adapt though, so we might need a different way to check what they're checking.\r\n\r\nAlso, after I reviewed yesterday, I thought of some more things:\r\n\r\n* We should add migrations tests to make sure that adding/removing `Meta.primary_key` works correctly and that removing a field that's part of a primary key also does something appropriate.\r\n* We might want tests for composite keys in forms and the admin. Maybe there's other areas too that we need to check the interactions.",
      "Thanks @charettes !\r\n\r\n> Something that came through my mind while reviewing is that we likely want a plan to eventually deprecate `Options.pk` in favor of `Options.primary_key`?\r\n\r\nI'm not sure what you mean by that, I don't think we can, because `Options.pk` refers to the field, while `Options.primary_key` is the list of field names.",
      "So as far as I understand, at the moment `MultiColSource` is used by Django internally to represent `JOIN`s on multiple fields - that's why it has a `sources` field.\r\n\r\nI'm not sure it's the right decision to reuse this for composite fields, which on the other hand don't need `sources`, it just needs to represent a list of `Col`s as an expression.\r\n\r\nLet me know what you think!",
      "> I'm not sure what you mean by that, I don't think we can, because Options.pk refers to the field, while Options.primary_key is the list of field names.\r\n\r\nYou're completely right. In this case is `pk` set to `CompositePrimaryKey` when `Meta.primary_key` is defined and is `primary_key` set when a non-composite primary is used as well?",
      "> > I'm not sure what you mean by that, I don't think we can, because Options.pk refers to the field, while Options.primary_key is the list of field names.\r\n> \r\n> You're completely right. In this case is `pk` set to `CompositePrimaryKey` when `Meta.primary_key` is defined and is `primary_key` set when a non-composite primary is used as well?\r\n\r\nIt would not be set, if it's a regular primary key, `Meta.primary_key` is `None`.",
      "Hey @csirmazbendeguz, thank you for the amazing work out there! I was trying to test this branch on my local with SQLite and realised a few things:\r\n\r\n1. If you run `makemigrations` for a model with a `CompositePrimaryKey`, the resulting migration file has erroneous imports. To fix this, I believe we need to add `django.db.models.fields.composite` path to the `if...elif` block [here](https://github.com/django/django/blob/main/django/db/models/fields/__init__.py#L645).\r\n2. Assume that I have the following models:\r\n\r\n    ```py\r\n    class Author(models.Model):\r\n    name = models.CharField(max_length=100)\r\n\r\n    class Book(models.Model):\r\n        id = models.CompositePrimaryKey(\"author\", \"title\")\r\n        author = models.ForeignKey(Author, on_delete=models.CASCADE, related_name=\"books\")\r\n        title = models.CharField(max_length=255)\r\n    ```\r\n\r\n    With the current implementation, following test fails:\r\n    ```py\r\n    class TestCompositeFks(TestCase):\r\n        def test_composite_fks(self):\r\n            author = Author.objects.create(name=\"Author\")\r\n            book = Book.objects.create(author=author, title=\"Title\")\r\n            list(Author.objects.filter(books__in=[book])) == book\r\n    ```\r\n    with an `OperationalError`, caused by a syntax error. Executed SQL is as following:\r\n    ```SQL\r\n    SELECT\r\n        \"books_author\".\"id\",\r\n        \"books_author\".\"name\"\r\n    FROM\r\n        \"books_author\"\r\n        INNER JOIN \"books_book\" ON (\"books_author\".\"id\" = \"books_book\".\"author_id\")\r\n    WHERE\r\n        \"books_book\".\"author_id\", \"books_book\".\"title\" IN ((1, 'Title'))\r\n    ```\r\n    because LHS in WHERE clause should have been wrapped with parantheses like this:\r\n    ```SQL\r\n    ...\r\n    WHERE\r\n        (\"books_book\".\"author_id\", \"books_book\".\"title\") IN ((1, 'Title'))\r\n    ```\r\n    Unfortunately I didn't have a time to deep-dive to this.\r\n3. Not a big issue but my code editor (VSCode) does not recognize `models.CompositePrimaryKey`, although the import is working fine. This is probably related with Pylance or something that VSCode uses to recognize fields under `models` module.\r\n\r\nAgain thanks for this amazing initiative! üöÄ ",
      "Thanks a lot for the review @omerfarukabaci ! I'll take a look",
      "> Author.objects.filter(books__in=[book])\r\n\r\n@omerfarukabaci , I pushed the changes to support this, but note that filtering on reverse relations is one of those \"gotchas\" in Django, it may not produce the results you expect.\r\n\r\n_EDIT: I mean it might return duplicates, you probably already know this, I'm just mentioning it just in case._",
      "> If you run makemigrations for a model with a CompositePrimaryKey, the resulting migration file has erroneous imports\r\n\r\nYes, I recently changed the API to `CompositePrimaryKey`, the migrations are not 100% yet. I'm working on sorting them out.\r\nI pushed the fix for the issue you mentioned, thanks üëç ",
      "@csirmazbendeguz Thanks for your answers, now the above issues seem like fixed, created migration is correct and reverse relation lookup is working as expected. Thank you! üöÄ\r\n\r\nWhile I was testing it further with the exact [same models](https://github.com/django/django/pull/18056#issuecomment-2158820017), I realized another issue:\r\n\r\n```py\r\nclass TestCompositeFks(TestCase):\r\n    def test_composite_fks(self):\r\n        author = Author.objects.create(name=\"Author\")\r\n        Book.objects.create(author=author, title=\"Title\")\r\n        author = Author.objects.annotate(book_count=Count(\"books\")).get()\r\n        assert author.book_count == 1\r\n```\r\n\r\nThis test fails with the following error:\r\n\r\n```\r\ndjango.db.utils.OperationalError: wrong number of arguments to function COUNT()\r\n```\r\n\r\nExecuted SQL is as following:\r\n\r\n```SQL\r\nSELECT\r\n    \"books_author\".\"id\",\r\n    \"books_author\".\"name\",\r\n    COUNT(\"books_book\".\"author_id\", \"books_book\".\"title\") AS \"book_count\"\r\nFROM\r\n    \"books_author\"\r\n    LEFT OUTER JOIN \"books_book\" ON (\"books_author\".\"id\" = \"books_book\".\"author_id\")\r\nGROUP BY\r\n    \"books_author\".\"id\",\r\n    \"books_author\".\"name\"\r\n```\r\n\r\nIf we could change the parameter we pass to the `COUNT` function to a concatenation as below:\r\n\r\n```SQL\r\nCOUNT(\"books_book\".\"author_id\" || '-' || \"books_book\".\"title\")\r\n```\r\n\r\nit should work fine (if I am not missing something), with the exception that for some databases we need to use `CONCAT` function instead of `||` operator, which might be resolved using the existing `db.models.functions.Concat` function.\r\n\r\nNote: I am not sure if concatenation works between every data type that is allowed to be a primary key, although this could be considered as an edge case.",
      "Thanks @omerfarukabaci , these bug reports are very helpful. Yes, I haven't considered annotations with multi-column pks. I'll look into this.",
      "Thanks @LilyFoote , @sarahboyce for the meeting.\r\nNotes:\r\n1. At the moment, `Count(\"books\")` is not too easy to fix. It could be written as `Count(\"books__author_id\")` and it would work. If we cannot fix it, we should document it. Maybe we could use `*` instead of `pk` for counting?\r\n2. The content types framework will not work with composite pks. This includes everything that depends on the content types framework, e.g. the `contrib.auth` module too.",
      "I squsahed all commits and rebased to latest main branch.",
      "Idea: how about calling the field `PrimaryKey` instead of `CompositePrimaryKey`?",
      "@omerfarukabaci , I thought about the issue of `Count(\"books\")`.\r\n\r\nMy conclusion is we can't support this.\r\n\r\nI don't think concatenating is a good solution. The only way we could support this is if we could get Django to count this with `*` instead of the primary key.\r\n\r\nThis is an edge case that is only needed for `Count` though, and it's not as simple to implement as it is to explain.\r\n\r\nI added a section to the docs about this. This is a case of using a database function with a composite primary key directly, which cannot be expected to work in general.\r\n\r\nIn your case, `Count(\"books__author_id\")` would do the trick instead.",
      "Regarding the issue raised by @sarahboyce last week...\r\n\r\nI think it is okay to merge this without support for generic relations. I added a section to the docs about this not being supported for now.\r\n\r\nThe only impact is some third-party packages using generic relations won't work with composite primary keys (e.g. `django-guardian`).\r\n\r\nLet's have a separate discussion on how to support this. I lean towards storing composite primary keys serialized as JSON in a single CharField.",
      "Btw, semantically it would be nice if it were possible to write:\r\n```python \r\nclass User(models.Model):\r\n    pk = models.CompositePrimaryKey(\"tenant_id\", \"id\")\r\n    tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE)\r\n    id = models.IntegerField()\r\n```\r\n\r\nie to let `CompositePrimaryKey` replace the automatically generated `pk`. Would that be possible?",
      "> Btw, semantically it would be nice if it were possible to write:\r\n> \r\n> ```python\r\n> class User(models.Model):\r\n>     pk = models.CompositePrimaryKey(\"tenant_id\", \"id\")\r\n>     tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE)\r\n>     id = models.IntegerField()\r\n> ```\r\n> \r\n> ie to let `CompositePrimaryKey` replace the automatically generated `pk`. Would that be possible?\r\n\r\n@apollo13 , good point! It also came up when we were discussing this with @LilyFoote and @charettes . It seems like a natural thing to do, so it's worth a discussion. Here are a couple ideas that make sense to me:\r\n\r\n1. `pk` at the moment is reserved, users can't add a field named `pk`. We could remove this restriction.\r\n2. If `pk` is defined, it should always set `primary_key=True`.\r\n3. If `pk` is not defined, it should still refer to the `primary_key=True` field (e.g. `id` field). This is required for backwards-compatibility.\r\n4. If `pk` is defined, and it's an `IntegerField`, then a field called `pk` should be created in the database (same as any field, e.g. `id`).\r\n5. If `pk` is defined, and it's a `CompositePrimaryKey`, then a field called `pk` shouldn't be created in the database (same as any field, e.g. `primary_key`).\r\n\r\nMy only issue with this is, it adds extra complexity to how `pk` works. In this case, `pk` can be both a reference to the primary key field, or the primary key field itself.\r\n\r\nSo I'm not sure if it's worth doing this. It doesn't feel like an elegant or consistent solution to me.\r\n\r\n---\r\n\r\nThe other approach @charettes and @LilyFoote mentioned is to always have `pk` be a `CompositePrimaryKey` (could be renamed to `PrimaryKey`):\r\n\r\n1. `pk` cannot be defined explicitly.\r\n2. `CompositePrimaryKey` cannot be used explicitly.\r\n3. `pk` is _always_ added to the model in the background, and it's _always_ an instance of `CompositePrimaryKey`.\r\n4. Consequently, `pk` will cease to be a reference to another field, it will always be a field itself.\r\n5. If field `x` defines `primary_key=True`, `pk` is `CompositePrimaryKey(\"x\")`. `obj.pk` returns the value of `x` for backwards-compatibility (instead of a tuple).\r\n6. If `Meta.primary_key` option is `(\"a\", \"b\", \"c\")`, `pk` is `CompositePrimaryKey(\"a\", \"b\", \"c\")`. `obj.pk` returns a tuple.\r\n7. If `Meta.primary_key` is not set, it could be set to `(\"x\",)` automatically.\r\n\r\nThis is quite an invasive change. It would mean all existing models get a new field called `pk`.\r\n`meta.pk` would return a different field. Instead of `IntegerField`, it would return `CompositePrimaryKey`. Is breaking backwards-compatibility okay here?\r\n\r\nI don't have anything against it other than that. It does feel more intuitive. If the community wants this, I could fork this branch and open another PR.",
      "Today's meeting with @LilyFoote and @charettes :\r\n* enable setting pk to CompositePrimaryKey explicitly. pk is a well-known Django keyword, so it makes sense to reuse it here, even if it somewhat complicates things.\r\n* pk can only be set to CompositePrimaryKey.\r\n* CompositePrimaryKey can't be set to anything else but pk.",
      "@apollo13 , I discussed your suggestion with @LilyFoote and @charettes and they agreed. I pushed the changes. The only way to define a composite pk is with the `pk` field name now."
    ],
    "num_comments": 30,
    "repository": "django/django",
    "diff_length": 140643
  },
  {
    "index": 54,
    "pr_title": "[Soc2014] Official meta API",
    "pr_body": "",
    "pr_number": 3114,
    "comments": [
      "Here are some docs edits: http://dpaste.com/1X0TZB4\nLet me know if any changes look questionable.\n",
      "Hi @timgraham thank you so much for the doc edits! I will have a look at them now.\n",
      "Daniel, I'd recommend to finish the docs and then I'll do another review. After that, we can put out a call for anyone else who wants to do a final review. We still have time before 1.8 feature freeze to make changes as needed after merge, but this way you won't have to keep resolving conflicts due to changes in master.\n",
      "Sounds great. I don't have access to a computer this week but will re-write\nall the docs as soon as I come back home.\n\nOn Wednesday, September 17, 2014, Tim Graham notifications@github.com\nwrote:\n\n> Daniel, I'd recommend to finish the docs and then I'll do another review.\n> After that, we can put out a call for anyone else who wants to do a final\n> review. We still have time before 1.8 feature freeze to make changes as\n> needed after merge, but this way you won't have to keep resolving conflicts\n> due to changes in master.\n> \n> ‚Äî\n> Reply to this email directly or view it on GitHub\n> https://github.com/django/django/pull/3114#issuecomment-55829765.\n\n## \n\n---\n\nPirosB3\n\nhttps://github.com/PirosB3\n",
      "@timgraham @freakboy3742 I have done pull from master, and now I am finishing up the docs. I expect this to be all complete in the next 2 days. Then we can do a final review \n",
      "I ran into this issue using the code from the tutorial:\n\n```\n$ python manage.py shell\nTraceback (most recent call last):\n  File \"manage.py\", line 10, in <module>\n    execute_from_command_line(sys.argv)\n  File \"/home/tim/code/django/django/core/management/__init__.py\", line 336, in execute_from_command_line\n    utility.execute()\n  File \"/home/tim/code/django/django/core/management/__init__.py\", line 310, in execute\n    django.setup()\n  File \"/home/tim/code/django/django/__init__.py\", line 23, in setup\n    apps.populate(settings.INSTALLED_APPS)\n  File \"/home/tim/code/django/django/apps/registry.py\", line 115, in populate\n    app_config.ready()\n  File \"/home/tim/code/django/django/contrib/admin/apps.py\", line 22, in ready\n    self.module.autodiscover()\n  File \"/home/tim/code/django/django/contrib/admin/__init__.py\", line 24, in autodiscover\n    autodiscover_modules('admin', register_to=site)\n  File \"/home/tim/code/django/django/utils/module_loading.py\", line 73, in autodiscover_modules\n    import_module('%s.%s' % (app_config.name, module_to_search))\n  File \"/usr/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\n  File \"/home/tim/code/django/django/contrib/auth/admin.py\", line 182, in <module>\n    admin.site.register(Group, GroupAdmin)\n  File \"/home/tim/code/django/django/contrib/admin/sites.py\", line 101, in register\n    admin_class.check(model)\n  File \"/home/tim/code/django/django/contrib/admin/options.py\", line 149, in check\n    return cls.checks_class().check(cls, model, **kwargs)\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 492, in check\n    errors = super(ModelAdminChecks, self).check(cls, model=model, **kwargs)\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 32, in check\n    errors.extend(self._check_filter_horizontal(cls, model))\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 245, in _check_filter_horizontal\n    for index, field_name in enumerate(cls.filter_horizontal)\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 253, in _check_filter_item\n    field = model._meta.get_field(field_name)\n  File \"/home/tim/code/django/django/db/models/options.py\", line 434, in get_field\n    \"The Apps registry is still not ready, this means get_field() is not able \"\ndjango.core.exceptions.AppRegistryNotReady: The Apps registry is still not ready, this means get_field() is not able to find related objects that point to this model.\n```\n",
      "There is still some usage of `get_field_by_name()` and other deprecated APIs in the tests. Run the tests with `python -Wall runtests.py` and ensure there are no errors.\n\nThere are also a fair number of flake8 errors -- some appear not related to your changes, but rather like you haven't merged in some commits from master. I think you could probably rebase and squash most of the commits now.\n",
      "@timgraham \nRE \"I ran into this issue using the code from the tutorial: ....\"\nTotally right, I added a fix for it, currently running unit tests. It looks like some admin checks are happening prior to the apps registry being ready. This should never happen actually, so I added a fix for it.\nI'll let you know once all tests pass with -Wall\n",
      "@timgraham I have just pushed the last changes with your comments fixed.\n",
      "There are still many flake8 errors on your branch aren't there? This is what I see:\n\n```\n./django/db/models/manager.py:6:1: F401 'FieldDoesNotExist' imported but unused\n./django/db/models/options.py:13:1: F401 'Field' imported but unused\n./django/db/models/options.py:500:17: E126 continuation line over-indented for hanging indent\n./django/db/models/base.py:1420:9: F401 'FieldDoesNotExist' imported but unused\n./django/db/models/fields/__init__.py:45:1: E302 expected 2 blank lines, found 1\n./django/contrib/contenttypes/fields.py:41:15: W291 trailing whitespace\n./django/contrib/admin/utils.py:462:1: E302 expected 2 blank lines, found 1\n./django/contrib/admin/utils.py:481:1: E302 expected 2 blank lines, found 1\n./tests/prefetch_related/tests.py:723:45: E127 continuation line over-indented for visual indent\n./tests/apps/tests.py:18:1: F401 'AbstractPerson' imported but unused\n./tests/apps/tests.py:18:1: F401 'BasePerson' imported but unused\n./tests/apps/tests.py:18:1: F401 'Relation' imported but unused\n./tests/apps/tests.py:18:1: F401 'new_apps_2' imported but unused\n./tests/test_client_regress/tests.py:997:31: E127 continuation line over-indented for visual indent\n./tests/introspection/tests.py:133:18: E127 continuation line over-indented for visual indent\n```\n",
      "@aaugustin - do you know if admin checks happening prior to the app registry being ready is expected? see https://github.com/django/django/pull/3114#issuecomment-57612835. Seems suspicious to me and the workaround adds more code which isn't ideal: 3a6a7131e020b49ae3c030adddf320b32d43f3a8.\n",
      "buildbot, retest this please.\n",
      "@freakboy3742 @timgraham Latest fixes (documentation + style + implementation) have been pushed. I'm ready for a further review\n",
      "buildbot, retest this please.\n",
      "@collinanderson did the last fixes we spoke about, can you give me another rev?\n",
      "@PirosB3 It looks like most of comments on the PR have now been addressed.\n",
      "Thanks @collinanderson \nLooking forward to hear comments from @timgraham @freakboy3742\n",
      "@timgraham To me it looks like the admin checks should be triggered from `AdminAppConfig.ready()`.\n",
      "# Further API change\n\n### Properties changes\n- many_to_many becomes _many_to_many and is only used internally, as there should be no more external distinction between m2m and forward fields\n- fields, concrete_fields, local_concrete_fields become all internal, (with a _ before and not documented) , as there should be no more external distinction between m2m and forward fields\n- related_objects become reverse_fields, in order to keep the same name convention\n- we add another property called \"forward_fields\"\n- make get_fields() internal, but we don't change the endpoint name for legacy reasons (there was already a get_fields())\n\n### Final _meta API\n- field_names => [\"name\", \"surname\", ...]\n- get_field(field_name) => FieldInstance\n- forward_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- reverse_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n\n### Final internal _meta API\n- _fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- _concrete_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- _local_concrete_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- _many_to_many => [FieldInstance, FieldInstance, FieldInstance, .. ]\n",
      "Assuming we document the `FieldDoesNotExist` exception as part of this (which will be necessary) this PR should also resolve https://code.djangoproject.com/ticket/9104 one way or the other.\n",
      "@tomchristie super correct! I have not documented FieldDoesNotExist yet. Waiting till we sort out the last field flags issues and the _meta API. Once I get the final blessing on these, I will finish the documentation part.\nSaid this, isn't django.db.models.fields the correct place for this Exception?\n",
      "If we make it a public API, I am in favor of moving it to `core.exceptions` (and keeping backwards compatibility where it is now)\n",
      "@timgraham sounds good to me. We can move it there and then alias it back on db.models.fields\n",
      "\"We can move it there and then alias it back on db.models.fields\"\n\nYes, that sounds like the right thing to do.\n\nOptionally we _could_ have the `db.models.fields` version be pushed into the pending deprecation state, but I don't much mind either way on that.\n",
      "A quick question on API correctness:\n`opts.field_names` API can also return more than 1 name for each field, this usually happens with ForeignKeys, where fields can be fetched by property or property_id.\n\nThis is an example where `manager` is a ForeignKey: `{u'id', 'item', 'manager', u'manager_id', 'name'}`\n\nDo you think this is the correct way to go? or shall we exclude duplicates from `field_names`?\n",
      "Gut reaction: I'd certainly expect it to only return the canonical attribute names, and not the `_id` variants.\n\nSo long as the API gives enough information for users to be able to derive the \"_id\" style ones if needed then that would seem sufficient.\n",
      "@tomchristie interestingly Django also uses the *_id stuff internally. I suggest we keep the possibility of Django fetching fields by *_id using get_field(), but we remove duplicates in field_names\n",
      "@PirosB3 What's the hold-up in using `_meta.fields` as the main (and only) entry point? Is that backward compatibility because `fields` doesn't have \"fake\" fields like reverse relations?\n\nIf that's the case I think we have here a unique opportunity to get it right and it's easy enough to provide an upgrade path.\n"
    ],
    "num_comments": 28,
    "repository": "django/django",
    "diff_length": 248741
  },
  {
    "index": 55,
    "pr_title": "Fixed #14370 -- Added select2 widget for related object fields in admin.",
    "pr_body": "Adds jQuery Select2 version 4 to support async select inputs\r\nincluding a search feature.\r\n\r\n**I split the PR in two commits, one is vendoring select2, one contains my code.**\r\n\r\n### Links & Discussions\r\n* [djangoproject#14370](https://code.djangoproject.com/ticket/14370)\r\n* https://groups.google.com/forum/#!topic/django-developers/tCNWnLP8jzM\r\n* https://groups.google.com/forum/#!topic/django-developers/Ip63Xqw01IA/discussion\r\n* https://groups.google.com/forum/#!topic/django-developers/jGgZngTq3",
    "pr_number": 6385,
    "comments": [
      "@jpic this is a first draft, I tested it manually, it seems fine\n@timgraham I only added tests for the new json view, I'll add the widget tests in the sprint tomorrow\n",
      "Nice !\n\nDid you try it on dynamically added formset rows ?\n",
      "@jpic no that can't work yet, but I'm on it today!\nI also got a lot of documentation ahead of me, but it really depends where this is going. I'm gonna talk to a couple of people here about it.\n",
      "@codingjoe we use DOMNodeInserted event for dynamically added selects: https://github.com/yourlabs/django-autocomplete-light/blob/master/src/dal/static/autocomplete_light/autocomplete.init.js#L25-L27\n\nWe also have a really small snippet for option renaming using the edit button which you might like: https://github.com/yourlabs/django-autocomplete-light/blob/master/src/dal_select2/static/autocomplete_light/select2.js#L100-L106\n",
      "I might be able to try test this out later this week. Seems to me we should give this a release or two in the real world before deprecating raw_id_fields. Like, make sure it's good enough in practice to replace raw_id_fields.\n",
      "Does `/foreignkey_json/` do permission checks? It seems to me it should require the same permissions as raw_id_fields (so if you're logged in to the admin, you can't just query that table unless you actually have permission, but maybe that's ok)\n\nEdit: Actually, maybe we just need to make sure that you have the change permission for the Model that has the foreign key. That way it follows the permissions of a normal ChoiceField.\n",
      "@collinanderson good point, that's what I thought. Lets see how it performs.\nRegarding the permissions, you are correct, the change permission would the right thing to check. I'll put it on my list, thanks!\n",
      "There is a small typo in the diff of docs/ref/models/fields.txt: you mean `admin` not `admon`.\n",
      "@codingjoe  first: Thank you for this great improvement. Next: It would be nice if the autocomplete would be easily re-usable outside the admin, too. Do you plan to support this?\n",
      "@guettli no, not really. We have `django-select2` and `django-autocomplete-light` for that.\nThe really tricky part is to know which queryset to server as a JSON. `django-select2` solves this by using the cache as a persistent storage shared by all application servers. In `django-autocomplete-light` you'll have to specify that explicitly.\n\nI don't see a way to get this into core. This should remain a admin only feature for now, just like the raw ID field.\n",
      "@codingjoe btw, at some point we'll need to eventually get django-developers mailing list approval for vendoring select2.\n\nAlso, you've been mentioning raw_id_fields. I'm also hoping we can eventually use select2 to replace filter_horizontal/filter_vertical for m2m's.\n",
      "@codingjoe you said:\n\n> The really tricky part is to know which queryset to server as a JSON\n\nYes, this is true, since the django admin interface needs a generic ajax server part.\n\nBut I still think it would be great to have a autocomplete component in django which can be used in django apps and the django admin.\n\nYou can make a BaseWidget available which gets subclassed once in the admin interface and once for the usage in custom apps.\n\nI like small systems and having select2 twice in my static directory gives me a bad feeling. Yes it works and does not hurt, but somehow I think \"less is more - avoid redundancy\".\n",
      "You don't need to have it twice, you can reuse it. For example, this public\nfacing-app reuses admin scripts:\nhttps://github.com/jonashaag/django-addanother/blob/master/django_addanother/widgets.py#L44-L52\n\nCorrect me if I'm wrong but the idea here is to first incorporate\nautocompletion in the admin first and then perhaps extract it into\ndjango.forms.\n",
      "@jpic  nice to hear, that you want it in django.forms, too.\n\nI just ask myself if this is the best order for the steps for the implementation:\n1. in admin\n2. then in django.forms.\n",
      "@guettli @jpic I'd like to end the discussion about a feature beyond Django admin at this point. Please submit another ticket for that, it's beyond the scope of the current ticket and seems to need a longer discussion.\n",
      "@collinanderson I'm not familiar with that process, can you help me out here?\n",
      "Yeah, I also agree adding generally to forms is a lot more work, and it's something we could maybe do down the road. I think the next set is to run this all by django-developer's mailing list. Though maybe we should wait til the vendoring/dependency discussion plays out first. https://groups.google.com/d/topic/django-developers/Ip63Xqw01IA/discussion \n",
      "@collinanderson we'll need to vendor select2 anyways, it can't be a dependency for the sake of offline development and I had to manually add a wrapper to support the jQuery's `noConflict`.\n[I posted into the mailing list.](https://groups.google.com/forum/#!topic/django-developers/tCNWnLP8jzM)\n",
      "I was able to try out a little and added some notes. Super cool. :)\n",
      "@kevin-brown thanks for the review, good the have some feedback form a select2 dev\n@collinanderson thanks to you too of course :)\nI'll try to get your these changes in this weekend and add some of the tests that I'm still missing.\n",
      "Ok, I fixed all the review notes and added support for M2M fields. That was actually a 1 liner :)\n",
      "Awesome. formsets/inlines are working for me, and m2m is also working well. This is so cool.\n\nIt looks like there's just one test failure that needs to be fixed?\n",
      "Also, I think there should be a check to be sure the User has access to change the model containing the field.\n",
      "@timgraham I'm slowly getting there. One question, I want to add system checks, as we have for `raw_id_fields`. Should I add new once or make the one for `raw_id_fields` check the `autocomplete_fields` as well?\nhttps://docs.djangoproject.com/en/1.9/ref/checks/#admin\n",
      "No string opinion but I guess I don't see much harm in reusing the existing error codes for the checks if they work similarly.\n",
      "Ok, I'm done with my own checklist. I need some serious reviews now to get going.\n\n@timgraham since I didn't no one was against vendoring Select2, I don't see anything holding this feature back. I'd like to start writing release notes, when would this be released?\n",
      "1.10 alpha is scheduled for May 16 so there's probably enough time to get this polished by then.\n",
      "Please add tests in `tests/admin_checks` for the new checks.\n",
      "A small bug: after using the pencil icon to open a pop and edit the related object, the representation of the object in the select box isn't updated after clicking the save of the popup.\n\nAlso I'm getting a `NoSuchElementException` failure for (admin_views.test_autocomplete_view.SeleniumTests.test_select `on both Firefox and Chrome.\n",
      "@timgraham they are not updated, because there isn't really a way to do that in select2 üòû \n"
    ],
    "num_comments": 30,
    "repository": "django/django",
    "diff_length": 68339
  },
  {
    "index": 56,
    "pr_title": "Schema alteration",
    "pr_body": "To accompany the mailing list thread here: https://groups.google.com/forum/?fromgroups=#!topic/django-developers/esCFLLXwIOY\n",
    "pr_number": 376,
    "comments": [
      "Andrew - it's occurred to me that this may not address the situation when someone starts a project then switches to a swapped user model - I am **NOT** talking about the data migration fore user data (people are own for that) - but raising the issue of what, if anything, needs to be done when a model._meta.swapped goes from False to True from one migration to the next.\n\nNot really being familiar with the core approach here, I don't even know if anything needs to be done, just realizing that this was probably developed before _meta.swapped was introduced and pointing that out. cc @freakboy3742 \n",
      "@ptone - @andrewgodwin is at least peripherally aware of the problem; I've already raised a bug on South's tracker about integration with AUTH_USER_MODEL. \n\nFully swapping the User model is a bit of a nightmare; On the South ticket, I suggested that a perfectly acceptable first pass is to disallow this - i.e., initial sync records the AUTH_USER_MODEL in use, and future migrations won't allow it to be changed. This is what we suggest in the docs anyway, so I don't see any problem with enforcing it.\n",
      "Yes, Russ has filed this in the South tracker already and I've not been able to take a good look at it yet. I suspect the first pass will be that we just moan, though I'd like to do something more intelligent (spit out a skeleton migration for swapping the tables out and preserving data, and letting them finish it off, perhaps).\n",
      "I just created a migration and the file shows:\n\n```\n    dependencies = [(u'testb', '0001_initial')]\n```\n\n-- That doesn't work on 3.2, you might also want to import unicode_literals, depending on whether you want text or bytes for everything.\n\nEDIT:// The fields also have unicode markers from time to time:\n\n```\n            fields = [(u'id', models.AutoField(verbose_name=u'ID', serialize=False, auto_created=True, primary_key=True),), ('char', models.CharField(max_length=256),), ('fk', models.ForeignKey(to=u'testb.TestB', to_field=u'id'),)],\n```\n",
      "Is there any way to not get asked everytime if you want to enable migrations for an app? \n",
      "I get migrations which are getting unapplied without me asking for it:\n\n```\nflorian@apollo13:~/.virtualenvs/522125f0c8c708a8/migrationtest$ ./manage.py migrate\nOperations to perform:\n  Synchronize unmigrated apps: sessions, admin, messages, testc, auth, staticfiles, contenttypes\n  Apply all migrations: testa, testb\nSynchronizing apps without migrations:\n  Creating tables...\n    Creating table django_admin_log\n    Creating table auth_permission\n    Creating table auth_group_permissions\n    Creating table auth_group\n    Creating table auth_user_groups\n    Creating table auth_user_user_permissions\n    Creating table auth_user\n    Creating table django_content_type\n    Creating table django_session\n    Creating table testc_test\n  Installing custom SQL...\n  Installing indexes...\nInstalled 0 object(s) from 0 fixture(s)\nRunning migrations:\n  Applying testb.0001_initial... OK\n  Applying testa.0001_initial... OK\n  Applying testa.0002_auto... OK\n  Unapplying testa.0002_auto... OK\n  Unapplying testa.0001_initial... OK\n\nYou just installed Django's auth system, which means you don't have any superusers defined.\nWould you like to create one now? (yes/no): no\nflorian@apollo13:~/.virtualenvs/522125f0c8c708a8/migrationtest$ ./manage.py migrate\nOperations to perform:\n  Synchronize unmigrated apps: sessions, admin, messages, testc, auth, staticfiles, contenttypes\n  Apply all migrations: testa, testb\nSynchronizing apps without migrations:\n  Creating tables...\n  Installing custom SQL...\n  Installing indexes...\nInstalled 0 object(s) from 0 fixture(s)\nRunning migrations:\n  Applying testa.0001_initial... OK\n  Applying testa.0002_auto... OK\n  Unapplying testa.0002_auto... OK\n  Unapplying testa.0001_initial... OK\n```\n\nPing me in IRC if you need details.\n",
      "@apollo13 That's weird, I'll look into it.\n\nAs for the asking every time, that's something that still needs to be resolved (current solution works, but is REALLY ANNOYING). The proposal I like most is having them enabled in the new app template, and then having this just assume they're disabled unless migrations directory is present.\n",
      "@andrewgodwin more details (from irc):\n\n```\n<apollo13> andrewgodwin: are you around? testa has a fk to testb, testb changes are \"stable\" so to say\n<apollo13> andrewgodwin: also, since django itself asks \"Would you like to create one now? (yes/no): no\"  -- we might wanna change [y/n] to stay consistent? [sry]\n```\n\nand migrating manually works:\n\n```\nflorian@apollo13:~/.virtualenvs/522125f0c8c708a8/migrationtest$ ./manage.py migrate testa 0001_initial\nOperations to perform:\n  Target specific migration: 0001_initial, from testa\nRunning migrations:\n  Applying testa.0001_initial... OK\n```\n",
      "Trying to migrate apps not in INSTALLED_APPS shows a confusing error:\n\n```\nflorian@apollo13:~/.virtualenvs/522125f0c8c708a8/migrationtest$ ./manage.py migrate fsdgdshdsfdsgdfshgds 0001_initial\nCommandError: App 'fsdgdshdsfdsgdfshgds' does not have migrations (you cannot selectively sync unmigrated apps)\n```\n\nSomething like \"this app doesn't exist\" would be better.\n",
      "Almost none of the new files import unicode_literals (and many of the files have string literals).\n",
      "I see different failures from what you described in the ML, and even more failures if I run just the tests for migrations and schema; I'm pretty sure several tests here depend on operations performed in other tests. This probably applies mostly to database systems which do not support transactional DDL, like Oracle and MySQL.\n",
      ":sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: \n",
      "![Thumbs up!](http://georgebrock.com/images/thumbsup.gif)\n",
      "[![LGTM](http://i.imgur.com/azxpEtW.jpg)](http://www.lgtm.in/i/Z2e)\n"
    ],
    "num_comments": 14,
    "repository": "django/django",
    "diff_length": 373926
  },
  {
    "index": 57,
    "pr_title": "Fixed #12990 -- Added JSONField model field.",
    "pr_body": "### This pull request is closed. Please look at #12392 instead.\r\n\r\n---\r\n\r\nTicket [#12990](https://code.djangoproject.com/ticket/12990), as part of the [Google Summer of Code](https://g.co/gsoc) program.\r\n\r\nSome points:\r\n- Currently supports storing and retrieving any valid JSON value (boolean, integer, float, string, object, array) on all supported database backends (SQLite, PostgreSQL, MySQL, MariaDB, Oracle).\r\n  Note: Oracle only supports JSON object and array if `IS JSON` constraint is enable",
    "pr_number": 11452,
    "comments": [
      "Any clue on which version of MariaDB is used on [djangoci.com](//djangoci.com)? The `json` data type is introduced in MariaDB 10.2.7.",
      "> Any clue on which version of MariaDB is used on [djangoci.com](//djangoci.com)? The `json` data type is introduced in MariaDB 10.2.7.\r\n\r\ndjangoci uses MariaDB 10.1.40. I can bump MariaDB version in the next few days. We need to remember that [Django 3.0 supports](https://docs.djangoproject.com/en/dev/ref/databases/#mariadb-notes) MariaDB 10.1 and higher so a new db feature is required e.g. `has_json_field`.",
      "> > Any clue on which version of MariaDB is used on [djangoci.com](//djangoci.com)? The `json` data type is introduced in MariaDB 10.2.7.\r\n> \r\n> djangoci uses MariaDB 10.1.40. I can bump MariaDB version in the next few days. We need to remember that [Django 3.0 supports](https://docs.djangoproject.com/en/dev/ref/databases/#mariadb-notes) MariaDB 10.1 and higher so a new db feature is required e.g. `has_json_field`.\r\n\r\nI see. I'll try to add it later.",
      "> djangoci uses MariaDB 10.1.40. I can bump MariaDB version in the next few days. We need to remember that Django 3.0 supports MariaDB 10.1 and higher so a new db feature is required e.g. has_json_field.\r\n\r\nHow about `supports_json` ? It's not really a separate data type on SQLite or MariaDB.",
      "> > djangoci uses MariaDB 10.1.40. I can bump MariaDB version in the next few days. We need to remember that Django 3.0 supports MariaDB 10.1 and higher so a new db feature is required e.g. has_json_field.\r\n> \r\n> How about `supports_json` ? It's not really a separate data type on SQLite or MariaDB.\r\n\r\nIt is also not a separate field on Oracle, but a feature flag will determine if backend has JSON field or not, so ... :thinking:   ",
      "@laymonage I updated MariaDB to 10.2.24 on Jenkins.",
      "> @laymonage I updated MariaDB to 10.2.24 on Jenkins.\r\n\r\nThanks! As expected, the tests have passed now.\r\n\r\nI have added a `supports_json` feature (can be renamed if desired). Not sure if I should check the SQLite version, though. I don't think there's any way to check if the JSON1 extension is enabled (maybe we could try to do `SELECT json('\"test\"')`, but that's a bit hack-ish).\r\nThe JSON1 extension was introduced with the release of SQLite 3.9.0. However, since it's a loadable extension, it *might* work if it's loaded on older SQLite version(s). I haven't tried.\r\n\r\nAlso, I'm not sure if I should use `check` and extend the list returned by that method instead of raising a `NotSupportedError`. I've seen both examples in the existing codebase.",
      "I've added a form field. It's pretty much the one in `contrib.postgres`, but I omitted the field value in the invalid JSON error message and changed the tests accordingly.",
      "> I have added a supports_json feature (can be renamed if desired). Not sure if I should check the SQLite version, though. I don't think there's any way to check if the JSON1 extension is enabled (maybe we could try to do SELECT json('\"test\"'), but that's a bit hack-ish).\r\n> The JSON1 extension was introduced with the release of SQLite 3.9.0. However, since it's a loadable extension, it might work if it's loaded on older SQLite version(s). I haven't tried.\r\n\r\nI think trying the `json` function and catching the error isn't so bad, as long as it won't break any transactions.\r\n\r\nThe other option is to use `PRAGMA compile_options` and check if the extension is in there, however I am not sure if it's possible to load the `json1` extension without it being built in at compile time...\r\n\r\n```\r\nsqlite> PRAGMA compile_options;\r\nBUG_COMPATIBLE_20160819\r\nCOMPILER=clang-10.0.1\r\nDEFAULT_CACHE_SIZE=2000\r\nDEFAULT_CKPTFULLFSYNC\r\nDEFAULT_JOURNAL_SIZE_LIMIT=32768\r\nDEFAULT_PAGE_SIZE=4096\r\nDEFAULT_SYNCHRONOUS=2\r\nDEFAULT_WAL_SYNCHRONOUS=1\r\nENABLE_API_ARMOR\r\nENABLE_COLUMN_METADATA\r\nENABLE_DBSTAT_VTAB\r\nENABLE_FTS3\r\nENABLE_FTS3_PARENTHESIS\r\nENABLE_FTS3_TOKENIZER\r\nENABLE_FTS4\r\nENABLE_FTS5\r\nENABLE_JSON1\r\nENABLE_LOCKING_STYLE=1\r\nENABLE_PREUPDATE_HOOK\r\nENABLE_RTREE\r\nENABLE_SESSION\r\nENABLE_SNAPSHOT\r\nENABLE_SQLLOG\r\nENABLE_UNKNOWN_SQL_FUNCTION\r\nENABLE_UPDATE_DELETE_LIMIT\r\nHAVE_ISNAN\r\nMAX_LENGTH=2147483645\r\nMAX_MMAP_SIZE=1073741824\r\nMAX_VARIABLE_NUMBER=500000\r\nOMIT_AUTORESET\r\nOMIT_LOAD_EXTENSION\r\nSTMTJRNL_SPILL=131072\r\nTHREADSAFE=2\r\nUSE_URI\r\n```",
      "> I think trying the json function and catching the error isn't so bad, as long as it won't break any transactions.\r\n\r\nI'm not sure where and how to properly put it in Django's source code, though.\r\n\r\n---\r\n\r\nI tried compiling SQLite 3.28.0 without JSON1, compiling JSON1 separately, and loading it with the `.load` command.\r\n`SELECT JSON('\"test\"');` works, but `ENABLE_JSON1` doesn't show up with `PRAGMA compile_options` (which is correct since I didn't build JSON1 along with SQLite).\r\n\r\nOn the other hand, I also tried loading JSON1 (compiled from SQLite 3.28.0 source code) on SQLite 3.8.7.1 (what's available on Debian Jessie). This SQLite version supports extension loading, but I got a segmentation fault when I tried to load JSON1. So, I guess it needs SQLite 3.9.0 and up.\r\n\r\nBy the way... JSON1 is also enabled by default if SQLite is compiled using `make` with the amalgamation and the given configurations.",
      "> I'm not sure where and how to properly put it in Django's source code, though.\r\n\r\nYou can use a `@cached_property` for the feature, for example https://github.com/django/django/blob/master/django/db/backends/mysql/features.py#L110",
      "> > I'm not sure where and how to properly put it in Django's source code, though.\r\n> \r\n> You can use a `@cached_property` for the feature, for example https://github.com/django/django/blob/master/django/db/backends/mysql/features.py#L110\r\n\r\nYeah, I've used it in my `supports_json` DB feature. What I mean is, should I do something like this?\r\n\r\n```python\r\ntry:\r\n    with self.connection.cursor() as cursor:\r\n        cursor.execute(\"SELECT JSON('\\\"test\\\"')\r\nexcept DatabaseError:\r\n    return False\r\nelse:\r\n    return True\r\n```",
      "That looks like what I was thinking of, though you might need a `transaction.atomic` around it to prevent the error from breaking any current transaction - at least that's the way it works with some kinds of error on other databases, I'm no SQLite expert.",
      "~~I'm thinking of adding~~ I added custom encoder and decoder support for the form field.~~, but I'm not sure if it makes sense. Any thoughts?~~",
      "> No, `json.dumps` and `json.loads` take `None` as the default argument for the `cls` parameter. See https://docs.python.org/3/library/json.html#json.dumps.\r\n\r\nActually, I didn't test it but I saw [this part](https://github.com/django/django/blob/698df6a009cb1c4dbd55905264f24f6edf41066e/django/contrib/postgres/fields/jsonb.py#L25) in code.",
      "> I believe the first argument in functions returned by `get_db_converters` in a `Field` should take the field's value. I'm not sure keeping it inside the class and use `@staticmethod` is a better option.\r\n> \r\n> Such functions are mostly found in the backend (https://github.com/django/django/blob/master/django/db/backends/oracle/operations.py#L164). Since there's `get_db_converters` in the field, I decided to use that to avoid modifying the backend too much. If modifying the backend is preferred, I can do it that way.\r\n\r\nI would move under class as instance method.",
      "> Actually, I didn't test it but I saw [this part](https://github.com/django/django/blob/698df6a009cb1c4dbd55905264f24f6edf41066e/django/contrib/postgres/fields/jsonb.py#L25) in code.\r\n\r\nYes, but that's unnecessary since the default argument is `None`.\r\n\r\n> I would move under class as instance method.\r\n\r\nI don't think that would work since the first argument would be the `JSONField` instance, instead of the value?\r\n",
      "@laymonage Thanks for updates :+1: I think that we should currently move all PostgreSQL tests related with JSONField (e.g. `postgres_tests/test_json.py`) to all databases scope and start to work on failures. I would also recommend to remove current implementation from `contrib.postgres` and for backward compatibility leave it only as a reference to a new implementation (probably some workaround should be added to migrations):\r\n\r\n- `django.contrib.postgres.fields.JSONField` -> `django.db.models.JSONField`,\r\n- `django.contrib.postgres.forms.JSONField` -> `django.forms.JSONField`,\r\n\r\nFor example, `django/contrib/postgres/fields/jsonb.py`:\r\n```python\r\nfrom django.db.models import JSONField\r\n\r\n__all__ = ['JSONField']\r\n```\r\nall lookups should be moved from `contrib/postgres/fields/jsonb.py`  to `db/models/lookups.py`.\r\n\r\nWith these changes we will be able to find caveats for each database :male_detective: .",
      "@laymonage It's easier to review new changes when you push more commits instead of force-pushing. We will squash commits at the end (before a final review).",
      "@felixxm I remember some folks saying it'd be better to leave the current implementation in `contrib.postgres` as it is (and add a deprecation message). However, I see your idea is reasonable, as long as we can maintain all of the lookups and transforms. I guess I'll try going down that route and see if we can do that.\r\n\r\nMeanwhile, I've removed some tests in `postgres_tests` and incorporated them into `test_jsonfield.py`.\r\n\r\nSome updates:\r\n\r\n- `JSON_VALID(NULL)` returns `0` (false) on SQLite, while it returns true on MySQL and MariaDB (or maybe the check just doesn't occur). This makes it impossible to store SQL `NULL` even if we specify `blank=True, null=True`. I've updated the SQLite constraint with `OR \"%(column)s\" IS NULL` and now it works correctly.\r\n- Oracle Database stores SQL `NULL` as an empty string `''` on fields that support empty strings. I've updated `JSONField` to accommodate this behavior. Saving empty Python strings would still work, as they would be encoded as `'\"\"'`.\r\n- I've refactored the tests into different classes for cohesiveness.",
      "> @laymonage It's easier to review new changes when you push more commits instead of force-pushing. We will squash commits at the end (before a final review).\r\n\r\nAh, yes. I was wondering if I should do that. Thanks for the reminder.\r\nEdit: Done. I guess I should've done so earlier, but oh well... :sweat_smile: ",
      "I've implemented `HasKey`, `HasAnyKeys`, and `HasKeys` lookups on all database backends.\r\n\r\nI still have a bit of a problem on Oracle, though. It seems that parameterized values in SQL queries aren't quoted on Oracle. The `JSON_EXISTS` function requires the path to be a literal, so it has to be quoted. I tried adding the quote manually into the template, but it didn't work until I formatted the string and left out the path from the SQL params. However, of course, I'm afraid this would allow SQL injections.\r\n\r\nI'm not very familiar with Oracle Database, so any help is highly appreciated.",
      "Apparently, it's not because the values aren't quoted.  \r\ncx_Oracle uses bind variables:  \r\nhttps://www.oracle.com/technetwork/articles/dsl/prez-python-queries-101587.html\r\nhttps://oracle.readthedocs.io/en/latest/plsql/bind/\r\n\r\nBasically, query parameters get passed using variables, so queries look like this on Oracle:\r\n\r\n```sql\r\nSELECT * FROM TABLE WHERE col1 = :arg1 AND col2 = :arg2 ...\r\n```\r\n\r\nand the arguments can be passed using a dictionary, kwargs, or sequence (list, tuple), e.g.\r\n```python\r\nparams = {'arg1': 'hello', 'arg2': 'world'}\r\n```\r\n\r\n(see also: https://github.com/django/django/blob/master/django/db/backends/oracle/base.py#L478)\r\n\r\nThe problem is, `JSON_EXISTS` function on Oracle [doesn't support bind variables](https://stackoverflow.com/questions/48913687/jdbc-prepared-statement-to-query-json-using-json-exists). We can format the arguments directly into the SQL string (which is what I've done), but this opens up the possibility of SQL injections.\r\n\r\nHowever, I do `json.dumps()` on the specified key before formatting it, so the key will be double-quoted. If someone were to execute an SQL injection, they should end the quote first, which I don't think is possible since `\"` will be escaped by `json.dumps()` into `\\\"`. I think the worst that could happen is a `DatabaseError`. I currently can't think of a key string that can be used to perform an SQL injection.\r\n\r\nShould we go through with it, or drop support for these lookups on Oracle?\r\n\r\n",
      "@laymonage I *think* json.dumps is sufficient protection against an SQL attack. Really weird that Oracle doesn't support binding variables for some functions, but hey Oracle seems weird. @felixxm might have an opinion as an ex-Oracle user.",
      "Thanks a lot for the feedback. I started working on the lookups and transforms on MySQL using @adamchainz's and @raphaelm's existing code. It turns out that the code doesn't pass all of the tests from `contrib.postgres`, so I still have to fix things up.\r\n\r\nI also try to simplify or find better ways to implement the lookups and transforms, but fixing one thing tends to break another. It's very confusing, to be honest. Not to mention debugging it isn't so easy since I have to inspect the queries most of the time... :grimacing: \r\n\r\nEdit: on the other hand, `TestQuerying` test cases aren't run by djangoci. What's up with that?",
      "All tests now pass on MySQL.\r\n\r\nI found an issue with MariaDB: there's no function that converts JSON values into their equivalent SQL values. I could work around it for the most part, and now all the tests pass, except one: ordering by JSON values.\r\nSee this dbfiddle for a demonstration: https://dbfiddle.uk/?rdbms=mariadb_10.2&fiddle=2b4cbd4c5106f6a9d701be516c2a315b\r\n\r\nWe could try `CAST`ing the values into `SIGNED` integers, but that doesn't really solve the issue. I guess we could just add a notice on the docs to say that the values would only be ordered by the string representation of the JSON values. I don't think there's any other option.",
      "I've implemented the transforms and lookups on Oracle. Some features aren't supported, so I skipped the tests for those on Oracle.\r\n\r\nSome notes:\r\n- I didn't choose to implement it using the simple dot-notation syntax.\r\n  It's mainly because it requires the tables to be given aliases in the query. I could not find an easy and clean way to do that. The [oracle_json_field](https://github.com/Exscientia/oracle-json-field/blob/master/oracle_json_field/managers.py) package uses a custom Queryset and Manager with forced self-join to make table aliases.\r\n- In effect, I had to use `JSON_QUERY` to retrieve JSON objects and arrays, and `JSON_VALUE` to retrieve scalar values. To combine this, I used `COALESCE`. I probably should use `models.functions.Coalesce` for this, but if that's the case, it would make sense to also write `JSON_QUERY` and `JSON_VALUE` functions. It would probably add a little overhead on the Python-side. I'm not sure if I should do this. If I should, I'll probably also write some JSON `Func`s for all database backends that support them. For now, I'm just writing `COALESCE` directly into the SQL.\r\n- On the upside, using `JSON_QUERY` and `JSON_VALUE` supports querying > 4 KBytes of data while using the dot-notation syntax does not.",
      "I've implemented the transforms and lookups on SQLite. It turns out I can reuse most of the code from MySQL implementation. I only had to handle the case for querying JSON `null` values in JSON objects to differentiate them from missing keys (by using the `JSON_TYPE` function).\r\nSurprisingly, the support is equivalent to MySQL, which is much better than on Oracle.\r\n\r\nI have also added tests for storing JSON `null` scalar values. It is possible to do so by using `Value` during object creation. However, the Python representation of SQL `NULL` and JSON `null` are the same, i.e. `None`.",
      "I think I've found a way to implement `contains` and `contained_by` on SQLite and Oracle. I'll see what I can do.",
      "I managed to get `contains` working on SQLite and Oracle, though it was a bit of a hack since they both don't include a function similar to `JSON_CONTAINS`. It seems to work fine for its intended use (a `dict` rhs, to be checked on the top level of the JSON document). I added more tests, but I cannot guarantee it to work uniformly across all backends, especially for scalar and array rhs.\r\n\r\nEdit: I cannot think of a way to implement `contained_by`. Without a `JSON_CONTAINS` function, one would need to enumerate the JSON document in the database, which I think is impossible to do in one query."
    ],
    "num_comments": 30,
    "repository": "django/django",
    "diff_length": 150948
  },
  {
    "index": 58,
    "pr_title": "Checking framework",
    "pr_body": "This branch is part of my Google Summer of Code 2013 project. It's not intended to be merged, it's only to make deep review easier.\n\nSee discussion of checking framework on django-developers: https://groups.google.com/forum/?fromgroups=&hl=en#!topic/django-developers/fEf21dtpqDE\n",
    "pr_number": 1364,
    "comments": [
      "I've made error message single-line so there is no short/long description separation. See https://github.com/chrismedrela/django/commit/1929a8c3565bdd6aa36b8ce3f578f34091105d59.\n",
      "@chrismedrela can you push over the fixes from your main GSOC branch to this review branch - looks like lots of updates have been made, but it will be easier to review the whole branch in one place.\n",
      "It is great to see validation.py get replaced with something far more sane - and I think the overall approach is good.\n\nIn addition to my line level comments - here are some overall thoughts:\n\nThere are a number of places where related field checks are skipped if the the value is a string - I'm assuming for lazy resolution. Shouldn't we be in a position by the time checks are done to have all related fields connected? It seems that potential problems that are checked for are now deferred to runtime leaving users with \"why did this setup pass checks and now bombs?\"\n\nI wish there was a way to test this without the brittle problem of doing essentially string comparisons on the error messages. Any typo fixes or rewording means updating the docs. Unfortunately I don't have any bright ideas. When hitting a similar situation for SuspiciousOperation the solution was to create specific subclasses - but that seems like the wrong type of fix here.\n\nThere is a bit too much opaque use of **kwargs being passed around - it is fine for this, but if the design of this feature were to be much more complex than it is, it would be an ass-biting laying in wait.\n\nAs said in a comment, I think the \"check_all_models\" adds enough enhancement and exposes enough checking API for this feature without also adding the global \"registration\" of custom check functions.\n\nThe docs will need some more polish (I'm willing to help - left no comments yet), and actual deprecations need to be started.\n\nI'm NOT NOT NOT a coverage zealot but I did run my little diff coverage tool on the branch which found the following lines that were added/changed that are not tested:\n\nhttps://gist.github.com/ptone/fa491c101de3bc4fc5c7\nhttp://ptone.com/temp/checks-coverage/ (untested changes have block red line numbers)\n\n100% coverage should not be a blind objective, but it can be helpful for you to see any major untested areas, but overall the tests looked good.\n\nThanks for the tremendous amount of work during your GSOC.\n",
      "Thanks for the review, Preston -- much appreciated to have another set of eyes on the codebase.\n\nRegarding the string resolution of related field names -- that's mostly inherited from the old codebase -- Chris hasn't introduced anything new there. You're completely correct that at the point checks are performed, all the models _should_ be resolved. I'll stand corrected on this, but as I recall, the reason the string exclusions exist is so that when a bad model has been referenced, we can catch the fact that it hasn't been resolved, report that problem, and then perform any other checks that are appropriate. However, some checks will break hard if the foreign key reference hasn't been resolved, so you need to skip over those checks.\n\nRegarding the tests checking string content -- I agree that isn't ideal. A stretch goal for this project is to enable pyflakes-style warning/error suppression -- so you'll be able to register that you don't care about E115, and have errors of that type suppressed. This will also give us a simple constant against which we can perform tests. \n\nThe *_kwargs usage is a 'room for expansion' thing, much like the use of *_kwargs on save(). The idea is that you might be able to pass in specific qualifiers or modifiers to the checks; we don't know exactly what they will be -- one use at the moment is \"the app name\", but there could be others. Requiring **kwargs in the prototype for check methods means any future flags will be silently ignored, but can be specifically catered for when appropriate.\n\nAdding custom check functions was a specific goal for the project, with security checks being the use case validating the need for the feature. \n\nCompletely agreed on docs needing polish before this is merged -- that's true of any project, however. I'll certainly remember to call on you when we get to a merge point :-) \n\nThanks for the hit list on coverage, too. My validation to date has been a line-for-line comparison with the old validation checks; that means we should be at least as covered as we were previously, but doesn't account for previously existing testing holes.\n",
      "Am I correct that this issue implies that a default value should always be set, and that this could be a check added to BooleanField?\n\nhttps://github.com/django/django/pull/1466/files\n",
      "Preston, thank you very much for your review! Your comments helped me to improve the code and I really appreciate it.\n\nI went through list of all untested lines. Some of them were just dead lines (so they had no chance to be executed). The rest was result of lack of tests. I don't have too much time, so I wrote tests only for those lines which were easy to cover.\n\nYes, I agree that the check in #1466 pull request should be moved to `BooleanField`.\n",
      "Regarding the naming, what about \"Runtime checks\"?\n\nFor more inspiration, maybe these two links can help:\n- http://en.wikipedia.org/wiki/Static_program_analysis.\n- http://en.wikipedia.org/wiki/Dynamic_program_analysis.\n",
      "@loic, thank you for your input. I've had a look at these wiki pages, but I think that we will stay with \"system checks\" -- I cannot see any option that is _much_ better.\n",
      "One thing I'm curious about: how should we (whether that's Django or third-parties) decide what validation should be done by this checking process, and what should be done in `__init__()`? A number of fields do checks in `__init__()` and raise exceptions there - for example, `FileField` will raise a `TypeError` from `__init__()` if you try to pass it a `unique` argument, but it will not check `upload_to` until model checking.\n\nSince `__init__()` is always run, while model checking is generally only run in development, it would seem that this distinction matters most in a production environment. Since model checking is skipped there, under the assumption that problems have already been addressed in development, perhaps the distinction should be that `__init__()` only does the validation necessary to make the code actually run, while all correctness checks are done by the checking process.\n\nAny thoughts?\n",
      "@marfire I think you've found an unusual edge case of the old validation design.\n\nThe only examples of exceptions raised in `__init__()` that I can find are:\n- AutoField (rejecting `primary_key=False`), \n- FileField (rejecting `primary_key` and `unique` arguments). \n- ForeignKey/M2M (rejecting references to abstract models, and references that aren't a model or a string)\n\nHistorically, implementing these checks in validation.py would have meant extending the 'type specific' blocks in validation.py. Although these blocks already existed, it's not an especially good design pattern (putting all your validation logic in one place), so those three cases of localized validation have slipped in. \n\nI'm fairly certain that these checks could all be converted into system checks without any real change in behavior; and given that we're now moved to a 'check behavior stored on the field' archictecture, we can avoid the bad architecture. We also get slightly improved error reporting behavior as well -- under the current setup, if you have multiple ForeignKeys pointing to an abstract model, each one would be reported as an individual exception. Using a check-based approach, you'd get a summary of _all_ the bad references at once.\n\nAs for third party fields -- historically, they haven't had a choice. They've had to use assertions in `__init__`, because they didn't have access to validation.py. This is one of the reasons behind a move to a checking framework.\n\nSo - my advice for third parties (once this all lands in trunk) would be to use checks, rather than assertions in `__init__` checks -- and, for backwards compatibility, do both :-)\n",
      "@freakboy3742 Thanks for the clarification. That's good news - it's certainly nicer to do everything in system checks than it is to split the work with `__init__()`. \n",
      "I've rebased this branch. I've also improved documentation. I've also fixed the problem of compatibility checks -- I've added new `is_overridden` method to `Settings` and `UserSettingsHolder`. @ptone, do you have time to review documentation? This is the last thing we need to do in order to merge this branch.\n",
      "@chrismedrela Thanks for rebasing, but at this point, that's not strictly necessary; I've got a copy of this project in a branch of my own that I've been polishing when I get a chance. I'm hoping to get some time this week to take a good stab at it. \n\nOf course, documentation reviews are always welcome :-)\n",
      "Are we still trying to merge this for 1.7 alpha on Monday? Looks like it's at least in need of a rebase to merge cleanly.\n",
      "My intention is to merge for 1.7, yes. I'm hoping to find some time in the evenings this week (nothing quite like the last minute‚Ä¶)\n",
      "I'm going to close this PR now; this one was used as the work-in-progress during the GSoC period. I've completed a final review and rebase against trunk ready for 1.7 alpha. This review includes the comments @timgraham made over the last few days to the documentation.\n\nThe new PR is #2181.\n"
    ],
    "num_comments": 16,
    "repository": "django/django",
    "diff_length": 467197
  },
  {
    "index": 59,
    "pr_title": "Refs #28643 -- Added math database functions.",
    "pr_body": "Added ACOS, ASIN, ATAN, ATAN2, CEILING, COS, COT, DEGREES, EXP,\r\nFLOOR, LOG, MOD, PI, POWER, RADIANS, ROUND, SIN, SQRT, TAN\r\nABS was added according to the commit by onkruid. \r\nAny suggestion is welcome!",
    "pr_number": 9622,
    "comments": [
      "> It seems that the test_math.py cannot import my math functions. However, it works just fine for me locally. Could anybody help me with that?\r\n\r\nAre you still struggling with that?\r\n\r\nIt seems a bit odd to me, PY2 could have got mixed up between the absolute `math` package and the relative one, but PY3 doesn't have this issue.\r\n\r\nHave you tried clearing `__pycache__`?",
      "@loic I think I found the reason. Thank you very much. ",
      "`.. module:: django.db.models.functions.math` remove this, and try again. The toplevel `..versionadded: 2.1` ought be enough. `PI` should be `Pi` IMO.",
      "@atombrella Thank you very much for the suggestions! I followed your instructions and now it works.",
      "@auvipy It supports sqlite, Mysql, postgresql and oracle.",
      "@pope1ni The test on oracle backend paused because of conflicts of releases/2.1.txt. It seems that the release/2.1.txt has been updated since my last commit. Do I need to resolve the conflict?\r\n\r\nI have tried to fetch the most recent releases/2.1.txt from django/django and update my local file based on this version. However, it doesn't work. There is still conflict after my update. Any suggestion?\r\n\r\nJunyi ",
      "(Sorry - GitHub seemed to break my review into pieces...)",
      "@pope1ni @atombrella Thank you so much for the reviews and suggestions. I am working on them now. Thank you for the detailed explanations and the comments really helps a lot. \r\n",
      "@pope1ni I have revised the code based on the review/comments and finished updating most of them. However, I noticed that there is no tests running for my last two commits. Is there any issue? Did I commit too much that the system prohibited running tests on my code?",
      "You can squash your commits and force push. That should trigger a build.",
      "@timgraham Thanks for the advice. I tried squash commits and force push, but it didn't trigger a build. Any suggestions?",
      "Hi @pope1ni I have resolved the conflicts now. Thank you. The conflicts resolving part is more complicated than I expected.",
      "I am a little bit surprised that none of the automatic tests test database oracle (correct me if I am wrong). @felixxm @pope1ni @atombrella @timgraham ",
      "@pope1ni Totally agreed with all your comments, thanks! :bowing_man: :rocket: ",
      "Thank you @pope1ni @felixxm for helping the oracle functions. I have committed all the changes as you suggested.",
      "Hi @pope1ni @felixxm @timgraham Thank you so much for your comments and review suggestions. I am wondering whether there is anything else to change or not? If not, could you help test on oracle and then merge it?",
      "Thank you for your patience, @JunyiJ. This is coming together well now.\r\n\r\nThere are a couple of things that I can think of outstanding.\r\n\r\n1. As suggested by @felixxm, we can now remove `django_power`:\r\n    ```diff\r\n    diff --git a/django/db/backends/sqlite3/base.py b/django/db/backends/sqlite3/base.py\r\n    index a9753bb094..07b153cd22 100644\r\n    --- a/django/db/backends/sqlite3/base.py\r\n    +++ b/django/db/backends/sqlite3/base.py\r\n    @@ -6,2 +6,3 @@ import decimal\r\n     import math\r\n    +import operator\r\n     import re\r\n    @@ -170,3 +171,2 @@ class DatabaseWrapper(BaseDatabaseWrapper):\r\n             conn.create_function(\"django_format_dtdelta\", 3, _sqlite_format_dtdelta)\r\n    -        conn.create_function(\"django_power\", 2, _sqlite_power)\r\n             conn.create_function('LPAD', 3, _sqlite_lpad)\r\n    @@ -187,3 +187,3 @@ class DatabaseWrapper(BaseDatabaseWrapper):\r\n             conn.create_function('PI', 0, lambda: math.pi)\r\n    -        conn.create_function('POWER', 2, _sqlite_power)\r\n    +        conn.create_function('POWER', 2, operator.pow)\r\n             conn.create_function('RADIANS', 1, math.radians)\r\n    @@ -498,5 +498 @@ def _sqlite_rpad(text, length, fill_text):\r\n         return (text + fill_text * length)[:length]\r\n    -\r\n    -\r\n    -def _sqlite_power(x, y):\r\n    -    return x ** y\r\n    diff --git a/django/db/backends/sqlite3/operations.py b/django/db/backends/sqlite3/operations.py\r\n    index 10b064d966..65796ea8a2 100644\r\n    --- a/django/db/backends/sqlite3/operations.py\r\n    +++ b/django/db/backends/sqlite3/operations.py\r\n    @@ -274,6 +274,6 @@ class DatabaseOperations(BaseDatabaseOperations):\r\n         def combine_expression(self, connector, sub_expressions):\r\n    -        # SQLite doesn't have a power function, so we fake it with a\r\n    -        # user-defined function django_power that's registered in connect().\r\n    +        # SQLite doesn't have a POWER function, so we fake it with a\r\n    +        # user-defined function that's registered in connect().\r\n             if connector == '^':\r\n    -            return 'django_power(%s)' % ','.join(sub_expressions)\r\n    +            return 'POWER(%s)' % ','.join(sub_expressions)\r\n             return super().combine_expression(connector, sub_expressions)\r\n    ```\r\n\r\n2. I raised the issue of input values being `DecimalField` and coming out as `FloatField`.\r\n\r\n    The functions `ACos`, `ASin`, `ATan`, `ATan2`, `Cos`, `Cot`, `Degrees`, `Log`, `Mod`, `Pi`, `Power`, `Radians`, `Sin`, `Sqrt` and `Tan` all declare `output_field = FloatField()`.\r\n\r\n    Firstly, this doesn't seem consistent as some functions are missing this, e.g. `Ln`. It makes sense that `IntegerField` becomes `FloatField`, but I'd expect `DecimalField` to stay `DecimalField`.\r\n\r\n    One way this could be achieved would be via a hack similar to this:\r\n   https://github.com/django/django/blob/d549b8805053d4b064bf492ba90e90db5d7e2a6b/django/db/models/functions/window.py#L49-L51\r\n    But as a mixin so that it can be added easily to each of the math functions that require it:\r\n    ```python\r\n    class MathOutputFieldMixin:\r\n        def _resolve_output_field(self):\r\n            sources = self.get_source_expressions()\r\n            if any(isinstance(s.output_field, DecimalField) for s in sources):\r\n                return DecimalField()\r\n            else:\r\n                return FloatField()\r\n    ```\r\n    I'd like some opinion on this from @felixxm and @timgraham before you spend time implementing it.",
      "Hi @pope1ni, I revised the code based on your suggestions except the output_field(Though I think it is a great idea to use output_field_reolved, I will wait to see whether there is different opinion). There are several issues that I noticed:\r\n1) For the log(a,b)function, different database behaves differently. Some use log(base, num) and some use log(num, base).\r\n2) Some data base doesn't support mod(double precision, double precision). I guess that is the reason why I didn't include the tests on float for the mod function.\r\n3) Some data base doesn't support log(double precision, double precision). I guess that is the reason why I didn't include the tests on float for the mod function.\r\n\r\nFor cases 2) and 3) Do you think it is OK to remove the tests  on float?\r\n\r\nThanks,\r\nJunyi",
      "Hi @JunyiJ,\r\n\r\nI've made a number of fixes that you can pull into your branch @ https://github.com/JunyiJ/django/pull/1:\r\n\r\n- Simplified the type casting for `Log()` and `Mod()` on PostgreSQL.\r\n  *(The issue was that a value is needed for `max_digits` and `decimal_places`.)*\r\n- We no longer cast `DecimalField` to `FloatField` for `output_field`.\r\n- Added type assertions to tests to complement the `output_field` stuff.\r\n- Added missing tests for `Round()`.\r\n- Fixed the problem with `Log()` on the SpatiaLite backend.\r\n- Various other bits of tidying in the tests.\r\n\r\nI've noted that `ATAN2` was added to SpatiaLite v4.3.0 which also seems to exhibit problems but I think Django's Jenkins currently uses < v4.3.0, so `math.atan2` is still being used.\r\n\r\nSee http://www.gaia-gis.it/gaia-sins/spatialite-sql-4.3.0.html#math\r\n\r\nBug filed for Log() on SpatiaLite: https://www.gaia-gis.it/fossil/libspatialite/tktview?name=8f59ddebf0",
      "@pope1ni Thank you very much for fixing these problems. I just merged all your changes to the branch.\r\n\r\nJunyi",
      "So apparently it looks like spatialite handles `ROUND()` differently to everyone else too although I didn't encounter a problem locally.\r\n\r\nJust checking that Oracle is behaving...",
      "@pope1ni In that case, we can either loose the test case criteria to pass the tests or change the Round function in math.py as what you did to Log. What do you think is a better way?",
      "> In that case, we can either loose the test case criteria to pass the tests...\r\n\r\nNo, we shouldn't do this. The behaviour of spatialite is incorrect. Tests should test correct behaviour, not be made lax to satisfy broken implementations. Could you revert that change?\r\n\r\nI'll do some more digging over the next couple of days and try and come up with a correct solution. I have a few ideas.",
      "@pope1ni OK. I have reverted the implementation. \r\n\r\nBased on the definition SpatiaLite round function returns the integer value nearest to x, but it doesn't specify the special case of numbers ended with 0.5. As a result, I am not sure whether SpatiaLite Round function is wrong here or it is designed to be so.",
      "Nick, do you want to look at this any more per https://github.com/django/django/pull/9622#issuecomment-376322325?\r\n\r\nJunyi, please target Django 2.2 and squash the commits.",
      "Tim, will aim to have a look at this over the next few days.",
      "@timgraham Hi Tim, Does 'Targeting Django 2.2' means that I should update the 2.2 in documents folder? \r\n@pope1ni Hi Nick, should I wait until you finish reviewing?\r\n\r\nThanks!\r\nJunyi",
      "So https://github.com/django/django/pull/9622#issuecomment-376322325 was already addressed by Junyi's last commit - it seems that `ROUND()` is unstable around `0.5`."
    ],
    "num_comments": 28,
    "repository": "django/django",
    "diff_length": 71275
  },
  {
    "index": 60,
    "pr_title": "Fixed #33308 -- Added support for psycopg version 3",
    "pr_body": "What did I do? I took\r\nhttps://github.com/dvarrazzo/django-psycopg3-backend and blackified it +\r\nported over most (all?) new commits. I am now opening this on GitHub to\r\nbe able to nicely diff and start a discussion about whether we can\r\nsupport psycopg2 & 3 easiyl from the same codebase (I think we can).\r\n\r\n----\r\nI (i.e. @felixxm) have the following plan to move this forward:\r\n- [x]  merge #16245,\r\n- [x]  squash commits,\r\n- [x]  rebase,\r\n- [x]  revert unnecessary changes, e.g.\r\n  - [x]  https:/",
    "pr_number": 15687,
    "comments": [
      "Looking through the code base there are quite a few areas where it would probably be easier if we just assumed that if psycopg3 is installed that we want to use it; this might get a bit more fun for testing (extra environment, but realistically speaking we want to be on psycopg3 only in the longrun anways‚Ä¶)",
      "We are down to three failures :)",
      "@timgraham I'd love if you could look over this and maybe test your cockroachdb backend against this. It would be great if I don't fully break it :)",
      "Besides the issue in `SchemaLoggerTests`, there's one other regression with psycopg2. (I'll work through the failures with psycopg3 later).\r\n```\r\n======================================================================\r\nFAIL: test_orders_nulls_first_on_filtered_subquery (ordering.tests.OrderingTests)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/tim/code/django/tests/ordering/tests.py\", line 199, in test_orders_nulls_first_on_filtered_subquery\r\n    self.assertQuerysetEqualReversible(\r\n  File \"/home/tim/code/django/tests/ordering/tests.py\", line 129, in assertQuerysetEqualReversible\r\n    self.assertSequenceEqual(queryset.reverse(), list(reversed(sequence)))\r\nAssertionError: Sequences differ: <QuerySet [<Author: Name 3>, <Author: Name 1>, <Author: Name 2>]> != [<Author: Name 2>, <Author: Name 1>, <Author: Name 3>]\r\n\r\nFirst differing element 0:\r\n<Author: Name 3>\r\n<Author: Name 2>\r\n\r\n- <QuerySet [<Author: Name 3>, <Author: Name 1>, <Author: Name 2>]>\r\n? ----------               ^                                   ^  -\r\n\r\n+ [<Author: Name 2>, <Author: Name 1>, <Author: Name 3>]\r\n?                ^                                   ^\r\n```\r\nThe old SQL:\r\n```sql\r\n SELECT DISTINCT \"ordering_author\".\"id\",\r\n                \"ordering_author\".\"name\",\r\n                \"ordering_author\".\"editor_id\",\r\n                (SELECT Max(U0.\"pub_date\") AS \"last_date\"\r\n                 FROM   \"ordering_article\" U0\r\n                 WHERE  ( U0.\"author_id\" = ( \"ordering_author\".\"id\" )\r\n                          AND Upper(U0.\"headline\" :: text) LIKE Upper(\r\n                              '%Article%') )\r\n                 GROUP  BY U0.\"author_id\") AS \"last_date\",\r\n                (SELECT Max(U0.\"pub_date\") AS \"last_date\"\r\n                 FROM   \"ordering_article\" U0\r\n                 WHERE  ( U0.\"author_id\" = ( \"ordering_author\".\"id\" )\r\n                          AND Upper(U0.\"headline\" :: text) LIKE Upper(\r\n                              '%Article%') )\r\n                 GROUP  BY U0.\"author_id\") IS NULL,\r\n                (SELECT Max(U0.\"pub_date\") AS \"last_date\"\r\n                 FROM   \"ordering_article\" U0\r\n                 WHERE  ( U0.\"author_id\" = ( \"ordering_author\".\"id\" )\r\n                          AND Upper(U0.\"headline\" :: text) LIKE Upper(\r\n                              '%Article%') )\r\n                 GROUP  BY U0.\"author_id\")\r\nFROM   \"ordering_author\"\r\nORDER  BY (SELECT Max(U0.\"pub_date\") AS \"last_date\"\r\n           FROM   \"ordering_article\" U0\r\n           WHERE  ( U0.\"author_id\" = ( \"ordering_author\".\"id\" )\r\n                    AND Upper(U0.\"headline\" :: text) LIKE Upper('%Article%') )\r\n           GROUP  BY U0.\"author_id\") IS NULL,\r\n          (SELECT Max(U0.\"pub_date\") AS \"last_date\"\r\n           FROM   \"ordering_article\" U0\r\n           WHERE  ( U0.\"author_id\" = ( \"ordering_author\".\"id\" )\r\n                    AND Upper(U0.\"headline\" :: text) LIKE Upper('%Article%') )\r\n           GROUP  BY U0.\"author_id\") DESC  \r\n```\r\n\r\n\r\nThe new SQL: \r\n```sql\r\n SELECT DISTINCT \"ordering_author\".\"id\",\r\n                \"ordering_author\".\"name\",\r\n                \"ordering_author\".\"editor_id\",\r\n                (SELECT Max(U0.\"pub_date\") AS \"last_date\"\r\n                 FROM   \"ordering_article\" U0\r\n                 WHERE  ( U0.\"author_id\" = ( \"ordering_author\".\"id\" )\r\n                          AND Upper(U0.\"headline\" :: text) LIKE Upper(\r\n                              '%Article%') )\r\n                 GROUP  BY U0.\"author_id\") AS \"last_date\",\r\n                (SELECT Max(U0.\"pub_date\") AS \"last_date\"\r\n                 FROM   \"ordering_article\" U0\r\n                 WHERE  ( U0.\"author_id\" = ( \"ordering_author\".\"id\" )\r\n                          AND Upper(U0.\"headline\" :: text) LIKE Upper(\r\n                              '%Article%') )\r\n                 GROUP  BY U0.\"author_id\") IS NULL,\r\n                (SELECT Max(U0.\"pub_date\") AS \"last_date\"\r\n                 FROM   \"ordering_article\" U0\r\n                 WHERE  ( U0.\"author_id\" = ( \"ordering_author\".\"id\" )\r\n                          AND Upper(U0.\"headline\" :: text) LIKE Upper(\r\n                              '%Article%') )\r\n                 GROUP  BY U0.\"author_id\")\r\nFROM   \"ordering_author\"\r\nORDER  BY 5 DESC  \r\n```\r\nIt might be that because CockroachDB has `DatabaseFeatures.nulls_order_largest = False` (unlike PostgreSQL), the loss of the second subquery in the `ORDER BY` is problematic.",
      "> It might be that because CockroachDB has `DatabaseFeatures.nulls_order_largest = False` (unlike PostgreSQL), the loss of the second subquery in the `ORDER BY` is problematic.\r\n\r\nThis is probably a result of https://github.com/django/django/pull/15687/files#diff-f58de2deaccecd2d53199c5ca29e3e1050ec2adb80fb057cdfc0b4e6accdf14fR753-R769 but if it looses the second `ORDER BY` then this might be a problem in the linked code and not in cdb.",
      "@timgraham I can reproduce your query issue when I set `supports_order_by_nulls_modifier = False` (which it probably is on old cockroachdb versions: https://github.com/cockroachdb/django-cockroachdb/blob/master/django_cockroachdb/features.py#L60 -- did you test against an old version?). That said, the combination of `supports_order_by_nulls_modifier = False` & `supports_order_column_alias = True` certainly shows there is a problem in the new code.",
      "> @timgraham I can reproduce your query issue when I set `supports_order_by_nulls_modifier = False` (which it probably is on old cockroachdb versions: https://github.com/cockroachdb/django-cockroachdb/blob/master/django_cockroachdb/features.py#L60 -- did you test against an old version?). That said, the combination of `supports_order_by_nulls_modifier = False` & `supports_order_column_alias = True` certainly shows there is a problem in the new code.\r\n\r\nYes, the failure is only present on older versions of CockroachDB.",
      "wow all tests passing! great work",
      "@timgraham Any chance you could test the latest changes against cockroach db?",
      "Just tested this with CockroachDB on [1043b36](https://github.com/django/django/commit/1043b3655d02d277a5c200788d381d8a9ed078d9). First impressions: Seems to work! Brilliant job.\r\n\r\nForgive my noobiness. This is a really exciting feature to me-- I'm really eager to see a release, so I wanted to post a report.\r\n\r\nhttps://github.com/cockroachdb/django-cockroachdb Needs to be updated with psycopg3 @timgraham. Was able to get it running by changing the following lines:\r\n\r\n* In `django_cockroachdb/base.py`\r\n```python\r\nimport psycopg\r\n#import psycopg2  # noqa\r\n#import psycopg2.extensions  # noqa\r\n#import psycopg2.extras  # noqa\r\n```\r\n* In `django_cockroachdb/operations.py`\r\n```python\r\nfrom psycopg import errors\r\n#from psycopg2 import errorcodes\r\n#.... I'm sure this will break, but I was just trying to get it running.\r\nif (getattr(exc.__cause__, 'pgcode', '') != errors.SERIALIZATION_FAILURE or\r\n#if (getattr(exc.__cause__, 'pgcode', '') != errorcodes.SERIALIZATION_FAILURE or\r\n```\r\n* Commented out version check in `django_cockroachdb/utils.py`\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/24665/184909616-520f48a7-4244-4559-a3dd-b3d2335f794c.png)\r\n",
      "@apollo13 Will you tackle the PostGIS backend? (First issue: `from psycopg2 import Binary` in `django/contrib/gis/db/backends/postgis/adapter.py`)",
      "@timgraham At some point yes, but probably not before I have weeded out the remaining issues with bind params in the core backend.",
      "Great! Your last commit here for EXTRACT params fixed failures on CockroachDB. Most of the remaining failures are in the following categories:\r\n* `could not determine data type of placeholder $1`\r\n* `column \"name\" must appear in the GROUP BY clause or be used in an aggregate function`\r\n* `unsupported binary operator: <decimal> / <float> (desired <decimal>)`\r\n\r\nI'm guessing that first category is what you're referring to in your last comment.",
      "Yes, bullets 1 & 2 are expected to show up currently. I just pushed (a rather ugly) gis support commit.",
      "Okay down to one failure that will probably require some work. Reviews welcome! GIS Tests pass also now.",
      "Hi @apollo13 , what stage this is currently at? Maybe I can help you with something? See, [my project](https://github.com/Bi-Coloured-Python-Rock-Snake/readme) needs this backend badly :)",
      "@pwtail Well code review here and testing your code against this branch with psycopg3 would be a massive help.\r\n\r\nI'll rebase & update the branch over the next days (parts of the required changes have already be merged to main)",
      "Thank you @apollo13 , already using your branch) ",
      "Hi folks,\r\n\r\nI have just rebased this PR to latest master. Now that all prerequisites for this PR are in further rebasing should get easier and not require manual intervention. I think the PR is starting to become solid, there are some areas though where I'd highly appreciate some help:\r\n\r\n * PostGIS in general. The adapter registration there is imo still rather ugly, I am open to creative ideas :)\r\n * Is my new handling of registering extension sound? \r\n * Do the new `as_postgresql` make sense everywhere?\r\n * Ideas on https://github.com/django/django/pull/15687/files#diff-530111bb812ef292d6db3ab0285e128bb585992d02d47dcca872d2e8c9b592daR586 \r\n * Is `compose` used correctly and consistently or are there other variants still around in the codebase?",
      "@apollo13 thanks for the rebase. I'm currently working on addressing the `as_postgresql` and `Text(str)` quirks by having `JSONField.get_db_prep_value` make use of `psycopg.types.json.Jsonb` instead and it's showing great results (down to a few remaining test failures).\r\n\r\nI'll keep you updated!",
      "@apollo13 I confirm that locally tests are working with Python 3.11 , psycopg2 or psycopg version 3, PostgreSQL 14.5",
      "@charettes Uff that is great to hear. Btw I do have a custom branch where I have enabled github actions to test all combinations: https://github.com/apollo13/django/tree/psycopg-dev So once you have something I'll reapply it there to run the tests against all combinations.",
      "We are not 100% there yet, ie Simon's changes will be coming in. But this PR is not in a reviewable state and I'd love to have more people look over it.",
      "I haven't reviewed much of the code, but it's mostly working on CockroachDB. Mostly it's down to `could not determine data type of placeholder` errors which I think will be fixed by adding `as_cockroachdb` to alias the new `as_postgresql` methods.\r\n\r\nOn GIS, there a a bunch of `cannot adapt type 'PostGISAdapter' using placeholder '%s' (format: AUTO)`. Glancing at the code, I haven't spotted the fix for this. (I'll dig in if something obvious doesn't come to mind.)",
      "After digging in, many of the errors about 'could not determine type of placeholder' are actually string arguments like:\r\n```\r\nSELECT \"ordering_article\".\"id\",\r\n       \"ordering_article\".\"author_id\",\r\n       \"ordering_article\".\"second_author_id\",\r\n       \"ordering_article\".\"headline\",\r\n       \"ordering_article\".\"pub_date\",\r\n       '1' AS \"constant\"\r\nFROM \"ordering_article\"\r\nORDER BY \"constant\" ASC,\r\n         \"ordering_article\".\"headline\" DESC;\r\n\r\nargs=('1',);\r\n```\r\nfails with:\r\n```\r\npsycopg.errors.IndeterminateDatatype: could not determine data type of placeholder $1\r\nHINT:  consider adding explicit type casts to the placeholder arguments\r\n```\r\nAs far as I can tell, the same query is generated when running against PostgreSQL. Am I missing some initialization code or something? Could it be a problem with CockroachDB?",
      "@timgraham if you want this to work properly for CockroachDB you'd likely want to override `Value.as_cockroachdb` to add explicit casts based of `self.output_field` so annotating `Value(\"1\")` turns into `('%s::text', '1')`.\r\n\r\nThis might not work properly until a form of https://github.com/apollo13/django/pull/3 lands here though as we've been supporting `Value(json.dumps(1))` and expect the JSON type inference to just work and I believe we'll have to deprecate that.",
      "Thanks for looking. It seems to be some difference between PostgreSQL and CockroachDB then? If so, I'll try to confirm and then report to the Cockroach team to see if they can address it since they try to be compatible with PostgreSQL. If they can't, thanks for the tip about a workaround.",
      "I added a temporary configuration to run tests with `psycopg` 3. You can trigger it with _\"buildbot, test on psycopg3.\"_"
    ],
    "num_comments": 28,
    "repository": "django/django",
    "diff_length": 75535
  },
  {
    "index": 61,
    "pr_title": "Fixed #33012 -- Added Redis cache backend.",
    "pr_body": "ticket-33012\r\n\r\nThis PR is in accordance with this [GSoC project](https://summerofcode.withgoogle.com/projects/#6292871491092480)\r\nThe detailed proposal can be found [here](https://docs.google.com/document/d/1_gIa_17uCNlwJTmqiMLkiVtRgTOD2MvHpy4NNFvKBWc/edit?usp=sharing)\r\n\r\nThis PR aims at adding support for Redis to be used as a caching backend with Django. As redis is the most popular caching backend, adding it to django.core.cache module would be a great addition for developers who previously ",
    "pr_number": 14437,
    "comments": [
      "Hey @carltongibson \r\nSo I was able to get a quick and simple implementation up and running. However, there are several decisions that I made for simplicity, like using pickle for serializing data. \r\nI am still not sure how shall be handle multiple servers. Do we setup a sharding based client (like memcached) or should it cater to a replication based setup with a \"Primary and replica\" based setup?\r\n\r\nDo let me know what improvement I should make and how I shall proceed!",
      "Sorry for stepping in. \r\n\r\nI have some questions, isn't this what [jazzband/django-redis](https://github.com/jazzband/django-redis) is doing?\r\n\r\nWill there be some code copying, what will be the faith of it?\r\nBy the way `django-redis` is already somewhat compatible with django api and widely used by the community.\r\n\r\nShould there be any discussion about it? Has it ever been one?",
      "Hey @WisdomPill ‚Äî The proposal is to add a Redis backend to core. \r\n\r\nIt will be simpler than that provided by `django-redis`, for instance customising the serialiser is out-of-scope for the initial pass. \r\n\r\nIt's been [discussed quite a few times on django-developers](https://groups.google.com/g/django-developers/search?q=redis). The swinger was [last year's survey showing approx twice as many users opting for Redis (where we have no backend) over memcached (where we have several)](https://www.djangoproject.com/weblog/2020/jul/28/community-survey-2020/).",
      "> Hi @abbasidaniyal ‚Äî good speedy start! \r\n> \r\n> The initial thing is tests. Can you look at the coverage for the existing backends and adapt the tests for the new backend? Then, that immediately gives us a todo list in terms of API.\r\n\r\nSure. I'll start working on the tests. Will be sharing coverage reports soon!",
      "> Sorry for stepping in.\r\n> \r\n> I have some questions, isn't this what [jazzband/django-redis](https://github.com/jazzband/django-redis) is doing?\r\n> \r\n> Will there be some code copying, what will be the faith of it?\r\n> By the way `django-redis` is already somewhat compatible with django api and widely used by the community.\r\n> \r\n> Should there be any discussion about it? Has it ever been one?\r\n\r\nHey @WisdomPill!\r\nYou can find a link to my proposal [here](https://docs.google.com/document/d/1_gIa_17uCNlwJTmqiMLkiVtRgTOD2MvHpy4NNFvKBWc/edit?usp=sharing). A lot of inspiration is taken from the `django-redis` package as mentioned in the proposal. There might be some code similarities with `django-redis` as the end-goal of remains the same, that is, connecting `redis-py` client with the django caching framework. \r\n",
      "Hey @carltongibson! \r\nSo I was going trying to work on the coverages of each backend. However, one tests keeps failing. \r\n`cache.tests.CreateCacheTableForDBCacheTests.test_createcachetable_observes_database_router`\r\n```\r\n======================================================================\r\nFAIL: test_createcachetable_observes_database_router (cache.tests.CreateCacheTableForDBCacheTests)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/daniyal/Desktop/django/django/test/utils.py\", line 430, in inner\r\n    return func(*args, **kwargs)\r\n  File \"/home/daniyal/Desktop/django/tests/cache/tests.py\", line 1238, in test_createcachetable_observes_database_router\r\n    management.call_command('createcachetable', database='other', verbosity=0)\r\n  File \"/home/daniyal/Desktop/django/django/test/testcases.py\", line 86, in __exit__\r\n    self.test_case.assertEqual(\r\nAssertionError: 1 != 5 : 1 queries executed, 5 expected\r\nCaptured queries were:\r\n1. \r\n            SELECT c.relname,\r\n            CASE WHEN c.relispartition THEN 'p' WHEN c.relkind IN ('m', 'v') THEN 'v' ELSE 't' END\r\n            FROM pg_catalog.pg_class c\r\n            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace\r\n            WHERE c.relkind IN ('f', 'm', 'p', 'r', 'v')\r\n                AND n.nspname NOT IN ('pg_catalog', 'pg_toast')\r\n                AND pg_catalog.pg_table_is_visible(c.oid)\r\n        \r\n\r\n----------------------------------------------------------------------\r\n```\r\n\r\nI did not completely understand the reason for this. \r\nMy test settings were\r\n```\r\nDATABASES = {\r\n    'default': {\r\n        'ENGINE': 'django.db.backends.postgresql',\r\n        'NAME': 'mydb_default',\r\n        'USER': 'myuser',\r\n        'PASSWORD': 'password',\r\n        'HOST': 'localhost',\r\n        'PORT': '5432',\r\n    },\r\n    'other': {\r\n        'ENGINE': 'django.db.backends.postgresql',\r\n        'NAME': 'mydb_other',\r\n        'USER': 'myuser',\r\n        'PASSWORD': 'password',\r\n        'HOST': 'localhost',\r\n        'PORT': '5432',\r\n    }\r\n}\r\n\r\nCACHES = {\r\n    \"default\": {\r\n        \"BACKEND\": \"django.core.cache.backends.db.DatabaseCache\",\r\n        \"LOCATION\": \"my_cache_table\",\r\n    },\r\n}\r\n```\r\nTried and tested with SQLite as well, and got the same results. \r\nError with SQLite\r\n```\r\n======================================================================\r\nFAIL: test_createcachetable_observes_database_router (cache.tests.CreateCacheTableForDBCacheTests)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/daniyal/Desktop/django/django/test/utils.py\", line 430, in inner\r\n    return func(*args, **kwargs)\r\n  File \"/home/daniyal/Desktop/django/tests/cache/tests.py\", line 1238, in test_createcachetable_observes_database_router\r\n    management.call_command('createcachetable', database='other', verbosity=0)\r\n  File \"/home/daniyal/Desktop/django/django/test/testcases.py\", line 86, in __exit__\r\n    self.test_case.assertEqual(\r\nAssertionError: 1 != 5 : 1 queries executed, 5 expected\r\nCaptured queries were:\r\n1. \r\n            SELECT name, type FROM sqlite_master\r\n            WHERE type in ('table', 'view') AND NOT name='sqlite_sequence'\r\n            ORDER BY name\r\n\r\n----------------------------------------------------------------------\r\n```\r\n\r\nHowever, when I comment out this line, which call `createcachetable`, the test passes.\r\nhttps://github.com/django/django/blob/d270dd584e0af12fe6229fb712d0704c232dc7e5/django/db/backends/base/creation.py#L92\r\n",
      "Hey @abbasidaniyal ‚Äî super. That's what we like to see. üòÉ\n\nCan you push your latest and I will take a look hopefully tomorrow. ",
      "> Hey @abbasidaniyal ‚Äî super. That's what we like to see. \r\n> \r\n> Can you push your latest and I will take a look hopefully tomorrow.\r\n\r\nI'm currently running the tests against the `main` branch. \r\nSharing the coverage results as screenshots [here](https://docs.google.com/document/d/1l2NiwZjNPCKYm5QLaQoWOtt7o4nt7nReLceVGF3DYks/edit?usp=sharing)\r\n\r\nI'll start adapting these existing tests for the new backend now!",
      "Hey @carltongibson !\r\nI've just pushed the lastest update that I have. I've adapted the existsing tests for the new backend. The tests are failing at two instance\r\n- Culling\r\n- zero and negative timeout handling : Redis-py does not support 0 or negative timeouts. I have implemented the `get_backend_timeout` similar to the memcache backend but I'm still not sure about how to handle 0 timeout. Ideally it should not store the key in the first place.",
      "> Hey @carltongibson!\r\n> So I was going trying to work on the coverages of each backend. However, one tests keeps failing.\r\n> `cache.tests.CreateCacheTableForDBCacheTests.test_createcachetable_observes_database_router`\r\n> \r\n> ```\r\n> ======================================================================\r\n> FAIL: test_createcachetable_observes_database_router (cache.tests.CreateCacheTableForDBCacheTests)\r\n> ----------------------------------------------------------------------\r\n> Traceback (most recent call last):\r\n>   File \"/home/daniyal/Desktop/django/django/test/utils.py\", line 430, in inner\r\n>     return func(*args, **kwargs)\r\n>   File \"/home/daniyal/Desktop/django/tests/cache/tests.py\", line 1238, in test_createcachetable_observes_database_router\r\n>     management.call_command('createcachetable', database='other', verbosity=0)\r\n>   File \"/home/daniyal/Desktop/django/django/test/testcases.py\", line 86, in __exit__\r\n>     self.test_case.assertEqual(\r\n> AssertionError: 1 != 5 : 1 queries executed, 5 expected\r\n> Captured queries were:\r\n> 1. \r\n>             SELECT c.relname,\r\n>             CASE WHEN c.relispartition THEN 'p' WHEN c.relkind IN ('m', 'v') THEN 'v' ELSE 't' END\r\n>             FROM pg_catalog.pg_class c\r\n>             LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace\r\n>             WHERE c.relkind IN ('f', 'm', 'p', 'r', 'v')\r\n>                 AND n.nspname NOT IN ('pg_catalog', 'pg_toast')\r\n>                 AND pg_catalog.pg_table_is_visible(c.oid)\r\n>         \r\n> \r\n> ----------------------------------------------------------------------\r\n> ```\r\n> \r\n> I did not completely understand the reason for this.\r\n> My test settings were\r\n> \r\n> ```\r\n> DATABASES = {\r\n>     'default': {\r\n>         'ENGINE': 'django.db.backends.postgresql',\r\n>         'NAME': 'mydb_default',\r\n>         'USER': 'myuser',\r\n>         'PASSWORD': 'password',\r\n>         'HOST': 'localhost',\r\n>         'PORT': '5432',\r\n>     },\r\n>     'other': {\r\n>         'ENGINE': 'django.db.backends.postgresql',\r\n>         'NAME': 'mydb_other',\r\n>         'USER': 'myuser',\r\n>         'PASSWORD': 'password',\r\n>         'HOST': 'localhost',\r\n>         'PORT': '5432',\r\n>     }\r\n> }\r\n> \r\n> CACHES = {\r\n>     \"default\": {\r\n>         \"BACKEND\": \"django.core.cache.backends.db.DatabaseCache\",\r\n>         \"LOCATION\": \"my_cache_table\",\r\n>     },\r\n> }\r\n> ```\r\n> \r\n> Tried and tested with SQLite as well, and got the same results.\r\n> Error with SQLite\r\n> \r\n> ```\r\n> ======================================================================\r\n> FAIL: test_createcachetable_observes_database_router (cache.tests.CreateCacheTableForDBCacheTests)\r\n> ----------------------------------------------------------------------\r\n> Traceback (most recent call last):\r\n>   File \"/home/daniyal/Desktop/django/django/test/utils.py\", line 430, in inner\r\n>     return func(*args, **kwargs)\r\n>   File \"/home/daniyal/Desktop/django/tests/cache/tests.py\", line 1238, in test_createcachetable_observes_database_router\r\n>     management.call_command('createcachetable', database='other', verbosity=0)\r\n>   File \"/home/daniyal/Desktop/django/django/test/testcases.py\", line 86, in __exit__\r\n>     self.test_case.assertEqual(\r\n> AssertionError: 1 != 5 : 1 queries executed, 5 expected\r\n> Captured queries were:\r\n> 1. \r\n>             SELECT name, type FROM sqlite_master\r\n>             WHERE type in ('table', 'view') AND NOT name='sqlite_sequence'\r\n>             ORDER BY name\r\n> \r\n> ----------------------------------------------------------------------\r\n> ```\r\n> \r\n> However, when I comment out this line, which call `createcachetable`, the test passes.\r\n> https://github.com/django/django/blob/d270dd584e0af12fe6229fb712d0704c232dc7e5/django/db/backends/base/creation.py#L92\r\n\r\n@carltongibson I was able to figure this one out. I was following the [documentation](https://docs.djangoproject.com/en/3.2/topics/cache/#database-caching) to setup the DatabaseCache.\r\n```\r\nCACHES = {\r\n    \"default\": {\r\n        \"BACKEND\": \"django.core.cache.backends.db.DatabaseCache\",\r\n        \"LOCATION\": \"my_cache_table\",\r\n    },\r\n}\r\n```\r\nHowever, I believe `my_cache_table` was conflicting with this\r\nhttps://github.com/django/django/blob/225d96533a8e05debd402a2bfe566487cc27d95f/tests/cache/tests.py#L1213-L1220\r\n\r\nSetting the \"LOCATION\" to some other table name leads to the test passing. \r\n\r\nMaybe we could mention it in the docs somewhere or update the test to check if duplicate table names exists? This is a little off-topic from this PR. Should I create a separate ticket for this? Or should we let it be for now?\r\n",
      "Hey!\r\nI've made the changes suggested by @pope1ni. I've updated the tests and added\r\n```\r\nredis_excluded_caches = {'cull', 'zero_cull'}\r\n...\r\n@override_settings(CACHES=caches_setting_for_tests(\r\n    base=RedisCache_params,\r\n    exclude=redis_excluded_caches\r\n))\r\nclass RedisCacheTests(BaseCacheTests, TestCase):\r\n    ...\r\n```\r\nNow only on test fails. Handling zero timeout. Redis-py does not support it natively and django expects to no set a key with zero timeout. I'm not sure at which level should this be handled. I was wondering if we perform the check in `get_backend_timeout` method and return a value (eg: None) or raise a suitable exception. \r\n",
      "@carltongibson I'm starting off with the documentation now. Should post updates in a few days!",
      "> If `redis-py` isn't installed, or if Redis isn't running we get a couple of errors:\r\n> \r\n> ```\r\n> django.core.cache.backends.base.InvalidCacheBackendError: Could not find backend 'django.core.cache.backends.redis.RedisCache': No module named 'redis'\r\n> ```\r\n> \r\n\r\nShould I move the `import redis` line inside the `__init__` method of the RedisCache class? All memcache backend do that and the error raised when a binding is not installed is like this\r\n```\r\nModuleNotFoundError: No module named 'pymemcache'\r\n```\r\nIncluding `import redis` at the top leads to an error message as you mentioned above.\r\nI wanted to move the import command like this\r\n```\r\nclass RedisCache(BaseCache):\r\n    def __init__(self, server, params):\r\n        import redis\r\n        super().__init__(params)\r\n        if isinstance(server, str):\r\n            self._servers = re.split('[;,]', server)\r\n        else:\r\n            self._servers = server\r\n\r\n        self._class = RedisCacheClient\r\n        self._options = params.get('OPTIONS') or {}\r\n```\r\nHowever, this would lead to some refactoring of code where `redis.ConnectionPool` etc are used.\r\nWhat do you think about this?\r\n",
      "> Should I move the `import redis` line inside the `__init__` method of the RedisCache class? All memcache backend do that and the error raised when a binding is not installed is like this\r\n\r\nYes, we should do something like this. Although with `pymemcache` it is done in `PyMemcacheCache.__init__()` because `pymemcache` provides the client class. We're writing the client class ourselves, so we want `import redis` in `RedisCacheClient.__init__()`.",
      "Hi @carltongibson. It's coming on nicely, yes.\r\n\r\nThese are some of the highlights of things addressed:\r\n\r\n- Fixed handling of `default` value with `.get()` allowing for use of a sentinel value in other operations. (Allows stored `None`.)\r\n  - See https://github.com/django/django/pull/14437#discussion_r656105087 for details.\r\n- Fixed handling of `timeout` values, notably delete/expire if `0` and persist if `None`. (Redis treats timeouts as we would expect.)\r\n  - See the thread at https://github.com/django/django/pull/14437#discussion_r658226217 for details.\r\n  - Also see https://github.com/django/django/pull/14437#discussion_r658806487 for more.\r\n- Fixed naming and ordering so things align with other backends, notably the memcached ones. (Easier maintenance.)\r\n- Fixed some bugs where `write=True` wasn't passed. Made `write` a keyword-only argument.\r\n- Implemented optimized `.delete_many()` and `.has_key()` operations instead of relying on the base class methods.\r\n- Used pipelines in `.set_many()` to optimize handling of timeouts.\r\n- Pinned to `redis >= 3.0.0` based on https://github.com/django/django/pull/14437#pullrequestreview-692861563.\r\n- Removed base serializer class - not much point. Can revisit if we need something other than pickle.\r\n- Removed half-baked support for importing client classes from string because:\r\n  - Subclassing the backend class and overriding a class attribute is better.\r\n  - We should be able to avoid adding additional client classes by passing options.\r\n  - We can always add this back if the implementation really needs it.\r\n  - See https://github.com/django/django/pull/14437#discussion_r657927858 for more commentary.\r\n\r\nThere are some outstanding comments that still need to be addressed:\r\n\r\n- [ ] As mentioned in https://github.com/django/django/pull/14437#pullrequestreview-691776531 some operations still need to be implemented:\r\n  - Implement atomic/optimized `.incr()` using `Redis.incr()` which uses the `INCRBY` command.\r\n  - Implement atomic/optimized `.decr()` using `Redis.decr()` which uses the `DECRBY` command.\r\n- [ ] As Redis supports timeouts in milliseconds, do we want to allow that? (What are your thoughts @carltongibson?)\r\n  - It would be nice as it has often come up as a complaint that memcached doesn't support this.\r\n  - We would still keep `timeout` in floating point seconds for compatibility, but scale up in `.get_backend_timeout()`.\r\n  - Then we would switch over from `ex` to `px` and `.expire()` to `.pexpire()`, etc.\r\n- [x] Redis has 16 logical databases, so, although most people will use the default, we should allow configuration of that.\r\n  - See https://github.com/django/django/pull/14437#discussion_r658856381 for more details.\r\n\r\nOther things that need attention:\r\n\r\n- [x] Documentation. I've only made brief comments, but it should be looked at thoroughly.\r\n- [x] Release notes. None have been added yet. This will be a headline feature, obviously.\r\n- [x] Tests. Currently we're piggybacking off the cross-backend tests nicely. But are there any gaps or other specific things to test?\r\n- [ ] How the connection pooling, etc. works. I haven't reviewed this at all yet.\r\n  - For example, there is a lot of parsing stuff, but can't we just use [`redis.Redis.from_url()`](https://redis-py.readthedocs.io/en/stable/#redis.Redis.from_url) or [`redis.from_url()`](https://redis-py.readthedocs.io/en/stable/#redis.from_url)? üòâ \r\n- [ ] What `OPTIONS` do we explicitly want to handle before being passed on to the underlying library?\r\n  - We'll need to forward `**kwargs` at the very least so that users have the flexibility.\r\n  - Is there anything we want to set by default? Check out [`redis.Redis()`](https://redis-py.readthedocs.io/en/stable/#redis.Redis).\r\n\r\nOnce this is done, I think that it would be good to land this as a very simple backend that essentially mirrors what the memcached backends can do. So as long as we have one or multiple servers and that they can support UNIX sockets, IPv6, possibly TLS -- then we have a drop-in replacement.\r\n\r\nThat would be the first phase. Adding sharding, etc. could then be considered in a follow up PR. As long as we have a very simple implementation here and now, extending for other things should be easy. \r\n\r\nSome other thoughts:\r\n\r\n- We don't need to consider culling. That is only necessary for services that do not handle expiry themselves, e.g. databases.\r\n  - *Which is why it is not implemented for the memcached backends.*\r\n\r\nThanks @abbasidaniyal for all your efforts so far. This is coming along nicely.",
      "Thanks @pope1ni. That's super helpful! ",
      "Hey @pope1ni and @carltongibson \r\n\r\nAccording to the comments https://github.com/django/django/pull/14437#pullrequestreview-691776531, if we want to use the `redis.incr` or `redis.decr`, we would need to stop serializing the valus which are integers. I think this will create a mess as there would be too much to manual handling of values based on their types. As we are pickling the values, we can not directly use the `redis.incr` or `redis.decr` methods.\r\n\r\nI'm not sure how useful it is to support milli-second timeouts. `django-redis` has migrated to an approach which supports both seconds and milliseconds ( [refs](https://github.com/jazzband/django-redis/pull/508/files) ). \r\n\r\nWe can make the logical databases configurable via the url as well as a parameter in the options. I'll work on it.\r\n\r\n",
      "While using the `from_url` method, we can not provide `username` and `password` in the `OPTIONS`. Even if we pass them in the kwargs, [kwargs.update(...)](https://redis-py.readthedocs.io/en/stable/_modules/redis/connection.html#ConnectionPool.from_url) overrides it with the `username` and `password` from the URL, else it sets it to None. One solution is that we only allow username and password to be set using the \"LOCATION\" key only. Let me know what you feel. @pope1ni @carltongibson ",
      "The master branch of redis-py has updated the implementation of the `from_url` method. \r\nhttps://github.com/andymccurdy/redis-py/blob/627db540acd1f1f36db88290d74cbcd75f6bda0c/redis/connection.py#L951-L955\r\n\r\nHowever, the latest stable branch (3.5.3) still uses the old implementation.\r\n```\r\nif decode_components:\r\n    username = unquote(url.username) if url.username else None\r\n    password = unquote(url.password) if url.password else None\r\n    path = unquote(url.path) if url.path else None\r\n    hostname = unquote(url.hostname) if url.hostname else None\r\nelse:\r\n    username = url.username or None\r\n    password = url.password or None\r\n    path = url.path\r\n    hostname = url.hostname\r\n\r\nif url.scheme == 'unix':\r\n    url_options.update({\r\n                'username': username,\r\n                'password': password,\r\n                'path': path,\r\n                'connection_class': UnixDomainSocketConnection,    \r\n})\r\n\r\nelif url.scheme in ('redis', 'rediss'):\r\n    url_options.update({\r\n                'host': hostname,\r\n                'port': int(url.port or 6379),\r\n                'username': username,\r\n                'password': password,\r\n            })\r\n...\r\nkwargs.update(url_options)\r\n```\r\nThis will always override the username and password in the kwargs. I think for now, we can only support giving the `username` and `password` via the url and once redis-py's latest implementation is stable, we can add supplying  `username` and `password` via the `OPTIONS`.\r\n",
      "I was working on the documentation and I wanted to mention about customizing the `parser_class`, `pool_class` and `pickle_protocol`. However, I think I can only add examples of these configurations in the [Cache Arguements](https://docs.djangoproject.com/en/3.2/topics/cache/#cache-arguments) section. I was thinking if we can add a sub-section for the redis backend. We can do this for the other backends or can include the arguments section inside each backend's section? ",
      "Hey @abbasidaniyal ‚Äî¬†I think adding a sub-section is fine. _\"The Redis backend accepts the following additional arguments...\"_, or such. ",
      "Hey @carltongibson!\r\nI've added a couple of new sections to the documentation and I've added few tests for the custom methods that we've implemented. I might be missing on few additional tests, do let me know if you find anything. \r\n\r\nAs far as the documentation is concerned, I believe most of the key points are mentioned however, I feel it can be worded a little better. Looking forward to inputs on this!\r\n\r\nLast, I was wondering about how can we add a new ci job on djangoci for the redis cache backend. I couldn't find any documentation / resources about that. Let me know if there are any resources that I can refer too!\r\n\r\nThanks!",
      "Hey @carltongibson !\r\n\r\n> Then, can I ask you to squash this down as it is and rebase, and go through the [Patch review checklist](https://docs.djangoproject.com/en/3.2/internals/contributing/writing-code/submitting-patches/#patch-review-checklist) to make sure all the _Admin_ type things are in place.\r\n\r\nOkay I've squashed the commits down. The checklist seems to be fine. Let me know if you thinking something is missing!\r\n\r\n> I've created a [ticket-33012](https://code.djangoproject.com/ticket/33012), and assigned you. I've ticked all the flags: we can uncheck those as we're happy. (Note the number for commit message(s))\r\n\r\nI didn't understand the commit message(s) part? Could you please elaborate?\r\n\r\n> That leaves us free to finish off the rough edges. I'll keep playing with it. Looking forward to getting this in for Django 4.0! üíÉ\r\n\r\nYes looking forward to it! üòÑ ",
      "> I didn't understand the commit message(s) part? Could you please elaborate?\n\nI'll try answering this. Currently your commit message is `Refs #32508` which would be for this ticket. https://code.djangoproject.com/ticket/32508\n\nThe ticket created for your project is #33012 and so your commit message should be something like... `Fixed #33012 -- Added Redis cache backend` \n\nHope this helps, and great work on this feature. üëç",
      "Hey @smithdc1!\r\nIt seems I mixed up the ticket number with another ticket I was working onüòõ \r\nThanks! üòÉ ",
      "Hi - I work for Redis (the company), maintain aioredis-py, contribute to redis-py, and am a long-time Django user. I'm happy to offer any review help on this PR if needed!",
      "> Hi - I work for Redis (the company), maintain aioredis-py, contribute to redis-py, and am a long-time Django user. I'm happy to offer any review help on this PR if needed!\r\n\r\nYou're most welcome!",
      "> Hi - I work for Redis (the company), maintain aioredis-py, contribute to redis-py, and am a long-time Django user. I'm happy to offer any review help on this PR if needed!\r\n\r\nThat'll be great! Looking forward to your inputs! üòÑ ",
      "Hey @smithdc1! Thank you for the review.\r\n\r\n\r\n> I'm not so confident to comment on the main part with all the different options. I think my main observation there is about the structure, I find it a little hard to follow. There's many options here but here's one idea of how it could be structured.\r\n> \r\n> * Required settings\r\n> * settings which are available to all backends\r\n> * Redis specific items (optional)\r\n\r\nYes we could do that but that'll require restructing the whole documentation as there are some memcached specific items that are currently laid out in the examples section. In the future, I think such a restructuring would be nice where we can talk about cache specific arguements in a separate section.\r\n",
      "Hi all!\r\nI just in corporated the suggestions above. Thank you to everyone who's taking time out for reviewing this PR! \r\n\r\n>For example, I do want to know how to select the db, but I'm not sure I need to be told (here) what happens if I specify multiple >dbs... thinking (I do want to know where to go to find out all the details.)\r\n>\r\n>Does that make sense?\r\n\r\nYes this seems better!\r\n\r\n>Understood. I think I got sucked in by the \"most popular\" comment. Maybe we don't need that either? Could just say...\r\n>\"Redis is an in-memory database...\"\r\n\r\nThoughts on this @carltongibson?\r\n\r\n\r\n\r\n"
    ],
    "num_comments": 30,
    "repository": "django/django",
    "diff_length": 20570
  },
  {
    "index": 62,
    "pr_title": "Fixed #26608 -- Add support for OVER-clause (window expressions).",
    "pr_body": "https://code.djangoproject.com/ticket/26608\r\n\r\nThanks to Jamie Cockburn for initial patch.",
    "pr_number": 7611,
    "comments": [
      "This is really impressive work! One thing I thought of is that filtering by an annotated window expression should be disallowed. For example:\r\n\r\n```python\r\nWindowTestModel.objects.annotate(sum=Window(\r\n    expression=Sum('salary'),\r\n    order_by=ExtractYear('hiredate'),\r\n   frame=RowRange(start=-2, end=2)\r\n)).filter(sum__gt=100)\r\n```\r\n\r\nShould raise an exception.",
      "@charettes Thank you! Also supported in Oracle, but I find PostgreSQL's presentation of the syntax a bit easier to read), your suggestion would fit neatly together with https://www.postgresql.org/docs/current/static/sql-expressions.html#SYNTAX-WINDOW-FUNCTIONS It took me a quite a while to write this initial patch, but perhaps this could be another iteration (perhaps open another ticket for these expressions).",
      "@atombrella ohh sorry about the confusion here. I was not referring to the window's expression `FILTER` clause but to attempts of referencing its alias in a `WHERE` statement.\r\n\r\nFor example, the following query is invalid AFAIK\r\n\r\n```sql\r\nSELECT\r\nstore_id, total,\r\nLAG(total) OVER (PARTITION BY store_id ORDER BY timestamp DESC) as lag_total\r\nFROM store_daily_total\r\nWHERE lag_total > 0\r\n```",
      "@charettes I didn't know. I'm trying to avoid touching core-classes of the ORM, but it appears that this is needed to guard against this type of query. At least, in `resolve_expression` of `Window`, the `query.where.children` is just a blank list. If you could provide a few pointers where to look, I'd be happy to have a go at this.\r\n\r\nAbout filtering, I have thought about extending it with a `FilterWindow`; MariaDB won't support this, so I guess it makes to just subclass `Window` and use a new template with `FILTER (WHERE condition)`.",
      "> @charettes I didn't know. I'm trying to avoid touching core-classes of the ORM, but it appears that this is needed to guard against this type of query. At least, in resolve_expression of Window, the query.where.children is just a blank list. If you could provide a few pointers where to look, I'd be happy to have a go at this.\r\n\r\nI'm not exactly sure where it should live but I suppose this will require another flag on the base `Expression` flag.",
      "@jarshwah There are things that are likely not to change more (for instances the actual functions); I'm adjusting some tests because of Oracle. Aggregation over the result of a window function causes problems on Oracle because the ORM adds a group by to the inner query; I'm not sure if this is correct behavior (I had a look in `get_aggregation` and `aggregate` in `Query` and `QuerySet`, respectively, but it's not trivial). The patch is fairly big, and it's been easier to get some suggestions along the way.",
      "How are you going with this patch @atombrella ? Is there anything you're still stuck on?",
      "I am not really sure what specifically in the code-section that adds additional work, probably some clean-up, for instance syntax for the partition and order by part. The last two commits were mostly clean-up. Is the structure of the documentation fine (its own section, functions documented along with the other functions)? It needs to be looked over by a native speaker.  @jarshwah You brought up aggregation as a consideration for window functions on the mailing list; I think distinct needs to be used in most scenarios, but this is already disallowed (although postgresql supports it if you comment out the raise exception in the ORM). On the mailing list, ExpressionList was proposed for ordering. I think it's a good idea for non-ambiguous ordering clauses, as I don't see how else to add descending and ascending specifiers to expressions. There are differences among supported features in all of the backends, I think. MariaDB (although Django does not officially support it, I think this is to be changed) has limitations on OrderBy (nulls first/last is not supported) and some functions (the test suite skips those), PostgreSQL doesn't support RESPECT/IGNORE NULLS or FROM FIRST/LAST. Would these restrictions be good to highlight in the documentation (that's the current approach), or is it needed to enforce it more strictly?",
      "@jarshwah Any input to this, e.g., are there more restrictions than the filtering on the result of a window and that they can't be used in `UPDATE`? I've tried to tidy up in a few places. Thank you. ",
      "@charettes You may have some more input, e.g., `contains_aggregate = True` takes care of a lot of the same restrictions on the expression, however disallowing `DISTINCT ON` with PostgreSQL. Currently, it's false.",
      "@atombrella about the `contains_aggregate` issue. I think that introducing a new `contains_window = True` (or `contains_frame`, `contains_over_clause`?) flag (with a default nested lookup on `BaseExpression`) that the ORM can use to branch on is the way to go here. Window functions are new concept for the ORM so it's normal we have to deal with these expressions with special care just like we do with aggregates.",
      "@jarshwah Thanks, the comments were quite useful. For convenience, I summarized the changes in the last commit message (there are still a few things that you commented that I'd like to dig into, such as the tagging of the compatible functions). About syntax for `order_by` and `partition_by`, I think a list that involves `ExpressionList` only internally in the `Window`-class could be an idea.\r\n\r\nEmpty windows are allowed, the three optional arguments should just be left empty. I can submit a ticket about `filter` and `Window` expressions later.",
      "So before this should go through another round of review the problem of window expressions causing a GROUP BY to be added to the query needs to be addressed. I'm going to move the ticket back into patch needs improvement.\r\n\r\nAlso, Aggregates should not inherit from WindowFunc. Just add the window_compatible property to the base aggregate type. I noticed that some of the docs around the window_compatible property need to be cleaned up.\r\n\r\nOnce the GROUP BY issue is sorted I can give another review. Can you ping me here when that's done, and I'll make it a priority.",
      "@jarshwah I corrected a few things (changes are summarized in commit messages), including the docs around `window_compatible` and `filterable`. The `GROUP BY` should be sorted out (`contains_aggregate` is False, and `get_group_by_cols` is a blank list).\r\n\r\nI'm welcoming input for the tests, including test data (some values may not be chosen well).",
      "http://mysqlserverteam.com/mysql-8-0-2-introducing-window-functions/ <- I haven't considered this in the current patch (but it affects just the test annotations and the feature-flag). I think `window_compatible` should remain `True` for all aggregate functions, although support is limited to just a few of them on MySQL and MariaDB.",
      "I'll be finishing off the review for this at the pycon au sprints this coming Monday",
      "@timgraham Would you have time to review docs soon? Thank you. I think the changes in `database-functions.txt` are mostly stand-alone. I made a bunch of improvements to the documentation today, and think it's approaching something that explains the concepts well (I don't know how much Django should cover in this regard since it's one of the more advanced features of SQL); I added some examples.\r\n\r\nI'd appreciate a look at the tests, some of them may be covered by other parts of Django's test suite (there are a couple of questions in comments in there). Also, MySQL/MariaDB should probably be handled (this involves test annotations, and the feature flag). MySQL 8.0.2+ has a richer support for the functions than MariaDB. It doesn't seem like the MariaDB flag will be included in 2.0, so maybe it's better to scratch MariaDB notes from the code, and the documentation?",
      "@timgraham Thanks for the comments. I adjusted the annotations in the tests, and experimented a bit with a pre-release of MySQL 8; they all ran, except for one. I adjusted the `test_range_n_preceding_and_following` due to this. Would it be an idea to highlight something about experimental support/tests for MySQL in the documentation? The tests run on MySQL 8.0.2, but MariaDB still has hiccups with lead/lag, and `range` (MariaDB should have `lead` and `lag`, but the default argument resulted in an error about an invalid query).\r\n\r\nAs the implementation uses the `Expression` API, I find it useful to highlight a trick with a dictionary for the parameters for multiple windows in the same query. I moved the document `window.txt` into `expressions.txt`. Most sections start with `.. class`, and then some text, and I'm not sure if the section requires some structural change.\r\n\r\nThe arguments for the frame were taken from sqlalchemy; the default in SQL is that `RANGE/ROWS UNBOUNDED PRECEDING` means `RANGE/ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW`, although without an elaborate end, the code produces `RANGE/ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING`, which I've tried to highlight.\r\n\r\n@felixxm And thanks for a detailed look on style :) It's really appreciated.",
      ">  Would it be an idea to highlight something about experimental support/tests for MySQL in the documentation?\r\n\r\nThanks for testing MySQL :) I think a sentence about MySQL 8 support would be okay, even though it's currently unreleased.\r\n\r\n> MariaDB still has hiccups with lead/lag, and range (MariaDB should have lead and lag, but the default argument resulted in an error about an invalid query).\r\n\r\nDon't worry about MariaDB for the time being, I'll try make it supported properly by Django and fix up things like this when I get round to it.",
      "I went through the feedback, but I still find the documentation tricky to get finalized (I fixed a few sloppy mistakes in the previous updates; it's squashed). Regarding examples, should I add sample data as well, or the description of what is enough? I think for some of those queries to make sense and fully\r\nillustrate what happens would require more than 4-5 rows (that's the number of in the aggregation section), making the document much longer. I use movies and books in three examples. The conditional aggregation document fully illustrates with a model, and some data, for comparison. All the documentation is now in already existing files.\r\n\r\nI believe all scenarios for the functions have tests, however there's a test, `test_two_functions` to check how two window expressions work. Perhaps it's redundant? There are some assertions to check the generated SQL, mainly for the frames-tests.",
      "@timgraham I went over the feedback, and the coverage should be increased. I don't know if `BackendsOperationsTests` actually makes sense. I decided to delete the `admonition` about ordering and frames; I think the content is described already.",
      "@timgraham I think the rest of your feedback is addressed.",
      "Thanks to people involved in getting this mergeable :tada:"
    ],
    "num_comments": 23,
    "repository": "django/django",
    "diff_length": 87407
  },
  {
    "index": 63,
    "pr_title": "[Soc2014] The new Options API",
    "pr_body": "# Main API\n\nOfficial Wiki page: https://code.djangoproject.com/wiki/new_meta_api\n\nget_fields(m2m, data, related_m2m, related_objects, virtual,\ninclude_parents, include_non_concrete, include_hidden, include_proxy) -> (field, field, ...)\n\nget_field(field_name, m2m, data, related_m2m, related_objects, virtual) -> field\n\nfield_names -> (field_name, field_name, ..)\n# Cached properties for fast access\n\nfields -> (field, field, ..)\nconcrete_fields -> (field, field, ...)\nlocal_concrete_fields -> (field,",
    "pr_number": 2894,
    "comments": [
      "@timgraham @freakboy3742 happy to start doing a \"formal\" review now.\nBuild is failing because of the usual Git checkout issue, but all passing locally.\nI'll also pull from master\n",
      "@freakboy3742 @timgraham in the mean-time can we do a second review on the documentation, while I sort out other bigger issues\n",
      "@timgraham @freakboy3742 can we start a third review?\n",
      "@timgraham for convenience I deployed all my documentation to a server, so it can be easier to review the style.\n\nAll this PRs documentation will be deployed here: http://5.101.98.142:49155\nex: http://5.101.98.142:49155/ref/models/meta.html\n",
      "@timgraham @freakboy3742 can we have another review?\n\n@timgraham: I will be reverting the structure of the options file (discarding the way I ordered it)\n",
      "@timgraham old formatting of models/options has been restored.\n",
      "@timgraham @freakboy3742 \n\nThis is the new get_field() API: https://github.com/PirosB3/django/pull/6. Do you prefer this or the one on the current PR?\nI prefer the new one, it's simpler and there is (not yet) any reason for so much filtering options. It also has smaller memory usage.\nSuggestions?\n",
      "Hi Tim,\n\nIt's not this PR anymore, the official one is the newest one from me. I\nshould kill this pr\n\nOn Friday, August 29, 2014, Tim Graham notifications@github.com wrote:\n\n> buildbot, test this please.\n> \n> ‚Äî\n> Reply to this email directly or view it on GitHub\n> https://github.com/django/django/pull/2894#issuecomment-53870059.\n\n## \n\n---\n\nPirosB3\n\nhttps://github.com/PirosB3\n",
      "Linking to newer ticket for folks browsing this... #3114.\n"
    ],
    "num_comments": 9,
    "repository": "django/django",
    "diff_length": 180275
  },
  {
    "index": 64,
    "pr_title": "Fixed #21231 -- Enforced a max size for POST values read into memory",
    "pr_body": "Enforce a maximum size for form field values read into memory.\nBased on https://github.com/django/django/pull/3020 and https://github.com/django/django/pull/2403.\n",
    "pr_number": 3852,
    "comments": [
      "I just thought of a rough idea that might be cleaner and have fewer holes:\n- Have request.read() keep track of the total amount of bytes read.\n- Have a way of reading chunks of files from the request that doesn't count towards the the above number.\n\nThat should handle things that this PR doesn't handle like too many files or really long file names.\n",
      "@epandurski Done.\n\n@collinanderson As for file names, or field names, this is already limited in multipartparser.py. 1024 is the default max value for boundary chunks. As for \"too many files\", this seems like a separate problem? \n",
      "Updated patch to apply to 1.9.\n",
      "I've tested with both normal POST data and with json payload and confirmed I get 'Request data too large' error in the console when data is larger than the setting.\n",
      "Would be great if you could reply to the unaddressed comments in from the previous PR (such as https://github.com/django/django/pull/3020#discussion_r15779470) so we know if they are addressed in this version.\n",
      "I've replied to all comments.\n",
      "@apollo13, could you please check if Andr√© has sufficiently addressed all your concerns on the previous PR?\n",
      "@edevil Did you ever check how much memory consumption 2.5 MB of form data would mean in the worst case scenario?\n",
      "```\nimport time\nfrom django.http import QueryDict\ncontent = ('a=1&' * 625000).rstrip('&') # +- 2.5MB\nd = QueryDict(content, encoding='utf-8') # takes 13s, 80MB at peak\n```\n",
      "how exactly are you measuring that?\n",
      "I suppose you mean the memory usage? I'm looking at the memory of the Python process during the last command.\n",
      "So that is just a rough estimate and not a concrete number?\n",
      "Well, yes. I suppose it is specific to the Python version I'm using and my hardware. I established the baseline memory before running the last command and during its execution the process used 80MB more memory before the command returned.\n",
      "After talking to @aaugustin we both still think that this too much, as an extra measurement want to limit the number of params to something sensible.\n",
      "An extra setting, where None would mean to disable that check.\n",
      "Done. New setting: DATA_UPLOAD_MAX_NUMBER_FIELDS\n",
      "The check has to happen before parse_qs -- this one already generates a\nlong list with all the data.\n\nOn Thu, Jun 4, 2015, 18:23 Andr√© Cruz notifications@github.com wrote:\n\n> Done. New setting: DATA_UPLOAD_MAX_NUMBER_FIELDS\n> \n> ‚Äî\n> Reply to this email directly or view it on GitHub\n> https://github.com/django/django/pull/3852#issuecomment-108981409.\n",
      "Well, but how can you count them without parsing the query string? Is it viable to count the number of \"&\" before?\n",
      "The question should be asked the other way: \"is it okay to parse it without\ncausing to much overhead\" -- counting before is basically o(n) and does not\nrequire substantial memory. So I once again ask for a better benchmark than\nlooking at the peak output of your memory usage. Ie debug more carefully\nhow the peaks occur, is it in parsing the initial qs or in constructing the\ndict. In that sense your architecture or python version doesn't matter that\nmuch since I'd expect the ratio between those two to stay (roughly --\nexcluding dict sharing optimizations in new py versions) the same.\n\nOn Thu, Jun 4, 2015, 18:41 Andr√© Cruz notifications@github.com wrote:\n\n> Well, but how can you count them without parsing the query string? Is it\n> viable to count the number of \"&\" before?\n> \n> ‚Äî\n> Reply to this email directly or view it on GitHub\n> https://github.com/django/django/pull/3852#issuecomment-108987372.\n",
      "You were right. Most of the memory/time spent when parsing a query string with a large number of parameters was on parse_qsl. I used ifilter to obtain the \"&\" in the query string in a streaming fashion so that we stop as soon as the limit is reached.\n",
      "This fails on python3, also, ifilter includes an extra scan of the string, can you please also time how well your approach works against a simple `str.count` as well as an approach which does the filtering & querystring parsing in one single linear pass.\n",
      "When we have to scan the whole string, ie. when the number of parameters does not exceed the limit, str.count is much faster.\n",
      "I think the problem is that the HTTP-handling code in django is very complex, so everybody who have the authority to include this change upstream is afraid that he will break something, and at the same time they do not have the time to dive deeply into the problem. This is not the first patch that seems to be ingnored (there were at least 3 of them, including mine). It is quite sad, given that the issue is not a minor one.\n",
      "I still don't see any example code for a single pass‚Ä¶ Even though you say it's slower I'd at least want to see the code so you didn't make any mistakes‚Ä¶\n",
      "@epandurski This issues is relatively minor, as this is best fixed at the frontend levels, not the backend servers. If it were a major issue, sites would complain that they are getting DOSed due to that‚Ä¶\n",
      "@apollo13 How would you fix it at the front-end? Typical front-end servers like Nginx won't look inside the request so you're left with limiting the total request size. When you're accepting file-uploads, it depends on what they're for, but I would think that accepting a max 10MB size is not too unusual. With 10MB you can cripple a Django web application without the patch we're currently discussing. As for the single-pass, I was referring to the ifilter approach, not a true single pass. I would have to import the parse_qsl code into Django and I would't know where to put it or the amount of tests I would have to produce for this new code.\n",
      "> Typical front-end servers like Nginx won't look inside the request so you're left with limiting the total request size.\n\nThat is a problem of your frontend server then.\n\n>   I would have to import the parse_qsl code into Django and I would't know where to put it or the amount of tests I would have to produce for this new code.\n\nWhy? from the looks of it, passing any generator should allow true single pass. I somewhat doubt it will be faster than count, but who knows.\n",
      "> @epandurski This issues is relatively minor, as this is best fixed at the frontend levels, not the\n> backend servers. If it were a major issue, sites would complain that they are getting DOSed due to \n> that‚Ä¶\n\nThis have been discussed in the issue thread: https://code.djangoproject.com/ticket/21231\n\nThere is no point to reiterate this discussion. This has been categorized as a security threat by the core theam, and I am pretty sure that I have read somewhere that Django is aiming to be suitable for high-profile banking applications. This is the reason I opened the issue.\n",
      "> That is a problem of your frontend server then.\n\nCan you give me an example of a front-end server that allows me to limit the number of multipart parts a request can contain? Maybe I've been using the wrong one.\n\n> Why? from the looks of it, passing any generator should allow true single pass. I somewhat doubt it will be faster than count, but who knows.\n\nparse_qsl() expects a qs object that implements a split() method. I could pass my own object that implements split() but a simple generator doesn't cut it. Are we looking at the same code?\n"
    ],
    "num_comments": 29,
    "repository": "django/django",
    "diff_length": 25247
  },
  {
    "index": 65,
    "pr_title": "Fixed #18468 -- Added support for comments on columns and tables.",
    "pr_body": "more detail description: https://code.djangoproject.com/ticket/18468\r\n\r\n\r\n#### Django\r\n* Field(db_comment=\"...\")\r\n* db_table_comment=\"....\"\r\n\r\n~~~Python\r\nclass AModel(Model):\r\n  \r\n  a_char = models.Field(db_comment=\"I Am comment to Column\", max_length=32)\r\n  \r\n  class Meta:\r\n      db_table = \"a_model\"\r\n      db_table_comment = \"table comment....\"\r\n\r\n~~~\r\n\r\n\r\n#### Converted to postgres dialect\r\n\r\n~~~SQL\r\n\r\ncreate table a_model\r\n(\r\n    id      bigserial   not null  constraint hello1_amodel_pkey  p",
    "pr_number": 14463,
    "comments": [
      "thank you for your feedback  üòÑ \r\n\r\nI will  add testcase for this feature and reflect your feedback until this weekend ",
      "Hi @jchubber\r\nIt tries to be helpful in making the test case. In this case, the new SQL grammar is reflected in django, so it can not be used with `assertTableExists()` or `assertColumnExists()` and the other test utils.  \r\nI think make assertion Util like a `assertDBComment()`\r\nIn order to make test cases, it is necessary to add information about `db_comment` to `DatabaseWrapper.introspection.get_table_description()`.  \r\nHowever, I am not sure whether it is the right way to change `get_table_description()` method to only use in test case.",
      "@KimSoungRyoul I do not have enough familiarity with migration testing either. I'll write a request into the `Django Core Mentorship` or `Django developers` groups to request advice. I'll let you know if/when I hear back.\r\n\r\nQuick question: Other than the testing, is there anything else you know needs to be done before this ticket is done? It looks to me like you already reflected every piece of feedback I gave ‚úÖ :)",
      "thank you for your feedback ,  yes  I  already reflected every piece of feedback.\r\nI'll think about testcase for this new feature without modifying `DatabaseWrapper.introspection.get_table_description()` \r\n\r\nand I will  do rollback 1 commit and force push which contained failed useless testcase\r\n\r\n~could give me link where the discussion is being requested?   if not exist  yet~\r\n[Django developers Groups: How can I make testcase for new migration feature (DB Comment) #18468](https://groups.google.com/u/1/g/django-developers/c/28Lv0H9jPAM)\r\n ",
      "@KimSoungRyoul You posted to django-developers and I posted to Django Core Mentorship ([link to thread](https://groups.google.com/g/django-core-mentorship/c/3KHlBAfpD5I)). It looks like the feedback from both groups is consistent: extending `get_table_description()` is ok and it's also recommended to extend inspectdb as well. It's great to have confirmation from both discussion boards about that ‚úÖ ‚úÖ üëç\r\nIf you need any help or want to discuss further, please don't hesitate to let me know.",
      "I haven't done much make testcase yet. but soon will be done\r\np.s\r\nI would be grateful if you could advise on a test case scenario.\r\n\r\n...\r\n\r\nby the way Can you **\"Resolve Conversation\"** that has already been reflected?",
      "@knyghty thank you for your feedback. \r\nIt seems more appropriate to remove `.. warning::`. \r\nand `supports_db_comments ` -> `supports_comments `\r\n\r\n@jchubber \r\nI add more testcase to cover up new feature(`db comment`)\r\n* add_db_comment\r\n* alter_db_comment\r\n* delete_db_comment\r\n* add_db_comment_with_default\r\n* alter_db_comment_with_default\r\n\r\n---\r\n\r\n\r\nIs there anything else to think about besides the feedback you suggested? \r\n",
      "What happens if you add `db_comment` to a field that isn't directly represented as a column, e.g. `ManyToManyField`? Do we need a system check or something for this? You may need to add something here: https://github.com/django/django/blob/main/django/db/models/fields/related.py#L1230-L1261 ideally with a test.\r\n\r\nI'm not sure if any other fields will have this issue.",
      "I didn't consider about that. \r\nJust like you said,  we need a system check  \r\nlike a ...\r\n~~~Python\r\nif self.db_comment:\r\n            warnings.append(\r\n                checks.Warning(\r\n                    'db_comment has no effect on ManyToManyField.',\r\n                    obj=self,\r\n                    id='fields.W3xx',\r\n                )\r\n            )\r\n\r\n~~~\r\n\r\nI will add this and consider what happens when `ManyToManyField` or ~`GenericForeignKey`~  etc... and `db_comment` are used together.  üòÑ \r\n\r\nThanks",
      "(üëç awesome work @KimSoungRyoul and great points @knyghty !)\r\n\r\n**ManyToManyFields:** This was a good catch by @knyghty. Django creates an intermediary join table in the db for every ManyToMany field. In theory, we could support db_comments on `ManyToManyFields` by putting those comments as **_table-level_** comments onto the intermediary join table that Django created. HOWEVER, we'd encounter a problem when the user specified a ManyToManyField with a `through` model, if they tried to put a db_comment on both the Field and also on the through model definition. I'm not 100% sure how to handle this. Either (1) Django supports db_comments on ManyToManyFields and adds them to the intermediary join table as a table-level comment _when there is NO `through` table_, but ignores the field-level comment _when there IS a `through` table_, or (2) Django never supports db_comments on ManyToManyFields at all (basically \"If you want a db comment on your M2M fields, you HAVE to use a through table and put the db_comment there\"). @KimSoungRyoul What do you think?",
      "**Test Cases:** \r\nThe test cases @KimSoungRyoul has now look good. I am trying to think of strange edge cases situations where covering with unit tests could be helpful. I'm not coming up with many. \r\n\r\n- ManyToManyField comments: As mentioned above, this special case might require separate unit tests.\r\n- Table-level comments on `through` models: Is there any difference for `through` models? I suppose not... Maybe unit tests on the `through` models is not needed?\r\n- What's the expected result if there is a comment in the db on a column and the Django user does NOT specify any comment  on the field? Django should make no change to the pre-existing comment, right?",
      "I did an additional review of the Django model docs and found three other situations where db_comment support might get complicated:\r\n\r\n### 1) Unmanaged models:\r\n([link to docs](https://docs.djangoproject.com/en/dev/ref/models/options/#managed)). For any model that has...\r\n```python\r\nclass Meta:\r\n        managed = False\r\n```\r\n...Django will not perform create, modify, or delete operations on the model. That means that db_comments cannot be supported for unmanaged models. I recommend that the docs be updated to state that db_comments are ignored when managed = False. \r\n\r\n### 2) Proxy models:\r\n([link to docs](https://docs.djangoproject.com/en/dev/topics/db/models/#proxy-models)). A `proxy` model doesn't exist in the db in the same way as a regular model. So if a model has...\r\n\r\n```python\r\nclass Meta:\r\n        proxy = True\r\n```\r\n...then I think perhaps db_comments should not be supported at the table _or_ column-levels. That should be documented in the docs, should trigger a warning (during migration?), and should have a unit test to ensure that if a Django user specifies a db_comment on a proxy model that Django doesn't error.\r\n\r\n### 3) Abstract Base Classes:\r\n([link to docs](https://docs.djangoproject.com/en/3.2/topics/db/models/#abstract-base-classes)) Django doesn't create tables for Abstract Base Classes, so a table-level db_comment on an Abstract Base Class **_does NOT_** make sense. But a field-level (or \"column-level\") db_comment on an Abstract Base Class' fields _**DOES**_ make sense because those fields will eventually be created for any of the models that inherit from the Abstract Base Class.\r\n\r\nSo for example, with...\r\n\r\n```python\r\nfrom django.db import models\r\n\r\nclass CommonInfo(models.Model):\r\n    name = models.CharField(max_length=100)\r\n    age = models.PositiveIntegerField(db_comment=\"User's age when they registered.\")\r\n\r\n    class Meta:\r\n        abstract = True\r\n\r\nclass Student(CommonInfo):\r\n    home_group = models.CharField(max_length=5)\r\n```\r\n...then a unit test should verify that in the db the `student` table has a column `age` with the comment \"`User's age when they registered.`\".\r\n\r\n",
      "@KimSoungRyoul I was busy the past 2 weeks, but I have more control over my time for the coming 2 weeks. Is there anything here that I can be helpful with? Writing docs? Working on code for some piece of the items mentioned above üëÜ? ",
      "> (üëç awesome work @KimSoungRyoul and great points @knyghty !)\r\n> \r\n> **ManyToManyFields:** This was a good catch by @knyghty. Django creates an intermediary join table in the db for every ManyToMany field. In theory, we could support db_comments on `ManyToManyFields` by putting those comments as **_table-level_** comments onto the intermediary join table that Django created. HOWEVER, we'd encounter a problem when the user specified a ManyToManyField with a `through` model, if they tried to put a db_comment on both the Field and also on the through model definition. I'm not 100% sure how to handle this. Either (1) Django supports db_comments on ManyToManyFields and adds them to the intermediary join table as a table-level comment _when there is NO `through` table_, but ignores the field-level comment _when there IS a `through` table_, or (2) Django never supports db_comments on ManyToManyFields at all (basically \"If you want a db comment on your M2M fields, you HAVE to use a through table and put the db_comment there\"). @KimSoungRyoul What do you think?\r\n\r\n\r\nI think `(2) Django never supports db_comments on ManyToManyFields at all` is a good choice. \r\n`(1)`  is a possibility that it will become too complicated and I agree with the problem you mentioned.\r\n\r\nLogically, it is correct that ManyToManyField does not support `db_comment` .  \r\n**ManyToManyField is not a column. It's a relationship mapping between models.** ",
      "Why fail to connect only py3.9-mysql?\r\n\r\nIs it just a temporary issue?\r\n\r\n~~~Python\r\n  File \"/home/jenkins/workspace/pull-requests-bionic/database/mysql_gis/label/bionic-pr/python/python3.9/tests/.env/lib/python3.9/site-packages/MySQLdb/__init__.py\", line 130, in Connect\r\n    return Connection(*args, **kwargs)\r\n  File \"/home/jenkins/workspace/pull-requests-bionic/database/mysql_gis/label/bionic-pr/python/python3.9/tests/.env/lib/python3.9/site-packages/MySQLdb/connections.py\", line 185, in __init__\r\n    super().__init__(*args, **kwargs2)\r\ndjango.db.utils.OperationalError: (2002, \"Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)\")\r\nBuild step 'Execute shell' marked build as failure\r\n\r\n~~~",
      "> @KimSoungRyoul I was busy the past 2 weeks, but I have more control over my time for the coming 2 weeks. Is there anything here that I can be helpful with? Writing docs? Working on code for some piece of the items mentioned above üëÜ?\r\n\r\nthanks for your feedback @jchubber\r\nI thought most of your suggestions were appropriate, so I reflected most of them. Are there more areas that need improvement?  If not, may I ask who can advice to get approval?\r\n\r\n\r\n* `test_add_comment_with_through_model` (testcase)\r\n* `test_add_comment_with_abstract_true_option` (testcase)\r\n*  add  migration file to test`test_migrations_with_db_comment.0003_create_proxymodel.py` \r\n*  add  migration file to test`test_migrations_with_db_comment.0004_create_unmanagedmodel.py` \r\n* `Proxy model and Unmanaged models ignore DB comment options`(docs)\r\n\r\n",
      "@charettes, would you like to take a look?",
      "# Status update: Patch is Ready for Review\r\n\r\n> I thought most of your suggestions were appropriate, so I reflected most of them. Are there more areas that need improvement? If not, may I ask who can advice to get approval?\r\n\r\nBecause this patch now meets every requirement on the development checklist, I've updated the status in the Django ticket tracker so that it shows up in the `Patches Needing Review` section of the [Django Development Dashboard](https://dashboard.djangoproject.com/).\r\n\r\nThe next step is for anyone except the patch author(s) to review the patch using [the patch review checklist](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/submitting-patches/#patch-review-checklist) and either mark the ticket as `Ready for checkin` on the [Django Development Ticket Tracker Entry for Ticket #18468](https://code.djangoproject.com/ticket/18468) if everything looks good, or leave comments for improvement and mark the ticket as `Patch needs improvement`. I'd also request that comments for improvement be left here in Github as well. \r\n",
      "> I left a few comments, mostly around the docs / grammar. They're all quite subjective.\r\n\r\nthanks!",
      "Hi may I know what more I should do? such as requesting reviews from others or reflecting feedback",
      "@KimSoungRyoul I'm reviewing the using [this patch review checklist](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/submitting-patches/#patch-review-checklist). Here's the current status of that checklist:\r\n\r\n- [x] Documentation: Does the documentation build without any errors (make html, or make.bat html on Windows, from the docs directory)? `Yes, it builds with no errors ‚úÖ` \r\n- [ ] Documentation: Does the documentation follow the writing style guidelines in Writing documentation? `There are two documentation issues related to code formatting. See below in the list of remaining changes. üü°`\r\n- [x] Documentation: Are there any spelling errors? `None. Looks good ‚úÖ`\r\n- [x] Bugs: Is there a proper regression test (the test should fail before the fix is applied)? `Yes, the tests will fail before the fix is applied ‚úÖ`\r\n- [x] Bugs: If it‚Äôs a bug that qualifies for a backport to the stable version of Django, is there a release note in docs/releases/A.B.C.txt? Bug fixes that will be applied only to the main branch don‚Äôt need a release note. `Not applicable. No backport needed.  ‚úÖ`\r\n- [x] New Features: Are there tests to ‚Äúexercise‚Äù all of the new code? `Yes. Well exercised. ‚úÖ`\r\n- [x] New Features: Is there a release note in docs/releases/A.B.txt? `Yes there is ‚úÖ`\r\n- [x] New Features: Is there documentation for the feature and is it annotated appropriately with .. versionadded:: A.B or .. versionchanged:: A.B? `Yes.  ‚úÖ`\r\n- [x] All code changes: Does the coding style conform to our guidelines? Are there any flake8 errors? You can install the pre-commit hooks to automatically catch these errors. `I ran flake8 on all files included in this patch and found no errors. ‚úÖ`\r\n- [x] If the change is backwards incompatible in any way, is there a note in the release notes (docs/releases/A.B.txt)? `Not applicable. This change does not lead to any backwards incompatibility. ‚úÖ`\r\n- [ ] Is Django‚Äôs test suite passing? `Not yet... I got one failure, which I'm investigating. I'm not sure if it's related to this patch or not. I'll report back. ‚è±` **_UPDATE: I do see one test failure that is related to this patch. I'll create a separate comment for that._** \r\n- [ ] All tickets: Is the pull request a single squashed commit with a message that follows our commit message format? `It's not a single squashed commit, but it does have a message that follows our commit message format. I'm not sure how important it is for the patch to be a single squashed commit, but if it's important, then I think KimSoungRyoul is the person who should squash the commit (so you retain authorship). If you are unfamiliar with squashing a commit (without having to create a new PR) then I'll go ahead and mark this as ready for merging and we'll see if the committers are comfortable with not having a single squashed commit. üü°`\r\n- [ ] All tickets: Are you the patch author and a new contributor? Please add yourself to the AUTHORS file and submit a Contributor License Agreement. `No. I do not see that @KimSoungRyoul added themselves to the AUTHORS file and I am unsure if they submitted a Contributor License Agreement. @KimSoungRyoul should do both. üü°` (@KimSoungRyoul here's a link for the contributor license agreement instructions https://www.djangoproject.com/foundation/cla/)\r\n\r\n## Changes that remain to be made:\r\n- [This](https://github.com/django/django/pull/14463/files#diff-fc688171203d4ce1e42c46f25bddfee5f494b0b1b81258907ff0531c81f2a4aeR332) should be ``` ``help_text`` ``` (not ``` `help_text` ```)\r\n- [This](https://github.com/django/django/pull/14463/files#diff-fc688171203d4ce1e42c46f25bddfee5f494b0b1b81258907ff0531c81f2a4aeR337) should be ``` ``db_comment`` ``` (not ``` `db_comment ` ```)\r\n- The warning on the db_comment docs [here](https://github.com/django/django/pull/14463/files#diff-fc688171203d4ce1e42c46f25bddfee5f494b0b1b81258907ff0531c81f2a4aeR347-R352) should be removed\r\n- Adding yourself to the `AUTHORS` file here: https://github.com/django/django/blob/main/AUTHORS .\r\n\r\nOnce these changes are made, I'll mark this \"Ready for checkin\" and then a committer will have the chance to review and either accept it or send it back for changes. (I'm not a committer)",
      "all done\r\n\r\n* fix documentation follow the writing style ( and remove)\r\n* fix failing testcase \r\n* adding to the AUTHORS (and submit a Contributor License Agreement.)\r\n* squash commit\r\n\r\nThanks again for your guide. @jchubber  :bowing_man: ",
      "# Updated checklist status:\r\n\r\n- [x] Documentation: Does the documentation build without any errors (make html, or make.bat html on Windows, from the docs directory)? `Yes, it builds with no errors ‚úÖ` \r\n- [x] Documentation: Does the documentation follow the writing style guidelines in Writing documentation?  `Looks good. ‚úÖ` \r\n- [x] Documentation: Are there any spelling errors? `None. Looks good ‚úÖ`\r\n- [x] Bugs: Is there a proper regression test (the test should fail before the fix is applied)? `Yes, the tests will fail before the fix is applied ‚úÖ`\r\n- [x] Bugs: If it‚Äôs a bug that qualifies for a backport to the stable version of Django, is there a release note in docs/releases/A.B.C.txt? Bug fixes that will be applied only to the main branch don‚Äôt need a release note. `Not applicable. No backport needed.  ‚úÖ`\r\n- [x] New Features: Are there tests to ‚Äúexercise‚Äù all of the new code? `Yes. Well exercised. ‚úÖ`\r\n- [x] New Features: Is there a release note in docs/releases/A.B.txt? `Yes there is ‚úÖ`\r\n- [x] New Features: Is there documentation for the feature and is it annotated appropriately with .. versionadded:: A.B or .. versionchanged:: A.B? `Yes.  ‚úÖ`\r\n- [x] All code changes: Does the coding style conform to our guidelines? Are there any flake8 errors? You can install the pre-commit hooks to automatically catch these errors. `I ran flake8 on all files included in this patch and found no errors. ‚úÖ`\r\n- [x] If the change is backwards incompatible in any way, is there a note in the release notes (docs/releases/A.B.txt)? `Not applicable. This change does not lead to any backwards incompatibility. ‚úÖ`\r\n- [x] Is Django‚Äôs test suite passing? `Passing tests. ‚úÖ`\r\n- [x] All tickets: Is the pull request a single squashed commit with a message that follows our commit message format? `Yes, it's a single squashed commit. ‚úÖ`\r\n- [x] All tickets: Are you the patch author and a new contributor? Please add yourself to the AUTHORS file and submit a Contributor License Agreement. `Yes, @KimSoungRyoul added themselves to the AUTHORS file ‚úÖ`\r\n\r\n# üëâ  Patch Review Checklist is Complete ‚úÖ  \r\n\r\nI have marked this patch `Ready for checkin` in the Django ticket tracker [here](https://code.djangoproject.com/ticket/18468#comment:35). A committer will have the chance to review and either accept it or send it back for changes. (I'm not a committer)",
      "@felixxm \r\n\r\nHi I reflected your comments.  9d769edbbd6e008e4553a18fda4474e5d54fbcf6\r\nI will squash all my commits after approve for your unpainful code review. thank you for your feedback üôá\r\n\r\n#### summary\r\n* reusable `COMMENT` SQL \r\n    * define `def _comment_sql(self, comment):`\r\n    \r\n    *  remove comment related sql or method like a `sql_create_table_with_comment`\r\n       and left comment related sql only `sql_alter_table_comment` and `sql_alter_column_comment`\r\n    \r\n* `column_comment` -> `comment`\r\n\r\n*   Each database handles '', None differently. so I define `def quote_comment_value(self, value):`\r\n\r\n\r\n",
      "Hi @KimSoungRyoul, if this is ready for re-review, please uncheck \"Needs improvement\" on the Trac ticket, which is how we track waiting-for-author. While here, I noticed the release notes and version annotations need to be moved to 4.1, which is under dev now. Thanks!",
      "@KimSoungRyoul Thank you for the link to your updated commit! When it's ready to be accepted I can update the issue in trac to remove the `Needs improvement` flag. That will enable the PR to be re-reviewed by Mariusz (@felixxm) or another maintainer. It's probably not feasible to ask felixxm to do a re-review on a PR that isn't ready to be accepted. Before doing that we should confirm a few things + update a few things in the PR:\r\n\r\n- [ ] I did a quick comparison of felixxm's feedback and your new commit, but it was difficult for me to be 100% sure if all of the feedback was reflected yet. Would you be please be willing to [please mark conversation(s) as resolved in Github](https://docs.github.com/en/github/collaborating-with-pull-requests/reviewing-changes-in-pull-requests/about-pull-request-reviews#resolving-conversations) for all of the suggestions that you've already updated in the PR? (If for some reason Github does not give you the option to resolve conversations, then an alternative option is to comment \"_I've updated the PR based on this feedback. Thanks._\")\r\n- [ ] Oracle: felixxm found _dozens of failures on Oracle_. @KimSoungRyoul were you able to replicate those failures on Oracle, and if so, has your updated patch resolved those failures? If not, I'll try to replicate those failures to see if I can help. \r\n- [ ] felixxm asked \"What about introspection of table comments?\" and I'm wondering if your updated patch addresses that.\r\n- [ ] Please update release notes and version annotations to 4.1 instead of 4.0 (the current dev version is 4.1 now that 4.0 feature lock has passed)\r\n- [ ] Please accept the changes @smithdc1 proposed\r\n- [ ] Please squash to 1 commit and update the PR with those changes",
      "Hey @KimSoungRyoul, do you plan to continue improving this pull request as per comments?",
      "yes I plan to work again rebased on django4.1 master\r\n",
      "Hi @KimSoungRyoul KimSoungRyoul\r\n\r\nThanks a lot for your great job!\r\n\r\nI have two questions:\r\n1. Is it safe in your opinion to use your very useful implementation ia a patch (so download https://github.com/django/django/pull/14463.patch and do git apply for my local django installation) for django 4.0.x or 4.1.x?\r\n2. Can you please advise some elegant way to use your implementation but to use verbose_name or help_text as a source for database comments for fields. I try to avoid specifying both things: e.g. help_text + db_comment",
      "I almost forget this pullrequest \r\n\r\nthank you for reminding me @sergun \r\n\r\n---\r\n# Updated checklist status:\r\n\r\nhttps://github.com/django/django/pull/14463#issuecomment-941152900\r\nIt's a checklist for the above comment\r\n\r\n- [x] (resolve comment which was reflected)\r\n- [x] (Oracle: @felixxm found dozens of failures on Oracle  <-- fixed it)\r\n- [x] ( update release notes 4.2)\r\n- [x] (accept feedback)\r\n- [x] (Please squash to 1 commit and update the PR with those changes)\r\n\r\n"
    ],
    "num_comments": 30,
    "repository": "django/django",
    "diff_length": 63890
  },
  {
    "index": 66,
    "pr_title": "Fixed #35515 -- Added auto-importing to shell command.",
    "pr_body": "# Branch description\r\nThis would be an update of the existing Django shell that auto-imports models for you from your app/project. Also, the goal would be to allow the user to subclass this shell to customize its behavior and import extra things.\r\n\r\n- Ticket [35515](https://code.djangoproject.com/ticket/35515#ticket)\r\n- Forum [discussion](https://forum.djangoproject.com/t/gsoc-2024-auto-importing-in-the-shell/30749/2)\r\n- GSOC [proposal](https://gist.github.com/salvo-polizzi/304b8cd001e7ccef95e7f",
    "pr_number": 18158,
    "comments": [
      "Thank you so much, @adamchainz, for the feedback. Currently, I'm concentrating on writing tests for these features. Do you have any references or suggestions on where to start? I'm considering creating new functions within the shellCommandTestCase to test the auto-imports.",
      "Yes, the tests should be within `ShellCommandTestCase`. \r\n\r\nYou can unit-test `get_namespace()` by calling it (`imports = Command().get_namespace()`) and making assertions on its contents. Then you can write integration tests similar to the existing ones that use `command` and `captured_stdin` to test those pathways.\r\n\r\nIt seems the existing tests don't actually cover launching the various shells. I think it‚Äôs worth trying adding coverage, at least for the default `python` shell, though there‚Äôs a risk that calling the startup file, interactive hook, or readline are not a good idea during a test run.",
      "Thanks @adamchainz again for your reviews. I left some questions in the comments",
      "Hi @DevilsAutumn, thanks for your review. I've started writing the new section on how to override the shell for a customized shell runner. I'll push it in the next few days.",
      "Hi @adamchainz,\r\n\r\nI've just changed the PR title and created a Trac ticket for this new feature. It's great to hear that this functionality is very well appreciated by other Django users and contributors, and I'm glad to contribute to this project. In the next few days, I'll work on writing tests to improve test coverage for methods that run the shell. I'm looking forward to seeing how this will turn out.",
      "I was thinking about how to document accessing models that had collisions. Do you think it would be better to add a new section to the tutorial or maybe a note?",
      "> I was thinking about how to document accessing models that had collisions. Do you think it would be better to add a new section to the tutorial or maybe a note?\r\n\r\nyep we need to add some information on how shell access models with collisions. A section would be too much, probably a note would be better.",
      "Thanks @sarahboyce for the precious review",
      "Don't forget to add a release note to Django 5.2 :star: ",
      "Another thing we need to think about is, should we update the [Django intro tutorial](https://docs.djangoproject.com/en/5.0/intro/tutorial02/#playing-with-the-api) when it is showing using the shell and importing the models (search for `>>> from polls.models import` in the docs)\r\nAs they don't need to do this importing, we can probably just remove them :thinking: we could add a `versionchanged` note (not sure if that's neccessary) - what do you think?",
      "> Another thing we need to think about is, should we update the [Django intro tutorial](https://docs.djangoproject.com/en/5.0/intro/tutorial02/#playing-with-the-api) when it is showing using the shell and importing the models (search for `>>> from polls.models import` in the docs) As they don't need to do this importing, we can probably just remove them ü§î we could add a `versionchanged` note (not sure if that's neccessary) - what do you think?\r\n\r\nI agree on removing the imports from there because it is unnecessary with this new feature. Regarding the `versionchanged` note, I actually don't know üòï. You know better than I do if this would be useful to most of django users or not.",
      "Maybe we should add it and then if someone is reading the tutorial on 5.2 but has an earlier version of Django installed (for some reason), they have a hint as to why they are getting an error :+1: ",
      "> Have you tested this on a Django project with lots of models? Is there a performance impact when a project has hundreds of models?\r\n\r\nI would not expect any performance impact as Django loads all models at startup anyway, before even loading the management command. This extension just fetches them from the app registry where they‚Äôre already referenced. Still worth testing with djangopackages to check everything works as expected.",
      "> Hi @salvo-polizzi , sorry for the radio silence on my part. I have had a busy time here with client work.\r\n\r\nHi @adamchainz, thank you for this and previous reviews that you did. \r\n\r\n> I have been thinking we could expand the automatic imports to include some useful utilities - at least adding `from django.conf import settings`. I definitely opened the shell a couple of times over the last few weeks just to check how a setting was being resolved. But perhaps we could avoid scope creep by pushing that kind of extension to a follow-up PR.\r\n\r\nIf we want to add some utilities by default, which ones do you think are the most useful? Should we discuss this on the forum first and then maybe open a ticket?",
      "> If we want to add some utilities by default, which ones do you think are the most useful? Should we discuss this on the forum first and then maybe open a ticket?\r\n\r\nYeah let‚Äôs do this on a forum thread first. Would you mind starting it?\r\n\r\n\r\n\r\n> I should have made this clear but I had squashed this into a single commit, rebased main, and done minor edits which have been lost (see [7137486](https://github.com/django/django/commit/71374867765ff5d228bdaaf13a06a3c18361d891))\r\n\r\n@salvo-polizzi I guess you used `git push --force` after you made changes locally, which erased Sarah‚Äôs work. To avoid this, use the ‚Äúsafe‚Äù force push options instead, which I blogged about here: https://adamj.eu/tech/2023/10/31/git-force-push-safely/ .\r\n\r\nI also have a post on squash-rebasing a branch here: https://adamj.eu/tech/2022/03/25/how-to-squash-and-rebase-a-git-branch/ . You‚Äôve added the commit message, which is great, but you should combine all 8 commits into one. To retain the message make sure you use the `s` (`squash`) rebase command for your last commit.",
      "> > If we want to add some utilities by default, which ones do you think are the most useful? Should we discuss this on the forum first and then maybe open a ticket?\r\n\r\n> Yeah let‚Äôs do this on a forum thread first. Would you mind starting it?\r\n\r\nIt would be great if we can roughly agree on the logic as to what should and what shouldn't be included by default. We want to draw a line somewhere and want to know when we should and shouldn't accept a ticket saying \"please add... to the auto imports\"",
      "> I also have a post on squash-rebasing a branch here: https://adamj.eu/tech/2022/03/25/how-to-squash-and-rebase-a-git-> branch/ . You‚Äôve added the commit message, which is great, but you should combine all 8 commits into one. To retain the > message make sure you use the s (squash) rebase command for your last commit.\r\n\r\nHi @adamchainz,\r\n\r\nI'm sorry for the confusion earlier.\r\n\r\nI wanted to ask you something about squashing commits. If I understand correctly, when I squash the latest 8 commits into one, the resulting commit message will be the first one, e.g., \"rebase on top of main branch.\" How can I retain the latest commit message instead of the first one? Do I need to reword both the first and the last commits so that the final message is \"Fixed ...\"?\r\n\r\nI apologize for these basic questions, but I'm not very experienced with git.",
      "> I wanted to ask you something about squashing commits. If I understand correctly, when I squash the latest 8 commits into one, the resulting commit message will be the first one, e.g., \"rebase on top of main branch.\" How can I retain the latest commit message instead of the first one? Do I need to reword both the first and the last commits so that the final message is \"Fixed ...\"?\r\n\r\nI might be wrong but I'm not sure you can do it in a single command (but Adam [wrote a book on git recently](https://adamchainz.gumroad.com/l/bygdx) :exploding_head: he might know)\r\nI would squash and have one commit and then [edit the message](https://docs.github.com/en/pull-requests/committing-changes-to-your-project/creating-and-editing-commits/changing-a-commit-message) of that squashed commit: `git commit --amend -m \"New commit message\"`\r\n\r\n> I apologize for these basic questions, but I'm not very experienced with git.\r\n\r\nI use the GUI integrated in PyCharm. Being purposeful about your git history is not a basic thing. I know many developers who are experienced and struggle with this :heart: ",
      "Thank you @salvo-polizzi for progressing with this project üéÅ \r\n\r\nA couple of questions:\r\n\r\n- There's the [`--no-startup`](https://docs.djangoproject.com/en/5.0/ref/django-admin/#cmdoption-shell-nostartup) option. I noticed that when using this option the auto-imports are still available. I was thinking that `--no-startup` should also mean \"no auto imports\". What do you think? \r\n\r\n- In my test project when printing `locals()` I see a number of items where the value is `None`. What do you think about filtering out the imports when the value is `None`. \r\n``` python\r\n ...\r\n 'messages_models': None,\r\n 'staticfiles_models': None\r\n```\r\n",
      "> I wanted to ask you something about squashing commits. If I understand correctly, when I squash the latest 8 commits into one, the resulting commit message will be the first one, e.g., \"rebase on top of main branch.\" How can I retain the latest commit message instead of the first one? Do I need to reword both the first and the last commits so that the final message is \"Fixed ...\"?\r\n\r\nTotally fine, and sorry this is even a task that many with years of Git experience might struggle with. Follow the tutorial, but for the final commit, use `s` (`squash`) instead of `f`. Then, you‚Äôll get your editor opened to merge the first and last commits‚Äô messages as you wish. When you save and close your editor, the rebase will continue and you‚Äôll have merged the message in.\r\n\r\nEdit: Or, yeah, you did what Sarah suggested, and that‚Äôs fine too! Sometimes it‚Äôs easier to use the tools you know and just copy-paste messages around to fix them up. Advanced rebasing is more of an efficiency thing.",
      "> * There's the [`--no-startup`](https://docs.djangoproject.com/en/5.0/ref/django-admin/#cmdoption-shell-nostartup) option. I noticed that when using this option the auto-imports are still available. I was thinking that `--no-startup` should also mean \"no auto imports\". What do you think?\r\n\r\nI don‚Äôt think we should overload the meaning of the option. If there was such a feature, I‚Äôd think it could be better as a separate option. But I also don‚Äôt think it‚Äôs particularly necessary.\r\n\r\n> * In my test project when printing `locals()` I see a number of items where the value is `None`. What do you think about filtering out the imports when the value is `None`.\r\n\r\n+1, let‚Äôs not include empty models objects.",
      "One thing I noticed that we have removed from the section of customising shell for different shell runners, probably because it out of the scope of this project (haven't read all the conversations so I am not very sure) but it will be a great addition to docs in my opinion. what do others think?",
      "> One thing I noticed that we have removed from the section of customising shell for different shell runners, probably because it out of the scope of this project (haven't read all the conversations so I am not very sure) but it will be a great addition to docs in my opinion. what do others think?\r\n\r\nI think this can be added in a separate commit or separate PR but not needed as part of ticket-35515",
      "@adamchainz I want to check that you're also happy before I merge as you've also been involved in the project. I think you're roughly happy but I want to be sure :+1:  ",
      "Thanks @jacobtylerwalls for your feedback :+1: ",
      "Thank you @salvo-polizzi for this work, I'm performing an in-depth review with the goal to land in the next 1-2 weeks. Sarah and I would love to have this feature merged before the 5.2 feature freeze. I'm also doing some trivial fixes and pushes, such as resolving conflicts.\r\n\r\nThere is one issue from the printed models (with `-v 2`) that REALLY bothers me which is that the shown imports does not follow the usual import isort guidelines that we use. (cc/ @adamchainz)\r\n\r\n(I'm adding this comment in isolation to start this conversation, other comments may come later as comments or new revnos pushed.)\r\n\r\nSpecifically, for a simple project with a single custom Django app (`testapp`), this is what I see:\r\n\r\n```\r\n(djangodev-3.13) nessita@picasso:~/fellowship/projectfromrepo$ python -Wall manage.py shell -v 2\r\n12 objects imported automatically\r\nfrom testapp.models import BasicModel\r\nfrom django.contrib.sessions.models import Session\r\nfrom django.contrib.contenttypes.models import ContentType\r\nfrom django.contrib.auth.models import User, Group, Permission\r\nfrom django.contrib.admin.models import LogEntry\r\nimport django.contrib.admin.models as admin_models\r\nimport django.contrib.auth.models as auth_models\r\nimport django.contrib.contenttypes.models as contenttypes_models\r\nimport django.contrib.sessions.models as sessions_models\r\nimport testapp.models as testapp_models\r\nPython 3.13.0 (main, Oct  8 2024, 08:51:27) [GCC 13.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n(InteractiveConsole)\r\n>>> \r\n```\r\n\r\n(MY EYES MY EYES) I would rather we indent one level in for the list, and we sort with isort if possible?\r\n\r\n```\r\n(djangodev-3.13) nessita@picasso:~/fellowship/projectfromrepo$ python -Wall manage.py shell -v 2\r\n\r\nAutomatic imports: 12 objects imported automatically.\r\n\r\n    import django.contrib.admin.models as admin_models\r\n    import django.contrib.auth.models as auth_models\r\n    import django.contrib.contenttypes.models as contenttypes_models\r\n    import django.contrib.sessions.models as sessions_models\r\n    from django.contrib.sessions.models import Session\r\n    from django.contrib.contenttypes.models import ContentType\r\n    from django.contrib.auth.models import User, Group, Permission\r\n    from django.contrib.admin.models import LogEntry\r\n\r\n    import testapp.models as testapp_models\r\n    from testapp.models import BasicModel\r\n\r\nPython 3.13.0 (main, Oct  8 2024, 08:51:27) [GCC 13.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n(InteractiveConsole)\r\n>>> \r\n```\r\n\r\nAlso, I think I have all the comments in the PR history and I did see the mention of including extra imports, but I think I don't see those in this PR? Are the ones that we agreed on https://forum.djangoproject.com/t/default-automatic-imports-in-the-shell/33708 being added in a follow up PR?\r\n\r\nThanks everyone!!!",
      "Hi @nessita,\r\nThank you for your valuable review. I apologize for not providing feedback over the past few weeks; I've been quite busy.\r\n\r\nRegarding the sorting of imports, I‚Äôd like to hear Adam‚Äôs thoughts, but personally, I think using isort could be a good solution.\r\n\r\nThe PR related to default imports is #18560. I haven‚Äôt worked on it yet because I was waiting for this PR to be merged first, so we can build the new changes upon it.",
      "> Hi @nessita, Thank you for your valuable review. I apologize for not providing feedback over the past few weeks; I've been quite busy.\r\n\r\nNo worries!\r\n\r\n> Regarding the sorting of imports, I‚Äôd like to hear Adam‚Äôs thoughts, but personally, I think using isort could be a good solution.\r\n\r\nSo I've been thinking about this, and I think that we should only sort if the env already has `isort` available, because at this stage we depend on the env created for the project and not in Django's. Does this make sense?\r\n\r\nI also think we should indent the listing, I can push a proposal soon if you don't object.\r\n\r\n> The PR related to default imports is #18560. I haven‚Äôt worked on it yet because I was waiting for this PR to be merged first, so we can build the new changes upon it.\r\n\r\nThank you! Makes sense to not update that until this one is completed and merged.",
      "Note that the current order printed is not the same as the order imported and we should probably update this (as duplicate model names overwrite eachother)",
      "> Note that the current order printed is not the same as the order imported and we should probably update this (as duplicate model names overwrite eachother)\r\n\r\nI was thinking whether we could only show the final list of \"really\" imported paths, that would mean removing from the list the shadowed imports.\r\n\r\n@salvo-polizzi Before changing anything, do you think that is doable and reasonably simple? Or does it add too much complexity?"
    ],
    "num_comments": 30,
    "repository": "django/django",
    "diff_length": 20983
  },
  {
    "index": 67,
    "pr_title": "Fixed #8936 -- Added view permissions and a read-only admin [rebased]",
    "pr_body": "Hi,\n\nThis is just a rebase of https://github.com/django/django/pull/5297\nThe only difference (besides fixing the merge conflicts) is that `ModelAdmin.declared_fieldsets` doesn't exist anymore and was replaced by `get_fieldsets`.\n\nThanks,\n\nOlivier\n",
    "pr_number": 6734,
    "comments": [
      "The test failures are:\nadmin_views.tests.UserAdminTest.test_user_fk_change_popup\nadmin_views.tests.UserAdminTest.test_user_fk_delete_popup\n",
      "Did you fix https://github.com/django/django/pull/5297#issuecomment-234072204?\n",
      "Hi,\n\nIt seems these tests fail because of a newline in the template (to comply with flake) :\n\n```\nself.assertContains(response, 'class=\"related-widget-wrapper-link change-related\" id=\"change_id_owner\"')\n```\n\n```\nAssertionError: False is not true : Couldn't find 'class=\"related-widget-wrapper-link change-related\" id=\"change_id_owner\"' in response\n```\n\nwhile this appears in the template :\n\n```\n        <a class=\"related-widget-wrapper-link change-related\"\n            id=\"change_id_owner\"\n```\n\nAn easy fix is to add the line break in the test, but this will fail again if the template gets changed. I see there's the `html` parameter to `assertContains`, but it doesn't seem to work with partial match (the test only tests for the `class` and the `id` attribute, it doesn't match since there are also a `data-href-template` and a `title` html attributes.\n",
      "I don't have a strong opinion about how to fix that.\n",
      "Hi,\n\nI made the changes :\n- missing space & flake8\n- failing tests (I just added the line break in the tested string, it's not very elegant but I don't see how to do it without making the test case too complex)\n- https://github.com/django/django/pull/5297#issuecomment-234072204 including another edge case when the inline has view and delete permissions\n\nI intend to squash those latter commits if they look good to you.\n\nI suggest closing #5297 to avoid having comments at different places.\n\nI removed the patch needs improvement flag on the ticket. Let me know if I can do anything more for this ! \n",
      "There's a failing build, but it looks like it's travis fault : `FATAL: Could not checkout ea3c082f7160685ab0c8215745dd191e0a85424c` \nAny way to restart the tests ?\n",
      "Rebase so the patch merges cleanly and squash commits (in general, there's no need to push incremental commits for minor changes; just squash right away). Of course with a patch of this size, after someday reviews the patch the first time , it might be useful to push incremental changes so they don't have to recheck the entire patch again.\n",
      "This will be a nice addition to the Django Admin. Can't wait to see it!\n",
      "We've been testing this in our own admin site and found a couple of things:\n- using `prepopulated_fields` with view only permissions fails (tries to access a field which doesn't exist on the form due to excludes).\n- using custom admin forms with form fields that only exist on the form fails (`label_for_field` issue).\n\nI'll try and write a couple of failing test cases.\n",
      "Hi. It's awesome PR and I tried it with my existing web app and existing database..\r\nMy question is how can I migrate from existing database? \r\nAs the Options.default_permissions doc said [here](https://github.com/django/django/pull/6734/files#diff-441cf273fa22534a25e767bb35062b7aR337), old existing apps can't use this new feature. \r\n\r\nI tried recreating the database and tried this feature, It worked with my app. \r\n",
      "@hirokiky: I see no reason why old existing apps cannot use this feature - the note states that backwards compatibility is maintained by ensuring that having a _change_ permission also implicitly means that the user has the _view_ permission for the same model. This is to avoid loss of access to pages in the admin site when Django is upgraded because users would not have the new _view_ permissions by default. After upgrade _change_ permissions can be removed and _view_ permissions added as required. (It also rarely makes sense to be able to change something but not view it!)",
      "@pope1ni Yes. Admin pages can be seen for existing users.\r\n\r\nBut with migrated DB, I can't apply `Can view <model>` for users. there isn't any `Can view <model>` permissions at change users page on admin.\r\nThe reason is that there aren't any `Can view <model>` permission on Permission model.\r\n\r\nanyway thank you. my comment was not enough.",
      "Any chance this feature will end up in Django 1.11? Not too much time left, right?",
      "New features aren't allowed after the alpha release, see https://code.djangoproject.com/wiki/Version1.11Roadmap.",
      "Hi all,\r\n\r\n@pope1ni Thanks a lot for the detailed review. I made some of the changes (the easy picks).\r\n\r\nI didn't do the initial implementation  Do you think there could be a better solution than get_uneditable_fields() ?\r\n\r\nSo here's the todo list to get this ready, am I missing something ?\r\n\r\n- [ ] Fix problems reported by @slurms  (@slurms, can you provide the tests ?)\r\n- [ ] Make it clear what to do to deal with old apps so that the view permission is created (@timgraham, any pointer on this ? I kind of naively thought the permissions would be created with migrations)\r\n- [ ] Explain get_uneditable_fields in the code (@PetrDlouhy , since you did the initial implementation, could you help me on this ? thanks again by the way)\r\n- [ ] Rebase on master\r\n\r\nJust a disclaimer : this is my first serious contribution to django, so reviewers please don't assume I'm exactly knowing what I'm doing\r\n\r\nLet's hope it will make it into Django one day :)\r\n\r\n\r\n\r\n\r\n\r\n",
      "Ok I just rebased, it was less painful than expected.\r\n\r\n- [ ] Fix problems reported by @slurms  (@slurms, can you provide the tests ?)\r\n- [ ] Make it clear what to do to deal with old apps so that the view permission is created (@timgraham, any pointer on this ? I kind of naively thought the permissions would be created with migrations)\r\n- [ ] Explain get_uneditable_fields in the code (@PetrDlouhy , since you did the initial implementation, could you help me on this ? thanks again by the way)\r\n- [X] Rebase on master",
      "@pope1ni thanks for the detailed review. I made all changes about style improvement and am starting to look into the three good questions you ask",
      "@olivergeorge Thank You for pushing this forward. The `uneditable_fields` are fields, that user can't edit either because he doesn't have permission or their edition is forbidden by admin settings. With introduction of view only permissions we need to be able to display all fields in read only mode.",
      "@PetrDlouhy Thank you for the initial work on this improvement. I have had time to think about this a little.\r\n\r\nMy main objection to the addition of `uneditable_fields` is that it seems exactly the same as `readonly_fields`, just reworded. Essentially if the user does not have permission to add or change (depending on the context) we really just want to dynamically append to `readonly_fields` for that request.\r\n\r\nThis could be achieved overloading `get_readonly_fields` with the permission checks although we would have to ensure that users who overload that themselves call `super()`. Alternatively there should be a private method/property that is used in place of `get_readonly_fields`, calls `get_readonly_fields` and then extends the result based on the permissions. This output can then be passed on down the chain to inline forms, etc.\r\n\r\nMy second problem is that the `uneditable_fields` argument / property and `get_uneditable_fields` method currently look as though they would be exposed as public API and this would confused users as the readonly_fields stuff exists already and this is really only intended to allow this new view permission to work.\r\n\r\nMy third issue is that `uneditable_fields` and `readonly_fields` are currently being passed around interchangeably which feels wrong and error-prone.\r\n\r\n",
      "We have implemented a detail view in a different way.\r\n\r\nWe have added `detail_view` method to model admin and a different template. Properties `fields_detail` and `fieldsets_detail`and methods `get_fields_detail` and `get_fieldsets_detail` to define fields and fieldsets. View permission and `has_view_permission` have been added as well. Wouldn't this approach be better? We are willing to share the code.",
      "@ryselis: What you suggest seems like a lot of copy and paste to provide a second copy of code used soley for the view-only case which is not going to be acceptable. If I am wrong feel free to comment with a link to a branch with your proposition.",
      "@pope1ni  It depends. We have used detail view for 2-3 years and at least for us it has diverged from the change view. Main differences:\r\n\r\n- we have implemented tabs instead of inlines. They are not just read-only inlines placed in tabs. They work more like mini changelists. Assume this data model: inquiry is the base model, commercial offer has a FK to inquiry (one inquiry may have multiple commercial offers) and commercial offer has its own inline model commercial offer item. There is no way to put commercial offer as inline in inquiry admin because it needs its own inlines, but it very reasonable to have a list of related commercial offers in inquiry detail, and with custom fields as well, like total sum of all items.\r\n- different fields are needed in change and detail forms, it is reasonable to show images and even charts there\r\n- different buttons are needed in change and detail forms\r\n\r\nBasically detail view is a blend of change form and changelist view for single item with additions - at least for how we are using it.\r\n\r\nI have hacked a detail view from our project into django so that you can see how much code would need to be duplicated. This code is not tested with unit tests and stripped to a minimal example. If we decide that this approach is acceptable, I will write tests and make the code more beautiful.\r\n [Here is the branch with the code, forked from master](https://github.com/ryselis/django/tree/issue_8936_detail_view).\r\nWe use a form under the hood to allow editing some fields from detail view - this might not be the best idea, it could be changed to something else.",
      "Hello everyone,\r\n\r\nSomeone wrote this project: https://github.com/vint21h/django-read-only-admin\r\nI don't know if it can help you but it might be worth sharing it.\r\n\r\nHave a great day!",
      "I had some time to work on this again. I think I was able to get rid of get_uneditable_fields. Basically, I moved the logic from get_uneditable_fields to  ModelAdmin.get_form and InlineAdminFormSet. It is much more clear this way.\r\n\r\nI also added a missing close button to the submit line in case the user has view only permissions.\r\n\r\nAnd I made some more changes according to  @pope1ni 's comments.\r\n\r\n@slurms it would be nice if you could provide the failing tests for your use case.\r\n",
      "Hello everyone,\r\nHow far is this feature from being merged?\r\nI'm hoping to see it in Django 2.0.  If someone could give me some direction, I'd be happy to help.",
      "Hi,\r\n\r\nFrom my point of view, this is ready to merge.\r\n\r\nI think @slurms problems happens because he has setup some custom admin forms, so when the form is read only, he tries to access inexistant fields. I don't think this should be considered as a bug, but it's true that with read only admin, the read-only case must now be considered when using custom forms. I wrote some notes about that in `docs/release/2.0.txt`.\r\n\r\n@viktor25 If you want to help make this into 2.0, please test the branch with your projects to see if you have issues and review the PR.\r\n\r\nAlso I will update the ticket to remove \"patch needs improvement\", so that it should be picked up by @timgraham (forgot about that last time :) ). Tim please let me know if there's anything more I can do to get this into 2.0.\r\n\r\n",
      "Hi @olivierdalang. I'll try to review this again sometime this week.",
      "I tested with my projects, here are the results.\r\n\r\nRegressions:\r\n1. JSONField with value [1, 2] is shown as 1, 2 instead of [1, 2].  JSONField with value [] is shown as empty.\r\n2. Geographic locations do not display on a map.  (Model with a django.contrib.gis.db.models.PointField, admin model inherits from django.contrib.gis.admin.OSMGeoAdmin)\r\n3. A ManyToManyField with lots of values displays as a wall of text.  It should display as a limited-size scrollable container.\r\n4. A foreign key in raw_id_fields should be displayed as a link to the foreign object.\r\n\r\nSuggestions:\r\n1. Related to point 4 above, it would be useful if any foreign relation is displayed as a link to the foreign object.  Including foreign keys not in raw_id_fields, and including many to many fields.\r\n2. Fields with editable=False (e.g. DateTimeField with auto_now=True) are not displayed in the change form, because they are not editable.  But being editable does not matter if I have only view permission.  So let's show non-editable fields.\r\n3. Use different URLs for viewing and for changing an object.  I will write a separate comment about the benefits of this.\r\n\r\n"
    ],
    "num_comments": 28,
    "repository": "django/django",
    "diff_length": 107177
  },
  {
    "index": 68,
    "pr_title": "Fixed #26167 -- Added support for functional indexes.",
    "pr_body": "Ticket: https://code.djangoproject.com/ticket/26167\r\n\r\nThis PR continues the work started in https://github.com/django/django/pull/8056. Since a lot of stuff have happened in regards to index creation rebasing on that fork was not really an option.\r\n\r\n~~One important change is made in https://github.com/django/django/pull/11929/commits/3d64e9c919fc8c91ba2de2354fdad209fa3d796f where an adjustment of wrapping parentheses had to be made to support casted indexes on postgres.~~ This is enables prett",
    "pr_number": 11929,
    "comments": [
      "Good work on getting this revived!\r\n\r\nI've only briefly looked at this, but it occurred to me:\r\n\r\n* What sort of API should we have for doing partial functional indexes? I believe the Index API handles this with a Q() expression as a `conditions` kwarg.\r\n\r\n* What about an API for covering indexes, or are these only a postgres thing?\r\n\r\nTo be clear, I'm not expecting either of those in this PR (although it's possible the first one may be possible). More that I don't want us to preclude us being able to make them later based on API decisions we make now.",
      "> What sort of API should we have for doing partial functional indexes? I believe the Index API handles this with a Q() expression as a conditions kwarg.\r\n\r\nIt is already supported by the `conditions` kwarg you mention:\r\n```python\r\nIndex(\r\n    fields=[Lower('headline')],\r\n    name=index_name,\r\n    condition=Q(pub_date__isnull=False),\r\n)\r\n```\r\n\r\n\r\n> What about an API for covering indexes, or are these only a postgres thing?\r\n\r\nYes that's a Postgres 11 feature where the `INCLUDE` keyword can be used to add non-key columns to the index. That would be a cool feature and probably implemented in a similar way as the `condition` kwarg. Also `INCLUDE` only supports columns and not expressions.",
      "> > What about an API for covering indexes, or are these only a postgres thing?\r\n> \r\n> Yes that's a Postgres 11 feature where the `INCLUDE` keyword can be used to add non-key columns to the index. That would be a cool feature and probably implemented in a similar way as the `condition` kwarg. Also `INCLUDE` only supports columns and not expressions.\r\n\r\nI believe that also SQL Server (I'm not a user, I just searched a bit for covering indexes): https://blog.sqlauthority.com/2007/04/23/sql-server-understanding-new-index-type-of-sql-server-2005-included-column-index-along-with-clustered-index-and-non-clustered-index/",
      "> Yes that's a Postgres 11 feature where the `INCLUDE` keyword can be used to add non-key columns to the index. That would be a cool feature and probably implemented in a similar way as the `condition` kwarg. Also `INCLUDE` only supports columns and not expressions.\r\n\r\nThis would be neat to add, but should be handled as a separate ticket/pr - should be quite simple - as you say, it only accepts columns.\r\n\r\n> I believe that also SQL Server (I'm not a user, I just searched a bit for covering indexes): https://blog.sqlauthority.com/2007/04/23/sql-server-understanding-new-index-type-of-sql-server-2005-included-column-index-along-with-clustered-index-and-non-clustered-index/\r\n\r\nSQL Server is not a supported backend in core Django, so I envisage the support being added in `django.contrib.postgres.indexes.Index` only.",
      "I found out that MySQL gained support for expression / function indexes in 8.0.13. At first all tests crashed with syntax errors when running against MySQL. This was because MySQL requires all expressions to be wrapped in parentheses while Postgres and SQLite allows not wrapping expressions if they are functions.  \r\n\r\nThis works on Postgres and SQLite but not on MySQL:\r\n`CREATE INDEX idx ON t1 (LOWER(col1) DESC);` \r\n\r\nMySQL requires the following (which Postgres and SQLite also supports)\r\n`CREATE INDEX idx ON t1 ((LOWER(col1)) DESC);`\r\n\r\nMaking the change to always wrap expressions in parentheses removed the required change in https://github.com/django/django/commit/3d64e9c919fc8c91ba2de2354fdad209fa3d796f to allow casted indexes for Postgres on `Cast.template`.\r\n\r\nHowever, adding this wrapping made expressions based on `OrderBy` throw syntax errors because the opclass / key_part is not seen as a part of the expression.  This would render to the following invalid SQL:\r\n`CREATE INDEX idx ON t1 ((LOWER(col1) DESC));`\r\n\r\nThis required a check to see if an expression is based on `OrderBy` (I added a convenience method on `BaseExpression` for this) and extract the ordering for appending at a later stage.  At the moment this change removes the possibility to add `NULLS LAST` and `NULLS FIRST` to column suffixes. This is not supported on MySQL and is not possible today with regular column indexes AFAIK. Maybe it‚Äôs okay to not support it initially? Adding support for these suffixes would require breaking out a lot of template-logic from `OrderBy`.\r\n",
      "Just realized that the current implementation messes up the index ordering. I‚Äôll have to refactor the splitting of `Index.fields` into columns and expressions and instead keep them as a single unit.",
      "I've added the `simple_col=False` argument to `BaseExpression.resolve_expression` as discussed in  https://github.com/django/django/pull/11929#discussion_r342496318. It makes for a much nicer interface but required a lot of changes. Let's see https://github.com/django/django/pull/11929/commits/79b594cfd6c0152d1a76fbe83cdccaf293937d31 as a proof-of-concept to be reverted if the `ExpressionIndexQuery` approach is preferred. ",
      "I think I have an external use case for simple_col, so I‚Äôm in favour of it in principle. ",
      "I've reverted the usage of `simple_col=True` in favour of `Query.alias_cols` introduced in https://github.com/django/django/pull/12067. (Nice job! üéâ)",
      "@hannseman Please squash the commits, and remember that the commit message should be \"Fixed #26167 -- Added support for functional indexes\". The ticket is already in the review queue. If you'd like to credit Markus for his work, you can use \"Co-Authored-By\", please see https://help.github.com/en/github/committing-changes-to-your-project/creating-a-commit-with-multiple-authors ",
      "> I think that the __init__ signature change to (*expressions, fields=(), ...) should be part of this PR.\r\n\r\nWe would need to make `*expressions` and `fields` mutually exclusive. The order of the fields and expressions are very important for composite indexes where one could create an index like:\r\n\r\n```\r\nCREATE INDEX foo_idx ON foo (field_a, UPPER(field_b), field_c);\r\n```\r\n\r\nThis would require:\r\n```\r\nIndex(F(\"field_a\"), Upper(\"field_b\"), F(\"field_b\"))\r\n```\r\n\r\nIn my opinion this makes for an even more confusing API than the `fields`-kwarg \r\n",
      "> > I think that the **init** signature change to (*expressions, fields=(), ...) should be part of this PR.\r\n> \r\n> We would need to make `*expressions` and `fields` mutually exclusive. The order of the fields and expressions are very important for composite indexes where one could create an index like:\r\n\r\nYes, that's correct.\r\n\r\n> \r\n> ```\r\n> CREATE INDEX foo_idx ON foo (field_a, UPPER(field_b), field_c);\r\n> ```\r\n> \r\n> This would require:\r\n> \r\n> ```\r\n> Index(F(\"field_a\"), Upper(\"field_b\"), F(\"field_b\"))\r\n> ```\r\n> \r\n> In my opinion this makes for an even more confusing API than the `fields`-kwarg\r\n\r\nWe could convert strings in `*expressions` to `F()` automatically.\r\n\r\n",
      "> We would need to make *expressions and fields mutually exclusive. The order of the fields and expressions are very important for composite indexes where one could create an index like:\r\n\r\nyep!\r\n\r\n> We could convert strings in *expressions to F() automatically.\r\n\r\nyeah I think that's the way to go, that's what we do for the all ORM expressions. e.g. we don't do `Max(fields=['field_a', 'field_b'])`.",
      "> yeah I think that's the way to go, that's what we do for the all ORM expressions. e.g. we don't do Max(fields=['field_a', 'field_b'])\r\n\r\nYup that makes sense. Should we raise an exception if both `*args` and `fields` are used?",
      "I this so, raising a `TypeError` to make sure both are exclusive seems like the most appropriate option.",
      "Should we require `Field('field').desc()` to be used when wanting to specifying a descending field through `expressions` or support we support `'-field'` there as well?\r\n\r\nI personally think we shouldn't support `'-field'` in `*expressions` just like we don't do anywhere else the expression API.",
      "> I personally think we shouldn't support -field in *expressions\r\n\r\nI agree. In my experience using mixed ordering in indexes is not so common that it warrants that shortcut.",
      "> > I personally think we shouldn't support -field in *expressions\r\n> \r\n> I agree. In my experience using mixed ordering in indexes is not so common that it warrants that shortcut.\r\n\r\nWorks for me :)",
      "I've been looking into this a bit more and in my opinion we are at a bit of a crossway. We either allow `django.db.backends.base.schema.BaseDatabaseSchemaEditor._create_index_sql` to be passed expressions in the `fields` argument or a new `expressions` argument.\r\n\r\nhttps://github.com/django/django/blob/d6db186427d33889e4d2f3b56e02807d51fc0376/django/db/backends/base/schema.py#L959-L986\r\n\r\n`_create_index_sql` would now be responsible of compiling the expressions along with some new DSL-class, `Expressions`? [This method](https://github.com/django/django/pull/11929/files#diff-803276386305dab54c20b97d3d34b82fR64-R81) would be moved into the schema editor or a `Expressions` DSL-class. The main issue with the current `Columns` DSL-class is the quoting of columns which should not be done on expresssions as that‚Äôs already handled.\r\n\r\nThe other option is to pass the already compiled SQL into `_create_index_sql`, as is the implementation today, but then we have the issue of the `Columns` DSL-class not knowing if the column-string is a compiled expression or a column which needs quoting, thus the hack that @MarkusH highlighted in https://github.com/django/django/pull/11929#discussion_r414609238.\r\n\r\nI feel like the former approach is the correct one but it would touch a lot mode in the schema editor and DSL so I wanted to discuss this before starting any work.\r\n\r\n> I guess we could keep the fields kwarg around and automatically turn it into expressions = list(map(F, fields))\r\n\r\nI looked into this and it _should_ be fine if we make sure to never wrap `F` expressions in parens, we need to do the wrapping for all other expressions.\r\n",
      "@hannseman \r\n\r\nI think that allowing either `fields` or `expressions` to be passed to `_create_index_sql` and using the old mechanism when `fields` is provided is the way to go. Providing resolved expressions via `expressions` to `_create_index_sql` should remove the need for manual quoting since [`F` resolves to `Col` which handles its quoting itself](https://github.com/django/django/blob/9ef4a18dbe71f538a9ef8c39111ae2f0b62eb90b/django/db/models/expressions.py#L779-L783).\r\n\r\nI suspect a new DSL `Expression(Reference)` reference will be required to implement `references_` method [based on `get_source_expressions`](https://github.com/django/django/blob/9ef4a18dbe71f538a9ef8c39111ae2f0b62eb90b/django/db/models/sql/query.py#L1647-L1652) and `rename_column_references` to use a similar logic but use `set_source_expressions` to create renamed cols and assign them.",
      "@charettes thanks for the pointers and sorry for the late reply, lots of stuff going on at the moment. \r\n\r\nIf I understand this correctly we would need to pass an instance of `SQLCompiler` to `Expressions(Reference)`.  Something like this:\r\n\r\n```python\r\nclass Expressions(Reference):\r\n    def __init__(self, table, expressions, compiler, quote_value):\r\n        self.table = table\r\n        self.expressions = expressions\r\n        self.compiler = compiler\r\n        self.quote_value = quote_value\r\n```\r\n\r\nWe would initialise the compiler in `_create_index_sql` like:\r\n```python\r\ncompiler = self.connection.ops.compiler('SQLCompiler')(Query(model, alias_cols=False), self.connection, using)\r\n```\r\n\r\nHaving the compiler available in `Expressions` would allow us to utilise `compiler.query. _gen_cols` to get the `Col` instances for usage in the `references_` and `rename_` methods. \r\n\r\nWe could then use `self.compiler` in `Expressions.__str__` to get the SQL:\r\n```python\r\ndef __str__(self):\r\n    sql_expressions = []\r\n    for expression in self.expressions:\r\n        sql, params = self.compiler.compile(expression)\r\n        sql = '(%s)' % sql\r\n        params = tuple(map(self.quote_value, params))\r\n        sql_expressions.append(sql % params)\r\n    return ', '.join(sql_expressions)\r\n```\r\n\r\nDoes this make sense? ",
      "@hannseman sorry my late answer as well, looks it slipped through the cracks.\r\n\r\nI think your approach makes sense but could you elaborate on why passing already resolved and compiled expressions to `_create_index_sql(expressions)` wouldn't work? It looks like it would avoid passing a compiler object all the way down there.",
      "> @hannseman sorry my late answer as well, looks it slipped through the cracks.\r\n\r\n@charettes, no worries!\r\n\r\n> I think your approach makes sense but could you elaborate on why passing already resolved and compiled expressions to _create_index_sql(expressions) wouldn't work? It looks like it would avoid passing a compiler object all the way down there.\r\n\r\nCorrect me if I'm wrong here but if we want to pass actual `Expression`-instances by `_create_index_sql(expressions)` we would need a compiler to get the actual SQL string? If that wasn't the goal I misunderstood you.  \r\n\r\nPassing the compiled expressions to `_create_index_sql(expressions, col_suffixes)` with their eventual ordering in `col_suffixes` would be simple. But implementing the DSL `Expression(Reference)` methods `references_` and `rename_` would be a bit problematic since we only have the compiled SQL expressions, I guess we could do some regex/string replacement but that feels a bit sketchy.\r\n\r\nHaven't really touched this since we last spoke but here's a working proof-of-concept implementation of the new DSL class with the \"pass-the-compiler\"-approach, the \"only\" non-working part is `rename_column_references`, I got a bit lost on how to update the expression with the new column name:\r\n\r\n```python\r\nclass Expressions(Reference):\r\n    def __init__(self, table, expressions, compiler, quote_value):\r\n        self.table = table\r\n        self.expressions = expressions\r\n        self.compiler = compiler\r\n        self.quote_value = quote_value\r\n\r\n    def references_table(self, table):\r\n        return self.table == table\r\n\r\n    def references_column(self, table, column):\r\n        columns = (col.target.column for col in self.compiler.query._gen_cols(self.expressions))\r\n        return self.table == table and column in columns\r\n\r\n    def rename_table_references(self, old_table, new_table):\r\n        if self.table == old_table:\r\n            self.table = new_table\r\n\r\n    def rename_column_references(self, table, old_column, new_column):\r\n        if self.table == table:\r\n            cols = self.compiler.query._gen_cols(self.expressions)\r\n            for index, col in enumerate(cols):\r\n                if col.target.column == old_column:\r\n                    # TODO: set_source_expressions somehow,\r\n                    # or can we mutable col.target.column?\r\n                    self.expressions[index] = col\r\n\r\n    def __str__(self):\r\n        sql_expressions = []\r\n        for expression in self.expressions:\r\n            expression = expression.resolve_expression(self.compiler.query)\r\n            ordering = ''\r\n            if expression.ordered:\r\n                ordering = ' DESC' if expression.descending else ' ASC'\r\n            sql, params = self.compiler.compile(expression.get_source_expressions()[0])\r\n            sql = '(%s)%s' % (sql, ordering)\r\n            params = tuple(map(self.quote_value, params))\r\n            sql_expressions.append(sql % params)\r\n        return ', '.join(sql_expressions)\r\n```\r\n",
      "> @hannseman Thanks üëç I left few comments, also not all previous comments were addressed, e.g. #11929 (comment).\r\n\r\nThanks for your comments! I'll look into them. \r\n\r\nRegarding https://github.com/django/django/pull/11929#discussion_r414609238, this will no longer be relevant when passing actual expressions (as proposed by @charettes) to `_create_index_sql`. We can then handle it properly in the DSL-class.",
      "@hannseman Could you please rebase? There are a few merge conflicts.",
      "@atombrella thanks for your reminder! \r\n\r\n~~`pull-requests-windows/database=sqlite3,label=windows,python=Python38` seems to be failing with `django.db.utils.OperationalError: no such function: JSON_VALID` when creating the test database. Not sure if this is related to this PR but can't really find other CI-runs with this error.. I did add a test model with a `JSONField` but it feels weird for this to only fail on windows~~ It was a flaky test.\r\n\r\nI've been busy with personal and work stuff lately so I've haven't really had the time to give this PR the love it need. Things should be calming down now and my plan is to start addressing outstanding issues next week. \r\n\r\nI plan on starting with setting `supports_expression_indexes=False` as default and allowing expressions to be passed as `Index(*args)` instead of `Index(fields=[...]` plus addressing the comments made by @felixxm in July. After that I can introduce my proof-of-concept of introducing `Expressions` to `ddl_references`.",
      "I've pushed commits addressing most of the discussed issues:\r\n* `supports_expression_indexes` now defaults to `False`.\r\n* Expressions can now be passed as `*args` to `Index`.\r\n* Expressions are now compiled in the new `ddl_references` class `Expressions`\r\n* Removed the usage of warnings in `Index` in preference of system checks.\r\n\r\nI still have some questions about how `django.db.backends.ddl_references.Expressions` should be implemented to be fully compatible with the `Reference` API, maybe it'll be easier to reason about them when committed to this PR. @charettes I would love some feedback when you have the time. See: https://github.com/django/django/pull/11929/files#diff-5cbfd43e179d9afbeb80629b206c1b77R227\r\n\r\nThanks!",
      "@charettes @felixxm do you have any advice on how to try and push this PR forward? The 3.2 feature freeze is approaching fast and it would sure be nice to get everything in shape for an inclusion in that release.\r\n\r\nOne area that might warrant an extra eye is the validation of arguments `Index.__init__` which changed a bit with the addition of the `*expressions` arg. I'm also not sure about if we need to save the original arguments of `*expressions` for the `deconstruct()` or if we can use the current version:\r\n\r\nhttps://github.com/django/django/blob/56644d8c1a873f6864429cf2c3661453a8d6e6c4/django/db/models/indexes.py#L63-L67\r\n\r\nThe whole new `Expressions` DDL-class also needs a needs a look through.\r\n\r\nMany thanks for your time!",
      "@hannseman It's on my list for Django 3.2. I will try to start work on it next week :crossed_fingers: ",
      "@charettes I've added an implementation of the discussed wrapper. The current implementation needs support for `F` expressions in `BaseExpression.flatten` thus the addition of `hasattr(expr, 'flatten')`."
    ],
    "num_comments": 30,
    "repository": "django/django",
    "diff_length": 93256
  },
  {
    "index": 69,
    "pr_title": "Fixed #35859 -- Implement Tasks interface as per DEP 14",
    "pr_body": "#### Trac ticket number\r\n\r\nticket-35859\r\n\r\nhttps://github.com/django/deps/blob/main/accepted/0014-background-workers.rst\r\n\r\n#### Branch description\r\n\r\nThis PR implements the first parts of `django.tasks`, as implemented in [`django-tasks`](https://github.com/realOrangeOne/django-tasks):\r\n\r\n- Common API interface\r\n- Base backend\r\n- Task / result classes\r\n- Immediate / Dummy backends\r\n\r\nThe database backend is intentionally absent, and will be added in future (**after** this PR is merged). This ma",
    "pr_number": 18627,
    "comments": [
      "Just one comment: Missing periods at the end of some of the docstrings.",
      "@carltongibson (as shepherd :sheep: ), what's the best way to get some Review Team eyeballs on this? Social media posting only gets the reviews so far.",
      "@RealOrangeOne Good hustle! Right... let me mention it to some folks.\r\n\r\nBut also ‚Äî create a Trac ticket \"Add DEP 14 Task interface\" (or similar), check Has Patch, link here, and change the title to `Fixed #... -- `. (Please also add carltongibson to the CC field on the ticket.) ‚Äî That way it will appear on the Fellow's \"Patches needing review\" list, which is pretty much all important. ",
      "I had a feeling a ticket might be the way forward. Opened ticket-35859.\r\n\r\n_Something something more content for the DEP talk_",
      "I have this checked out and am going through and reviewing this. Excited about getting this moving forward, but have a lot of little nits and things I think we want to clean up. There's so much scar tissue around backends that I know we all have, so I think we can provide something great but not complicated here!\r\n\r\nReally don't want to expand the scope, maybe some of this will involve simply hiding some stuff to future PRs. In any case hope to have finished reviewing this later tonight or tomorrow ",
      "Looking forward for this go out, any update on this?\r\n",
      "@malkoG https://justinmayer.com/posts/any-updates/"
    ],
    "num_comments": 7,
    "repository": "django/django",
    "diff_length": 101305
  },
  {
    "index": 70,
    "pr_title": "Added #34277 --  Add Conditional WHERE Clause to bulk_create for SQLite and PostgreSQL",
    "pr_body": "[#34227](https://code.djangoproject.com/ticket/34277)\r\nThis pull request introduces a significant enhancement to Django's ORM by adding a conditional WHERE clause capability to the `bulk_create` method for SQLite and PostgreSQL backends. This feature allows users to specify conditions under which updates should occur in case of conflicts during bulk insert operations, offering more control and flexibility in data handling.\r\n\r\n**Key Changes and Implementation:**\r\n- Added a `where_clause` paramete",
    "pr_number": 17515,
    "comments": [
      "@HamaBarhamou Thanks üèÜ I left a few cursory comments",
      "> Thanks for the initial work on this - it'll be a nice feature to have.\r\n> \r\n> I've added a bunch of comments with regards to making things more consistent, but I think the main blocker to progress will be properly supporting passing expressions to `where_clause` rather than backend-specific SQL which will leave this open to increased risk of SQL injection.\r\n\r\nThank you so much, ngnpope, for your constructive and detailed feedback. I am delighted to hear that this feature will be a welcomed addition and I take note of your suggestions to improve my pull request. I will work on the modifications you have recommended and incorporate them into the code. Your assistance is highly valuable and greatly contributes to my understanding of the Django project.",
      "Dear colleagues, @ngnpope , @shangxiao ,  I believe I have completed the modifications for my recent pull request. I eagerly await your feedback and suggestions for any necessary improvements. Thank you for your support and collaboration",
      "> Thanks for the updates @HamaBarhamou üôÇ\r\n> \r\n> I think you missed some of my previous comments. Unfortunately GitHub collapses stuff and it's easy to miss - look for the \"XX hidden conversations\" bits and click \"Load more...\".\r\n> \r\n> I've added some more comments. The big things of interest going forward are:\r\n> \r\n> * Where do we compile the condition expression - can we push down, etc. ?\r\n> * Can we make the condition expression more general than hardcoding to `F` and `Q`?\r\n> * How do we handle PostgreSQL's `EXCLUDED`?\r\n>   \r\n>   * I think this could be a subclass of `F` with some special handling perhaps\r\n>   * We could also probably use the name `EXCLUDED` on MySQL for the table alias\r\n>     \r\n>     * Currently we have `AS new`, but that can be anything and `new` is a bit generic\r\n\r\n\r\n\r\n> * Comment g√©rons-nous les PostgreSQL `EXCLUDED`?\r\n\r\nHello @ngnpope  and the team üôÇ,\r\n\r\nThank you for your insightful questions. Here are my thoughts:\r\n\r\nCompiling the condition expression: I will further reflect on the possibility of pushing the condition expression lower in the execution stack. It's an interesting point that I wish to explore more.\r\n\r\nGeneralizing the condition expression: My approach did not involve specific hardcoding for F and Q. I have utilized Django's existing mechanisms, which, to my understanding, are already suited to handle these expressions in a general manner. If my understanding diverges from what you expect, I am open to clarifications.\r\n\r\nHandling EXCLUDED in PostgreSQL: My work is a continuation of PR [#13065](https://github.com/django/django/pull/13065) where EXCLUDED was incorporated. My goal has been to add a WHERE clause to the existing query. If you think there are aspects I might have missed or misinterpreted regarding EXCLUDED, I am open to your guidance to ensure my contribution aligns perfectly with the project's expectations.\r\n\r\nI am still in a learning phase and appreciate your patience and guidance in this process.",
      "Dear Team @ngnpope @shangxiao ,\r\n\r\nI am writing to inform you that I have completed the necessary adjustments on the project and am ready for another review.\r\n\r\nHowever, I would like to seek your opinion on a specific point: is the current state of my work, which does not yet include an implementation for the MySQL backends, sufficient for acceptance? In other words, is it imperative to also integrate MySQL for my contribution to be considered complete, or are the current improvements adequate for acceptance?\r\n\r\nThank you for your feedback and guidance.\r\n\r\n",
      "Hello team @ngnpope, @felixxm, and @shangxiao üôå,\r\n\r\nI'm ready for another review. üöÄ\r\n\r\nI would like to bring to your attention the keyword EXCLUDED introduced in Django. I'm wondering if we should consider renaming EXCLUDED to avoid confusion with the EXCLUDED keyword specific to SQLite and PostgreSQL. From Django's perspective, EXCLUDED refers to the fields of new rows being inserted into the database, which implies using backend-specific keywords (like EXCLUDED, VALUES, NEW...). Hence, it seems necessary to clearly distinguish EXCLUDED in the Django context from EXCLUDED in the backend context.\r\n\r\nWhat are your thoughts on this? Your insights and suggestions would be greatly appreciated. üòäüëç\r\n\r\nThanks for your time and continued collaboration! üåü\r\n",
      "> As a suggestion, you might want to reduce the scope of this PR to getting condition into bulk_create which supports F and Q expressions. Then once that's landed, you can create a new PR with adding Excluded support.\r\n\r\n@sarahboyce I already requested that `Excluded` be added straightaway as it is, in my mind, a primary requirement of this feature.",
      "> > √Ä titre de suggestion, vous souhaiterez peut-√™tre r√©duire la port√©e de ce PR √† obtenir une condition dans Bulk_create qui prend en charge les expressions F et Q. Ensuite, une fois que cela est obtenu, vous pouvez cr√©er un nouveau PR en ajoutant le support exclu.\r\n> \r\n> @sarahboyceJ'ai d√©j√† demand√© que cela `Excluded`soit ajout√© imm√©diatement car c'est, √† mon avis, une exigence principale de cette fonctionnalit√©.\r\n\r\nthe idea of limiting the scope of this functionality and opening a pull request for the rest is good. only it must be applied to the case of mysql, limiting this feature only for sqlit and protesql. i tried to integrate mysql and gave up because i realized that it would be more complicated to manage, because mysql does not natively support conditional updates like protesql and sqlite. so in my opinion it deserves another tikect.",
      "Hi @HamaBarhamou, thank you for adding the test for `abulk_create` and the formatting changes ‚≠ê üéâ \r\n\r\nA couple of things have been missed\r\n\r\n- Please update the release notes based off this feedback: https://github.com/django/django/pull/17515/files#r1442594149\r\n- Please consider the documentation feedback I gave here: https://github.com/django/django/pull/17515#discussion_r1442588641\r\n\r\nThen the last one is whether you can have applied changes to have `Excluded` subclass `F` based off this discussion: https://github.com/django/django/pull/17515#discussion_r1442597457\r\nThink with a new year, you can approach this with fresh eyes and see if you can get this to work ü§û ",
      "> Ensuite, la derni√®re question est de savoir si vous pouvez avoir appliqu√© des modifications pour avoir `Excluded`une sous-classe `F`bas√©e sur cette discussion¬†: [#17515 (commentaire)](https://github.com/django/django/pull/17515#discussion_r1442597457) Pensez √† une nouvelle ann√©e, vous pouvez aborder cela avec un regard neuf et voir si vous pouvez faire fonctionner cela ü§û\r\n\r\nI don't know if you saw my comments. I had already solved the problem of Excluded sous class de F in my last commit.",
      "\r\n> Quelques choses ont √©t√© manqu√©es\r\n> \r\n> * Veuillez mettre √† jour les notes de version en fonction de ces commentaires¬†: https://github.com/django/django/pull/17515/files#r1442594149\r\n> * Veuillez prendre en compte les commentaires sur la documentation que j'ai donn√©s ici¬†: [Ajout de #34277 -- Ajouter une clause WHERE conditionnelle √† Bulk_create pour SQLite et PostgreSQL ¬†#17515 (commentaire)](https://github.com/django/django/pull/17515#discussion_\r\n> \r\n\r\nI see it on my github comment .\r\n![msg git](https://github.com/django/django/assets/77896711/c964e6a1-31b9-4c67-9f86-911855c7f6e6)\r\nMaybe you haven't seen my previous comments, I wonder if they have been registered by github.\r\n\r\n\r\n",
      "> * Veuillez mettre √† jour les notes de version en fonction de ces commentaires¬†: https://github.com/django/django/pull/17515/files#r1442594149\r\n\r\nI applied @ngnpope's suggestion here in his [comment ] (https://github.com/django/django/pull/17515#discussion_r1404166128)\r\nThere must be a reason for this.\r\nYou didn't say anything about it. Which of you two suggestions should I follow?",
      "> I've only managed a quick pass through right now - will have to have a more thorough look later.\r\n> \r\n> Please can you rebase **and squash all commits** so that we can have a clean slate for the next phase of review - there's quite a bit of clutter in the commit history now. And please ensure that any `@username` mentions are removed from the commit message so that we don't get pinged multiple times every time you push to the branch? Thank you.\r\n\r\nNice to see you again ngnpope. ok i'll see how to do it and i'll get back to you if there's a problem.",
      "Hi @ngnpope @kezabelle , don't forget to check the \"Patch needs improvement:\" box if you've finished the revision.",
      "Hi @ngnpope ready for another revision",
      "> Hi @ngnpope ready for another revision\r\n\r\nHello @HamaBarhamou! Thank you for your continued work in this branch. I wanted to mention two things:\r\n\r\n1. I believe that Nick asked you to please squash all commits into one. This does not seem to have done. If you have any doubts, [this post is a good resource to learn](https://adamj.eu/tech/2022/03/25/how-to-squash-and-rebase-a-git-branch/).\r\n2. There is no need to mention people by nickname when a PR is ready for a re-review, reviewers will get to this when they have some availability. The proper procedure to get a re-review is described in [these docs](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/submitting-patches/#patch-style). You just need to unset the relevant ticket flags so this PR gets added back to the \"patches needing review\" section of the [Django Developer Dahsboard](https://dashboard.djangoproject.com/).\r\n\r\nYou already did (2) which is great, but you'd still need to do the first request (rebase and squash). I'll set the ticket to \"patch needs improvement\" again just so we reflect the latest status following the reviewers comments.\r\n",
      "\r\n> 1. I believe that Nick asked you to please squash all commits into one. This does not seem to have done. If you have any doubts, [this post is a good resource to learn](https://adamj.eu/tech/2022/03/25/how-to-squash-and-rebase-a-git-branch/).\r\n\r\nThank you for the resource",
      "Hello,\r\n\r\nI apologize for the recent silence, I'm currently busy. I just wanted to know how to proceed with the docs/releases/5.1.txt file, since Django 5.1 is out. Should I transfer my work to docs/releases/5.2.txt ?",
      "> I apologize for the recent silence, I'm currently busy. I just wanted to know how to proceed with the docs/releases/5.1.txt file, since Django 5.1 is out. Should I transfer my work to docs/releases/5.2.txt ?\r\n\r\nYes that's right ‚úÖÔ∏è and no need to apologize ",
      "Hello,\r\n\r\nI was considering adding this feature myself, but looked to see if there was a PR in progress, and I'm glad to see that there is\r\n\r\nIs there any update on the progress of this PR being accepted?  It would be a great improvement!",
      "> Bonjour,\r\n> \r\n> J'envisageais d'ajouter cette fonctionnalit√© moi-m√™me, mais j'ai regard√© s'il y avait une PR en cours, et je suis heureux de voir qu'il y en a une\r\n> \r\n> Avez-vous des nouvelles de l'avancement de cette demande de participation¬†? Ce serait une grande am√©lioration¬†!\r\n\r\nthank you for your interest in this branch. i didn't have enough time, i admit, but i'm planning to start working on it [again soon ](https://forum.djangoproject.com/t/gsoc-2025-proposal-ticket-34277-conditional-where-clause-for-bulk-create/39920)"
    ],
    "num_comments": 21,
    "repository": "django/django",
    "diff_length": 28884
  },
  {
    "index": 71,
    "pr_title": "Refs #27332 -- Add feature to express conditional join on queryset",
    "pr_body": "```python\r\nQuerySet().filtered_relation('relation', alias='alias_relation', condition=Q())\r\n```\r\nEDIT for new API:\r\n```python\r\nfrom django.db.models import FilteredRelation\r\nQuerySet().annotate(alias_relation=FilteredRelation('relation', condition=Q()))\r\n```\r\nhttps://code.djangoproject.com/ticket/27332\r\n\r\n@akaariai I'm not fully satisfied with the implementation. I had to fight the ORM to make it work in my direction.\r\nSo I hope someone will be able to spot quickly the wrong choices I made, to p",
    "pr_number": 7560,
    "comments": [
      "i guess @holvianssi is his active id",
      "I tried a couple of approaches and this was best I was able to come up with https://github.com/holvi/django/tree/anssi-filtered_relation",
      "Thanks @holvianssi,\r\nIt looks very nice.\r\n<strike>the rebase didn't work like expected. I lost original ownership. The second commit is your work.</strike>\r\n I granted you collaborator of my repo so you can push your changes with your name on my branch.",
      "I had some problems with rebase, sorry for the author change! You can just cherry-pick my commit and continue from there. I likely won't have much time for this, but I'll try to review your work if at all possible.",
      "@holvianssi I think we managed to get something mergeable.\r\n\r\nof course some commits needs to be fixed up, I'll keep them until we reach consensus to ease the review with incremental changes.",
      "@timgraham Thank you for your feedback. I will raise awareness of this pull request on the mailing list.",
      "Great, I'm looking forward to its final implementation in Django!",
      "Thank you @Ian-Foote , I addressed your comments and rebased the branch against master to solve the conflict.",
      "Any chance before feature freeze ? :grimacing:",
      "Any news before feature freeze? Or it happened already?",
      "@ticosax probably you need a rebase",
      "Sorry, this won't make it as I haven't had time to review in detail and I don't see any other particularly detailed reviews.",
      "Do you think there might be a way to specify if the join should force the use of INNER or LEFT? It's a common problem that people have, and it feels like this patch should be able to deliver that. Something like:\r\n\r\n```\r\nQuerySet().filtered_relation('relation', alias='alias_relation', condition=Q(), force_left=True)\r\nQuerySet().filtered_relation('relation', alias='alias_relation', condition=Q(), force_inner=True)\r\n```\r\n\r\nThoughts?",
      "About left joins, I think we should always generate the join as LEFT join. If the user wants to have INNER join, let's recommend doing `.filter(alias_relation__isnull=False)`. Now Django should be smart enough to turn that join to INNER join.",
      "There are two cases where this needs additional tests.\r\n\r\nIf you do a filtered relation against a NOT NULL field, then the join should be generated as LEFT join instead of INNER join. Assume book.author is not nullable, then `Book.objects.filtered_relation('author', alias='only_young_authors', condition=Q('author__age__lte=20'))` should produce a query with LEFT JOIN for author.\r\n\r\nWe need to consider what should happen in split exclude cases:\r\n```\r\n qs1 = Author.objects.filtered_relation('friends', alias='young_friends', Q(friends__age__lte=20))\r\n qs2 = Author.objects.all()\r\n```\r\nnow, `qs1.exclude(young_friends__age__gte=10)` should produce a subquery like `qs2.exclude(friends__age__gte=10)` does for the filter clause. The test would be something along the lines of having one author with friends with ages 5 and 10 and 15, and another with friends of age 5 and 25 and 30.",
      "@holvianssi Nice to see you back.\r\nI will work on adding those new use cases.",
      "@holvianssi 0aac5d81a85f754719781bbb5f44dd01dff6c5d6 shows that you were right.\r\nexclude() was not supported at all.\r\n\r\nYou mentioned 2 use cases that are missing. I'm not sure I understood both, just one instead.\r\nplease can you clarify in view of latest commit ?",
      "The other case can be seen with the following example data:\r\n   Book -> Author: age = 30\r\n\r\nWhere the model is something like Book.author = ForeignKey(Author, null=False)\r\n\r\nAnd the query is:\r\n```\r\nqs = Book.objects.filtered_relation(\r\n    'author', alias='young_authors', condition=Q(author__age__lte=20)\r\n)\r\nself.assertEqual(qs.filter(young_authors__isnull=True).count(), 1)\r\n```\r\nAs an additional performance improvement, if you do some other query against this relation, then the join type should be INNER. For example:\r\n```\r\n    self.assertIn('INNER JOIN' in str(qs.filter(young_authors__age__gte=10).query))\r\n```\r\nbut this case is not that important, it's just a performance optimization.",
      "There is still another case to consider - should .filter(young_friends__age__lte=20).filter(young_friends__name__icontains='a') produce two joins, or reuse the same join (the question is if the query should match if there is a young friend with age less than 20 and 'a' in the name, or if it should match if there is a young friend with age less than 20, and a possibly separate young friend with 'a' in the name). If you query for .filter(friends__age__lte=20).filter(friends__name__icontains='a'), you'll get two joins with Django.\r\n\r\nThere are cases where it would be useful to be able to say \"add this join to the query, further .filter() or .exclude() operations will work against that exact join\", and there are cases where you want the current Django semantics for the added relation. So, I'm not sure which way would be the best one forward. If it would be possible it would be nice to have current Django semantics as default, but be able to say \"I want this join, I know what I'm doing\" as an option. But doing both might make this too complicated to work on.\r\n\r\nI hope this makes even some sense. We are getting into the dark areas of split_exclude(), join promotion and multiple joins for same reverse foreign key relation...",
      "You know how to scare people :wink:\r\nI will try harder, thank you for your commitment, this is helpful.",
      "I'm sorry this is getting so complex... I am a big advocate of doing something simple and then building on top of that.\r\n\r\nThe problem here is that the query semantics are hard to change. Doing so means breaking applications in subtle ways... Who's going to have test cases for all the different .exclude() and .filter(q1, q2) vs .filter(q1).filter(q2) weirdness?\r\n\r\nRight now I'm thinking that maybe we should go with a definition where .filtered_relation() essentially adds a single JOIN to the query no matter what. That is, we will not need split_exclude() support for this, nor do we have to implement .filter(q1).filter(q2) vs .filter(q1, q2) semantics. I believe this behaviour is what people will expect in any case. And, we can always add a flag to filtered_relation later on so that users can pick different semantics.\r\n\r\nIf we go with the above definition of \"single join per filtered_relation()\", then we'll need to verify the following items:\r\n   - We don't try to generate multiple joins in case of `.filter(young_friends__age__gte=10).filter(young_friends__name__icontains='a')`\r\n   - We don't try to split_exclude in case of `.exclude(young_friends__age__gte=10)`\r\n   - We correctly generate LEFT joins as explained in previous comments, and possibly also implement the INNER JOIN promotion performance optimisation.\r\n   - Documentation for the single join semantics.\r\n\r\nIt would also be nice to support .select_related() and .prefetch_related() for .filtered_relation(), but let's leave that for later.",
      "I'm going to check this one a bit. I'm now thinking that we should definitely go with an approach where you can select_related() filtered relations. If you have datamodel like this:\r\n```\r\nclass Payment:\r\n    amount = DecimalField()\r\n\r\nclass Debt:\r\n   amount = DecimalField()\r\n\r\nclass DebtPayment:\r\n   payment = ForeignKey(Payment, related_name='debt_payments')\r\n   debt = ForeignKey(Debt, related_name='debt_payments')   \r\n   amount = DecimalField()\r\n```\r\n\r\nThen you could run a query like:\r\n```\r\nDebt.objects.filtered_relation(\r\n    'debt_payments', alias='debt_payments_filtered', condition=Q()\r\n).select_related('debt_payments_filtered__payment')\r\n```\r\nthis would then produce results like this:\r\n```\r\ndebt1: amount 100 - debtpayment1: amount 60 - payment1: 60\r\ndebt1: amount 100 - debtpayment2: amount 40 - payment2: 200\r\ndebt2: amount 160 - debtpayment3: amount 160 - payment2: 200\r\n```\r\n\r\ngetting this kind of result as model objects is currently impossible in Django, and this would be an useful feature for sure...",
      "I did a bit of work on top of this in https://github.com/django/django/pull/8238. There is a rebase + select_related support. If you feel like working on this still, please pick the work from the other PR and I'll close it.\r\n\r\nThis is starting to look like a really nice feature to me, nice work. And, we can forget about all of the complexities I mentioned in the couple of previous comments. If you can select_related to the filtered relation, and there is no need for the weird split exclude cases, I believe this will work much more intuitively for users.\r\n\r\nIn fact, it might be worth it to check if we could somehow deprecate the existing .filter().annotate() interactions, and instead ask users to use .filtered_relation().annotate(). This would remove a special case from the ORM. The special case is causing confusion both for users and for ORM developers,  so from my point of view that would be a nice cleanup.",
      "<strike>superseded by #8238</strike>",
      "@ticosax and @holvianssi / @akaariai where are we at with this? If we can do the review work now there's a good chance of getting in for 2.0. Letting this languish for another release would be unfortunate.",
      "@jarshwah Thank you for your interest into this PR, I'd really like to see it merged as it is a critical feature for us.\r\nWhat is missing, I believe, is more reviewer to get it merged.\r\n\r\nI'm maintaining it on top of master regularly, but it seems bfb746f983aa741afa3709794e70f1e0ab6040b5 is breaking `select_related` feature.\r\nI'm working on it, but it is still WIP on my side.",
      "I've posted to django-dev mailing list asking for some reviewers: https://groups.google.com/forum/#!topic/django-developers/extn_W-w5sk",
      "@jarshwah @atombrella Thank you both for your feeback. This is really appreciated, I do intend to address them, but first, I need to successfully rebase the PR.\r\nThe difficulty is unfortunately not just solving merge conflicts, but rather solving a design question that\r\nbfb746f983aa741afa3709794e70f1e0ab6040b5 brought since the last rebase of this PR, roughly 1 month ago.\r\nI will try to explain in few words what is my blocker.\r\nBefore bfb746f983aa741afa3709794e70f1e0ab6040b5 the select_related feature was implemented this way:\r\n```python\r\n# django/db/models/query.py\r\nsetattr(from_obj, self.cache_name, obj)\r\n```\r\n\r\nBut after the new API introduced by bfb746f983aa741afa3709794e70f1e0ab6040b5 it became:\r\n```python\r\n# django/db/models/query.py\r\nself.field.set_cached_value(instance, value)\r\n```\r\n`select_related` feature is broken because the new implementation expect to have a descriptor field for every value selected by `select_related`.\r\n\r\nLet's take an example from the tests:\r\n```python\r\nqs = Author.objects.filtered_relation(\r\n            'book', 'book_join', condition=Q()\r\n        ).select_related(\r\n            'book_join__editor'\r\n        ).order_by('pk', 'book_join__pk')\r\n```\r\nFollowing this example, the new API expect to have a field on `Author` instance called `book_join`, which of course doesn't exists. So the test fails with `AttributeError` when we try to access `qs[0].book_join`.\r\n\r\nI will explore few ideas in order to solve the problem, but for the moment I'm wondering if it wouldn't be better instead, to leave `select_related` feature out of the scope of this PR, and come back later with another PR to bring it back. Once `filtered_relation` (or `filter_related`) is part of master.\r\nIt will be easier to tackle one challenge at a time.",
      "I did a rebase of the feature here: https://github.com/holvi/django/tree/filtered_relation\r\n\r\nFor the set_cached_value case I ended up just storing a setter in klass_info for both local and the remote object value setting. This seems to work well, and makes the code a bit cleaner than it was.\r\n\r\nI went through the queryset docs and checked how this works in combination with things you can do to a queryset. I ended up doing a small fix for .defer() queries. Note that some of the features aren't tested explicitly, and of course there's very little tests for combinations of the features.\r\n   - tested or no need to test separately: filter(), exclude(), get(), first(), last()\r\n   - values_list() tested, values() *not* tested\r\n   - annotate() tested\r\n   - order_by(), reverse() tested\r\n   - distinct() tested\r\n   - dates(), datetimes() - should be no need to test separately\r\n   - none(), all() - should be no need to test separately\r\n   - union(), interesection(), difference() *not* tested\r\n   - select_related() tested\r\n   - prefetch_related() *not working*\r\n   - extra() *not* tested, should work\r\n   - defer(), only() defer tested, only() should work\r\n   - select_for_update() not tested, should work\r\n\r\nThen there exists a bunch of data altering methods, of which I guess .update() together with F() to filtered relation might be worth a check.\r\n\r\nOf the above ones, I think we need something for prefetch_related() (IMO it's ok to document this doesn't work yet), and we should check union() type queries, and then still maybe add a test for values().\r\n\r\nAs for the API itself - I'll post to django-developers about that separately.",
      "@holvianssi This is pure awesomeness. Thank you again !\r\n\r\nTo help with coordination, I plan to take your branch and push it here.\r\nThen, I will address all comments left by @jarshwah, @atombrella and @adamchainz.\r\nThen, I will add more tests for.\r\n- [x] `values()`\r\n- [x] `extra()`\r\n- [x] `union()`, `interesection()`, `difference()`\r\n- [x] `only()`\r\n- [x] `select_for_update() `\r\n\r\n- [x] Finally, Document that `prefetch_related()` is not supported.\r\n\r\nLet's make it :rocket: "
    ],
    "num_comments": 30,
    "repository": "django/django",
    "diff_length": 65947
  },
  {
    "index": 72,
    "pr_title": "Code() in file Code_mobject.py to display code with color highlighted works correctly with updates in text_mobject.py and svg_mobject. ",
    "pr_body": "you can use it as follow.\r\nif you put file into \"assets/codes\" folder then you don't need to specify full file path, just name of file is enough otherwise specify full file path.\r\n`if generate_html_file==True` it create a html file with color  highlighted and save it to \"assets/codes/generated_html_files/\" \r\n```python\r\nfrom manimlib.imports import *\r\nclass codeExample(Scene):\r\n    def construct(self):\r\n        heading = TextMobject(\"\\\"Hello, World\\\" Program\", stroke_width=0).scale(1.3)\r\n        ",
    "pr_number": 1018,
    "comments": [
      "`text = Text('a', ' ', 'b')`\r\nit shows only 'a' to the screen \r\nany one can help ?",
      "> `text = Text('a', ' ', 'b')`\r\n> it shows only 'a' to the screen\r\n> any one can help ?\r\n\r\nSolved !",
      "now everything is working fine.",
      "Only changes I would make is \r\n\r\n1.)adding CodeMobject to imports.py\r\n\r\n2.) changing some of the variable names to more meaningful things I've noticed you used letters alot which may be confusing to someone who may come about this file in the future\r\n\r\n3.)also there seems to be an issue on line 125 ``` i = lines.index(\"</pre>\")``` where sometimes there is white spaces before ```</pre>``` which then results in an error saying that they couldn't find ```</pre>'s``` index because its looking for an exact match \r\n\r\notherwise it looks good maybe we can try implementing the conversion of the HTML for the user so they don't need to rewrite code and convert it to a readable version for Manim, instead I'm proposing that we allow the user to add any file type to assets/codes and then we convert for them",
      "> Only changes I would make is\r\n> \r\n> 1.)adding CodeMobject to imports.py\r\n> \r\n> 2.) changing some of the variable names to more meaningful things I've noticed you used letters alot which may be confusing to someone who may come about this file in the future\r\n> \r\n> 3.)also there seems to be an issue on line 125 ` i = lines.index(\"</pre>\")` where sometimes there is white spaces before `</pre>` which then results in an error saying that they couldn't find `</pre>'s` index because its looking for an exact match\r\n> \r\n> otherwise it looks good maybe we can try implementing the conversion of the HTML for the user so they don't need to rewrite code and convert it to a readable version for Manim, instead I'm proposing that we allow the user to add any file type to assets/codes and then we convert for them\r\n\r\nupdated !",
      "implementing the conversion of the HTML\r\n\r\ndo you mean user input .cpp file or any other and it automatically converts it to html ?\r\n\r\ni don't found any better way to do that, i tried pygments but it have only few coding languages options and sometimes don't highlight correctly.\r\n\r\ndo you have any other better option?\r\n",
      "well i can implement that online highlighter in python then it send request to the server and get highlighted html",
      "> Dude awesome work, lets try and get a code converter working to make code_mobject even better!\n\nI will try to achieve this by using markdown to html conversion. ",
      "> \r\n> \r\n> implementing the conversion of the HTML\r\n> \r\n> do you mean user input .cpp file or any other and it automatically converts it to html ?\r\n> \r\n> i don't found any better way to do that, i tried pygments but it have only few coding languages options and sometimes don't highlight correctly.\r\n> \r\n> do you have any other better option?\r\n\r\nyou might want to checkout http://hilite.me/ it seems they have an api available to use",
      "> > implementing the conversion of the HTML\r\n> > do you mean user input .cpp file or any other and it automatically converts it to html ?\r\n> > i don't found any better way to do that, i tried pygments but it have only few coding languages options and sometimes don't highlight correctly.\r\n> > do you have any other better option?\r\n> \r\n> you might want to checkout http://hilite.me/ it seems they have an api available to use\r\n\r\nthanku\r\n\r\nimplemented that !",
      "Seems like delete empty path can't solve space problem correctly.\r\nt2c failed to work.\r\n```py\r\nfrom manimlib.imports import *\r\n\r\nclass Test(Scene):\r\n    def construct(self):\r\n        t = Text('hello, world!', t2c={'world':BLUE})\r\n        self.add(t)\r\n```\r\n![Code](https://user-images.githubusercontent.com/47266984/81032522-c2218e00-8ec2-11ea-8855-e42843aa067b.png)\r\nI think we should count space character, because it's more intuitive.",
      "I find a way now, but how can I show you...",
      "> Seems like delete empty path can't solve space problem correctly.\r\n> t2c failed to work.\r\n> \r\n> ```python\r\n> from manimlib.imports import *\r\n> \r\n> class Test(Scene):\r\n>     def construct(self):\r\n>         t = Text('hello, world!', t2c={'world':BLUE})\r\n>         self.add(t)\r\n> ```\r\n> \r\n> ![Code](https://user-images.githubusercontent.com/47266984/81032522-c2218e00-8ec2-11ea-8855-e42843aa067b.png)\r\n> I think we should count space character, because it's more intuitive.\r\n\r\nSolved !\r\nCheck updated text_mobject.py\r\n\r\n\r\ni just added `self.text = text.replace(\" \", \"\")`",
      "but,  like I said, not counting space character is a not good way for people who want to use t2c and index.\r\nHere I think is a better way.\r\n```py\r\n    def __init__(self, text, **config):\r\n        self.text = text\r\n        self.full2short(config)\r\n        digest_config(self, config)\r\n        self.lsh = self.size if self.lsh == -1 else self.lsh\r\n\r\n        file_name = self.text2svg()\r\n        SVGMobject.__init__(self, file_name, **config)\r\n\r\n        # deal with space character\r\n        self.apply_space_char()\r\n\r\n        if self.t2c:\r\n            self.set_color_by_t2c()\r\n        if self.gradient:\r\n            self.set_color_by_gradient(*self.gradient)\r\n        if self.t2g:\r\n            self.set_color_by_t2g()\r\n\r\n        # anti-aliasing\r\n        self.scale(0.1)\r\n\r\n    def apply_space_char(self):\r\n        for start, end in self.find_indexes(' '):\r\n            space = Dot(fill_opacity=0, stroke_opacity=0)\r\n            space.next_to(self.submobjects[start])\r\n            self.submobjects.insert(start, space)\r\n```",
      "TextMobject() is also works like that without counting spaces even without editing svg_mobject.py\r\n```python\r\nclass Test3(Scene):\r\n    def construct(self):\r\n        text = TextMobject(\"a b\")\r\n        text[0][1].set_color(RED)\r\n        self.add(text)\r\n        self.wait()\r\n```\r\nOutput\r\n![Test3](https://user-images.githubusercontent.com/30471072/81033964-20467500-8eb3-11ea-90fb-49c40bca2a54.png)",
      "wait\r\nspace.next_to(self.submobjects[start]) should be space.next_to(self.submobjects[start-1])",
      "But it's not intuitive, you need to calculate by yourself before using index, and we can avoid it simply by adding the above code.\r\n> TextMobject() is also works like that without counting spaces even without editing svg_mobject.py\r\n\r\nI think this should not be the reason, the goal of making Text, is to replace TextMobject (in some way). There are lots of things of manim that we can improve and let users use them more easy and comfortable.",
      "> But it's not intuitive, you need to calculate by yourself before using index, and we can avoid it simply by adding the above code.\r\n> \r\n> > TextMobject() is also works like that without counting spaces even without editing svg_mobject.py\r\n> \r\n> I think this should not be the reason, the goal of making Text, is to replace TextMobject (in some way). There are lots of things of manim that we can improve and let users use them more easy and comfortable.\r\n\r\nResolved !",
      "I'm not sure that adding background_rect to CodeMobject is a good choice.\r\nI actually made a Window sometime ago.\r\nBut I haven't finished yet and haven't thought it carefully yet...\r\n```py\r\nfrom manimlib.imports import *\r\n\r\nSCRIPT = \"\"\"\r\nfrom manimlib.imports import *\r\n\r\nclass Hello(Scene):\r\n    def construct(self):\r\n        greet = Text('Hello, world!')\r\n        self.play(Write(greet))\r\n\"\"\"\r\n\r\nclass Window(VGroup):\r\n    def __init__(self, height=4, width=6, mobject=None):\r\n        if mobject:\r\n            height = mobject.get_height() + 0.1*2*2 + 0.1*3*2\r\n            width = mobject.get_width() + 0.1*3*2\r\n        rrect = RoundedRectangle(corner_radius=0.1, height=height, width=width,\r\n                                 stroke_width=0,\r\n                                 color='#263238', fill_opacity=1)\r\n        red_button = Dot(radius=0.1, stroke_width=0, color='#ff5f56')\r\n        red_button.shift(LEFT*0.1*3)\r\n        yellow_button = Dot(radius=0.1, stroke_width=0, color='#ffbd2e')\r\n        green_button = Dot(radius=0.1, stroke_width=0, color='#27c93f')\r\n        green_button.shift(RIGHT*0.1*3)\r\n        buttons = VGroup(red_button, yellow_button, green_button)\r\n        buttons.shift(UP*(height/2-0.1*3) + LEFT*(width/2-0.1*6))\r\n\r\n        VGroup.__init__(self, rrect, buttons)\r\n        if mobject:\r\n            x = (height - mobject.get_height())/2 - 0.1*3\r\n            self.shift(mobject.get_center())\r\n            self.shift(UP*x)\r\n            self.submobjects.append(mobject)\r\n\r\nclass Demo(Scene):\r\n    CONFIG = {\r\n        'camera_config': {\r\n            'background_color': WHITE,\r\n        }\r\n    }\r\n\r\n    def construct(self):\r\n        code = Text(SCRIPT, font='Microsoft YaHei Mono', size=0.3)\r\n        window = Window(mobject=code)\r\n        self.play(DrawBorderThenFill(window))\r\n        self.wait()\r\n```\r\n![image](https://user-images.githubusercontent.com/47266984/81034991-98b93000-8ecb-11ea-88c1-aaca5f273582.png)\r\n",
      "the spaces(' ') in front or back will not be ignored.\r\nFor example `Text(\"          a   b               \")` will work fine.",
      "> I'm not sure that adding background_rect to CodeMobject is a good choice.\r\n> I actually made a Window sometime ago.\r\n> But I haven't finished yet and haven't thought it carefully yet...\r\n> \r\n> \r\n> ![image](https://user-images.githubusercontent.com/47266984/81034991-98b93000-8ecb-11ea-88c1-aaca5f273582.png)\r\n\r\nThanku\r\nimplemented that !",
      "You probably misunderstand my comment üòÇ\r\n\r\nHonestly, I have planned to make a subclass of `Text` called `Code`,\r\nbut clearly you are faster than me üòÇ, \r\nbut it doesn't matter, I am happy to see someone want to improve manim's functionality ‚ù§\r\n\r\nAnd here are some thoughts I was planning to do with `Code` and I'd like to share with you.\r\n1. I think `Code` is a enhanced `Text`, which can handle syntax highlighting (based on `pygment`).\r\n2. Unlike the way of `Text` dealing with multi-line text (which is one dimension array to index), `Code` will separate each line (two dimension array e.g. code[row][column])\r\n3. Add another `Mobject` called `Window`, which behaves pretty like `SurroundingRectangle`, but has those buttons on the top, and I'm also planning two styles of `Window` (macos-like and windows-like)\r\n\r\nbtw, the number in the front of each line is a good idea. And reading code-text directly from file is also something I haven't thought before, so nice work!\r\n\r\nMost of them have been implemented by you. But not as same as I would expect.\r\nThe main difference is that I thought `Window` is an independent `Mobject` which is not related to `Code` (or your `CodeMobject`). I think it would be much better if you can delete `background` and let `Window` to handle it, because I think it's a more understandable way. (Text should only handle text's things)\r\n\r\nYou have done an excellent work. And I hope my advice can improve this a little.\r\n\r\nIf you like, you can change the name `CodeMobject` into `Code`.\r\n\r\nNote: I'm not a native English speaker, so if you are not sure what I'm saying, please tell me.\r\n\r\nHope to discuss with you : )",
      "also, one PR should only do one thing. So if you doesn't mind, I would make a new PR which solve the text spacing problem.",
      "I'm also not a native English speaker.\r\n",
      "> also, one PR should only do one thing. So if you doesn't mind, I would make a new PR which solve the text spacing problem.\r\n\r\nyes sure.",
      "> also, one PR should only do one thing. So if you doesn't mind, I would make a new PR which solve the text spacing problem.\r\n\r\nchange two files \"svg_mobjet.py\" and \"text_mobject.py\"\r\n",
      "> also, one PR should only do one thing. So if you doesn't mind, I would make a new PR which solve the text spacing problem.\r\n\r\ni think its better if a single PR is solving two problems.\r\nas you can see the 2nd one is very small problem.\r\nFor this particular PR 1st one is depends upon 2nd one.\r\nwithout correction in Text_mobject.py  code_mobject.py won't work correctly.",
      "as you said \"delete `background`\"  \r\nCode colors are visible only because of background \r\nif we remove background then according to code's style it colors text according to background for example if background is white then it color text with dark colors so text is visible.",
      "> i think its better if a single PR is solving two problems.\r\n> as you can see the 2nd one is very small problem.\r\n> For this particular PR 1st one is depends upon 2nd one.\r\n> without correction in Text_mobject.py code_mobject.py won't work correctly.\r\n\r\nYeah, that's true. I understand.\r\nBut Your PR probably need some testing and change, until that your PR can't be merged.\r\nThis would take some time. And that's why I want to make another PR to solve the space character problem, which probably could be merged today.",
      "You can create another one if your PR is merged then this PR will automatically updated and don't show up that text_mobject.py or svg_mobject.py changes in files changes."
    ],
    "num_comments": 30,
    "repository": "3b1b/manim",
    "diff_length": 39389
  },
  {
    "index": 73,
    "pr_title": "Fixed Some bugs of code_mobject.py and Text_mobject.py",
    "pr_body": "Fixed https://github.com/3b1b/manim/issues/1067\r\nNOTE : SurroundingRectangle() only contains visible text.\r\n```Python\r\nclass te(Scene):\r\n    def construct(self):\r\n        text1 = Text(\" ab \", font=\"Consolas\", size=2)\r\n        rect1 = SurroundingRectangle(text1)\r\n        text1.chars[1].set_color(GREEN)\r\n        self.add(text1,rect1)\r\n```\r\nOutput\r\n![te](https://user-images.githubusercontent.com/30471072/81986815-27f5de80-9656-11ea-8eef-9e6a927e28c0.png)\r\n\r\n```python\r\nclass bug1(Scene):\r\n    def co",
    "pr_number": 1071,
    "comments": [
      "Good job!\r\nBut can you fix the second bug mentioned in #1067, by making `Code()` distinguish between space and tabs for identation.\r\n\r\nAnd I think it's better to put front space characters in the first display character's position, which makes them in the first line. This can make Transform more natural.",
      "> But can you fix the second bug mentioned in #1067, by making `Code()` distinguish between space and tabs for identation.\r\n> And I think it's better to put front space characters in the first display character's position, which makes them in the first line. This can make Transform more natural.\r\n\r\n\r\ni don't get you.\r\n\r\ni just make cairo to handle spaces or tabs (replaced by `tab_width` number of spaces before cairo)\r\nand put empty Dot() as spaces at the center of previous character in text so characters indexes works correctly and transform() works correctly because Dot() are placed under some other character.\r\n\r\n",
      "Sorry for your failure to understand me.\r\nThe indexes work well. But there is still a little problem with Transform()\r\nnow the structure of Text() is like this:\r\n![image](https://user-images.githubusercontent.com/44120331/81999674-686e5000-9688-11ea-9985-d8590b833efa.png)\r\nall of the front spaces(`Dot()`s) are in the place of the last character(e), this cause the last character Transform to the first character(not in the same line) when TransformText.\r\nSo I think it will be better if you can put the front spaces(`Dot()`s which are not displayed) in the place of the first character('a' which in the same line as front spaces), just like:\r\n![image](https://user-images.githubusercontent.com/44120331/81999636-4e347200-9688-11ea-8e00-26424f66107c.png)\r\nI try it manually:\r\n**before**:\r\n```python\r\ntext = Text(\"  ab\\ncd\\nef\", font=\"Consolas\", size=2)\r\ntext2 = Text(\"ab\\n  cd\\nef\", font=\"Consolas\", size=2)\r\nself.add(text)\r\nself.wait()\r\nself.play(Transform(text, text2))\r\nself.wait()\r\n```\r\n![Test105](https://user-images.githubusercontent.com/44120331/81999872-1e399e80-9689-11ea-8b59-030c9a5d4385.gif)\r\n(See that? 'ab' is growing from 'f' when transforming)\r\n**after**:\r\n```python\r\ntext = Text(\"  ab\\ncd\\nef\", font=\"Consolas\", size=2)\r\ntext2 = Text(\"ab\\n  cd\\nef\", font=\"Consolas\", size=2)\r\n\r\ntext[:2].move_to(text[2])\r\n\r\nself.add(text)\r\nself.wait()\r\nself.play(Transform(text, text2))\r\nself.wait()\r\n```\r\n![Test105](https://user-images.githubusercontent.com/44120331/81999908-3e695d80-9689-11ea-9a47-6f5ec1e35625.gif)\r\n",
      "Now i get it \r\nactually i did that i copied line and forgot to remove -1 or may be i undo for something or mistakenly did it more then one.\r\n```python\r\n    def apply_space_chars(self):\r\n        for char_index in range(self.text.__len__()):\r\n            if self.text[char_index] == \" \" or self.text[char_index] == \"\\t\" or self.text[char_index] == \"\\n\":\r\n                space = Dot(redius=0, fill_opacity=0, stroke_opacity=0)\r\n                if char_index == 0:\r\n                    #Here is the mistake i forgot to remove -1 \r\n                    space.move_to(self.submobjects[char_index - 1].get_center())\r\n                else:\r\n                    space.move_to(self.submobjects[char_index - 1].get_center())\r\n                self.submobjects.insert(char_index, space)\r\n```",
      "Good Job!\r\nWhat about Bug 2. You can check the input code file first for identation, and replace `tab_width` spaces with a 'tab' before all. ",
      "if i remove this lines \r\n```python\r\n        SVGMobject.__init__(self, file_name, **config)\r\n        #self.text = text\r\n        #self.apply_space_chars()\r\n```\r\nIt shows more smooth Transformation\r\n![ezgif-6-1faf6ae91b48](https://user-images.githubusercontent.com/30471072/82001163-2210f500-9678-11ea-918b-7a59cc9dcfd8.gif)\r\n\r\nBut this will result into failure of indexes i.e spaces are not counted ",
      "its better if we just accept that space characters are not counted and make Text() that way.\r\nwhat do you think?",
      "Yes, Tranform's problems are all above the spaces.\r\nIf you can only receive spaces, but do not allow spaces to participate in Transform, it is better.\r\nHowever, it is still required to calculate spaces on the index, which is a feature of Text.\r\nFor example: `text=Text(\"ab  cd\")`\r\nif we don't display spaces(don't let spaces participate in Transform), but still let `text[4]='c'`, This is the best. But it seems difficult to achieve.",
      "well i have an idea but for now i don't know to achieve that\r\nthe idea is to introduce a `None` submobject that don't participate in any of submobject's things like transformation.",
      "can you explain me \r\nlet `text=Text(\"ab cd\")`\r\nnow my question is why `text` is acting as an array like  `text[4]='c'` and why `text` is equivalate to `text.submobject` ",
      "oops, I typed two spaces between b and c, but maybe GitHub shows only one space.\r\n\r\n`Text` is a subclass of `SVGMobject`, so the submobjects of Text is each path(character) in the svg which cairo made.\r\nI said `text[4]='c'` is just for convenience. My meaning is that `text[4]` points to the object with the character 'c' in text.",
      "@NavpreetDevpuri I solved Bug2.\r\n```python\r\ndef replace_identation(self):\r\n    with open(self.file_path, 'r') as fpr:\r\n        content = fpr.read()\r\n    content = re.sub(' ' * self.tab_width, '\\t', content)\r\n    with open(self.file_path, 'w') as fpw:\r\n        fpw.write(content)\r\n```\r\nadd this method to Code(), and use it after `ensure_valid_fild()`\r\n```python\r\nself.ensure_valid_file()\r\nself.replace_identation()\r\nself.style = self.style.lower()\r\n```\r\nYou can commit it to your pr. and it will be perfect.",
      "> @NavpreetDevpuri I solved Bug2.\r\n>     content = re.sub(' ' * self.tab_width, '\\t', content)\r\n\r\nthis will replace all spaces from file for example `printf(\"    ab\")` will convert to `printf(\"\\tab\"`\r\nyou may confused about `tab_width` and `indentation_char` \r\n`tab_width` defines number of spaces in indentation \r\nthere is another parameter `indentation_char` which defines how many spaces is equal to one indentation for example some may have only two spaces defines one indentation as for your code its four spaces equal to one indentation \r\n\r\nwe have to use `indentation_char` because we don't know how many spaces user defines equal to indentation ",
      "m working on it \r\n```python \r\nclass te1(Scene):\r\n    def construct(self):\r\n        text = Text(\"  ab\\ncd\\nef\", font=\"Consolas\", size=2)\r\n        text2 = Text(\"ab\\n  cd\\nef\", font=\"Consolas\", size=2)\r\n        self.add(text)\r\n        text.chars[2].set_color(YELLOW)\r\n        self.wait()\r\n        text.chars[0:4].set_color(RED)\r\n        text2.chars[0:2].set_color(GREEN)\r\n        text.set_color_by_t2c(t2c={\"cd\": GREEN})\r\n        self.wait()\r\n        # Wrong Transform(text.chars[0:4], text2.chars[0:2])\r\n        self.play(Transform(text.get_sub_text(0, 4), text2.get_sub_text(0, 2)))\r\n        self.wait()\r\n```\r\n![ezgif-6-7961e5648f9b](https://user-images.githubusercontent.com/30471072/82007907-095d0b00-9689-11ea-94ca-c5ca15d2d612.gif)\r\n\r\n\r\nTransformations are smoother and we can access chars by `text.chars[]` and get sub text by `text.get_sub_text()`\r\n\r\n\r\nnow m working on Paragraph() and Code()",
      "> we have to use `indentation_char` because we don't know how many spaces user defines equal to indentation\r\n\r\nOh, Sorry. I didn't notice the keyword `indentation_char` before. This is not a bug, so sorry.",
      "> m working on it\r\n> \r\n> Transformations are smoother and we can access chars by `text.chars[]` and get sub text by `text.get_sub_text()`\r\n> \r\n> now m working on Paragraph() and Code()\r\n\r\nBut don't you think this will make Transform more complicated.\r\nI think it is good enough now.\r\n",
      "> But don't you think this will make Transform more complicated.\r\n\r\nyes, but then we just have choice that \r\n* use simple `text[]` to access characters without counting spaces(invisible chars) \r\n* use `text.chars[]` and `text.get_sub_text()` counting spaces.\r\n\r\n",
      "```python\r\n# WRONG\r\n        #self.play(Transform(text.chars[0:4], text2.chars[0:2]))\r\n        self.play(Transform(remove_spaces_from_chars(text.chars[0:4]), remove_spaces_from_chars(text2.chars[0:2])))\r\n```\r\n\r\nNow look better `remove_spaces_from_chars()` for removing spaces from `text.chars[]`",
      "I still think it is too complicated.",
      "i included \r\n## For Text()\r\n```python\r\n'''\r\nText.chars is VGroup() of each characters including invisible characters \r\ni.e including spaces(\" \"), tabs(\"\\t\") and newlines(\"\\n\") (visible characters are Dot()s with zero radius)\r\nthat mean you can use it like \r\n    Text.chars[0:5] to access first five characters \r\nOr you can use simply Text[0:5] But this way it counts only visible characters i.e not including spaces(\" \"), tabs(\"\\t\") and newlines(\"\\n\")\r\nthat means if Text(\" a b\") then Text[3] = 'b'\r\n\r\nText.chars[0:5] will create problems when using Transform() because of invisible characters \r\nso, before using Transform() remove invisible characters by using remove_invisible_chars()\r\nfor example self.play(Transform(remove_invisible_chars(text.chars[0:4]), remove_invisible_chars(text2.chars[0:2])))\r\n'''\r\n```\r\n## For Paragraph()\r\n```python\r\n'''\r\nParagraph.chars is VGroup() of each lines and each line is VGroup() of that line's characters including invisible characters \r\ni.e including spaces(\" \"), tabs(\"\\t\") and newlines(\"\\n\") (visible characters are Dot()s with zero radius)\r\nthat mean you can use it like \r\n    paragraph.chars[0:5] to access first five lines\r\n    paragraph.chars[0][0:5] to access first line's first five characters\r\nOr you can use simply paragraph[0:5] to access first five lines and paragraph[0][0:5] to access first line's first five characters\r\nBut this way it counts only visible characters i.e not including spaces(\" \"), tabs(\"\\t\") and newlines(\"\\n\")\r\nthat means if paragraph(\" a b\", \" b\") then Paragraph[1] = 'b'\r\n\r\nparagraph.chars[][] will create problems when using Transform() because of invisible characters \r\nso, before using Transform() remove invisible characters by using remove_invisible_chars()\r\nfor example self.play(Transform(remove_invisible_chars(paragraph.chars[0:2]), remove_invisible_chars(paragraph.chars[3][0:3])))\r\n\r\nparagraph(\" a b\", \" bcd\\nefg\") is same as paragraph(\" a b\", \" bcd\", \"efg\")\r\nthat means paragraph[2] is \"efg\"\r\n'''\r\n```\r\n## For Code()\r\n```python\r\n'''\r\nCode is VGroup() with three things\r\n    Code[0] is Code.background_mobject\r\n        which can be a \r\n            Rectangle() if background == \"rectangle\" \r\n            VGroup() of Rectangle() and Dot() for three buttons if background == \"window\" \r\n    Code[1] is Code.line_numbers Which is a Paragraph() object, this mean you can use \r\n                Code.line_numbers.chars[0] or Code[1].chars[0] to access first line number \r\n    Code[2] is Code.code\r\n        Which is a Paragraph() with color highlighted, this mean you can use \r\n            Code.code.chars[1] or Code[2].chars[1] \r\n                line number 1\r\n            Code.code.chars[1][0] or Code[2].chars[1][0]\r\n                first character of line number 1\r\n            Code.code.chars[1][0:5] or Code[2].chars[1][0:5]\r\n                first five characters of line number 1\r\n\r\nOr you can use simply Code.code[0:5] to access first five lines and Code.code[0][0:5] to access first line's first five characters\r\nBut this way it counts only visible characters i.e not including spaces(\" \"), tabs(\"\\t\") and newlines(\"\\n\")\r\nthat means if Code.code = \"c = a + b\" then Code.code[2]  = 'a'\r\n\r\nCode.code.chars[][] will create problems when using Transform() because of invisible characters \r\nso, before using Transform() remove invisible characters by using remove_invisible_chars()\r\nfor example self.play(Transform(remove_invisible_chars(Code.code.chars[0:2]), remove_invisible_chars(Code.code.chars[3][0:3])))\r\n'''\r\n```\r\n",
      "Now it looks natural \r\n```python\r\nclass bug1(Scene):\r\n    def construct(self):\r\n        text1 = Text(\"  ab\\ncd\", font=\"Consolas\", size=2)\r\n        text2 = Text(\"ef\\ngh\", font=\"Consolas\", size=2)\r\n        rect1 = SurroundingRectangle(text1)\r\n        rect2 = SurroundingRectangle(text2)\r\n        self.play(Transform(text1, text2), Transform(rect1, rect2))\r\n        self.wait()\r\n```\r\nOutput\r\n![ezgif-6-842083fdea8e](https://user-images.githubusercontent.com/30471072/82013817-db7fc280-9698-11ea-823e-aaa4c4999896.gif)\r\n",
      "> can you explain me\r\n> let `text=Text(\"ab cd\")`\r\n> now my question is why `text` is acting as an array like `text[4]='c'` and why `text` is equivalate to `text.submobject`\r\n\r\n\r\nDue to method `def __getitem__(self, value):` in `mobject.py`\r\nThis is called making object subscriptable.\r\nfor example \r\n```python\r\nclass a:\r\n    def __init__(self):\r\n        self.b = [0, 1, 2, 3]\r\n    def __getitem__(self, value):\r\n        return self.b.__getitem__(value) \r\n        # OR\r\n        # self.b[value] \r\nc = a()\r\nprint(c[2])\r\n```\r\nOutput will be `2`\r\n      ",
      "@eulertour \r\nNow, its ready for merge from my side. üòå ",
      "@eulertour, @3b1b , @bhbr  please merge this as soon as possible because after that i want to work on new ideas like \r\n* `svg-mobject.py` make it support `styles` so svg file will show all colors correctly and Make it render `Text` tags also. Add more tag's attributes supports like `stroke`, `stroke-width`, `fill-opacity`, `fill` ...etc for circles tags, paths tags...etc\r\n* Add methods in `svg_mobject.py` to visually show indexes of submobjects.\r\n* May be use inkscape instead of cairo to render `Text()` and `paragraph()`.\r\n* `TextWithBackground()`\r\n* add `Text.lines[]`, `Text.words[]`, and improve `t2c()`, `t2g()` and `t2f`..etc to support which indexes of word acccurance should effected.\r\n* `html()` converts `html` to `svg`\r\n* `MobjectWithBackgroud(background, foreground)`  makes `VGroup()` of `background` and `foreground` \r\n* `backgrounds.py` having backgrounds like `window` ...etc\r\n* GUI like other video editors.\r\n* ..etc\r\n\r\nm new to github. Now, i got an idea that make master branch same as original and create new branches for new features in my fork.",
      "reopened at https://github.com/ManimCommunity/manim/pull/198"
    ],
    "num_comments": 25,
    "repository": "3b1b/manim",
    "diff_length": 54272
  },
  {
    "index": 74,
    "pr_title": "Fix space characters problem of Text",
    "pr_body": "Related issue #1017\r\n\r\nCode to reproduce the problem\r\n1. character `'\\n'`\r\n```py\r\nfrom manimlib.imports import *\r\n\r\nclass Test(Scene):\r\n    def construct(self):\r\n        t1 = Text('a\\nb').move_to(UP)\r\n        t2 = Text('123').move_to(DOWN)\r\n        self.play(Transform(t1, t2))\r\n        self.wait()\r\n```\r\n![enter](https://user-images.githubusercontent.com/47266984/81162376-ac45c300-8fbf-11ea-97bf-96c3a18eab17.gif)\r\n\r\n2. character `'\\t'`\r\n```py\r\nfrom manimlib.imports import *\r\n\r\nclass Test(Scene):\r",
    "pr_number": 1035,
    "comments": [
      "`\\t` is going to fail t2c() ..etc \r\n",
      "Check this \r\nSolves tab and spaces problem but now newlines creating problem \r\nI think we should try the same way i did in code_mobject for handling newlines\r\n\r\n\r\n```python\r\n    def __init__(self, text, **config):\r\n        self.full2short(config)\r\n        digest_config(self, config)\r\n        text_without_tabs = text\r\n        if text.find('\\t') != -1:\r\n            text_without_tabs = text.replace('\\t', ' ' * self.tab_width)\r\n        self.text = text_without_tabs\r\n        self.lsh = self.size if self.lsh == -1 else self.lsh\r\n        file_name = self.text2svg()\r\n        self.remove_last_M(file_name)\r\n        SVGMobject.__init__(self, file_name, **config)\r\n        # self.text = text_without_tabs\r\n\r\n        nppc = self.n_points_per_cubic_curve\r\n        for each in self:\r\n            if len(each.points) == 0:\r\n                continue\r\n            points = each.points\r\n            last = points[0]\r\n            each.clear_points()\r\n            for index, point in enumerate(points):\r\n                each.append_points([point])\r\n                if index != len(points) - 1 and (index + 1) % nppc == 0 and any(point != points[index + 1]):\r\n                    each.add_line_to(last)\r\n                    last = points[index + 1]\r\n            each.add_line_to(last)\r\n\r\n        self.text = text\r\n        # anti-aliasing\r\n        self.scale(TEXT_MOB_SCALE_FACTOR)\r\n        if self.text.find(\"\\t\") != -1 or self.text.find(\"\\n\") != -1 or self.text.find(\" \") != -1:\r\n            self.apply_space_chars()\r\n        if self.t2c:\r\n            self.set_color_by_t2c()\r\n        if self.gradient:\r\n            self.set_color_by_gradient(*self.gradient)\r\n        if self.t2g:\r\n            self.set_color_by_t2g()\r\n\r\n    def apply_space_chars(self):\r\n        indexes = self.find_indexes(' ') + self.find_indexes('\\n') + self.find_indexes(\"\\t\")\r\n        indexes = sorted(indexes, key=lambda i: i[0])\r\n        for i in range(self.text.__len__()):\r\n            if self.text[i] == \"\\t\" or self.text[i] == \"\\n\" or self.text[i] == \" \":\r\n                continue\r\n            else:\r\n                break\r\n        first_visible_char_index = i\r\n\r\n        for i in range(self.text.__len__() - 1, -1, -1):\r\n            if self.text[i] == \"\\t\" or self.text[i] == \"\\n\" or self.text[i] == \" \":\r\n                continue\r\n            else:\r\n                break\r\n        last_visible_char_index = i\r\n        space_width = Text(\"_\", size=self.size, font=self.font).get_width()\r\n        for i in range(first_visible_char_index - 1, -1, -1):\r\n            if self.text[i] == \" \":\r\n                space = Rectangle(width=space_width, height=space_width / 2, fill_opacity=0, stroke_opacity=0,\r\n                                  stroke_width=0)\r\n            elif self.text[i] == \"\\n\":\r\n                space = Rectangle(width=0, height=space_width / 2, fill_opacity=0, stroke_opacity=0,\r\n                                  stroke_width=0)\r\n            elif self.text[i] == \"\\t\":\r\n                space = Rectangle(width=space_width*self.tab_width, height=space_width / 2, fill_opacity=0, stroke_opacity=0,\r\n                                  stroke_width=0)\r\n            text_width = self.get_width()\r\n            space.move_to(np.array([-text_width / 2, 0, 0]))\r\n            self.next_to(space, direction=RIGHT, buff=0)\r\n            self.submobjects.insert(0, space)\r\n\r\n        for i in range(indexes.__len__()):\r\n            start = indexes[i][0]\r\n            if self.text[start] == \" \":\r\n                space = Rectangle(width=space_width, height=space_width / 2, fill_opacity=0, stroke_opacity=0,\r\n                                  stroke_width=0)\r\n            elif self.text[start] == \"\\n\":\r\n                space = Rectangle(width=0, height=space_width / 2, fill_opacity=0, stroke_opacity=0,\r\n                                  stroke_width=0)\r\n            elif self.text[start] == \"\\t\":\r\n                space = Rectangle(width=space_width * self.tab_width, height=space_width / 2, fill_opacity=0,\r\n                                  stroke_opacity=0,\r\n                                  stroke_width=0)\r\n            if first_visible_char_index <= start <= last_visible_char_index:\r\n                space.next_to(self.submobjects[start - 1], direction=RIGHT, buff=0)\r\n                self.submobjects.insert(start, space)\r\n            elif start > last_visible_char_index:\r\n                space.next_to(self.submobjects[start - 1], direction=RIGHT, buff=0)\r\n                self.submobjects.insert(start, space)\r\n        self.move_to(np.array([0,0,0]))\r\n\r\n```\r\n",
      "> `\\t` is going to fail t2c() ..etc\r\n\r\nI haven't this problem, could you show me your code?\r\n\r\n```py\r\nfrom manimlib.imports import *\r\n\r\nSCRIPT = '''\r\nfrom manimlib.imports import *\r\n\r\nclass Demo(Scene):\r\n    def construct(self):\r\n\\t\\tt = Text('Hello, world!')\r\n        self.play(Write(t))\r\n'''\r\n\r\nT2C = {'from': '#c586c0', '[23:29]': '#c586c0', 'class': '#468ed0',\r\n       'Demo': '#4ec98f', 'Scene': '#4ec98f', 'def': '#468ed0',\r\n       'construct': '#dcc774', '[70:74]': '#9cdcfe', \r\n       \"'Hello, world!'\": '#ce9178', '[119:123]': '#468ed0'}\r\n\r\nclass Demo(Scene):\r\n    def construct(self):\r\n        t = Text(SCRIPT, t2c=T2C, font='Microsoft YaHei Mono')\r\n        self.add(t)\r\n```\r\n![Demo](https://user-images.githubusercontent.com/47266984/81239284-f8801a00-9036-11ea-8fcc-14b1df6c5fc8.png)\r\n",
      "> I think we should try the same way i did in code_mobject for handling newlines\r\n\r\nDon't you think the code you show is too complex?",
      "> `\\t` is going to fail t2c() ..etc\r\n\r\nxy-23's code doesn't have that problem, because 4 space characters have replaced '\\t' in self.text before `find_indexes()`.",
      "i have a better solution for spaces, tabs and newlines\r\nyou can check by making a SurroundingRectangle() to the text with having spaces or tabs at front of text and at end of text\r\nTry following code\r\n```python\r\nclass Test4(Scene):\r\n    def construct(self):\r\n        t = Text(\"\\t\\ta b c d   \")\r\n        r = SurroundingRectangle(t)\r\n        self.add(t,r)\r\n        self.wait()\r\n```\r\n\r\nAnd this is what my program shows\r\n![Test4](https://user-images.githubusercontent.com/30471072/81244355-d3d47400-902f-11ea-8366-3e64d67f0395.png)\r\n",
      "text_mobject is working fine but M working on code_mobject\r\n```python\r\nclass Test3(Scene):\r\n    def construct(self):\r\n        t = Text('this is a awesome', 'paragraph', 'With \\nNewlines', '\\tWith Tabs', '  With Spaces', 'With Alignments',\r\n                 'center', \"left\", \"right\", line_spacing=0.1, alignment=\"left\", t2c={\"Tabs\": RED})\r\n        t.set_alignment(\"center\", 7)\r\n        t.set_alignment(\"left\", 8)\r\n        t.set_alignment(\"right\", 9)\r\n\r\n        t[0][0].set_color(GREEN)\r\n        t[1][0:4].set_color(YELLOW)\r\n        self.add(t)\r\n        self.wait()\r\n```\r\nOutput \r\n![Test3](https://user-images.githubusercontent.com/30471072/81244438-18f8a600-9030-11ea-91f4-3ffaa78f6d4b.png)\r\n",
      "> text_mobject is working fine but M working on code_mobject\r\n\r\n@NavpreetDevpuri What does M mean? Mine?",
      "> > text_mobject is working fine but M working on code_mobject\r\n> \r\n> What does M mean? Mine?\r\n\r\nshort form of 'i  am'",
      "check updates https://github.com/3b1b/manim/pull/1018",
      "@NavpreetDevpuri\r\n> ```py\r\n> class Test4(Scene):\r\n>     def construct(self):\r\n>         t = Text(\"\\t\\ta b c d   \")\r\n>         r = SurroundingRectangle(t)\r\n>         self.add(t,r)\r\n>         self.wait()\r\n> ```\r\nHandling this situation is not really useful and it costs too much",
      "> Handling this situation is not really useful and it costs too much\r\n\r\nThis is a main part of text that <b>it should be display exactly same as it is written by user</b> ",
      "@NavpreetDevpuri But would you need it? I mean if  you can't display something like `'    ab    '`, will that effect your Code()?",
      "> But would you need it? I mean if you can't display something like `' ab '`, will that effect your Code()?\r\n\r\nYes, sometimes text may contains spaces at beginning of text for example\r\nwe need those characters( \"\\t\" \" \") to be displayed somehow so that anyone can easily access those characters also \r\nfor example someone may want to highlight '\\t' character by SurroundingRectangle() \r\nor someone may want to display something just left to the '\\t'.\r\nor someone may want to make a animation hovering something over those \"\\t' characters",
      "so you mean you want to keep character `'\\t'` as a single character, rather than many(4) spaces `' '` ?",
      "> so you mean you want to keep character `'\\t'` as a single character, rather than many(4) spaces `' '` ?\r\n\r\nyes and also want to give those characters a physical height and width.",
      "@NavpreetDevpuri\r\nThe reason not giving those space characters a physical height and width is that\r\nthey don't have a static size at all. Their size are dynamic.\r\n![image](https://user-images.githubusercontent.com/47266984/81257265-63484a00-9065-11ea-8926-fa8a3359b4a3.png)\r\nSo, how could you even decide the size of those characters which are in the front or back of letters."
    ],
    "num_comments": 17,
    "repository": "3b1b/manim",
    "diff_length": 3212
  },
  {
    "index": 75,
    "pr_title": "Docker Support",
    "pr_body": "It seems that getting the dependencies installed just right for this project is quite tricky, so I decided to write a Dockerfile to eliminate/standardize that headache.\n\nIt ended up being fairly straightforward with the final usage going from:\n`python extract_scenes.py example_scenes.py WarpSquare`\nto\n`docker run --rm -v \"$PWD\"/files:/app/files manim example_scenes.py WarpSquare`\nwhich, while longer, doesn't add any more work for the user and could be hidden behind an alias or shell script if de",
    "pr_number": 7,
    "comments": [
      "I'm trying the Docker method but I got this error message when trying to execute the last step:\n`flag provided but not defined: -vpwd/files:/app/files`\nThanks\n",
      "Hmm. Not sure how that happened. Try copy and pasting it. You need to have a space between `-v` and `\"$PWD\"`\n",
      "Oh, I see. I was trying to use the readme command. Now it's working :)\n",
      "Ah, yea, I realized that command would fail if you had spaces in the path, I should update that if this PR gets merged. \n",
      "This is great, however in addition to a Linux `-v` switch, you might want to document a similar construct for Windows.\n",
      "@nesteruk true, I don't have any experience with docker on windows, it looks like its just a matter of changing the env var from `\"$PWD\"` to `\"%CD%\"`, is that accurate?\n",
      "Well I couldn‚Äôt get it to work with the quotes placed where you had them. I run it with\n\ndocker run -v \"//r/:/app/files/movies\" ‚Ä¶\n\n%CD% is indeed the current directory. \n\nFrom: Scott Opell [mailto:notifications@github.com] \nSent: 11 September 2016 20:40\nTo: 3b1b/manim manim@noreply.github.com\nCc: Dmitri Nesteruk dmitrinesteruk@gmail.com; Mention mention@noreply.github.com\nSubject: Re: [3b1b/manim] Docker Support (#7)\n\n@nesteruk https://github.com/nesteruk  true, I don't have any experience with docker on windows, it looks like its just a matter of changing the env var from \"$PWD\" to \"%CD%\", is that accurate?\n\n‚Äî\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/3b1b/manim/pull/7#issuecomment-246192977 , or mute the thread https://github.com/notifications/unsubscribe-auth/AAcoNrG2i-b_3tCJ4RzHL3dBO-d7qbcTks5qpD0NgaJpZM4Jn4Pr .  https://github.com/notifications/beacon/AAcoNjuy_Xk0PyuH1yqFI8P_xneKVc8Wks5qpD0NgaJpZM4Jn4Pr.gif \n",
      "Oh, and you completely forgot the LaTeX part in the docker file. That‚Äôs actually something I‚Äôm struggling with right now ‚Äì I install blang/latex, but the ordinary `latex` command doesn‚Äôt work for me. Perhaps you could integrate LaTeX in the docker file in the correct way.\n\nFrom: Scott Opell [mailto:notifications@github.com] \nSent: 11 September 2016 20:40\nTo: 3b1b/manim manim@noreply.github.com\nCc: Dmitri Nesteruk dmitrinesteruk@gmail.com; Mention mention@noreply.github.com\nSubject: Re: [3b1b/manim] Docker Support (#7)\n\n@nesteruk https://github.com/nesteruk  true, I don't have any experience with docker on windows, it looks like its just a matter of changing the env var from \"$PWD\" to \"%CD%\", is that accurate?\n\n‚Äî\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/3b1b/manim/pull/7#issuecomment-246192977 , or mute the thread https://github.com/notifications/unsubscribe-auth/AAcoNrG2i-b_3tCJ4RzHL3dBO-d7qbcTks5qpD0NgaJpZM4Jn4Pr .  https://github.com/notifications/beacon/AAcoNjuy_Xk0PyuH1yqFI8P_xneKVc8Wks5qpD0NgaJpZM4Jn4Pr.gif \n",
      "Is this still working?\nThis is what I am getting:\n\n`$ sudo  docker run --rm -v \"$PWD\"/files:/app/files manim example_scenes.py WarpSquare`\n`Unable to find image 'manim:latest' locally`\n`Pulling repository docker.io/library/manim`\n`docker: Error: image library/manim not found.`\n`See 'docker run --help'.`\n\nThanks,\n",
      "@nesteruk What is a good file to generate to test latex support? I can add it in, but the full package is huge so I'd rather just add in exactly what's needed for this project.\n\n@tonypower I haven't submitted it to docker hub so you'll need to build it manually. So clone my fork, then run the docker build command mentioned in my readme. Then that command should work as expected\n",
      "Hi scottpell,\n\nThank for your reply.\nI cloned your fork, but they only readme file I see is: README.md\nwhich doesn't mention anything about the docker build command.\nSorry, but I am a newbie with docker.\nIs there any other readme file?\n\nThanks, \n",
      "Here's a link. It should be in there so make sure you have the right repo cloned \nhttps://github.com/scottopell/manim/blob/c2c592679e76d5e5663bed1ce650702648b192f1/README.md#docker-method\n",
      "Hi scottpell,\nThanks again. This is what I get:\n\n$ pip install requirements.txt \nCollecting requirements.txt\n  Could not find a version that satisfies the requirement requirements.txt (from versions: )\nNo matching distribution found for requirements.txt\naanjos@bot ~/Downloads/manim $ cat requirements.txt \ncolour==0.1.2\nnumpy==1.11.0\nPillow==1.7.8\nprogressbar==2.3\nscipy==0.17.1\ntqdm==4.7.1\n\nI am using Mint 18.\nAm I doing anything wrong?\nThanks,\n",
      "Why are you running that command? Docker removes the need to install using pip. Only follow the directions i linked you to\n",
      "LOL\nThanks once again.\nWhat am I doing stupid right now?\n\n$ sudo docker build -t manim .\nunable to prepare context: unable to evaluate symlinks in Dockerfile path: lstat /home/aanjos/Downloads/Dockerfile: no such file or directory\n\nThat happens both if I am inside manin or outside of it.\nPlease be patient ;)\nThanks,\n\nPS: `man help` says the build option is to build from a Dockerfile. I don't see any.\n",
      "To install LaTeX, just add this line:\n\n`RUN apt-get install texlive-full -y`\n\nThat's all you need to do. Warning: LaTeX installation is massive, around 2Gig.\n",
      "@nesteruk yea, I realize its big, which is why I said I'd prefer to only include whatever is necessary for this project. Which scene/command uses tex?\n\nand @tonypower, your docker install doesn't seem to be setup correctly. I would post on stackoverflow or something similar and try to fix that issue, its kind of outside of the scope of this pull request/issue.\n",
      "Well, everything in manim uses TeX. You don't _have to_ use it, but I think\nthat's the whole point, if you use it for math.\n\nI sell online courses on math so for me it's essential.\n\nOn 17 September 2016 at 19:47, Scott Opell notifications@github.com wrote:\n\n> @nesteruk https://github.com/nesteruk yea, I realize its big, which is\n> why I said I'd prefer to only include whatever is necessary for this\n> project. Which scene/command uses tex?\n> \n> and @tonypower https://github.com/tonypower, your docker install\n> doesn't seem to be setup correctly. I would post on stackoverflow or\n> something similar and try to fix that issue, its kind of outside of the\n> scope of this pull request/issue.\n> \n> ‚Äî\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/3b1b/manim/pull/7#issuecomment-247787706, or mute\n> the thread\n> https://github.com/notifications/unsubscribe-auth/AAcoNoZrgxhF0CbavZ5WfsrR2UTHwVeOks5qrBm8gaJpZM4Jn4Pr\n> .\n\n## \n\nDmitri Nesteruk\ndmitrinesteruk@gmail.com\nskype: dmitri.nesteruk\n",
      "How to deal with this problem? It seems the directory is okay but exception still shows:\r\n\r\nException:\r\n        Redefine MEDIA_DIR in constants.py to point to\r\n        a valid directory where movies and images will\r\n        be written\r\n\r\n@scottopell "
    ],
    "num_comments": 19,
    "repository": "3b1b/manim",
    "diff_length": 1662
  },
  {
    "index": 76,
    "pr_title": "Refactor the structure of the package and add configuration guidelines",
    "pr_body": "<!-- Thanks for contributing to manim!\r\n    Please ensure that your pull request works with the latest version of manim.\r\n-->\r\n## Motivation\r\n<!-- Outline your motivation: In what way do your changes improve the library? -->\r\nThe current `manimlib` is relatively inconsistent with the package specification, so some slight refactoring has been carried out.\r\nAnd added an automation guide for setting `custom_default.yml`\r\n## Proposed changes\r\n<!-- What you changed in those files -->\r\n- Move `manimli",
    "pr_number": 1366,
    "comments": [
      "Most of this is certainly in the right direction, thank you.\r\n\r\n> Move manimlib/imports.py into manimlib/__init__.py. So we can use from manimlib import * to import this package.\r\n\r\nGiven that the current use of manimlib/imports.py is not the best practice, I'd be hesitant to make it something that's called by default when you import the package.\r\n\r\nAt the very least, it would be best to separate out the non-manim libraries that it imports at the bottom.  In fact, arguably most of those should be removed, and we should encourage more explicit imports of numpy, math, etc.  If for someone's personal use-case they want to bring all those in with a single highly-implicit import call, they can always do that, but I don't think it should be systematized into the structure of manim.\r\n\r\n> Add configuration guide, which will be run when there is no configuration file (custom_config.yml or manimlib/default_config.yml)\r\n\r\nI don't think the first time someone runs manim they should have to fill all this out.  It's a nicer user experience if it falls back on some defaults so they can at least jump in and start running scenes.  It might be better to print a warning that certain defaults are used, which points the user to where they can go to set their own defaults for where files are output, etc.",
      "After asking the manim community a little about their decisions, I suppose it seems fine to put all the \"from <module> import *\" commands in the \\_\\_init\\_\\_.py file, but we should remove the non-manim imports from there.",
      "> After asking the manim community a little about their decisions, I suppose it seems fine to put all the \"from import *\" commands in the __init__.py file, but we should remove the non-manim imports from there.\r\n\r\nI have deleted the non-manim imports in `__init__.py`.\r\n\r\n> I don't think the first time someone runs manim they should have to fill all this out. It's a nicer user experience if it falls back on some defaults so they can at least jump in and start running scenes. It might be better to print a warning that certain defaults are used, which points the user to where they can go to set their own defaults for where files are output, etc.\r\n\r\nI re-added the global default configuration `manimlib/default_config.yml`.\r\nNow it will only warn that the default configuration is being used when it is run for the first time, and give the path to change it.\r\nAt the same time, if one accidentally delete the default configuration in manimlib/, he will enter the configuration guide during runtime.\r\n\r\nBut there is another issue here. In Windows, if `temporary_storage` is not set and the system default temporary folder is used, `OSError` will be thrown:\r\n```\r\nOSError: C:\\Users\\...\\AppData\\Local\\Temp\\Tex\\cf5d7f9f2e57398a.svg not Found\r\n```",
      "When I run it right now with the manimgl command, there seems to be an issue in initializing the Window.  I can try to look into it, but do you have any sense of what might have affected Window?\r\n\r\nIt works fine for file writing.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/opt/anaconda3/envs/py39/bin/manimgl\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/grant/cs/manim/manimlib/__main__.py\", line 14, in main\r\n    scenes = manimlib.extract_scene.main(config)\r\n  File \"/Users/grant/cs/manim/manimlib/extract_scene.py\", line 112, in main\r\n    return [BlankScene(**scene_config)]\r\n  File \"/Users/grant/cs/manim/manimlib/scene/scene.py\", line 47, in __init__\r\n    self.window = Window(self, **self.window_config)\r\n  File \"/Users/grant/cs/manim/manimlib/window.py\", line 18, in __init__\r\n    super().__init__(**kwargs)\r\n  File \"/opt/anaconda3/envs/py39/lib/python3.9/site-packages/moderngl_window/context/pyglet/window.py\", line 51, in __init__\r\n    self._window = PygletWrapper(\r\n  File \"/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pyglet/window/__init__.py\", line 648, in __init__\r\n    self._create()\r\n  File \"/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pyglet/window/cocoa/__init__.py\", line 197, in _create\r\n    self.context.attach(self.canvas)\r\n  File \"/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pyglet/gl/cocoa.py\", line 299, in attach\r\n    self._nscontext.setView_(canvas.nsview)\r\nAttributeError: 'NoneType' object has no attribute 'setView_'\r\n```",
      "But there is no problem running manimgl on my computer. And I probably didn‚Äôt make any changes related to Window.\r\n<details>\r\n<summary>envs</summary>\r\nOS: Windows 10<br/>\r\nPython: Python 3.7.9 (anaconda env)<br/>\r\npyglet: 1.5.14\r\n</details>\r\n\r\nMaybe it's a problem with Python 3.9 ? I am trying.",
      "I used anaconda to create a clean Python 3.9 environment, and executed with the following commands, successfully running without error.\r\n```sh\r\nconda create -n py39 python=3.9\r\nconda activate py39\r\npip install cmake -i https://pypi.tuna.tsinghua.edu.cn/simple/ # for mapbox_earcut\r\npip install -e . -i https://pypi.tuna.tsinghua.edu.cn/simple/\r\nmanimgl\r\n```\r\n\r\n<details>\r\n<summary>pip freeze</summary>\r\n\r\n```\r\nbackcall==0.2.0\r\ncertifi==2020.12.5\r\ncmake==3.18.4.post1\r\ncolorama==0.4.4\r\ncolour==0.1.5\r\ncycler==0.10.0\r\ndecorator==4.4.2\r\nglcontext==2.3\r\nipython==7.20.0\r\nipython-genutils==0.2.0\r\njedi==0.18.0\r\nkiwisolver==1.3.1\r\n-e git+https://github.com/TonyCrane/manim.git@7c683c8992b5829b1de42320f51bcff2e9bce2ea#egg=manimgl\r\nmapbox-earcut==0.12.10\r\nmatplotlib==3.3.4\r\nmoderngl==5.6.3\r\nmoderngl-window==2.3.0\r\nmpmath==1.1.0\r\nmultipledispatch==0.6.0\r\nnumpy==1.20.1\r\nparso==0.8.1\r\npickleshare==0.7.5\r\nPillow==8.1.0\r\nprogressbar==2.5\r\nprompt-toolkit==3.0.14\r\npycairo==1.20.0\r\npydub==0.24.1\r\npyglet==1.5.14\r\nPygments==2.7.4\r\nPyOpenGL==3.1.5\r\npyparsing==2.4.7\r\npyreadline==2.1\r\npyrr==0.10.3\r\npython-dateutil==2.8.1\r\nPyYAML==5.4.1\r\nscipy==1.6.0\r\nscreeninfo==0.6.7\r\nsix==1.15.0\r\nsympy==1.7.1\r\ntqdm==4.56.0\r\ntraitlets==5.0.5\r\nvalidators==0.18.2\r\nwcwidth==0.2.5\r\nwincertstore==0.2\r\n```\r\n\r\n</details>",
      "Creating a similar clean environment with all the same commands, I still run into some OpenGL related issue.  (I'm on OSX 11.1)\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/darwin.py\", line 35, in GL\r\n    return ctypesloader.loadLibrary(\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/ctypesloader.py\", line 36, in loadLibrary\r\n    return _loadLibraryWindows(dllType, name, mode)\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/ctypesloader.py\", line 89, in _loadLibraryWindows\r\n    return dllType( name, mode )\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/ctypes/__init__.py\", line 382, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: ('dlopen(OpenGL, 10): image not found', 'OpenGL', None)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/anaconda3/envs/tonytest/bin/manimgl\", line 6, in <module>\r\n    from manimlib.__main__ import main\r\n  File \"/Users/grant/cs/manim/manimlib/__init__.py\", line 17, in <module>\r\n    from manimlib.camera.camera import *\r\n  File \"/Users/grant/cs/manim/manimlib/camera/camera.py\", line 3, in <module>\r\n    import OpenGL.GL as gl\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/GL/__init__.py\", line 3, in <module>\r\n    from OpenGL import error as _error\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/error.py\", line 12, in <module>\r\n    from OpenGL import platform, _configflags\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/__init__.py\", line 36, in <module>\r\n    _load()\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/__init__.py\", line 33, in _load\r\n    plugin.install(globals())\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/baseplatform.py\", line 97, in install\r\n    namespace[ name ] = getattr(self,name,None)\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/baseplatform.py\", line 15, in __get__\r\n    value = self.fget( obj )\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/darwin.py\", line 62, in GetCurrentContext\r\n    return self.CGL.CGLGetCurrentContext \r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/baseplatform.py\", line 15, in __get__\r\n    value = self.fget( obj )\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/darwin.py\", line 45, in CGL\r\n    def CGL(self): return self.GL\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/baseplatform.py\", line 15, in __get__\r\n    value = self.fget( obj )\r\n  File \"/opt/anaconda3/envs/tonytest/lib/python3.9/site-packages/OpenGL/platform/darwin.py\", line 41, in GL\r\n    raise ImportError(\"Unable to load OpenGL library\", *err.args)\r\nImportError: ('Unable to load OpenGL library', 'dlopen(OpenGL, 10): image not found', 'OpenGL', None)\r\n```\r\n\r\nSimilar pip freeze\r\n\r\n```\r\nappnope==0.1.2\r\nbackcall==0.2.0\r\ncertifi==2020.12.5\r\ncmake==3.18.4.post1\r\ncolour==0.1.5\r\ncycler==0.10.0\r\nCython==0.29.21\r\ndecorator==4.4.2\r\nglcontext==2.3\r\nipython==7.20.0\r\nipython-genutils==0.2.0\r\njedi==0.18.0\r\nkiwisolver==1.3.1\r\n-e git+git@github.com:3b1b/manim.git@cb4b67655bf9a385344e44dc0b9331c155b921b7#egg=manimgl\r\nmapbox-earcut==0.12.10\r\nmatplotlib==3.3.4\r\nmoderngl==5.6.3\r\nmoderngl-window==2.3.0\r\nmpmath==1.1.0\r\nmultipledispatch==0.6.0\r\nnumpy==1.20.1\r\nparso==0.8.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==8.1.0\r\nprogressbar==2.5\r\nprompt-toolkit==3.0.14\r\nptyprocess==0.7.0\r\npycairo==1.20.0\r\npydub==0.24.1\r\npyglet==1.5.14\r\nPygments==2.7.4\r\npyobjc-core==7.1\r\npyobjc-framework-Cocoa==7.1\r\nPyOpenGL==3.1.5\r\npyparsing==2.4.7\r\npyrr==0.10.3\r\npython-dateutil==2.8.1\r\nPyYAML==5.4.1\r\nscipy==1.6.0\r\nscreeninfo==0.6.7\r\nsix==1.15.0\r\nsympy==1.7.1\r\ntqdm==4.56.0\r\ntraitlets==5.0.5\r\nvalidators==0.18.2\r\nwcwidth==0.2.5\r\n```",
      "I merged your commits after this pr and created a new environment, and no errors appeared. This shows that there is no problem on Windows.\r\n\r\nI asked a friend of mine who also uses MacOS, and he has similar problems when using the new version of manim. He sent me the following document on how to fix it, I hope it can help you.\r\n\r\n---\r\nIn the latest macOS Big Sur, the default location of OpenGL has been changed from the library to the frameworks under the library, so in the current version PyOpenGL cannot find the original location, which will cause an error\r\n```\r\nImportError: ('Unable to load OpenGL library','dlopen(OpenGL, 10): image not found','OpenGL', None)\r\n```\r\nFor this, the long-term solution is to wait for the next Python update.\r\nThe short-term solution is to change the reading position of PyOpenGL, the steps are as follows:\r\n1. Find the PyOpenGL file `OpenGL/platform/ctypesloader.py` under Python folder, and make a complete backup before making any changes.\r\n2. Find line: `fullName = util.find_library( name )`\r\n3. Change it to: `fullName = '/System/Library/Frameworks/OpenGL.framework/OpenGL'`",
      "Ah, my apologies, I should have been able to recognize that.  It's an issue that shows up in other places too but is fixed in Python 3.9, which is why that's what I've usually been using.  In setting up the clean environment above, I guess I had forgotten this fact.\r\n\r\nStill, when I set it up in a python 3.9 environment, I get that same separate issue, which seems to be related to the Window not having a proper OpenGL context.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/opt/anaconda3/envs/py39/bin/manimgl\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/grant/cs/manim/manimlib/__main__.py\", line 14, in main\r\n    scenes = manimlib.extract_scene.main(config)\r\n  File \"/Users/grant/cs/manim/manimlib/extract_scene.py\", line 115, in main\r\n    scenes = get_scenes_to_render(all_scene_classes, scene_config, config)\r\n  File \"/Users/grant/cs/manim/manimlib/extract_scene.py\", line 91, in get_scenes_to_render\r\n    return [scene_class(**scene_config) for scene_class in result]\r\n  File \"/Users/grant/cs/manim/manimlib/extract_scene.py\", line 91, in <listcomp>\r\n    return [scene_class(**scene_config) for scene_class in result]\r\n  File \"/Users/grant/cs/manim/manimlib/scene/scene.py\", line 47, in __init__\r\n    self.window = Window(self, **self.window_config)\r\n  File \"/Users/grant/cs/manim/manimlib/window.py\", line 18, in __init__\r\n    super().__init__(**kwargs)\r\n  File \"/opt/anaconda3/envs/py39/lib/python3.9/site-packages/moderngl_window/context/pyglet/window.py\", line 51, in __init__\r\n    self._window = PygletWrapper(\r\n  File \"/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pyglet/window/__init__.py\", line 648, in __init__\r\n    self._create()\r\n  File \"/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pyglet/window/cocoa/__init__.py\", line 197, in _create\r\n    self.context.attach(self.canvas)\r\n  File \"/opt/anaconda3/envs/py39/lib/python3.9/site-packages/pyglet/gl/cocoa.py\", line 299, in attach\r\n    self._nscontext.setView_(canvas.nsview)\r\nAttributeError: 'NoneType' object has no attribute 'setView_'\r\n```\r\n\r\nI'm still very confused by why anything from this PR (which seems unrelated to the OpenGL context) would have changed this.  Mostly I remain confused by what the issue is, exactly.",
      "I suspect it has something to do with how the PygletWindow is being used, and that I probably didn't know what I was doing as I wrote that.  Let me look into that a bit more.",
      "I think this may be a bug on Big Sur. \r\nBut have you tried creating a new environment and then running the current master branch? \r\nI did not make any changes to the window.",
      "Or maybe you can try to create a new Python 3.8 environment and run it?",
      "Hey Grant. I am the ‚Äúfriend‚Äù up there, and I‚Äôm currently using the macOS on my MacBook, so I also had to face this problem, though I found a way to solve it. And here‚Äôs what I did:\r\nThe brand new macOS 11(Big Sur) no longer has the OpenGL library nor other system libraries in standard locations in the file system and instead uses a cache.\r\nAs we‚Äôre talking, there‚Äôs a pull request in Python to fix the ctypes:\r\nhttps://github.com/python/cpython/pull/21241\r\nBut for currently use, we can perform some change in the PyOpenGL file:\r\nGo to ‚Äò/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/OpenGL/platform/ctypesloader.py ‚Äô\r\nAnd in line79, you should find \r\n`fullName = util.find_library( name )`\r\nAnd change it into :\r\n`fullName = ‚Äò/System/Library/Frameworks/OpenGL.framework/OpenGL‚Äô`\r\nAfter the change, the new version of Manim works just fine.\r\nAnd if there‚Äôs any other problems you can just write‚Äôem down there, and even though I cannot solve it when troubles getting too difficult, I‚Äôll also try to help;)\r\n",
      "I think there are two separate issues.  One has to do with Big Sur and find_library, which it seems can be fixed either the way you're describing, by changing the OpenGL code, or by updating to a sufficiently new version of Python, where 3.9 seems to work for me.\r\n\r\nBut it looks like something separate is going on too, associated with the moderngl window.  I suspect it has to do with something wrong I did when it comes to initializing that window and the OpenGL context.  In the same environment where master branch runs fine on my system, something about the changes on this branch cause this window initializing issue to happen.  This happens in environments with both 3.8 and 3.9, and looks unrelated to the question of loading libraries.\r\n\r\nI don't think it's anything wrong with what @TonyCrane wrote, but I'm still hesitant to merge while knowing it will break on some systems, at least without knowing why.",
      "Okay, this is incredibly bizarre.  I could fix the issue by removing the line\r\n\r\n```\r\nfrom manimlib.mobject.interactive import *\r\n```\r\n\r\nFrom \\_\\_init\\_\\_.py.  Something about the import line\r\n\r\n```\r\nfrom pyglet.window import key as PygletWindowKeys\r\n```\r\n\r\nbeing called before the window creation seemed to affect things.",
      "> Okay, this is incredibly bizarre. I could fix the issue by removing the line\r\n> \r\n> ```\r\n> from manimlib.mobject.interactive import *\r\n> ```\r\n> \r\n> From __init__.py. Something about the import line\r\n> \r\n> ```\r\n> from pyglet.window import key as PygletWindowKeys\r\n> ```\r\n> \r\n> being called before the window creation seemed to affect things.\r\n\r\nOhh! If that's the problem then move the import statement in `TextBox` `on_key_press` method since, the PygletWindowKeys is only used there.\r\n\r\n```\r\ndef on_key_press(self, mob, event_data):\r\n        from pyglet.window import key as PygletWindowKeys\r\n        symbol = event_data[\"symbol\"]\r\n        modifiers = event_data[\"modifiers\"]\r\n        char = chr(symbol)\r\n        ...\r\n```",
      "It's also solved by calling \"from manimlib.window import *\" above that line.\r\n\r\nThis seems like it's exposing a deeper problem, though, which I'll look into.",
      "But this will cause `ControlsExample` in example_scenes.py can't run, because `Textbox`, etc. haven't been imported.",
      "Am also struggling with the OpenGL problem.  No apparent resolution in sight.   \r\n\r\nRunning Mac OS Big Sur 11.2.3 and I see that:\r\n(i) Mac OS deprecated OpenGL some time ago and the Big Sur upgrade appears to have broken several packages (including manim)\r\n(ii) [This](https://stackoverflow.com/questions/63475461/unable-to-import-opengl-gl-in-python-on-macos) StackExchange thread appears to be a great resolution for many people but the many great suggestions provided by contributors but hasn't worked for me.\r\n\r\nI gather that not only is OpenGL a deprecated library, but also the Python-native routines to find libraries are also undergoing revisions in an effort to do better at finding binaries to prevent these kinds of problems.\r\n\r\nSo... I've been >>stuck in a ditch<< for days trying to do what should be a simple install.  Sigh....\r\n\r\nHelp I think I could use:\r\n(A) How do I run a linux \"find\" command that will precisely identify the specific location of the the OpenGL library?  I have, for instance, clearly eliminated the possibility that /System/Library/Frameworks/OpenGL.framework/OpenGL is the path I need; since that file (after many attempts at installation) just does not exist on my system.   Could be that I have it....but so far all I can find is >>directories<< named OpenGL (not libraries.)\r\n\r\n(B) What command can I run that will guarantee the download, installation, and report-of-location of the OpenGL library?  It'd be great if there was some easy way to easily install a fresh OpenGL lib based on Apple's new \"Metal\" API; but I have failed to find an easy way to do this.\r\n\r\nYour help would be appreciated!  :)\r\n\r\nBTW -- me and my son just LOVE the vids and graphics from the 3b1b team!   Stay strong you fine people!\r\n",
      "> \r\n\r\nI had this problem on Python 3.8 but changing to 3.9 solved the issue. Worth a try for anyone who is on 3.8 and get `OpenGL missing` issue on Mac."
    ],
    "num_comments": 20,
    "repository": "3b1b/manim",
    "diff_length": 55161
  },
  {
    "index": 77,
    "pr_title": "Code() in file Code_mobject.py to display code with color highlighted added Paragraph() and \"exact_spaces\" parameter to Text() ",
    "pr_body": "## It solves the following problems\r\n1) display code with color highlighted\r\n2) manage to print single '{' or '}'  because of using Text() instead of TextMobject() from https://github.com/3b1b/manim/issues/941#issuecomment-621615699\r\n3) Solved Text( ) transform animation for \" \" space character from https://github.com/3b1b/manim/issues/1017\r\n4) Text() with tabs, indexes not works correctly https://github.com/3b1b/manim/issues/1060\r\n5) Text() don't shows spaces in front of the text and at the end",
    "pr_number": 1036,
    "comments": [
      "In my opinion, there is no need to turn `Text` into `SingleStringTextMobject`, that will cause some problems when users using Text from old version to new version.\r\n\r\nIt is better to create a new class `Texts` to archive the same effect of `Text` now which archives more functions. Do you undersand me?\r\n```text\r\nSingleStringTextMobject -> Text\r\nText -> Texts\r\n```",
      "> SingleStringTextMobject -> Text\r\n> Text -> Texts\r\n\r\nGreat !\r\n\r\n",
      "Well, I have implemented the multiple text parameters in `Text` just now...\r\nAnd I think it's a better way compared to your current solution.\r\nSo, I think we don't need `Texts` nor `SingleStringTextMobject`.\r\nBut I need to fix the space problem first until make another PR to update it.",
      "> Well, I have implemented the multiple text parameters in `Text` just now...\n> And I think it's a better way compared to your current solution.\n> So, I think we don't need `Texts` nor `SingleStringTextMobject`.\n> But I need to fix the space problem first until make another PR to update it.\n\nYes, the space problem is a **bug** of Text which must to be fixed, but code(or Texts) is a new **feature**.",
      "> Yes, the space problem is a **bug** of Text which must to be fixed, but code(or Texts) is a new **feature**.\r\n\r\nspaces and tabs problem is solved by just giving those characters a physical height and width by putting a appropriate invisible Rectangle so that those characters are also select able for example by using SurroundingRectangle()\r\n\r\n",
      "The reason not giving those space characters a physical height and width is that\r\nthey don't have a static size at all. Their size are dynamic.\r\n![image](https://user-images.githubusercontent.com/47266984/81257265-63484a00-9065-11ea-8926-fa8a3359b4a3.png)\r\nSo, how could you even decide the size of those characters which are in the front or back of letters.",
      "And from your reply, it seems that without displaying the space in the front or back of text, your Code() can behave correctly.",
      "I calculated the width of space according to font a\r\n\r\n> The reason not giving those space characters a physical height and width is that\r\n> they don't have a static size at all. Their size are dynamic.\r\n> ![image](https://user-images.githubusercontent.com/47266984/81257265-63484a00-9065-11ea-8926-fa8a3359b4a3.png)\r\n> So, how could you even decide the size of those characters which are in the front or back of letters.\r\n\r\nIt calculate the width of space character according to font.",
      "But calculating the width of space according to font a is not rigorous.",
      "> But calculating the width of space according to font a is not rigorous.\r\n\r\ncheck new method get_space_width() at line 233 in text_mobject.py to calculate space_width which calculates the exact width of space according to font or language type\r\n```python\r\nclass Test4(Scene):\r\n    def construct(self):\r\n        t = Text(\"a c\").scale(3.6)\r\n        r = SurroundingRectangle(t[1],stroke_width=1,buff=0)\r\n        self.add(t, r)\r\n        self.wait()\r\n```\r\noutput \r\n![Test4](https://user-images.githubusercontent.com/30471072/81265889-778a4800-9061-11ea-822b-bacdc2fb1953.png)\r\n\r\n",
      "Seems my PR is merged. But I have to say something.\r\n\r\nI think the main disagreement between us is that whether we should display those space characters in the front or back of letters. I think that I should emphasize here that I am saying the situation where there is only single line of letters, more specificallyÔºåthis picture's situation.\r\n![image](https://user-images.githubusercontent.com/47266984/81278745-aa940200-9088-11ea-88ef-8edac7ad5ed3.png)\r\nI contradict this because, like I said, the size of those characters are dynamic. And the text layout engine that currently Text uses will ignore them directly. I knows little about the layout process under the engine, so I decided to do nothing, not displaying the empty space is the current solution.\r\n\r\nAnd you think we should display those empty space. I understand. And from the user's perspective, I definitely agree that you said `it should be display exactly same as it is written by user`. But that is hard to achieve, because the engine we are using can't provide this information at all! And your solution is not a good choice because it adds potential problems to `Text()`which we are not sure.\r\n\r\nSo, I'm trying to persuade you to give up fixing the space characters problem in svg_mobject.py and text_mobject.py. Your `Code()` have already good enough. And thanks you for contributing manim.\r\n\r\nI think you probably need this. I noticed the way you are dealing with multiple-lines text, you separate them by split('\\n'), and sent them to `Text()` one by one, that's why you need to display those empty characters (the situation above), am I right? Well, there is a better way to do this, you can send the multiple-lines text directly to `Text()` and separate (or group) them via Text.submobjects, this means you can have the \"space size information\". You can implement this as following:\r\n```py\r\n    def set_group(self):\r\n        new_submobjects = []\r\n        start = 0\r\n        for text in self.texts:\r\n            submobjects = self.submobjects[start:start+len(text)]\r\n            new_submobjects.append(VGroup(*submobjects))\r\n            start += len(text)\r\n        self.submobjects = new_submobjects\r\n```\r\nYes, this would lose the ability to align manually. But it's not very important. And I should also notice you that this would let `t2c` failed to work. It's just an example.\r\n\r\nThe reason why I don't want you to change the `Text()` is that I don't want `Text()` to be a another `TextMobject()` which is hard to use (in some way). And in order to keep its compatibility as well. What's more, I'm planning to switch to another text layout engine, which can not only display those empty space characters correctly, but also provide more features like alignment, emoji-support and so on.\r\n\r\nAs for your `Code()`, I still think that it would be much better if you can separate the features that `Code()` provides. I think `Code()` is just a colored `Text()`, and line numbers can be another Mobject such as calling it `LineNum()`,  and the background, should be handle by something like `Window()`Ôºå rather than by `Code()` itself. But that's just my suggestions. It depends on you.",
      "I agree with xy-23, I don‚Äôt think it is a good idea to change too many codes of `Text()`.\n\nBut the feature which displays space characters in front of text may be very useful to your `Code()`. \n\nIf ‚Äòthe feature‚Äô is very necessary to your `Code()`, I think it‚Äôs better to create a new subclass of `Text()`.\nYou only have to rewrite some methods to archive your goals. In this way, `text_mobject.py` don‚Äôt need to be changed, and you can create `Code()` as well.\n\nBy the way, I think `code_mobject.py` is better in folder `mobject/svg/` (the same as `text_mobject.py` ) than in folder `mobject/`",
      "Added a new parameter \"exact_spaces\" to Text()",
      "> And you think we should display those empty space. I understand. And from the user's perspective, I definitely agree that you said `it should be display exactly same as it is written by user`. But that is hard to achieve, because the engine we are using can't provide this information at all! And your solution is not a good choice because it adds potential problems to Text()which we are not sure.\r\n\r\ni did that i just calculated space_width as `the engine` is drawing those space character according to font and language and i just calculate that width. This will work fine even with different languages or fonts.\r\n",
      "> As for your `Code()`, I still think that it would be much better if you can separate the features that `Code()` provides. I think `Code()` is just a colored `Text()`, and line numbers can be another Mobject such as calling it `LineNum()`, and the background, should be handle by something like `Window()`Ôºå rather than by `Code()` itself. But that's just my suggestions. It depends on you.\r\n\r\nby creating new classes ?\r\n",
      "@NavpreetDevpuri you forgot add `pygments` to `environment.yml` which used for anaconda. See #1136 ",
      "@Tony031218 \r\ncheck [this](https://github.com/NavpreetDevpuri/manim/blob/master/environment.yml)\r\nis this alright ?",
      "btw @eulertour should merge https://github.com/3b1b/manim/pull/1071 as soon as possible.\r\nbecause it fixes very big problems."
    ],
    "num_comments": 18,
    "repository": "3b1b/manim",
    "diff_length": 34341
  },
  {
    "index": 78,
    "pr_title": "Package manimlib and automatically publish to pypi",
    "pr_body": "I added the code to package manimlib and publish it on pypi using GitHub Action. Also fixed some bugs that made manimlib unable to be used normally after packaging.\r\n- The first commit https://github.com/3b1b/manim/commit/9916f56fb10b8600856b37e1bb84b57f5cc63ad2: The package will not include `manim.py`, so the \"manim\" module will not be found. So I changed to get the manimlib directory, and returned to the previous level to get the original \"manim_dir\".\r\n- The second commit https://github.com/3b",
    "pr_number": 1336,
    "comments": [
      "Before doing this, we should better check in with the manim community to think about what the two versions of manim look like on pypi.  Let me get back to you here.",
      "@TonyCrane, before publishing to pypi, please take a look at https://github.com/3b1b/manim/pull/1338",
      "> Before doing this, we should better check in with the manim community to think about what the two versions of manim look like on pypi. Let me get back to you here.\r\n\r\nTheir version is called [manim](https://pypi.org/project/manim/) on pypi, and there is no conflict in installation.\r\nBut both of them and our console scripts include `manim`, which may cause conflicts after the two versions are installed at the same time.",
      "I think we should have a name other than \"manimlib\" that better references the distinction between the two.  Would it be strange to name it \"manim3b1b\"?  I would say manimgl, but it sounds like the community has plans to adapt the OpenGL backend here for that version too.  What are your thoughts?",
      "I think it is strange to name it \"manim3b1b\". It is not a good idea to include your channel name in the name of the package, which may make people think that the package is only used by 3b1b himself.\r\nIn my opinion, it might be a good idea to name it \"manimgl\" or \"manimGL\". What ManimCommunity is doing should support multiple rendering backends (including cairo, WebGL, OpenGL), so maybe this is not conflicting, and it can also reflect the special features of 3b1b/manim.",
      "Right, at least for where they both are now, manimgl would most accurately capture part of the distinction.  And even when they do adapt the OpenGL backend here to their repo, it would at least convey the less flexible backend here :)\r\n\r\nWhat's involved in changing the name on pypi?",
      "Maybe we need to rename the manimlib folder to manimgl, but this will cause the history of the source code to be lost.\r\nThen just change the name in setup.cfg to change the name to manimgl",
      "So I still doubt whether we need to change the package name from manimlib to manimgl. The two versions do not conflict here (we use manimlib, they use manim). But we have conflicts on the entry point (we both are manim), maybe we only need to change console_scripts to `manimgl = manimlib:main` to run through `manimgl code.py Scene`.",
      "Does git have no way to rename a folder while preserving its history?\r\n\r\nIt's not super necessary to change names; I'll go ahead and just merge this and get things going.  It's just that manimlib doesn't really feel descriptive.",
      "So with that, shall I go ahead and make a new release?",
      "You should set `PYPI_USERNAME` and `PYPI_PASSWORD` in secrets first.",
      "I believe that's already done.\r\n\r\nAny objection to labeling this release 1.0.0?",
      "Before publishing it, I think we should rename the entry point to `manimgl`. What about you?\r\nIt is certainly no problem to label it as 1.0.0",
      "It seems a little messy with the repo being named manim, the pypi presence being under manimlib, and an entry point named manimgl.\r\n\r\nIf we're going with manimlib on pypi, then for consistency we should also make the entry point manimlib.  Thoughts?",
      "However, the name manimlib is more like a library, and using it as an entry point does not seem appropriate.\r\nPerhaps names like `manim-run` , `manim-render`, etc. sound good as entries?",
      "Right, I see what you are saying.  Is there a reason not to do \"manimgl\" as both the entry point and the pypi name, but then leave the manimlib folder named as it is?  Sorry if that's a dumb question, but it sounded like maybe there was a reason to change the manimlib folder name if we also named it something different on pypi.",
      "It would be terrible to rename both the folder and pypi. Git cannot migrate the history of folders, so the historical versions and change records of these files cannot be viewed easily on GitHub. This is also very inconvenient.\r\nBecause there is no conflict between us and the community in this respect, I still recommend keeping the original \"manimlib\" folder name and pypi name. Although this does not clearly highlight the characteristics of 3b1b/manim, at least it will not cause more trouble.\r\nBut on entry point, we and community both use \"manim\", so I think we'd better change the entry point name to a new one, such as \"manimgl\", \"manim-render\", \"manim-run\", etc.\r\nIn this way, we can still install 3b1b/manim via `pip install manimlib`, import via `from manimlib.imports import *`, and then run it via `manimlib(or manim-render, etc.) code.py Scene`.",
      "I just answered this in email but copying here for the record.  I was only asking if there's anything explicitly wrong with this configuration:\r\n\r\n- Pip name: manimgl\r\n- Entry point: manimgl\r\n- Folder name (unchanged): manimlib\r\n\r\nI would be alright with what you're suggesting, which is certainly easiest and probably the best:\r\n\r\n- Pip name: manimlib\r\n- Entry point: manim-render\r\n- Folder name (unchanged): manimlib\r\n\r\nWe could also add a note that for anyone who doesn't plan to also have the community edition installed, suggesting that they alias \"manim\" to \"manim-render\".",
      "Sorry I may have misunderstood you.\r\nThis is of course no problem, but still uses `from manimlib.imports import *` after installing manimgl from pypi, which may be a bit strange. \r\nBut this can also distinguish the current version from cairo-backend.\r\nThe naming is also good, so I just changed it in https://github.com/3b1b/manim/commit/b558ae98cf4ad1f6af13a680e820001c92ad63e6.\r\nFor the entry point, I set two names manimgl and manim-render."
    ],
    "num_comments": 19,
    "repository": "3b1b/manim",
    "diff_length": 5711
  },
  {
    "index": 79,
    "pr_title": "Interactive Mobjects Performance Improvements",
    "pr_body": "# Motivation\r\nAs mentioned in https://github.com/3b1b/manim/pull/1323#issuecomment-769350572, interactive mobjects were a bit laggy.\r\n\r\nSo, to improve interactively mobjects performance, the following changes are made.\r\n1. Maintain a separate list of mobject listeners instead of filtering mobjects on every frame.\r\n>   This significantly improved the performance on all events except the on_mouse_drag event. So to improve it the 2nd change was made.\r\n2.  Changed the way drag events are handled.\r\n>",
    "pr_number": 1326,
    "comments": [
      "Great. One issue for me is when I run ControlsExample without the ‚Äúself.embed()‚Äù, it works just as you show. However, if is included, then the python crashes and error message appears as:\r\n\r\n```\r\nPython 3.9.1 (v3.9.1:1e5d33e9b9, Dec  7 2020, 12:10:52) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.19.0 -- An enhanced Interactive Python. Type '?' for help.\r\n~/Pycharm/Manim/venv/lib/python3.9/site-packages/IPython/terminal/embed.py:285: UserWarning: Failed to get module example_scenes\r\n    warnings.warn(\"Failed to get module %s\" % \\\r\n```\r\n\r\nAny ideas about what is wrong here for me? Thank you.\r\n",
      "> Great. One issue for me is when I run ControlsExample without the ‚Äúself.embed()‚Äù, it works just as you show. However, if is included, then the python crashes and error message appears as:\r\n> \r\n> ```\r\n> Python 3.9.1 (v3.9.1:1e5d33e9b9, Dec  7 2020, 12:10:52) \r\n> Type 'copyright', 'credits' or 'license' for more information\r\n> IPython 7.19.0 -- An enhanced Interactive Python. Type '?' for help.\r\n> ~/Pycharm/Manim/venv/lib/python3.9/site-packages/IPython/terminal/embed.py:285: UserWarning: Failed to get module example_scenes\r\n>     warnings.warn(\"Failed to get module %s\" % \\\r\n> ```\r\n> \r\n> Any ideas about what is wrong here for me? Thank you.\r\n\r\n@BenEcon, if you add ‚Äúself.embed()‚Äù, you have to use \"self.wait({duration})\" to start interaction for a specified duration.\r\nYou could either write it before ‚Äúself.embed()‚Äù or in ipython embedded in console.\r\n\r\nTry adding \"self.wait(60)\" before \"self.embed()\" to start interactions for 60 seconds.",
      "> > Great. One issue for me is when I run ControlsExample without the ‚Äúself.embed()‚Äù, it works just as you show. However, if is included, then the python crashes and error message appears as:\r\n> > ```\r\n> > Python 3.9.1 (v3.9.1:1e5d33e9b9, Dec  7 2020, 12:10:52) \r\n> > Type 'copyright', 'credits' or 'license' for more information\r\n> > IPython 7.19.0 -- An enhanced Interactive Python. Type '?' for help.\r\n> > ~/Pycharm/Manim/venv/lib/python3.9/site-packages/IPython/terminal/embed.py:285: UserWarning: Failed to get module example_scenes\r\n> >     warnings.warn(\"Failed to get module %s\" % \\\r\n> > ```\r\n> > \r\n> > \r\n> > Any ideas about what is wrong here for me? Thank you.\r\n> \r\n> @BenEcon, if you add ‚Äúself.embed()‚Äù, you have to use \"self.wait({duration})\" to start interaction for a specified duration.\r\n> You could either write it before ‚Äúself.embed()‚Äù or in ipython embedded in console.\r\n> \r\n> Try adding \"self.wait(60)\" before \"self.embed()\" to start interactions for 60 seconds.\r\n\r\nThank you for the advice. I added waiting time before ‚Äúself.embed()‚Äù. During the waiting time, I can‚Äôt write command in shell, but I can use mouse to control. However, after the waiting time, the error message jumps again, I can write command in shell now, but I can not click python icon in Dock to active it, I can only use \"Command+Tab‚Äù to see python window. Good thing is that the shell result is there, however the python window is frozen and I can not do anything else. Any idea?",
      "> Thank you for the advice. I added waiting time before ‚Äúself.embed()‚Äù. During the waiting time, I can‚Äôt write command in shell, but I can use mouse to control. However, after the waiting time, the error message jumps again, I can write command in shell now, but I can not click python icon in Dock to active it, I can only use \"Command+Tab‚Äù to see python window. Good thing is that the shell result is there, however the python window is frozen and I can not do anything else. Any idea?\r\n\r\nAfter waiting time, you could write commands in the shell. You could add objects to the scene or play animations. But if you want to start the interaction mode, in the shell you could either run \"self.wait()\" for some duration or call \"self.interact()\" to start interactions until you press q (quit).\r\n",
      "> > Thank you for the advice. I added waiting time before ‚Äúself.embed()‚Äù. During the waiting time, I can‚Äôt write command in shell, but I can use mouse to control. However, after the waiting time, the error message jumps again, I can write command in shell now, but I can not click python icon in Dock to active it, I can only use \"Command+Tab‚Äù to see python window. Good thing is that the shell result is there, however the python window is frozen and I can not do anything else. Any idea?\r\n> \r\n> After waiting time, you could write commands in the shell. You could add objects to the scene or play animations. But if you want to start the interaction mode, in the shell you could either run \"self.wait()\" for some duration or call \"self.interact()\" to start interactions until you press q (quit).\r\n\r\nMany thanks. Even though the annoying error message is still there, your suggestion works. Great.",
      "Maybe it's better to remove the `self.embed()` in the last line of `ControlsExample`.",
      "> Maybe it's better to remove the `self.embed()` in the last line of `ControlsExample`.\r\n\r\nYes, that is right. However, to add objects or control the objects, it must include ‚Äúself.embed()‚Äù.",
      "Oh, sorry, I just didn't find that this has already been commented out.",
      "By the way, in interactive.py, in some places, control is mistyped as contol, for example, ContolMobject. ",
      "> Great. One issue for me is when I run ControlsExample without the ‚Äúself.embed()‚Äù, it works just as you show. However, if is included, then the python crashes and error message appears as:\r\n> \r\n> Python 3.9.1 (v3.9.1:1e5d33e9b9, Dec  7 2020, 12:10:52) \r\n> Type 'copyright', 'credits' or 'license' for more information\r\n> IPython 7.19.0 -- An enhanced Interactive Python. Type '?' for help.\r\n> ~/Pycharm/Manim/venv/lib/python3.9/site-packages/IPython/terminal/embed.py:285: UserWarning: Failed to get module example_scenes\r\n>     warnings.warn(\"Failed to get module %s\" % \\\r\n> Any ideas about what is wrong here for me? Thank you.\r\n\r\nDoes the embed line work in other scenes?  What was the line you ran to run the scene?\r\n\r\n> @BenEcon, if you add ‚Äúself.embed()‚Äù, you have to use \"self.wait({duration})\" to start interaction for a specified duration.\r\n> You could either write it before ‚Äúself.embed()‚Äù or in ipython embedded in console.\r\n\r\nActually, for interaction during an embed you can call \"touch()\" or \"self.interact()\" and then when you're done, press the key \"q\".\r\n",
      "> By the way, in interactive.py, in some places, control is mistyped as contol, for example, ContolMobject.\r\n\r\noops!! Fixed typo",
      "> > Great. One issue for me is when I run ControlsExample without the ‚Äúself.embed()‚Äù, it works just as you show. However, if is included, then the python crashes and error message appears as:\r\n> > Python 3.9.1 (v3.9.1:1e5d33e9b9, Dec  7 2020, 12:10:52)\r\n> > Type 'copyright', 'credits' or 'license' for more information\r\n> > IPython 7.19.0 -- An enhanced Interactive Python. Type '?' for help.\r\n> > ~/Pycharm/Manim/venv/lib/python3.9/site-packages/IPython/terminal/embed.py:285: UserWarning: Failed to get module example_scenes\r\n> > warnings.warn(\"Failed to get module %s\" % \r\n> > Any ideas about what is wrong here for me? Thank you.\r\n> \r\n> Does the embed line work in other scenes? What was the line you ran to run the scene?\r\n> \r\n> > @BenEcon, if you add ‚Äúself.embed()‚Äù, you have to use \"self.wait({duration})\" to start interaction for a specified duration.\r\n> > You could either write it before ‚Äúself.embed()‚Äù or in ipython embedded in console.\r\n> \r\n> Actually, for interaction during an embed you can call \"touch()\" or \"self.interact()\" and then when you're done, press the key \"q\".\r\n\r\nIn other scenes, the embed line works, however, the same error message is there. The line I ran to run the scene is:\r\n`python3 -m manim example_scenes.py ControlsExample`\r\n"
    ],
    "num_comments": 12,
    "repository": "3b1b/manim",
    "diff_length": 10961
  },
  {
    "index": 80,
    "pr_title": "New Text Mobject",
    "pr_body": "# Motivation\r\n\r\nBecause the `TextMobject` is the subclass of `TexMobject`,\r\n\r\nso it requires some latex-style behaviours in order to add some changes.\r\n\r\n(e.g. other languages, font, slant and weight)\r\n\r\nSo I create `Text` mobject but you can still use `TextMobject`.\r\n\r\n# Introduction\r\n\r\n`Text` is a subclass of `SVGMobject`.\r\n\r\nIt uses `cairo` to generate text svgs.\r\n\r\nIt has a better UTF-8 support, multi-line support, and various options. \r\n\r\nIt doesn't support mathematical formula(latex), \r\n\r\n",
    "pr_number": 680,
    "comments": [
      "It works perfectly, I do add it to my version of Manim, thanks for this!",
      "@xy-23 : can you add your beautiful instruction here:\r\nhttps://github.com/Elteoremadebeethoven/Manim-community \r\n??\r\nThat would be great, because it is very invisible in a pull request.\r\nIt should be easy to find for everyone",
      "@kolibril13 \r\nThanks, I will, but it has some bugs and improvements need to be finished.\r\nI will do this later until I finish them.",
      "is it possible to change the alignment from (left to right) to (right to left ) ?",
      "> is it possible to change the alignment from (left to right) to (right to left ) ?\r\n\r\nSorry, it can't, but you can use multiple Text and align by yourself (manim provides some methods of mobject).\r\nMaybe I will add this feture later depending on whether the package I used(pycairo) has this function.",
      "I really love this addition of the `Text` object, however, I'm seeing some strange artifacts when rendering text in some fonts. Look at the letters b, d, g, o, p, q below with Roboto Condensed font.\r\n\r\n<img width=\"959\" alt=\"Screen Shot 2019-11-11 at 11 07 32 PM\" src=\"https://user-images.githubusercontent.com/2654175/68641283-5d1f4980-04d8-11ea-854b-2850ebd46934.png\">\r\n\r\nAlso see the B and P below, with Noto Sans. These are just examples of what I see and not the only artifacts I encounter. \r\n\r\n<img width=\"1042\" alt=\"Screen Shot 2019-11-11 at 11 13 39 PM\" src=\"https://user-images.githubusercontent.com/2654175/68641489-036b4f00-04d9-11ea-8f01-08e7a1b74314.png\">\r\n\r\n\r\nAny idea what I might be doing wrong?\r\n\r\n\r\n",
      "Try `Text(‚Äùtext‚Äù,stroke_width=0)`",
      "That appears to have worked. Thank you!",
      "Doesn't work\r\n![image](https://user-images.githubusercontent.com/35609308/74359634-7096c500-4de5-11ea-823a-553c1cb047cc.png)\r\n",
      "**How can I write different size in one string?**\r\n\r\nFor example: I want \"Hello World how are you?\" to be looking like\r\n*\"Hello World\"* size=2 and *\"how are you?\"* size=1",
      "@ahmedafifkhan you can scale \"how are you\" manually.\r\n```python\r\ntext = Text(\"Hello World how are you?\", size=2)\r\ntext[12:].scale(0.5, about_edge=LEFT)\r\n```"
    ],
    "num_comments": 11,
    "repository": "3b1b/manim",
    "diff_length": 11566
  },
  {
    "index": 81,
    "pr_title": "Add simple table drawing functionality.",
    "pr_body": "## Motivation\r\nTables are really useful for displaying data concisely, which is really useful when making animations on topics such as statistics and science. Currently, Manim can only generate Tables easily through LaTeX, which results in difficulty when generating tables programmatically.\r\n\r\n## Results Obtained\r\nWith this addition, tables can be made by calling `Table.get_table(<dictionary>)`, where the main, required parameter is a dictionary with the Keys as the field names and Values per Ke",
    "pr_number": 841,
    "comments": [
      "Hi thanks for this great work. Can you update the table to add info in it after it has been created? ",
      "> Hi thanks for this great work. Can you update the table to add info in it after it has been created?\r\n\r\nI'm still working on that. However, as a workaround, you can index the table like a list, since it's just a VGroup.\r\n\r\nThe way I've set it up now, the first few objects in the VGroup are the field names/headings.\r\n\r\nAfter the field names, the next few objects are reserved for those in the first column (the leftmost one) and are ordered top to bottom.\r\n\r\nThe next few objects are the values in the column to the immediate right of it and so on, until all the records are in the VGroup. \r\n\r\nThe object present immediately after the records is the horizontal line. The objects present after that are the vertical separators. \r\n\r\nOnce you know which object to modify, you can ReplacementTransform() them with the new value you want them to be.\r\n\r\nFor example:\r\n```python\r\nfrom manimlib.imports import *\r\nfrom sanim.anim_tools.tables import *\r\nclass Tables(Scene):\r\n    def construct(self):\r\n        \r\n        tabledict={\r\n            TextMobject(\"TextMobject Input\"):[TextMobject(\"Must\"),TextMobject(\"add\"),TextMobject(\"element\"),TextMobject(\"retrieval.\")],\r\n            TexMobject(\"TexMobject Input\"):[TexMobject(r\"e^{\\iota\\pi}+1 = 0\"),TexMobject(r\"Tex: \\alpha\\theta\\epsilon\")],\r\n            Text(\"Text input\",font=\"Lucida Grande\"):[Text(\"Text\",font=\"sans-serif\"),Text(\"is\"),Text(\"Supported\")],\r\n            \"Raw String Input\":[\"Defaults\",\"to\",\"TextMobject.\"]\r\n\r\n        }\r\n\r\n        table=Table.get_table(tabledict,line_color=GREY,raw_string_color=BLUE)\r\n        table.move_to((0,0,0))\r\n        self.play(Write(table.scale(0.5)),run_time=2)\r\n        #CHECK THIS OUT ‚Üì\r\n        newvalue=TextMobject(\"New Value\").move_to(table[0]) #The first index is the first columns heading\r\n        self.play(ReplacementTransform(table[0],newvalue))\r\n\r\n        self.wait(1)\r\n```\r\n\r\nThe code above gives this output:\r\n\r\n\r\n\r\n![TableExample](https://user-images.githubusercontent.com/33193764/74328276-9e631600-4db3-11ea-82b0-f558ccc35d11.gif)\r\n\r\nAdding info will be a bit more difficult. I'll get to that soon!",
      "Thanks it worked. The counting does not include empty table cells? It's a bit strange. Looking forward to the rest of your code!",
      "Perhaps you could use empty strings for those locations?\n\nOn Wed, 12 Feb, 2020, 23:17 Nathenat, <notifications@github.com> wrote:\n\n> Thanks it worked. The counting does not include empty table cells? It's a\n> bit strange. Looking forward to the rest of your code!\n>\n> ‚Äî\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/3b1b/manim/pull/841?email_source=notifications&email_token=AH5H6JHULQEGJT4VEVJ34LLRCQY4ZA5CNFSM4J7XGHK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOELRXAIA#issuecomment-585330720>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AH5H6JHA4HKP6CTPVUDJTELRCQY4ZANCNFSM4J7XGHKQ>\n> .\n>\n",
      "> Thanks it worked. The counting does not include empty table cells? It's a bit strange. Looking forward to the rest of your code!\r\n\r\nHey! I managed to add basic Record addition and removal to the table.\r\n\r\nYou can get the most recent version of the script here: https://github.com/Aathish04/sanim/\r\n\r\nI've had to make some major changes regarding how everything works.\r\n\r\nTable() is now it's own type of Mobject, and not just a VGroup. You can still use it like a VGroup though.\r\n\r\nYou can use `Table.add_record(record object,field_number)` to add records.\r\nYou can use  `Table.remove_record(field_number,record_number)` to remove  the record_numbered record in a field.\r\n\r\nSee the example below:\r\n```python\r\nfrom manimlib.imports import *\r\nfrom sanim.anim_tools.tables import *\r\nclass Tables(Scene):\r\n    def construct(self):\r\n        \r\n        tabledict={\r\n            TextMobject(\"TextMobject Input\"):[TextMobject(\"Must\"),TextMobject(\"add\"),TextMobject(\"element\"),TextMobject(\"retrieval.\")],\r\n            TexMobject(\"TexMobject Input\"):[TexMobject(r\"e^{\\iota\\pi}+1 = 0\"),TexMobject(r\"Tex: \\alpha\\theta\\epsilon\")],\r\n            \"Raw String Input\":[\"Defaults\",\"to\",\"TextMobject.\"],\r\n            Text(\"Text input\",font=\"Lucida Grande\"):[Text(\"Text\",font=\"Alys Script Bold\"),Text(\"is\",font=\"serif\"),Text(\"Supported\",font=\"serif\")],\r\n        }\r\n\r\n        table=Table(tabledict=tabledict,line_color=GRAY,raw_string_color=BLUE)\r\n        table.move_to((0,0,0))\r\n        table.scale(0.5)\r\n        \r\n        self.play(Write(table),run_time=2)\r\n\r\n        self.play(Write(table.add_record(record=TextMobject(\"Hello\"),field_num=1)))\r\n        \r\n        self.play(Uncreate(table.remove_record(field_num=1,record_num=0)))\r\n        \r\n        self.wait(1)\r\n```\r\nHope this helps! I'm still working on Field addition and removal. That is a lot harder than I thought ;)",
      "For the empty string, I had already tried and the cell was ignored in the numbering.\r\n\r\nThanks a lot for the new code, I'll use it asap and let you know if I have any feedback. \r\n",
      "Please do tell me if there are any wierd bugs etc!\n\nOn Mon, 17 Feb, 2020, 16:08 Nathenat, <notifications@github.com> wrote:\n\n> For the empty string, I had already tried and the cell was ignored in the\n> numbering.\n>\n> Thanks a lot for the new code, I'll use it asap and let you know if I have\n> any feedback.\n>\n> ‚Äî\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/3b1b/manim/pull/841?email_source=notifications&email_token=AH5H6JBWIESUY7JKRRHEIHTRDJSLNA5CNFSM4J7XGHK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEL546JY#issuecomment-586927911>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AH5H6JBQ5CHKJNYT2ESI2UDRDJSLNANCNFSM4J7XGHKQ>\n> .\n>\n",
      "![image](https://user-images.githubusercontent.com/48950631/78357406-0de4cd00-75cf-11ea-9181-738fa08e7f68.png)\r\n\r\nI am getting this error. Any Suggestions?\r\n",
      "First Off:\nYou‚Äôre using a really old version of the Manim Library.\n\nInstead of using the version with Pip, you should use the version from GitHub.\n\n> On 03-Apr-2020, at 17:18, AIE- Machine Learning & Image Processing <notifications@github.com> wrote:\n> \n> \n>  <https://user-images.githubusercontent.com/48950631/78357406-0de4cd00-75cf-11ea-9181-738fa08e7f68.png>\n> I am getting this error. Any Suggestions?\n> \n> ‚Äî\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub <https://github.com/3b1b/manim/pull/841#issuecomment-608389825>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AH5H6JH7QEK6QUZCFYYZ7ODRKXEI3ANCNFSM4J7XGHKQ>.\n> \n\n\n",
      "I'm having the error:\r\n\r\n    table=Table.get_table(tabledict)\r\nNameError: name 'Table' is not defined\r\n\r\nI put the file tables.py into the folder manimlib/mobjects, not sure what the issue is.",
      "> I'm having the error:\r\n> \r\n> ```\r\n> table=Table.get_table(tabledict)\r\n> ```\r\n> \r\n> NameError: name 'Table' is not defined\r\n> \r\n> I put the file tables.py into the folder manimlib/mobjects, not sure what the issue is.\r\n\r\nHave you added `from manimlib.mobjects.tables import *` to `manimlib/imports.py` ?",
      "> I'm having the error:\r\n> \r\n> ```\r\n> table=Table.get_table(tabledict)\r\n> ```\r\n> \r\n> NameError: name 'Table' is not defined\r\n> \r\n> I put the file tables.py into the folder manimlib/mobjects, not sure what the issue is.\r\n@almccutc \r\n\r\nLike @Tony031218 mentioned, also add `from manimlib.mobjects.tables import * to manimlib/imports.py`, so you can import it that way.\r\n\r\nAlso, `Table.get_table(<dict>)` has been deprecated, and you should use `Table(<dict>)` instead.",
      "FOR THE REFERENCE OF ANYONE WHO STUMBLES UPON THIS THREAD:\r\nPlease use https://github.com/Aathish04/sanim/blob/manim-3b1b/anim_tools/tables.py for the most recent, bug free version of this feature.",
      "Simple adding the latest version of `tables.py` doesn't work. But the  previous version (95 lines) works good.",
      "> Simple adding the latest version of `tables.py` doesn't work. But the  previous version (95 lines) works good.\n\n@zdarovakoresh \n\nCan you please file an issue on the repository I linked stating what went wrong and the traceback/errors, if any?"
    ],
    "num_comments": 15,
    "repository": "3b1b/manim",
    "diff_length": 5372
  },
  {
    "index": 82,
    "pr_title": "Featured a blog post about installing the Manim",
    "pr_body": "Maybe it will help grow the support and the community around this project.",
    "pr_number": 60,
    "comments": [
      "Without trying to sound rude, there are some issues with your tutorial(s) for installing Manim.\r\nThe first post is pretty good, though the grammar needs a bit of work.\r\nThe second post has a lot of errors:\r\n- You should be copying the `__init__.py` file anywhere, it's in the Manim folder so python will treat the directory as a package, you can read more about that [here](https://pythontips.com/2013/07/28/what-is-__init__-py/).\r\n- The `example_scenes.py` file should also not be copied out of the Manim folder, when you specify it in the command line, it can be a local path, or an absolute path. Since you are running python from the Scripts folder, and not the Manim folder, it will check there for local paths. If you instead executed the following, you wouldn't have any issues:\r\n    ```\r\n    C:\\WINDOWS\\system32> cd ../../Python27/Manim\r\n    C:\\Python27\\Manim> \"C:/Python27/Scripts/python\" extract_scene.py -w example_scenes.py SquareToCircle\r\n    ```\r\n    Alternatively, you could add it to the path as you mentioned in the first post, and just reference it as `python`.\r\n- If you are going to modify the `MOVIE_DIR` variable to a fixed path, you can get rid of the `os.path.join()` surrounding it, and instead just have: `MOVIE_DIR = \"<your output folder path>\"`.\r\n- The error you are seeing at the end: `The system cannot find the path specified` is because it plays a chord when it finishes rendering a scene, you can find this method at the top of the `helpers.py` file: `play_chord(*nums)`. It tries to call a program `play`, which isn't installed on Windows, I installed [SoX](http://sox.sourceforge.net/) on my Arch Linux installation (package [here](https://www.archlinux.org/packages/extra/x86_64/sox/)) when getting Manim setup.",
      "Check it out, now.. I corrected them just like you said... Thank you!",
      "Better, though I recommend verifying installing SoX is a fix for Windows. From the looks of the Manim code, this is developed for Linux, some of the changes I recommended were also from me developing on Linux, which might not be applicable on Windows.\r\nThe command line snippets you have on the second blog are still referring to the Manim folder, rather than being called from *inside* the Manim folder. You did change them on the first post, but not on the second.\r\nThanks for the shout out for the updates by the way.",
      "Another thing that might be worth making a post about, is how to get the text rendering working. When I first tried this project on my Linux installation, there were a lot of issues with dvisvgm and latex (what Manim uses to convert text to SVG for rendering). On the README for Manim it mentions having ffmpeg and latex installed before using, you made a post about ffmpeg, so latex seems like the next step.",
      "I corrected what you have said. I made a new screenshot with the new path structure and MOVIE_DIR... I think that it's complete now. And, you are right, the next step is latex. I installed latex, but it seems that there is a issue when creating a .svg file... It says that it's missing some .svg file in the /files/Tex.. So, can help me get through this issue...? Also, is there an option that allows me to make you a contributor on my blog, so you can easily correct stuff...?",
      "I think you can follow the steps [here](https://support.google.com/blogger/answer/42673?hl=en) for allowing me to edit your blog. You can use my email, which should be visible to you on my profile.\r\n\r\nI think one last edit though, at the top of the second post is a snippet:\r\n```\r\npython \"C:/Python27/Manim/extract_scene.py\" -p example_scenes.py SquareToCircle\r\n```\r\nYou should change it to the following to match the screenshots below and the snippet at the end of the first post:\r\n```\r\npython extract_scene.py -p example_scenes.py SquareToCircle\r\n```",
      "As for the LaTeX issue, if you have a file `<NUMBERS>.tex` in the /files/Tex directory, try calling the conversion calls (found at the bottom of `mobject/tex_mobject.py`) manually (but with logging) from the command line. For example:\r\n```\r\n> cd /files/Tex/\r\n> copy \"<NUMBERS>.tex\" test.tex\r\n> latex -halt-on-error test.tex\r\n> dvisvgm test.dvi -n -o test.svg\r\n```\r\nIf there aren't any errors at each step, it should convert properly when running the python file, if there are any errors, let me know.",
      "Done, done and done!\r\nJust it pops an error on the last command: \r\n\r\n`C:\\Python27\\Manim\\files\\Tex>dvisvgm test.dvi -n -o test.svg\r\npre-processing DVI file (format version 2)\r\nprocessing page 1\r\n  computing extents based on data set by preview package (version 11.91)\r\n  width=0pt, height=7.319pt, depth=7.31985e-06pt\r\n  page is empty\r\n  graphic size: 0pt x 7.31901pt (0mm x 2.57234mm)\r\n  ERROR: table value 175872 out of range`\r\n\r\nThe latex command was a success... But this one, seems the width is the problem somehow...",
      "Alright, I've seen [that issue](https://github.com/mgieseki/dvisvgm/issues/79) before, I think it can be fixed by installing the [latest dvisvgm](https://github.com/mgieseki/dvisvgm/releases/tag/2.2.3)",
      "Boom! THANK YOU VERY MUCH!\r\nIt worked.. We can write about it in the next blog post.. I tried it with the scene 'WriteStuff', it is complete success. Thank you again!",
      "No problem, if you ever want me to look over another post, just send me an email. I don't think this pull request should be used for much more. Even if this request doesn't get merged, writing a blog for various aspects of Manim would be useful to anyone who's interested, so keep at it.",
      "You are absolutely right. I will send you an email if I write couple of new posts about the Manim and we shouldn't use this pull request for further conversations. Thank you again for helping me out.  ",
      "I'm trying to install it, but I'm having trouble. Whenever I run `pip install -r -requirements.txt` I get `RecursionError: maximum recursion depth exceeded.`",
      "@zhangwn I think the right command is `pip install -r requirements.txt` (you wrote `-requirements.txt`). It should fix, otherwise follow his tutorial if you are a Windows user. And you should have created a new issue, not posted this comment in this pull request."
    ],
    "num_comments": 14,
    "repository": "3b1b/manim",
    "diff_length": 723
  },
  {
    "index": 83,
    "pr_title": "Svgmobject update with basic processing of 'text' tag",
    "pr_body": "# Motivation\r\n\r\nCurrently,, `SVGMobject` doesn't support `<text>` tag in SVG format. The support of this tag is good for plotting diagrams, graphs, and other structures from SVG. I've faced it when trying to plot graphs rendered by [graphviz](https://www.graphviz.org/).\r\n\r\n# Implementation\r\n\r\nI've added text processing to SVGMobject using `Text` mobject with the following features:\r\n\r\n- scaling text using `text_scale` for better drawing (original font size is incorrectly small;\r\n- support of fon",
    "pr_number": 1083,
    "comments": [
      "I think we have to use cairo directly to do this.\r\nM Trying.",
      "![bandicam 2020-05-19 03-30-51-296](https://user-images.githubusercontent.com/30471072/82263741-2cd1cf80-9981-11ea-87dd-84477b6b07a3.jpg)\r\nLook at the text background which is black colored rectangle\r\nand the position of text is pink colored circle the mid point of that background rectangle\r\nfor now i don't know how to get that center for different-different fonts\r\n\r\n",
      "@NavpreetDevpuri\r\n\r\nYes, currently, the arrangement is naturally done with whole text along the center of the rectangle (see red dots below).\r\n\r\n![test_1](https://user-images.githubusercontent.com/11081197/82269889-b088bd80-997b-11ea-971a-e5fe86de2de6.png)\r\n\r\nThe desired behavior is to arrange vertically along with the small characters of text ('o' position). To count that I propose counting extra space for each character using the original cairo function `text_extents` and comparing height and vertical bearing for the whole text and separate characters. So the text can be arranged as follows. Green dots - new vertical \"center\".\r\n\r\n![test_2](https://user-images.githubusercontent.com/11081197/82269981-fb0a3a00-997b-11ea-9132-5b247f87bd99.png)\r\n",
      "I think if we store all Text elements from svg files in a list and after that just replace Text elements in svg file with cairo rendered Texts at appropriate locations according to font and style. Save this new generated svg file may be in new media folder `media/svg`\r\nThis seems a better approach because we don't need to rebuild text render.\r\n\r\nBut for a base your method is just fine.\r\nWe can improve it later.",
      "But svg file is still showing in wrong way.\r\nReset `text_mobject.py` \r\nLeft side is in chrome\r\nRight side is in manim \r\n![collage](https://user-images.githubusercontent.com/30471072/82276813-f22d5e80-99a3-11ea-93dd-51ed03eef1e8.jpg)\r\n",
      "@NavpreetDevpuri, yes, I see. The problem was in the interpretation of vertical alignment in SVG. The vertical anchor in SVG is [along the baseline, not in center](https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/text-anchor). Now the text placement seems to be correct:\r\n\r\n![test_3](https://user-images.githubusercontent.com/11081197/82309127-662f2d00-99cb-11ea-98a3-c70dfc679a0e.png)\r\n",
      "Good job! \r\nNow implement `text-anchor` shift text right or left by the half of width according to 'text-anchor' and set default value for text stroke to 0 and fill the text with color. ",
      "@NavpreetDevpuri \r\n\r\n1. The horizontal alignment was updated. See below. **NB** The `text-anchor` attribute was modified manually in SVG file for \"A\" (`text-anchor=\"start\"`) and \"B b\" (`text-anchor=\"end\"`) nodes, so they are shifted. With the original file, everything is placed fine.\r\n\r\n![test_4](https://user-images.githubusercontent.com/11081197/82317485-ff177580-99d6-11ea-8ce2-3d8d101b9bfb.png)\r\n\r\n2. Stroke and fill is updated for all submobjects in base `VMobject`. So, new `update_text_stroke_and_fill()` called in `__init__` was added. The default stroke is used for text color. Stroke in the text is disabled by default.",
      "> I think if we store all Text elements from svg files in a list and after that just replace Text elements in svg file with cairo rendered Texts at appropriate locations according to font and style. Save this new generated svg file may be in new media folder `media/svg`\r\n> This seems a better approach because we don't need to rebuild text render.\r\n> \r\n> But for a base your method is just fine.\r\n> We can improve it later.\r\n\r\n\r\nas i said \r\na better way to use `inkscape` to convert svg's text to paths automatically according to font, size ..etc it handles everything.\r\nYou can try as follow \r\ninstall inkscape then add `C:\\Program Files\\Inkscape\\bin;` to environment variable `path`.\r\nopen terminal or cmd at 'g.svg' file's directory\r\nthen run following command \r\n```console\r\ninkscape g.svg --export-text-to-path --export-plain-svg --export-filename=output.svg\r\n```\r\nthis will create `output.svg` containing `path` tags instead of `text` tag.",
      "Yes, that possibly works. But as I see there are two issues.\r\n\r\n1. This requires additional external software to be used. As a general solution, that looks not so good. So I believe adding the functions proposed in this PR will be better.\r\n\r\n2. In my particular case, `SVGMobject` fails in the processing of `<path>`  tag both in my branch and in master with the following error: `TypeError: add_cubic_bezier_curve_to() missing 2 required positional arguments: 'handle2' and 'anchor'`. [Here is the input SVG file](https://yadi.sk/i/5_jTz-wtY5ZhYg). And I think it should be another issue independent of this PR. (I can create an issue here for that)\r\n\r\nAll in all, for my purpose, my update seems to be working well. See an example from my current work (sorry for text in Cyrillic):\r\n\r\n![Shapes](https://user-images.githubusercontent.com/11081197/82502043-fcb03b00-9afe-11ea-99de-bcb00c8f6e97.gif)\r\n",
      "It looks like this pull request is out of date, as `SVGobject` has been refactored in #1731 and support for text is also in the works.\r\nThanks for this, but I'm closing this pull request."
    ],
    "num_comments": 11,
    "repository": "3b1b/manim",
    "diff_length": 7013
  },
  {
    "index": 84,
    "pr_title": "Construct `MTex`",
    "pr_body": "Updated on 11/28 (GMT+8): Some information in this comment may be outdated. Please see the latest comment.\r\n\r\n## Motivation\r\nAs what I've mentioned in #1677 , recently I'm working on the refactoring of `Tex` mobject. Manim generates all substrings of a `Tex`, namely the `SingleStringTex` objects, and calculates their lengths in order to figure out indices of some certain submobjects. This may cause the program to become slow as a `Tex` is split into tons of components, which is a usual case for ",
    "pr_number": 1678,
    "comments": [
      "I daren't modify the `Tex` class as it's deeply rooted in manim, so I've written a new class called `MTex` for substitute. This class shares some similarities but also some differences with `Tex`. Why choose \"M\" as a prefix? ~~Because it means \"magic\".~~\r\n\r\n- `MTex` takes in exactly one string and has no `arg_separator` argument. One may simply use `join` function to cover this problem.\r\n- Every `MTex` needs to be compiled once, no matter how many substrings are specified in `isolate` and `tex_to_color_map`. However, they must be a valid tex string when isolated, like `{a`, `\\right)` are no longer allowed since `MTex` no longer provides automatic brace balancing. Also, inputting strings that cross (like `ab` and `bc`, which can be simply replaced by `a`, `b` and `c`) may also cause problems and is strongly unrecommended.\r\n- One of the main goals of this PR is to avoid wasting time finding the indices of mobjects of tex desired to be colored. Note that `get_parts_by_tex` is set to be always case sensitive, and strings cannot be matched as substrings in `MTex`.\r\n```python\r\n# Substrings enclosed by a pair of braces (not escaped characters) are automatically isolated.\r\n# tex1 = Tex(\"x = \\\\frac{-b \\\\pm \\\\sqrt{b^2-4ac}}{2a}\", isolate=[\"{b^2-4ac}\", \"{2a}\"])\r\ntex1 = MTex(\"x = \\\\frac{-b \\\\pm \\\\sqrt{b^2-4ac}}{2a}\")\r\n# Needn't use `isolate` or `tex_to_color_map`\r\ntex1.set_color_by_tex(\"{b^2-4ac}\", YELLOW)\r\ntex1.set_color_by_tex(\"{2a}\", BLUE)\r\n\r\n# Furthermore, subscripts and superscripts are also automatically isolated.\r\ntex2 = MTex(\"a^2 + b^2 = c^2\")\r\n# Either would be OK:\r\n# tex2.set_color_by_tex(\"2\", LIGHT_PINK)\r\ntex2.set_color_by_tex(\"^2\", LIGHT_PINK)\r\n\r\n# A variable with a subscript and a superscript won't cause problems.\r\ntex3 = MTex(\"N = p_1^{r_1} p_2^{r_2} \\\\cdots p_s^{r_s}\", tex_to_color_map={\r\n    \"p_1\": GREEN,\r\n    \"p_2\": RED,\r\n    \"p_s\": BLUE,\r\n})\r\n\r\n# You can even color a string as long as their substrings are all isolated.\r\n# You may use `get_all_isolated_substrings()` method to check all the substrings isolated.\r\n# Isolating \" \\\\cdot \" is not recommended since `{ \\cdot }` eliminates the space on both sides of the operator.\r\ntex4 = MTex(\"Q = {c_m} \\\\cdot {m} \\\\cdot {\\\\Delta T}\", isolate=[\" \\\\cdot \"])\r\ntex4.set_color_by_tex(\"{c_m} \\\\cdot {m} \\\\cdot {\\\\Delta T}\", RED)\r\n\r\nself.add(VGroup(tex1, tex2, tex3, tex4).arrange(DOWN, buff=1))\r\n```\r\n\r\nThe result of the code above is shown here:\r\n![TestScene](https://user-images.githubusercontent.com/50232075/143676133-b86ba216-03d8-44f8-b0a8-38b64f2f5294.png)\r\n\r\nHowever, the `MTex` class isn't able to assign a corresponding to each component, since the tex string doesn't always align well with the svg generated, so the `get_tex()` method is removed. This will make it unable to work with `TransformMatchingTex`. This may be fixed in the future.\r\n\r\nI use `full_tex` to generate hash keys, so two tex files that should contain different contents must be generated separately.\r\n\r\nYou are welcome to discuss any bugs or issues encountered with this new class!\r\n",
      "Thanks for doing this! It's a clever solution to the problem. I'll take a closer look and see if I can find any edge cases that outweigh the pros, but overall I think replacing Tex with this implementation will be the right way to go.",
      "Let me clarify some main differences between methods of `Tex` and `MTex`.\r\n```python\r\nSingleStringTex.get_tex(self)\r\n```\r\n`Tex` is made up by a series of `SingleStringTex` with this method to return a prtial tex string. However, submobjects of `MTex` don't have such a method. The `MTex` version may be implenented in the future. (Updated on 12/7 (GMT + 8): Already implemented)\r\n\r\n```python\r\nTex.get_parts_by_tex(self, tex, substring=True, case_sensitive=True)\r\nTex.get_part_by_tex(self, tex, **kwargs)\r\n```\r\nThe former returns a `VGroup` containing several submobjects, which are of type `SingleStringTex`. The latter returns the first submobject matched, or `None` if nothing can be matched. The tex string can be matched in `substring` or `case_sensitive` mode as options.\r\n\r\n```python\r\nMTex.get_parts_by_tex(self, tex)\r\nMTex.get_part_by_tex(self, tex, index=0)\r\n```\r\nThe former returns a `VGroup` with several parts. Note that in `MTex`, `part` is regarded as a `VGroup` of submobjects, so a `part` and a submobject have different hierarchies. The latter returns the `index`-th element of the former result, so it may raise `IndexError`. The tex string must be able to be decomposed into some substrings that are already isolated.\r\n\r\n```python\r\nTex.index_of_part(self, part, start=0)\r\nTex.index_of_part_by_tex(self, tex, start=0, **kwargs)\r\n```\r\nReturn the index of the submobject, namely the `part`. An optional attribute `start` may be passed.\r\n\r\n```python\r\nMTex.indices_of_part(self, part)\r\nMTex.indices_of_part_by_tex(self, tex, index=0)\r\nMTex.slice_of_part(self, part)\r\nMTex.slice_of_part_by_tex(self, tex, index=0)\r\nMTex.index_of_part(self, part)\r\nMTex.index_of_part_by_tex(self, tex, index=0)\r\n```\r\nThe `indices_of_part()` function returns the indices of each submobject of `part` in submobjects of `MTex`. `slice_of_part()` only gets the first and the last indices returned by `indices_of_part()`, and returns the slice spanned by them. It's assumed the order of submobjects preserve that of tex string (at least in this scope). `index_of_part()` returns the first index returned by `indices_of_part()`.\r\n\r\n```python\r\nMTex.get_all_isolated_substrings(self)\r\n```\r\nReturns all substrings that are already isolated. It's implemented here to make the class more user-friendly.\r\n",
      "I've just finished implementing the `get_tex()` method for submobjects of `MTex`. I have no idea whether this works fluently in many other cases that I haven't tested so far, and it sometimes may assign some meaningless `tex_string`s to submobjects because of the ordering issue. As an example, a fraction line will be assigned with an empty string if the tex given is `\\frac{1}{2}`. The `print_tex_strings_of_submobjects()` method is provided for debugging, which works well with `index_labels()`.\r\nAnyway, `MTex` is now almost fully compatible with `Tex`, at least all methods are implemented. One may use `TransformMatchingTex` for `MTex` objects.",
      "@3b1b I think the code is ready for reviewing now. Sorry for forgetting marking this as a draft before. This implementation works so far so good based on my LaTeX environment. I wonder whether there're still some bugs remaining in some edge cases...",
      "Hey @YishiMichael! This is a very clever approach which we'd also like to include over at https://github.com/ManimCommunity/manim -- are you either interested in submitting a similar PR there, or are you otherwise okay with someone of the community devs taking care of that for you?\r\n\r\n(Inclusion of your new classes as-is should be a more or less straightforward process, replacing the current default Tex classes could be a completely separate, second step.)",
      "I noticed that its feature that all paired braces are automatically broken up would cause unexpected breakings like `\\begin{matrix}`, `\\hspace{3em}`. So I added `unbreakable_commands` parameter for users to input some commands, the braces follow which won't be broken up. It's default to be `[\"\\\\begin\", \"\\\\end\"]`.\r\n@behackl Sorry for replying so lately, for I'm busy with school work these days. Thanks for your approval! I'd prefer someone of the community to help maintain the code, and add more features or make some modifications if necessary. To be honest, some methods in this class may still have space for better implementation, or even have bugs I haven't discovered so far, so I'm glad if someone can come up with ideas and further improve the code.",
      "@3b1b I think it's time to merge this. What about you?",
      "I agree, it looks good to me. I'll merge it, then make a separate PR to replace Tex and TexText with this.",
      "Why I have the following same errors popping up either I use the examples above or input anything in MTex?\r\nmy environment: Win10, python 39. Conda,  But using Tex is fine.\r\n\r\n----> 1 b = MTex(\"hello\")\r\n\r\nd:\\appsgrouped\\conda\\envs\\py39\\lib\\site-packages\\manimlib\\mobject\\svg\\mtex_mobject.py in __init__(self\r\n, tex_string, **kwargs)\r\n    283             for submob in tex_hash_to_mob_map[hash_val]\r\n    284         ])\r\n--> 285         self.build_submobjects()\r\n    286\r\n    287         self.init_colors()\r\n\r\nd:\\appsgrouped\\conda\\envs\\py39\\lib\\site-packages\\manimlib\\mobject\\svg\\mtex_mobject.py in build_submobj\r\nects(self)\r\n    322         self.group_submobjects()\r\n    323         self.sort_scripts_in_tex_order()\r\n--> 324         self.assign_submob_tex_strings()\r\n    325\r\n    326     def group_submobjects(self):\r\n\r\nd:\\appsgrouped\\conda\\envs\\py39\\lib\\site-packages\\manimlib\\mobject\\svg\\mtex_mobject.py in assign_submob\r\n_tex_strings(self)\r\n    400             curr_labels, prev_labels, next_labels\r\n    401         ):\r\n--> 402             curr_span_tuple = label_dict[curr_label]\r\n    403             prev_span_tuple = label_dict[prev_label]\r\n    404             next_span_tuple = label_dict[next_label]\r\n\r\nKeyError: -1\r\n",
      "@mark-zz That's weird as it totally works on my computer (Windows 10). I guess it could be the different behaviors of LaTeX compilers. Could you give me your svg file generated?\r\nMine is shown below (I use MikTeX):\r\n```python\r\nMTex(\"hello\")\r\n```\r\n```svg\r\n<?xml version='1.0' encoding='UTF-8'?>\r\n<!-- This file was generated by dvisvgm 2.11.1 -->\r\n<svg version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='22.707525pt' height='7.291664pt' viewBox='88.501797 -56.729015 22.707525 7.291664'>\r\n<defs>\r\n<path id='g0-101' d='M1.963499-2.425498C2.267998-2.425498 3.044998-2.446498 3.569998-2.666998C4.304997-2.981998 4.357497-3.601497 4.357497-3.748497C4.357497-4.210497 3.958497-4.640997 3.233998-4.640997C2.068499-4.640997 .483-3.622497 .483-1.784999C.483-.714 1.102499 .1155 2.131499 .1155C3.632997 .1155 4.514997-.997499 4.514997-1.123499C4.514997-1.186499 4.451997-1.259999 4.388997-1.259999C4.336497-1.259999 4.315497-1.238999 4.252497-1.154999C3.422998-.1155 2.278498-.1155 2.152499-.1155C1.333499-.1155 1.238999-.997499 1.238999-1.333499C1.238999-1.459499 1.249499-1.784999 1.406999-2.425498H1.963499ZM1.469999-2.656498C1.879499-4.252497 2.960998-4.409997 3.233998-4.409997C3.727497-4.409997 4.010997-4.105497 4.010997-3.748497C4.010997-2.656498 2.330998-2.656498 1.900499-2.656498H1.469999Z'/>\r\n<path id='g0-104' d='M3.013498-7.171495C3.013498-7.181995 3.013498-7.286995 2.876998-7.286995C2.635498-7.286995 1.868999-7.202995 1.595999-7.181995C1.511999-7.171495 1.396499-7.160995 1.396499-6.971995C1.396499-6.845995 1.490999-6.845995 1.648499-6.845995C2.152499-6.845995 2.173498-6.772495 2.173498-6.667495L2.141999-6.457496L.6195-.4095C.5775-.2625 .5775-.2415 .5775-.1785C.5775 .063 .787499 .1155 .881999 .1155C1.049999 .1155 1.217999-.0105 1.270499-.1575L1.469999-.955499L1.700999-1.900499C1.763999-2.131499 1.826999-2.362498 1.879499-2.603998C1.900499-2.666998 1.984499-3.013498 1.994999-3.076498C2.026499-3.170998 2.351998-3.758997 2.708998-4.042497C2.939998-4.210497 3.265498-4.409997 3.716997-4.409997S4.283997-4.052997 4.283997-3.674997C4.283997-3.107998 3.884997-1.963499 3.632997-1.322999C3.548998-1.081499 3.496498-.955499 3.496498-.745499C3.496498-.252 3.863997 .1155 4.357497 .1155C5.344496 .1155 5.732996-1.417499 5.732996-1.501499C5.732996-1.606499 5.638496-1.606499 5.606996-1.606499C5.501996-1.606499 5.501996-1.574999 5.449496-1.417499C5.291996-.860999 4.955997-.1155 4.378497-.1155C4.199997-.1155 4.126497-.2205 4.126497-.462C4.126497-.724499 4.220997-.976499 4.315497-1.207499C4.483497-1.658999 4.955997-2.908498 4.955997-3.517498C4.955997-4.199997 4.535997-4.640997 3.748497-4.640997C3.086998-4.640997 2.582998-4.315497 2.194498-3.832497L3.013498-7.171495Z'/>\r\n<path id='g0-108' d='M2.708998-7.171495C2.708998-7.181995 2.708998-7.286995 2.572498-7.286995C2.330998-7.286995 1.564499-7.202995 1.291499-7.181995C1.207499-7.171495 1.091999-7.160995 1.091999-6.961495C1.091999-6.845995 1.196999-6.845995 1.354499-6.845995C1.858499-6.845995 1.868999-6.751495 1.868999-6.667495L1.837499-6.457496L.5145-1.207499C.483-1.091999 .462-1.018499 .462-.850499C.462-.252 .923999 .1155 1.417499 .1155C1.763999 .1155 2.026499-.0945 2.204998-.4725C2.393998-.871499 2.519998-1.480499 2.519998-1.501499C2.519998-1.606499 2.425498-1.606499 2.393998-1.606499C2.288998-1.606499 2.278498-1.564499 2.246998-1.417499C2.068499-.734999 1.868999-.1155 1.448999-.1155C1.133999-.1155 1.133999-.4515 1.133999-.5985C1.133999-.850499 1.144499-.902999 1.196999-1.102499L2.708998-7.171495Z'/>\r\n<path id='g0-111' d='M4.924497-2.866498C4.924497-3.958497 4.189497-4.640997 3.244498-4.640997C1.837499-4.640997 .4305-3.149998 .4305-1.658999C.4305-.6195 1.133999 .1155 2.110499 .1155C3.506998 .1155 4.924497-1.333499 4.924497-2.866498ZM2.120999-.1155C1.669499-.1155 1.207499-.441 1.207499-1.259999C1.207499-1.774499 1.480499-2.908498 1.816499-3.443998C2.341498-4.252497 2.939998-4.409997 3.233998-4.409997C3.842997-4.409997 4.157997-3.905997 4.157997-3.275998C4.157997-2.866498 3.947997-1.763999 3.548998-1.081499C3.181498-.4725 2.603998-.1155 2.120999-.1155Z'/>\r\n</defs>\r\n<g id='page1'>\r\n<g fill='#000001'>\r\n<use x='88.501797' y='-49.437352' xlink:href='#g0-104'/>\r\n<use x='94.551468' y='-49.437352' xlink:href='#g0-101'/>\r\n<use x='99.440545' y='-49.437352' xlink:href='#g0-108'/>\r\n<use x='102.780139' y='-49.437352' xlink:href='#g0-108'/>\r\n<use x='106.119733' y='-49.437352' xlink:href='#g0-111'/>\r\n</g>\r\n</g>\r\n</svg>\r\n```",
      "@YishiMichael Here is the svg generated by Tex('hello').   I can't generate using MTex because it keeps popping up the key errors.\r\nI use MikTex too.\r\n\r\n<?xml version='1.0' encoding='UTF-8'?>\r\n<!-- This file was generated by dvisvgm 2.11.1 -->\r\n<svg version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' width='22.707525pt' height='7.291664pt' viewBox='88.501797 -56.729015 22.707525 7.291664'>\r\n<defs>\r\n<path id='g0-101' d='M1.963499-2.425498C2.267998-2.425498 3.044998-2.446498 3.569998-2.666998C4.304997-2.981998 4.357497-3.601497 4.357497-3.748497C4.357497-4.210497 3.958497-4.640997 3.233998-4.640997C2.068499-4.640997 .483-3.622497 .483-1.784999C.483-.714 1.102499 .1155 2.131499 .1155C3.632997 .1155 4.514997-.997499 4.514997-1.123499C4.514997-1.186499 4.451997-1.259999 4.388997-1.259999C4.336497-1.259999 4.315497-1.238999 4.252497-1.154999C3.422998-.1155 2.278498-.1155 2.152499-.1155C1.333499-.1155 1.238999-.997499 1.238999-1.333499C1.238999-1.459499 1.249499-1.784999 1.406999-2.425498H1.963499ZM1.469999-2.656498C1.879499-4.252497 2.960998-4.409997 3.233998-4.409997C3.727497-4.409997 4.010997-4.105497 4.010997-3.748497C4.010997-2.656498 2.330998-2.656498 1.900499-2.656498H1.469999Z'/>\r\n<path id='g0-104' d='M3.013498-7.171495C3.013498-7.181995 3.013498-7.286995 2.876998-7.286995C2.635498-7.286995 1.868999-7.202995 1.595999-7.181995C1.511999-7.171495 1.396499-7.160995 1.396499-6.971995C1.396499-6.845995 1.490999-6.845995 1.648499-6.845995C2.152499-6.845995 2.173498-6.772495 2.173498-6.667495L2.141999-6.457496L.6195-.4095C.5775-.2625 .5775-.2415 .5775-.1785C.5775 .063 .787499 .1155 .881999 .1155C1.049999 .1155 1.217999-.0105 1.270499-.1575L1.469999-.955499L1.700999-1.900499C1.763999-2.131499 1.826999-2.362498 1.879499-2.603998C1.900499-2.666998 1.984499-3.013498 1.994999-3.076498C2.026499-3.170998 2.351998-3.758997 2.708998-4.042497C2.939998-4.210497 3.265498-4.409997 3.716997-4.409997S4.283997-4.052997 4.283997-3.674997C4.283997-3.107998 3.884997-1.963499 3.632997-1.322999C3.548998-1.081499 3.496498-.955499 3.496498-.745499C3.496498-.252 3.863997 .1155 4.357497 .1155C5.344496 .1155 5.732996-1.417499 5.732996-1.501499C5.732996-1.606499 5.638496-1.606499 5.606996-1.606499C5.501996-1.606499 5.501996-1.574999 5.449496-1.417499C5.291996-.860999 4.955997-.1155 4.378497-.1155C4.199997-.1155 4.126497-.2205 4.126497-.462C4.126497-.724499 4.220997-.976499 4.315497-1.207499C4.483497-1.658999 4.955997-2.908498 4.955997-3.517498C4.955997-4.199997 4.535997-4.640997 3.748497-4.640997C3.086998-4.640997 2.582998-4.315497 2.194498-3.832497L3.013498-7.171495Z'/>\r\n<path id='g0-108' d='M2.708998-7.171495C2.708998-7.181995 2.708998-7.286995 2.572498-7.286995C2.330998-7.286995 1.564499-7.202995 1.291499-7.181995C1.207499-7.171495 1.091999-7.160995 1.091999-6.961495C1.091999-6.845995 1.196999-6.845995 1.354499-6.845995C1.858499-6.845995 1.868999-6.751495 1.868999-6.667495L1.837499-6.457496L.5145-1.207499C.483-1.091999 .462-1.018499 .462-.850499C.462-.252 .923999 .1155 1.417499 .1155C1.763999 .1155 2.026499-.0945 2.204998-.4725C2.393998-.871499 2.519998-1.480499 2.519998-1.501499C2.519998-1.606499 2.425498-1.606499 2.393998-1.606499C2.288998-1.606499 2.278498-1.564499 2.246998-1.417499C2.068499-.734999 1.868999-.1155 1.448999-.1155C1.133999-.1155 1.133999-.4515 1.133999-.5985C1.133999-.850499 1.144499-.902999 1.196999-1.102499L2.708998-7.171495Z'/>\r\n<path id='g0-111' d='M4.924497-2.866498C4.924497-3.958497 4.189497-4.640997 3.244498-4.640997C1.837499-4.640997 .4305-3.149998 .4305-1.658999C.4305-.6195 1.133999 .1155 2.110499 .1155C3.506998 .1155 4.924497-1.333499 4.924497-2.866498ZM2.120999-.1155C1.669499-.1155 1.207499-.441 1.207499-1.259999C1.207499-1.774499 1.480499-2.908498 1.816499-3.443998C2.341498-4.252497 2.939998-4.409997 3.233998-4.409997C3.842997-4.409997 4.157997-3.905997 4.157997-3.275998C4.157997-2.866498 3.947997-1.763999 3.548998-1.081499C3.181498-.4725 2.603998-.1155 2.120999-.1155Z'/>\r\n</defs>\r\n<g id='page1'>\r\n<use x='88.501797' y='-49.437352' xlink:href='#g0-104'/>\r\n<use x='94.551468' y='-49.437352' xlink:href='#g0-101'/>\r\n<use x='99.440545' y='-49.437352' xlink:href='#g0-108'/>\r\n<use x='102.780139' y='-49.437352' xlink:href='#g0-108'/>\r\n<use x='106.119733' y='-49.437352' xlink:href='#g0-111'/>\r\n</g>\r\n</svg>\r\n",
      "> @YishiMichael Here is the svg generated by Tex('hello'). I can't generate using MTex because it keeps popping up the key errors. I use MikTex too.\r\n\r\nPlease open a new issue and attach your .svg file.",
      "> @YishiMichael Here is the svg generated by Tex('hello'). I can't generate using MTex because it keeps popping up the key errors. I use MikTex too.\r\n\r\nIt appears to me that the .svg file is successfully generated, and some error pops up when parsing it. You may look up where you store these intermediate files and find the specific .svg file. I need to check it to figure out whether it's generated in an unexpected style."
    ],
    "num_comments": 14,
    "repository": "3b1b/manim",
    "diff_length": 21064
  },
  {
    "index": 85,
    "pr_title": "Cleanup Dockerfile",
    "pr_body": "Thank you for making this tool available to everyone. This is just a tiny thing, the `Dockerfile` can be simplified by removing two packages that are installed anyways. The apt package texlive-full already includes texlive-latex-base and texlive-fonts-extra, so they don't have to installed separately.",
    "pr_number": 328,
    "comments": [
      "If you want you can remove this line as well, since the entire Python3 directory is deleted later.\r\nhttps://github.com/3b1b/manim/blob/8d66cfb75b2781e74f1de29d8e331f349aef03a8/Dockerfile#L21",
      "@eulertour Good idea. I've also consolidated the `apt install` calls into one single one and sprinkled some comments into there. How does it look?",
      "I think it's best not to consolidate the `apt install` commands because it obscures the logical flow of the installation (see [here](https://github.com/3b1b/manim/pull/301#issuecomment-425510200)). For example, the dockerfile won't work after 4ba9f6b5a31188c53cf51da618de351863a43348 is applied because `texlive` is installed before the time zone is setup (you'll get [this problem](https://askubuntu.com/questions/909277/avoiding-user-interaction-with-tzdata-when-installing-certbot-in-a-docker-contai)).",
      "The way it is now, `requirements.txt` will be left on the image since it gets copied in after the python 3 directory is deleted. Additionally, the time zone setup is still separated from the texlive install, which makes it unclear why it is necessary (although it was admittedly pretty unclear before as well).\r\n\r\nI'd recommend moving the time zone setup to just before the texlive install, mentioning in the comment that the time zone setup is required by texlive, and getting rid of `requirements.txt` somehow, either by deleting it with the python 3 directory or adding another `rm` for it afterward.",
      "Can you confirm that it now works as intended and that it makes sense?",
      "This looks fine. The comment says textlive instead of texlive, but that's a nitpick.",
      "It's best to have all the `apt install`ing that van be done at once all be done in one `RUN` command.  That way it only creates one layer, saving the end user a bunch of disk space.\r\n\r\nTo make the list of dependencies clear, use backslashes:\r\n\r\n```Dockerfile\r\nRUN apt install -y \\\r\n  build-essential \\\r\n  something-else \\\r\n  yet-another-package\r\n```",
      "@Asday You're completely right, this dockerfile is ridiculous.",
      "The good news is that the dockerfile is now much simpler. The bad news is that the image is actually _larger_ now, up to 5.72 GB from 4.28 GB."
    ],
    "num_comments": 9,
    "repository": "3b1b/manim",
    "diff_length": 2026
  },
  {
    "index": 86,
    "pr_title": "Fix spelling errors",
    "pr_body": "",
    "pr_number": 36,
    "comments": [
      "why \"Explain stateless vs. stateful\" needs a question mark?\r\nIf it was \"Can you Explain stateless vs. stateful?\" I understand but why the first form requires a question mark?",
      "> why \"Explain stateless vs. stateful\" needs a question mark?\r\n> If it was \"Can you Explain stateless vs. stateful?\" I understand but why the first form requires a question mark?\r\n\r\nYou are right. The first form is correct, indirect questions do not get question marks. I'll change it back to the first form. \r\n\r\n",
      "Thanks for the effort but I still see question marks where it shouldn't be. Like here:\r\n\r\n\"Describe the workflow of setting up some type of web server?\"",
      "Accidently closed it. See my comment above.",
      "I removed all the changes to question marks. Only the spelling fixes are included now. ",
      "That's great (I see we had quite a lot :X) Thank you for the effort."
    ],
    "num_comments": 6,
    "repository": "bregman-arie/devops-exercises",
    "diff_length": 18547
  },
  {
    "index": 87,
    "pr_title": "Feature/new perl regex questions and answers",
    "pr_body": "",
    "pr_number": 186,
    "comments": [
      "Nice. I think we might want to have a whole separate section for regular expression exercises, but that's for another commit.",
      "How do you think is the best way to do it? Create a new `perl` folder in the `exercises` directory and:\r\n\r\n1. Move the whole Perl section\r\n2. Move just the Perl regex section and create a table in the main perl README",
      "> How do you think is the best way to do it? Create a new `perl` folder in the `exercises` directory and:\r\n> \r\n> 1. Move the whole Perl section\r\n> 2. Move just the Perl regex section and create a table in the main perl README\r\n\r\nPerl section should move entirely to exercises/perl/README.md as it will be done for all the other sections.\r\nWhat I was thinking about regex is to create exercises/regex/README.md and combine all the regex questions there from all the different sections (Perl, Python, ...). What do you think? or is it better to have separate regex questions for each programming language? I'm open to any idea at this point",
      "> > How do you think is the best way to do it? Create a new `perl` folder in the `exercises` directory and:\r\n> > \r\n> > 1. Move the whole Perl section\r\n> > 2. Move just the Perl regex section and create a table in the main perl README\r\n> \r\n> Perl section should move entirely to exercises/perl/README.md as it will be done for all the other sections. What I was thinking about regex is to create exercises/regex/README.md and combine all the regex questions there from all the different sections (Perl, Python, ...). What do you think? or is it better to have separate regex questions for each programming language? I'm open to any idea at this point\r\n\r\nPerfect, I'll move the whole section then. It will be better.\r\n\r\nI think it's better to have separated regex sections for every language. Python does not have all the features of the `PCRE` and there are differences using the `re` module.\r\n\r\n[Regular expressions in Python and Perl](https://www.johndcook.com/blog/python_regex/)\r\n\r\nLet me know what do you think about and we can make the change as you think it's better.",
      "> > > How do you think is the best way to do it? Create a new `perl` folder in the `exercises` directory and:\r\n> > > \r\n> > > 1. Move the whole Perl section\r\n> > > 2. Move just the Perl regex section and create a table in the main perl README\r\n> > \r\n> > \r\n> > Perl section should move entirely to exercises/perl/README.md as it will be done for all the other sections. What I was thinking about regex is to create exercises/regex/README.md and combine all the regex questions there from all the different sections (Perl, Python, ...). What do you think? or is it better to have separate regex questions for each programming language? I'm open to any idea at this point\r\n> \r\n> Perfect, I'll move the whole section then. It will be better.\r\n> \r\n> I think it's better to have separated regex sections for every language. Python does not have all the features of the `PCRE` and there are differences using the `re` module.\r\n> \r\n> [Regular expressions in Python and Perl](https://www.johndcook.com/blog/python_regex/)\r\n> \r\n> Let me know what do you think about and we can make the change as you think it's better.\r\n\r\nSounds good to me. Let's then move Perl to the exercises directory and keep the regex sections separated. ",
      "> Sounds good to me. Let's then move Perl to the exercises directory and keep the regex sections separated.\r\n\r\nPerfect. I'll do the change.\r\n\r\nTyvm!\r\n\r\n"
    ],
    "num_comments": 6,
    "repository": "bregman-arie/devops-exercises",
    "diff_length": 3056
  },
  {
    "index": 88,
    "pr_title": "feat: Implement hair swapping and enhance realism",
    "pr_body": "This commit introduces the capability to swap hair along with the face from a source image to a target image/video or live webcam feed.\r\n\r\nKey changes include:\r\n\r\n1.  **Hair Segmentation:**\r\n    - Integrated the `isjackwild/segformer-b0-finetuned-segments-skin-hair-clothing` model from Hugging Face using the `transformers` library.\r\n    - Added `modules/hair_segmenter.py` with a `segment_hair` function to produce a binary hair mask from an image.\r\n    - Updated `requirements.txt` with `transform",
    "pr_number": 1298,
    "comments": [
      "Looks great! Awesome work but is very slow on live. Can you create a toggle to enable/disable the effects?",
      "yes i made some changes, please let me know ",
      "Will be reviewing this over the weekend! Thanks!",
      "As per testing, I have encountered this\r\n\r\nTraceback (most recent call last):\r\n  File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\run.py\", line 6, in <module>\r\n    core.run()\r\n  File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\modules\\core.py\", line 257, in run\r\n    if hasattr(frame_processor, 'pre_start') and not frame_processor.pre_start(status_fn_callback=update_status): # Pass callback here\r\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\modules\\processors\\frame\\face_swapper.py\", line 68, in pre_start\r\n    status_fn_callback(\"Select an image for source path.\", NAME)\r\n  File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\modules\\core.py\", line 176, in update_status\r\n    ui.update_status(message)\r\n  File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\modules\\ui.py\", line 573, in update_status\r\n    status_label.configure(text=_(text))\r\n    ^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'NoneType' object has no attribute 'configure'",
      "Same error. I also run your fork on my computer to ensure if i'm missing something  and it have similar error. Will also investigate my environment on this. But the push 5 days ago works great (i'll just add toggle on that).",
      "how do i make my model mouth stop warping i am not very tech savvy but i have been able to navigate my way to install and run the app properly . but the mouth still doesn't warp well."
    ],
    "num_comments": 6,
    "repository": "hacksider/Deep-Live-Cam",
    "diff_length": 114521
  },
  {
    "index": 89,
    "pr_title": "UI, D&D, Opacity, Hotswap",
    "pr_body": "## Summary by Sourcery\n\nEnhance the UI with a new dropdown menu and reorganize layout for better usability. Add features for saving and loading switch states, and implement face opacity and mouth mask in face swapping. Update documentation with new media paths and additional guidance.\n\nNew Features:\n- Introduce a new ModernOptionMenu class for improved UI dropdown functionality.\n- Add functionality to save and load switch states to a JSON file for persistent settings.\n- Implement face opacity an",
    "pr_number": 746,
    "comments": [
      "Awesome work @KRSHH but there's still frame dips on the new theme. \r\n\r\nhttps://github.com/user-attachments/assets/23495085-1d90-4497-8d92-c6b7416174cc\r\n\r\n\r\nhttps://github.com/user-attachments/assets/9b127668-97fe-4028-bf12-8ce4e4b62eb5\r\n\r\nSee comparison video on the push",
      "what is mask size and mask feather pls",
      "> what is mask size and mask feather pls\r\n\r\nThis PR is still not there. use main",
      "i don't get what you mean by main but bro i used yours/pulled yours into my project and its working very well, in terms of performance with my GPU i was having performance issues with the main one and also some issues with the slider but this one is working perfectly, but i don't know what mask size and mask feather is so i wanted to know if its something that will help me, the \"show fps\" button really helped me out honestly thansk",
      "> i don't get what you mean by main but bro i used yours/pulled yours into my project and its working very well, in terms of performance with my GPU i was having performance issues with the main one and also some issues with the slider but this one is working perfectly, but i don't know what mask size and mask feather is so i wanted to know if its something that will help me, the \"show fps\" button really helped me out honestly thansk\r\n\r\nMask size is the size of the cropping of mouth region from faceswap and feather is the smoothening of it. you can see it by enabling show mouth box\r\n\r\nHow much FPS are you getting on main compared to this?",
      "thanks, I'm getting at least 4 times more fps when I use this one with CUDA or tensorrt when i was using main I was getting max 0.8 fps with my NVIDIA RTX 6GB graphics card(on main CUDA isnt working so i could only use CPU), when i used this I'm getting from 2.9 to 6fps on CUDA and tensorrt, using CPU gives me like 1.8, now the difference between 0.8 and 2.9 fps is very big and its more than enough for me \r\ni just need to find a good webcam because some webcams slow it down so thanks a lot",
      "it seems like the repo maintainers actively try to keep its quality down, the install complicated and push for a paid compiled version but i could be misunderstanding things. thankfully there better forks",
      "You can actually use this if you want but I won't be pushing anything that will make everything slower @hexxt-git ‚ò∫Ô∏è"
    ],
    "num_comments": 8,
    "repository": "hacksider/Deep-Live-Cam",
    "diff_length": 64068
  },
  {
    "index": 90,
    "pr_title": "BOUNTY - Webcam Merged (tested)",
    "pr_body": "## Summary by Sourcery\n\nAdd camera selection and face opacity adjustment features to the UI, enhancing the webcam preview functionality. Update the README to reflect completed tasks and introduce a bug report template for better issue tracking.\n\nNew Features:\n- Introduce a camera selection feature in the UI, allowing users to choose from available cameras for webcam preview.\n- Add a face opacity slider to the UI, enabling users to adjust the transparency of the face overlay in real-time.\n\nEnhanc",
    "pr_number": 686,
    "comments": [
      "Hi there, as per testing it's throwing errors.\r\n\r\n`TypeError: webcam_preview() missing 1 required positional argument: 'camera_index'\r\nException in Tkinter callback\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\My Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1967, in __call__\r\n    return self.func(*args)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\venv\\Lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_button.py\", line 554, in _clicked\r\n    self._command()\r\n  File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\modules\\ui.py\", line 410, in <lambda>\r\n    command=lambda: webcam_preview(root),\r\n                    ^^^^^^^^^^^^^^^^^^^^\r\nTypeError: webcam_preview() missing 1 required positional argument: 'camera_index'\r\nException in Tkinter callback\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\My Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1967, in __call__\r\n    return self.func(*args)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\venv\\Lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_button.py\", line 554, in _clicked\r\n    self._command()\r\n  File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\modules\\ui.py\", line 410, in <lambda>\r\n    command=lambda: webcam_preview(root),\r\n                    ^^^^^^^^^^^^^^^^^^^^\r\nTypeError: webcam_preview() missing 1 required positional argument: 'camera_index'`",
      "> Hi there, as per testing it's throwing errors.\r\n> \r\n> `TypeError: webcam_preview() missing 1 required positional argument: 'camera_index' Exception in Tkinter callback Traceback (most recent call last): File \"C:\\Users\\My Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1967, in __call__ return self.func(*args) ^^^^^^^^^^^^^^^^ File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\venv\\Lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_button.py\", line 554, in _clicked self._command() File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\modules\\ui.py\", line 410, in <lambda> command=lambda: webcam_preview(root), ^^^^^^^^^^^^^^^^^^^^ TypeError: webcam_preview() missing 1 required positional argument: 'camera_index' Exception in Tkinter callback Traceback (most recent call last): File \"C:\\Users\\My Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1967, in __call__ return self.func(*args) ^^^^^^^^^^^^^^^^ File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\venv\\Lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_button.py\", line 554, in _clicked self._command() File \"E:\\Deep-Live-Cam\\Deep-Live-Cam\\modules\\ui.py\", line 410, in <lambda> command=lambda: webcam_preview(root), ^^^^^^^^^^^^^^^^^^^^ TypeError: webcam_preview() missing 1 required positional argument: 'camera_index'`\r\n\r\n@hacksider fixed this issue. Tested the code and it does launch a preview window for me but my laptop is under powered to actually see the final result. Could you test it and find out? Also any suggestions for the placement of the selection text and menu would be appreciated",
      "Still same error after testing :)\r\n![image](https://github.com/user-attachments/assets/e896ac3f-ea08-4810-afc5-038d4793d8d5)\r\n",
      "> Still same error after testing :) ![image](https://private-user-images.githubusercontent.com/1267200/373139223-e896ac3f-ea08-4810-afc5-038d4793d8d5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc5NDc2ODcsIm5iZiI6MTcyNzk0NzM4NywicGF0aCI6Ii8xMjY3MjAwLzM3MzEzOTIyMy1lODk2YWMzZi1lYTA4LTQ4MTAtYWZjNS0wMzhkNDc5M2Q4ZDUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMDNUMDkyMzA3WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZDJhOTNlZTgwYWFlYWYyMWRiMDM4YzcxM2QxZmQzNzc0ZDllYmZjOTgyYzU3NjQ0ZGNhMzhlYTM0OTI1MjY4MCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.UWOg3pmaZFrGBrEg85EDxmr7Q-fXTehkvWU1-113u0o)\r\n\r\nCould you try git pulling the repo once? I can see that I am calling the function with the correct arguements on my side.",
      "Awesome! Works really well! Can you put your paypal link here?",
      "> Awesome! Works really well! Can you put your paypal link here?\r\n\r\nHi, I sent you an email because I wasn't comfortable sending my paypal email. Could you check to see if you received it?"
    ],
    "num_comments": 6,
    "repository": "hacksider/Deep-Live-Cam",
    "diff_length": 10591
  },
  {
    "index": 91,
    "pr_title": "Updates for metal / GPU and performance improves on Silicon Macs",
    "pr_body": "<!-- Generated by sourcery-ai[bot]: start summary -->\n\n## Summary by Sourcery\n\nEnhance performance on Silicon Macs by adding Metal support and updating default settings for video encoding and execution providers. Improve resource management and refactor code for better organization. Update documentation to reflect these changes.\n\nNew Features:\n- Introduce Metal support for improved performance on macOS devices, particularly Silicon Macs.\n\nEnhancements:\n- Change default video encoder to 'libx265'",
    "pr_number": 295,
    "comments": [
      "The package `customtkinter` is still needed to launch the UI, otherwise:\r\n\r\n```\r\npython run.py --execution-provider coreml\r\nTraceback (most recent call last):\r\n  File \"/Users/easto/deep-live-cam-tmp/Deep-Live-Cam/run.py\", line 3, in <module>\r\n    from modules import core\r\n  File \"/Users/easto/deep-live-cam-tmp/Deep-Live-Cam/modules/core.py\", line 22, in <module>\r\n    import modules.ui as ui\r\n  File \"/Users/easto/deep-live-cam-tmp/Deep-Live-Cam/modules/ui.py\", line 3, in <module>\r\n    import customtkinter as ctk\r\nModuleNotFoundError: No module named 'customtkinter'\r\n```",
      "I have tried your PR on the latest commit, on an M2 Pro, and still get very low FPS. I don't hear my fans kick in and my GPU usage is pretty low, do you think there is any way to improve it ?",
      "Checking activity monitor, this still uses the CPU only. Compared to\r\nnsfw-roop where it does use the GPU.\r\n\r\nOn Wed, Aug 14, 2024 at 03:13 hvmzx ***@***.***> wrote:\r\n\r\n> I have tried your PR on the latest commit, on an M2 Pro, and still get\r\n> very low FPS. I don't hear my fans kick in and my GPU usage is pretty low,\r\n> do you think there is any way to improve it ?\r\n>\r\n> ‚Äî\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/hacksider/Deep-Live-Cam/pull/295#issuecomment-2288369090>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAG436LKMRPJXGSTNP4PKH3ZRMUU7AVCNFSM6AAAAABMOZGEDOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEOBYGM3DSMBZGA>\r\n> .\r\n> You are receiving this because you commented.Message ID:\r\n> ***@***.***>\r\n>\r\n",
      "> Checking activity monitor, this still uses the CPU only. Compared to nsfw-roop where it does use the GPU.\r\n> [‚Ä¶](#)\r\n> On Wed, Aug 14, 2024 at 03:13 hvmzx ***@***.***> wrote: I have tried your PR on the latest commit, on an M2 Pro, and still get very low FPS. I don't hear my fans kick in and my GPU usage is pretty low, do you think there is any way to improve it ? ‚Äî Reply to this email directly, view it on GitHub <[#295 (comment)](https://github.com/hacksider/Deep-Live-Cam/pull/295#issuecomment-2288369090)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAG436LKMRPJXGSTNP4PKH3ZRMUU7AVCNFSM6AAAAABMOZGEDOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEOBYGM3DSMBZGA> . You are receiving this because you commented.Message ID: ***@***.***>\r\n\r\nGetting the same on mac M1",
      "@jasonkneen \r\n\r\n## Issue 1\r\nRunning fails since the detection sized has changed:\r\n```\r\ndef get_face_analyser() -> Any:\r\n    global FACE_ANALYSER\r\n\r\n    if FACE_ANALYSER is None:\r\n        FACE_ANALYSER = insightface.app.FaceAnalysis(name='buffalo_l', providers=modules.globals.execution_providers)\r\n        FACE_ANALYSER.prepare(ctx_id=0, det_size=(1280, 720))\r\n    return FACE_ANALYSER\r\n ```\r\n \r\n Reverting back to \r\n ```\r\n         FACE_ANALYSER.prepare(ctx_id=0, det_size=(640, 640))\r\n```\r\nworks.\r\nError:\r\n\r\n```\r\n(venv) [easto@MacBook-Pro][/tmp/Deep-Live-Cam]$ python run.py --execution-provider coreml  --execution-threads 12\r\nFrame processor face_enhancer not found\r\nDownloading: 56.0kB [00:00, 213kB/s]                                                                                                                                                                       \r\nONNX Runtime version: 1.16.3\r\nAvailable execution providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider']\r\nSelected execution provider: CoreMLExecutionProvider (with CPU fallback for face detection)\r\nTensorFlow devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nTensorFlow is using GPU (Metal)\r\nPyTorch is using MPS (Metal Performance Shaders)\r\nFrame processor face_enhancer not found\r\nApplied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\nfind model: /Users/easto/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\r\nApplied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\nfind model: /Users/easto/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\r\nApplied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\nfind model: /Users/easto/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\r\nApplied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\nfind model: /Users/easto/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\r\nApplied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\nfind model: /Users/easto/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\r\nset det-size: (1280, 720)\r\n2024-08-21 12:28:23.815556 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running CoreML_9447659792891585317_6 node. Name:'CoreMLExecutionProvider_CoreML_9447659792891585317_6_6' Status Message: Exception: /Users/cansik/git/private/onnxruntime-silicon/onnxruntime/onnxruntime/core/providers/coreml/model/model.mm:63 InlinedVector<int64_t> (anonymous namespace)::GetStaticOutputShape(gsl::span<const int64_t>, gsl::span<const int64_t>, const logging::Logger &) inferred_shape.size() == coreml_static_shape.size() was false. CoreML static output shape ({1,1,1,7200,1}) and inferred shape ({3200,1}) have different ranks.\r\n\r\nException in Tkinter callback\r\nTraceback (most recent call last):\r\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tkinter/__init__.py\", line 1967, in __call__\r\n    return self.func(*args)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/Deep-Live-Cam/venv/lib/python3.11/site-packages/customtkinter/windows/widgets/ctk_button.py\", line 554, in _clicked\r\n    self._command()\r\n  File \"/private/tmp/Deep-Live-Cam/modules/ui.py\", line 97, in <lambda>\r\n    start_button = ctk.CTkButton(root, text='Start', cursor='hand2', command=lambda: select_output_path(start))\r\n                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/Deep-Live-Cam/modules/ui.py\", line 194, in select_output_path\r\n    start()\r\n  File \"/private/tmp/Deep-Live-Cam/modules/core.py\", line 135, in start\r\n    if not frame_processor.pre_start():\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/Deep-Live-Cam/modules/processors/frame/face_swapper.py\", line 28, in pre_start\r\n    elif not get_one_face(cv2.imread(modules.globals.source_path)):\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/Deep-Live-Cam/modules/face_analyser.py\", line 20, in get_one_face\r\n    face = get_face_analyser().get(frame)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/Deep-Live-Cam/venv/lib/python3.11/site-packages/insightface/app/face_analysis.py\", line 59, in get\r\n    bboxes, kpss = self.det_model.detect(img,\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/Deep-Live-Cam/venv/lib/python3.11/site-packages/insightface/model_zoo/retinaface.py\", line 224, in detect\r\n    scores_list, bboxes_list, kpss_list = self.forward(det_img, self.det_thresh)\r\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/Deep-Live-Cam/venv/lib/python3.11/site-packages/insightface/model_zoo/retinaface.py\", line 152, in forward\r\n    net_outs = self.session.run(self.output_names, {self.input_name : blob})\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/Deep-Live-Cam/venv/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 220, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running CoreML_9447659792891585317_6 node. Name:'CoreMLExecutionProvider_CoreML_9447659792891585317_6_6' Status Message: Exception: /Users/cansik/git/private/onnxruntime-silicon/onnxruntime/onnxruntime/core/providers/coreml/model/model.mm:63 InlinedVector<int64_t> (anonymous namespace)::GetStaticOutputShape(gsl::span<const int64_t>, gsl::span<const int64_t>, const logging::Logger &) inferred_shape.size() == coreml_static_shape.size() was false. CoreML static output shape ({1,1,1,7200,1}) and inferred shape ({3200,1}) have different ranks.\r\n```\r\n\r\n## Issue 2\r\nAdditionally, `nsfw` is missing from `modules/globals`:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/private/tmp/Deep-Live-Cam/run.py\", line 6, in <module>\r\n    core.run()\r\n  File \"/private/tmp/Deep-Live-Cam/modules/core.py\", line 247, in run\r\n    start()\r\n  File \"/private/tmp/Deep-Live-Cam/modules/core.py\", line 154, in start\r\n    if modules.globals.nsfw == False:\r\n       ^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: module 'modules.globals' has no attribute 'nsfw'\r\n```\r\nAdding `nsfw = None` fixes the error.\r\n\r\n## GPU Usage\r\n\r\nLastly, this still fails to use the GPU on Apple Silicon (MacBook Pro M2 Max):\r\n\r\n```\r\nFrame processor face_enhancer not found\r\nONNX Runtime version: 1.16.3\r\nAvailable execution providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider']\r\nSelected execution provider: CoreMLExecutionProvider (with CPU fallback for face detection)\r\nTensorFlow devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nTensorFlow is using GPU (Metal)\r\nPyTorch is using MPS (Metal Performance Shaders)\r\nFrame processor face_enhancer not found\r\nApplied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\nfind model: /Users/easto/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\r\nApplied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\nfind model: /Users/easto/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\r\nApplied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\nfind model: /Users/easto/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\r\nApplied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\nfind model: /Users/easto/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\r\nApplied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\nfind model: /Users/easto/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\r\nset det-size: (640, 640)\r\n[DLC.CORE] Creating temp resources...\r\n[DLC.CORE] Extracting frames...\r\nFrame processor face_enhancer not found\r\n[DLC.FACE-SWAPPER] Progressing...\r\nProcessing:   0%|                                                                         | 0/1626 [00:00<?, ?frame/s, execution_providers=['CoreMLExecutionProvider'], execution_threads=12, max_memory=6]Applied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\r\ninswapper-shape: [1, 3, 128, 128]\r\nProcessing:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 1023/1626 [01:21<00:46, 12.97frame/s, execution_providers=['CoreMLExecutionProvider'], execution_threads=12, max_memory=6]\r\n```\r\n<img width=\"1460\" alt=\"Screenshot 2024-08-21 at 12 48 04\" src=\"https://github.com/user-attachments/assets/d5a52be0-ae24-411d-a8cc-7d855ef992da\">\r\n",
      "@hacksider this should not be merged yet as GPU support does not work for mac (still uses CPU)",
      "> Mine uses metal and the GPU. \n\nMyself and the 5 other users in this PR all of us don't see GPU being used in the activity monitor and it's very slow. Even with your latest commit :( "
    ],
    "num_comments": 7,
    "repository": "hacksider/Deep-Live-Cam",
    "diff_length": 21349
  },
  {
    "index": 92,
    "pr_title": "Better UI",
    "pr_body": "This PR introduces a significant overhaul of the user interface, focusing on a more modern aesthetic and a more intuitive layout. \r\n\r\n**Key Changes:**\r\n\r\n- **Modern Design Language:** Implemented a modern design language using CustomTkinter's capabilities, featuring a dark theme, updated color palettes, and rounded corners for buttons and frames.\r\n- **Improved Layout:**  Reorganized the main window using a grid layout for better organization and responsiveness. Source and target sections are now",
    "pr_number": 592,
    "comments": [
      "@KRSHH Looks really good but can you align the switches. We don't want too many movements when choosing between the tabs. For user experience, it will be better to just either move horizontal or vertical, not diagonal. Thanks in advance dude! Really makes the UI looks fresh :)",
      "> @KRSHH Looks really good but can you align the switches. We don't want too many movements when choosing between the tabs. For user experience, it will be better to just either move horizontal or vertical, not diagonal. Thanks in advance dude! Really makes the UI looks fresh :)\r\n\r\nI just made them all vertical.\r\n+Make me a collaborator",
      "@hacksider \r\n![2024-09-16 19-12-28](https://github.com/user-attachments/assets/345ed1b2-a3ab-4f36-997c-e2f8bdfe130b)\r\n\r\n\r\n",
      "Will add you a collaborator as soon as we have enough activities going. It'll be hard if there's too many chefs on the kitchen :)",
      "I have to undo the commit as per testing the \"face mapping\" stopped working. Will have to do a thorough test on it on a fork of mine, this is what happens when I got too excited on new features ü§£ ",
      "Its working fine on my end tho...",
      "All the features are working fine, even the face mapper (In my testing)\r\n![2024-09-16 20-29-38 (2)](https://github.com/user-attachments/assets/061e47ec-0ce1-4fda-9ab9-0c1f8693313a)\r\n\r\n",
      "Can you try commiting it again? I'll try it again on my fork :)",
      "Commited again, made another PR too..."
    ],
    "num_comments": 9,
    "repository": "hacksider/Deep-Live-Cam",
    "diff_length": 25246
  },
  {
    "index": 93,
    "pr_title": "Two face feature and multi target face placement control",
    "pr_body": "### Two Face Feature and Face Controls\r\nAdded a new feature that can work with two faces in source image and replace two target faces on webcam, video or image. You can select a source image that has one or two faces. Left face in source image will replace left target face and right face in source image will replace right target face. You can also control how one face is replaced if two target faces are on webcam, video or image from left or right. \r\n\r\n### Two faces replaced on webcam\r\n\r\n![DemoT",
    "pr_number": 398,
    "comments": [
      "@iVideoGameBoss Thank you for the pull request. Before I do a merging into the branch, could you please update the codes to support multiple faces? This will ensure the feature is more versatile and can handle various scenarios. Thanks!",
      "> @iVideoGameBoss Thank you for the pull request. Before I do a merging into the branch, could you please update the codes to support multiple faces? This will ensure the feature is more versatile and can handle various scenarios. Thanks!\r\n\r\n\"Thank you for reviewing my pull request! I appreciate the feedback.\r\n\r\nTo clarify, the code already supports multiple faces. Here‚Äôs how it works:\r\n\r\n**Multiple Source Faces:** The program can handle either one or two source faces. When two source faces are provided, the first detected target face from the left is replaced with the first source face, and the next detected face is replaced with the second source face. If there are more than two faces on the target frame, then the first two detected faces from the left are replaced.\r\n\r\n\r\n**Single Source Face:** When only one source face is provided, it‚Äôs duplicated internally to ensure the same functionality. The 'show both faces' option will replace the first detected face with the left source face and the next one with the right source face.\r\n\r\n\r\n**Behavior Consistency:** The 'many faces' option works as before, replacing all detected faces with the left source face by default. If there are two source faces, you can choose which one to use for the 'many faces' option with the flip feature that I will add.\r\n\r\nThis approach keeps the functionality consistent with previous versions while adding flexibility for handling multiple faces. \r\n\r\nI will add code to support to many face option so you can at least flip which source face to use.",
      "> @iVideoGameBoss Thank you for the pull request. Before I do a merging into the branch, could you please update the codes to support multiple faces? This will ensure the feature is more versatile and can handle various scenarios. Thanks!\r\n\r\nI added two face flip support to many face option. So when you have two faces in source image and one, two or more faces in target, You can flip between the two faces on many face option. As mentioned above, when you have one source face it will also be loaded as second face. So when you flip a face it still remains same face and will work with many face option.  ",
      "@iVideoGameBoss Sorry for the late reply. This function takes time to review when I'm busy, so I cannot reply quickly.\r\n\r\nYour PR seem only support two faces, it seems does not cover to support multiple faces. The design should:\r\n1. List all person faces in the image/video/frame.\r\n2. Add a UI to pick the replacement face for each one to create a list of face mappings.\r\n3. Then, based on this mapping, swap faces during Start/Live.\r\n\r\nThis will ensure the feature is more versatile and can handle various scenarios, and better for maintaining the codes later.\r\n\r\nI appreciate your contribution, but If you do not have time to update your codes. Please wait for support of the multiple faces in the later version. Thanks.\r\n\r\nLike this\r\n![image](https://github.com/user-attachments/assets/64b2b39b-1e01-4a3a-a997-eb60df65f3ca)",
      "@iVideoGameBoss just want to ask if you want to be a collaborator of this repo :) I saw you're doing a lot of stuffs and I want the community to see your visions as well.",
      "> @iVideoGameBoss just want to ask if you want to be a collaborator of this repo :) I saw you're doing a lot of stuffs and I want the community to see your visions as well.\r\n\r\nsure. that would be really cool"
    ],
    "num_comments": 6,
    "repository": "hacksider/Deep-Live-Cam",
    "diff_length": 29719
  },
  {
    "index": 94,
    "pr_title": "Add PaddlePaddle Implementation",
    "pr_body": "",
    "pr_number": 1198,
    "comments": [
      "Initiated evaluation from scratch: \r\nhttp://ci.d2l.ai/blue/organizations/jenkins/d2l-zh/detail/PR-1198/1/pipeline\r\nhttp://ci.d2l.ai/blue/organizations/jenkins/d2l-zh/detail/PR-1198/2/pipeline/\r\nhttp://ci.d2l.ai/blue/organizations/jenkins/d2l-zh/detail/PR-1198/3/pipeline/",
      "> LGTM\r\n\r\n![Screen Shot 2022-08-27 at 4 28 26 PM](https://user-images.githubusercontent.com/22279212/187051392-f6e06959-c590-48cb-bcda-b1779f03c4b0.png)\r\n\r\nPer http://ci.d2l.ai/blue/organizations/jenkins/d2l-zh/detail/PR-1198/3/pipeline/, it looks that the paddle evaluation runs significantly longer (1h47m) than implementation with other frameworks (pytorch 38m). Could you look into the complete log (click \"Show Complete Log\") and identify individual notebooks that take longer to evaluate? Can you improve the efficiency? \r\n\r\nFor example:\r\n\r\n1. why is there this error:\r\n\r\n![Screen Shot 2022-08-27 at 4 31 31 PM](https://user-images.githubusercontent.com/22279212/187051458-84cdc9dc-2ada-4db9-8fe0-64a9becd7f20.png)\r\n\r\n2. In paddle complete log:\r\n```\r\n[d2lbook:resource.py:L223] INFO   Task \"Evaluating ./chapter_computer-vision/image-augmentation.md\" on CPU [1], GPU [1, 0] is finished in 00:12:19\r\n```\r\n\r\nIn pytorch complete log:\r\n```\r\n[d2lbook:resource.py:L223] INFO   Task \"Evaluating ./chapter_computer-vision/image-augmentation.md\" on CPU [3], GPU [1, 3] is finished in 00:02:36\r\n```\r\n\r\nThere can be more examples like the above.\r\n\r\n\r\n",
      "Hi, @astonzhang, I would like to know how to make the CI build the whole project again? it seems that the CI only builds the files that I modified.",
      "we started a CI from scratch. @w5688414 ",
      "> we started a CI from scratch. @w5688414\r\n\r\nHi, @cheungdaven   Could you please rebuild whole projects, it seems that I can't rerun the whole project by myself.",
      "Hi, @astonzhang , I removed multi gpu training, because paddle doesn't support multi gpu training on notebooks, so it takes about 50mins to build the paddle version's of d2l notebooks.\r\n\r\n![image](https://user-images.githubusercontent.com/12107462/189269649-a88b993c-b784-45dd-8709-bb19a926a798.png)\r\n\r\nwhat's more, I can't reproduce the error on my local machine, it seems that the error won't affect the building procedure, is this a serivous problem? can you give me some suggestions?\r\n\r\n```\r\n--------------------------------------\r\n\r\nC++ Traceback (most recent call last):\r\n\r\n--------------------------------------\r\n\r\nNo stack trace in paddle, may be caused by external reasons.\r\n\r\n\r\n\r\n----------------------\r\n\r\nError Message Summary:\r\n\r\n----------------------\r\n\r\nFatalError: `Termination signal` is detected by the operating system.\r\n\r\n  [TimeInfo: *** Aborted at 1662692867 (unix time) try \"date -d @1662692867\" if you are using GNU date ***]\r\n\r\n  [SignalInfo: *** SIGTERM (@0x3e900017699) received by PID 95900 (TID 0x7f2bcf693080) from PID 95897 ***]\r\n```",
      "> Hi, @astonzhang , I removed multi gpu training, because paddle doesn't support multi gpu training on notebooks, so ti takes about 50mins to build the paddle version's of d2l notebooks.\r\n> \r\n> ![image](https://user-images.githubusercontent.com/12107462/189269649-a88b993c-b784-45dd-8709-bb19a926a798.png)\r\n> \r\n> what's more, I can't reproduce the error on my local machine, it seems that the error won't affect the building procedure, is this a serivous problem? can you give me some suggestions?\r\n> \r\n> ```\r\n> --------------------------------------\r\n> \r\n> C++ Traceback (most recent call last):\r\n> \r\n> --------------------------------------\r\n> \r\n> No stack trace in paddle, may be caused by external reasons.\r\n> \r\n> \r\n> \r\n> ----------------------\r\n> \r\n> Error Message Summary:\r\n> \r\n> ----------------------\r\n> \r\n> FatalError: `Termination signal` is detected by the operating system.\r\n> \r\n>   [TimeInfo: *** Aborted at 1662692867 (unix time) try \"date -d @1662692867\" if you are using GNU date ***]\r\n> \r\n>   [SignalInfo: *** SIGTERM (@0x3e900017699) received by PID 95900 (TID 0x7f2bcf693080) from PID 95897 ***]\r\n> ```\r\n\r\nCan you follow https://github.com/d2l-ai/d2l-zh/blob/paddle/Jenkinsfile and run \r\n```\r\npip install git+https://github.com/d2l-ai/d2l-book\r\nd2lbook build eval --tab paddle\r\n```\r\nto try reproducing the error?",
      "@xiaotinghe Can you review this PR and make sure it doesn't affect the content within the scope of our forthcoming publication?",
      "Hi, @astonzhang , I reproduced the error, the error has been ignored by setting `paddle.disable_signal_handler()`Ôºå Can you review this pr again?\r\n\r\n<img width=\"1126\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12107462/189522467-e85c8b61-2617-41b0-b7ca-2164466ff36d.png\">\r\n\r\n\r\n\r\n> > Hi, @astonzhang , I removed multi gpu training, because paddle doesn't support multi gpu training on notebooks, so ti takes about 50mins to build the paddle version's of d2l notebooks.\r\n> > ![image](https://user-images.githubusercontent.com/12107462/189269649-a88b993c-b784-45dd-8709-bb19a926a798.png)\r\n> > what's more, I can't reproduce the error on my local machine, it seems that the error won't affect the building procedure, is this a serivous problem? can you give me some suggestions?\r\n> > ```\r\n> > --------------------------------------\r\n> > \r\n> > C++ Traceback (most recent call last):\r\n> > \r\n> > --------------------------------------\r\n> > \r\n> > No stack trace in paddle, may be caused by external reasons.\r\n> > \r\n> > \r\n> > \r\n> > ----------------------\r\n> > \r\n> > Error Message Summary:\r\n> > \r\n> > ----------------------\r\n> > \r\n> > FatalError: `Termination signal` is detected by the operating system.\r\n> > \r\n> >   [TimeInfo: *** Aborted at 1662692867 (unix time) try \"date -d @1662692867\" if you are using GNU date ***]\r\n> > \r\n> >   [SignalInfo: *** SIGTERM (@0x3e900017699) received by PID 95900 (TID 0x7f2bcf693080) from PID 95897 ***]\r\n> > ```\r\n> \r\n> Can you follow https://github.com/d2l-ai/d2l-zh/blob/paddle/Jenkinsfile and run\r\n> \r\n> ```\r\n> pip install git+https://github.com/d2l-ai/d2l-book\r\n> d2lbook build eval --tab paddle\r\n> ```\r\n> \r\n> to try reproducing the error?\r\n\r\n",
      "@astonzhang @cheungdaven @xiaotinghe  HiÔºåthank you very much for reviewing our submission, could we know the progress of review work? Looking forward to your replyÔΩûü§ó"
    ],
    "num_comments": 10,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 774629
  },
  {
    "index": 95,
    "pr_title": "[Paddle] Add chapter chapter_linear-networks",
    "pr_body": "",
    "pr_number": 1134,
    "comments": [
      "hi @AnirudhDagar  I submitted the PR according to the provided process, the first PR is used to test process. The second is for committing chap3 content, and the third removes some \"None\" characters that I didn't notice before.\r\n\r\nNow the CI have failed and I find that the problem is that simple_alias is missing in the [library-paddle] section of the cofig.ini file. Can I modify this file?\r\n\r\n-----------------\r\nsimple_alias = xx\r\nfluent_alias = xx\r\nalias = xx\r\nreverse_alias = xx\r\n ",
      "Thanks, @tngt for all the hard work! This seems perfectly organized, as is also reflected in the reduced diff. Yes please go ahead with adding all the aliases to `config.ini`.",
      "> @tngt I've made a few more suggestions on the PR. Thanks again for working on this.\r\n\r\nThank you for your suggestion. When I load jupyter notebook, it will automatically generate a lot of 'none' characters. I will solve it as soon as possible and PR again. Thank you for your patience and guidance.",
      "Hello @AnirudhDagar ,sorry to bother you, I see that CI shows \"name nn is not defined\", I found that the import is missing in paddle.py, I have run d2lbook build lib, but the following code is not automatically generated:\r\n\r\nHere is the code in torch.py, we are missing the same part:\r\n\r\n-------\r\n\r\nimport torchvision\r\nfrom PIL import Image\r\nfrom torch import nn\r\nfrom torch.nn import functional as F\r\nfrom torch.utils import data\r\nfrom torchvision import transforms\r\n\r\n-------\r\n\r\nBut I can't modify the paddle.py file manually, how can I fix this?",
      "Hi @tngt that's a good question. As mentioned in the [contributing guidelines](https://github.com/d2l-ai/d2l-en/blob/master/CONTRIBUTING.md):\r\n\r\n> If the saved functions require some packages to be imported, you can add them to chapter_preface/index.md under the respective framework tab and run d2lbook build lib. Now the import will also be reflected in the d2l library after running and the saved functions can access the imported lib.\r\n\r\nIn simple words you need to add the imports that you want to save in `paddle.py` file to `chapter_preface/index.md` so that they are included after automatic generation.\r\n\r\nYou can see my PR here for reference https://github.com/d2l-ai/d2l-zh/pull/1127/files. If you look closely, you'll see the changes made in `chapter_preface/index.md`.\r\n ",
      "> Hi @tngt that's a good question. As mentioned in the [contributing guidelines](https://github.com/d2l-ai/d2l-en/blob/master/CONTRIBUTING.md):\r\n> \r\n> > If the saved functions require some packages to be imported, you can add them to chapter_preface/index.md under the respective framework tab and run d2lbook build lib. Now the import will also be reflected in the d2l library after running and the saved functions can access the imported lib.\r\n> \r\n> In simple words you need to add the imports that you want to save in `paddle.py` file to `chapter_preface/index.md` so that they are included after automatic generation.\r\n> \r\n> You can see my PR here for reference https://github.com/d2l-ai/d2l-zh/pull/1127/files. If you look closely, you'll see the changes made in `chapter_preface/index.md`.\r\n\r\nhi, @AnirudhDagar Thank you for your patience, Could you help us review PR and evaluate whether it can be mergedÔºü",
      "> > Hi @tngt that's a good question. As mentioned in the [contributing guidelines](https://github.com/d2l-ai/d2l-en/blob/master/CONTRIBUTING.md):\r\n> > > If the saved functions require some packages to be imported, you can add them to chapter_preface/index.md under the respective framework tab and run d2lbook build lib. Now the import will also be reflected in the d2l library after running and the saved functions can access the imported lib.\r\n> > \r\n> > \r\n> > In simple words you need to add the imports that you want to save in `paddle.py` file to `chapter_preface/index.md` so that they are included after automatic generation.\r\n> > You can see my PR here for reference https://github.com/d2l-ai/d2l-zh/pull/1127/files. If you look closely, you'll see the changes made in `chapter_preface/index.md`.\r\n> \r\n> hi, @AnirudhDagar Thank you for your patience, Could you help us review PR and evaluate whether it can be mergedÔºü\r\n\r\n@AnirudhDagar Could you help us review PR and evaluate whether it can be mergedÔºüsorry to bother U„ÄÇ",
      "@tngt I couldn't find the modified `chapter_preface/index.md` file for imports in paddle as I mentioned in my last comment. Could you please commit that as well? I'll then take a pass and request @cheungdaven to also make a final pass before merging. Thanks!",
      "> @tngt I couldn't find the modified `chapter_preface/index.md` file for imports in paddle as I mentioned in my last comment. Could you please commit that as well? I'll then take a pass and request @cheungdaven to also make a final pass before merging. Thanks!\r\n\r\n@AnirudhDagar Can you help review it again? thanks",
      "Please go through the comments for future PRs; even though I've resolved most of these. Thanks!",
      "@cheungdaven could you please take a final look and merge when you feel it's good to go? Thanks",
      "can this PR merge now? it takes us too long and the remaining chapters are ready, we want to finish this pr as soon as possible ",
      "Hi @w5688414,\nI'm on the same page with you about getting this in ASAP. But since I can't read Chinese, it is good to have a second review for the comments and also in general maybe some more improvements.\n\nMaybe Shuai was busy this week, I'll request him to review this by today so that we can unblock other chapters.\n\nAppreciate your patience.",
      "@AnirudhDagar  Thanks for the reminder. Hi, @w5688414, the submission seems to be incomplete. Please check my comments.",
      "@w5688414 Could you take a look at the CI issues?",
      "> \r\n\r\nOkay, I am building an offline python environment for testing these md files, so I need more time to deal with python environment problem for supporting MXNET, pytorch, and tf at the same time , but it works fine on our Aistudio(https://aistudio.baidu.com/aistudio/index) platform,  maybe this is the reason for CI test failing",
      "@cheungdaven @AnirudhDagar  The SGD bug fixed, can this PR merge now? ",
      "@w5688414 Thank you very much. The commits look good to me.",
      "I do not want to block it for too long but @w5688414  could you please fix the style issues @AnirudhDagar mentioned in later commits. Feel free to create another pr since I have already merged this pr."
    ],
    "num_comments": 19,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 31291
  },
  {
    "index": 96,
    "pr_title": "CNN Why-conv",
    "pr_body": "",
    "pr_number": 581,
    "comments": [
      "Job d2l-zh/PR-581/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/5 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/6 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/7 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/8 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/9 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/10 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/11 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/12 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/13 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/14 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/15 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/16 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/17 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/18 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/19 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/20 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/21 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/",
      "Job d2l-zh/PR-581/22 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-581/"
    ],
    "num_comments": 22,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 11430
  },
  {
    "index": 97,
    "pr_title": "[MRG] Linear Neural Networks/Linear Regression",
    "pr_body": "",
    "pr_number": 552,
    "comments": [
      "Job d2l-zh/PR-552/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/",
      "Job d2l-zh/PR-552/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/",
      "Job d2l-zh/PR-552/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/",
      "Job d2l-zh/PR-552/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/",
      "Job d2l-zh/PR-552/5 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/",
      "Job d2l-zh/PR-552/6 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/",
      "ÈÉ®ÂàÜissueÈáçÂ§çÂá∫Áé∞‰ΩÜÂè™commentÂú®Á¨¨‰∏ÄÊ¨°Ôºà‰æãÂ¶ÇËã±ÊñáÊúØËØ≠ÁøªËØëÂ∫îÁΩÆ‰∫éÊòüÂè∑Â§ñÔºâÔºåÈúÄË¶ÅÈáçÊñ∞ÂÖ®Â±ÄÊ£ÄÊü•",
      "Job d2l-zh/PR-552/7 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/",
      "Job d2l-zh/PR-552/8 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/",
      "Job d2l-zh/PR-552/9 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/",
      "Job d2l-zh/PR-552/10 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/",
      "Job d2l-zh/PR-552/11 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-552/"
    ],
    "num_comments": 12,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 21466
  },
  {
    "index": 98,
    "pr_title": "Chinese translation of corresponding sections in English",
    "pr_body": "Create directory for chapter of recommender-systems and add two sections of index and movielens dataset.",
    "pr_number": 550,
    "comments": [
      "Job d2l-zh/PR-550/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/6 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/7 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/8 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/9 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/10 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/11 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/12 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/13 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/14 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/15 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/16 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/17 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/18 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/19 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/20 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/21 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/22 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/23 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/24 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/25 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/26 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/28 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/29 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/32 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/33 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/36 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/",
      "Job d2l-zh/PR-550/37 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-550/"
    ],
    "num_comments": 30,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 28748
  },
  {
    "index": 99,
    "pr_title": "[MRG] Linear Neural Networks/Softmax Regression",
    "pr_body": "",
    "pr_number": 555,
    "comments": [
      "Job d2l-zh/PR-555/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-555/",
      "Job d2l-zh/PR-555/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-555/",
      "Job d2l-zh/PR-555/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-555/",
      "Job d2l-zh/PR-555/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-555/",
      "Job d2l-zh/PR-555/5 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-555/",
      "Job d2l-zh/PR-555/6 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-555/",
      "Job d2l-zh/PR-555/7 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-555/",
      "Job d2l-zh/PR-555/8 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-555/",
      "Job d2l-zh/PR-555/9 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-555/"
    ],
    "num_comments": 9,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 15769
  },
  {
    "index": 100,
    "pr_title": "[PaddlePaddle] Merge master into Paddle branch",
    "pr_body": "",
    "pr_number": 1186,
    "comments": [
      "Thanks. Please also sync more recent changes on the master branch.\r\n\r\nBesides, do we still need https://github.com/d2l-ai/d2l-zh/pull/1122 and https://github.com/d2l-ai/d2l-zh/pull/1116?",
      "> Besides, do we still need #1122 and #1116?\r\n\r\nThese PRs are from the developers of PaddlePaddle, who want to contribute d2l, but the submitted content is not standardized, so @w5688414 and I resubmitted the content, and the content has been merged. Could you help close these PRs? Thanks!!",
      "Hi, the recent changes on master branch are incorporated into this pr, can you review this pr again? @astonzhang @cheungdaven ",
      "Quick issue:\r\nhttps://github.com/d2l-ai/d2l-zh/blob/paddle/static/build.yml looks outdated, can you also sync the env from the master branch?\r\n\r\n@cheungdaven PTAL",
      "> Quick issue: https://github.com/d2l-ai/d2l-zh/blob/paddle/static/build.yml looks outdated, can you also sync the env from the master branch?\r\n> \r\n> @cheungdaven PTAL\r\n\r\nit seems that  when I add     `- d2l==0.17.5 ` to build.ymlÔºåthe ci failed and there are conflicts here",
      "> > Quick issue: https://github.com/d2l-ai/d2l-zh/blob/paddle/static/build.yml looks outdated, can you also sync the env from the master branch?\r\n> > @cheungdaven PTAL\r\n> \r\n> it seems that when I add `- d2l==0.17.5 ` to build.ymlÔºåthe ci failed and there are conflicts here\r\n\r\nd2l==0.17.5 does not contain paddle code while `..` means installing from source (containing d2l/paddle.py) on the paddle branch. Please copy d2l/mxnet.py, d2l/torch.py, and d2l/tensorflow.py from the 0.17.5 release source: https://github.com/d2l-ai/d2l-en/tree/v0.17.5/d2l  to paddle branch and keep `..` in build.yml. In this way, installing d2l from your source will include all the d2l==0.17.5 code, together with the `d2l/paddle.py`. We may consider uploading d2l==0.17.6 containing paddle implementation later.",
      "<img width=\"1094\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12107462/185079086-68bcac56-b82c-4260-b2f3-2d6be3beda6a.png\">\r\n\r\nI tried to upgrade pandas version for fixing too much logging display bug, it seems there are conflicts here",
      "can you assist me to hidden the extra logs, it seems that using warningfilter does not worsk. @cheungdaven \r\n\r\n![image](https://user-images.githubusercontent.com/12107462/185110315-3c69512c-472b-4cda-b8e5-45a51ebca93f.png)\r\n",
      "> can you assist me to hidden the extra logs, it seems that using warningfilter does not worsk. @cheungdaven\r\n> \r\n> ![image](https://user-images.githubusercontent.com/12107462/185110315-3c69512c-472b-4cda-b8e5-45a51ebca93f.png)\r\n\r\n@w5688414  Please follow this commit, it should be able to disable the logs. \r\nhttp://preview.d2l.ai/d2l-zh/PR-1186/chapter_recurrent-modern/gru.html\r\n\r\nsolution: put the line \"warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\" right before the line \"from d2l import paddle as d2l\"",
      "The too much logging bug has been solved, can you review this pr again? @astonzhang , @cheungdaven ",
      "The following log is still there, could you try to solve that? @w5688414 \r\n\r\n\r\n /home/d2l-worker/miniconda3/envs/d2l-zh-paddle-0/lib/python3.9/site-packages/paddle/fluid/framework.py:516: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\r\n  warnings.warn("
    ],
    "num_comments": 11,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 608176
  },
  {
    "index": 101,
    "pr_title": "CNN Conv-layer",
    "pr_body": "",
    "pr_number": 589,
    "comments": [
      "Job d2l-zh/PR-589/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/",
      "Job d2l-zh/PR-589/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/",
      "Job d2l-zh/PR-589/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/",
      "Job d2l-zh/PR-589/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/",
      "Job d2l-zh/PR-589/5 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/",
      "Job d2l-zh/PR-589/6 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/",
      "Job d2l-zh/PR-589/7 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/",
      "Job d2l-zh/PR-589/8 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/",
      "Job d2l-zh/PR-589/9 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/",
      "Job d2l-zh/PR-589/10 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/",
      "Job d2l-zh/PR-589/11 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-589/"
    ],
    "num_comments": 11,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 12762
  },
  {
    "index": 102,
    "pr_title": "CNN Padding",
    "pr_body": "",
    "pr_number": 590,
    "comments": [
      "Job d2l-zh/PR-590/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-590/",
      "Job d2l-zh/PR-590/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-590/",
      "Job d2l-zh/PR-590/5 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-590/",
      "Job d2l-zh/PR-590/6 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-590/",
      "Job d2l-zh/PR-590/7 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-590/",
      "Job d2l-zh/PR-590/8 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-590/",
      "Job d2l-zh/PR-590/9 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-590/",
      "Job d2l-zh/PR-590/10 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-590/"
    ],
    "num_comments": 8,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 11001
  },
  {
    "index": 103,
    "pr_title": "fix errors in bahdanau-attention.md",
    "pr_body": "PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?",
    "pr_number": 718,
    "comments": [
      "Job d2l-zh/PR-718/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-718/",
      "Job d2l-zh/PR-718/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-718/",
      "Job d2l-zh/PR-718/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-718/",
      "> PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n\r\nHi @zhuyuanxiang , you can try the following command on you current repo:\r\n\r\n```\r\ngit fetch origin master\r\ngit rebase origin/master\r\ngit log  ## you should see your latest changes\r\n```\r\nPlease see more details about \"git fetch + git rebase\" here: https://stackoverflow.com/questions/3357122/what-is-the-difference-between-git-pull-and-git-fetch-git-rebase",
      "> PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n\r\nAnother trick is posting one PR per file. ;) ",
      "> > PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n> \r\n> Another trick is posting one PR per file. ;)\r\n\r\nThe comparison is based on where the branch is. Just rebase your branch to the head of d2l-zh/master, then it'll compare based on head of d2l-zh/master: only your current edits will be compared",
      "> > PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n> \r\n> Another trick is posting one PR per file. ;)\r\n\r\nI will do it like that. It will be less confusing.",
      "> > > PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n> > \r\n> > \r\n> > Another trick is posting one PR per file. ;)\r\n> \r\n> The comparison is based on where the branch is. Just rebase your branch to the head of d2l-zh/master, then it'll compare based on head of d2l-zh/master: only your current edits will be compared\r\n\r\nThks for your help. But I could not catch the meaning. I am a junior of the git and the github. Could you teach me how to do in github when I wnat to translate a job? Should I delete my d2l project and fork the project d2l again fter my request is closed?",
      "> > > > PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n> > > \r\n> > > \r\n> > > Another trick is posting one PR per file. ;)\r\n> > \r\n> > \r\n> > The comparison is based on where the branch is. Just rebase your branch to the head of d2l-zh/master, then it'll compare based on head of d2l-zh/master: only your current edits will be compared\r\n> \r\n> Thks for your help. But I could not catch the meaning. I am a junior of the git and the github. Could you teach me how to do in github when I wnat to translate a job? Should I delete my d2l project and fork the project d2l again fter my request is closed?\r\n\r\nGreat questions and no worries at all! What Aston means is similar to the \"git fetch + git rebase\" command (in my first comment of this PR). Let me know if that works!",
      "> > > > > PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n> > > > \r\n> > > > \r\n> > > > Another trick is posting one PR per file. ;)\r\n> > > \r\n> > > \r\n> > > The comparison is based on where the branch is. Just rebase your branch to the head of d2l-zh/master, then it'll compare based on head of d2l-zh/master: only your current edits will be compared\r\n> > \r\n> > \r\n> > Thks for your help. But I could not catch the meaning. I am a junior of the git and the github. Could you teach me how to do in github when I wnat to translate a job? Should I delete my d2l project and fork the project d2l again fter my request is closed?\r\n> \r\n> Great questions and no worries at all! What Aston means is similar to the \"git fetch + git rebase\" command (in my first comment of this PR). Let me know if that works!\r\n\r\nOK, I will try it.",
      "> > PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n> \r\n> Another trick is posting one PR per file. ;)\r\n\r\nI found that only one PR will be created before the last is closed. If I commit the new file, the last PR will be used for request.",
      "> > > PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n> > \r\n> > \r\n> > Another trick is posting one PR per file. ;)\r\n> \r\n> I found that only one PR will be created before the last is closed. If I commit the new file, the last PR will be used for request.\r\n\r\nTry the following cmd:\r\n## Step 0: commit all your change to your current git repo, and then check the official git name (mine is called \"origin\"):\r\n\r\n```\r\ngit remote -v\r\n```\r\n![image](https://user-images.githubusercontent.com/37914843/113808804-a4d0f180-971b-11eb-99ca-803cbc01c65b.png)\r\n\r\n## Step 1: download(fetch) the latest changes from official d2l-zh:\r\n```\r\ngit fetch origin\r\n```\r\n\r\n## Step 2: clone a brand new \"branch\" as same as \"origin/master\":\r\n```\r\ngit checkout -b new_branch origin/master\r\n```\r\n![image](https://user-images.githubusercontent.com/37914843/113809009-1610a480-971c-11eb-8a97-2c9a13b1496b.png)\r\n\r\nNow you should be at this fresh new branch, and you can make changes here. When you make a PR, you can use this branch for comparison.\r\n",
      "> > > > PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n> > > \r\n> > > \r\n> > > Another trick is posting one PR per file. ;)\r\n> > \r\n> > \r\n> > I found that only one PR will be created before the last is closed. If I commit the new file, the last PR will be used for request.\r\n> \r\n> Try the following cmd:\r\n> \r\n> ## Step 0: commit all your change to your current git repo, and then check the official git name (mine is called \"origin\"):\r\n> ```\r\n> git remote -v\r\n> ```\r\n> \r\n> ![image](https://user-images.githubusercontent.com/37914843/113808804-a4d0f180-971b-11eb-99ca-803cbc01c65b.png)\r\n> \r\n> ## Step 1: download(fetch) the latest changes from official d2l-zh:\r\n> ```\r\n> git fetch origin\r\n> ```\r\n> \r\n> ## Step 2: clone a brand new \"branch\" as same as \"origin/master\":\r\n> ```\r\n> git checkout -b new_branch origin/master\r\n> ```\r\n> \r\n> ![image](https://user-images.githubusercontent.com/37914843/113809009-1610a480-971c-11eb-8a97-2c9a13b1496b.png)\r\n> \r\n> Now you should be at this fresh new branch, and you can make changes here. When you make a PR, you can use this branch for comparison.\r\n\r\nThks for your expatiation.",
      "I was confused bythe conficts. I checked the two files in the repository, but I have not found any errors in my changes.",
      "Job d2l-zh/PR-718/5 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-718/",
      "> > > > > PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n> > > > \r\n> > > > \r\n> > > > Another trick is posting one PR per file. ;)\r\n> > > \r\n> > > \r\n> > > I found that only one PR will be created before the last is closed. If I commit the new file, the last PR will be used for request.\r\n> > \r\n> > \r\n> > Try the following cmd:\r\n> > ## Step 0: commit all your change to your current git repo, and then check the official git name (mine is called \"origin\"):\r\n> > ```\r\n> > git remote -v\r\n> > ```\r\n> > \r\n> > \r\n> > ![image](https://user-images.githubusercontent.com/37914843/113808804-a4d0f180-971b-11eb-99ca-803cbc01c65b.png)\r\n> > ## Step 1: download(fetch) the latest changes from official d2l-zh:\r\n> > ```\r\n> > git fetch origin\r\n> > ```\r\n> > \r\n> > \r\n> > ## Step 2: clone a brand new \"branch\" as same as \"origin/master\":\r\n> > ```\r\n> > git checkout -b new_branch origin/master\r\n> > ```\r\n> > \r\n> > \r\n> > ![image](https://user-images.githubusercontent.com/37914843/113809009-1610a480-971c-11eb-8a97-2c9a13b1496b.png)\r\n> > Now you should be at this fresh new branch, and you can make changes here. When you make a PR, you can use this branch for comparison.\r\n> \r\n> Thks for your expatiation.\r\n\r\nI found GitHub Desktop provided a tool for contributing to others project. I will try it.",
      "> > > > > > PS: I don't know why the request compare the oldest version and show the all changes. Should I fork the project again before I modify the new file?\r\n> > > > > \r\n> > > > > \r\n> > > > > Another trick is posting one PR per file. ;)\r\n> > > > \r\n> > > > \r\n> > > > I found that only one PR will be created before the last is closed. If I commit the new file, the last PR will be used for request.\r\n> > > \r\n> > > \r\n> > > Try the following cmd:\r\n> > > ## Step 0: commit all your change to your current git repo, and then check the official git name (mine is called \"origin\"):\r\n> > > ```\r\n> > > git remote -v\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > ![image](https://user-images.githubusercontent.com/37914843/113808804-a4d0f180-971b-11eb-99ca-803cbc01c65b.png)\r\n> > > ## Step 1: download(fetch) the latest changes from official d2l-zh:\r\n> > > ```\r\n> > > git fetch origin\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > ## Step 2: clone a brand new \"branch\" as same as \"origin/master\":\r\n> > > ```\r\n> > > git checkout -b new_branch origin/master\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > ![image](https://user-images.githubusercontent.com/37914843/113809009-1610a480-971c-11eb-8a97-2c9a13b1496b.png)\r\n> > > Now you should be at this fresh new branch, and you can make changes here. When you make a PR, you can use this branch for comparison.\r\n> > \r\n> > \r\n> > Thks for your expatiation.\r\n> \r\n> I found GitHub Desktop provided a tool for contributing to others project. I will try it.\r\n\r\nI have created a new PR #721  with one file\r\n\r\nShould I close this PR and create new branch for every file?",
      "I plan to close this PR and split into several PRs that each PR owns one file"
    ],
    "num_comments": 18,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 33052
  },
  {
    "index": 104,
    "pr_title": "fix typo in chapter_introduction/index.md",
    "pr_body": "Êõ¥Êîπ‰∫Ü‰∏Ä‰∫õ‰∏çÈÄöÈ°∫ÁöÑËØ≠Âè•Ôºå‰øÆÂ§ç‰∫Ü‰∏Ä‰∫õÂ§ö‰ΩôÁöÑÁ©∫Ê†ºÔºå‰øÆÊ≠£‰∫Ü‰∏Ä‰∫õÈîôËØØÊúØËØ≠Á≠âÁ≠â„ÄÇ",
    "pr_number": 991,
    "comments": [
      "Job d2l-zh/PR-991/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-991/",
      "> Thanks @geometryolife ! I've made some tiny comments.\r\n\r\nThat looks great, I'll add suggestions later.",
      "Job d2l-zh/PR-991/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-991/",
      "Job d2l-zh/PR-991/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-991/",
      " thanks for your dedication @geometryolife ! i made a few suggestion above. ",
      "Job d2l-zh/PR-991/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-991/",
      "all good. merged. thanks @geometryolife !",
      "> all good. merged. thanks @geometryolife !\r\n\r\nMy pleasure."
    ],
    "num_comments": 8,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 20339
  },
  {
    "index": 105,
    "pr_title": "[MRG] Linear Neural Networks/Implementation of Softmax Regression from Scratch",
    "pr_body": "",
    "pr_number": 557,
    "comments": [
      "Job d2l-zh/PR-557/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-557/",
      "Job d2l-zh/PR-557/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-557/",
      "Job d2l-zh/PR-557/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-557/",
      "Job d2l-zh/PR-557/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-557/",
      "Job d2l-zh/PR-557/5 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-557/",
      "Job d2l-zh/PR-557/6 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-557/",
      "Job d2l-zh/PR-557/7 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-557/"
    ],
    "num_comments": 7,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 17183
  },
  {
    "index": 106,
    "pr_title": "CNN index.md",
    "pr_body": "",
    "pr_number": 580,
    "comments": [
      "Job d2l-zh/PR-580/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/5 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/6 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/7 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/8 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/9 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/10 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/11 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/12 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/13 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/",
      "Job d2l-zh/PR-580/14 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-580/"
    ],
    "num_comments": 14,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 2108
  },
  {
    "index": 107,
    "pr_title": "[MRG] Linear Neural Networks/Concise Implementation of Linear Regression",
    "pr_body": "",
    "pr_number": 554,
    "comments": [
      "Job d2l-zh/PR-554/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-554/",
      "Job d2l-zh/PR-554/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-554/",
      "Job d2l-zh/PR-554/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-554/",
      "Job d2l-zh/PR-554/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-554/",
      "Job d2l-zh/PR-554/5 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-554/",
      "Job d2l-zh/PR-554/6 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-554/",
      "Job d2l-zh/PR-554/7 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-554/"
    ],
    "num_comments": 7,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 14268
  },
  {
    "index": 108,
    "pr_title": "[slides] CNN",
    "pr_body": "Check no 404 before merge. https://github.com/d2l-ai/d2l-zh-pytorch-slides",
    "pr_number": 753,
    "comments": [
      "Job d2l-zh/PR-753/1 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/2 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/3 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/4 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/5 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/6 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/8 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/9 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/10 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/11 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/12 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/13 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/pooling.ipynb\r\n\r\nhttps://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/conv-layer.ipynb\r\n\r\nDone",
      "Lenet Done!\r\nhttps://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/lenet.ipynb#/",
      "Job d2l-zh/PR-753/14 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Job d2l-zh/PR-753/15 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Channels 404 Fixed\r\n\r\nhttps://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/channels.ipynb#/",
      "Job d2l-zh/PR-753/16 is complete. \nCheck the results at http://preview.d2l.ai/d2l-zh/PR-753/",
      "Padding and stride 404 fixed!\r\nhttps://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/padding-and-strides.ipynb\r\n",
      "> Padding and stride 404 fixed!\r\n> https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/padding-and-strides.ipynb\r\n\r\nSounds good. Did you figure out the root cause?",
      "> > Padding and stride 404 fixed!\r\n> > https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/padding-and-strides.ipynb\r\n> \r\n> Sounds good. Did you figure out the root cause?\r\n\r\nIt is a bit tricky. Until now, I noticed that `*`, `$` and space may cause 404 if there are inside `[**` and `**]`."
    ],
    "num_comments": 21,
    "repository": "d2l-ai/d2l-zh",
    "diff_length": 10334
  },
  {
    "index": 109,
    "pr_title": "Add AZURE support",
    "pr_body": "This PR add the support for Azure OpenAI Services (Vision & DALLE-3)\r\n\r\nSome considerations:\r\n- Azure parameters are managed only in .env file (not in web interface), I have updated the README file with instructions\r\n- On Azure the vision ad dalle-3 distributions must be in the same reource and same region\r\n- If in .env are present OPENAI and AZURE settings, OPENAI has the priority\r\n- The code probably need some refactor (i am not an high level python developer)\r\n\r\nMy tests with AZURE are ok, pl",
    "pr_number": 186,
    "comments": [
      "I just need it, thanks for the contribution",
      "which works better, Azure or OpenAI?",
      "They are the same model. Should work the same. ",
      "> which works better, Azure or OpenAI?\r\n\r\nyou can upload customized data and set api rate limit in Azure.",
      "Great! I just want to know when will this PR be merged...",
      "Sorry for the slowness (catching up after the holidays). Should be merged some time next week.",
      "> Sorry for the slowness (catching up after the holidays). Should be merged some time next week.\r\n\r\n@abi Will this be merged in this week? Waiting for using it...",
      "@thuzhf Azure GPT 4 Vision has low token limits per minute so this hasn't been a priority for me. Have you tried cloning cristianorevil:azure-support and using it directly? You don't need to wait for this to be merged in to use it.",
      "Since stream requests are already supported and the issue with token limitations has been somewhat improved, can we support Azure now?"
    ],
    "num_comments": 9,
    "repository": "abi/screenshot-to-code",
    "diff_length": 15683
  },
  {
    "index": 110,
    "pr_title": "Feat: support generate react code",
    "pr_body": "#96 \r\n\r\n## Background\r\n\r\nNow our system only supports generating HTML. However, the frontend community now mainly uses React, and Vue as development frameworks/libraries. Thus adding react generation capacity is crucial.\r\n\r\n## Methods\r\n\r\nThere are two ways to generate react code:\r\n\r\n1. **image ‚Üí react**: Feed GPT the same materials as we generate HTML, and prompt GPT to generate React(and other) code.\r\n2. **image ‚Üí html ‚Üí react**: Prompt GPT to translate HTML into React code.\r\n\r\nHere are some si",
    "pr_number": 105,
    "comments": [
      "Nice analysis! Agree with you that generating React directly is a much better approach.\r\n\r\nReact can be previewed live in the browser by including babel, which will compile JSX on page load. Example: https://dirask.com/posts/React-runtime-compilation-in-browser-with-Babel-example-DWe9Oj\r\n\r\nThe approach I'm leaning towards is having an \"Output settings\" section on the left sidebar where the user can choose:\r\n\r\n- JS framework - React, Vue, Flutter(?)\r\n- CSS - plain CSS, Tailwind, etc. \r\n- component library - bootstrap, ionic\r\n\r\nand then, we update the prompt based on the user setting and render a preview according to the setting as well.\r\n\r\ncc @dialmedu ",
      "> Output settings\r\n\r\nThanks for sharing this! I will take a look at how to implement it.\r\n\r\nThe question I have about the output setting is now the system records history, and if we wanna reuse the same logic for different language, the history would be messive for GPT to understand, We may need a more sophisticated history protocol.\r\n\r\nMy suggestion is to separate the html and different languages out and provide a selection section for users when they enter the system, so that the user can select react, vue, or html one time, this makes the system much simpler compared to enabling users to switch between different languages after generating the code. What do you think? @abi ",
      "@clean99 yeah, I don't think the user should be allowed to switch frameworks after the 1st generation. They'll reset to change frameworks. Don't think there's a real use case where you want to switch frameworks in the middle.",
      "> @clean99 yeah, I don't think the user should be allowed to switch frameworks after the 1st generation. They'll reset to change frameworks. Don't think there's a real use case where you want to switch frameworks in the middle.\r\n\r\nGreat, I will design and update later",
      "I'm working on a version that I'll push today as well.",
      "I pushed React generation to master today. Check it out, and let me know if there's some improvements we can make.",
      "This functionality is now in master so closing this PR. Thanks for investigating and creating this PR. "
    ],
    "num_comments": 7,
    "repository": "abi/screenshot-to-code",
    "diff_length": 14661
  }
]