[
  {
    "index": 1,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.ci/test.sh b/.ci/test.sh\nindex db4427e6dbaa..fe627ce87077 100755\n--- a/.ci/test.sh\n+++ b/.ci/test.sh\n@@ -226,8 +226,8 @@ import matplotlib\\\n matplotlib.use\\(\\\"Agg\\\"\\)\\\n ' plot_example.py  # prevent interactive window mode\n     sed -i'.bak' 's/graph.render(view=True)/graph.render(view=False)/' plot_example.py\n+    conda install -q -y -n $CONDA_ENV h5py ipywidgets notebook  # requirements for examples\n     for f in *.py **/*.py; do python $f || exit -1; done  # run all examples\n     cd $BUILD_DIRECTORY/examples/python-guide/notebooks\n-    conda install -q -y -n $CONDA_ENV ipywidgets notebook\n     jupyter nbconvert --ExecutePreprocessor.timeout=180 --to notebook --execute --inplace *.ipynb || exit -1  # run all notebooks\n fi\ndiff --git a/.ci/test_windows.ps1 b/.ci/test_windows.ps1\nindex 20e7bf654a68..cb191c0804ee 100644\n--- a/.ci/test_windows.ps1\n+++ b/.ci/test_windows.ps1\n@@ -105,11 +105,11 @@ if (($env:TASK -eq \"regular\") -or (($env:APPVEYOR -eq \"true\") -and ($env:TASK -e\n   cd $env:BUILD_SOURCESDIRECTORY/examples/python-guide\n   @(\"import matplotlib\", \"matplotlib.use('Agg')\") + (Get-Content \"plot_example.py\") | Set-Content \"plot_example.py\"\n   (Get-Content \"plot_example.py\").replace('graph.render(view=True)', 'graph.render(view=False)') | Set-Content \"plot_example.py\"  # prevent interactive window mode\n+  conda install -q -y -n $env:CONDA_ENV h5py ipywidgets notebook\n   foreach ($file in @(Get-ChildItem *.py)) {\n     @(\"import sys, warnings\", \"warnings.showwarning = lambda message, category, filename, lineno, file=None, line=None: sys.stdout.write(warnings.formatwarning(message, category, filename, lineno, line))\") + (Get-Content $file) | Set-Content $file\n     python $file ; Check-Output $?\n   }  # run all examples\n   cd $env:BUILD_SOURCESDIRECTORY/examples/python-guide/notebooks\n-  conda install -q -y -n $env:CONDA_ENV ipywidgets notebook\n   jupyter nbconvert --ExecutePreprocessor.timeout=180 --to notebook --execute --inplace *.ipynb ; Check-Output $?  # run all notebooks\n }\ndiff --git a/docs/Python-API.rst b/docs/Python-API.rst\nindex a50ff43f0a4e..f57125c46a5a 100644\n--- a/docs/Python-API.rst\n+++ b/docs/Python-API.rst\n@@ -12,6 +12,7 @@ Data Structure API\n     Dataset\n     Booster\n     CVBooster\n+    Sequence\n \n Training API\n ------------\ndiff --git a/docs/Python-Intro.rst b/docs/Python-Intro.rst\nindex 2fd9c33def2e..063dbf172445 100644\n--- a/docs/Python-Intro.rst\n+++ b/docs/Python-Intro.rst\n@@ -39,6 +39,8 @@ The LightGBM Python module can load data from:\n \n -  LightGBM binary file\n \n+-  LightGBM ``Sequence`` object(s)\n+\n The data is stored in a ``Dataset`` object.\n \n Many of the examples in this page use functionality from ``numpy``. To run the examples, be sure to import ``numpy`` in your session.\n@@ -69,6 +71,38 @@ Many of the examples in this page use functionality from ``numpy``. To run the e\n     csr = scipy.sparse.csr_matrix((dat, (row, col)))\n     train_data = lgb.Dataset(csr)\n \n+**Load from Sequence objects:**\n+\n+We can implement ``Sequence`` interface to read binary files. The following example shows reading HDF5 file with ``h5py``.\n+\n+.. code:: python\n+\n+    import h5py\n+\n+    class HDFSequence(lgb.Sequence):\n+        def __init__(self, hdf_dataset, batch_size):\n+            self.data = hdf_dataset\n+            self.batch_size = batch_size\n+\n+        def __getitem__(self, idx):\n+            return self.data[idx]\n+\n+        def __len__(self):\n+            return len(self.data)\n+\n+    f = h5py.File('train.hdf5', 'r')\n+    train_data = lgb.Dataset(HDFSequence(f['X'], 8192), label=f['Y'][:])\n+\n+Features of using ``Sequence`` interface:\n+\n+- Data sampling uses random access, thus does not go through the whole dataset\n+- Reading data in batch, thus saves memory when constructing ``Dataset`` object\n+- Supports creating ``Dataset`` from multiple data files\n+\n+Please refer to ``Sequence`` `API doc <./Python-API.rst#data-structure-api>`__.\n+\n+`dataset_from_multi_hdf5.py <https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/dataset_from_multi_hdf5.py>`__ is a detailed example.\n+\n **Saving Dataset into a LightGBM binary file will make loading faster:**\n \n .. code:: python\ndiff --git a/examples/python-guide/README.md b/examples/python-guide/README.md\nindex 08ded17ab559..b34e0fa6e002 100644\n--- a/examples/python-guide/README.md\n+++ b/examples/python-guide/README.md\n@@ -61,3 +61,6 @@ Examples include:\n     - Plot split value histogram\n     - Plot one specified tree\n     - Plot one specified tree with Graphviz\n+- [dataset_from_multi_hdf5.py](https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/dataset_from_multi_hdf5.py)\n+  - Construct Dataset from multiple HDF5 files\n+  - Avoid loading all data into memory\ndiff --git a/examples/python-guide/dataset_from_multi_hdf5.py b/examples/python-guide/dataset_from_multi_hdf5.py\nnew file mode 100644\nindex 000000000000..98022679af33\n--- /dev/null\n+++ b/examples/python-guide/dataset_from_multi_hdf5.py\n@@ -0,0 +1,106 @@\n+import h5py\n+import numpy as np\n+import pandas as pd\n+\n+import lightgbm as lgb\n+\n+\n+class HDFSequence(lgb.Sequence):\n+    def __init__(self, hdf_dataset, batch_size):\n+        \"\"\"\n+        Construct a sequence object from HDF5 with required interface.\n+\n+        Parameters\n+        ----------\n+        hdf_dataset : h5py.Dataset\n+            Dataset in HDF5 file.\n+        batch_size : int\n+            Size of a batch. When reading data to construct lightgbm Dataset, each read reads batch_size rows.\n+        \"\"\"\n+        # We can also open HDF5 file once and get access to\n+        self.data = hdf_dataset\n+        self.batch_size = batch_size\n+\n+    def __getitem__(self, idx):\n+        return self.data[idx]\n+\n+    def __len__(self):\n+        return len(self.data)\n+\n+\n+def create_dataset_from_multiple_hdf(input_flist, batch_size):\n+    data = []\n+    ylist = []\n+    for f in input_flist:\n+        f = h5py.File(f, 'r')\n+        data.append(HDFSequence(f['X'], batch_size))\n+        ylist.append(f['Y'][:])\n+\n+    params = {\n+        'bin_construct_sample_cnt': 200000,\n+        'max_bin': 255,\n+    }\n+    y = np.concatenate(ylist)\n+    dataset = lgb.Dataset(data, label=y, params=params)\n+    # With binary dataset created, we can use either Python API or cmdline version to train.\n+    #\n+    # Note: in order to create exactly the same dataset with the one created in simple_example.py, we need\n+    # to modify simple_example.py to pass numpy array instead of pandas DataFrame to Dataset constructor.\n+    # The reason is that DataFrame column names will be used in Dataset. For a DataFrame with Int64Index\n+    # as columns, Dataset will use column names like [\"0\", \"1\", \"2\", ...]. While for numpy array, column names\n+    # are using the default one assigned in C++ code (dataset_loader.cpp), like [\"Column_0\", \"Column_1\", ...].\n+    dataset.save_binary('regression.train.from_hdf.bin')\n+\n+\n+def save2hdf(input_data, fname, batch_size):\n+    \"\"\"Store numpy array to HDF5 file.\n+\n+    Please note chunk size settings in the implementation for I/O performance optimization.\n+    \"\"\"\n+    with h5py.File(fname, 'w') as f:\n+        for name, data in input_data.items():\n+            nrow, ncol = data.shape\n+            if ncol == 1:\n+                # Y has a single column and we read it in single shot. So store it as an 1-d array.\n+                chunk = (nrow,)\n+                data = data.values.flatten()\n+            else:\n+                # We use random access for data sampling when creating LightGBM Dataset from Sequence.\n+                # When accessing any element in a HDF5 chunk, it's read entirely.\n+                # To save I/O for sampling, we should keep number of total chunks much larger than sample count.\n+                # Here we are just creating a chunk size that matches with batch_size.\n+                #\n+                # Also note that the data is stored in row major order to avoid extra copy when passing to\n+                # lightgbm Dataset.\n+                chunk = (batch_size, ncol)\n+            f.create_dataset(name, data=data, chunks=chunk, compression='lzf')\n+\n+\n+def generate_hdf(input_fname, output_basename, batch_size):\n+    # Save to 2 HDF5 files for demonstration.\n+    df = pd.read_csv(input_fname, header=None, sep='\\t')\n+\n+    mid = len(df) // 2\n+    df1 = df.iloc[:mid]\n+    df2 = df.iloc[mid:]\n+\n+    # We can store multiple datasets inside a single HDF5 file.\n+    # Separating X and Y for choosing best chunk size for data loading.\n+    fname1 = f'{output_basename}1.h5'\n+    fname2 = f'{output_basename}2.h5'\n+    save2hdf({'Y': df1.iloc[:, :1], 'X': df1.iloc[:, 1:]}, fname1, batch_size)\n+    save2hdf({'Y': df2.iloc[:, :1], 'X': df2.iloc[:, 1:]}, fname2, batch_size)\n+\n+    return [fname1, fname2]\n+\n+\n+def main():\n+    batch_size = 64\n+    output_basename = 'regression'\n+    hdf_files = generate_hdf('../regression/regression.train', output_basename, batch_size)\n+\n+    create_dataset_from_multiple_hdf(hdf_files, batch_size=batch_size)\n+\n+\n+if __name__ == '__main__':\n+    main()\ndiff --git a/include/LightGBM/c_api.h b/include/LightGBM/c_api.h\nindex 025633c97bde..01e5f7f8ea0c 100644\n--- a/include/LightGBM/c_api.h\n+++ b/include/LightGBM/c_api.h\n@@ -53,6 +53,32 @@ LIGHTGBM_C_EXPORT const char* LGBM_GetLastError();\n  */\n LIGHTGBM_C_EXPORT int LGBM_RegisterLogCallback(void (*callback)(const char*));\n \n+/*!\n+ * \\brief Get number of samples based on parameters and total number of rows of data.\n+ * \\param num_total_row Number of total rows\n+ * \\param parameters Additional parameters, namely, ``bin_construct_sample_cnt`` is used to calculate returned value\n+ * \\param[out] out Number of samples. This value is used to pre-allocate memory to hold sample indices when calling ``LGBM_SampleIndices``\n+ * \\return 0 when succeed, -1 when failure happens\n+ */\n+LIGHTGBM_C_EXPORT int LGBM_GetSampleCount(int32_t num_total_row,\n+                                          const char* parameters,\n+                                          int* out);\n+\n+/*!\n+ * \\brief Create sample indices for total number of rows.\n+ * \\note\n+ * You should pre-allocate memory for ``out``, you can get its length by ``LGBM_GetSampleCount``.\n+ * \\param num_total_row Number of total rows\n+ * \\param parameters Additional parameters, namely, ``bin_construct_sample_cnt`` and ``data_random_seed`` are used to produce the output\n+ * \\param[out] out Created indices, type is int32_t\n+ * \\param[out] out_len Number of indices. This may be less than the one returned by ``LGBM_GetSampleCount``\n+ * \\return 0 when succeed, -1 when failure happens\n+ */\n+LIGHTGBM_C_EXPORT int LGBM_SampleIndices(int32_t num_total_row,\n+                                         const char* parameters,\n+                                         void* out,\n+                                         int32_t* out_len);\n+\n // --- start Dataset interface\n \n /*!\ndiff --git a/python-package/lightgbm/__init__.py b/python-package/lightgbm/__init__.py\nindex c7a1e0303dcd..dc2143674be2 100644\n--- a/python-package/lightgbm/__init__.py\n+++ b/python-package/lightgbm/__init__.py\n@@ -5,7 +5,7 @@\n \"\"\"\n import os\n \n-from .basic import Booster, Dataset, register_logger\n+from .basic import Booster, Dataset, Sequence, register_logger\n from .callback import early_stopping, print_evaluation, record_evaluation, reset_parameter\n from .engine import CVBooster, cv, train\n \n@@ -29,7 +29,7 @@\n     with open(os.path.join(dir_path, 'VERSION.txt')) as version_file:\n         __version__ = version_file.read().strip()\n \n-__all__ = ['Dataset', 'Booster', 'CVBooster',\n+__all__ = ['Dataset', 'Booster', 'CVBooster', 'Sequence',\n            'register_logger',\n            'train', 'cv',\n            'LGBMModel', 'LGBMRegressor', 'LGBMClassifier', 'LGBMRanker',\ndiff --git a/python-package/lightgbm/basic.py b/python-package/lightgbm/basic.py\nindex 121b371459d1..77a1ddf08fd7 100644\n--- a/python-package/lightgbm/basic.py\n+++ b/python-package/lightgbm/basic.py\n@@ -1,5 +1,6 @@\n # coding: utf-8\n \"\"\"Wrapper for C API of LightGBM.\"\"\"\n+import abc\n import ctypes\n import json\n import os\n@@ -9,7 +10,7 @@\n from functools import wraps\n from logging import Logger\n from tempfile import NamedTemporaryFile\n-from typing import Any, Dict, List, Set, Union\n+from typing import Any, Dict, Iterable, List, Optional, Set, Tuple, Union\n \n import numpy as np\n import scipy.sparse\n@@ -17,6 +18,18 @@\n from .compat import PANDAS_INSTALLED, concat, dt_DataTable, is_dtype_sparse, pd_DataFrame, pd_Series\n from .libpath import find_lib_path\n \n+ZERO_THRESHOLD = 1e-35\n+\n+\n+def _get_sample_count(total_nrow: int, params: str):\n+    sample_cnt = ctypes.c_int(0)\n+    _safe_call(_LIB.LGBM_GetSampleCount(\n+        ctypes.c_int32(total_nrow),\n+        c_str(params),\n+        ctypes.byref(sample_cnt),\n+    ))\n+    return sample_cnt.value\n+\n \n class _DummyLogger:\n     def info(self, msg):\n@@ -591,6 +604,67 @@ def _load_pandas_categorical(file_name=None, model_str=None):\n         return None\n \n \n+class Sequence(abc.ABC):\n+    \"\"\"\n+    Generic data access interface.\n+\n+    Object should support the following operations:\n+\n+    .. code-block::\n+\n+        # Get total row number.\n+        >>> len(seq)\n+        # Random access by row index. Used for data sampling.\n+        >>> seq[10]\n+        # Range data access. Used to read data in batch when constructing Dataset.\n+        >>> seq[0:100]\n+        # Optionally specify batch_size to control range data read size.\n+        >>> seq.batch_size\n+\n+    - With random access, **data sampling does not need to go through all data**.\n+    - With range data access, there's **no need to read all data into memory thus reduce memory usage**.\n+\n+    Attributes\n+    ----------\n+    batch_size : int\n+        Default size of a batch.\n+    \"\"\"\n+\n+    batch_size = 4096  # Defaults to read 4K rows in each batch.\n+\n+    @abc.abstractmethod\n+    def __getitem__(self, idx: Union[int, slice]) -> np.ndarray:\n+        \"\"\"Return data for given row index.\n+\n+        A basic implementation should look like this:\n+\n+        .. code-block:: python\n+\n+            if isinstance(idx, numbers.Integral):\n+                return self.__get_one_line__(idx)\n+            elif isinstance(idx, slice):\n+                return np.stack(self.__get_one_line__(i) for i in range(idx.start, idx.stop))\n+            else:\n+                raise TypeError(f\"Sequence index must be integer or slice, got {type(idx)}\")\n+\n+        Parameters\n+        ----------\n+        idx : int, slice[int]\n+            Item index.\n+\n+        Returns\n+        -------\n+        result : numpy 1-D array, numpy 2-D array\n+            1-D array if idx is int, 2-D array if idx is slice.\n+        \"\"\"\n+        raise NotImplementedError(\"Sub-classes of lightgbm.Sequence must implement __getitem__()\")\n+\n+    @abc.abstractmethod\n+    def __len__(self) -> int:\n+        \"\"\"Return row count of this sequence.\"\"\"\n+        raise NotImplementedError(\"Sub-classes of lightgbm.Sequence must implement __len__()\")\n+\n+\n class _InnerPredictor:\n     \"\"\"_InnerPredictor of LightGBM.\n \n@@ -1055,7 +1129,7 @@ def __init__(self, data, label=None, reference=None,\n \n         Parameters\n         ----------\n-        data : string, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse or list of numpy arrays\n+        data : string, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequences or list of numpy arrays\n             Data source of Dataset.\n             If string, it represents the path to txt file.\n         label : list, numpy 1-D array, pandas Series / one-column DataFrame or None, optional (default=None)\n@@ -1111,6 +1185,7 @@ def __init__(self, data, label=None, reference=None,\n         self.feature_penalty = None\n         self.monotone_constraints = None\n         self.version = 0\n+        self._start_row = 0  # Used when pushing rows one by one.\n \n     def __del__(self):\n         try:\n@@ -1118,6 +1193,149 @@ def __del__(self):\n         except AttributeError:\n             pass\n \n+    def _create_sample_indices(self, total_nrow: int) -> np.ndarray:\n+        \"\"\"Get an array of randomly chosen indices from this ``Dataset``.\n+\n+        Indices are sampled without replacement.\n+\n+        Parameters\n+        ----------\n+        total_nrow : int\n+            Total number of rows to sample from.\n+            If this value is greater than the value of parameter ``bin_construct_sample_cnt``, only ``bin_construct_sample_cnt`` indices will be used.\n+            If Dataset has multiple input data, this should be the sum of rows of every file.\n+\n+        Returns\n+        -------\n+        indices : numpy array\n+            Indices for sampled data.\n+        \"\"\"\n+        param_str = param_dict_to_str(self.get_params())\n+        sample_cnt = _get_sample_count(total_nrow, param_str)\n+        indices = np.empty(sample_cnt, dtype=np.int32)\n+        ptr_data, _, _ = c_int_array(indices)\n+        actual_sample_cnt = ctypes.c_int32(0)\n+\n+        _safe_call(_LIB.LGBM_SampleIndices(\n+            ctypes.c_int32(total_nrow),\n+            c_str(param_str),\n+            ptr_data,\n+            ctypes.byref(actual_sample_cnt),\n+        ))\n+        return indices[:actual_sample_cnt.value]\n+\n+    def _init_from_ref_dataset(self, total_nrow: int, ref_dataset: 'Dataset') -> 'Dataset':\n+        \"\"\"Create dataset from a reference dataset.\n+\n+        Parameters\n+        ----------\n+        total_nrow : int\n+            Number of rows expected to add to dataset.\n+        ref_dataset : Dataset\n+            Reference dataset to extract meta from.\n+\n+        Returns\n+        -------\n+        self : Dataset\n+            Constructed Dataset object.\n+        \"\"\"\n+        self.handle = ctypes.c_void_p()\n+        _safe_call(_LIB.LGBM_DatasetCreateByReference(\n+            ref_dataset,\n+            ctypes.c_int64(total_nrow),\n+            ctypes.byref(self.handle),\n+        ))\n+        return self\n+\n+    def _init_from_sample(\n+        self,\n+        sample_data: List[np.ndarray],\n+        sample_indices: List[np.ndarray],\n+        sample_cnt: int,\n+        total_nrow: int,\n+    ) -> \"Dataset\":\n+        \"\"\"Create Dataset from sampled data structures.\n+\n+        Parameters\n+        ----------\n+        sample_data : list of numpy arrays\n+            Sample data for each column.\n+        sample_indices : list of numpy arrays\n+            Sample data row index for each column.\n+        sample_cnt : int\n+            Number of samples.\n+        total_nrow : int\n+            Total number of rows for all input files.\n+\n+        Returns\n+        -------\n+        self : Dataset\n+            Constructed Dataset object.\n+        \"\"\"\n+        ncol = len(sample_indices)\n+        assert len(sample_data) == ncol, \"#sample data column != #column indices\"\n+\n+        for i in range(ncol):\n+            if sample_data[i].dtype != np.double:\n+                raise ValueError(f\"sample_data[{i}] type {sample_data[i].dtype} is not double\")\n+            if sample_indices[i].dtype != np.int32:\n+                raise ValueError(f\"sample_indices[{i}] type {sample_indices[i].dtype} is not int32\")\n+\n+        # c type: double**\n+        # each double* element points to start of each column of sample data.\n+        sample_col_ptr = (ctypes.POINTER(ctypes.c_double) * ncol)()\n+        # c type int**\n+        # each int* points to start of indices for each column\n+        indices_col_ptr = (ctypes.POINTER(ctypes.c_int32) * ncol)()\n+        for i in range(ncol):\n+            sample_col_ptr[i] = c_float_array(sample_data[i])[0]\n+            indices_col_ptr[i] = c_int_array(sample_indices[i])[0]\n+\n+        num_per_col = np.array([len(d) for d in sample_indices], dtype=np.int32)\n+        num_per_col_ptr, _, _ = c_int_array(num_per_col)\n+\n+        self.handle = ctypes.c_void_p()\n+        params_str = param_dict_to_str(self.get_params())\n+        _safe_call(_LIB.LGBM_DatasetCreateFromSampledColumn(\n+            ctypes.cast(sample_col_ptr, ctypes.POINTER(ctypes.POINTER(ctypes.c_double))),\n+            ctypes.cast(indices_col_ptr, ctypes.POINTER(ctypes.POINTER(ctypes.c_int32))),\n+            ctypes.c_int32(ncol),\n+            num_per_col_ptr,\n+            ctypes.c_int32(sample_cnt),\n+            ctypes.c_int32(total_nrow),\n+            c_str(params_str),\n+            ctypes.byref(self.handle),\n+        ))\n+        return self\n+\n+    def _push_rows(self, data: np.ndarray) -> 'Dataset':\n+        \"\"\"Add rows to Dataset.\n+\n+        Parameters\n+        ----------\n+        data : numpy 1-D array\n+            New data to add to the Dataset.\n+\n+        Returns\n+        -------\n+        self : Dataset\n+            Dataset object.\n+        \"\"\"\n+        nrow, ncol = data.shape\n+        data = data.reshape(data.size)\n+        data_ptr, data_type, _ = c_float_array(data)\n+\n+        _safe_call(_LIB.LGBM_DatasetPushRows(\n+            self.handle,\n+            data_ptr,\n+            data_type,\n+            ctypes.c_int32(nrow),\n+            ctypes.c_int32(ncol),\n+            ctypes.c_int32(self._start_row),\n+        ))\n+        self._start_row += nrow\n+        return self\n+\n     def get_params(self):\n         \"\"\"Get the used parameters in the Dataset.\n \n@@ -1262,8 +1480,15 @@ def _lazy_init(self, data, label=None, reference=None,\n             self.__init_from_csc(data, params_str, ref_dataset)\n         elif isinstance(data, np.ndarray):\n             self.__init_from_np2d(data, params_str, ref_dataset)\n-        elif isinstance(data, list) and len(data) > 0 and all(isinstance(x, np.ndarray) for x in data):\n-            self.__init_from_list_np2d(data, params_str, ref_dataset)\n+        elif isinstance(data, list) and len(data) > 0:\n+            if all(isinstance(x, np.ndarray) for x in data):\n+                self.__init_from_list_np2d(data, params_str, ref_dataset)\n+            elif all(isinstance(x, Sequence) for x in data):\n+                self.__init_from_seqs(data, ref_dataset)\n+            else:\n+                raise TypeError('Data list can only be of ndarray or Sequence')\n+        elif isinstance(data, Sequence):\n+            self.__init_from_seqs([data], ref_dataset)\n         elif isinstance(data, dt_DataTable):\n             self.__init_from_np2d(data.to_numpy(), params_str, ref_dataset)\n         else:\n@@ -1291,6 +1516,77 @@ def _lazy_init(self, data, label=None, reference=None,\n         # set feature names\n         return self.set_feature_name(feature_name)\n \n+    def __yield_row_from(self, seqs: List[Sequence], indices: Iterable[int]):\n+        offset = 0\n+        seq_id = 0\n+        seq = seqs[seq_id]\n+        for row_id in indices:\n+            assert row_id >= offset, \"sample indices are expected to be monotonic\"\n+            while row_id >= offset + len(seq):\n+                offset += len(seq)\n+                seq_id += 1\n+                seq = seqs[seq_id]\n+            id_in_seq = row_id - offset\n+            row = seq[id_in_seq]\n+            yield row if row.flags['OWNDATA'] else row.copy()\n+\n+    def __sample(self, seqs: List[Sequence], total_nrow: int) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n+        \"\"\"Sample data from seqs.\n+\n+        Mimics behavior in c_api.cpp:LGBM_DatasetCreateFromMats()\n+\n+        Returns\n+        -------\n+            sampled_rows, sampled_row_indices\n+        \"\"\"\n+        indices = self._create_sample_indices(total_nrow)\n+\n+        # Select sampled rows, transpose to column order.\n+        sampled = np.array([row for row in self.__yield_row_from(seqs, indices)])\n+        sampled = sampled.T\n+\n+        filtered = []\n+        filtered_idx = []\n+        sampled_row_range = np.arange(len(indices), dtype=np.int32)\n+        for col in sampled:\n+            col_predicate = (np.abs(col) > ZERO_THRESHOLD) | np.isnan(col)\n+            filtered_col = col[col_predicate]\n+            filtered_row_idx = sampled_row_range[col_predicate]\n+\n+            filtered.append(filtered_col)\n+            filtered_idx.append(filtered_row_idx)\n+\n+        return filtered, filtered_idx\n+\n+    def __init_from_seqs(self, seqs: List[Sequence], ref_dataset: Optional['Dataset'] = None):\n+        \"\"\"\n+        Initialize data from list of Sequence objects.\n+\n+        Sequence: Generic Data Access Object\n+            Supports random access and access by batch if properly defined by user\n+\n+        Data scheme uniformity are trusted, not checked\n+        \"\"\"\n+        total_nrow = sum(len(seq) for seq in seqs)\n+\n+        # create validation dataset from ref_dataset\n+        if ref_dataset is not None:\n+            self._init_from_ref_dataset(total_nrow, ref_dataset)\n+        else:\n+            param_str = param_dict_to_str(self.get_params())\n+            sample_cnt = _get_sample_count(total_nrow, param_str)\n+\n+            sample_data, col_indices = self.__sample(seqs, total_nrow)\n+            self._init_from_sample(sample_data, col_indices, sample_cnt, total_nrow)\n+\n+        for seq in seqs:\n+            nrow = len(seq)\n+            batch_size = getattr(seq, 'batch_size', None) or Sequence.batch_size\n+            for start in range(0, nrow, batch_size):\n+                end = min(start + batch_size, nrow)\n+                self._push_rows(seq[start:end])\n+        return self\n+\n     def __init_from_np2d(self, mat, params_str, ref_dataset):\n         \"\"\"Initialize data from a 2-D numpy matrix.\"\"\"\n         if len(mat.shape) != 2:\n@@ -1474,7 +1770,7 @@ def create_valid(self, data, label=None, weight=None, group=None,\n \n         Parameters\n         ----------\n-        data : string, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse or list of numpy arrays\n+        data : string, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequences or list of numpy arrays\n             Data source of Dataset.\n             If string, it represents the path to txt file.\n         label : list, numpy 1-D array, pandas Series / one-column DataFrame or None, optional (default=None)\ndiff --git a/src/c_api.cpp b/src/c_api.cpp\nindex 3d20d92da70d..26ef43184a65 100644\n--- a/src/c_api.cpp\n+++ b/src/c_api.cpp\n@@ -894,6 +894,51 @@ int LGBM_RegisterLogCallback(void (*callback)(const char*)) {\n   API_END();\n }\n \n+static inline int SampleCount(int32_t total_nrow, const Config& config) {\n+  return static_cast<int>(total_nrow < config.bin_construct_sample_cnt ? total_nrow : config.bin_construct_sample_cnt);\n+}\n+\n+static inline std::vector<int32_t> CreateSampleIndices(int32_t total_nrow, const Config& config) {\n+  Random rand(config.data_random_seed);\n+  int sample_cnt = SampleCount(total_nrow, config);\n+  return rand.Sample(total_nrow, sample_cnt);\n+}\n+\n+int LGBM_GetSampleCount(int32_t num_total_row,\n+                        const char* parameters,\n+                        int* out) {\n+  API_BEGIN();\n+  if (out == nullptr) {\n+    Log::Fatal(\"LGBM_GetSampleCount output is nullptr\");\n+  }\n+  auto param = Config::Str2Map(parameters);\n+  Config config;\n+  config.Set(param);\n+\n+  *out = SampleCount(num_total_row, config);\n+  API_END();\n+}\n+\n+int LGBM_SampleIndices(int32_t num_total_row,\n+                       const char* parameters,\n+                       void* out,\n+                       int32_t* out_len) {\n+  // This API is to keep python binding's behavior the same with C++ implementation.\n+  // Sample count, random seed etc. should be provided in parameters.\n+  API_BEGIN();\n+  if (out == nullptr) {\n+    Log::Fatal(\"LGBM_SampleIndices output is nullptr\");\n+  }\n+  auto param = Config::Str2Map(parameters);\n+  Config config;\n+  config.Set(param);\n+\n+  auto sample_indices = CreateSampleIndices(num_total_row, config);\n+  memcpy(out, sample_indices.data(), sizeof(int32_t) * sample_indices.size());\n+  *out_len = static_cast<int32_t>(sample_indices.size());\n+  API_END();\n+}\n+\n int LGBM_DatasetCreateFromFile(const char* filename,\n                                const char* parameters,\n                                const DatasetHandle reference,\n@@ -1034,7 +1079,6 @@ int LGBM_DatasetCreateFromMat(const void* data,\n                                     out);\n }\n \n-\n int LGBM_DatasetCreateFromMats(int32_t nmat,\n                                const void** data,\n                                int data_type,\ndiff --git a/tests/python_package_test/test_basic.py b/tests/python_package_test/test_basic.py\nindex b92c7998e554..069dd1b2a63d 100644\n--- a/tests/python_package_test/test_basic.py\n+++ b/tests/python_package_test/test_basic.py\n@@ -1,4 +1,6 @@\n # coding: utf-8\n+import filecmp\n+import numbers\n import os\n \n import numpy as np\n@@ -89,6 +91,109 @@ def test_basic(tmp_path):\n                                    bst.predict, tname)\n \n \n+class NumpySequence(lgb.Sequence):\n+    def __init__(self, ndarray, batch_size):\n+        self.ndarray = ndarray\n+        self.batch_size = batch_size\n+\n+    def __getitem__(self, idx):\n+        # The simple implementation is just a single \"return self.ndarray[idx]\"\n+        # The following is for demo and testing purpose.\n+        if isinstance(idx, numbers.Integral):\n+            return self.ndarray[idx]\n+        elif isinstance(idx, slice):\n+            if not (idx.step is None or idx.step == 1):\n+                raise NotImplementedError(\"No need to implement, caller will not set step by now\")\n+            return self.ndarray[idx.start:idx.stop]\n+        else:\n+            raise TypeError(f\"Sequence Index must be an integer/list/slice, got {type(idx)}\")\n+\n+    def __len__(self):\n+        return len(self.ndarray)\n+\n+\n+def _create_sequence_from_ndarray(data, num_seq, batch_size):\n+    if num_seq == 1:\n+        return NumpySequence(data, batch_size)\n+\n+    nrow = data.shape[0]\n+    seqs = []\n+    seq_size = nrow // num_seq\n+    for start in range(0, nrow, seq_size):\n+        end = min(start + seq_size, nrow)\n+        seq = NumpySequence(data[start:end], batch_size)\n+        seqs.append(seq)\n+    return seqs\n+\n+\n+@pytest.mark.parametrize('sample_count', [11, 100, None])\n+@pytest.mark.parametrize('batch_size', [3, None])\n+@pytest.mark.parametrize('include_0_and_nan', [False, True])\n+@pytest.mark.parametrize('num_seq', [1, 3])\n+def test_sequence(tmpdir, sample_count, batch_size, include_0_and_nan, num_seq):\n+    params = {'bin_construct_sample_cnt': sample_count}\n+\n+    nrow = 50\n+    half_nrow = nrow // 2\n+    ncol = 11\n+    data = np.arange(nrow * ncol, dtype=np.float64).reshape((nrow, ncol))\n+\n+    if include_0_and_nan:\n+        # whole col\n+        data[:, 0] = 0\n+        data[:, 1] = np.nan\n+\n+        # half col\n+        data[:half_nrow, 3] = 0\n+        data[:half_nrow, 2] = np.nan\n+\n+        data[half_nrow:-2, 4] = 0\n+        data[:half_nrow, 4] = np.nan\n+\n+    X = data[:, :-1]\n+    Y = data[:, -1]\n+\n+    npy_bin_fname = os.path.join(tmpdir, 'data_from_npy.bin')\n+    seq_bin_fname = os.path.join(tmpdir, 'data_from_seq.bin')\n+\n+    # Create dataset from numpy array directly.\n+    ds = lgb.Dataset(X, label=Y, params=params)\n+    ds.save_binary(npy_bin_fname)\n+\n+    # Create dataset using Sequence.\n+    seqs = _create_sequence_from_ndarray(X, num_seq, batch_size)\n+    seq_ds = lgb.Dataset(seqs, label=Y, params=params)\n+    seq_ds.save_binary(seq_bin_fname)\n+\n+    assert filecmp.cmp(npy_bin_fname, seq_bin_fname)\n+\n+    # Test for validation set.\n+    # Select some random rows as valid data.\n+    rng = np.random.default_rng()  # Pass integer to set seed when needed.\n+    valid_idx = (rng.random(10) * nrow).astype(np.int)\n+    valid_data = data[valid_idx, :]\n+    valid_X = valid_data[:, :-1]\n+    valid_Y = valid_data[:, -1]\n+\n+    valid_npy_bin_fname = os.path.join(tmpdir, 'valid_data_from_npy.bin')\n+    valid_seq_bin_fname = os.path.join(tmpdir, 'valid_data_from_seq.bin')\n+    valid_seq2_bin_fname = os.path.join(tmpdir, 'valid_data_from_seq2.bin')\n+\n+    valid_ds = lgb.Dataset(valid_X, label=valid_Y, params=params, reference=ds)\n+    valid_ds.save_binary(valid_npy_bin_fname)\n+\n+    # From Dataset constructor, with dataset from numpy array.\n+    valid_seqs = _create_sequence_from_ndarray(valid_X, num_seq, batch_size)\n+    valid_seq_ds = lgb.Dataset(valid_seqs, label=valid_Y, params=params, reference=ds)\n+    valid_seq_ds.save_binary(valid_seq_bin_fname)\n+    assert filecmp.cmp(valid_npy_bin_fname, valid_seq_bin_fname)\n+\n+    # From Dataset.create_valid, with dataset from sequence.\n+    valid_seq_ds2 = seq_ds.create_valid(valid_seqs, label=valid_Y, params=params)\n+    valid_seq_ds2.save_binary(valid_seq2_bin_fname)\n+    assert filecmp.cmp(valid_npy_bin_fname, valid_seq2_bin_fname)\n+\n+\n def test_chunked_dataset():\n     X_train, X_test, y_train, y_test = train_test_split(*load_breast_cancer(return_X_y=True), test_size=0.1,\n                                                         random_state=2)\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Bug in Validation Dataset Attributes**: `num_features_` is incorrectly set to `0`. Ensure it is initialized in `Dataset::CreateValid`. Investigate potential uninitialized variables from PR #4177.\n\n2. **Sample Count Error**: Verify that `rand.Sample` consistently returns the requested number of samples. Update API documentation to reflect any discrepancies.\n\n3. **Type Hinting**: Update to use `numpy.typing` for type hints to avoid linting issues. Change to `List[npt.NDArray[np.float64]]` and `List[npt.NDArray[np.int]]`.\n\n4. **Code Logic Improvement**: Consider a more reliable implementation for sample index logic after the PR merge. Ensure `NextInt(0, r)` in sampling code is corrected to `NextInt(0, r + 1)` to eliminate a reported bug.\n\n5. **Review Request**: Update code reviews to reflect significant changes made since the last approval."
      }
    ],
    "codediff_length": 32690
  },
  {
    "index": 2,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/python-package/lightgbm/dask.py b/python-package/lightgbm/dask.py\nindex 66883c688e4e..5e6436be4736 100644\n--- a/python-package/lightgbm/dask.py\n+++ b/python-package/lightgbm/dask.py\n@@ -9,7 +9,8 @@\n import socket\n from collections import defaultdict\n from copy import deepcopy\n-from typing import Any, Callable, Dict, List, Optional, Type, Union\n+from enum import Enum, auto\n+from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Type, Union\n from urllib.parse import urlparse\n \n import numpy as np\n@@ -18,7 +19,8 @@\n from .basic import _LIB, LightGBMError, _choose_param_value, _ConfigAliases, _log_info, _log_warning, _safe_call\n from .compat import (DASK_INSTALLED, PANDAS_INSTALLED, SKLEARN_INSTALLED, Client, LGBMNotFittedError, concat,\n                      dask_Array, dask_DataFrame, dask_Series, default_client, delayed, pd_DataFrame, pd_Series, wait)\n-from .sklearn import LGBMClassifier, LGBMModel, LGBMRanker, LGBMRegressor, _lgbmmodel_doc_fit, _lgbmmodel_doc_predict\n+from .sklearn import (LGBMClassifier, LGBMModel, LGBMRanker, LGBMRegressor, _lgbmmodel_doc_custom_eval_note,\n+                      _lgbmmodel_doc_fit, _lgbmmodel_doc_predict)\n \n _DaskCollection = Union[dask_Array, dask_DataFrame, dask_Series]\n _DaskMatrixLike = Union[dask_Array, dask_DataFrame]\n@@ -27,6 +29,18 @@\n _PredictionDtype = Union[Type[np.float32], Type[np.float64], Type[np.int32], Type[np.int64]]\n \n \n+class _DatasetNames(Enum):\n+    \"\"\"Placeholder names used by lightgbm.dask internals to say 'also evaluate the training data'.\n+\n+    Avoid duplicating the training data when the validation set refers to elements of training data.\n+    \"\"\"\n+\n+    TRAINSET = auto()\n+    SAMPLE_WEIGHT = auto()\n+    INIT_SCORE = auto()\n+    GROUP = auto()\n+\n+\n def _get_dask_client(client: Optional[Client]) -> Client:\n     \"\"\"Choose a Dask client to use.\n \n@@ -71,6 +85,25 @@ def _concat(seq: List[_DaskPart]) -> _DaskPart:\n         raise TypeError(f'Data must be one of: numpy arrays, pandas dataframes, sparse matrices (from scipy). Got {type(seq[0])}.')\n \n \n+def _remove_list_padding(*args: Any) -> List[List[Any]]:\n+    return [[z for z in arg if z is not None] for arg in args]\n+\n+\n+def _pad_eval_names(lgbm_model: LGBMModel, required_names: Optional[List[str]] = None) -> LGBMModel:\n+    \"\"\"Append missing (key, value) pairs to a LightGBM model's evals_result_ and best_score_ OrderedDict attrs based on a set of required eval_set names.\n+\n+    Allows users to rely on expected eval_set names being present when fitting DaskLGBM estimators with ``eval_set``.\n+    \"\"\"\n+    not_evaluated = 'not evaluated'\n+    for eval_name in required_names:\n+        if eval_name not in lgbm_model.evals_result_:\n+            lgbm_model.evals_result_[eval_name] = not_evaluated\n+        if eval_name not in lgbm_model.best_score_:\n+            lgbm_model.best_score_[eval_name] = not_evaluated\n+\n+    return lgbm_model\n+\n+\n def _train_part(\n     params: Dict[str, Any],\n     model_factory: Type[LGBMModel],\n@@ -111,16 +144,140 @@ def _train_part(\n     else:\n         init_score = None\n \n+    # construct local eval_set data.\n+    n_evals = max(len(x.get('eval_set', [])) for x in list_of_parts)\n+    eval_names = kwargs.pop('eval_names', None)\n+    eval_class_weight = kwargs.get('eval_class_weight')\n+    local_eval_set = None\n+    local_eval_names = None\n+    local_eval_sample_weight = None\n+    local_eval_init_score = None\n+    local_eval_group = None\n+\n+    if n_evals:\n+        has_eval_sample_weight = any(x.get('eval_sample_weight') is not None for x in list_of_parts)\n+        has_eval_init_score = any(x.get('eval_init_score') is not None for x in list_of_parts)\n+\n+        local_eval_set = []\n+        evals_result_names = []\n+        if has_eval_sample_weight:\n+            local_eval_sample_weight = []\n+        if has_eval_init_score:\n+            local_eval_init_score = []\n+        if is_ranker:\n+            local_eval_group = []\n+\n+        # store indices of eval_set components that were not contained within local parts.\n+        missing_eval_component_idx = []\n+\n+        # consolidate parts of each individual eval component.\n+        for i in range(n_evals):\n+            x_e = []\n+            y_e = []\n+            w_e = []\n+            init_score_e = []\n+            g_e = []\n+            for part in list_of_parts:\n+                if not part.get('eval_set'):\n+                    continue\n+\n+                # require that eval_name exists in evaluated result data in case dropped due to padding.\n+                # in distributed training the 'training' eval_set is not detected, will have name 'valid_<index>'.\n+                if eval_names:\n+                    evals_result_name = eval_names[i]\n+                else:\n+                    evals_result_name = f'valid_{i}'\n+\n+                eval_set = part['eval_set'][i]\n+                if eval_set is _DatasetNames.TRAINSET:\n+                    x_e.append(part['data'])\n+                    y_e.append(part['label'])\n+                else:\n+                    x_e.extend(eval_set[0])\n+                    y_e.extend(eval_set[1])\n+\n+                if evals_result_name not in evals_result_names:\n+                    evals_result_names.append(evals_result_name)\n+\n+                eval_weight = part.get('eval_sample_weight')\n+                if eval_weight:\n+                    if eval_weight[i] is _DatasetNames.SAMPLE_WEIGHT:\n+                        w_e.append(part['weight'])\n+                    else:\n+                        w_e.extend(eval_weight[i])\n+\n+                eval_init_score = part.get('eval_init_score')\n+                if eval_init_score:\n+                    if eval_init_score[i] is _DatasetNames.INIT_SCORE:\n+                        init_score_e.append(part['init_score'])\n+                    else:\n+                        init_score_e.extend(eval_init_score[i])\n+\n+                eval_group = part.get('eval_group')\n+                if eval_group:\n+                    if eval_group[i] is _DatasetNames.GROUP:\n+                        g_e.append(part['group'])\n+                    else:\n+                        g_e.extend(eval_group[i])\n+\n+            # filter padding from eval parts then _concat each eval_set component.\n+            x_e, y_e, w_e, init_score_e, g_e = _remove_list_padding(x_e, y_e, w_e, init_score_e, g_e)\n+            if x_e:\n+                local_eval_set.append((_concat(x_e), _concat(y_e)))\n+            else:\n+                missing_eval_component_idx.append(i)\n+                continue\n+\n+            if w_e:\n+                local_eval_sample_weight.append(_concat(w_e))\n+            if init_score_e:\n+                local_eval_init_score.append(_concat(init_score_e))\n+            if g_e:\n+                local_eval_group.append(_concat(g_e))\n+\n+        # reconstruct eval_set fit args/kwargs depending on which components of eval_set are on worker.\n+        eval_component_idx = [i for i in range(n_evals) if i not in missing_eval_component_idx]\n+        if eval_names:\n+            local_eval_names = [eval_names[i] for i in eval_component_idx]\n+        if eval_class_weight:\n+            kwargs['eval_class_weight'] = [eval_class_weight[i] for i in eval_component_idx]\n+\n     try:\n         model = model_factory(**params)\n         if is_ranker:\n-            model.fit(data, label, sample_weight=weight, init_score=init_score, group=group, **kwargs)\n+            model.fit(\n+                data,\n+                label,\n+                sample_weight=weight,\n+                init_score=init_score,\n+                group=group,\n+                eval_set=local_eval_set,\n+                eval_sample_weight=local_eval_sample_weight,\n+                eval_init_score=local_eval_init_score,\n+                eval_group=local_eval_group,\n+                eval_names=local_eval_names,\n+                **kwargs\n+            )\n         else:\n-            model.fit(data, label, sample_weight=weight, init_score=init_score, **kwargs)\n+            model.fit(\n+                data,\n+                label,\n+                sample_weight=weight,\n+                init_score=init_score,\n+                eval_set=local_eval_set,\n+                eval_sample_weight=local_eval_sample_weight,\n+                eval_init_score=local_eval_init_score,\n+                eval_names=local_eval_names,\n+                **kwargs\n+            )\n \n     finally:\n         _safe_call(_LIB.LGBM_NetworkFree())\n \n+    if n_evals:\n+        # ensure that expected keys for evals_result_ and best_score_ exist regardless of padding.\n+        model = _pad_eval_names(model, required_names=evals_result_names)\n+\n     return model if return_model else None\n \n \n@@ -218,6 +375,14 @@ def _train(\n     sample_weight: Optional[_DaskVectorLike] = None,\n     init_score: Optional[_DaskVectorLike] = None,\n     group: Optional[_DaskVectorLike] = None,\n+    eval_set: Optional[List[Tuple[_DaskMatrixLike, _DaskCollection]]] = None,\n+    eval_names: Optional[List[str]] = None,\n+    eval_sample_weight: Optional[List[_DaskCollection]] = None,\n+    eval_class_weight: Optional[List[Union[dict, str]]] = None,\n+    eval_init_score: Optional[List[_DaskCollection]] = None,\n+    eval_group: Optional[List[_DaskCollection]] = None,\n+    eval_metric: Optional[Union[Callable, str, List[Union[Callable, str]]]] = None,\n+    eval_at: Optional[Iterable[int]] = None,\n     **kwargs: Any\n ) -> LGBMModel:\n     \"\"\"Inner train routine.\n@@ -244,6 +409,29 @@ def _train(\n         sum(group) = n_samples.\n         For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n         where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n+    eval_set : list of (X, y) tuples of Dask data collections or None, optional (default=None)\n+        List of (X, y) tuple pairs to use as validation sets.\n+        Note, that not all workers may receive chunks of every eval set within ``eval_set``. When the returned\n+        lightgbm estimator is not trained using any chunks of a particular eval set, its corresponding component\n+        of evals_result_ and best_score_ will be 'not_evaluated'.\n+    eval_names : list of strings or None, optional (default=None)\n+        Names of eval_set.\n+    eval_sample_weight : list of Dask Arrays, Dask Series or None, optional (default=None)\n+        Weights for each validation set in eval_set.\n+    eval_class_weight : list of dict or str, or None, optional (default=None)\n+        Class weights, one dict or str for each validation set in eval_set.\n+    eval_init_score : list of Dask Arrays, Dask Series or None, optional (default=None)\n+        Initial model score for each validation set in eval_set.\n+    eval_group : list of Dask Arrays, Dask Series or None, optional (default=None)\n+        Group/query for each validation set in eval_set.\n+    eval_metric : string, callable, list or None, optional (default=None)\n+        If string, it should be a built-in evaluation metric to use.\n+        If callable, it should be a custom evaluation metric, see note below for more details.\n+        If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.\n+        In either case, the ``metric`` from the Dask model parameters (or inferred from the objective) will be evaluated and used as well.\n+        Default: 'l2' for DaskLGBMRegressor, 'binary(multi)_logloss' for DaskLGBMClassifier, 'ndcg' for DaskLGBMRanker.\n+    eval_at : iterable of int, optional (default=None)\n+        The evaluation positions of the specified ranking metric.\n     **kwargs\n         Other parameters passed to ``fit`` method of the local underlying model.\n \n@@ -339,6 +527,116 @@ def _train(\n         for i in range(n_parts):\n             parts[i]['init_score'] = init_score_parts[i]\n \n+    # evals_set will to be re-constructed into smaller lists of (X, y) tuples, where\n+    # X and y are each delayed sub-lists of original eval dask Collections.\n+    if eval_set:\n+        # find maximum number of parts in an individual eval set so that we can\n+        # pad eval sets when they come in different sizes.\n+        n_largest_eval_parts = max(x[0].npartitions for x in eval_set)\n+\n+        eval_sets = defaultdict(list)\n+        if eval_sample_weight:\n+            eval_sample_weights = defaultdict(list)\n+        if eval_group:\n+            eval_groups = defaultdict(list)\n+        if eval_init_score:\n+            eval_init_scores = defaultdict(list)\n+\n+        for i, (X_eval, y_eval) in enumerate(eval_set):\n+            n_this_eval_parts = X_eval.npartitions\n+\n+            # when individual eval set is equivalent to training data, skip recomputing parts.\n+            if X_eval is data and y_eval is label:\n+                for parts_idx in range(n_parts):\n+                    eval_sets[parts_idx].append(_DatasetNames.TRAINSET)\n+            else:\n+                eval_x_parts = _split_to_parts(data=X_eval, is_matrix=True)\n+                eval_y_parts = _split_to_parts(data=y_eval, is_matrix=False)\n+                for j in range(n_largest_eval_parts):\n+                    parts_idx = j % n_parts\n+\n+                    # add None-padding for individual eval_set member if it is smaller than the largest member.\n+                    if j < n_this_eval_parts:\n+                        x_e = eval_x_parts[j]\n+                        y_e = eval_y_parts[j]\n+                    else:\n+                        x_e = None\n+                        y_e = None\n+\n+                    if j < n_parts:\n+                        # first time a chunk of this eval set is added to this part.\n+                        eval_sets[parts_idx].append(([x_e], [y_e]))\n+                    else:\n+                        # append additional chunks of this eval set to this part.\n+                        eval_sets[parts_idx][-1][0].append(x_e)\n+                        eval_sets[parts_idx][-1][1].append(y_e)\n+\n+            if eval_sample_weight:\n+                if eval_sample_weight[i] is sample_weight:\n+                    for parts_idx in range(n_parts):\n+                        eval_sample_weights[parts_idx].append(_DatasetNames.SAMPLE_WEIGHT)\n+                else:\n+                    eval_w_parts = _split_to_parts(data=eval_sample_weight[i], is_matrix=False)\n+\n+                    # ensure that all evaluation parts map uniquely to one part.\n+                    for j in range(n_largest_eval_parts):\n+                        if j < n_this_eval_parts:\n+                            w_e = eval_w_parts[j]\n+                        else:\n+                            w_e = None\n+\n+                        parts_idx = j % n_parts\n+                        if j < n_parts:\n+                            eval_sample_weights[parts_idx].append([w_e])\n+                        else:\n+                            eval_sample_weights[parts_idx][-1].append(w_e)\n+\n+            if eval_init_score:\n+                if eval_init_score[i] is init_score:\n+                    for parts_idx in range(n_parts):\n+                        eval_init_scores[parts_idx].append(_DatasetNames.INIT_SCORE)\n+                else:\n+                    eval_init_score_parts = _split_to_parts(data=eval_init_score[i], is_matrix=False)\n+                    for j in range(n_largest_eval_parts):\n+                        if j < n_this_eval_parts:\n+                            init_score_e = eval_init_score_parts[j]\n+                        else:\n+                            init_score_e = None\n+\n+                        parts_idx = j % n_parts\n+                        if j < n_parts:\n+                            eval_init_scores[parts_idx].append([init_score_e])\n+                        else:\n+                            eval_init_scores[parts_idx][-1].append(init_score_e)\n+\n+            if eval_group:\n+                if eval_group[i] is group:\n+                    for parts_idx in range(n_parts):\n+                        eval_groups[parts_idx].append(_DatasetNames.GROUP)\n+                else:\n+                    eval_g_parts = _split_to_parts(data=eval_group[i], is_matrix=False)\n+                    for j in range(n_largest_eval_parts):\n+                        if j < n_this_eval_parts:\n+                            g_e = eval_g_parts[j]\n+                        else:\n+                            g_e = None\n+\n+                        parts_idx = j % n_parts\n+                        if j < n_parts:\n+                            eval_groups[parts_idx].append([g_e])\n+                        else:\n+                            eval_groups[parts_idx][-1].append(g_e)\n+\n+        # assign sub-eval_set components to worker parts.\n+        for parts_idx, e_set in eval_sets.items():\n+            parts[parts_idx]['eval_set'] = e_set\n+            if eval_sample_weight:\n+                parts[parts_idx]['eval_sample_weight'] = eval_sample_weights[parts_idx]\n+            if eval_init_score:\n+                parts[parts_idx]['eval_init_score'] = eval_init_scores[parts_idx]\n+            if eval_group:\n+                parts[parts_idx]['eval_group'] = eval_groups[parts_idx]\n+\n     # Start computation in the background\n     parts = list(map(delayed, parts))\n     parts = client.compute(parts)\n@@ -355,6 +653,32 @@ def _train(\n     for key, workers in who_has.items():\n         worker_map[next(iter(workers))].append(key_to_part_dict[key])\n \n+    # Check that all workers were provided some of eval_set. Otherwise warn user that validation\n+    # data artifacts may not be populated depending on worker returning final estimator.\n+    if eval_set:\n+        for worker in worker_map:\n+            has_eval_set = False\n+            for part in worker_map[worker]:\n+                if 'eval_set' in part.result():\n+                    has_eval_set = True\n+                    break\n+\n+            if not has_eval_set:\n+                _log_warning(\n+                    f\"Worker {worker} was not allocated eval_set data. Therefore evals_result_ and best_score_ data may be unreliable. \"\n+                    \"Try rebalancing data across workers.\"\n+                )\n+\n+    # assign general validation set settings to fit kwargs.\n+    if eval_names:\n+        kwargs['eval_names'] = eval_names\n+    if eval_class_weight:\n+        kwargs['eval_class_weight'] = eval_class_weight\n+    if eval_metric:\n+        kwargs['eval_metric'] = eval_metric\n+    if eval_at:\n+        kwargs['eval_at'] = eval_at\n+\n     master_worker = next(iter(worker_map))\n     worker_ncores = client.ncores()\n \n@@ -607,11 +931,23 @@ def _lgb_dask_fit(\n         sample_weight: Optional[_DaskVectorLike] = None,\n         init_score: Optional[_DaskVectorLike] = None,\n         group: Optional[_DaskVectorLike] = None,\n+        eval_set: Optional[List[Tuple[_DaskMatrixLike, _DaskCollection]]] = None,\n+        eval_names: Optional[List[str]] = None,\n+        eval_sample_weight: Optional[List[_DaskCollection]] = None,\n+        eval_class_weight: Optional[List[Union[dict, str]]] = None,\n+        eval_init_score: Optional[List[_DaskCollection]] = None,\n+        eval_group: Optional[List[_DaskCollection]] = None,\n+        eval_metric: Optional[Union[Callable, str, List[Union[Callable, str]]]] = None,\n+        eval_at: Optional[Iterable[int]] = None,\n+        early_stopping_rounds: Optional[int] = None,\n         **kwargs: Any\n     ) -> \"_DaskLGBMModel\":\n         if not all((DASK_INSTALLED, PANDAS_INSTALLED, SKLEARN_INSTALLED)):\n             raise LightGBMError('dask, pandas and scikit-learn are required for lightgbm.dask')\n \n+        if early_stopping_rounds is not None:\n+            raise RuntimeError('early_stopping_rounds is not currently supported in lightgbm.dask')\n+\n         params = self.get_params(True)\n         params.pop(\"client\", None)\n \n@@ -624,6 +960,14 @@ def _lgb_dask_fit(\n             sample_weight=sample_weight,\n             init_score=init_score,\n             group=group,\n+            eval_set=eval_set,\n+            eval_names=eval_names,\n+            eval_sample_weight=eval_sample_weight,\n+            eval_class_weight=eval_class_weight,\n+            eval_init_score=eval_init_score,\n+            eval_group=eval_group,\n+            eval_metric=eval_metric,\n+            eval_at=eval_at,\n             **kwargs\n         )\n \n@@ -724,15 +1068,31 @@ def fit(\n         y: _DaskCollection,\n         sample_weight: Optional[_DaskVectorLike] = None,\n         init_score: Optional[_DaskVectorLike] = None,\n+        eval_set: Optional[List[Tuple[_DaskMatrixLike, _DaskCollection]]] = None,\n+        eval_names: Optional[List[str]] = None,\n+        eval_sample_weight: Optional[List[_DaskCollection]] = None,\n+        eval_class_weight: Optional[List[Union[dict, str]]] = None,\n+        eval_init_score: Optional[List[_DaskCollection]] = None,\n+        eval_metric: Optional[Union[Callable, str, List[Union[Callable, str]]]] = None,\n+        early_stopping_rounds: Optional[int] = None,\n         **kwargs: Any\n     ) -> \"DaskLGBMClassifier\":\n         \"\"\"Docstring is inherited from the lightgbm.LGBMClassifier.fit.\"\"\"\n+        if early_stopping_rounds is not None:\n+            raise RuntimeError('early_stopping_rounds is not currently supported in lightgbm.dask')\n+\n         return self._lgb_dask_fit(\n             model_factory=LGBMClassifier,\n             X=X,\n             y=y,\n             sample_weight=sample_weight,\n             init_score=init_score,\n+            eval_set=eval_set,\n+            eval_names=eval_names,\n+            eval_sample_weight=eval_sample_weight,\n+            eval_class_weight=eval_class_weight,\n+            eval_init_score=eval_init_score,\n+            eval_metric=eval_metric,\n             **kwargs\n         )\n \n@@ -741,16 +1101,27 @@ def fit(\n         y_shape=\"Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]\",\n         sample_weight_shape=\"Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\",\n         init_score_shape=\"Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\",\n-        group_shape=\"Dask Array or Dask Series or None, optional (default=None)\"\n+        group_shape=\"Dask Array or Dask Series or None, optional (default=None)\",\n+        eval_sample_weight_shape=\"list of Dask Arrays or Dask Series or None, optional (default=None)\",\n+        eval_init_score_shape=\"list of Dask Arrays or Dask Series or None, optional (default=None)\",\n+        eval_group_shape=\"list of Dask Arrays or Dask Series or None, optional (default=None)\"\n     )\n \n-    # DaskLGBMClassifier does not support evaluation data, or early stopping\n+    # DaskLGBMClassifier does not support group, eval_group, early_stopping_rounds.\n     _base_doc = (_base_doc[:_base_doc.find('group :')]\n+                 + _base_doc[_base_doc.find('eval_set :'):])\n+\n+    _base_doc = (_base_doc[:_base_doc.find('eval_group :')]\n+                 + _base_doc[_base_doc.find('eval_metric :'):])\n+\n+    _base_doc = (_base_doc[:_base_doc.find('early_stopping_rounds :')]\n                  + _base_doc[_base_doc.find('verbose :'):])\n \n     # DaskLGBMClassifier support for callbacks and init_model is not tested\n     fit.__doc__ = f\"\"\"{_base_doc[:_base_doc.find('callbacks :')]}**kwargs\n         Other parameters passed through to ``LGBMClassifier.fit()``.\n+\n+    {_lgbmmodel_doc_custom_eval_note}\n         \"\"\"\n \n     def predict(self, X: _DaskMatrixLike, **kwargs: Any) -> dask_Array:\n@@ -874,15 +1245,29 @@ def fit(\n         y: _DaskCollection,\n         sample_weight: Optional[_DaskVectorLike] = None,\n         init_score: Optional[_DaskVectorLike] = None,\n+        eval_set: Optional[List[Tuple[_DaskMatrixLike, _DaskCollection]]] = None,\n+        eval_names: Optional[List[str]] = None,\n+        eval_sample_weight: Optional[List[_DaskCollection]] = None,\n+        eval_init_score: Optional[List[_DaskCollection]] = None,\n+        eval_metric: Optional[Union[Callable, str, List[Union[Callable, str]]]] = None,\n+        early_stopping_rounds: Optional[int] = None,\n         **kwargs: Any\n     ) -> \"DaskLGBMRegressor\":\n         \"\"\"Docstring is inherited from the lightgbm.LGBMRegressor.fit.\"\"\"\n+        if early_stopping_rounds is not None:\n+            raise RuntimeError('early_stopping_rounds is not currently supported in lightgbm.dask')\n+\n         return self._lgb_dask_fit(\n             model_factory=LGBMRegressor,\n             X=X,\n             y=y,\n             sample_weight=sample_weight,\n             init_score=init_score,\n+            eval_set=eval_set,\n+            eval_names=eval_names,\n+            eval_sample_weight=eval_sample_weight,\n+            eval_init_score=eval_init_score,\n+            eval_metric=eval_metric,\n             **kwargs\n         )\n \n@@ -891,16 +1276,30 @@ def fit(\n         y_shape=\"Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]\",\n         sample_weight_shape=\"Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\",\n         init_score_shape=\"Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\",\n-        group_shape=\"Dask Array or Dask Series or None, optional (default=None)\"\n+        group_shape=\"Dask Array or Dask Series or None, optional (default=None)\",\n+        eval_sample_weight_shape=\"list of Dask Arrays or Dask Series or None, optional (default=None)\",\n+        eval_init_score_shape=\"list of Dask Arrays or Dask Series or None, optional (default=None)\",\n+        eval_group_shape=\"list of Dask Arrays or Dask Series or None, optional (default=None)\"\n     )\n \n-    # DaskLGBMRegressor does not support evaluation data, or early stopping\n+    # DaskLGBMRegressor does not support group, eval_class_weight, eval_group, early_stopping_rounds.\n     _base_doc = (_base_doc[:_base_doc.find('group :')]\n+                 + _base_doc[_base_doc.find('eval_set :'):])\n+\n+    _base_doc = (_base_doc[:_base_doc.find('eval_class_weight :')]\n+                 + _base_doc[_base_doc.find('eval_init_score :'):])\n+\n+    _base_doc = (_base_doc[:_base_doc.find('eval_group :')]\n+                 + _base_doc[_base_doc.find('eval_metric :'):])\n+\n+    _base_doc = (_base_doc[:_base_doc.find('early_stopping_rounds :')]\n                  + _base_doc[_base_doc.find('verbose :'):])\n \n     # DaskLGBMRegressor support for callbacks and init_model is not tested\n     fit.__doc__ = f\"\"\"{_base_doc[:_base_doc.find('callbacks :')]}**kwargs\n         Other parameters passed through to ``LGBMRegressor.fit()``.\n+\n+    {_lgbmmodel_doc_custom_eval_note}\n         \"\"\"\n \n     def predict(self, X: _DaskMatrixLike, **kwargs) -> dask_Array:\n@@ -1007,9 +1406,20 @@ def fit(\n         sample_weight: Optional[_DaskVectorLike] = None,\n         init_score: Optional[_DaskVectorLike] = None,\n         group: Optional[_DaskVectorLike] = None,\n+        eval_set: Optional[List[Tuple[_DaskMatrixLike, _DaskCollection]]] = None,\n+        eval_names: Optional[List[str]] = None,\n+        eval_sample_weight: Optional[List[_DaskCollection]] = None,\n+        eval_init_score: Optional[List[_DaskCollection]] = None,\n+        eval_group: Optional[List[_DaskCollection]] = None,\n+        eval_metric: Optional[Union[Callable, str, List[Union[Callable, str]]]] = None,\n+        eval_at: Iterable[int] = (1, 2, 3, 4, 5),\n+        early_stopping_rounds: Optional[int] = None,\n         **kwargs: Any\n     ) -> \"DaskLGBMRanker\":\n         \"\"\"Docstring is inherited from the lightgbm.LGBMRanker.fit.\"\"\"\n+        if early_stopping_rounds is not None:\n+            raise RuntimeError('early_stopping_rounds is not currently supported in lightgbm.dask')\n+\n         return self._lgb_dask_fit(\n             model_factory=LGBMRanker,\n             X=X,\n@@ -1017,6 +1427,13 @@ def fit(\n             sample_weight=sample_weight,\n             init_score=init_score,\n             group=group,\n+            eval_set=eval_set,\n+            eval_names=eval_names,\n+            eval_sample_weight=eval_sample_weight,\n+            eval_init_score=eval_init_score,\n+            eval_group=eval_group,\n+            eval_metric=eval_metric,\n+            eval_at=eval_at,\n             **kwargs\n         )\n \n@@ -1025,16 +1442,26 @@ def fit(\n         y_shape=\"Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]\",\n         sample_weight_shape=\"Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\",\n         init_score_shape=\"Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)\",\n-        group_shape=\"Dask Array or Dask Series or None, optional (default=None)\"\n+        group_shape=\"Dask Array or Dask Series or None, optional (default=None)\",\n+        eval_sample_weight_shape=\"list of Dask Arrays or Dask Series or None, optional (default=None)\",\n+        eval_init_score_shape=\"list of Dask Arrays or Dask Series or None, optional (default=None)\",\n+        eval_group_shape=\"list of Dask Arrays or Dask Series or None, optional (default=None)\"\n     )\n \n-    # DaskLGBMRanker does not support evaluation data, or early stopping\n-    _base_doc = (_base_doc[:_base_doc.find('eval_set :')]\n-                 + _base_doc[_base_doc.find('verbose :'):])\n+    # DaskLGBMRanker does not support eval_class_weight or early stopping\n+    _base_doc = (_base_doc[:_base_doc.find('eval_class_weight :')]\n+                 + _base_doc[_base_doc.find('eval_init_score :'):])\n+\n+    _base_doc = (_base_doc[:_base_doc.find('early_stopping_rounds :')]\n+                 + \"eval_at : iterable of int, optional (default=(1, 2, 3, 4, 5))\\n\"\n+                 + f\"{' ':8}The evaluation positions of the specified metric.\\n\"\n+                 + f\"{' ':4}{_base_doc[_base_doc.find('verbose :'):]}\")\n \n     # DaskLGBMRanker support for callbacks and init_model is not tested\n     fit.__doc__ = f\"\"\"{_base_doc[:_base_doc.find('callbacks :')]}**kwargs\n         Other parameters passed through to ``LGBMRanker.fit()``.\n+\n+    {_lgbmmodel_doc_custom_eval_note}\n         \"\"\"\n \n     def predict(self, X: _DaskMatrixLike, **kwargs: Any) -> dask_Array:\ndiff --git a/python-package/lightgbm/sklearn.py b/python-package/lightgbm/sklearn.py\nindex cb7dd95a92f0..cf881024e325 100644\n--- a/python-package/lightgbm/sklearn.py\n+++ b/python-package/lightgbm/sklearn.py\n@@ -207,13 +207,13 @@ def __call__(self, preds, dataset):\n         A list of (X, y) tuple pairs to use as validation sets.\n     eval_names : list of strings or None, optional (default=None)\n         Names of eval_set.\n-    eval_sample_weight : list of arrays or None, optional (default=None)\n+    eval_sample_weight : {eval_sample_weight_shape}\n         Weights of eval data.\n     eval_class_weight : list or None, optional (default=None)\n         Class weights of eval data.\n-    eval_init_score : list of arrays or None, optional (default=None)\n+    eval_init_score : {eval_init_score_shape}\n         Init score of eval data.\n-    eval_group : list of arrays or None, optional (default=None)\n+    eval_group : {eval_group_shape}\n         Group data of eval data.\n     eval_metric : string, callable, list or None, optional (default=None)\n         If string, it should be a built-in evaluation metric to use.\n@@ -718,7 +718,10 @@ def _get_meta_data(collection, name, i):\n         y_shape=\"array-like of shape = [n_samples]\",\n         sample_weight_shape=\"array-like of shape = [n_samples] or None, optional (default=None)\",\n         init_score_shape=\"array-like of shape = [n_samples] or None, optional (default=None)\",\n-        group_shape=\"array-like or None, optional (default=None)\"\n+        group_shape=\"array-like or None, optional (default=None)\",\n+        eval_sample_weight_shape=\"list of arrays or None, optional (default=None)\",\n+        eval_init_score_shape=\"list of arrays or None, optional (default=None)\",\n+        eval_group_shape=\"list of arrays or None, optional (default=None)\"\n     ) + \"\\n\\n\" + _lgbmmodel_doc_custom_eval_note\n \n     def predict(self, X, raw_score=False, start_iteration=0, num_iteration=None,\ndiff --git a/tests/python_package_test/test_dask.py b/tests/python_package_test/test_dask.py\nindex 10c0bc93ed51..ada06c8de55b 100644\n--- a/tests/python_package_test/test_dask.py\n+++ b/tests/python_package_test/test_dask.py\n@@ -214,6 +214,13 @@ def _accuracy_score(dy_true, dy_pred):\n     return da.average(dy_true == dy_pred).compute()\n \n \n+def _constant_metric(dy_true, dy_pred):\n+    metric_name = 'constant_metric'\n+    value = 0.708\n+    is_higher_better = False\n+    return metric_name, value, is_higher_better\n+\n+\n def _pickle(obj, filepath, serializer):\n     if serializer == 'pickle':\n         with open(filepath, 'wb') as f:\n@@ -717,6 +724,231 @@ def test_ranker(output, group, boosting_type, tree_learner, cluster):\n             assert tree_df.loc[node_uses_cat_col, \"decision_type\"].unique()[0] == '=='\n \n \n+@pytest.mark.parametrize('task', tasks)\n+@pytest.mark.parametrize('output', data_output)\n+@pytest.mark.parametrize('eval_sizes', [[0.5, 1, 1.5], [0]])\n+@pytest.mark.parametrize('eval_names_prefix', ['specified', None])\n+def test_eval_set_no_early_stopping(task, output, eval_sizes, eval_names_prefix, cluster):\n+    if task == 'ranking' and output == 'scipy_csr_matrix':\n+        pytest.skip('LGBMRanker is not currently tested on sparse matrices')\n+\n+    with Client(cluster) as client:\n+        # Use larger trainset to prevent premature stopping due to zero loss, causing num_trees() < n_estimators.\n+        # Use small chunk_size to avoid single-worker allocation of eval data partitions.\n+        n_samples = 1000\n+        chunk_size = 10\n+        n_eval_sets = len(eval_sizes)\n+        eval_set = []\n+        eval_sample_weight = []\n+        eval_class_weight = None\n+        eval_init_score = None\n+\n+        if eval_names_prefix:\n+            eval_names = [f'{eval_names_prefix}_{i}' for i in range(len(eval_sizes))]\n+        else:\n+            eval_names = None\n+\n+        X, y, w, g, dX, dy, dw, dg = _create_data(\n+            objective=task,\n+            n_samples=n_samples,\n+            output=output,\n+            chunk_size=chunk_size\n+        )\n+\n+        if task == 'ranking':\n+            eval_metrics = ['ndcg']\n+            eval_at = (5, 6)\n+            eval_metric_names = [f'ndcg@{k}' for k in eval_at]\n+            eval_group = []\n+        else:\n+            # test eval_class_weight, eval_init_score on binary-classification task.\n+            # Note: objective's default `metric` will be evaluated in evals_result_ in addition to all eval_metrics.\n+            if task == 'binary-classification':\n+                eval_metrics = ['binary_error', 'auc']\n+                eval_metric_names = ['binary_logloss', 'binary_error', 'auc']\n+                eval_class_weight = []\n+                eval_init_score = []\n+            elif task == 'multiclass-classification':\n+                eval_metrics = ['multi_error']\n+                eval_metric_names = ['multi_logloss', 'multi_error']\n+            elif task == 'regression':\n+                eval_metrics = ['l1']\n+                eval_metric_names = ['l2', 'l1']\n+\n+        # create eval_sets by creating new datasets or copying training data.\n+        for eval_size in eval_sizes:\n+            if eval_size == 1:\n+                y_e = y\n+                dX_e = dX\n+                dy_e = dy\n+                dw_e = dw\n+                dg_e = dg\n+            else:\n+                n_eval_samples = max(chunk_size, int(n_samples * eval_size))\n+                _, y_e, _, _, dX_e, dy_e, dw_e, dg_e = _create_data(\n+                    objective=task,\n+                    n_samples=n_eval_samples,\n+                    output=output,\n+                    chunk_size=chunk_size\n+                )\n+\n+            eval_set.append((dX_e, dy_e))\n+            eval_sample_weight.append(dw_e)\n+            if task == 'ranking':\n+                eval_group.append(dg_e)\n+\n+            if task == 'binary-classification':\n+                n_neg = np.sum(y_e == 0)\n+                n_pos = np.sum(y_e == 1)\n+                eval_class_weight.append({0: n_neg / n_pos, 1: n_pos / n_neg})\n+                init_score_value = np.log(np.mean(y_e) / (1 - np.mean(y_e)))\n+                if 'dataframe' in output:\n+                    d_init_score = dy_e.map_partitions(lambda x: pd.Series([init_score_value] * x.size))\n+                else:\n+                    d_init_score = dy_e.map_blocks(lambda x: np.repeat(init_score_value, x.size))\n+\n+                eval_init_score.append(d_init_score)\n+\n+        fit_trees = 50\n+        params = {\n+            \"random_state\": 42,\n+            \"n_estimators\": fit_trees,\n+            \"num_leaves\": 2\n+        }\n+\n+        model_factory = task_to_dask_factory[task]\n+        dask_model = model_factory(\n+            client=client,\n+            **params\n+        )\n+\n+        fit_params = {\n+            'X': dX,\n+            'y': dy,\n+            'eval_set': eval_set,\n+            'eval_names': eval_names,\n+            'eval_sample_weight': eval_sample_weight,\n+            'eval_init_score': eval_init_score,\n+            'eval_metric': eval_metrics,\n+            'verbose': True\n+        }\n+        if task == 'ranking':\n+            fit_params.update(\n+                {'group': dg,\n+                 'eval_group': eval_group,\n+                 'eval_at': eval_at}\n+            )\n+        elif task == 'binary-classification':\n+            fit_params.update({'eval_class_weight': eval_class_weight})\n+\n+        if eval_sizes == [0]:\n+            with pytest.warns(UserWarning, match='Worker (.*) was not allocated eval_set data. Therefore evals_result_ and best_score_ data may be unreliable.'):\n+                dask_model.fit(**fit_params)\n+        else:\n+            dask_model = dask_model.fit(**fit_params)\n+\n+            # total number of trees scales up for ova classifier.\n+            if task == 'multiclass-classification':\n+                model_trees = fit_trees * dask_model.n_classes_\n+            else:\n+                model_trees = fit_trees\n+\n+            # check that early stopping was not applied.\n+            assert dask_model.booster_.num_trees() == model_trees\n+            assert dask_model.best_iteration_ is None\n+\n+            # checks that evals_result_ and best_score_ contain expected data and eval_set names.\n+            evals_result = dask_model.evals_result_\n+            best_scores = dask_model.best_score_\n+            assert len(evals_result) == n_eval_sets\n+            assert len(best_scores) == n_eval_sets\n+\n+            for eval_name in evals_result:\n+                assert eval_name in dask_model.best_score_\n+                if eval_names:\n+                    assert eval_name in eval_names\n+\n+                # check that each eval_name and metric exists for all eval sets, allowing for the\n+                # case when a worker receives a fully-padded eval_set component which is not evaluated.\n+                if evals_result[eval_name] != 'not evaluated':\n+                    for metric in eval_metric_names:\n+                        assert metric in evals_result[eval_name]\n+                        assert metric in best_scores[eval_name]\n+                        assert len(evals_result[eval_name][metric]) == fit_trees\n+\n+\n+@pytest.mark.parametrize('task', ['binary-classification', 'regression', 'ranking'])\n+def test_eval_set_with_custom_eval_metric(task, cluster):\n+    with Client(cluster) as client:\n+        n_samples = 1000\n+        n_eval_samples = int(n_samples * 0.5)\n+        chunk_size = 10\n+        output = 'array'\n+\n+        X, y, w, g, dX, dy, dw, dg = _create_data(\n+            objective=task,\n+            n_samples=n_samples,\n+            output=output,\n+            chunk_size=chunk_size\n+        )\n+        _, _, _, _, dX_e, dy_e, _, dg_e = _create_data(\n+            objective=task,\n+            n_samples=n_eval_samples,\n+            output=output,\n+            chunk_size=chunk_size\n+        )\n+\n+        if task == 'ranking':\n+            eval_at = (5, 6)\n+            eval_metrics = ['ndcg', _constant_metric]\n+            eval_metric_names = [f'ndcg@{k}' for k in eval_at] + ['constant_metric']\n+        elif task == 'binary-classification':\n+            eval_metrics = ['binary_error', 'auc', _constant_metric]\n+            eval_metric_names = ['binary_logloss', 'binary_error', 'auc', 'constant_metric']\n+        else:\n+            eval_metrics = ['l1', _constant_metric]\n+            eval_metric_names = ['l2', 'l1', 'constant_metric']\n+\n+        fit_trees = 50\n+        params = {\n+            \"random_state\": 42,\n+            \"n_estimators\": fit_trees,\n+            \"num_leaves\": 2\n+        }\n+        model_factory = task_to_dask_factory[task]\n+        dask_model = model_factory(\n+            client=client,\n+            **params\n+        )\n+\n+        eval_set = [(dX_e, dy_e)]\n+        fit_params = {\n+            'X': dX,\n+            'y': dy,\n+            'eval_set': eval_set,\n+            'eval_metric': eval_metrics\n+        }\n+        if task == 'ranking':\n+            fit_params.update(\n+                {'group': dg,\n+                 'eval_group': [dg_e],\n+                 'eval_at': eval_at}\n+            )\n+\n+        dask_model = dask_model.fit(**fit_params)\n+\n+        eval_name = 'valid_0'\n+        evals_result = dask_model.evals_result_\n+        assert len(evals_result) == 1\n+        assert eval_name in evals_result\n+\n+        for metric in eval_metric_names:\n+            assert metric in evals_result[eval_name]\n+            assert len(evals_result[eval_name][metric]) == fit_trees\n+\n+        np.testing.assert_allclose(evals_result[eval_name]['constant_metric'], 0.708)\n+\n+\n @pytest.mark.parametrize('task', tasks)\n def test_training_works_if_client_not_provided_or_set_after_construction(task, cluster):\n     with Client(cluster) as client:\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Stochastic test failures related to `len(model.evals_result_)` need addressing. Ensure consistent handling of entries in `evals_result_` when components are entirely padded with `None`. Proposed solution: post-process `evals_result_` to insert empty key-value pairs for removed components, maintaining consistency in naming.\n\n2. Review `_DatasetNames` class usage in `fit()`. Consider simplifying to constant definitions to prevent potential issues.\n\n3. Add note about custom eval functions to the `fit()` method signature; consider linking to documentation instead of duplicating text for brevity.\n\n4. Merge the fix from PR 4104 to investigate potential CUDA build issues that may not be related but need confirmation."
      }
    ],
    "codediff_length": 41749
  },
  {
    "index": 3,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/include/LightGBM/boosting.h b/include/LightGBM/boosting.h\nindex 31bb430f0aed..b6286c238006 100644\n--- a/include/LightGBM/boosting.h\n+++ b/include/LightGBM/boosting.h\n@@ -166,10 +166,11 @@ class LIGHTGBM_EXPORT Boosting {\n   * \\brief Feature contributions for the model's prediction of one record\n   * \\param feature_values Feature value on this record\n   * \\param output Prediction result for this record\n-  * \\param early_stop Early stopping instance. If nullptr, no early stopping is applied and all models are evaluated.\n   */\n-  virtual void PredictContrib(const double* features, double* output,\n-                              const PredictionEarlyStopInstance* early_stop) const = 0;\n+  virtual void PredictContrib(const double* features, double* output) const = 0;\n+\n+  virtual void PredictContribByMap(const std::unordered_map<int, double>& features,\n+                                   std::vector<std::unordered_map<int, double>>* output) const = 0;\n \n   /*!\n   * \\brief Dump model to json format string\ndiff --git a/include/LightGBM/c_api.h b/include/LightGBM/c_api.h\nindex 9d7c6e61dd27..ac2164a93775 100644\n--- a/include/LightGBM/c_api.h\n+++ b/include/LightGBM/c_api.h\n@@ -33,6 +33,9 @@ typedef void* BoosterHandle;  /*!< \\brief Handle of booster. */\n #define C_API_PREDICT_LEAF_INDEX (2)  /*!< \\brief Predict leaf index. */\n #define C_API_PREDICT_CONTRIB    (3)  /*!< \\brief Predict feature contributions (SHAP values). */\n \n+#define C_API_MATRIX_TYPE_CSR (0)  /*!< \\brief CSR sparse matrix type. */\n+#define C_API_MATRIX_TYPE_CSC (1)  /*!< \\brief CSC sparse matrix type. */\n+\n /*!\n  * \\brief Get string message of the last error.\n  * \\return Error information\n@@ -742,6 +745,62 @@ LIGHTGBM_C_EXPORT int LGBM_BoosterPredictForCSR(BoosterHandle handle,\n                                                 int64_t* out_len,\n                                                 double* out_result);\n \n+/*!\n+ * \\brief Make sparse prediction for a new dataset in CSR or CSC format. Currently only used for feature contributions.\n+ * \\note\n+ * The outputs are pre-allocated, as they can vary for each invocation, but the shape should be the same:\n+ *   - for feature contributions, the shape of sparse matrix will be ``num_class * num_data * (num_feature + 1)``.\n+ * The output indptr_type for the sparse matrix will be the same as the given input indptr_type.\n+ * Call ``LGBM_BoosterFreePredictSparse`` to deallocate resources.\n+ * \\param handle Handle of booster\n+ * \\param indptr Pointer to row headers for CSR or column headers for CSC\n+ * \\param indptr_type Type of ``indptr``, can be ``C_API_DTYPE_INT32`` or ``C_API_DTYPE_INT64``\n+ * \\param indices Pointer to column indices for CSR or row indices for CSC\n+ * \\param data Pointer to the data space\n+ * \\param data_type Type of ``data`` pointer, can be ``C_API_DTYPE_FLOAT32`` or ``C_API_DTYPE_FLOAT64``\n+ * \\param nindptr Number of rows in the matrix + 1\n+ * \\param nelem Number of nonzero elements in the matrix\n+ * \\param num_col_or_row Number of columns for CSR or number of rows for CSC\n+ * \\param predict_type What should be predicted, only feature contributions supported currently\n+ *   - ``C_API_PREDICT_CONTRIB``: feature contributions (SHAP values)\n+ * \\param num_iteration Number of iterations for prediction, <= 0 means no limit\n+ * \\param parameter Other parameters for prediction, e.g. early stopping for prediction\n+ * \\param matrix_type Type of matrix input and output, can be ``C_API_MATRIX_TYPE_CSR`` or ``C_API_MATRIX_TYPE_CSC``\n+ * \\param[out] out_len Length of output indices and data\n+ * \\param[out] out_indptr Pointer to output row headers for CSR or column headers for CSC\n+ * \\param[out] out_indices Pointer to sparse column indices for CSR or row indices for CSC\n+ * \\param[out] out_data Pointer to sparse data space\n+ * \\return 0 when succeed, -1 when failure happens\n+ */\n+LIGHTGBM_C_EXPORT int LGBM_BoosterPredictSparseOutput(BoosterHandle handle,\n+                                                      const void* indptr,\n+                                                      int indptr_type,\n+                                                      const int32_t* indices,\n+                                                      const void* data,\n+                                                      int data_type,\n+                                                      int64_t nindptr,\n+                                                      int64_t nelem,\n+                                                      int64_t num_col_or_row,\n+                                                      int predict_type,\n+                                                      int num_iteration,\n+                                                      const char* parameter,\n+                                                      int matrix_type,\n+                                                      int64_t* out_len,\n+                                                      void** out_indptr,\n+                                                      int32_t** out_indices,\n+                                                      void** out_data);\n+\n+/*!\n+ * \\brief Method corresponding to ``LGBM_BoosterPredictSparseOutput`` to free the allocated data.\n+ * \\param indptr Pointer to output row headers or column headers to be deallocated\n+ * \\param indices Pointer to sparse indices to be deallocated\n+ * \\param data Pointer to sparse data space to be deallocated\n+ * \\param indptr_type Type of ``indptr``, can be ``C_API_DTYPE_INT32`` or ``C_API_DTYPE_INT64``\n+ * \\param data_type Type of ``data`` pointer, can be ``C_API_DTYPE_FLOAT32`` or ``C_API_DTYPE_FLOAT64``\n+ * \\return 0 when succeed, -1 when failure happens\n+ */\n+LIGHTGBM_C_EXPORT int LGBM_BoosterFreePredictSparse(void* indptr, int32_t* indices, void* data, int indptr_type, int data_type);\n+\n /*!\n  * \\brief Make prediction for a new dataset in CSR format. This method re-uses the internal predictor structure\n  *        from previous calls and is optimized for single row invocation.\ndiff --git a/include/LightGBM/meta.h b/include/LightGBM/meta.h\nindex b15b1ba4b378..3452f28d8ebc 100644\n--- a/include/LightGBM/meta.h\n+++ b/include/LightGBM/meta.h\n@@ -5,10 +5,11 @@\n #ifndef LIGHTGBM_META_H_\n #define LIGHTGBM_META_H_\n \n-#include <limits>\n #include <cstdint>\n #include <functional>\n+#include <limits>\n #include <memory>\n+#include <unordered_map>\n #include <utility>\n #include <vector>\n \n@@ -58,6 +59,9 @@ typedef int32_t comm_size_t;\n using PredictFunction =\n std::function<void(const std::vector<std::pair<int, double>>&, double* output)>;\n \n+using PredictSparseFunction =\n+std::function<void(const std::vector<std::pair<int, double>>&, std::vector<std::unordered_map<int, double>>* output)>;\n+\n typedef void(*ReduceFunction)(const char* input, char* output, int type_size, comm_size_t array_size);\n \n \ndiff --git a/include/LightGBM/tree.h b/include/LightGBM/tree.h\nindex 5ce3ff9b3eb1..b8e4800164f9 100644\n--- a/include/LightGBM/tree.h\n+++ b/include/LightGBM/tree.h\n@@ -136,6 +136,8 @@ class Tree {\n   inline int PredictLeafIndexByMap(const std::unordered_map<int, double>& feature_values) const;\n \n   inline void PredictContrib(const double* feature_values, int num_features, double* output);\n+  inline void PredictContribByMap(const std::unordered_map<int, double>& feature_values,\n+                                  int num_features, std::unordered_map<int, double>* output);\n \n   /*! \\brief Get Number of leaves*/\n   inline int num_leaves() const { return num_leaves_; }\n@@ -387,6 +389,12 @@ class Tree {\n                 PathElement *parent_unique_path, double parent_zero_fraction,\n                 double parent_one_fraction, int parent_feature_index) const;\n \n+  void TreeSHAPByMap(const std::unordered_map<int, double>& feature_values,\n+                     std::unordered_map<int, double>* phi,\n+                     int node, int unique_depth,\n+                     PathElement *parent_unique_path, double parent_zero_fraction,\n+                     double parent_one_fraction, int parent_feature_index) const;\n+\n   /*! \\brief Extend our decision path with a fraction of one and zero extensions for TreeSHAP*/\n   static void ExtendPath(PathElement *unique_path, int unique_depth,\n                          double zero_fraction, double one_fraction, int feature_index);\n@@ -539,6 +547,18 @@ inline void Tree::PredictContrib(const double* feature_values, int num_features,\n   }\n }\n \n+inline void Tree::PredictContribByMap(const std::unordered_map<int, double>& feature_values,\n+                                      int num_features, std::unordered_map<int, double>* output) {\n+  (*output)[num_features] += ExpectedValue();\n+  // Run the recursion with preallocated space for the unique path data\n+  if (num_leaves_ > 1) {\n+    CHECK_GE(max_depth_, 0);\n+    const int max_path_len = max_depth_ + 1;\n+    std::vector<PathElement> unique_path_data(max_path_len*(max_path_len + 1) / 2);\n+    TreeSHAPByMap(feature_values, output, 0, 0, unique_path_data.data(), 1, 1, -1);\n+  }\n+}\n+\n inline void Tree::RecomputeLeafDepths(int node, int depth) {\n   if (node == 0) leaf_depth_.resize(num_leaves());\n   if (node < 0) {\ndiff --git a/python-package/lightgbm/basic.py b/python-package/lightgbm/basic.py\nindex 01a5f31e51b6..9d5be6501b60 100644\n--- a/python-package/lightgbm/basic.py\n+++ b/python-package/lightgbm/basic.py\n@@ -115,7 +115,15 @@ def cint32_array_to_numpy(cptr, length):\n     if isinstance(cptr, ctypes.POINTER(ctypes.c_int32)):\n         return np.fromiter(cptr, dtype=np.int32, count=length)\n     else:\n-        raise RuntimeError('Expected int pointer')\n+        raise RuntimeError('Expected int32 pointer')\n+\n+\n+def cint64_array_to_numpy(cptr, length):\n+    \"\"\"Convert a ctypes int pointer array to a numpy array.\"\"\"\n+    if isinstance(cptr, ctypes.POINTER(ctypes.c_int64)):\n+        return np.fromiter(cptr, dtype=np.int64, count=length)\n+    else:\n+        raise RuntimeError('Expected int64 pointer')\n \n \n def c_str(string):\n@@ -272,6 +280,10 @@ def get(cls, *args):\n C_API_PREDICT_LEAF_INDEX = 2\n C_API_PREDICT_CONTRIB = 3\n \n+\"\"\"Macro definition of sparse matrix type\"\"\"\n+C_API_MATRIX_TYPE_CSR = 0\n+C_API_MATRIX_TYPE_CSC = 1\n+\n \"\"\"Data type of data field\"\"\"\n FIELD_TYPE_MAPPER = {\"label\": C_API_DTYPE_FLOAT32,\n                      \"weight\": C_API_DTYPE_FLOAT32,\n@@ -525,8 +537,9 @@ def predict(self, data, num_iteration=-1,\n \n         Returns\n         -------\n-        result : numpy array\n+        result : numpy array, scipy.sparse or list of scipy.sparse\n             Prediction result.\n+            Can be sparse or a list of sparse objects (each element represents predictions for one class) for feature contributions (when ``pred_contrib=True``).\n         \"\"\"\n         if isinstance(data, Dataset):\n             raise TypeError(\"Cannot use Dataset instance for prediction, please use raw data instead\")\n@@ -579,7 +592,8 @@ def predict(self, data, num_iteration=-1,\n             preds, nrow = self.__pred_for_csr(csr, num_iteration, predict_type)\n         if pred_leaf:\n             preds = preds.astype(np.int32)\n-        if is_reshape and preds.size != nrow:\n+        is_sparse = scipy.sparse.issparse(preds) or isinstance(preds, list)\n+        if is_reshape and not is_sparse and preds.size != nrow:\n             if preds.size % nrow == 0:\n                 preds = preds.reshape(nrow, -1)\n             else:\n@@ -651,6 +665,52 @@ def inner_predict(mat, num_iteration, predict_type, preds=None):\n         else:\n             return inner_predict(mat, num_iteration, predict_type)\n \n+    def __create_sparse_native(self, cs, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,\n+                               indptr_type, data_type, is_csr=True):\n+        # create numpy array from output arrays\n+        data_indices_len = out_shape[0]\n+        indptr_len = out_shape[1]\n+        if indptr_type == C_API_DTYPE_INT32:\n+            out_indptr = cint32_array_to_numpy(out_ptr_indptr, indptr_len)\n+        elif indptr_type == C_API_DTYPE_INT64:\n+            out_indptr = cint64_array_to_numpy(out_ptr_indptr, indptr_len)\n+        else:\n+            raise TypeError(\"Expected int32 or int64 type for indptr\")\n+        if data_type == C_API_DTYPE_FLOAT32:\n+            out_data = cfloat32_array_to_numpy(out_ptr_data, data_indices_len)\n+        elif data_type == C_API_DTYPE_FLOAT64:\n+            out_data = cfloat64_array_to_numpy(out_ptr_data, data_indices_len)\n+        else:\n+            raise TypeError(\"Expected float32 or float64 type for data\")\n+        out_indices = cint32_array_to_numpy(out_ptr_indices, data_indices_len)\n+        # break up indptr based on number of rows (note more than one matrix in multiclass case)\n+        per_class_indptr_shape = cs.indptr.shape[0]\n+        # for CSC there is extra column added\n+        if not is_csr:\n+            per_class_indptr_shape += 1\n+        out_indptr_arrays = np.split(out_indptr, out_indptr.shape[0] / per_class_indptr_shape)\n+        # reformat output into a csr or csc matrix or list of csr or csc matrices\n+        cs_output_matrices = []\n+        offset = 0\n+        for cs_indptr in out_indptr_arrays:\n+            matrix_indptr_len = cs_indptr[cs_indptr.shape[0] - 1]\n+            cs_indices = out_indices[offset + cs_indptr[0]:offset + matrix_indptr_len]\n+            cs_data = out_data[offset + cs_indptr[0]:offset + matrix_indptr_len]\n+            offset += matrix_indptr_len\n+            # same shape as input csr or csc matrix except extra column for expected value\n+            cs_shape = [cs.shape[0], cs.shape[1] + 1]\n+            # note: make sure we copy data as it will be deallocated next\n+            if is_csr:\n+                cs_output_matrices.append(scipy.sparse.csr_matrix((cs_data, cs_indices, cs_indptr), cs_shape))\n+            else:\n+                cs_output_matrices.append(scipy.sparse.csc_matrix((cs_data, cs_indices, cs_indptr), cs_shape))\n+        # free the temporary native indptr, indices, and data\n+        _safe_call(_LIB.LGBM_BoosterFreePredictSparse(out_ptr_indptr, out_ptr_indices, out_ptr_data,\n+                                                      ctypes.c_int(indptr_type), ctypes.c_int(data_type)))\n+        if len(cs_output_matrices) == 1:\n+            return cs_output_matrices[0]\n+        return cs_output_matrices\n+\n     def __pred_for_csr(self, csr, num_iteration, predict_type):\n         \"\"\"Predict for a CSR data.\"\"\"\n         def inner_predict(csr, num_iteration, predict_type, preds=None):\n@@ -666,13 +726,13 @@ def inner_predict(csr, num_iteration, predict_type, preds=None):\n             ptr_data, type_ptr_data, _ = c_float_array(csr.data)\n \n             assert csr.shape[1] <= MAX_INT32\n-            csr.indices = csr.indices.astype(np.int32, copy=False)\n+            csr_indices = csr.indices.astype(np.int32, copy=False)\n \n             _safe_call(_LIB.LGBM_BoosterPredictForCSR(\n                 self.handle,\n                 ptr_indptr,\n                 ctypes.c_int32(type_ptr_indptr),\n-                csr.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n+                csr_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n                 ptr_data,\n                 ctypes.c_int(type_ptr_data),\n                 ctypes.c_int64(len(csr.indptr)),\n@@ -687,6 +747,46 @@ def inner_predict(csr, num_iteration, predict_type, preds=None):\n                 raise ValueError(\"Wrong length for predict results\")\n             return preds, nrow\n \n+        def inner_predict_sparse(csr, num_iteration, predict_type):\n+            ptr_indptr, type_ptr_indptr, __ = c_int_array(csr.indptr)\n+            ptr_data, type_ptr_data, _ = c_float_array(csr.data)\n+            csr_indices = csr.indices.astype(np.int32, copy=False)\n+            matrix_type = C_API_MATRIX_TYPE_CSR\n+            if type_ptr_indptr == C_API_DTYPE_INT32:\n+                out_ptr_indptr = ctypes.POINTER(ctypes.c_int32)()\n+            else:\n+                out_ptr_indptr = ctypes.POINTER(ctypes.c_int64)()\n+            out_ptr_indices = ctypes.POINTER(ctypes.c_int32)()\n+            if type_ptr_data == C_API_DTYPE_FLOAT32:\n+                out_ptr_data = ctypes.POINTER(ctypes.c_float)()\n+            else:\n+                out_ptr_data = ctypes.POINTER(ctypes.c_double)()\n+            out_shape = np.zeros(2, dtype=np.int64)\n+            _safe_call(_LIB.LGBM_BoosterPredictSparseOutput(\n+                self.handle,\n+                ptr_indptr,\n+                ctypes.c_int32(type_ptr_indptr),\n+                csr_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n+                ptr_data,\n+                ctypes.c_int(type_ptr_data),\n+                ctypes.c_int64(len(csr.indptr)),\n+                ctypes.c_int64(len(csr.data)),\n+                ctypes.c_int64(csr.shape[1]),\n+                ctypes.c_int(predict_type),\n+                ctypes.c_int(num_iteration),\n+                c_str(self.pred_parameter),\n+                ctypes.c_int(matrix_type),\n+                out_shape.ctypes.data_as(ctypes.POINTER(ctypes.c_int64)),\n+                ctypes.byref(out_ptr_indptr),\n+                ctypes.byref(out_ptr_indices),\n+                ctypes.byref(out_ptr_data)))\n+            matrices = self.__create_sparse_native(csr, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,\n+                                                   type_ptr_indptr, type_ptr_data, is_csr=True)\n+            nrow = len(csr.indptr) - 1\n+            return matrices, nrow\n+\n+        if predict_type == C_API_PREDICT_CONTRIB:\n+            return inner_predict_sparse(csr, num_iteration, predict_type)\n         nrow = len(csr.indptr) - 1\n         if nrow > MAX_INT32:\n             sections = [0] + list(np.arange(start=MAX_INT32, stop=nrow, step=MAX_INT32)) + [nrow]\n@@ -704,9 +804,49 @@ def inner_predict(csr, num_iteration, predict_type, preds=None):\n \n     def __pred_for_csc(self, csc, num_iteration, predict_type):\n         \"\"\"Predict for a CSC data.\"\"\"\n+        def inner_predict_sparse(csc, num_iteration, predict_type):\n+            ptr_indptr, type_ptr_indptr, __ = c_int_array(csc.indptr)\n+            ptr_data, type_ptr_data, _ = c_float_array(csc.data)\n+            csc_indices = csc.indices.astype(np.int32, copy=False)\n+            matrix_type = C_API_MATRIX_TYPE_CSC\n+            if type_ptr_indptr == C_API_DTYPE_INT32:\n+                out_ptr_indptr = ctypes.POINTER(ctypes.c_int32)()\n+            else:\n+                out_ptr_indptr = ctypes.POINTER(ctypes.c_int64)()\n+            out_ptr_indices = ctypes.POINTER(ctypes.c_int32)()\n+            if type_ptr_data == C_API_DTYPE_FLOAT32:\n+                out_ptr_data = ctypes.POINTER(ctypes.c_float)()\n+            else:\n+                out_ptr_data = ctypes.POINTER(ctypes.c_double)()\n+            out_shape = np.zeros(2, dtype=np.int64)\n+            _safe_call(_LIB.LGBM_BoosterPredictSparseOutput(\n+                self.handle,\n+                ptr_indptr,\n+                ctypes.c_int32(type_ptr_indptr),\n+                csc_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n+                ptr_data,\n+                ctypes.c_int(type_ptr_data),\n+                ctypes.c_int64(len(csc.indptr)),\n+                ctypes.c_int64(len(csc.data)),\n+                ctypes.c_int64(csc.shape[0]),\n+                ctypes.c_int(predict_type),\n+                ctypes.c_int(num_iteration),\n+                c_str(self.pred_parameter),\n+                ctypes.c_int(matrix_type),\n+                out_shape.ctypes.data_as(ctypes.POINTER(ctypes.c_int64)),\n+                ctypes.byref(out_ptr_indptr),\n+                ctypes.byref(out_ptr_indices),\n+                ctypes.byref(out_ptr_data)))\n+            matrices = self.__create_sparse_native(csc, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,\n+                                                   type_ptr_indptr, type_ptr_data, is_csr=False)\n+            nrow = csc.shape[0]\n+            return matrices, nrow\n+\n         nrow = csc.shape[0]\n         if nrow > MAX_INT32:\n             return self.__pred_for_csr(csc.tocsr(), num_iteration, predict_type)\n+        if predict_type == C_API_PREDICT_CONTRIB:\n+            return inner_predict_sparse(csc, num_iteration, predict_type)\n         n_preds = self.__get_num_preds(num_iteration, nrow, predict_type)\n         preds = np.zeros(n_preds, dtype=np.float64)\n         out_num_preds = ctypes.c_int64(0)\n@@ -715,13 +855,13 @@ def __pred_for_csc(self, csc, num_iteration, predict_type):\n         ptr_data, type_ptr_data, _ = c_float_array(csc.data)\n \n         assert csc.shape[0] <= MAX_INT32\n-        csc.indices = csc.indices.astype(np.int32, copy=False)\n+        csc_indices = csc.indices.astype(np.int32, copy=False)\n \n         _safe_call(_LIB.LGBM_BoosterPredictForCSC(\n             self.handle,\n             ptr_indptr,\n             ctypes.c_int32(type_ptr_indptr),\n-            csc.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n+            csc_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n             ptr_data,\n             ctypes.c_int(type_ptr_data),\n             ctypes.c_int64(len(csc.indptr)),\n@@ -1074,12 +1214,12 @@ def __init_from_csr(self, csr, params_str, ref_dataset):\n         ptr_data, type_ptr_data, _ = c_float_array(csr.data)\n \n         assert csr.shape[1] <= MAX_INT32\n-        csr.indices = csr.indices.astype(np.int32, copy=False)\n+        csr_indices = csr.indices.astype(np.int32, copy=False)\n \n         _safe_call(_LIB.LGBM_DatasetCreateFromCSR(\n             ptr_indptr,\n             ctypes.c_int(type_ptr_indptr),\n-            csr.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n+            csr_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n             ptr_data,\n             ctypes.c_int(type_ptr_data),\n             ctypes.c_int64(len(csr.indptr)),\n@@ -1100,12 +1240,12 @@ def __init_from_csc(self, csc, params_str, ref_dataset):\n         ptr_data, type_ptr_data, _ = c_float_array(csc.data)\n \n         assert csc.shape[0] <= MAX_INT32\n-        csc.indices = csc.indices.astype(np.int32, copy=False)\n+        csc_indices = csc.indices.astype(np.int32, copy=False)\n \n         _safe_call(_LIB.LGBM_DatasetCreateFromCSC(\n             ptr_indptr,\n             ctypes.c_int(type_ptr_indptr),\n-            csc.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n+            csc_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n             ptr_data,\n             ctypes.c_int(type_ptr_data),\n             ctypes.c_int64(len(csc.indptr)),\n@@ -2677,8 +2817,9 @@ def predict(self, data, num_iteration=None,\n \n         Returns\n         -------\n-        result : numpy array\n+        result : numpy array, scipy.sparse or list of scipy.sparse\n             Prediction result.\n+            Can be sparse or a list of sparse objects (each element represents predictions for one class) for feature contributions (when ``pred_contrib=True``).\n         \"\"\"\n         predictor = self._to_predictor(copy.deepcopy(kwargs))\n         if num_iteration is None:\ndiff --git a/python-package/lightgbm/sklearn.py b/python-package/lightgbm/sklearn.py\nindex 24cd96471220..d0a61f526273 100644\n--- a/python-package/lightgbm/sklearn.py\n+++ b/python-package/lightgbm/sklearn.py\n@@ -648,7 +648,7 @@ def predict(self, X, raw_score=False, num_iteration=None,\n             The predicted values.\n         X_leaves : array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n             If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n-        X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes]\n+        X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects\n             If ``pred_contrib=True``, the feature contributions for each sample.\n         \"\"\"\n         if self._n_features is None:\n@@ -873,7 +873,7 @@ def predict_proba(self, X, raw_score=False, num_iteration=None,\n             The predicted probability for each class for each sample.\n         X_leaves : array-like of shape = [n_samples, n_trees * n_classes]\n             If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n-        X_SHAP_values : array-like of shape = [n_samples, (n_features + 1) * n_classes]\n+        X_SHAP_values : array-like of shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects\n             If ``pred_contrib=True``, the feature contributions for each sample.\n         \"\"\"\n         result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\ndiff --git a/src/application/predictor.hpp b/src/application/predictor.hpp\nindex 1c56cfa5eb2c..48ef227de2c6 100644\n--- a/src/application/predictor.hpp\n+++ b/src/application/predictor.hpp\n@@ -88,12 +88,18 @@ class Predictor {\n                          double* output) {\n         int tid = omp_get_thread_num();\n         CopyToPredictBuffer(predict_buf_[tid].data(), features);\n-        // get result for leaf index\n-        boosting_->PredictContrib(predict_buf_[tid].data(), output,\n-                                  &early_stop_);\n+        // get feature importances\n+        boosting_->PredictContrib(predict_buf_[tid].data(), output);\n         ClearPredictBuffer(predict_buf_[tid].data(), predict_buf_[tid].size(),\n                            features);\n       };\n+      predict_sparse_fun_ = [=](const std::vector<std::pair<int, double>>& features,\n+                                std::vector<std::unordered_map<int, double>>* output) {\n+        auto buf = CopyToPredictMap(features);\n+        // get sparse feature importances\n+        boosting_->PredictContribByMap(buf, output);\n+      };\n+\n     } else {\n       if (is_raw_score) {\n         predict_fun_ = [=](const std::vector<std::pair<int, double>>& features,\n@@ -140,6 +146,11 @@ class Predictor {\n     return predict_fun_;\n   }\n \n+\n+  inline const PredictSparseFunction& GetPredictSparseFunction() const {\n+    return predict_sparse_fun_;\n+  }\n+\n   /*!\n   * \\brief predicting on data, then saving result to disk\n   * \\param data_filename Filename of data\n@@ -275,6 +286,7 @@ class Predictor {\n   const Boosting* boosting_;\n   /*! \\brief function for prediction */\n   PredictFunction predict_fun_;\n+  PredictSparseFunction predict_sparse_fun_;\n   PredictionEarlyStopInstance early_stop_;\n   int num_feature_;\n   int num_pred_one_row_;\ndiff --git a/src/boosting/gbdt.cpp b/src/boosting/gbdt.cpp\nindex 7871bbfb086c..491e7966aff5 100644\n--- a/src/boosting/gbdt.cpp\n+++ b/src/boosting/gbdt.cpp\n@@ -570,8 +570,7 @@ const double* GBDT::GetTrainingScore(int64_t* out_len) {\n   return train_score_updater_->score();\n }\n \n-void GBDT::PredictContrib(const double* features, double* output, const PredictionEarlyStopInstance* early_stop) const {\n-  int early_stop_round_counter = 0;\n+void GBDT::PredictContrib(const double* features, double* output) const {\n   // set zero\n   const int num_features = max_feature_idx_ + 1;\n   std::memset(output, 0, sizeof(double) * num_tree_per_iteration_ * (num_features + 1));\n@@ -580,13 +579,16 @@ void GBDT::PredictContrib(const double* features, double* output, const Predicti\n     for (int k = 0; k < num_tree_per_iteration_; ++k) {\n       models_[i * num_tree_per_iteration_ + k]->PredictContrib(features, num_features, output + k*(num_features + 1));\n     }\n-    // check early stopping\n-    ++early_stop_round_counter;\n-    if (early_stop->round_period == early_stop_round_counter) {\n-      if (early_stop->callback_function(output, num_tree_per_iteration_)) {\n-        return;\n-      }\n-      early_stop_round_counter = 0;\n+  }\n+}\n+\n+void GBDT::PredictContribByMap(const std::unordered_map<int, double>& features,\n+                               std::vector<std::unordered_map<int, double>>* output) const {\n+  const int num_features = max_feature_idx_ + 1;\n+  for (int i = 0; i < num_iteration_for_pred_; ++i) {\n+    // predict all the trees for one iteration\n+    for (int k = 0; k < num_tree_per_iteration_; ++k) {\n+      models_[i * num_tree_per_iteration_ + k]->PredictContribByMap(features, num_features, &((*output)[k]));\n     }\n   }\n }\ndiff --git a/src/boosting/gbdt.h b/src/boosting/gbdt.h\nindex f3ece67fec0b..0e1d014636f4 100644\n--- a/src/boosting/gbdt.h\n+++ b/src/boosting/gbdt.h\n@@ -210,18 +210,18 @@ class GBDT : public GBDTBase {\n   * \\return number of prediction\n   */\n   inline int NumPredictOneRow(int num_iteration, bool is_pred_leaf, bool is_pred_contrib) const override {\n-    int num_preb_in_one_row = num_class_;\n+    int num_pred_in_one_row = num_class_;\n     if (is_pred_leaf) {\n       int max_iteration = GetCurrentIteration();\n       if (num_iteration > 0) {\n-        num_preb_in_one_row *= static_cast<int>(std::min(max_iteration, num_iteration));\n+        num_pred_in_one_row *= static_cast<int>(std::min(max_iteration, num_iteration));\n       } else {\n-        num_preb_in_one_row *= max_iteration;\n+        num_pred_in_one_row *= max_iteration;\n       }\n     } else if (is_pred_contrib) {\n-      num_preb_in_one_row = num_tree_per_iteration_ * (max_feature_idx_ + 2);  // +1 for 0-based indexing, +1 for baseline\n+      num_pred_in_one_row = num_tree_per_iteration_ * (max_feature_idx_ + 2);  // +1 for 0-based indexing, +1 for baseline\n     }\n-    return num_preb_in_one_row;\n+    return num_pred_in_one_row;\n   }\n \n   void PredictRaw(const double* features, double* output,\n@@ -240,8 +240,10 @@ class GBDT : public GBDTBase {\n \n   void PredictLeafIndexByMap(const std::unordered_map<int, double>& features, double* output) const override;\n \n-  void PredictContrib(const double* features, double* output,\n-                      const PredictionEarlyStopInstance* earlyStop) const override;\n+  void PredictContrib(const double* features, double* output) const override;\n+\n+  void PredictContribByMap(const std::unordered_map<int, double>& features,\n+                           std::vector<std::unordered_map<int, double>>* output) const override;\n \n   /*!\n   * \\brief Dump model to json format string\ndiff --git a/src/c_api.cpp b/src/c_api.cpp\nindex 290f219fa639..ec77673b28a8 100644\n--- a/src/c_api.cpp\n+++ b/src/c_api.cpp\n@@ -382,16 +382,11 @@ class Booster {\n     *out_len = single_row_predictor_[predict_type]->num_pred_in_one_row;\n   }\n \n-\n-  void Predict(int num_iteration, int predict_type, int nrow, int ncol,\n-               std::function<std::vector<std::pair<int, double>>(int row_idx)> get_row_fun,\n-               const Config& config,\n-               double* out_result, int64_t* out_len) {\n+  Predictor CreatePredictor(int num_iteration, int predict_type, int ncol, const Config& config) {\n     if (!config.predict_disable_shape_check && ncol != boosting_->MaxFeatureIdx() + 1) {\n       Log::Fatal(\"The number of features in data (%d) is not the same as it was in training data (%d).\\n\" \\\n                  \"You can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.\", ncol, boosting_->MaxFeatureIdx() + 1);\n     }\n-    std::lock_guard<std::mutex> lock(mutex_);\n     bool is_predict_leaf = false;\n     bool is_raw_score = false;\n     bool predict_contrib = false;\n@@ -407,6 +402,22 @@ class Booster {\n \n     Predictor predictor(boosting_.get(), num_iteration, is_raw_score, is_predict_leaf, predict_contrib,\n                         config.pred_early_stop, config.pred_early_stop_freq, config.pred_early_stop_margin);\n+    return predictor;\n+  }\n+\n+  void Predict(int num_iteration, int predict_type, int nrow, int ncol,\n+               std::function<std::vector<std::pair<int, double>>(int row_idx)> get_row_fun,\n+               const Config& config,\n+               double* out_result, int64_t* out_len) {\n+    std::lock_guard<std::mutex> lock(mutex_);\n+    auto predictor = CreatePredictor(num_iteration, predict_type, ncol, config);\n+    bool is_predict_leaf = false;\n+    bool predict_contrib = false;\n+    if (predict_type == C_API_PREDICT_LEAF_INDEX) {\n+      is_predict_leaf = true;\n+    } else if (predict_type == C_API_PREDICT_CONTRIB) {\n+      predict_contrib = true;\n+    }\n     int64_t num_pred_in_one_row = boosting_->NumPredictOneRow(num_iteration, is_predict_leaf, predict_contrib);\n     auto pred_fun = predictor.GetPredictFunction();\n     OMP_INIT_EX();\n@@ -422,6 +433,236 @@ class Booster {\n     *out_len = num_pred_in_one_row * nrow;\n   }\n \n+  void PredictSparse(int num_iteration, int predict_type, int64_t nrow, int ncol,\n+                     std::function<std::vector<std::pair<int, double>>(int64_t row_idx)> get_row_fun,\n+                     const Config& config, int64_t* out_elements_size,\n+                     std::vector<std::vector<std::unordered_map<int, double>>>* agg_ptr,\n+                     int32_t** out_indices, void** out_data, int data_type,\n+                     bool* is_data_float32_ptr, int num_matrices) {\n+    auto predictor = CreatePredictor(num_iteration, predict_type, ncol, config);\n+    auto pred_sparse_fun = predictor.GetPredictSparseFunction();\n+    std::vector<std::vector<std::unordered_map<int, double>>>& agg = *agg_ptr;\n+    OMP_INIT_EX();\n+    #pragma omp parallel for schedule(static)\n+    for (int64_t i = 0; i < nrow; ++i) {\n+      OMP_LOOP_EX_BEGIN();\n+      auto one_row = get_row_fun(i);\n+      agg[i] = std::vector<std::unordered_map<int, double>>(num_matrices);\n+      pred_sparse_fun(one_row, &agg[i]);\n+      OMP_LOOP_EX_END();\n+    }\n+    OMP_THROW_EX();\n+    // calculate the nonzero data and indices size\n+    int64_t elements_size = 0;\n+    for (int64_t i = 0; i < static_cast<int64_t>(agg.size()); ++i) {\n+      auto row_vector = agg[i];\n+      for (int j = 0; j < static_cast<int>(row_vector.size()); ++j) {\n+        elements_size += static_cast<int64_t>(row_vector[j].size());\n+      }\n+    }\n+    *out_elements_size = elements_size;\n+    *is_data_float32_ptr = false;\n+    // allocate data and indices arrays\n+    if (data_type == C_API_DTYPE_FLOAT32) {\n+      *out_data = new float[elements_size];\n+      *is_data_float32_ptr = true;\n+    } else if (data_type == C_API_DTYPE_FLOAT64) {\n+      *out_data = new double[elements_size];\n+    } else {\n+      Log::Fatal(\"Unknown data type in PredictSparse\");\n+      return;\n+    }\n+    *out_indices = new int32_t[elements_size];\n+  }\n+\n+  void PredictSparseCSR(int num_iteration, int predict_type, int64_t nrow, int ncol,\n+                        std::function<std::vector<std::pair<int, double>>(int64_t row_idx)> get_row_fun,\n+                        const Config& config,\n+                        int64_t* out_len, void** out_indptr, int indptr_type,\n+                        int32_t** out_indices, void** out_data, int data_type) {\n+    std::lock_guard<std::mutex> lock(mutex_);\n+    // Get the number of trees per iteration (for multiclass scenario we output multiple sparse matrices)\n+    int num_matrices = boosting_->NumModelPerIteration();\n+    bool is_indptr_int32 = false;\n+    bool is_data_float32 = false;\n+    int64_t indptr_size = (nrow + 1) * num_matrices;\n+    if (indptr_type == C_API_DTYPE_INT32) {\n+      *out_indptr = new int32_t[indptr_size];\n+      is_indptr_int32 = true;\n+    } else if (indptr_type == C_API_DTYPE_INT64) {\n+      *out_indptr = new int64_t[indptr_size];\n+    } else {\n+      Log::Fatal(\"Unknown indptr type in PredictSparseCSR\");\n+      return;\n+    }\n+    // aggregated per row feature contribution results\n+    std::vector<std::vector<std::unordered_map<int, double>>> agg(nrow);\n+    int64_t elements_size = 0;\n+    PredictSparse(num_iteration, predict_type, nrow, ncol, get_row_fun, config, &elements_size, &agg,\n+                  out_indices, out_data, data_type, &is_data_float32, num_matrices);\n+    std::vector<int> row_sizes(num_matrices * nrow);\n+    std::vector<int64_t> row_matrix_offsets(num_matrices * nrow);\n+    int64_t row_vector_cnt = 0;\n+    for (int m = 0; m < num_matrices; ++m) {\n+      for (int64_t i = 0; i < static_cast<int64_t>(agg.size()); ++i) {\n+        auto row_vector = agg[i];\n+        auto row_vector_size = row_vector[m].size();\n+        // keep track of the row_vector sizes for parallelization\n+        row_sizes[row_vector_cnt] = static_cast<int>(row_vector_size);\n+        if (i == 0) {\n+          row_matrix_offsets[row_vector_cnt] = 0;\n+        } else {\n+          row_matrix_offsets[row_vector_cnt] = static_cast<int64_t>(row_sizes[row_vector_cnt - 1] + row_matrix_offsets[row_vector_cnt - 1]);\n+        }\n+        row_vector_cnt++;\n+      }\n+    }\n+    // copy vector results to output for each row\n+    int64_t indptr_index = 0;\n+    for (int m = 0; m < num_matrices; ++m) {\n+      if (is_indptr_int32) {\n+        (reinterpret_cast<int32_t*>(*out_indptr))[indptr_index] = 0;\n+      } else {\n+        (reinterpret_cast<int64_t*>(*out_indptr))[indptr_index] = 0;\n+      }\n+      indptr_index++;\n+      int64_t matrix_start_index = m * static_cast<int64_t>(agg.size());\n+      OMP_INIT_EX();\n+      #pragma omp parallel for schedule(static)\n+      for (int64_t i = 0; i < static_cast<int64_t>(agg.size()); ++i) {\n+        OMP_LOOP_EX_BEGIN();\n+        auto row_vector = agg[i];\n+        int64_t row_start_index = matrix_start_index + i;\n+        int64_t element_index = row_matrix_offsets[row_start_index];\n+        int64_t indptr_loop_index = indptr_index + i;\n+        for (auto it = row_vector[m].begin(); it != row_vector[m].end(); ++it) {\n+          (*out_indices)[element_index] = it->first;\n+          if (is_data_float32) {\n+            (reinterpret_cast<float*>(*out_data))[element_index] = static_cast<float>(it->second);\n+          } else {\n+            (reinterpret_cast<double*>(*out_data))[element_index] = it->second;\n+          }\n+          element_index++;\n+        }\n+        int64_t indptr_value = row_matrix_offsets[row_start_index] + row_sizes[row_start_index];\n+        if (is_indptr_int32) {\n+          (reinterpret_cast<int32_t*>(*out_indptr))[indptr_loop_index] = static_cast<int32_t>(indptr_value);\n+        } else {\n+          (reinterpret_cast<int64_t*>(*out_indptr))[indptr_loop_index] = indptr_value;\n+        }\n+        OMP_LOOP_EX_END();\n+      }\n+      OMP_THROW_EX();\n+      indptr_index += static_cast<int64_t>(agg.size());\n+    }\n+    out_len[0] = elements_size;\n+    out_len[1] = indptr_size;\n+  }\n+\n+  void PredictSparseCSC(int num_iteration, int predict_type, int64_t nrow, int ncol,\n+                        std::function<std::vector<std::pair<int, double>>(int64_t row_idx)> get_row_fun,\n+                        const Config& config,\n+                        int64_t* out_len, void** out_col_ptr, int col_ptr_type,\n+                        int32_t** out_indices, void** out_data, int data_type) {\n+    std::lock_guard<std::mutex> lock(mutex_);\n+    // Get the number of trees per iteration (for multiclass scenario we output multiple sparse matrices)\n+    int num_matrices = boosting_->NumModelPerIteration();\n+    auto predictor = CreatePredictor(num_iteration, predict_type, ncol, config);\n+    auto pred_sparse_fun = predictor.GetPredictSparseFunction();\n+    bool is_col_ptr_int32 = false;\n+    bool is_data_float32 = false;\n+    int num_output_cols = ncol + 1;\n+    int col_ptr_size = (num_output_cols + 1) * num_matrices;\n+    if (col_ptr_type == C_API_DTYPE_INT32) {\n+      *out_col_ptr = new int32_t[col_ptr_size];\n+      is_col_ptr_int32 = true;\n+    } else if (col_ptr_type == C_API_DTYPE_INT64) {\n+      *out_col_ptr = new int64_t[col_ptr_size];\n+    } else {\n+      Log::Fatal(\"Unknown col_ptr type in PredictSparseCSC\");\n+      return;\n+    }\n+    // aggregated per row feature contribution results\n+    std::vector<std::vector<std::unordered_map<int, double>>> agg(nrow);\n+    int64_t elements_size = 0;\n+    PredictSparse(num_iteration, predict_type, nrow, ncol, get_row_fun, config, &elements_size, &agg,\n+                  out_indices, out_data, data_type, &is_data_float32, num_matrices);\n+    // calculate number of elements per column to construct\n+    // the CSC matrix with random access\n+    std::vector<std::vector<int64_t>> column_sizes(num_matrices);\n+    for (int m = 0; m < num_matrices; ++m) {\n+      column_sizes[m] = std::vector<int64_t>(num_output_cols, 0);\n+      for (int64_t i = 0; i < static_cast<int64_t>(agg.size()); ++i) {\n+        auto row_vector = agg[i];\n+        for (auto it = row_vector[m].begin(); it != row_vector[m].end(); ++it) {\n+          column_sizes[m][it->first] += 1;\n+        }\n+      }\n+    }\n+    // keep track of column counts\n+    std::vector<std::vector<int64_t>> column_counts(num_matrices);\n+    // keep track of beginning index for each column\n+    std::vector<std::vector<int64_t>> column_start_indices(num_matrices);\n+    // keep track of beginning index for each matrix\n+    std::vector<int64_t> matrix_start_indices(num_matrices, 0);\n+    int col_ptr_index = 0;\n+    for (int m = 0; m < num_matrices; ++m) {\n+      int64_t col_ptr_value = 0;\n+      column_start_indices[m] = std::vector<int64_t>(num_output_cols, 0);\n+      column_counts[m] = std::vector<int64_t>(num_output_cols, 0);\n+      if (is_col_ptr_int32) {\n+        (reinterpret_cast<int32_t*>(*out_col_ptr))[col_ptr_index] = static_cast<int32_t>(col_ptr_value);\n+      } else {\n+        (reinterpret_cast<int64_t*>(*out_col_ptr))[col_ptr_index] = col_ptr_value;\n+      }\n+      col_ptr_index++;\n+      for (int64_t i = 1; i < static_cast<int64_t>(column_sizes[m].size()); ++i) {\n+        column_start_indices[m][i] = column_sizes[m][i - 1] + column_start_indices[m][i - 1];\n+        if (is_col_ptr_int32) {\n+          (reinterpret_cast<int32_t*>(*out_col_ptr))[col_ptr_index] = static_cast<int32_t>(column_start_indices[m][i]);\n+        } else {\n+          (reinterpret_cast<int64_t*>(*out_col_ptr))[col_ptr_index] = column_start_indices[m][i];\n+        }\n+        col_ptr_index++;\n+      }\n+      int64_t last_elem_index = static_cast<int64_t>(column_sizes[m].size()) - 1;\n+      int64_t last_column_start_index = column_start_indices[m][last_elem_index];\n+      int64_t last_column_size = column_sizes[m][last_elem_index];\n+      if (is_col_ptr_int32) {\n+        (reinterpret_cast<int32_t*>(*out_col_ptr))[col_ptr_index] = static_cast<int32_t>(last_column_start_index + last_column_size);\n+      } else {\n+        (reinterpret_cast<int64_t*>(*out_col_ptr))[col_ptr_index] = last_column_start_index + last_column_size;\n+      }\n+      if (m != 0) {\n+        matrix_start_indices[m] = matrix_start_indices[m - 1] +\n+          last_column_start_index +\n+          last_column_size;\n+      }\n+    }\n+    for (int m = 0; m < num_matrices; ++m) {\n+      for (int64_t i = 0; i < static_cast<int64_t>(agg.size()); ++i) {\n+        auto row_vector = agg[i];\n+        for (auto it = row_vector[m].begin(); it != row_vector[m].end(); ++it) {\n+          int64_t col_idx = it->first;\n+          int64_t element_index = column_start_indices[m][col_idx] +\n+            matrix_start_indices[m] +\n+            column_counts[m][col_idx];\n+          // store the row index\n+          (*out_indices)[element_index] = static_cast<int32_t>(i);\n+          // update column count\n+          column_counts[m][col_idx]++;\n+          if (is_data_float32) {\n+            (reinterpret_cast<float*>(*out_data))[element_index] = static_cast<float>(it->second);\n+          } else {\n+            (reinterpret_cast<double*>(*out_data))[element_index] = it->second;\n+          }\n+        }\n+      }\n+    }\n+    out_len[0] = elements_size;\n+    out_len[1] = col_ptr_size;\n+  }\n+\n   void Predict(int num_iteration, int predict_type, const char* data_filename,\n                int data_has_header, const Config& config,\n                const char* result_filename) {\n@@ -581,7 +822,8 @@ RowPairFunctionFromDenseMatric(const void* data, int num_row, int num_col, int d\n std::function<std::vector<std::pair<int, double>>(int row_idx)>\n RowPairFunctionFromDenseRows(const void** data, int num_col, int data_type);\n \n-std::function<std::vector<std::pair<int, double>>(int idx)>\n+template<typename T>\n+std::function<std::vector<std::pair<int, double>>(T idx)>\n RowFunctionFromCSR(const void* indptr, int indptr_type, const int32_t* indices,\n                    const void* data, int data_type, int64_t nindptr, int64_t nelem);\n \n@@ -713,7 +955,7 @@ int LGBM_DatasetPushRowsByCSR(DatasetHandle dataset,\n                               int64_t start_row) {\n   API_BEGIN();\n   auto p_dataset = reinterpret_cast<Dataset*>(dataset);\n-  auto get_row_fun = RowFunctionFromCSR(indptr, indptr_type, indices, data, data_type, nindptr, nelem);\n+  auto get_row_fun = RowFunctionFromCSR<int>(indptr, indptr_type, indices, data, data_type, nindptr, nelem);\n   int32_t nrow = static_cast<int32_t>(nindptr - 1);\n   OMP_INIT_EX();\n   #pragma omp parallel for schedule(static)\n@@ -860,7 +1102,7 @@ int LGBM_DatasetCreateFromCSR(const void* indptr,\n     omp_set_num_threads(config.num_threads);\n   }\n   std::unique_ptr<Dataset> ret;\n-  auto get_row_fun = RowFunctionFromCSR(indptr, indptr_type, indices, data, data_type, nindptr, nelem);\n+  auto get_row_fun = RowFunctionFromCSR<int>(indptr, indptr_type, indices, data, data_type, nindptr, nelem);\n   int32_t nrow = static_cast<int32_t>(nindptr - 1);\n   if (reference == nullptr) {\n     // sample data first\n@@ -1520,13 +1762,98 @@ int LGBM_BoosterPredictForCSR(BoosterHandle handle,\n     omp_set_num_threads(config.num_threads);\n   }\n   Booster* ref_booster = reinterpret_cast<Booster*>(handle);\n-  auto get_row_fun = RowFunctionFromCSR(indptr, indptr_type, indices, data, data_type, nindptr, nelem);\n+  auto get_row_fun = RowFunctionFromCSR<int>(indptr, indptr_type, indices, data, data_type, nindptr, nelem);\n   int nrow = static_cast<int>(nindptr - 1);\n   ref_booster->Predict(num_iteration, predict_type, nrow, static_cast<int>(num_col), get_row_fun,\n                        config, out_result, out_len);\n   API_END();\n }\n \n+int LGBM_BoosterPredictSparseOutput(BoosterHandle handle,\n+                                    const void* indptr,\n+                                    int indptr_type,\n+                                    const int32_t* indices,\n+                                    const void* data,\n+                                    int data_type,\n+                                    int64_t nindptr,\n+                                    int64_t nelem,\n+                                    int64_t num_col_or_row,\n+                                    int predict_type,\n+                                    int num_iteration,\n+                                    const char* parameter,\n+                                    int matrix_type,\n+                                    int64_t* out_len,\n+                                    void** out_indptr,\n+                                    int32_t** out_indices,\n+                                    void** out_data) {\n+  API_BEGIN();\n+  Booster* ref_booster = reinterpret_cast<Booster*>(handle);\n+  auto param = Config::Str2Map(parameter);\n+  Config config;\n+  config.Set(param);\n+  if (config.num_threads > 0) {\n+    omp_set_num_threads(config.num_threads);\n+  }\n+  if (matrix_type == C_API_MATRIX_TYPE_CSR) {\n+    if (num_col_or_row <= 0) {\n+      Log::Fatal(\"The number of columns should be greater than zero.\");\n+    } else if (num_col_or_row >= INT32_MAX) {\n+      Log::Fatal(\"The number of columns should be smaller than INT32_MAX.\");\n+    }\n+    auto get_row_fun = RowFunctionFromCSR<int64_t>(indptr, indptr_type, indices, data, data_type, nindptr, nelem);\n+    int64_t nrow = nindptr - 1;\n+    ref_booster->PredictSparseCSR(num_iteration, predict_type, nrow, static_cast<int>(num_col_or_row), get_row_fun,\n+                                  config, out_len, out_indptr, indptr_type, out_indices, out_data, data_type);\n+  } else if (matrix_type == C_API_MATRIX_TYPE_CSC) {\n+    int num_threads = OMP_NUM_THREADS();\n+    int ncol = static_cast<int>(nindptr - 1);\n+    std::vector<std::vector<CSC_RowIterator>> iterators(num_threads, std::vector<CSC_RowIterator>());\n+    for (int i = 0; i < num_threads; ++i) {\n+      for (int j = 0; j < ncol; ++j) {\n+        iterators[i].emplace_back(indptr, indptr_type, indices, data, data_type, nindptr, nelem, j);\n+      }\n+    }\n+    std::function<std::vector<std::pair<int, double>>(int64_t row_idx)> get_row_fun =\n+      [&iterators, ncol](int64_t i) {\n+      std::vector<std::pair<int, double>> one_row;\n+      one_row.reserve(ncol);\n+      const int tid = omp_get_thread_num();\n+      for (int j = 0; j < ncol; ++j) {\n+        auto val = iterators[tid][j].Get(static_cast<int>(i));\n+        if (std::fabs(val) > kZeroThreshold || std::isnan(val)) {\n+          one_row.emplace_back(j, val);\n+        }\n+      }\n+      return one_row;\n+    };\n+    ref_booster->PredictSparseCSC(num_iteration, predict_type, num_col_or_row, ncol, get_row_fun, config,\n+                                  out_len, out_indptr, indptr_type, out_indices, out_data, data_type);\n+  } else {\n+    Log::Fatal(\"Unknown matrix type in LGBM_BoosterPredictSparseOutput\");\n+  }\n+  API_END();\n+}\n+\n+int LGBM_BoosterFreePredictSparse(void* indptr, int32_t* indices, void* data, int indptr_type, int data_type) {\n+  API_BEGIN();\n+  if (indptr_type == C_API_DTYPE_INT32) {\n+    delete reinterpret_cast<int32_t*>(indptr);\n+  } else if (indptr_type == C_API_DTYPE_INT64) {\n+    delete reinterpret_cast<int64_t*>(indptr);\n+  } else {\n+    Log::Fatal(\"Unknown indptr type in LGBM_BoosterFreePredictSparse\");\n+  }\n+  delete indices;\n+  if (data_type == C_API_DTYPE_FLOAT32) {\n+    delete reinterpret_cast<float*>(data);\n+  } else if (data_type == C_API_DTYPE_FLOAT64) {\n+    delete reinterpret_cast<double*>(data);\n+  } else {\n+    Log::Fatal(\"Unknown data type in LGBM_BoosterFreePredictSparse\");\n+  }\n+  API_END();\n+}\n+\n int LGBM_BoosterPredictForCSRSingleRow(BoosterHandle handle,\n                                        const void* indptr,\n                                        int indptr_type,\n@@ -1554,7 +1881,7 @@ int LGBM_BoosterPredictForCSRSingleRow(BoosterHandle handle,\n     omp_set_num_threads(config.num_threads);\n   }\n   Booster* ref_booster = reinterpret_cast<Booster*>(handle);\n-  auto get_row_fun = RowFunctionFromCSR(indptr, indptr_type, indices, data, data_type, nindptr, nelem);\n+  auto get_row_fun = RowFunctionFromCSR<int>(indptr, indptr_type, indices, data, data_type, nindptr, nelem);\n   ref_booster->PredictSingleRow(num_iteration, predict_type, static_cast<int32_t>(num_col), get_row_fun, config, out_result, out_len);\n   API_END();\n }\n@@ -1890,13 +2217,14 @@ RowPairFunctionFromDenseRows(const void** data, int num_col, int data_type) {\n   };\n }\n \n-std::function<std::vector<std::pair<int, double>>(int idx)>\n+template<typename T>\n+std::function<std::vector<std::pair<int, double>>(T idx)>\n RowFunctionFromCSR(const void* indptr, int indptr_type, const int32_t* indices, const void* data, int data_type, int64_t , int64_t ) {\n   if (data_type == C_API_DTYPE_FLOAT32) {\n     const float* data_ptr = reinterpret_cast<const float*>(data);\n     if (indptr_type == C_API_DTYPE_INT32) {\n       const int32_t* ptr_indptr = reinterpret_cast<const int32_t*>(indptr);\n-      return [=] (int idx) {\n+      return [=] (T idx) {\n         std::vector<std::pair<int, double>> ret;\n         int64_t start = ptr_indptr[idx];\n         int64_t end = ptr_indptr[idx + 1];\n@@ -1910,7 +2238,7 @@ RowFunctionFromCSR(const void* indptr, int indptr_type, const int32_t* indices,\n       };\n     } else if (indptr_type == C_API_DTYPE_INT64) {\n       const int64_t* ptr_indptr = reinterpret_cast<const int64_t*>(indptr);\n-      return [=] (int idx) {\n+      return [=] (T idx) {\n         std::vector<std::pair<int, double>> ret;\n         int64_t start = ptr_indptr[idx];\n         int64_t end = ptr_indptr[idx + 1];\n@@ -1927,7 +2255,7 @@ RowFunctionFromCSR(const void* indptr, int indptr_type, const int32_t* indices,\n     const double* data_ptr = reinterpret_cast<const double*>(data);\n     if (indptr_type == C_API_DTYPE_INT32) {\n       const int32_t* ptr_indptr = reinterpret_cast<const int32_t*>(indptr);\n-      return [=] (int idx) {\n+      return [=] (T idx) {\n         std::vector<std::pair<int, double>> ret;\n         int64_t start = ptr_indptr[idx];\n         int64_t end = ptr_indptr[idx + 1];\n@@ -1941,7 +2269,7 @@ RowFunctionFromCSR(const void* indptr, int indptr_type, const int32_t* indices,\n       };\n     } else if (indptr_type == C_API_DTYPE_INT64) {\n       const int64_t* ptr_indptr = reinterpret_cast<const int64_t*>(indptr);\n-      return [=] (int idx) {\n+      return [=] (T idx) {\n         std::vector<std::pair<int, double>> ret;\n         int64_t start = ptr_indptr[idx];\n         int64_t end = ptr_indptr[idx + 1];\ndiff --git a/src/io/tree.cpp b/src/io/tree.cpp\nindex 63641311787f..8e5104f168eb 100644\n--- a/src/io/tree.cpp\n+++ b/src/io/tree.cpp\n@@ -687,7 +687,9 @@ void Tree::TreeSHAP(const double *feature_values, double *phi,\n                     double parent_one_fraction, int parent_feature_index) const {\n   // extend the unique path\n   PathElement* unique_path = parent_unique_path + unique_depth;\n-  if (unique_depth > 0) std::copy(parent_unique_path, parent_unique_path + unique_depth, unique_path);\n+  if (unique_depth > 0) {\n+    std::copy(parent_unique_path, parent_unique_path + unique_depth, unique_path);\n+  }\n   ExtendPath(unique_path, unique_depth, parent_zero_fraction,\n              parent_one_fraction, parent_feature_index);\n \n@@ -730,6 +732,58 @@ void Tree::TreeSHAP(const double *feature_values, double *phi,\n   }\n }\n \n+// recursive sparse computation of SHAP values for a decision tree\n+void Tree::TreeSHAPByMap(const std::unordered_map<int, double>& feature_values, std::unordered_map<int, double>* phi,\n+                         int node, int unique_depth,\n+                         PathElement *parent_unique_path, double parent_zero_fraction,\n+                         double parent_one_fraction, int parent_feature_index) const {\n+  // extend the unique path\n+  PathElement* unique_path = parent_unique_path + unique_depth;\n+  if (unique_depth > 0) {\n+    std::copy(parent_unique_path, parent_unique_path + unique_depth, unique_path);\n+  }\n+  ExtendPath(unique_path, unique_depth, parent_zero_fraction,\n+             parent_one_fraction, parent_feature_index);\n+\n+  // leaf node\n+  if (node < 0) {\n+    for (int i = 1; i <= unique_depth; ++i) {\n+      const double w = UnwoundPathSum(unique_path, unique_depth, i);\n+      const PathElement &el = unique_path[i];\n+      (*phi)[el.feature_index] += w*(el.one_fraction - el.zero_fraction)*leaf_value_[~node];\n+    }\n+\n+  // internal node\n+  } else {\n+    const int hot_index = Decision(feature_values.count(split_feature_[node]) > 0 ? feature_values.at(split_feature_[node]) : 0.0f, node);\n+    const int cold_index = (hot_index == left_child_[node] ? right_child_[node] : left_child_[node]);\n+    const double w = data_count(node);\n+    const double hot_zero_fraction = data_count(hot_index) / w;\n+    const double cold_zero_fraction = data_count(cold_index) / w;\n+    double incoming_zero_fraction = 1;\n+    double incoming_one_fraction = 1;\n+\n+    // see if we have already split on this feature,\n+    // if so we undo that split so we can redo it for this node\n+    int path_index = 0;\n+    for (; path_index <= unique_depth; ++path_index) {\n+      if (unique_path[path_index].feature_index == split_feature_[node]) break;\n+    }\n+    if (path_index != unique_depth + 1) {\n+      incoming_zero_fraction = unique_path[path_index].zero_fraction;\n+      incoming_one_fraction = unique_path[path_index].one_fraction;\n+      UnwindPath(unique_path, unique_depth, path_index);\n+      unique_depth -= 1;\n+    }\n+\n+    TreeSHAPByMap(feature_values, phi, hot_index, unique_depth + 1, unique_path,\n+                  hot_zero_fraction*incoming_zero_fraction, incoming_one_fraction, split_feature_[node]);\n+\n+    TreeSHAPByMap(feature_values, phi, cold_index, unique_depth + 1, unique_path,\n+                  cold_zero_fraction*incoming_zero_fraction, 0, split_feature_[node]);\n+  }\n+}\n+\n double Tree::ExpectedValue() const {\n   if (num_leaves_ == 1) return LeafOutput(0);\n   const double total_count = internal_count_[0];\ndiff --git a/tests/python_package_test/test_engine.py b/tests/python_package_test/test_engine.py\nindex dc48fc9d3a39..7af45ecb84af 100644\n--- a/tests/python_package_test/test_engine.py\n+++ b/tests/python_package_test/test_engine.py\n@@ -9,9 +9,9 @@\n \n import lightgbm as lgb\n import numpy as np\n-from scipy.sparse import csr_matrix\n+from scipy.sparse import csr_matrix, isspmatrix_csr, isspmatrix_csc\n from sklearn.datasets import (load_boston, load_breast_cancer, load_digits,\n-                              load_iris, load_svmlight_file)\n+                              load_iris, load_svmlight_file, make_multilabel_classification)\n from sklearn.metrics import log_loss, mean_absolute_error, mean_squared_error, roc_auc_score\n from sklearn.model_selection import train_test_split, TimeSeriesSplit, GroupKFold\n \n@@ -941,6 +941,60 @@ def test_contribs(self):\n         self.assertLess(np.linalg.norm(gbm.predict(X_test, raw_score=True)\n                                        - np.sum(gbm.predict(X_test, pred_contrib=True), axis=1)), 1e-4)\n \n+    def test_contribs_sparse(self):\n+        n_features = 20\n+        n_samples = 100\n+        # generate CSR sparse dataset\n+        X, y = make_multilabel_classification(n_samples=n_samples,\n+                                              sparse=True,\n+                                              n_features=n_features,\n+                                              n_classes=1,\n+                                              n_labels=2)\n+        y = y.flatten()\n+        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n+        params = {\n+            'objective': 'binary',\n+            'verbose': -1,\n+        }\n+        lgb_train = lgb.Dataset(X_train, y_train)\n+        gbm = lgb.train(params, lgb_train, num_boost_round=20)\n+        contribs_csr = gbm.predict(X_test, pred_contrib=True)\n+        self.assertTrue(isspmatrix_csr(contribs_csr))\n+        # convert data to dense and get back same contribs\n+        contribs_dense = gbm.predict(X_test.toarray(), pred_contrib=True)\n+        # validate the values are the same\n+        np.testing.assert_allclose(contribs_csr.toarray(), contribs_dense)\n+        self.assertLess(np.linalg.norm(gbm.predict(X_test, raw_score=True)\n+                                       - np.sum(contribs_dense, axis=1)), 1e-4)\n+        # validate using CSC matrix\n+        X_test_csc = X_test.tocsc()\n+        contribs_csc = gbm.predict(X_test_csc, pred_contrib=True)\n+        self.assertTrue(isspmatrix_csc(contribs_csc))\n+        # validate the values are the same\n+        np.testing.assert_allclose(contribs_csc.toarray(), contribs_dense)\n+\n+    @unittest.skipIf(psutil.virtual_memory().available / 1024 / 1024 / 1024 < 3, 'not enough RAM')\n+    def test_int32_max_sparse_contribs(self):\n+        params = {\n+            'objective': 'binary'\n+        }\n+        train_features = np.random.rand(100, 1000)\n+        train_targets = [0] * 50 + [1] * 50\n+        lgb_train = lgb.Dataset(train_features, train_targets)\n+        gbm = lgb.train(params, lgb_train, num_boost_round=2)\n+        csr_input_shape = (3000000, 1000)\n+        test_features = csr_matrix(csr_input_shape)\n+        for i in range(0, csr_input_shape[0], csr_input_shape[0] // 6):\n+            for j in range(0, 1000, 100):\n+                test_features[i, j] = random.random()\n+        y_pred_csr = gbm.predict(test_features, pred_contrib=True)\n+        # Note there is an extra column added to the output for the expected value\n+        csr_output_shape = (csr_input_shape[0], csr_input_shape[1] + 1)\n+        self.assertTupleEqual(y_pred_csr.shape, csr_output_shape)\n+        y_pred_csc = gbm.predict(test_features.tocsc(), pred_contrib=True)\n+        # Note output CSC shape should be same as CSR output shape\n+        self.assertTupleEqual(y_pred_csc.shape, csr_output_shape)\n+\n     def test_sliced_data(self):\n         def train_and_get_predictions(features, labels):\n             dataset = lgb.Dataset(features, label=labels)\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Timeout Errors:** The CI build is failing due to HTTPS connection timeouts on `webscope.sandbox.yahoo.com` and `www.microsoft.com`. Consider increasing the timeout duration in the CI configuration or replacing these links with more reliable alternatives.\n\n2. **Matrix Size Handling:** The code for `reshape` does not support sizes > int32 max due to a bug in SciPy, causing issues with sparse matrices. Address this by ensuring the matrix handling logic correctly utilizes CSR rather than CSC for rows exceeding int32 max, leveraging the working CSR code.\n\n3. **Testing Concerns:** The new test for > int32 max adds 23 seconds to CI. Evaluate its necessity for the codebase; if deemed unnecessary, consider disabling or removing it.\n\n4. **Warnings:** Compiler warnings for CSC matrices require further attention \u2014 indices for CSC need to be int64 for rows > int32 max, potentially necessitating significant code adjustments.\n\n5. **Shape Prediction:** Confirmed that current PR does not break SHAP predictions for CSC matrices > INT32_MAX. No change in logic necessary since CSR now handles those cases correctly."
      }
    ],
    "codediff_length": 60138
  },
  {
    "index": 4,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.ci/test.sh b/.ci/test.sh\nindex 4224864a4cae..9da8b48f4ddb 100755\n--- a/.ci/test.sh\n+++ b/.ci/test.sh\n@@ -52,8 +52,8 @@ if [[ $TRAVIS == \"true\" ]] && [[ $TASK == \"lint\" ]]; then\n             \"r-lintr>=2.0\"\n     pip install --user cpplint\n     echo \"Linting Python code\"\n-    pycodestyle --ignore=E501,W503 --exclude=./compute,./.nuget . || exit -1\n-    pydocstyle --convention=numpy --add-ignore=D105 --match-dir=\"^(?!^compute|test|example).*\" --match=\"(?!^test_|setup).*\\.py\" . || exit -1\n+    pycodestyle --ignore=E501,W503 --exclude=./compute,./.nuget,./external_libs . || exit -1\n+    pydocstyle --convention=numpy --add-ignore=D105 --match-dir=\"^(?!^compute|external_libs|test|example).*\" --match=\"(?!^test_|setup).*\\.py\" . || exit -1\n     echo \"Linting R code\"\n     Rscript ${BUILD_DIRECTORY}/.ci/lint_r_code.R ${BUILD_DIRECTORY} || exit -1\n     echo \"Linting C++ code\"\ndiff --git a/.gitmodules b/.gitmodules\nindex 133ceb3889da..8f1772cd19fa 100644\n--- a/.gitmodules\n+++ b/.gitmodules\n@@ -1,3 +1,9 @@\n [submodule \"include/boost/compute\"]\n \tpath = compute\n \turl = https://github.com/boostorg/compute\n+[submodule \"external_libs/fmt\"]\n+\tpath = external_libs/fmt\n+\turl = https://github.com/fmtlib/fmt.git\n+[submodule \"external_libs/fast_double_parser\"]\n+\tpath = external_libs/fast_double_parser\n+\turl = https://github.com/lemire/fast_double_parser.git\ndiff --git a/R-package/.Rbuildignore b/R-package/.Rbuildignore\nindex c231a58a126b..2aeecfe18cc8 100644\n--- a/R-package/.Rbuildignore\n+++ b/R-package/.Rbuildignore\n@@ -1,10 +1,14 @@\n+\\.appveyor\\.yml\n AUTOCONF_UBUNTU_VERSION\n ^autom4te.cache/.*$\n ^.*\\.bin\n ^build_r.R$\n+\\.clang-format\n ^cran-comments\\.md$\n ^docs$\n ^.*\\.dll\n+\\.drone\\.yml\n+\\.git\n \\.gitkeep$\n ^.*\\.history\n ^Makefile$\n@@ -24,3 +28,22 @@ AUTOCONF_UBUNTU_VERSION\n ^src/compute/.gitignore$\n ^src/compute/CONTRIBUTING.md$\n ^src/compute/README.md$\n+src/external_libs/fast_double_parser/benchmarks\n+src/external_libs/fast_double_parser/Makefile\n+src/external_libs/fast_double_parser/.*\\.md\n+src/external_libs/fast_double_parser/tests\n+src/external_libs/fast_double_parser/.*\\.yaml\n+src/external_libs/fast_double_parser/.*\\.yml\n+src/external_libs/fmt/.*\\.md\n+src/external_libs/fmt/doc\n+src/external_libs/fmt/support/Android\\.mk\n+src/external_libs/fmt/support/.*\\.gradle\n+src/external_libs/fmt/support/.*\\.pro\n+src/external_libs/fmt/support/.*\\.py\n+src/external_libs/fmt/support/rtd\n+src/external_libs/fmt/support/.*sublime-syntax\n+src/external_libs/fmt/support/Vagrantfile\n+src/external_libs/fmt/support/.*\\.xml\n+src/external_libs/fmt/support/.*\\.yml\n+src/external_libs/fmt/test\n+\\.travis\\.yml\ndiff --git a/R-package/DESCRIPTION b/R-package/DESCRIPTION\nindex 6e969b087c30..6e61f459c99b 100755\n--- a/R-package/DESCRIPTION\n+++ b/R-package/DESCRIPTION\n@@ -20,6 +20,9 @@ Authors@R: c(\n     person(\"Jay\", \"Loden\", role = c(\"cph\")),\n     person(\"Dave\", \"Daeschler\", role = c(\"cph\")),\n     person(\"Giampaolo\", \"Rodola\", role = c(\"cph\")),\n+    person(\"Alberto\", \"Ferreira\", role = c(\"ctb\")),\n+    person(\"Daniel\", \"Lemire\", role = c(\"ctb\")),\n+    person(\"Victor\", \"Zverovich\", role = c(\"cph\")),\n     person(\"IBM Corporation\", role = c(\"ctb\"))\n     )\n Description: Tree based algorithms can be improved by introducing boosting frameworks. \ndiff --git a/R-package/README.md b/R-package/README.md\nindex f237f14686f6..fc787faed117 100644\n--- a/R-package/README.md\n+++ b/R-package/README.md\n@@ -251,6 +251,7 @@ For more information on this approach, see [\"Writing R Extensions\"](https://cran\n From the root of the repository, run the following.\n \n ```shell\n+git submodule update --init --recursive\n sh build-cran-package.sh\n ```\n \ndiff --git a/build-cran-package.sh b/build-cran-package.sh\nindex d21f5f051d16..a18c9456864b 100755\n--- a/build-cran-package.sh\n+++ b/build-cran-package.sh\n@@ -28,6 +28,15 @@ cp -R R-package/* ${TEMP_R_DIR}\n cp -R include ${TEMP_R_DIR}/src/\n cp -R src/* ${TEMP_R_DIR}/src/\n \n+cp \\\n+    external_libs/fast_double_parser/include/fast_double_parser.h \\\n+    ${TEMP_R_DIR}/src/include/LightGBM\n+\n+mkdir -p ${TEMP_R_DIR}/src/include/LightGBM/fmt\n+cp \\\n+    external_libs/fmt/include/fmt/*.h \\\n+    ${TEMP_R_DIR}/src/include/LightGBM/fmt/\n+\n cd ${TEMP_R_DIR}\n \n     # Remove files not needed for CRAN\n@@ -67,6 +76,16 @@ cd ${TEMP_R_DIR}\n     done\n     find . -name '*.h.bak' -o -name '*.hpp.bak' -o -name '*.cpp.bak' -exec rm {} \\;\n \n+    sed \\\n+        -i.bak \\\n+        -e 's/\\.\\..*fmt\\/format\\.h/LightGBM\\/fmt\\/format\\.h/' \\\n+        src/include/LightGBM/utils/common.h\n+\n+    sed \\\n+        -i.bak \\\n+        -e 's/\\.\\..*fast_double_parser\\.h/LightGBM\\/fast_double_parser\\.h/' \\\n+        src/include/LightGBM/utils/common.h\n+\n     # When building an R package with 'configure', it seems\n     # you're guaranteed to get a shared library called\n     #  <packagename>.so/dll. The package source code expects\ndiff --git a/build_r.R b/build_r.R\nindex b3a98c45cc6a..719e622a9d01 100644\n--- a/build_r.R\n+++ b/build_r.R\n@@ -135,6 +135,17 @@ result <- file.remove(\n )\n .handle_result(result)\n \n+#------------#\n+# submodules #\n+#------------#\n+result <- file.copy(\n+  from = \"external_libs/\"\n+  , to = sprintf(\"%s/\", TEMP_SOURCE_DIR)\n+  , recursive = TRUE\n+  , overwrite = TRUE\n+)\n+.handle_result(result)\n+\n # copy files into the place CMake expects\n for (src_file in c(\"lightgbm_R.cpp\", \"lightgbm_R.h\", \"R_object_helper.h\")) {\n   result <- file.copy(\ndiff --git a/external_libs/fast_double_parser b/external_libs/fast_double_parser\nnew file mode 160000\nindex 000000000000..ace60646c02d\n--- /dev/null\n+++ b/external_libs/fast_double_parser\n@@ -0,0 +1 @@\n+Subproject commit ace60646c02dc54c57f19d644e49a61e7e7758ec\ndiff --git a/external_libs/fmt b/external_libs/fmt\nnew file mode 160000\nindex 000000000000..cc09f1a6798c\n--- /dev/null\n+++ b/external_libs/fmt\n@@ -0,0 +1 @@\n+Subproject commit cc09f1a6798c085c325569ef466bcdcffdc266d4\ndiff --git a/include/LightGBM/utils/common.h b/include/LightGBM/utils/common.h\nindex 07b8484b5577..dd71782fb1ae 100644\n--- a/include/LightGBM/utils/common.h\n+++ b/include/LightGBM/utils/common.h\n@@ -2,9 +2,12 @@\n  * Copyright (c) 2016 Microsoft Corporation. All rights reserved.\n  * Licensed under the MIT License. See LICENSE file in the project root for license information.\n  */\n-#ifndef LIGHTGBM_UTILS_COMMON_FUN_H_\n-#define LIGHTGBM_UTILS_COMMON_FUN_H_\n+#ifndef LIGHTGBM_UTILS_COMMON_H_\n+#define LIGHTGBM_UTILS_COMMON_H_\n \n+#if ((defined(sun) || defined(__sun)) && (defined(__SVR4) || defined(__svr4__)))\n+#include <LightGBM/utils/common_legacy_solaris.h>\n+#endif\n #include <LightGBM/utils/log.h>\n #include <LightGBM/utils/openmp_wrapper.h>\n \n@@ -15,6 +18,7 @@\n #include <cmath>\n #include <cstdint>\n #include <cstdio>\n+#include <cstring>\n #include <functional>\n #include <iomanip>\n #include <iterator>\n@@ -26,6 +30,12 @@\n #include <utility>\n #include <vector>\n \n+#if (!((defined(sun) || defined(__sun)) && (defined(__SVR4) || defined(__svr4__))))\n+#define FMT_HEADER_ONLY\n+#include \"../../../external_libs/fmt/include/fmt/format.h\"\n+#endif\n+#include \"../../../external_libs/fast_double_parser/include/fast_double_parser.h\"\n+\n #ifdef _MSC_VER\n #include <intrin.h>\n #pragma intrinsic(_BitScanReverse)\n@@ -51,6 +61,13 @@ namespace LightGBM {\n \n namespace Common {\n \n+/*!\n+* Imbues the stream with the C locale.\n+*/\n+static void C_stringstream(std::stringstream &ss) {\n+  ss.imbue(std::locale::classic());\n+}\n+\n inline static char tolower(char in) {\n   if (in <= 'Z' && in >= 'A')\n     return in - ('Z' - 'z');\n@@ -329,94 +346,6 @@ inline static bool AtofAndCheck(const char* p, double* out) {\n   return true;\n }\n \n-inline static unsigned CountDecimalDigit32(uint32_t n) {\n-#if defined(_MSC_VER) || defined(__GNUC__)\n-  static const uint32_t powers_of_10[] = {\n-    0,\n-    10,\n-    100,\n-    1000,\n-    10000,\n-    100000,\n-    1000000,\n-    10000000,\n-    100000000,\n-    1000000000\n-  };\n-#ifdef _MSC_VER\n-  // NOLINTNEXTLINE\n-  unsigned long i = 0;\n-  _BitScanReverse(&i, n | 1);\n-  uint32_t t = (i + 1) * 1233 >> 12;\n-#elif __GNUC__\n-  uint32_t t = (32 - __builtin_clz(n | 1)) * 1233 >> 12;\n-#endif\n-  return t - (n < powers_of_10[t]) + 1;\n-#else\n-  if (n < 10) return 1;\n-  if (n < 100) return 2;\n-  if (n < 1000) return 3;\n-  if (n < 10000) return 4;\n-  if (n < 100000) return 5;\n-  if (n < 1000000) return 6;\n-  if (n < 10000000) return 7;\n-  if (n < 100000000) return 8;\n-  if (n < 1000000000) return 9;\n-  return 10;\n-#endif\n-}\n-\n-inline static void Uint32ToStr(uint32_t value, char* buffer) {\n-  const char kDigitsLut[200] = {\n-    '0', '0', '0', '1', '0', '2', '0', '3', '0', '4', '0', '5', '0', '6', '0', '7', '0', '8', '0', '9',\n-    '1', '0', '1', '1', '1', '2', '1', '3', '1', '4', '1', '5', '1', '6', '1', '7', '1', '8', '1', '9',\n-    '2', '0', '2', '1', '2', '2', '2', '3', '2', '4', '2', '5', '2', '6', '2', '7', '2', '8', '2', '9',\n-    '3', '0', '3', '1', '3', '2', '3', '3', '3', '4', '3', '5', '3', '6', '3', '7', '3', '8', '3', '9',\n-    '4', '0', '4', '1', '4', '2', '4', '3', '4', '4', '4', '5', '4', '6', '4', '7', '4', '8', '4', '9',\n-    '5', '0', '5', '1', '5', '2', '5', '3', '5', '4', '5', '5', '5', '6', '5', '7', '5', '8', '5', '9',\n-    '6', '0', '6', '1', '6', '2', '6', '3', '6', '4', '6', '5', '6', '6', '6', '7', '6', '8', '6', '9',\n-    '7', '0', '7', '1', '7', '2', '7', '3', '7', '4', '7', '5', '7', '6', '7', '7', '7', '8', '7', '9',\n-    '8', '0', '8', '1', '8', '2', '8', '3', '8', '4', '8', '5', '8', '6', '8', '7', '8', '8', '8', '9',\n-    '9', '0', '9', '1', '9', '2', '9', '3', '9', '4', '9', '5', '9', '6', '9', '7', '9', '8', '9', '9'\n-  };\n-  unsigned digit = CountDecimalDigit32(value);\n-  buffer += digit;\n-  *buffer = '\\0';\n-\n-  while (value >= 100) {\n-    const unsigned i = (value % 100) << 1;\n-    value /= 100;\n-    *--buffer = kDigitsLut[i + 1];\n-    *--buffer = kDigitsLut[i];\n-  }\n-\n-  if (value < 10) {\n-    *--buffer = static_cast<char>(value) + '0';\n-  } else {\n-    const unsigned i = value << 1;\n-    *--buffer = kDigitsLut[i + 1];\n-    *--buffer = kDigitsLut[i];\n-  }\n-}\n-\n-inline static void Int32ToStr(int32_t value, char* buffer) {\n-  uint32_t u = static_cast<uint32_t>(value);\n-  if (value < 0) {\n-    *buffer++ = '-';\n-    u = ~u + 1;\n-  }\n-  Uint32ToStr(u, buffer);\n-}\n-\n-inline static void DoubleToStr(double value, char* buffer, size_t buffer_len) {\n-  #ifdef _MSC_VER\n-  int num_chars = sprintf_s(buffer, buffer_len, \"%.17g\", value);\n-  #else\n-  int num_chars = snprintf(buffer, buffer_len, \"%.17g\", value);\n-  #endif\n-  CHECK_GE(num_chars, 0);\n-}\n-\n inline static const char* SkipSpaceAndTab(const char* p) {\n   while (*p == ' ' || *p == '\\t') {\n     ++p;\n@@ -440,67 +369,6 @@ inline static std::vector<T2> ArrayCast(const std::vector<T>& arr) {\n   return ret;\n }\n \n-template<typename T, bool is_float, bool is_unsign>\n-struct __TToStringHelperFast {\n-  void operator()(T value, char* buffer, size_t) const {\n-    Int32ToStr(value, buffer);\n-  }\n-};\n-\n-template<typename T>\n-struct __TToStringHelperFast<T, true, false> {\n-  void operator()(T value, char* buffer, size_t buf_len)\n-  const {\n-    #ifdef _MSC_VER\n-    int num_chars = sprintf_s(buffer, buf_len, \"%g\", value);\n-    #else\n-    int num_chars = snprintf(buffer, buf_len, \"%g\", value);\n-    #endif\n-    CHECK_GE(num_chars, 0);\n-  }\n-};\n-\n-template<typename T>\n-struct __TToStringHelperFast<T, false, true> {\n-  void operator()(T value, char* buffer, size_t) const {\n-    Uint32ToStr(value, buffer);\n-  }\n-};\n-\n-template<typename T>\n-inline static std::string ArrayToStringFast(const std::vector<T>& arr, size_t n) {\n-  if (arr.empty() || n == 0) {\n-    return std::string(\"\");\n-  }\n-  __TToStringHelperFast<T, std::is_floating_point<T>::value, std::is_unsigned<T>::value> helper;\n-  const size_t buf_len = 16;\n-  std::vector<char> buffer(buf_len);\n-  std::stringstream str_buf;\n-  helper(arr[0], buffer.data(), buf_len);\n-  str_buf << buffer.data();\n-  for (size_t i = 1; i < std::min(n, arr.size()); ++i) {\n-    helper(arr[i], buffer.data(), buf_len);\n-    str_buf << ' ' << buffer.data();\n-  }\n-  return str_buf.str();\n-}\n-\n-inline static std::string ArrayToString(const std::vector<double>& arr, size_t n) {\n-  if (arr.empty() || n == 0) {\n-    return std::string(\"\");\n-  }\n-  const size_t buf_len = 32;\n-  std::vector<char> buffer(buf_len);\n-  std::stringstream str_buf;\n-  DoubleToStr(arr[0], buffer.data(), buf_len);\n-  str_buf << buffer.data();\n-  for (size_t i = 1; i < std::min(n, arr.size()); ++i) {\n-    DoubleToStr(arr[i], buffer.data(), buf_len);\n-    str_buf << ' ' << buffer.data();\n-  }\n-  return str_buf.str();\n-}\n-\n template<typename T, bool is_float>\n struct __StringToTHelper {\n   T operator()(const std::string& str) const {\n@@ -588,11 +456,14 @@ inline static std::vector<T> StringToArrayFast(const std::string& str, int n) {\n }\n \n template<typename T>\n-inline static std::string Join(const std::vector<T>& strs, const char* delimiter) {\n+inline static std::string Join(const std::vector<T>& strs, const char* delimiter, const bool force_C_locale = false) {\n   if (strs.empty()) {\n     return std::string(\"\");\n   }\n   std::stringstream str_buf;\n+  if (force_C_locale) {\n+    C_stringstream(str_buf);\n+  }\n   str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);\n   str_buf << strs[0];\n   for (size_t i = 1; i < strs.size(); ++i) {\n@@ -603,11 +474,14 @@ inline static std::string Join(const std::vector<T>& strs, const char* delimiter\n }\n \n template<>\n-inline std::string Join<int8_t>(const std::vector<int8_t>& strs, const char* delimiter) {\n+inline std::string Join<int8_t>(const std::vector<int8_t>& strs, const char* delimiter, const bool force_C_locale) {\n   if (strs.empty()) {\n     return std::string(\"\");\n   }\n   std::stringstream str_buf;\n+  if (force_C_locale) {\n+    C_stringstream(str_buf);\n+  }\n   str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);\n   str_buf << static_cast<int16_t>(strs[0]);\n   for (size_t i = 1; i < strs.size(); ++i) {\n@@ -618,13 +492,16 @@ inline std::string Join<int8_t>(const std::vector<int8_t>& strs, const char* del\n }\n \n template<typename T>\n-inline static std::string Join(const std::vector<T>& strs, size_t start, size_t end, const char* delimiter) {\n+inline static std::string Join(const std::vector<T>& strs, size_t start, size_t end, const char* delimiter, const bool force_C_locale = false) {\n   if (end - start <= 0) {\n     return std::string(\"\");\n   }\n   start = std::min(start, static_cast<size_t>(strs.size()) - 1);\n   end = std::min(end, static_cast<size_t>(strs.size()));\n   std::stringstream str_buf;\n+  if (force_C_locale) {\n+    C_stringstream(str_buf);\n+  }\n   str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);\n   str_buf << strs[start];\n   for (size_t i = start + 1; i < end; ++i) {\n@@ -1137,6 +1014,217 @@ class FunctionTimer {\n \n extern Common::Timer global_timer;\n \n+\n+/*!\n+* Provides locale-independent alternatives to Common's methods.\n+* Essential to make models robust to locale settings.\n+*/\n+namespace CommonC {\n+\n+template<typename T>\n+inline static std::string Join(const std::vector<T>& strs, const char* delimiter) {\n+  return LightGBM::Common::Join(strs, delimiter, true);\n+}\n+\n+template<typename T>\n+inline static std::string Join(const std::vector<T>& strs, size_t start, size_t end, const char* delimiter) {\n+  return LightGBM::Common::Join(strs, start, end, delimiter, true);\n+}\n+\n+inline static const char* Atof(const char* p, double* out) {\n+  return LightGBM::Common::Atof(p, out);\n+}\n+\n+template<typename T, bool is_float>\n+struct __StringToTHelperFast {\n+  const char* operator()(const char*p, T* out) const {\n+    return LightGBM::Common::Atoi(p, out);\n+  }\n+};\n+\n+/*!\n+* \\warning Beware that ``Common::Atof`` in ``__StringToTHelperFast``,\n+*          has **less** floating point precision than ``__StringToTHelper``.\n+*          Both versions are kept to maintain bit-for-bit the \"legacy\" LightGBM behaviour in terms of precision.\n+*          Check ``StringToArrayFast`` and ``StringToArray`` for more details on this.\n+*/\n+template<typename T>\n+struct __StringToTHelperFast<T, true> {\n+  const char* operator()(const char*p, T* out) const {\n+    double tmp = 0.0f;\n+    auto ret = Atof(p, &tmp);\n+    *out = static_cast<T>(tmp);\n+    return ret;\n+  }\n+};\n+\n+template<typename T, bool is_float>\n+struct __StringToTHelper {\n+  T operator()(const std::string& str) const {\n+    T ret = 0;\n+    LightGBM::Common::Atoi(str.c_str(), &ret);\n+    return ret;\n+  }\n+};\n+\n+/*!\n+* \\warning Beware that ``Common::Atof`` in ``__StringToTHelperFast``,\n+*          has **less** floating point precision than ``__StringToTHelper``.\n+*          Both versions are kept to maintain bit-for-bit the \"legacy\" LightGBM behaviour in terms of precision.\n+*          Check ``StringToArrayFast`` and ``StringToArray`` for more details on this.\n+* \\note It is possible that ``fast_double_parser::parse_number`` is faster than ``Common::Atof``.\n+*/\n+template<typename T>\n+struct __StringToTHelper<T, true> {\n+  T operator()(const std::string& str) const {\n+    double tmp;\n+\n+    // Fast (common) path: For numeric inputs in RFC 7159 format:\n+    const bool fast_parse_succeeded = fast_double_parser::parse_number(str.c_str(), &tmp);\n+\n+    // Rare path: Not in RFC 7159 format. Possible \"inf\", \"nan\", etc. Fallback to standard library:\n+    if (!fast_parse_succeeded) {\n+      std::stringstream ss;\n+      Common::C_stringstream(ss);\n+      ss << str;\n+      ss >> tmp;\n+    }\n+\n+    return static_cast<T>(tmp);\n+  }\n+};\n+\n+\n+/*!\n+* \\warning Beware that due to internal use of ``Common::Atof`` in ``__StringToTHelperFast``,\n+*          this method has less precision for floating point numbers than ``StringToArray``,\n+*          which calls ``__StringToTHelper``.\n+*          As such, ``StringToArrayFast`` and ``StringToArray`` are not equivalent!\n+*          Both versions were kept to maintain bit-for-bit the \"legacy\" LightGBM behaviour in terms of precision.\n+*/\n+template<typename T>\n+inline static std::vector<T> StringToArrayFast(const std::string& str, int n) {\n+  if (n == 0) {\n+    return std::vector<T>();\n+  }\n+  auto p_str = str.c_str();\n+  __StringToTHelperFast<T, std::is_floating_point<T>::value> helper;\n+  std::vector<T> ret(n);\n+  for (int i = 0; i < n; ++i) {\n+    p_str = helper(p_str, &ret[i]);\n+  }\n+  return ret;\n+}\n+\n+/*!\n+* \\warning Do not replace calls to this method by ``StringToArrayFast``.\n+*          This method is more precise for floating point numbers.\n+*          Check ``StringToArrayFast`` for more details.\n+*/\n+template<typename T>\n+inline static std::vector<T> StringToArray(const std::string& str, int n) {\n+  if (n == 0) {\n+    return std::vector<T>();\n+  }\n+  std::vector<std::string> strs = LightGBM::Common::Split(str.c_str(), ' ');\n+  CHECK_EQ(strs.size(), static_cast<size_t>(n));\n+  std::vector<T> ret;\n+  ret.reserve(strs.size());\n+  __StringToTHelper<T, std::is_floating_point<T>::value> helper;\n+  for (const auto& s : strs) {\n+    ret.push_back(helper(s));\n+  }\n+  return ret;\n+}\n+\n+/*!\n+* \\warning Do not replace calls to this method by ``StringToArrayFast``.\n+*          This method is more precise for floating point numbers.\n+*          Check ``StringToArrayFast`` for more details.\n+*/\n+template<typename T>\n+inline static std::vector<T> StringToArray(const std::string& str, char delimiter) {\n+  std::vector<std::string> strs = LightGBM::Common::Split(str.c_str(), delimiter);\n+  std::vector<T> ret;\n+  ret.reserve(strs.size());\n+  __StringToTHelper<T, std::is_floating_point<T>::value> helper;\n+  for (const auto& s : strs) {\n+    ret.push_back(helper(s));\n+  }\n+  return ret;\n+}\n+\n+#if (!((defined(sun) || defined(__sun)) && (defined(__SVR4) || defined(__svr4__))))\n+/*!\n+* Safely formats a value onto a buffer according to a format string and null-terminates it.\n+*\n+* \\note It checks that the full value was written or forcefully aborts.\n+*       This safety check serves to prevent incorrect internal API usage.\n+*       Correct usage will never incur in this problem:\n+*         - The received buffer size shall be sufficient at all times for the input format string and value.\n+*/\n+template <typename T>\n+inline static void format_to_buf(char* buffer, const size_t buf_len, const char* format, const T value) {\n+    auto result = fmt::format_to_n(buffer, buf_len, format, value);\n+    if (result.size >= buf_len) {\n+      Log::Fatal(\"Numerical conversion failed. Buffer is too small.\");\n+    }\n+    buffer[result.size] = '\\0';\n+}\n+\n+template<typename T, bool is_float, bool high_precision>\n+struct __TToStringHelper {\n+  void operator()(T value, char* buffer, size_t buf_len) const {\n+    format_to_buf(buffer, buf_len, \"{}\", value);\n+  }\n+};\n+\n+template<typename T>\n+struct __TToStringHelper<T, true, false> {\n+  void operator()(T value, char* buffer, size_t buf_len) const {\n+    format_to_buf(buffer, buf_len, \"{:g}\", value);\n+  }\n+};\n+\n+template<typename T>\n+struct __TToStringHelper<T, true, true> {\n+  void operator()(T value, char* buffer, size_t buf_len) const {\n+    format_to_buf(buffer, buf_len, \"{:.17g}\", value);\n+  }\n+};\n+\n+/*!\n+* Converts an array to a string with with values separated by the space character.\n+* This method replaces Common's ``ArrayToString`` and ``ArrayToStringFast`` functionality\n+* and is locale-independent.\n+* \n+* \\note If ``high_precision_output`` is set to true,\n+*       floating point values are output with more digits of precision.\n+*/\n+template<bool high_precision_output = false, typename T>\n+inline static std::string ArrayToString(const std::vector<T>& arr, size_t n) {\n+  if (arr.empty() || n == 0) {\n+    return std::string(\"\");\n+  }\n+  __TToStringHelper<T, std::is_floating_point<T>::value, high_precision_output> helper;\n+  const size_t buf_len = high_precision_output ? 32 : 16;\n+  std::vector<char> buffer(buf_len);\n+  std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n+  helper(arr[0], buffer.data(), buf_len);\n+  str_buf << buffer.data();\n+  for (size_t i = 1; i < std::min(n, arr.size()); ++i) {\n+    helper(arr[i], buffer.data(), buf_len);\n+    str_buf << ' ' << buffer.data();\n+  }\n+  return str_buf.str();\n+}\n+#endif  // (!((defined(sun) || defined(__sun)) && (defined(__SVR4) || defined(__svr4__))))\n+\n+\n+}  // namespace CommonC\n+\n+\n }  // namespace LightGBM\n \n-#endif   // LightGBM_UTILS_COMMON_FUN_H_\n+#endif  // LIGHTGBM_UTILS_COMMON_H_\ndiff --git a/include/LightGBM/utils/common_legacy_solaris.h b/include/LightGBM/utils/common_legacy_solaris.h\nnew file mode 100644\nindex 000000000000..97f977108fc6\n--- /dev/null\n+++ b/include/LightGBM/utils/common_legacy_solaris.h\n@@ -0,0 +1,160 @@\n+/*!\n+ * Copyright (c) 2016 Microsoft Corporation. All rights reserved.\n+ * Licensed under the MIT License. See LICENSE file in the project root for license information.\n+ */\n+/*!\n+ * This file is meant to be used ONLY IN SOLARIS!\n+ * The newer code that replaced it is faster and safe regarding locale!\n+ */\n+#ifndef LIGHTGBM_UTILS_COMMON_LEGACY_SOLARIS_H_\n+#define LIGHTGBM_UTILS_COMMON_LEGACY_SOLARIS_H_\n+\n+#include <LightGBM/utils/log.h>\n+\n+#include <algorithm>\n+#include <sstream>\n+#include <type_traits>\n+#include <vector>\n+#include <string>\n+\n+namespace LightGBM {\n+\n+namespace CommonLegacy {\n+\n+inline static unsigned CountDecimalDigit32(uint32_t n) {\n+  if (n < 10) return 1;\n+  else if (n < 100) return 2;\n+  else if (n < 1000) return 3;\n+  else if (n < 10000) return 4;\n+  else if (n < 100000) return 5;\n+  else if (n < 1000000) return 6;\n+  else if (n < 10000000) return 7;\n+  else if (n < 100000000) return 8;\n+  else if (n < 1000000000) return 9;\n+  else\n+    return 10;\n+}\n+\n+inline static void Uint32ToStr(uint32_t value, char* buffer) {\n+  const char kDigitsLut[200] = {\n+    '0', '0', '0', '1', '0', '2', '0', '3', '0', '4', '0', '5', '0', '6', '0', '7', '0', '8', '0', '9',\n+    '1', '0', '1', '1', '1', '2', '1', '3', '1', '4', '1', '5', '1', '6', '1', '7', '1', '8', '1', '9',\n+    '2', '0', '2', '1', '2', '2', '2', '3', '2', '4', '2', '5', '2', '6', '2', '7', '2', '8', '2', '9',\n+    '3', '0', '3', '1', '3', '2', '3', '3', '3', '4', '3', '5', '3', '6', '3', '7', '3', '8', '3', '9',\n+    '4', '0', '4', '1', '4', '2', '4', '3', '4', '4', '4', '5', '4', '6', '4', '7', '4', '8', '4', '9',\n+    '5', '0', '5', '1', '5', '2', '5', '3', '5', '4', '5', '5', '5', '6', '5', '7', '5', '8', '5', '9',\n+    '6', '0', '6', '1', '6', '2', '6', '3', '6', '4', '6', '5', '6', '6', '6', '7', '6', '8', '6', '9',\n+    '7', '0', '7', '1', '7', '2', '7', '3', '7', '4', '7', '5', '7', '6', '7', '7', '7', '8', '7', '9',\n+    '8', '0', '8', '1', '8', '2', '8', '3', '8', '4', '8', '5', '8', '6', '8', '7', '8', '8', '8', '9',\n+    '9', '0', '9', '1', '9', '2', '9', '3', '9', '4', '9', '5', '9', '6', '9', '7', '9', '8', '9', '9'\n+  };\n+  unsigned digit = CountDecimalDigit32(value);\n+  buffer += digit;\n+  *buffer = '\\0';\n+\n+  while (value >= 100) {\n+    const unsigned i = (value % 100) << 1;\n+    value /= 100;\n+    *--buffer = kDigitsLut[i + 1];\n+    *--buffer = kDigitsLut[i];\n+  }\n+\n+  if (value < 10) {\n+    *--buffer = static_cast<char>(value) + '0';\n+  } else {\n+    const unsigned i = value << 1;\n+    *--buffer = kDigitsLut[i + 1];\n+    *--buffer = kDigitsLut[i];\n+  }\n+}\n+\n+inline static void Int32ToStr(int32_t value, char* buffer) {\n+  uint32_t u = static_cast<uint32_t>(value);\n+  if (value < 0) {\n+    *buffer++ = '-';\n+    u = ~u + 1;\n+  }\n+  Uint32ToStr(u, buffer);\n+}\n+\n+inline static void DoubleToStr(double value, char* buffer, size_t buffer_len) {\n+  int num_chars = snprintf(buffer, buffer_len, \"%.17g\", value);\n+  CHECK_GE(num_chars, 0);\n+}\n+\n+\n+template<typename T, bool is_float, bool is_unsign>\n+struct __TToStringHelperFast {\n+  void operator()(T value, char* buffer, size_t) const {\n+    Int32ToStr(value, buffer);\n+  }\n+};\n+\n+template<typename T>\n+struct __TToStringHelperFast<T, true, false> {\n+  void operator()(T value, char* buffer, size_t buf_len) const {\n+    int num_chars = snprintf(buffer, buf_len, \"%g\", value);\n+    CHECK_GE(num_chars, 0);\n+  }\n+};\n+\n+template<typename T>\n+struct __TToStringHelperFast<T, false, true> {\n+  void operator()(T value, char* buffer, size_t) const {\n+    Uint32ToStr(value, buffer);\n+  }\n+};\n+\n+template<typename T>\n+inline static std::string _ArrayToStringFast(const std::vector<T>& arr, size_t n) {\n+  if (arr.empty() || n == 0) {\n+    return std::string(\"\");\n+  }\n+  __TToStringHelperFast<T, std::is_floating_point<T>::value, std::is_unsigned<T>::value> helper;\n+  const size_t buf_len = 16;\n+  std::vector<char> buffer(buf_len);\n+  std::stringstream str_buf;\n+  helper(arr[0], buffer.data(), buf_len);\n+  str_buf << buffer.data();\n+  for (size_t i = 1; i < std::min(n, arr.size()); ++i) {\n+    helper(arr[i], buffer.data(), buf_len);\n+    str_buf << ' ' << buffer.data();\n+  }\n+  return str_buf.str();\n+}\n+\n+inline static std::string _ArrayToString(const std::vector<double>& arr, size_t n) {\n+  if (arr.empty() || n == 0) {\n+    return std::string(\"\");\n+  }\n+  const size_t buf_len = 32;\n+  std::vector<char> buffer(buf_len);\n+  std::stringstream str_buf;\n+  DoubleToStr(arr[0], buffer.data(), buf_len);\n+  str_buf << buffer.data();\n+  for (size_t i = 1; i < std::min(n, arr.size()); ++i) {\n+    DoubleToStr(arr[i], buffer.data(), buf_len);\n+    str_buf << ' ' << buffer.data();\n+  }\n+  return str_buf.str();\n+}\n+\n+\n+template<bool high_precision_output = false, typename T>\n+inline static typename std::enable_if<high_precision_output == false, std::string>::type\n+ArrayToString(const std::vector<T>& arr, size_t n) {\n+    return _ArrayToStringFast(arr, n);\n+}\n+\n+template<bool high_precision_output, typename T>\n+inline static typename std::enable_if<\n+(high_precision_output == true) && (std::is_same<T, double>::value), std::string>::type\n+ArrayToString(const std::vector<T>& arr, size_t n) {\n+    return _ArrayToString(arr, n);\n+}\n+\n+}  // namespace CommonLegacy\n+\n+}  // namespace LightGBM\n+\n+#endif  // LIGHTGBM_UTILS_COMMON_LEGACY_SOLARIS_H_\ndiff --git a/python-package/MANIFEST.in b/python-package/MANIFEST.in\nindex 8104cdbe93e9..2732a9962e14 100644\n--- a/python-package/MANIFEST.in\n+++ b/python-package/MANIFEST.in\n@@ -8,6 +8,7 @@ recursive-include compile/compute/ *.txt\n recursive-include compile/compute/cmake *\n recursive-include compile/compute/include *\n recursive-include compile/compute/meta *\n+recursive-include compile/external_libs *\n recursive-include compile/include *\n recursive-include compile/src *\n recursive-include compile/windows LightGBM.sln LightGBM.vcxproj\ndiff --git a/python-package/setup.py b/python-package/setup.py\nindex 4e3242fe2191..61a69c42c299 100644\n--- a/python-package/setup.py\n+++ b/python-package/setup.py\n@@ -43,6 +43,7 @@ def copy_files_helper(folder_name):\n     if not os.path.isfile(os.path.join(CURRENT_DIR, '_IS_SOURCE_PACKAGE.txt')):\n         copy_files_helper('include')\n         copy_files_helper('src')\n+        copy_files_helper('external_libs')\n         if not os.path.exists(os.path.join(CURRENT_DIR, \"compile\", \"windows\")):\n             os.makedirs(os.path.join(CURRENT_DIR, \"compile\", \"windows\"))\n         copy_file(os.path.join(CURRENT_DIR, os.path.pardir, \"windows\", \"LightGBM.sln\"),\ndiff --git a/src/boosting/gbdt_model_text.cpp b/src/boosting/gbdt_model_text.cpp\nindex 4eeb731f587f..e5cec8b61db0 100644\n--- a/src/boosting/gbdt_model_text.cpp\n+++ b/src/boosting/gbdt_model_text.cpp\n@@ -20,6 +20,7 @@ const char* kModelVersion = \"v3\";\n \n std::string GBDT::DumpModel(int start_iteration, int num_iteration, int feature_importance_type) const {\n   std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n \n   str_buf << \"{\";\n   str_buf << \"\\\"name\\\":\\\"\" << SubModelName() << \"\\\",\" << '\\n';\n@@ -34,16 +35,17 @@ std::string GBDT::DumpModel(int start_iteration, int num_iteration, int feature_\n \n   str_buf << \"\\\"average_output\\\":\" << (average_output_ ? \"true\" : \"false\") << \",\\n\";\n \n-  str_buf << \"\\\"feature_names\\\":[\\\"\" << Common::Join(feature_names_, \"\\\",\\\"\")\n+  str_buf << \"\\\"feature_names\\\":[\\\"\" << CommonC::Join(feature_names_, \"\\\",\\\"\")\n           << \"\\\"],\" << '\\n';\n \n   str_buf << \"\\\"monotone_constraints\\\":[\"\n-          << Common::Join(monotone_constraints_, \",\") << \"],\" << '\\n';\n+          << CommonC::Join(monotone_constraints_, \",\") << \"],\" << '\\n';\n \n   str_buf << \"\\\"feature_infos\\\":\" << \"{\";\n   bool first_obj = true;\n   for (size_t i = 0; i < feature_infos_.size(); ++i) {\n     std::stringstream json_str_buf;\n+    Common::C_stringstream(json_str_buf);\n     auto strs = Common::Split(feature_infos_[i].c_str(), \":\");\n     if (strs[0][0] == '[') {\n       strs[0].erase(0, 1);  // remove '['\n@@ -56,12 +58,12 @@ std::string GBDT::DumpModel(int start_iteration, int num_iteration, int feature_\n       json_str_buf << \"\\\"max_value\\\":\" << Common::AvoidInf(max_) << \",\";\n       json_str_buf << \"\\\"values\\\":[]}\";\n     } else if (strs[0] != \"none\") {  // categorical feature\n-      auto vals = Common::StringToArray<int>(feature_infos_[i], ':');\n+      auto vals = CommonC::StringToArray<int>(feature_infos_[i], ':');\n       auto max_idx = ArrayArgs<int>::ArgMax(vals);\n       auto min_idx = ArrayArgs<int>::ArgMin(vals);\n       json_str_buf << \"{\\\"min_value\\\":\" << vals[min_idx] << \",\";\n       json_str_buf << \"\\\"max_value\\\":\" << vals[max_idx] << \",\";\n-      json_str_buf << \"\\\"values\\\":[\" << Common::Join(vals, \",\") << \"]}\";\n+      json_str_buf << \"\\\"values\\\":[\" << CommonC::Join(vals, \",\") << \"]}\";\n     } else {  // unused feature\n       continue;\n     }\n@@ -121,6 +123,7 @@ std::string GBDT::DumpModel(int start_iteration, int num_iteration, int feature_\n \n std::string GBDT::ModelToIfElse(int num_iteration) const {\n   std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n \n   str_buf << \"#include \\\"gbdt.h\\\"\" << '\\n';\n   str_buf << \"#include <LightGBM/utils/common.h>\" << '\\n';\n@@ -155,6 +158,7 @@ std::string GBDT::ModelToIfElse(int num_iteration) const {\n   str_buf << \" };\" << '\\n' << '\\n';\n \n   std::stringstream pred_str_buf;\n+  Common::C_stringstream(pred_str_buf);\n \n   pred_str_buf << \"\\t\" << \"int early_stop_round_counter = 0;\" << '\\n';\n   pred_str_buf << \"\\t\" << \"std::memset(output, 0, sizeof(double) * num_tree_per_iteration_);\" << '\\n';\n@@ -186,6 +190,7 @@ std::string GBDT::ModelToIfElse(int num_iteration) const {\n   str_buf << \" };\" << '\\n' << '\\n';\n \n   std::stringstream pred_str_buf_map;\n+  Common::C_stringstream(pred_str_buf_map);\n \n   pred_str_buf_map << \"\\t\" << \"int early_stop_round_counter = 0;\" << '\\n';\n   pred_str_buf_map << \"\\t\" << \"std::memset(output, 0, sizeof(double) * num_tree_per_iteration_);\" << '\\n';\n@@ -305,6 +310,7 @@ bool GBDT::SaveModelToIfElse(int num_iteration, const char* filename) const {\n \n std::string GBDT::SaveModelToString(int start_iteration, int num_iteration, int feature_importance_type) const {\n   std::stringstream ss;\n+  Common::C_stringstream(ss);\n \n   // output model type\n   ss << SubModelName() << '\\n';\n@@ -325,14 +331,14 @@ std::string GBDT::SaveModelToString(int start_iteration, int num_iteration, int\n     ss << \"average_output\" << '\\n';\n   }\n \n-  ss << \"feature_names=\" << Common::Join(feature_names_, \" \") << '\\n';\n+  ss << \"feature_names=\" << CommonC::Join(feature_names_, \" \") << '\\n';\n \n   if (monotone_constraints_.size() != 0) {\n-    ss << \"monotone_constraints=\" << Common::Join(monotone_constraints_, \" \")\n+    ss << \"monotone_constraints=\" << CommonC::Join(monotone_constraints_, \" \")\n        << '\\n';\n   }\n \n-  ss << \"feature_infos=\" << Common::Join(feature_infos_, \" \") << '\\n';\n+  ss << \"feature_infos=\" << CommonC::Join(feature_infos_, \" \") << '\\n';\n \n   int num_used_model = static_cast<int>(models_.size());\n   int total_iteration = num_used_model / num_tree_per_iteration_;\n@@ -356,7 +362,7 @@ std::string GBDT::SaveModelToString(int start_iteration, int num_iteration, int\n     tree_sizes[idx] = tree_strs[idx].size();\n   }\n \n-  ss << \"tree_sizes=\" << Common::Join(tree_sizes, \" \") << '\\n';\n+  ss << \"tree_sizes=\" << CommonC::Join(tree_sizes, \" \") << '\\n';\n   ss << '\\n';\n \n   for (int i = 0; i < num_used_model - start_model; ++i) {\n@@ -491,7 +497,7 @@ bool GBDT::LoadModelFromString(const char* buffer, size_t len) {\n \n   // get monotone_constraints\n   if (key_vals.count(\"monotone_constraints\")) {\n-    monotone_constraints_ = Common::StringToArray<int8_t>(key_vals[\"monotone_constraints\"].c_str(), ' ');\n+    monotone_constraints_ = CommonC::StringToArray<int8_t>(key_vals[\"monotone_constraints\"].c_str(), ' ');\n     if (monotone_constraints_.size() != static_cast<size_t>(max_feature_idx_ + 1)) {\n       Log::Fatal(\"Wrong size of monotone_constraints\");\n       return false;\n@@ -533,7 +539,7 @@ bool GBDT::LoadModelFromString(const char* buffer, size_t len) {\n       p = Common::SkipNewLine(p);\n     }\n   } else {\n-    std::vector<size_t> tree_sizes = Common::StringToArray<size_t>(key_vals[\"tree_sizes\"].c_str(), ' ');\n+    std::vector<size_t> tree_sizes = CommonC::StringToArray<size_t>(key_vals[\"tree_sizes\"].c_str(), ' ');\n     std::vector<size_t> tree_boundries(tree_sizes.size() + 1, 0);\n     int num_trees = static_cast<int>(tree_sizes.size());\n     for (int i = 0; i < num_trees; ++i) {\n@@ -564,6 +570,7 @@ bool GBDT::LoadModelFromString(const char* buffer, size_t len) {\n   iter_ = 0;\n   bool is_inparameter = false;\n   std::stringstream ss;\n+  Common::C_stringstream(ss);\n   while (p < end) {\n     auto line_len = Common::GetLine(p);\n     if (line_len > 0) {\ndiff --git a/src/io/tree.cpp b/src/io/tree.cpp\nindex 92f016dfe6b0..a4e42831b0e7 100644\n--- a/src/io/tree.cpp\n+++ b/src/io/tree.cpp\n@@ -219,37 +219,45 @@ double Tree::GetLowerBoundValue() const {\n \n std::string Tree::ToString() const {\n   std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n+\n+  #if ((defined(sun) || defined(__sun)) && (defined(__SVR4) || defined(__svr4__)))\n+  using CommonLegacy::ArrayToString;  // Slower & unsafe regarding locale.\n+  #else\n+  using CommonC::ArrayToString;\n+  #endif\n+\n   str_buf << \"num_leaves=\" << num_leaves_ << '\\n';\n   str_buf << \"num_cat=\" << num_cat_ << '\\n';\n   str_buf << \"split_feature=\"\n-    << Common::ArrayToStringFast(split_feature_, num_leaves_ - 1) << '\\n';\n+    << ArrayToString(split_feature_, num_leaves_ - 1) << '\\n';\n   str_buf << \"split_gain=\"\n-    << Common::ArrayToStringFast(split_gain_, num_leaves_ - 1) << '\\n';\n+    << ArrayToString(split_gain_, num_leaves_ - 1) << '\\n';\n   str_buf << \"threshold=\"\n-    << Common::ArrayToString(threshold_, num_leaves_ - 1) << '\\n';\n+    << ArrayToString<true>(threshold_, num_leaves_ - 1) << '\\n';\n   str_buf << \"decision_type=\"\n-    << Common::ArrayToStringFast(Common::ArrayCast<int8_t, int>(decision_type_), num_leaves_ - 1) << '\\n';\n+    << ArrayToString(Common::ArrayCast<int8_t, int>(decision_type_), num_leaves_ - 1) << '\\n';\n   str_buf << \"left_child=\"\n-    << Common::ArrayToStringFast(left_child_, num_leaves_ - 1) << '\\n';\n+    << ArrayToString(left_child_, num_leaves_ - 1) << '\\n';\n   str_buf << \"right_child=\"\n-    << Common::ArrayToStringFast(right_child_, num_leaves_ - 1) << '\\n';\n+    << ArrayToString(right_child_, num_leaves_ - 1) << '\\n';\n   str_buf << \"leaf_value=\"\n-    << Common::ArrayToString(leaf_value_, num_leaves_) << '\\n';\n+    << ArrayToString<true>(leaf_value_, num_leaves_) << '\\n';\n   str_buf << \"leaf_weight=\"\n-    << Common::ArrayToString(leaf_weight_, num_leaves_) << '\\n';\n+    << ArrayToString<true>(leaf_weight_, num_leaves_) << '\\n';\n   str_buf << \"leaf_count=\"\n-    << Common::ArrayToStringFast(leaf_count_, num_leaves_) << '\\n';\n+    << ArrayToString(leaf_count_, num_leaves_) << '\\n';\n   str_buf << \"internal_value=\"\n-    << Common::ArrayToStringFast(internal_value_, num_leaves_ - 1) << '\\n';\n+    << ArrayToString(internal_value_, num_leaves_ - 1) << '\\n';\n   str_buf << \"internal_weight=\"\n-    << Common::ArrayToStringFast(internal_weight_, num_leaves_ - 1) << '\\n';\n+    << ArrayToString(internal_weight_, num_leaves_ - 1) << '\\n';\n   str_buf << \"internal_count=\"\n-    << Common::ArrayToStringFast(internal_count_, num_leaves_ - 1) << '\\n';\n+    << ArrayToString(internal_count_, num_leaves_ - 1) << '\\n';\n   if (num_cat_ > 0) {\n     str_buf << \"cat_boundaries=\"\n-      << Common::ArrayToStringFast(cat_boundaries_, num_cat_ + 1) << '\\n';\n+      << ArrayToString(cat_boundaries_, num_cat_ + 1) << '\\n';\n     str_buf << \"cat_threshold=\"\n-      << Common::ArrayToStringFast(cat_threshold_, cat_threshold_.size()) << '\\n';\n+      << ArrayToString(cat_threshold_, cat_threshold_.size()) << '\\n';\n   }\n   str_buf << \"shrinkage=\" << shrinkage_ << '\\n';\n   str_buf << '\\n';\n@@ -258,6 +266,7 @@ std::string Tree::ToString() const {\n \n std::string Tree::ToJSON() const {\n   std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n   str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);\n   str_buf << \"\\\"num_leaves\\\":\" << num_leaves_ << \",\" << '\\n';\n   str_buf << \"\\\"num_cat\\\":\" << num_cat_ << \",\" << '\\n';\n@@ -273,6 +282,7 @@ std::string Tree::ToJSON() const {\n \n std::string Tree::NodeToJSON(int index) const {\n   std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n   str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);\n   if (index >= 0) {\n     // non-leaf\n@@ -292,7 +302,7 @@ std::string Tree::NodeToJSON(int index) const {\n           }\n         }\n       }\n-      str_buf << \"\\\"threshold\\\":\\\"\" << Common::Join(cats, \"||\") << \"\\\",\" << '\\n';\n+      str_buf << \"\\\"threshold\\\":\\\"\" << CommonC::Join(cats, \"||\") << \"\\\",\" << '\\n';\n       str_buf << \"\\\"decision_type\\\":\\\"==\\\",\" << '\\n';\n     } else {\n       str_buf << \"\\\"threshold\\\":\" << Common::AvoidInf(threshold_[index]) << \",\" << '\\n';\n@@ -333,6 +343,7 @@ std::string Tree::NodeToJSON(int index) const {\n \n std::string Tree::NumericalDecisionIfElse(int node) const {\n   std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n   uint8_t missing_type = GetMissingType(decision_type_[node]);\n   bool default_left = GetDecisionType(decision_type_[node], kDefaultLeftMask);\n   if (missing_type == MissingType::None\n@@ -357,6 +368,7 @@ std::string Tree::NumericalDecisionIfElse(int node) const {\n std::string Tree::CategoricalDecisionIfElse(int node) const {\n   uint8_t missing_type = GetMissingType(decision_type_[node]);\n   std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n   if (missing_type == MissingType::NaN) {\n     str_buf << \"if (std::isnan(fval)) { int_fval = -1; } else { int_fval = static_cast<int>(fval); }\";\n   } else {\n@@ -372,6 +384,7 @@ std::string Tree::CategoricalDecisionIfElse(int node) const {\n \n std::string Tree::ToIfElse(int index, bool predict_leaf_index) const {\n   std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n   str_buf << \"double PredictTree\" << index;\n   if (predict_leaf_index) {\n     str_buf << \"Leaf\";\n@@ -430,6 +443,7 @@ std::string Tree::ToIfElse(int index, bool predict_leaf_index) const {\n \n std::string Tree::NodeToIfElse(int index, bool predict_leaf_index) const {\n   std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n   str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);\n   if (index >= 0) {\n     // non-leaf\n@@ -461,6 +475,7 @@ std::string Tree::NodeToIfElse(int index, bool predict_leaf_index) const {\n \n std::string Tree::NodeToIfElseByMap(int index, bool predict_leaf_index) const {\n   std::stringstream str_buf;\n+  Common::C_stringstream(str_buf);\n   str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);\n   if (index >= 0) {\n     // non-leaf\n@@ -523,13 +538,13 @@ Tree::Tree(const char* str, size_t* used_len) {\n   Common::Atoi(key_vals[\"num_cat\"].c_str(), &num_cat_);\n \n   if (key_vals.count(\"leaf_value\")) {\n-    leaf_value_ = Common::StringToArray<double>(key_vals[\"leaf_value\"], num_leaves_);\n+    leaf_value_ = CommonC::StringToArray<double>(key_vals[\"leaf_value\"], num_leaves_);\n   } else {\n     Log::Fatal(\"Tree model string format error, should contain leaf_value field\");\n   }\n \n   if (key_vals.count(\"shrinkage\")) {\n-    Common::Atof(key_vals[\"shrinkage\"].c_str(), &shrinkage_);\n+    CommonC::Atof(key_vals[\"shrinkage\"].c_str(), &shrinkage_);\n   } else {\n     shrinkage_ = 1.0f;\n   }\n@@ -537,80 +552,80 @@ Tree::Tree(const char* str, size_t* used_len) {\n   if (num_leaves_ <= 1) { return; }\n \n   if (key_vals.count(\"left_child\")) {\n-    left_child_ = Common::StringToArrayFast<int>(key_vals[\"left_child\"], num_leaves_ - 1);\n+    left_child_ = CommonC::StringToArrayFast<int>(key_vals[\"left_child\"], num_leaves_ - 1);\n   } else {\n     Log::Fatal(\"Tree model string format error, should contain left_child field\");\n   }\n \n   if (key_vals.count(\"right_child\")) {\n-    right_child_ = Common::StringToArrayFast<int>(key_vals[\"right_child\"], num_leaves_ - 1);\n+    right_child_ = CommonC::StringToArrayFast<int>(key_vals[\"right_child\"], num_leaves_ - 1);\n   } else {\n     Log::Fatal(\"Tree model string format error, should contain right_child field\");\n   }\n \n   if (key_vals.count(\"split_feature\")) {\n-    split_feature_ = Common::StringToArrayFast<int>(key_vals[\"split_feature\"], num_leaves_ - 1);\n+    split_feature_ = CommonC::StringToArrayFast<int>(key_vals[\"split_feature\"], num_leaves_ - 1);\n   } else {\n     Log::Fatal(\"Tree model string format error, should contain split_feature field\");\n   }\n \n   if (key_vals.count(\"threshold\")) {\n-    threshold_ = Common::StringToArray<double>(key_vals[\"threshold\"], num_leaves_ - 1);\n+    threshold_ = CommonC::StringToArray<double>(key_vals[\"threshold\"], num_leaves_ - 1);\n   } else {\n     Log::Fatal(\"Tree model string format error, should contain threshold field\");\n   }\n \n   if (key_vals.count(\"split_gain\")) {\n-    split_gain_ = Common::StringToArrayFast<float>(key_vals[\"split_gain\"], num_leaves_ - 1);\n+    split_gain_ = CommonC::StringToArrayFast<float>(key_vals[\"split_gain\"], num_leaves_ - 1);\n   } else {\n     split_gain_.resize(num_leaves_ - 1);\n   }\n \n   if (key_vals.count(\"internal_count\")) {\n-    internal_count_ = Common::StringToArrayFast<int>(key_vals[\"internal_count\"], num_leaves_ - 1);\n+    internal_count_ = CommonC::StringToArrayFast<int>(key_vals[\"internal_count\"], num_leaves_ - 1);\n   } else {\n     internal_count_.resize(num_leaves_ - 1);\n   }\n \n   if (key_vals.count(\"internal_value\")) {\n-    internal_value_ = Common::StringToArrayFast<double>(key_vals[\"internal_value\"], num_leaves_ - 1);\n+    internal_value_ = CommonC::StringToArrayFast<double>(key_vals[\"internal_value\"], num_leaves_ - 1);\n   } else {\n     internal_value_.resize(num_leaves_ - 1);\n   }\n \n   if (key_vals.count(\"internal_weight\")) {\n-    internal_weight_ = Common::StringToArrayFast<double>(key_vals[\"internal_weight\"], num_leaves_ - 1);\n+    internal_weight_ = CommonC::StringToArrayFast<double>(key_vals[\"internal_weight\"], num_leaves_ - 1);\n   } else {\n     internal_weight_.resize(num_leaves_ - 1);\n   }\n \n   if (key_vals.count(\"leaf_weight\")) {\n-    leaf_weight_ = Common::StringToArray<double>(key_vals[\"leaf_weight\"], num_leaves_);\n+    leaf_weight_ = CommonC::StringToArray<double>(key_vals[\"leaf_weight\"], num_leaves_);\n   } else {\n     leaf_weight_.resize(num_leaves_);\n   }\n \n   if (key_vals.count(\"leaf_count\")) {\n-    leaf_count_ = Common::StringToArrayFast<int>(key_vals[\"leaf_count\"], num_leaves_);\n+    leaf_count_ = CommonC::StringToArrayFast<int>(key_vals[\"leaf_count\"], num_leaves_);\n   } else {\n     leaf_count_.resize(num_leaves_);\n   }\n \n   if (key_vals.count(\"decision_type\")) {\n-    decision_type_ = Common::StringToArrayFast<int8_t>(key_vals[\"decision_type\"], num_leaves_ - 1);\n+    decision_type_ = CommonC::StringToArrayFast<int8_t>(key_vals[\"decision_type\"], num_leaves_ - 1);\n   } else {\n     decision_type_ = std::vector<int8_t>(num_leaves_ - 1, 0);\n   }\n \n   if (num_cat_ > 0) {\n     if (key_vals.count(\"cat_boundaries\")) {\n-      cat_boundaries_ = Common::StringToArrayFast<int>(key_vals[\"cat_boundaries\"], num_cat_ + 1);\n+      cat_boundaries_ = CommonC::StringToArrayFast<int>(key_vals[\"cat_boundaries\"], num_cat_ + 1);\n     } else {\n       Log::Fatal(\"Tree model should contain cat_boundaries field.\");\n     }\n \n     if (key_vals.count(\"cat_threshold\")) {\n-      cat_threshold_ = Common::StringToArrayFast<uint32_t>(key_vals[\"cat_threshold\"], cat_boundaries_.back());\n+      cat_threshold_ = CommonC::StringToArrayFast<uint32_t>(key_vals[\"cat_threshold\"], cat_boundaries_.back());\n     } else {\n       Log::Fatal(\"Tree model should contain cat_threshold field\");\n     }\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Integration Tests**: Ensure round-trip model read/write and score comparisons match `v3.0.0` for all locales. Test failures with non-C locales indicate discrepancies that need resolution.\n\n2. **CMake Issues**: Fix `CMakeLists.txt` to ensure `external_libs` are copied correctly. Modify `MANIFEST.in` to include necessary files from `fmt`.\n\n3. **Dependencies Compatibility**: Verify that new libraries are compatible with gcc 4.8.4 and ensure all required submodules are cloned or handled in `setup.py`.\n\n4. **Shared Library Flags**: Use `-fPIC` for `fmt` without enabling `BUILD_SHARED_LIBS`, to resolve linking errors.\n\n5. **Linting Issues**: Review import orders in the code to conform to linting standards.\n\n6. **Performance Testing**: Document and confirm observed improvements in model loading performance. Consider establishing benchmarks for large models."
      }
    ],
    "codediff_length": 46257
  },
  {
    "index": 5,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/python-package/lightgbm/basic.py b/python-package/lightgbm/basic.py\nindex c02b4642b58a..380c5d213124 100644\n--- a/python-package/lightgbm/basic.py\n+++ b/python-package/lightgbm/basic.py\n@@ -1628,7 +1628,7 @@ def __init__(self, params=None, train_set=None, model_file=None, model_str=None,\n         self.handle = None\n         self.network = False\n         self.__need_reload_eval_info = True\n-        self.__train_data_name = \"training\"\n+        self._train_data_name = \"training\"\n         self.__attr = {}\n         self.__set_objective_to_none = False\n         self.best_iteration = -1\n@@ -1817,7 +1817,7 @@ def set_train_data_name(self, name):\n         self : Booster\n             Booster with set training Dataset name.\n         \"\"\"\n-        self.__train_data_name = name\n+        self._train_data_name = name\n         return self\n \n     def add_valid(self, data, name):\n@@ -2044,7 +2044,7 @@ def eval(self, data, name, feval=None):\n                 eval_data : Dataset\n                     The evaluation dataset.\n                 eval_name : string\n-                    The name of evaluation function.\n+                    The name of evaluation function (without whitespaces).\n                 eval_result : float\n                     The eval result.\n                 is_higher_better : bool\n@@ -2090,7 +2090,7 @@ def eval_train(self, feval=None):\n                 train_data : Dataset\n                     The training dataset.\n                 eval_name : string\n-                    The name of evaluation function.\n+                    The name of evaluation function (without whitespaces).\n                 eval_result : float\n                     The eval result.\n                 is_higher_better : bool\n@@ -2104,7 +2104,7 @@ def eval_train(self, feval=None):\n         result : list\n             List with evaluation results.\n         \"\"\"\n-        return self.__inner_eval(self.__train_data_name, 0, feval)\n+        return self.__inner_eval(self._train_data_name, 0, feval)\n \n     def eval_valid(self, feval=None):\n         \"\"\"Evaluate for validation data.\n@@ -2121,7 +2121,7 @@ def eval_valid(self, feval=None):\n                 valid_data : Dataset\n                     The validation dataset.\n                 eval_name : string\n-                    The name of evaluation function.\n+                    The name of evaluation function (without whitespaces).\n                 eval_result : float\n                     The eval result.\n                 is_higher_better : bool\ndiff --git a/python-package/lightgbm/callback.py b/python-package/lightgbm/callback.py\nindex 0af06540dd30..071988e0f841 100644\n--- a/python-package/lightgbm/callback.py\n+++ b/python-package/lightgbm/callback.py\n@@ -89,12 +89,13 @@ def record_evaluation(eval_result):\n         The callback that records the evaluation history into the passed dictionary.\n     \"\"\"\n     if not isinstance(eval_result, dict):\n-        raise TypeError('Eval_result should be a dictionary')\n+        raise TypeError('eval_result should be a dictionary')\n     eval_result.clear()\n \n     def _init(env):\n-        for data_name, _, _, _ in env.evaluation_result_list:\n-            eval_result.setdefault(data_name, collections.defaultdict(list))\n+        for data_name, eval_name, _, _ in env.evaluation_result_list:\n+            eval_result.setdefault(data_name, collections.OrderedDict())\n+            eval_result[data_name].setdefault(eval_name, [])\n \n     def _callback(env):\n         if not eval_result:\n@@ -132,7 +133,7 @@ def _callback(env):\n             if key in ['num_class', 'num_classes',\n                        'boosting', 'boost', 'boosting_type',\n                        'metric', 'metrics', 'metric_types']:\n-                raise RuntimeError(\"cannot reset {} during training\".format(repr(key)))\n+                raise RuntimeError(\"Cannot reset {} during training\".format(repr(key)))\n             if isinstance(value, list):\n                 if len(value) != env.end_iteration - env.begin_iteration:\n                     raise ValueError(\"Length of list {} has to equal to 'num_boost_round'.\"\n@@ -182,6 +183,7 @@ def early_stopping(stopping_rounds, first_metric_only=False, verbose=True):\n     best_score_list = []\n     cmp_op = []\n     enabled = [True]\n+    first_metric = ['']\n \n     def _init(env):\n         enabled[0] = not any((boost_alias in env.params\n@@ -196,9 +198,11 @@ def _init(env):\n                              'at least one dataset and eval metric is required for evaluation')\n \n         if verbose:\n-            msg = \"Training until validation scores don't improve for {} rounds.\"\n+            msg = \"Training until validation scores don't improve for {} rounds\"\n             print(msg.format(stopping_rounds))\n \n+        # split is needed for \"<dataset type> <metric>\" case (e.g. \"train l1\")\n+        first_metric[0] = env.evaluation_result_list[0][1].split(\" \")[-1]\n         for eval_ret in env.evaluation_result_list:\n             best_iter.append(0)\n             best_score_list.append(None)\n@@ -209,6 +213,15 @@ def _init(env):\n                 best_score.append(float('inf'))\n                 cmp_op.append(lt)\n \n+    def _final_iteration_check(env, eval_name_splitted, i):\n+        if env.iteration == env.end_iteration - 1:\n+            if verbose:\n+                print('Did not meet early stopping. Best iteration is:\\n[%d]\\t%s' % (\n+                    best_iter[i] + 1, '\\t'.join([_format_eval_result(x) for x in best_score_list[i]])))\n+                if first_metric_only:\n+                    print(\"Evaluated only: {}\".format(eval_name_splitted[-1]))\n+            raise EarlyStopException(best_iter[i], best_score_list[i])\n+\n     def _callback(env):\n         if not cmp_op:\n             _init(env)\n@@ -220,17 +233,21 @@ def _callback(env):\n                 best_score[i] = score\n                 best_iter[i] = env.iteration\n                 best_score_list[i] = env.evaluation_result_list\n+            # split is needed for \"<dataset type> <metric>\" case (e.g. \"train l1\")\n+            eval_name_splitted = env.evaluation_result_list[i][1].split(\" \")\n+            if first_metric_only and first_metric[0] != eval_name_splitted[-1]:\n+                continue  # use only the first metric for early stopping\n+            if ((env.evaluation_result_list[i][0] == \"cv_agg\" and eval_name_splitted[0] == \"train\"\n+                 or env.evaluation_result_list[i][0] == env.model._train_data_name)):\n+                _final_iteration_check(env, eval_name_splitted, i)\n+                continue  # train data for lgb.cv or sklearn wrapper (underlying lgb.train)\n             elif env.iteration - best_iter[i] >= stopping_rounds:\n                 if verbose:\n                     print('Early stopping, best iteration is:\\n[%d]\\t%s' % (\n                         best_iter[i] + 1, '\\t'.join([_format_eval_result(x) for x in best_score_list[i]])))\n+                    if first_metric_only:\n+                        print(\"Evaluated only: {}\".format(eval_name_splitted[-1]))\n                 raise EarlyStopException(best_iter[i], best_score_list[i])\n-            if env.iteration == env.end_iteration - 1:\n-                if verbose:\n-                    print('Did not meet early stopping. Best iteration is:\\n[%d]\\t%s' % (\n-                        best_iter[i] + 1, '\\t'.join([_format_eval_result(x) for x in best_score_list[i]])))\n-                raise EarlyStopException(best_iter[i], best_score_list[i])\n-            if first_metric_only:  # the only first metric is used for early stopping\n-                break\n+            _final_iteration_check(env, eval_name_splitted, i)\n     _callback.order = 30\n     return _callback\ndiff --git a/python-package/lightgbm/engine.py b/python-package/lightgbm/engine.py\nindex 5135d83ffc8c..2eb0acf591ad 100644\n--- a/python-package/lightgbm/engine.py\n+++ b/python-package/lightgbm/engine.py\n@@ -65,7 +65,7 @@ def train(params, train_set, num_boost_round=100,\n             train_data : Dataset\n                 The training dataset.\n             eval_name : string\n-                The name of evaluation function.\n+                The name of evaluation function (without whitespaces).\n             eval_result : float\n                 The eval result.\n             is_higher_better : bool\n@@ -266,7 +266,7 @@ def train(params, train_set, num_boost_round=100,\n             booster.best_iteration = earlyStopException.best_iteration + 1\n             evaluation_result_list = earlyStopException.best_score\n             break\n-    booster.best_score = collections.defaultdict(dict)\n+    booster.best_score = collections.defaultdict(collections.OrderedDict)\n     for dataset_name, eval_name, score, _ in evaluation_result_list:\n         booster.best_score[dataset_name][eval_name] = score\n     if not keep_training_booster:\n@@ -356,7 +356,7 @@ def _make_n_folds(full_data, folds, nfold, params, seed, fpreproc=None, stratifi\n \n def _agg_cv_result(raw_results, eval_train_metric=False):\n     \"\"\"Aggregate cross-validation results.\"\"\"\n-    cvmap = collections.defaultdict(list)\n+    cvmap = collections.OrderedDict()\n     metric_type = {}\n     for one_result in raw_results:\n         for one_line in one_result:\n@@ -365,6 +365,7 @@ def _agg_cv_result(raw_results, eval_train_metric=False):\n             else:\n                 key = one_line[1]\n             metric_type[key] = one_line[3]\n+            cvmap.setdefault(key, [])\n             cvmap[key].append(one_line[2])\n     return [('cv_agg', k, np.mean(v), metric_type[k], np.std(v)) for k, v in cvmap.items()]\n \n@@ -429,7 +430,7 @@ def cv(params, train_set, num_boost_round=100,\n             train_data : Dataset\n                 The training dataset.\n             eval_name : string\n-                The name of evaluation function.\n+                The name of evaluation function (without whitespaces).\n             eval_result : float\n                 The eval result.\n             is_higher_better : bool\ndiff --git a/python-package/lightgbm/sklearn.py b/python-package/lightgbm/sklearn.py\nindex a60e661c19c8..b7e667df1b15 100644\n--- a/python-package/lightgbm/sklearn.py\n+++ b/python-package/lightgbm/sklearn.py\n@@ -121,7 +121,7 @@ def __init__(self, func):\n                 group : array-like\n                     Group/query data, used for ranking task.\n                 eval_name : string\n-                    The name of evaluation function.\n+                    The name of evaluation function (without whitespaces).\n                 eval_result : float\n                     The eval result.\n                 is_higher_better : bool\n@@ -147,7 +147,7 @@ def __call__(self, preds, dataset):\n         Returns\n         -------\n         eval_name : string\n-            The name of evaluation function.\n+            The name of evaluation function (without whitespaces).\n         eval_result : float\n             The eval result.\n         is_higher_better : bool\n@@ -464,7 +464,7 @@ def fit(self, X, y,\n             group : array-like\n                 Group/query data, used for ranking task.\n             eval_name : string\n-                The name of evaluation function.\n+                The name of evaluation function (without whitespaces).\n             eval_result : float\n                 The eval result.\n             is_higher_better : bool\n@@ -524,7 +524,8 @@ def fit(self, X, y,\n             # concatenate metric from params (or default if not provided in params) and eval_metric\n             original_metric = [original_metric] if isinstance(original_metric, (string_type, type(None))) else original_metric\n             eval_metric = [eval_metric] if isinstance(eval_metric, (string_type, type(None))) else eval_metric\n-            params['metric'] = set(original_metric + eval_metric)\n+            params['metric'] = [e for e in eval_metric if e not in original_metric] + original_metric\n+            params['metric'] = [metric for metric in params['metric'] if metric is not None]\n \n         if not isinstance(X, (DataFrame, DataTable)):\n             _X, _y = _LGBMCheckXY(X, y, accept_sparse=True, force_all_finite=False, ensure_min_samples=2)\ndiff --git a/tests/python_package_test/test_engine.py b/tests/python_package_test/test_engine.py\nindex 63f1468132a5..539b6f10834f 100644\n--- a/tests/python_package_test/test_engine.py\n+++ b/tests/python_package_test/test_engine.py\n@@ -494,10 +494,8 @@ def test_continue_train_dart(self):\n                         evals_result=evals_result,\n                         init_model=init_gbm)\n         ret = mean_absolute_error(y_test, gbm.predict(X_test))\n-        self.assertLess(ret, 3.5)\n+        self.assertLess(ret, 2.5)\n         self.assertAlmostEqual(evals_result['valid_0']['l1'][-1], ret, places=5)\n-        for l1, mae in zip(evals_result['valid_0']['l1'], evals_result['valid_0']['mae']):\n-            self.assertAlmostEqual(l1, mae, places=5)\n \n     def test_continue_train_multiclass(self):\n         X, y = load_iris(True)\n@@ -1545,17 +1543,6 @@ def test_get_split_value_histogram(self):\n         self.assertRaises(lgb.basic.LightGBMError, gbm.get_split_value_histogram, 2)\n \n     def test_early_stopping_for_only_first_metric(self):\n-        X, y = load_boston(True)\n-        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n-        params = {\n-            'objective': 'regression',\n-            'metric': 'None',\n-            'verbose': -1\n-        }\n-        lgb_train = lgb.Dataset(X_train, y_train)\n-        lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n-\n-        decreasing_generator = itertools.count(0, -1)\n \n         def decreasing_metric(preds, train_data):\n             return ('decreasing_metric', next(decreasing_generator), False)\n@@ -1563,27 +1550,117 @@ def decreasing_metric(preds, train_data):\n         def constant_metric(preds, train_data):\n             return ('constant_metric', 0.0, False)\n \n-        # test that all metrics are checked (default behaviour)\n-        gbm = lgb.train(params, lgb_train, num_boost_round=20, valid_sets=[lgb_eval],\n-                        feval=lambda preds, train_data: [decreasing_metric(preds, train_data),\n-                                                         constant_metric(preds, train_data)],\n-                        early_stopping_rounds=5, verbose_eval=False)\n-        self.assertEqual(gbm.best_iteration, 1)\n-\n-        # test that only the first metric is checked\n-        gbm = lgb.train(dict(params, first_metric_only=True), lgb_train,\n-                        num_boost_round=20, valid_sets=[lgb_eval],\n-                        feval=lambda preds, train_data: [decreasing_metric(preds, train_data),\n-                                                         constant_metric(preds, train_data)],\n-                        early_stopping_rounds=5, verbose_eval=False)\n-        self.assertEqual(gbm.best_iteration, 20)\n-        # ... change the order of metrics\n-        gbm = lgb.train(dict(params, first_metric_only=True), lgb_train,\n-                        num_boost_round=20, valid_sets=[lgb_eval],\n-                        feval=lambda preds, train_data: [constant_metric(preds, train_data),\n-                                                         decreasing_metric(preds, train_data)],\n-                        early_stopping_rounds=5, verbose_eval=False)\n-        self.assertEqual(gbm.best_iteration, 1)\n+        def metrics_combination_train_regression(valid_sets, metric_list, assumed_iteration,\n+                                                 first_metric_only, feval=None):\n+            params = {\n+                'objective': 'regression',\n+                'learning_rate': 1.1,\n+                'num_leaves': 10,\n+                'metric': metric_list,\n+                'verbose': -1,\n+                'seed': 123\n+            }\n+            gbm = lgb.train(dict(params, first_metric_only=first_metric_only), lgb_train,\n+                            num_boost_round=25, valid_sets=valid_sets, feval=feval,\n+                            early_stopping_rounds=5, verbose_eval=False)\n+            self.assertEqual(assumed_iteration, gbm.best_iteration)\n+\n+        def metrics_combination_cv_regression(metric_list, assumed_iteration,\n+                                              first_metric_only, eval_train_metric, feval=None):\n+            params = {\n+                'objective': 'regression',\n+                'learning_rate': 0.9,\n+                'num_leaves': 10,\n+                'metric': metric_list,\n+                'verbose': -1,\n+                'seed': 123,\n+                'gpu_use_dp': True\n+            }\n+            ret = lgb.cv(dict(params, first_metric_only=first_metric_only),\n+                         train_set=lgb_train, num_boost_round=25,\n+                         stratified=False, feval=feval,\n+                         early_stopping_rounds=5, verbose_eval=False,\n+                         eval_train_metric=eval_train_metric)\n+            self.assertEqual(assumed_iteration, len(ret[list(ret.keys())[0]]))\n+\n+        decreasing_generator = itertools.count(0, -1)\n+        X, y = load_boston(True)\n+        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n+        X_test1, X_test2, y_test1, y_test2 = train_test_split(X_test, y_test, test_size=0.5, random_state=73)\n+        lgb_train = lgb.Dataset(X_train, y_train)\n+        lgb_valid1 = lgb.Dataset(X_test1, y_test1, reference=lgb_train)\n+        lgb_valid2 = lgb.Dataset(X_test2, y_test2, reference=lgb_train)\n+\n+        iter_valid1_l1 = 3\n+        iter_valid1_l2 = 14\n+        iter_valid2_l1 = 2\n+        iter_valid2_l2 = 15\n+        self.assertEqual(len(set([iter_valid1_l1, iter_valid1_l2, iter_valid2_l1, iter_valid2_l2])), 4)\n+        iter_min_l1 = min([iter_valid1_l1, iter_valid2_l1])\n+        iter_min_l2 = min([iter_valid1_l2, iter_valid2_l2])\n+        iter_min = min([iter_min_l1, iter_min_l2])\n+        iter_min_valid1 = min([iter_valid1_l1, iter_valid1_l2])\n+\n+        iter_cv_l1 = 3\n+        iter_cv_l2 = 17\n+        self.assertEqual(len(set([iter_cv_l1, iter_cv_l2])), 2)\n+        iter_cv_min = min([iter_cv_l1, iter_cv_l2])\n+\n+        # test for lgb.train\n+        metrics_combination_train_regression(lgb_valid1, [], iter_valid1_l2, False)\n+        metrics_combination_train_regression(lgb_valid1, [], iter_valid1_l2, True)\n+        metrics_combination_train_regression(lgb_valid1, None, iter_valid1_l2, False)\n+        metrics_combination_train_regression(lgb_valid1, None, iter_valid1_l2, True)\n+        metrics_combination_train_regression(lgb_valid1, 'l2', iter_valid1_l2, True)\n+        metrics_combination_train_regression(lgb_valid1, 'l1', iter_valid1_l1, True)\n+        metrics_combination_train_regression(lgb_valid1, ['l2', 'l1'], iter_valid1_l2, True)\n+        metrics_combination_train_regression(lgb_valid1, ['l1', 'l2'], iter_valid1_l1, True)\n+        metrics_combination_train_regression(lgb_valid1, ['l2', 'l1'], iter_min_valid1, False)\n+        metrics_combination_train_regression(lgb_valid1, ['l1', 'l2'], iter_min_valid1, False)\n+\n+        # test feval for lgb.train\n+        metrics_combination_train_regression(lgb_valid1, 'None', 1, False,\n+                                             feval=lambda preds, train_data: [decreasing_metric(preds, train_data),\n+                                                                              constant_metric(preds, train_data)])\n+        metrics_combination_train_regression(lgb_valid1, 'None', 25, True,\n+                                             feval=lambda preds, train_data: [decreasing_metric(preds, train_data),\n+                                                                              constant_metric(preds, train_data)])\n+        metrics_combination_train_regression(lgb_valid1, 'None', 1, True,\n+                                             feval=lambda preds, train_data: [constant_metric(preds, train_data),\n+                                                                              decreasing_metric(preds, train_data)])\n+\n+        # test with two valid data for lgb.train\n+        metrics_combination_train_regression([lgb_valid1, lgb_valid2], ['l2', 'l1'], iter_min_l2, True)\n+        metrics_combination_train_regression([lgb_valid2, lgb_valid1], ['l2', 'l1'], iter_min_l2, True)\n+        metrics_combination_train_regression([lgb_valid1, lgb_valid2], ['l1', 'l2'], iter_min_l1, True)\n+        metrics_combination_train_regression([lgb_valid2, lgb_valid1], ['l1', 'l2'], iter_min_l1, True)\n+\n+        # test for lgb.cv\n+        metrics_combination_cv_regression(None, iter_cv_l2, True, False)\n+        metrics_combination_cv_regression('l2', iter_cv_l2, True, False)\n+        metrics_combination_cv_regression('l1', iter_cv_l1, True, False)\n+        metrics_combination_cv_regression(['l2', 'l1'], iter_cv_l2, True, False)\n+        metrics_combination_cv_regression(['l1', 'l2'], iter_cv_l1, True, False)\n+        metrics_combination_cv_regression(['l2', 'l1'], iter_cv_min, False, False)\n+        metrics_combination_cv_regression(['l1', 'l2'], iter_cv_min, False, False)\n+        metrics_combination_cv_regression(None, iter_cv_l2, True, True)\n+        metrics_combination_cv_regression('l2', iter_cv_l2, True, True)\n+        metrics_combination_cv_regression('l1', iter_cv_l1, True, True)\n+        metrics_combination_cv_regression(['l2', 'l1'], iter_cv_l2, True, True)\n+        metrics_combination_cv_regression(['l1', 'l2'], iter_cv_l1, True, True)\n+        metrics_combination_cv_regression(['l2', 'l1'], iter_cv_min, False, True)\n+        metrics_combination_cv_regression(['l1', 'l2'], iter_cv_min, False, True)\n+\n+        # test feval for lgb.cv\n+        metrics_combination_cv_regression('None', 1, False, False,\n+                                          feval=lambda preds, train_data: [decreasing_metric(preds, train_data),\n+                                                                           constant_metric(preds, train_data)])\n+        metrics_combination_cv_regression('None', 25, True, False,\n+                                          feval=lambda preds, train_data: [decreasing_metric(preds, train_data),\n+                                                                           constant_metric(preds, train_data)])\n+        metrics_combination_cv_regression('None', 1, True, False,\n+                                          feval=lambda preds, train_data: [constant_metric(preds, train_data),\n+                                                                           decreasing_metric(preds, train_data)])\n \n     def test_node_level_subcol(self):\n         X, y = load_breast_cancer(True)\ndiff --git a/tests/python_package_test/test_sklearn.py b/tests/python_package_test/test_sklearn.py\nindex 39e8447fd072..a0ef09b881d5 100644\n--- a/tests/python_package_test/test_sklearn.py\n+++ b/tests/python_package_test/test_sklearn.py\n@@ -638,6 +638,113 @@ def test_nan_handle(self):\n         gbm = lgb.LGBMRegressor(**params).fit(**params_fit)\n         np.testing.assert_allclose(gbm.evals_result_['training']['l2'], np.nan)\n \n+    def test_first_metric_only(self):\n+\n+        def decreasing_metric(y_true, y_pred):\n+            return ('decreasing_metric', next(decreasing_generator), False)\n+\n+        def constant_metric(y_true, y_pred):\n+            return ('constant_metric', 0.0, False)\n+\n+        def fit_and_check(eval_set_names, metric_names, assumed_iteration, first_metric_only):\n+            params['first_metric_only'] = first_metric_only\n+            gbm = lgb.LGBMRegressor(**params).fit(**params_fit)\n+            self.assertEqual(len(gbm.evals_result_), len(eval_set_names))\n+            for eval_set_name in eval_set_names:\n+                self.assertIn(eval_set_name, gbm.evals_result_)\n+                self.assertEqual(len(gbm.evals_result_[eval_set_name]), len(metric_names))\n+                for metric_name in metric_names:\n+                    self.assertIn(metric_name, gbm.evals_result_[eval_set_name])\n+\n+                    actual = len(gbm.evals_result_[eval_set_name][metric_name])\n+                    expected = assumed_iteration + (params_fit['early_stopping_rounds']\n+                                                    if eval_set_name != 'training'\n+                                                    and assumed_iteration != gbm.n_estimators else 0)\n+                    self.assertEqual(expected, actual)\n+                    self.assertEqual(assumed_iteration if eval_set_name != 'training' else params['n_estimators'],\n+                                     gbm.best_iteration_)\n+\n+        decreasing_generator = itertools.count(0, -1)\n+        X, y = load_boston(True)\n+        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n+        X_test1, X_test2, y_test1, y_test2 = train_test_split(X_test, y_test, test_size=0.5, random_state=72)\n+        params = {'n_estimators': 30,\n+                  'learning_rate': 0.8,\n+                  'num_leaves': 15,\n+                  'verbose': -1,\n+                  'seed': 123}\n+        params_fit = {'X': X_train,\n+                      'y': y_train,\n+                      'early_stopping_rounds': 5,\n+                      'verbose': False}\n+\n+        iter_valid1_l1 = 3\n+        iter_valid1_l2 = 18\n+        iter_valid2_l1 = 11\n+        iter_valid2_l2 = 7\n+        self.assertEqual(len(set([iter_valid1_l1, iter_valid1_l2, iter_valid2_l1, iter_valid2_l2])), 4)\n+        iter_min_l1 = min([iter_valid1_l1, iter_valid2_l1])\n+        iter_min_l2 = min([iter_valid1_l2, iter_valid2_l2])\n+        iter_min = min([iter_min_l1, iter_min_l2])\n+        iter_min_valid1 = min([iter_valid1_l1, iter_valid1_l2])\n+\n+        # training data as eval_set\n+        params_fit['eval_set'] = (X_train, y_train)\n+        fit_and_check(['training'], ['l2'], 30, False)\n+        fit_and_check(['training'], ['l2'], 30, True)\n+\n+        # feval\n+        params['metric'] = 'None'\n+        params_fit['eval_metric'] = lambda preds, train_data: [decreasing_metric(preds, train_data),\n+                                                               constant_metric(preds, train_data)]\n+        params_fit['eval_set'] = (X_test1, y_test1)\n+        fit_and_check(['valid_0'], ['decreasing_metric', 'constant_metric'], 1, False)\n+        fit_and_check(['valid_0'], ['decreasing_metric', 'constant_metric'], 30, True)\n+        params_fit['eval_metric'] = lambda preds, train_data: [constant_metric(preds, train_data),\n+                                                               decreasing_metric(preds, train_data)]\n+        fit_and_check(['valid_0'], ['decreasing_metric', 'constant_metric'], 1, True)\n+\n+        # single eval_set\n+        params.pop('metric')\n+        params_fit.pop('eval_metric')\n+        fit_and_check(['valid_0'], ['l2'], iter_valid1_l2, False)\n+        fit_and_check(['valid_0'], ['l2'], iter_valid1_l2, True)\n+\n+        params_fit['eval_metric'] = \"l2\"\n+        fit_and_check(['valid_0'], ['l2'], iter_valid1_l2, False)\n+        fit_and_check(['valid_0'], ['l2'], iter_valid1_l2, True)\n+\n+        params_fit['eval_metric'] = \"l1\"\n+        fit_and_check(['valid_0'], ['l1', 'l2'], iter_min_valid1, False)\n+        fit_and_check(['valid_0'], ['l1', 'l2'], iter_valid1_l1, True)\n+\n+        params_fit['eval_metric'] = [\"l1\", \"l2\"]\n+        fit_and_check(['valid_0'], ['l1', 'l2'], iter_min_valid1, False)\n+        fit_and_check(['valid_0'], ['l1', 'l2'], iter_valid1_l1, True)\n+\n+        params_fit['eval_metric'] = [\"l2\", \"l1\"]\n+        fit_and_check(['valid_0'], ['l1', 'l2'], iter_min_valid1, False)\n+        fit_and_check(['valid_0'], ['l1', 'l2'], iter_valid1_l2, True)\n+\n+        params_fit['eval_metric'] = [\"l2\", \"regression\", \"mse\"]  # test aliases\n+        fit_and_check(['valid_0'], ['l2'], iter_valid1_l2, False)\n+        fit_and_check(['valid_0'], ['l2'], iter_valid1_l2, True)\n+\n+        # two eval_set\n+        params_fit['eval_set'] = [(X_test1, y_test1), (X_test2, y_test2)]\n+        params_fit['eval_metric'] = [\"l1\", \"l2\"]\n+        fit_and_check(['valid_0', 'valid_1'], ['l1', 'l2'], iter_min_l1, True)\n+        params_fit['eval_metric'] = [\"l2\", \"l1\"]\n+        fit_and_check(['valid_0', 'valid_1'], ['l1', 'l2'], iter_min_l2, True)\n+\n+        params_fit['eval_set'] = [(X_test2, y_test2), (X_test1, y_test1)]\n+        params_fit['eval_metric'] = [\"l1\", \"l2\"]\n+        fit_and_check(['valid_0', 'valid_1'], ['l1', 'l2'], iter_min, False)\n+        fit_and_check(['valid_0', 'valid_1'], ['l1', 'l2'], iter_min_l1, True)\n+        params_fit['eval_metric'] = [\"l2\", \"l1\"]\n+        fit_and_check(['valid_0', 'valid_1'], ['l1', 'l2'], iter_min, False)\n+        fit_and_check(['valid_0', 'valid_1'], ['l1', 'l2'], iter_min_l2, True)\n+\n     def test_class_weight(self):\n         X, y = load_digits(10, True)\n         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Relax `num_boost_round` to 25, applicable for all checks. Ensure \"Allow edits from maintainers\" is enabled.\n\n2. Replace all instances of `params['metric']` with `params_fit['eval_metric']`, and update callbacks with `params['first_metric_only']` and `params_fit['early_stopping_rounds'] = 5` in `test_sklearn.py`.\n\n3. The `first_metric_only` flag is causing early stopping to malfunction; ensure to add tests that capture this behavior.\n\n4. Investigate and address the CI error related to SSL when accessing URLs in tests.\n\n5. Reduce the number of tests for the sklearn wrapper, as the current quantity is excessive.\n\n6. Adjust test assertions in the sklearn tests to avoid failures related to early stopping behavior."
      }
    ],
    "codediff_length": 28836
  },
  {
    "index": 6,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.appveyor.yml b/.appveyor.yml\nindex 20807e36e6f5..2ad8f641e426 100644\n--- a/.appveyor.yml\n+++ b/.appveyor.yml\n@@ -9,6 +9,9 @@ environment:\n   matrix:\n     - COMPILER: MINGW\n       TASK: r-package\n+    - COMPILER: MSVC\n+      TASK: r-package\n+      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2019\n     - COMPILER: MSVC\n       TASK: python\n     - COMPILER: MINGW\ndiff --git a/.ci/test_r_package_windows.ps1 b/.ci/test_r_package_windows.ps1\nindex 5bd65d28408b..966cc3dc0e91 100644\n--- a/.ci/test_r_package_windows.ps1\n+++ b/.ci/test_r_package_windows.ps1\n@@ -14,6 +14,7 @@ function Download-File-With-Retries {\n \n $env:R_WINDOWS_VERSION = \"3.6.3\"\n $env:R_LIB_PATH = \"$env:BUILD_SOURCESDIRECTORY/RLibrary\" -replace '[\\\\]', '/'\n+$env:R_LIBS = \"$env:R_LIB_PATH\"\n $env:PATH = \"$env:R_LIB_PATH/Rtools/bin;\" + \"$env:R_LIB_PATH/R/bin/x64;\" + \"$env:R_LIB_PATH/miktex/texmfs/install/miktex/bin/x64;\" + $env:PATH\n $env:CRAN_MIRROR = \"https://cloud.r-project.org/\"\n $env:CTAN_MIRROR = \"https://ctan.math.illinois.edu/systems/win32/miktex/tm/packages/\"\n@@ -64,45 +65,65 @@ if ($env:COMPILER -eq \"MINGW\") {\n     conda install -q -y --no-deps pandoc\n }\n \n-Add-Content .Renviron \"R_LIBS=$env:R_LIB_PATH\"\n-\n Write-Output \"Installing dependencies\"\n-$packages = \"c('data.table', 'jsonlite', 'Matrix', 'R6', 'testthat'), dependencies = c('Imports', 'Depends', 'LinkingTo')\"\n+$packages = \"c('data.table', 'jsonlite', 'Matrix', 'processx', 'R6', 'testthat'), dependencies = c('Imports', 'Depends', 'LinkingTo')\"\n Rscript --vanilla -e \"options(install.packages.check.source = 'no'); install.packages($packages, repos = '$env:CRAN_MIRROR', type = 'binary', lib = '$env:R_LIB_PATH')\" ; Check-Output $?\n \n Write-Output \"Building R package\"\n-Rscript build_r.R --skip-install ; Check-Output $?\n \n-$PKG_FILE_NAME = Get-Item *.tar.gz\n-$LOG_FILE_NAME = \"lightgbm.Rcheck/00check.log\"\n+# R CMD check is not used for MSVC builds\n+if ($env:COMPILER -ne \"MSVC\") {\n+  Rscript build_r.R --skip-install ; Check-Output $?\n \n-$env:_R_CHECK_FORCE_SUGGESTS_ = 0\n-if ($env:COMPILER -ne \"MINGW\") {\n-  Write-Output \"Running R CMD check without checking documentation\"\n-  R.exe CMD check --no-multiarch --no-examples --no-manual --ignore-vignettes ${PKG_FILE_NAME} ; $check_succeeded = $?\n-} else {\n+  $PKG_FILE_NAME = Get-Item *.tar.gz\n+  $LOG_FILE_NAME = \"lightgbm.Rcheck/00check.log\"\n+\n+  $env:_R_CHECK_FORCE_SUGGESTS_ = 0\n   Write-Output \"Running R CMD check as CRAN\"\n   R.exe CMD check --no-multiarch --as-cran ${PKG_FILE_NAME} ; $check_succeeded = $?\n-}\n \n-Write-Output \"R CMD check build logs:\"\n-Get-Content -Path $env:BUILD_SOURCESDIRECTORY\\lightgbm.Rcheck\\00install.out\n-\n-Check-Output $check_succeeded\n+  Write-Output \"R CMD check build logs:\"\n+  $INSTALL_LOG_FILE_NAME = \"$env:BUILD_SOURCESDIRECTORY\\lightgbm.Rcheck\\00install.out\"\n+  Get-Content -Path \"$INSTALL_LOG_FILE_NAME\"\n+\n+  Check-Output $check_succeeded\n+\n+  Write-Output \"Looking for issues with R CMD check results\"\n+  if (Get-Content \"$LOG_FILE_NAME\" | Select-String -Pattern \"WARNING\" -Quiet) {\n+      echo \"WARNINGS have been found by R CMD check!\"\n+      Check-Output $False\n+  }\n+\n+  $note_str = Get-Content \"${LOG_FILE_NAME}\" | Select-String -Pattern ' NOTE' | Out-String ; Check-Output $?\n+  $relevant_line = $note_str -match '.*Status: (\\d+) NOTE.*'\n+  $NUM_CHECK_NOTES = $matches[1]\n+  $ALLOWED_CHECK_NOTES = 3\n+  if ([int]$NUM_CHECK_NOTES -gt $ALLOWED_CHECK_NOTES) {\n+      Write-Output \"Found ${NUM_CHECK_NOTES} NOTEs from R CMD check. Only ${ALLOWED_CHECK_NOTES} are allowed\"\n+      Check-Output $False\n+  }\n+} else {\n+  $INSTALL_LOG_FILE_NAME = \"$env:BUILD_SOURCESDIRECTORY\\00install_out.txt\"\n+  Rscript build_r.R *> $INSTALL_LOG_FILE_NAME ; $install_succeeded = $?\n+  Write-Output \"----- build and install logs -----\"\n+  Get-Content -Path \"$INSTALL_LOG_FILE_NAME\"\n+  Write-Output \"----- end of build and install logs -----\"\n+  Check-Output $install_succeeded\n+}\n \n-Write-Output \"Looking for issues with R CMD check results\"\n-if (Get-Content \"$LOG_FILE_NAME\" | Select-String -Pattern \"WARNING\" -Quiet) {\n-    echo \"WARNINGS have been found by R CMD check!\"\n-    Check-Output $False\n+# Checking that we actually got the expected compiler. The R package has some logic\n+# to fail back to MinGW if MSVC fails, but for CI builds we need to check that the correct\n+# compiler was used.\n+$checks = Select-String -Path \"${INSTALL_LOG_FILE_NAME}\" -Pattern \"Check for working CXX compiler.*$env:COMPILER\"\n+if ($checks.Matches.length -eq 0) {\n+  Write-Output \"The wrong compiler was used. Check the build logs.\"\n+  Check-Output $False\n }\n \n-$note_str = Get-Content \"${LOG_FILE_NAME}\" | Select-String -Pattern ' NOTE' | Out-String ; Check-Output $?\n-$relevant_line = $note_str -match '.*Status: (\\d+) NOTE.*'\n-$NUM_CHECK_NOTES = $matches[1]\n-$ALLOWED_CHECK_NOTES = 3\n-if ([int]$NUM_CHECK_NOTES -gt $ALLOWED_CHECK_NOTES) {\n-    Write-Output \"Found ${NUM_CHECK_NOTES} NOTEs from R CMD check. Only ${ALLOWED_CHECK_NOTES} are allowed\"\n-    Check-Output $False\n+if ($env:COMPILER -eq \"MSVC\") {\n+  Write-Output \"Running tests with testthat.R\"\n+  cd R-package/tests\n+  Rscript testthat.R ; Check-Output $?\n }\n \n Write-Output \"No issues were found checking the R package\"\ndiff --git a/.vsts-ci.yml b/.vsts-ci.yml\nindex c72d3a2e2291..359ecc4389b9 100644\n--- a/.vsts-ci.yml\n+++ b/.vsts-ci.yml\n@@ -120,7 +120,7 @@ jobs:\n     matrix:\n       r_package:\n         TASK: r-package\n-        COMPILER: MINGW\n+        COMPILER: MSVC\n       regular:\n         TASK: regular\n         PYTHON_VERSION: 3.6\ndiff --git a/R-package/DESCRIPTION b/R-package/DESCRIPTION\nindex 1924b6a1d666..9e2cf6b1e513 100755\n--- a/R-package/DESCRIPTION\n+++ b/R-package/DESCRIPTION\n@@ -27,6 +27,7 @@ Biarch: false\n Suggests:\n     ggplot2 (>= 1.0.1),\n     knitr,\n+    processx,\n     rmarkdown,\n     testthat\n Depends:\ndiff --git a/R-package/src/install.libs.R b/R-package/src/install.libs.R\nindex 339e8417ee70..b04eecc3317f 100644\n--- a/R-package/src/install.libs.R\n+++ b/R-package/src/install.libs.R\n@@ -12,7 +12,77 @@ R_ver <- as.double(R.Version()$major) + as.double(R.Version()$minor) / 10.0\n \n if (!(R_int_UUID == \"0310d4b8-ccb1-4bb8-ba94-d36a55f60262\"\n     || R_int_UUID == \"2fdf6c18-697a-4ba7-b8ef-11c0d92f1327\")) {\n-  print(\"Warning: unmatched R_INTERNALS_UUID, may cannot run normally.\")\n+  warning(\"Warning: unmatched R_INTERNALS_UUID, may not run normally.\")\n+}\n+\n+# system() will not raise an R exception if the process called\n+# fails. Wrapping it here to get that behavior.\n+#\n+# system() introduces a lot of overhead, at least on Windows,\n+# so trying processx if it is available\n+.run_shell_command <- function(cmd, args, strict = TRUE) {\n+    on_windows <- .Platform$OS.type == \"windows\"\n+    has_processx <- suppressMessages({\n+      suppressWarnings({\n+        require(\"processx\")  # nolint\n+      })\n+    })\n+    if (has_processx && on_windows) {\n+      result <- processx::run(\n+        command = cmd\n+        , args = args\n+        , windows_verbatim_args = TRUE\n+        , error_on_status = FALSE\n+        , echo = TRUE\n+      )\n+      exit_code <- result$status\n+    } else {\n+      if (on_windows) {\n+        message(paste0(\n+          \"Using system() to run shell commands. Installing \"\n+          , \"'processx' with install.packages('processx') might \"\n+          , \"make this faster.\"\n+        ))\n+      }\n+      cmd <- paste0(cmd, \" \", paste0(args, collapse = \" \"))\n+      exit_code <- system(cmd)\n+    }\n+\n+    if (exit_code != 0L && isTRUE(strict)) {\n+        stop(paste0(\"Command failed with exit code: \", exit_code))\n+    }\n+    return(invisible(exit_code))\n+}\n+\n+# try to generate Visual Studio build files\n+.generate_vs_makefiles <- function(cmake_args) {\n+  vs_versions <- c(\n+    \"Visual Studio 16 2019\"\n+    , \"Visual Studio 15 2017\"\n+    , \"Visual Studio 14 2015\"\n+  )\n+  working_vs_version <- NULL\n+  for (vs_version in vs_versions) {\n+    message(sprintf(\"Trying '%s'\", vs_version))\n+    # if the build directory is not empty, clean it\n+    if (file.exists(\"CMakeCache.txt\")) {\n+      file.remove(\"CMakeCache.txt\")\n+    }\n+    vs_cmake_args <- c(\n+      cmake_args\n+      , \"-G\"\n+      , shQuote(vs_version)\n+      , \"-A\"\n+      , \"x64\"\n+    )\n+    exit_code <- .run_shell_command(\"cmake\", c(vs_cmake_args, \"..\"), strict = FALSE)\n+    if (exit_code == 0L) {\n+      message(sprintf(\"Successfully created build files for '%s'\", vs_version))\n+      return(invisible(TRUE))\n+    }\n+\n+  }\n+  return(invisible(FALSE))\n }\n \n # Move in CMakeLists.txt\n@@ -41,17 +111,18 @@ if (!use_precompile) {\n   setwd(build_dir)\n \n   # Prepare installation steps\n-  cmake_cmd <- \"cmake \"\n-  build_cmd <- \"make _lightgbm\"\n+  cmake_args <- NULL\n+  build_cmd <- \"make\"\n+  build_args <- \"_lightgbm\"\n   lib_folder <- file.path(source_dir, fsep = \"/\")\n \n   if (use_gpu) {\n-    cmake_cmd <- paste0(cmake_cmd, \" -DUSE_GPU=ON \")\n+    cmake_args <- c(cmake_args, \"-DUSE_GPU=ON\")\n   }\n   if (R_ver >= 3.5) {\n-    cmake_cmd <- paste0(cmake_cmd, \" -DUSE_R35=ON \")\n+    cmake_args <- c(cmake_args, \"-DUSE_R35=ON\")\n   }\n-  cmake_cmd <- paste0(cmake_cmd, \" -DBUILD_FOR_R=ON \")\n+  cmake_args <- c(cmake_args, \"-DBUILD_FOR_R=ON\")\n \n   # Pass in R version, used to help find R executable for linking\n   R_version_string <- paste(\n@@ -59,53 +130,47 @@ if (!use_precompile) {\n     , R.Version()[[\"minor\"]]\n     , sep = \".\"\n   )\n-  cmake_cmd <- sprintf(\n-    paste0(cmake_cmd, \" -DCMAKE_R_VERSION='%s' \")\n-    , R_version_string\n-  )\n+  r_version_arg <- sprintf(\"-DCMAKE_R_VERSION='%s'\", R_version_string)\n+  cmake_args <- c(cmake_args, r_version_arg)\n+\n+  # the checks below might already run `cmake -G`. If they do, set this flag\n+  # to TRUE to avoid re-running it later\n+  makefiles_already_generated <- FALSE\n \n   # Check if Windows installation (for gcc vs Visual Studio)\n   if (WINDOWS) {\n     if (use_mingw) {\n-      print(\"Trying to build with MinGW\")\n-      cmake_cmd <- paste0(cmake_cmd, \" -G \\\"MinGW Makefiles\\\" \")\n-      build_cmd <- \"mingw32-make.exe _lightgbm\"\n-      system(paste0(cmake_cmd, \" ..\")) # Must build twice for Windows due sh.exe in Rtools\n+      message(\"Trying to build with MinGW\")\n+      # Must build twice for Windows due sh.exe in Rtools\n+      cmake_args <- c(cmake_args, \"-G\", shQuote(\"MinGW Makefiles\"))\n+      .run_shell_command(\"cmake\", c(cmake_args, \"..\"), strict = FALSE)\n+      build_cmd <- \"mingw32-make.exe\"\n+      build_args <- \"_lightgbm\"\n     } else {\n-      local_vs_def <- \"\"\n-      vs_versions <- c(\n-        \"Visual Studio 16 2019\"\n-        , \"Visual Studio 15 2017\"\n-        , \"Visual Studio 14 2015\"\n-      )\n-      for (vs in vs_versions) {\n-        print(paste0(\"Trying to build with: '\", vs, \"'\"))\n-        vs_def <- paste0(\" -G \\\"\", vs, \"\\\" -A x64\")\n-        tmp_cmake_cmd <- paste0(cmake_cmd, vs_def)\n-        try_vs <- system(paste0(tmp_cmake_cmd, \" ..\"))\n-        if (try_vs == 0L) {\n-          local_vs_def <- vs_def\n-          print(paste0(\"Building with '\", vs, \"' succeeded\"))\n-          break\n-        } else {\n-          unlink(\"./*\", recursive = TRUE) # Clean up build directory\n-        }\n-      }\n-      if (try_vs == 1L) {\n-        print(\"Building with Visual Studio failed. Attempted with MinGW\")\n-        cmake_cmd <- paste0(cmake_cmd, \" -G \\\"MinGW Makefiles\\\" \")\n-        system(paste0(cmake_cmd, \" ..\")) # Must build twice for Windows due sh.exe in Rtools\n-        build_cmd <- \"mingw32-make.exe _lightgbm\"\n+      visual_studio_succeeded <- .generate_vs_makefiles(cmake_args)\n+      if (!isTRUE(visual_studio_succeeded)) {\n+        warning(\"Building with Visual Studio failed. Attempting with MinGW\")\n+        # Must build twice for Windows due sh.exe in Rtools\n+        cmake_args <- c(cmake_args, \"-G\", shQuote(\"MinGW Makefiles\"))\n+        .run_shell_command(\"cmake\", c(cmake_args, \"..\"), strict = FALSE)\n+        build_cmd <- \"mingw32-make.exe\"\n+        build_args <- \"_lightgbm\"\n       } else {\n-        cmake_cmd <- paste0(cmake_cmd, local_vs_def)\n-        build_cmd <- \"cmake --build . --target _lightgbm --config Release\"\n+        build_cmd <- \"cmake\"\n+        build_args <- c(\"--build\", \".\", \"--target\", \"_lightgbm\", \"--config\", \"Release\")\n         lib_folder <- file.path(source_dir, \"Release\", fsep = \"/\")\n+        makefiles_already_generated <- TRUE\n       }\n     }\n+  } else {\n+      .run_shell_command(\"cmake\", c(cmake_args, \"..\"))\n+      makefiles_already_generated <- TRUE\n   }\n \n-  # Install\n-  system(paste0(cmake_cmd, \" ..\"))\n+  # generate build files\n+  if (!makefiles_already_generated) {\n+    .run_shell_command(\"cmake\", c(cmake_args, \"..\"))\n+  }\n \n   # R CMD check complains about the .NOTPARALLEL directive created in the cmake\n   # Makefile. We don't need it here anyway since targets are built serially, so trying\n@@ -130,7 +195,8 @@ if (!use_precompile) {\n     )\n   }\n \n-  system(build_cmd)\n+  # build the library\n+  .run_shell_command(build_cmd, build_args)\n   src <- file.path(lib_folder, paste0(\"lib_lightgbm\", SHLIB_EXT), fsep = \"/\")\n \n } else {\n@@ -169,7 +235,7 @@ if (!use_precompile) {\n dest <- file.path(R_PACKAGE_DIR, paste0(\"libs\", R_ARCH), fsep = \"/\")\n dir.create(dest, recursive = TRUE, showWarnings = FALSE)\n if (file.exists(src)) {\n-  print(paste0(\"Found library file: \", src, \" to move to \", dest))\n+  message(paste0(\"Found library file: \", src, \" to move to \", dest))\n   file.copy(src, dest, overwrite = TRUE)\n \n   symbols_file <- file.path(source_dir, \"symbols.rds\")\n@@ -183,7 +249,7 @@ if (file.exists(src)) {\n \n # clean up the \"build\" directory\n if (dir.exists(build_dir)) {\n-  print(\"Removing 'build/' directory\")\n+  message(\"Removing 'build/' directory\")\n   unlink(\n     x = build_dir\n     , recursive = TRUE\ndiff --git a/build_r.R b/build_r.R\nindex 29a4d3cc382d..886ad1ae90b4 100644\n--- a/build_r.R\n+++ b/build_r.R\n@@ -17,12 +17,42 @@ INSTALL_AFTER_BUILD <- !(\"--skip-install\" %in% args)\n }\n \n # system() will not raise an R exception if the process called\n-# fails. Wrapping it here to get that behavior\n-.run_shell_command <- function(cmd, ...) {\n-    exit_code <- system(cmd, ...)\n-    if (exit_code != 0L) {\n+# fails. Wrapping it here to get that behavior.\n+#\n+# system() introduces a lot of overhead, at least on Windows,\n+# so trying processx if it is available\n+.run_shell_command <- function(cmd, args, strict = TRUE) {\n+    on_windows <- .Platform$OS.type == \"windows\"\n+    has_processx <- suppressMessages({\n+      suppressWarnings({\n+        require(\"processx\")  # nolint\n+      })\n+    })\n+    if (has_processx && on_windows) {\n+      result <- processx::run(\n+        command = cmd\n+        , args = args\n+        , windows_verbatim_args = TRUE\n+        , error_on_status = FALSE\n+        , echo = TRUE\n+      )\n+      exit_code <- result$status\n+    } else {\n+      if (on_windows) {\n+        message(paste0(\n+          \"Using system() to run shell commands. Installing \"\n+          , \"'processx' with install.packages('processx') might \"\n+          , \"make this faster.\"\n+        ))\n+      }\n+      cmd <- paste0(cmd, \" \", paste0(args, collapse = \" \"))\n+      exit_code <- system(cmd)\n+    }\n+\n+    if (exit_code != 0L && isTRUE(strict)) {\n         stop(paste0(\"Command failed with exit code: \", exit_code))\n     }\n+    return(invisible(exit_code))\n }\n \n # Make a new temporary folder to work in\n@@ -73,8 +103,7 @@ result <- file.copy(\n # NOTE: --keep-empty-dirs is necessary to keep the deep paths expected\n #       by CMake while also meeting the CRAN req to create object files\n #       on demand\n-cmd <- \"R CMD build lightgbm_r --keep-empty-dirs\"\n-.run_shell_command(cmd)\n+.run_shell_command(\"R\", c(\"CMD\", \"build\", \"lightgbm_r\", \"--keep-empty-dirs\"))\n \n # Install the package\n version <- gsub(\n@@ -88,9 +117,11 @@ version <- gsub(\n )\n tarball <- file.path(getwd(), sprintf(\"lightgbm_%s.tar.gz\", version))\n \n-cmd <- sprintf(\"R CMD INSTALL %s --no-multiarch --with-keep.source\", tarball)\n+install_cmd <- \"R\"\n+install_args <- c(\"CMD\", \"INSTALL\", \"--no-multiarch\", \"--with-keep.source\", tarball)\n if (INSTALL_AFTER_BUILD) {\n-  .run_shell_command(cmd)\n+  .run_shell_command(install_cmd, install_args)\n } else {\n+  cmd <- paste0(install_cmd, \" \", paste0(install_args, collapse = \" \"))\n   print(sprintf(\"Skipping installation. Install the package with command '%s'\", cmd))\n }\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Environment Configuration**: Add `\"$env:R_LIB_PATH/Rtools/mingw_64/bin;` to `$env:PATH` in CI for `gendef` and `dlltool` accessibility. Include instructions for `Rtools/mingw_*/` in installation guidelines.\n\n2. **CI Strategy**: Remove all CI speed-up conditions for MSVC and execute a full `--as-cran` test to assess build times.\n\n3. **Build Time Issues**: Current Azure build takes ~10 minutes between \"build files have been written\" and starting compilation. Investigate I/O performance and consider minimizing redundant CMake calls during builds.\n\n4. **Overhead and Optimization**: Experiment with alternatives to `system()` for running CMake commands due to observed overhead leading to ~10x slowdown. Consider using R packages like `processx`.\n\n5. **Debugging**: Explore solutions to eliminate unnecessary CMake calls to further optimize build processes."
      }
    ],
    "codediff_length": 16198
  },
  {
    "index": 7,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.ci/test_r_package_valgrind.sh b/.ci/test_r_package_valgrind.sh\nnew file mode 100755\nindex 000000000000..1cc06e0660a2\n--- /dev/null\n+++ b/.ci/test_r_package_valgrind.sh\n@@ -0,0 +1,66 @@\n+#!/bin/bash\n+\n+cd R-package/tests\n+\n+ALL_LOGS_FILE=\"out.log\"\n+VALGRIND_LOGS_FILE=\"valgrind-logs.log\"\n+\n+RDvalgrind \\\n+  --no-readline \\\n+  --vanilla \\\n+  -d \"valgrind --tool=memcheck --leak-check=full --track-origins=yes\" \\\n+  -f testthat.R \\\n+  2>&1 > ${ALL_LOGS_FILE} || exit -1\n+\n+cat ${ALL_LOGS_FILE}\n+\n+cat ${ALL_LOGS_FILE} | grep -E \"^\\=\" > ${VALGRIND_LOGS_FILE}\n+\n+bytes_definitely_lost=$(\n+  cat ${VALGRIND_LOGS_FILE} \\\n+      | grep -E \"definitely lost\\: .*\" \\\n+      | sed 's/^.*definitely lost\\: \\(.*\\) bytes.*$/\\1/' \\\n+      | tr -d \",\"\n+)\n+if [[ ${bytes_definitely_lost} -gt 0 ]]; then\n+    echo \"valgrind found ${bytes_definitely_lost} bytes definitely lost\"\n+    exit -1\n+fi\n+\n+bytes_indirectly_lost=$(\n+    cat ${VALGRIND_LOGS_FILE} \\\n+    | grep -E \"indirectly lost\\: .*\" \\\n+    | sed 's/^.*indirectly lost\\: \\(.*\\) bytes.*$/\\1/' \\\n+    | tr -d \",\"\n+)\n+if [[ ${bytes_indirectly_lost} -gt 0 ]]; then\n+    echo \"valgrind found ${bytes_indirectly_lost} bytes indirectly lost\"\n+    exit -1\n+fi\n+\n+# one error caused by a false positive between valgrind and openmp is allowed\n+# ==1312== 352 bytes in 1 blocks are possibly lost in loss record 146 of 2,458\n+# ==1312==    at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so)\n+# ==1312==    by 0x40149CA: allocate_dtv (dl-tls.c:286)\n+# ==1312==    by 0x40149CA: _dl_allocate_tls (dl-tls.c:532)\n+# ==1312==    by 0x5702322: allocate_stack (allocatestack.c:622)\n+# ==1312==    by 0x5702322: pthread_create@@GLIBC_2.2.5 (pthread_create.c:660)\n+# ==1312==    by 0x56D0DDA: ??? (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n+# ==1312==    by 0x56C88E0: GOMP_parallel (in /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0)\n+# ==1312==    by 0x154351B8: LGBM_DatasetCreateFromCSC (c_api.cpp:1286)\n+# ==1312==    by 0x1545789C: LGBM_DatasetCreateFromCSC_R (lightgbm_R.cpp:91)\n+# ==1312==    by 0x4941E2F: R_doDotCall (dotcode.c:634)\n+# ==1312==    by 0x494CCC6: do_dotcall (dotcode.c:1281)\n+# ==1312==    by 0x499FB01: bcEval (eval.c:7078)\n+# ==1312==    by 0x498B67F: Rf_eval (eval.c:727)\n+# ==1312==    by 0x498E414: R_execClosure (eval.c:1895)\n+bytes_possibly_lost=$(\n+    cat ${VALGRIND_LOGS_FILE} \\\n+    | grep -E \"possibly lost\\: .*\" \\\n+    | sed 's/^.*possibly lost\\: \\(.*\\) bytes.*$/\\1/' \\\n+    | tr -d \",\"\n+)\n+if [[ ${bytes_possibly_lost} -gt 352 ]]; then\n+    echo \"valgrind found ${bytes_possibly_lost} bytes possibly lost\"\n+    exit -1\n+fi\ndiff --git a/.github/workflows/r_valgrind.yml b/.github/workflows/r_valgrind.yml\nnew file mode 100644\nindex 000000000000..b94ab532c251\n--- /dev/null\n+++ b/.github/workflows/r_valgrind.yml\n@@ -0,0 +1,28 @@\n+name: R valgrind tests\n+\n+on:\n+  pull_request_review_comment:\n+    types: [created]\n+\n+jobs:\n+  test-r-valgrind:\n+    name: r-package (ubuntu-latest, R-devel, valgrind)\n+    if: github.event.comment.body == '/gha run r-valgrind' && contains('OWNER,MEMBER,COLLABORATOR', github.event.comment.author_association)\n+    timeout-minutes: 120\n+    runs-on: ubuntu-latest\n+    container: wch1/r-debug\n+    steps:\n+      - name: Checkout repository\n+        uses: actions/checkout@v1\n+        with:\n+          fetch-depth: 5\n+          submodules: true\n+      - name: Install packages\n+        shell: bash\n+        run: |\n+          RDscriptvalgrind -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'testthat'), repos = 'https://cran.r-project.org')\"\n+          sh build-cran-package.sh\n+          RDvalgrind CMD INSTALL --preclean --install-tests lightgbm_*.tar.gz || exit -1\n+      - name: Run tests with valgrind\n+        shell: bash\n+        run: ./.ci/test_r_package_valgrind.sh\ndiff --git a/R-package/R/lgb.Predictor.R b/R-package/R/lgb.Predictor.R\nindex c996bb1731ae..ab0bea7fc8e6 100644\n--- a/R-package/R/lgb.Predictor.R\n+++ b/R-package/R/lgb.Predictor.R\n@@ -30,7 +30,7 @@ Predictor <- R6::R6Class(\n       params <- list(...)\n       private$params <- lgb.params2str(params)\n       # Create new lgb handle\n-      handle <- 0.0\n+      handle <- lgb.null.handle()\n \n       # Check if handle is a character\n       if (is.character(modelfile)) {\ndiff --git a/R-package/README.md b/R-package/README.md\nindex f0199cb6ba73..8ef5c7818148 100644\n--- a/R-package/README.md\n+++ b/R-package/README.md\n@@ -454,13 +454,17 @@ cd R-package/tests\n RDvalgrind \\\n     --no-readline \\\n     --vanilla \\\n-    -d valgrind \\\n+    -d \"valgrind --tool=memcheck --leak-check=full --track-origins=yes\" \\\n         -f testthat.R \\\n 2>&1 \\\n | tee out.log \\\n | cat\n ```\n \n+These tests can also be triggered on any pull request by leaving a \"Comment\" review with the following comment:\n+\n+> /gha run r-valgrind\n+\n External (Unofficial) Repositories\n ----------------------------------\n \ndiff --git a/R-package/src/R_object_helper.h b/R-package/src/R_object_helper.h\nindex db75c5792520..e14a2ac6697b 100644\n--- a/R-package/src/R_object_helper.h\n+++ b/R-package/src/R_object_helper.h\n@@ -104,8 +104,6 @@ typedef union { VECTOR_SER s; double align; } SEXPREC_ALIGN;\n \n #define R_INT_PTR(x)   (reinterpret_cast<int*> DATAPTR(x))\n \n-#define R_INT64_PTR(x) (reinterpret_cast<int64_t*> DATAPTR(x))\n-\n #define R_REAL_PTR(x)  (reinterpret_cast<double*> DATAPTR(x))\n \n #define R_AS_INT(x)    (*(reinterpret_cast<int*> DATAPTR(x)))\ndiff --git a/R-package/src/lightgbm_R.cpp b/R-package/src/lightgbm_R.cpp\nindex f6dc82e9bd04..a5e94f011ac5 100644\n--- a/R-package/src/lightgbm_R.cpp\n+++ b/R-package/src/lightgbm_R.cpp\n@@ -506,7 +506,7 @@ LGBM_SE LGBM_BoosterGetNumPredict_R(LGBM_SE handle,\n   R_API_BEGIN();\n   int64_t len;\n   CHECK_CALL(LGBM_BoosterGetNumPredict(R_GET_PTR(handle), R_AS_INT(data_idx), &len));\n-  R_INT64_PTR(out)[0] = len;\n+  R_INT_PTR(out)[0] = static_cast<int>(len);\n   R_API_END();\n }\n \n@@ -624,7 +624,7 @@ LGBM_SE LGBM_BoosterPredictForMat_R(LGBM_SE handle,\n   int32_t nrow = R_AS_INT(num_row);\n   int32_t ncol = R_AS_INT(num_col);\n \n-  double* p_mat = R_REAL_PTR(data);\n+  const double* p_mat = R_REAL_PTR(data);\n   double* ptr_ret = R_REAL_PTR(out_result);\n   int64_t out_len;\n   CHECK_CALL(LGBM_BoosterPredictForMat(R_GET_PTR(handle),\ndiff --git a/R-package/tests/testthat/test_dataset.R b/R-package/tests/testthat/test_dataset.R\nindex 9431cb32f646..d0ac9c0627d2 100644\n--- a/R-package/tests/testthat/test_dataset.R\n+++ b/R-package/tests/testthat/test_dataset.R\n@@ -85,6 +85,8 @@ test_that(\"lgb.Dataset: Dataset should be able to construct from matrix and retu\n     , ref_handle\n   )\n   expect_false(is.na(handle))\n+  lgb.call(\"LGBM_DatasetFree_R\", ret = NULL, handle)\n+  handle <- NULL\n })\n \n test_that(\"lgb.Dataset$setinfo() should convert 'group' to integer\", {\ndiff --git a/R-package/tests/testthat/test_lgb.Booster.R b/R-package/tests/testthat/test_lgb.Booster.R\nindex 1db70dc2608b..e4d75661755e 100644\n--- a/R-package/tests/testthat/test_lgb.Booster.R\n+++ b/R-package/tests/testthat/test_lgb.Booster.R\n@@ -439,6 +439,23 @@ test_that(\"Saving a model with different feature importance types works\", {\n             , \"spore-print-color=green=1\"\n         )\n     )\n+})\n+\n+test_that(\"Saving a model with unknown importance type fails\", {\n+    testthat::skip(\"Skipping this test because it causes issues for valgrind\")\n+    set.seed(708L)\n+    data(agaricus.train, package = \"lightgbm\")\n+    train <- agaricus.train\n+    bst <- lightgbm(\n+        data = as.matrix(train$data)\n+        , label = train$label\n+        , num_leaves = 4L\n+        , learning_rate = 1.0\n+        , nrounds = 2L\n+        , objective = \"binary\"\n+        , save_name = tempfile(fileext = \".model\")\n+    )\n+    expect_true(lgb.is.Booster(bst))\n \n     UNSUPPORTED_IMPORTANCE <- 2L\n     expect_error({\n@@ -446,6 +463,7 @@ test_that(\"Saving a model with different feature importance types works\", {\n     }, \"Unknown importance type\")\n })\n \n+\n .params_from_model_string <- function(model_str) {\n     file_lines <- strsplit(model_str, \"\\n\")[[1L]]\n     start_indx <- which(grepl(\"^parameters\\\\:$\", file_lines)) + 1L\ndiff --git a/R-package/tests/testthat/test_utils.R b/R-package/tests/testthat/test_utils.R\nindex 5a9cfb641d61..5ac43cc50b9a 100644\n--- a/R-package/tests/testthat/test_utils.R\n+++ b/R-package/tests/testthat/test_utils.R\n@@ -67,6 +67,10 @@ test_that(\"lgb.last_error() throws an error if there are no errors\", {\n })\n \n test_that(\"lgb.last_error() correctly returns errors from the C++ side\", {\n+    testthat::skip(paste0(\n+        \"Skipping this test because it causes valgrind to think \"\n+        , \"there is a memory leak, and needs to be rethought\"\n+    ))\n     data(agaricus.train, package = \"lightgbm\")\n     train <- agaricus.train\n     dvalid1 <- lgb.Dataset(\ndiff --git a/include/LightGBM/utils/log.h b/include/LightGBM/utils/log.h\nindex 7d795ff755a1..131d1f6a0353 100644\n--- a/include/LightGBM/utils/log.h\n+++ b/include/LightGBM/utils/log.h\n@@ -123,10 +123,10 @@ class Log {\n #ifndef LGB_R_BUILD\n     fprintf(stderr, \"[LightGBM] [Fatal] %s\\n\", str_buf);\n     fflush(stderr);\n-    throw std::runtime_error(std::string(str_buf));\n #else\n     Rf_error(\"[LightGBM] [Fatal] %s\\n\", str_buf);\n #endif\n+    throw std::runtime_error(std::string(str_buf));\n   }\n \n  private:\ndiff --git a/src/boosting/gbdt_model_text.cpp b/src/boosting/gbdt_model_text.cpp\nindex 4eeb731f587f..4d9174313d38 100644\n--- a/src/boosting/gbdt_model_text.cpp\n+++ b/src/boosting/gbdt_model_text.cpp\n@@ -393,7 +393,7 @@ std::string GBDT::SaveModelToString(int start_iteration, int num_iteration, int\n     ss << loaded_parameter_ << \"\\n\";\n     ss << \"end of parameters\" << '\\n';\n   }\n-  return ss.str();\n+  return std::move(ss.str());\n }\n \n bool GBDT::SaveModelToFile(int start_iteration, int num_iteration, int feature_importance_type, const char* filename) const {\n@@ -618,7 +618,7 @@ std::vector<double> GBDT::FeatureImportance(int num_iteration, int importance_ty\n   } else {\n     Log::Fatal(\"Unknown importance type: only support split=0 and gain=1\");\n   }\n-  return feature_importances;\n+  return std::move(feature_importances);\n }\n \n }  // namespace LightGBM\ndiff --git a/src/treelearner/monotone_constraints.hpp b/src/treelearner/monotone_constraints.hpp\nindex fde4bfbf033d..6c86e61d1c2d 100644\n--- a/src/treelearner/monotone_constraints.hpp\n+++ b/src/treelearner/monotone_constraints.hpp\n@@ -9,6 +9,7 @@\n #include <algorithm>\n #include <cstdint>\n #include <limits>\n+#include <memory>\n #include <utility>\n #include <vector>\n \n@@ -37,6 +38,7 @@ struct FeatureConstraint {\n };\n \n struct ConstraintEntry {\n+  virtual ~ConstraintEntry() {}\n   virtual void Reset() = 0;\n   virtual void UpdateMin(double new_min) = 0;\n   virtual void UpdateMax(double new_max) = 0;\n@@ -462,12 +464,12 @@ class BasicLeafConstraints : public LeafConstraintsBase {\n  public:\n   explicit BasicLeafConstraints(int num_leaves) : num_leaves_(num_leaves) {\n     for (int i = 0; i < num_leaves; ++i) {\n-      entries_.push_back(new BasicConstraintEntry());\n+      entries_.emplace_back(new BasicConstraintEntry());\n     }\n   }\n \n   void Reset() override {\n-    for (auto entry : entries_) {\n+    for (auto& entry : entries_) {\n       entry->Reset();\n     }\n   }\n@@ -484,7 +486,7 @@ class BasicLeafConstraints : public LeafConstraintsBase {\n                           int8_t monotone_type, double right_output,\n                           double left_output, int, const SplitInfo& ,\n                           const std::vector<SplitInfo>&) override {\n-    entries_[new_leaf] = entries_[leaf]->clone();\n+    entries_[new_leaf].reset(entries_[leaf]->clone());\n     if (is_numerical_split) {\n       double mid = (left_output + right_output) / 2.0f;\n       if (monotone_type < 0) {\n@@ -498,7 +500,7 @@ class BasicLeafConstraints : public LeafConstraintsBase {\n     return std::vector<int>();\n   }\n \n-  const ConstraintEntry* Get(int leaf_idx) override { return entries_[leaf_idx]; }\n+  const ConstraintEntry* Get(int leaf_idx) override { return entries_[leaf_idx].get(); }\n \n   FeatureConstraint* GetFeatureConstraint(int leaf_idx, int feature_index) final {\n     return entries_[leaf_idx]->GetFeatureConstraint(feature_index);\n@@ -506,7 +508,7 @@ class BasicLeafConstraints : public LeafConstraintsBase {\n \n  protected:\n   int num_leaves_;\n-  std::vector<ConstraintEntry*> entries_;\n+  std::vector<std::unique_ptr<ConstraintEntry>> entries_;\n };\n \n class IntermediateLeafConstraints : public BasicLeafConstraints {\n@@ -541,7 +543,7 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n   void UpdateConstraintsWithOutputs(bool is_numerical_split, int leaf,\n                                     int new_leaf, int8_t monotone_type,\n                                     double right_output, double left_output) {\n-    entries_[new_leaf] = entries_[leaf]->clone();\n+    entries_[new_leaf].reset(entries_[leaf]->clone());\n     if (is_numerical_split) {\n       if (monotone_type < 0) {\n         entries_[leaf]->UpdateMin(right_output);\n@@ -857,7 +859,7 @@ class AdvancedLeafConstraints : public IntermediateLeafConstraints {\n                           int num_features)\n       : IntermediateLeafConstraints(config, num_leaves) {\n     for (int i = 0; i < num_leaves; ++i) {\n-      entries_[i] = new AdvancedConstraintEntry(num_features);\n+      entries_[i].reset(new AdvancedConstraintEntry(num_features));\n     }\n   }\n \ndiff --git a/windows/LightGBM.vcxproj b/windows/LightGBM.vcxproj\nindex 9dd319527229..4c95af83b03c 100644\n--- a/windows/LightGBM.vcxproj\n+++ b/windows/LightGBM.vcxproj\n@@ -287,6 +287,7 @@\n     <ClInclude Include=\"..\\src\\treelearner\\data_partition.hpp\" />\n     <ClInclude Include=\"..\\src\\treelearner\\feature_histogram.hpp\" />\n     <ClInclude Include=\"..\\src\\treelearner\\leaf_splits.hpp\" />\n+    <ClInclude Include=\"..\\src\\treelearner\\monotone_constraints.hpp\" />\n     <ClInclude Include=\"..\\src\\treelearner\\parallel_tree_learner.h\" />\n     <ClInclude Include=\"..\\src\\treelearner\\serial_tree_learner.h\" />\n     <ClInclude Include=\"..\\src\\treelearner\\split_info.hpp\" />\ndiff --git a/windows/LightGBM.vcxproj.filters b/windows/LightGBM.vcxproj.filters\nindex 8540b2d5f297..9490e3655387 100644\n--- a/windows/LightGBM.vcxproj.filters\n+++ b/windows/LightGBM.vcxproj.filters\n@@ -222,6 +222,9 @@\n     <ClInclude Include=\"..\\include\\LightGBM\\utils\\yamc\\alternate_shared_mutex.hpp\">\n       <Filter>include\\LightGBM\\utils\\yamc</Filter>\n     </ClInclude>\n+    <ClInclude Include=\"..\\src\\treelearner\\monotone_constraints.hpp\">\n+      <Filter>src\\treelearner</Filter>\n+    </ClInclude>\n   </ItemGroup>\n   <ItemGroup>\n     <ClCompile Include=\"..\\src\\application\\application.cpp\">\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Valgrind Errors**: \n   - Successfully reproduced memory errors: Invalid write in `LGBM_BoosterGetNumPredict_R` indicating a need for modification.\n   - Conditional jump or move relies on uninitialized values in regex functions. Investigate and address these in related tests.\n\n2. **Performance**: \n   - Valgrind job duration exceeding 40 minutes; consider moving it to a comment-triggered job for efficiency.\n\n3. **Memory Management**:\n   - Implement `PROTECT/UNPROTECT` to prevent R's garbage collection issues. This could resolve memory leakage. Research necessary changes to ensure R handles memory appropriately.\n\n4. **Test Modifications**: \n   - Temporarily commented out `expect_error()` tests that introduced significant memory leaks; document as an issue for future resolution.\n\n5. **Compilation Issue**: \n   - C compiler error relates to Chocolatey setup; ensure `make` uses Rtools for compatibility.\n\n6. **Subsequent Actions**: \n   - Create an issue for tracking the resolution of the skipped tests to ensure they are revisited. \n\n7. **OpenMP Investigation**: \n   - Assess whether OpenMP-related errors are false positives per GCC reports; if confirmed, re-enable OpenMP."
      }
    ],
    "codediff_length": 14645
  },
  {
    "index": 8,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.appveyor.yml b/.appveyor.yml\nindex f8cd85f17dcb..20807e36e6f5 100644\n--- a/.appveyor.yml\n+++ b/.appveyor.yml\n@@ -7,6 +7,8 @@ configuration:  # a trick to construct a build matrix with multiple Python versi\n \n environment:\n   matrix:\n+    - COMPILER: MINGW\n+      TASK: r-package\n     - COMPILER: MSVC\n       TASK: python\n     - COMPILER: MINGW\ndiff --git a/.ci/test_r_package_windows.ps1 b/.ci/test_r_package_windows.ps1\nnew file mode 100644\nindex 000000000000..5bd65d28408b\n--- /dev/null\n+++ b/.ci/test_r_package_windows.ps1\n@@ -0,0 +1,108 @@\n+# Download a file and retry upon failure. This looks like\n+# an infinite loop but CI-level timeouts will kill it\n+function Download-File-With-Retries {\n+  param(\n+    [string]$url,\n+    [string]$destfile\n+  )\n+  do {\n+    Write-Output \"Downloading ${url}\"\n+    sleep 5;\n+    (New-Object System.Net.WebClient).DownloadFile($url, $destfile)\n+  } while(!$?);\n+}\n+\n+$env:R_WINDOWS_VERSION = \"3.6.3\"\n+$env:R_LIB_PATH = \"$env:BUILD_SOURCESDIRECTORY/RLibrary\" -replace '[\\\\]', '/'\n+$env:PATH = \"$env:R_LIB_PATH/Rtools/bin;\" + \"$env:R_LIB_PATH/R/bin/x64;\" + \"$env:R_LIB_PATH/miktex/texmfs/install/miktex/bin/x64;\" + $env:PATH\n+$env:CRAN_MIRROR = \"https://cloud.r-project.org/\"\n+$env:CTAN_MIRROR = \"https://ctan.math.illinois.edu/systems/win32/miktex/tm/packages/\"\n+\n+if ($env:COMPILER -eq \"MINGW\") {\n+  $env:CXX = \"$env:R_LIB_PATH/Rtools/mingw_64/bin/g++.exe\"\n+  $env:CC = \"$env:R_LIB_PATH/Rtools/mingw_64/bin/gcc.exe\"\n+}\n+\n+cd $env:BUILD_SOURCESDIRECTORY\n+tzutil /s \"GMT Standard Time\"\n+[Void][System.IO.Directory]::CreateDirectory($env:R_LIB_PATH)\n+\n+if ($env:COMPILER -eq \"MINGW\") {\n+  Write-Output \"Telling R to use MinGW\"\n+  $install_libs = \"$env:BUILD_SOURCESDIRECTORY/R-package/src/install.libs.R\"\n+  ((Get-Content -path $install_libs -Raw) -replace 'use_mingw <- FALSE','use_mingw <- TRUE') | Set-Content -Path $install_libs\n+}\n+\n+# download R and RTools\n+Write-Output \"Downloading R and Rtools\"\n+Download-File-With-Retries -url \"https://cloud.r-project.org/bin/windows/base/old/$env:R_WINDOWS_VERSION/R-$env:R_WINDOWS_VERSION-win.exe\" -destfile \"R-win.exe\"\n+Download-File-With-Retries -url \"https://cloud.r-project.org/bin/windows/Rtools/Rtools35.exe\" -destfile \"Rtools.exe\"\n+\n+# Install R\n+Write-Output \"Installing R\"\n+Start-Process -FilePath R-win.exe -NoNewWindow -Wait -ArgumentList \"/VERYSILENT /DIR=$env:R_LIB_PATH/R /COMPONENTS=main,x64\" ; Check-Output $?\n+Write-Output \"Done installing R\"\n+\n+Write-Output \"Installing Rtools\"\n+Start-Process -FilePath Rtools.exe -NoNewWindow -Wait -ArgumentList \"/VERYSILENT /DIR=$env:R_LIB_PATH/Rtools\" ; Check-Output $?\n+Write-Output \"Done installing Rtools\"\n+\n+# MiKTeX and pandoc can be skipped on non-MINGW builds, since we don't\n+# build the package documentation for those\n+if ($env:COMPILER -eq \"MINGW\") {\n+    Write-Output \"Downloading MiKTeX\"\n+    Download-File-With-Retries -url \"https://miktex.org/download/win/miktexsetup-x64.zip\" -destfile \"miktexsetup-x64.zip\"\n+    Add-Type -AssemblyName System.IO.Compression.FileSystem\n+    [System.IO.Compression.ZipFile]::ExtractToDirectory(\"miktexsetup-x64.zip\", \"miktex\")\n+    Write-Output \"Setting up MiKTeX\"\n+    .\\miktex\\miktexsetup.exe --remote-package-repository=\"$env:CTAN_MIRROR\" --local-package-repository=./miktex/download --package-set=essential --quiet download ; Check-Output $?\n+    Write-Output \"Installing MiKTeX\"\n+    .\\miktex\\download\\miktexsetup.exe --remote-package-repository=\"$env:CTAN_MIRROR\" --portable=\"$env:R_LIB_PATH/miktex\" --quiet install ; Check-Output $?\n+    Write-Output \"Done installing MiKTeX\"\n+\n+    initexmf --set-config-value [MPM]AutoInstall=1\n+    conda install -q -y --no-deps pandoc\n+}\n+\n+Add-Content .Renviron \"R_LIBS=$env:R_LIB_PATH\"\n+\n+Write-Output \"Installing dependencies\"\n+$packages = \"c('data.table', 'jsonlite', 'Matrix', 'R6', 'testthat'), dependencies = c('Imports', 'Depends', 'LinkingTo')\"\n+Rscript --vanilla -e \"options(install.packages.check.source = 'no'); install.packages($packages, repos = '$env:CRAN_MIRROR', type = 'binary', lib = '$env:R_LIB_PATH')\" ; Check-Output $?\n+\n+Write-Output \"Building R package\"\n+Rscript build_r.R --skip-install ; Check-Output $?\n+\n+$PKG_FILE_NAME = Get-Item *.tar.gz\n+$LOG_FILE_NAME = \"lightgbm.Rcheck/00check.log\"\n+\n+$env:_R_CHECK_FORCE_SUGGESTS_ = 0\n+if ($env:COMPILER -ne \"MINGW\") {\n+  Write-Output \"Running R CMD check without checking documentation\"\n+  R.exe CMD check --no-multiarch --no-examples --no-manual --ignore-vignettes ${PKG_FILE_NAME} ; $check_succeeded = $?\n+} else {\n+  Write-Output \"Running R CMD check as CRAN\"\n+  R.exe CMD check --no-multiarch --as-cran ${PKG_FILE_NAME} ; $check_succeeded = $?\n+}\n+\n+Write-Output \"R CMD check build logs:\"\n+Get-Content -Path $env:BUILD_SOURCESDIRECTORY\\lightgbm.Rcheck\\00install.out\n+\n+Check-Output $check_succeeded\n+\n+Write-Output \"Looking for issues with R CMD check results\"\n+if (Get-Content \"$LOG_FILE_NAME\" | Select-String -Pattern \"WARNING\" -Quiet) {\n+    echo \"WARNINGS have been found by R CMD check!\"\n+    Check-Output $False\n+}\n+\n+$note_str = Get-Content \"${LOG_FILE_NAME}\" | Select-String -Pattern ' NOTE' | Out-String ; Check-Output $?\n+$relevant_line = $note_str -match '.*Status: (\\d+) NOTE.*'\n+$NUM_CHECK_NOTES = $matches[1]\n+$ALLOWED_CHECK_NOTES = 3\n+if ([int]$NUM_CHECK_NOTES -gt $ALLOWED_CHECK_NOTES) {\n+    Write-Output \"Found ${NUM_CHECK_NOTES} NOTEs from R CMD check. Only ${ALLOWED_CHECK_NOTES} are allowed\"\n+    Check-Output $False\n+}\n+\n+Write-Output \"No issues were found checking the R package\"\ndiff --git a/.ci/test_windows.ps1 b/.ci/test_windows.ps1\nindex 82849577152d..fd0e9f95a5e4 100644\n--- a/.ci/test_windows.ps1\n+++ b/.ci/test_windows.ps1\n@@ -12,6 +12,11 @@ if (Test-Path env:APPVEYOR) {\n   $env:BUILD_SOURCESDIRECTORY = $env:APPVEYOR_BUILD_FOLDER\n }\n \n+if ($env:TASK -eq \"r-package\") {\n+  & $env:BUILD_SOURCESDIRECTORY\\.ci\\test_r_package_windows.ps1 ; Check-Output $?\n+  Exit 0\n+}\n+\n # setup for Python\n conda init powershell\n conda activate\ndiff --git a/.vsts-ci.yml b/.vsts-ci.yml\nindex a39dbc0e105b..a533ab1659e4 100644\n--- a/.vsts-ci.yml\n+++ b/.vsts-ci.yml\n@@ -22,7 +22,7 @@ jobs:\n     vmImage: 'ubuntu-latest'\n   container: ubuntu1404\n   strategy:\n-    maxParallel: 6\n+    maxParallel: 7\n     matrix:\n       regular:\n         TASK: regular\n@@ -76,7 +76,7 @@ jobs:\n   pool:\n     vmImage: 'macOS-10.14'\n   strategy:\n-    maxParallel: 3\n+    maxParallel: 4\n     matrix:\n       regular:\n         TASK: regular\n@@ -117,8 +117,11 @@ jobs:\n   pool:\n     vmImage: 'vs2017-win2016'\n   strategy:\n-    maxParallel: 3\n+    maxParallel: 4\n     matrix:\n+      r_package:\n+        TASK: r-package\n+        COMPILER: MINGW\n       regular:\n         TASK: regular\n         PYTHON_VERSION: 3.6\ndiff --git a/R-package/NAMESPACE b/R-package/NAMESPACE\nindex 7aef39a1f6de..14db7ba98d6c 100644\n--- a/R-package/NAMESPACE\n+++ b/R-package/NAMESPACE\n@@ -36,6 +36,7 @@ export(saveRDS.lgb.Booster)\n export(setinfo)\n export(slice)\n import(methods)\n+importFrom(Matrix,Matrix)\n importFrom(R6,R6Class)\n importFrom(data.table,\":=\")\n importFrom(data.table,as.data.table)\ndiff --git a/R-package/R/lightgbm.R b/R-package/R/lightgbm.R\nindex 9459ccc4d5c4..12640ecfb0af 100644\n--- a/R-package/R/lightgbm.R\n+++ b/R-package/R/lightgbm.R\n@@ -178,6 +178,7 @@ NULL\n \n # Various imports\n #' @import methods\n+#' @importFrom Matrix Matrix\n #' @importFrom R6 R6Class\n #' @useDynLib lib_lightgbm , .registration = TRUE\n NULL\ndiff --git a/R-package/src/cmake/modules/FindLibR.cmake b/R-package/src/cmake/modules/FindLibR.cmake\nindex 20c0a974e1ff..ad26f06dfeef 100644\n--- a/R-package/src/cmake/modules/FindLibR.cmake\n+++ b/R-package/src/cmake/modules/FindLibR.cmake\n@@ -174,17 +174,31 @@ execute_process(\n   OUTPUT_VARIABLE LIBR_LIB_DIR\n )\n \n+set(LIBR_HOME ${LIBR_HOME} CACHE PATH \"R home directory\")\n+set(LIBR_EXECUTABLE ${LIBR_EXECUTABLE} CACHE PATH \"R executable\")\n+set(LIBR_INCLUDE_DIRS ${LIBR_INCLUDE_DIRS} CACHE PATH \"R include directory\")\n+set(LIBR_LIB_DIR ${LIBR_LIB_DIR} CACHE PATH \"R shared libraries directory\")\n+\n+# where is R.so / R.dll / libR.so likely to be found?\n+set(LIBR_PATH_HINTS \"${CMAKE_CURRENT_BINARY_DIR}\" \"${LIBR_LIB_DIR}\" \"${LIBR_HOME}/bin/${R_ARCH}\" \"${LIBR_HOME}/bin\" \"${LIBR_LIBRARIES}\")\n+\n # look for the core R library\n find_library(\n   LIBR_CORE_LIBRARY\n-  NAMES R\n-  HINTS \"${CMAKE_CURRENT_BINARY_DIR}\" \"${LIBR_LIB_DIR}\" \"${LIBR_HOME}/bin\" \"${LIBR_LIBRARIES}\"\n+  NAMES R R.dll\n+  HINTS ${LIBR_PATH_HINTS}\n )\n \n-set(LIBR_HOME ${LIBR_HOME} CACHE PATH \"R home directory\")\n-set(LIBR_EXECUTABLE ${LIBR_EXECUTABLE} CACHE PATH \"R executable\")\n-set(LIBR_INCLUDE_DIRS ${LIBR_INCLUDE_DIRS} CACHE PATH \"R include directory\")\n-set(LIBR_LIB_DIR ${LIBR_LIB_DIR} CACHE PATH \"R shared libraries directory\")\n+# starting from CMake 3.17, find_library() will not find .dll files by default\n+# https://cmake.org/cmake/help/v3.17/release/3.17.html#other-changes\n+if (WIN32 AND NOT LIBR_CORE_LIBRARY)\n+    find_file(\n+        LIBR_CORE_LIBRARY\n+        NAME R.dll\n+        HINTS ${LIBR_PATH_HINTS}\n+    )\n+endif()\n+\n set(LIBR_CORE_LIBRARY ${LIBR_CORE_LIBRARY} CACHE PATH \"R core shared library\")\n \n if(WIN32 AND MSVC)\ndiff --git a/R-package/src/install.libs.R b/R-package/src/install.libs.R\nindex a79c93d846b7..339e8417ee70 100644\n--- a/R-package/src/install.libs.R\n+++ b/R-package/src/install.libs.R\n@@ -67,6 +67,7 @@ if (!use_precompile) {\n   # Check if Windows installation (for gcc vs Visual Studio)\n   if (WINDOWS) {\n     if (use_mingw) {\n+      print(\"Trying to build with MinGW\")\n       cmake_cmd <- paste0(cmake_cmd, \" -G \\\"MinGW Makefiles\\\" \")\n       build_cmd <- \"mingw32-make.exe _lightgbm\"\n       system(paste0(cmake_cmd, \" ..\")) # Must build twice for Windows due sh.exe in Rtools\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Remove `LIBR_LIB_DIR`** from `FindLibR.cmake` as it's unnecessary for finding `R.dll`. This will simplify build processes.\n\n2. **Investigate MSVC hangs** indicated during builds; currently, it's hanging on Azure but not locally. Consolidate MSVC-related changes into #2963. \n\n3. **Separate Python changes** into a new PR (#2962) to clarify reviews and reduce duplication.\n\n4. **Address warnings** related to `normalizePath()`, ensuring directories exist as required. Fixes are in #2963.\n\n5. **Merge strategy**:\n   - Merge #2936 first for CI coverage of the R package with MinGW.\n   - Follow with #2963 for Visual Studio fixes.\n   - Conclude with #2965 for enhanced CI and MSVC build improvements. \n\n6. **Monitor build and note counts** during checks and address as necessary to ensure compliance."
      }
    ],
    "codediff_length": 9691
  },
  {
    "index": 9,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.ci/test.sh b/.ci/test.sh\nindex 4cd181790ad7..cf3f51e3899a 100755\n--- a/.ci/test.sh\n+++ b/.ci/test.sh\n@@ -70,7 +70,7 @@ if [[ $TASK == \"if-else\" ]]; then\n     exit 0\n fi\n \n-conda install -q -y -n $CONDA_ENV joblib matplotlib numpy pandas psutil pytest python-graphviz scikit-learn scipy\n+conda install -q -y -n $CONDA_ENV dask dask-ml distributed joblib matplotlib numpy pandas psutil pytest python-graphviz scikit-learn scipy\n \n if [[ $OS_NAME == \"macos\" ]] && [[ $COMPILER == \"clang\" ]]; then\n     # fix \"OMP: Error #15: Initializing libiomp5.dylib, but found libomp.dylib already initialized.\" (OpenMP library conflict due to conda's MKL)\ndiff --git a/.github/CODEOWNERS b/.github/CODEOWNERS\nindex 7164a84e8ca5..7812ccdc3bff 100644\n--- a/.github/CODEOWNERS\n+++ b/.github/CODEOWNERS\n@@ -30,6 +30,10 @@ R-package/    @Laurae2 @jameslamb\n # Python code\n python-package/    @StrikerRUS @chivee @wxchan @henry0312\n \n+# Dask integration\n+python-package/lightgbm/dask.py    @jameslamb\n+tests/python_package_test/test_dask.py    @jameslamb\n+\n # helpers\n helpers/    @StrikerRUS @guolinke\n \ndiff --git a/python-package/lightgbm/dask.py b/python-package/lightgbm/dask.py\nnew file mode 100644\nindex 000000000000..66ab83591cdb\n--- /dev/null\n+++ b/python-package/lightgbm/dask.py\n@@ -0,0 +1,280 @@\n+# coding: utf-8\n+\"\"\"Distributed training with LightGBM and Dask.distributed.\n+\n+This module enables you to perform distributed training with LightGBM on Dask.Array and Dask.DataFrame collections.\n+It is based on dask-xgboost package.\n+\"\"\"\n+import logging\n+from collections import defaultdict\n+from urllib.parse import urlparse\n+\n+import numpy as np\n+import pandas as pd\n+from dask import array as da\n+from dask import dataframe as dd\n+from dask import delayed\n+from dask.distributed import default_client, get_worker, wait\n+\n+from .basic import _LIB, _safe_call\n+from .sklearn import LGBMClassifier, LGBMRegressor\n+\n+import scipy.sparse as ss\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+def _parse_host_port(address):\n+    parsed = urlparse(address)\n+    return parsed.hostname, parsed.port\n+\n+\n+def _build_network_params(worker_addresses, local_worker_ip, local_listen_port, time_out):\n+    \"\"\"Build network parameters suitable for LightGBM C backend.\n+\n+    Parameters\n+    ----------\n+    worker_addresses : iterable of str - collection of worker addresses in `<protocol>://<host>:port` format\n+    local_worker_ip : str\n+    local_listen_port : int\n+    time_out : int\n+\n+    Returns\n+    -------\n+    params: dict\n+    \"\"\"\n+    addr_port_map = {addr: (local_listen_port + i) for i, addr in enumerate(worker_addresses)}\n+    params = {\n+        'machines': ','.join('%s:%d' % (_parse_host_port(addr)[0], port) for addr, port in addr_port_map.items()),\n+        'local_listen_port': addr_port_map[local_worker_ip],\n+        'time_out': time_out,\n+        'num_machines': len(addr_port_map)\n+    }\n+    return params\n+\n+\n+def _concat(seq):\n+    if isinstance(seq[0], np.ndarray):\n+        return np.concatenate(seq, axis=0)\n+    elif isinstance(seq[0], (pd.DataFrame, pd.Series)):\n+        return pd.concat(seq, axis=0)\n+    elif isinstance(seq[0], ss.spmatrix):\n+        return ss.vstack(seq, format='csr')\n+    else:\n+        raise TypeError('Data must be one of: numpy arrays, pandas dataframes, sparse matrices (from scipy). Got %s.' % str(type(seq[0])))\n+\n+\n+def _train_part(params, model_factory, list_of_parts, worker_addresses, return_model, local_listen_port=12400,\n+                time_out=120, **kwargs):\n+    network_params = _build_network_params(worker_addresses, get_worker().address, local_listen_port, time_out)\n+    params.update(network_params)\n+\n+    # Concatenate many parts into one\n+    parts = tuple(zip(*list_of_parts))\n+    data = _concat(parts[0])\n+    label = _concat(parts[1])\n+    weight = _concat(parts[2]) if len(parts) == 3 else None\n+\n+    try:\n+        model = model_factory(**params)\n+        model.fit(data, label, sample_weight=weight, **kwargs)\n+    finally:\n+        _safe_call(_LIB.LGBM_NetworkFree())\n+\n+    return model if return_model else None\n+\n+\n+def _split_to_parts(data, is_matrix):\n+    parts = data.to_delayed()\n+    if isinstance(parts, np.ndarray):\n+        assert (parts.shape[1] == 1) if is_matrix else (parts.ndim == 1 or parts.shape[1] == 1)\n+        parts = parts.flatten().tolist()\n+    return parts\n+\n+\n+def _train(client, data, label, params, model_factory, weight=None, **kwargs):\n+    \"\"\"Inner train routine.\n+\n+    Parameters\n+    ----------\n+    client: dask.Client - client\n+    X : dask array of shape = [n_samples, n_features]\n+        Input feature matrix.\n+    y : dask array of shape = [n_samples]\n+        The target values (class labels in classification, real numbers in regression).\n+    params : dict\n+    model_factory : lightgbm.LGBMClassifier or lightgbm.LGBMRegressor class\n+    sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n+            Weights of training data.\n+    \"\"\"\n+    # Split arrays/dataframes into parts. Arrange parts into tuples to enforce co-locality\n+    data_parts = _split_to_parts(data, is_matrix=True)\n+    label_parts = _split_to_parts(label, is_matrix=False)\n+    if weight is None:\n+        parts = list(map(delayed, zip(data_parts, label_parts)))\n+    else:\n+        weight_parts = _split_to_parts(weight, is_matrix=False)\n+        parts = list(map(delayed, zip(data_parts, label_parts, weight_parts)))\n+\n+    # Start computation in the background\n+    parts = client.compute(parts)\n+    wait(parts)\n+\n+    for part in parts:\n+        if part.status == 'error':\n+            return part  # trigger error locally\n+\n+    # Find locations of all parts and map them to particular Dask workers\n+    key_to_part_dict = dict([(part.key, part) for part in parts])\n+    who_has = client.who_has(parts)\n+    worker_map = defaultdict(list)\n+    for key, workers in who_has.items():\n+        worker_map[next(iter(workers))].append(key_to_part_dict[key])\n+\n+    master_worker = next(iter(worker_map))\n+    worker_ncores = client.ncores()\n+\n+    if 'tree_learner' not in params or params['tree_learner'].lower() not in {'data', 'feature', 'voting'}:\n+        logger.warning('Parameter tree_learner not set or set to incorrect value '\n+                       '(%s), using \"data\" as default', params.get(\"tree_learner\", None))\n+        params['tree_learner'] = 'data'\n+\n+    # Tell each worker to train on the parts that it has locally\n+    futures_classifiers = [client.submit(_train_part,\n+                                         model_factory=model_factory,\n+                                         params={**params, 'num_threads': worker_ncores[worker]},\n+                                         list_of_parts=list_of_parts,\n+                                         worker_addresses=list(worker_map.keys()),\n+                                         local_listen_port=params.get('local_listen_port', 12400),\n+                                         time_out=params.get('time_out', 120),\n+                                         return_model=(worker == master_worker),\n+                                         **kwargs)\n+                           for worker, list_of_parts in worker_map.items()]\n+\n+    results = client.gather(futures_classifiers)\n+    results = [v for v in results if v]\n+    return results[0]\n+\n+\n+def _predict_part(part, model, proba, **kwargs):\n+    data = part.values if isinstance(part, pd.DataFrame) else part\n+\n+    if data.shape[0] == 0:\n+        result = np.array([])\n+    elif proba:\n+        result = model.predict_proba(data, **kwargs)\n+    else:\n+        result = model.predict(data, **kwargs)\n+\n+    if isinstance(part, pd.DataFrame):\n+        if proba:\n+            result = pd.DataFrame(result, index=part.index)\n+        else:\n+            result = pd.Series(result, index=part.index, name='predictions')\n+\n+    return result\n+\n+\n+def _predict(model, data, proba=False, dtype=np.float32, **kwargs):\n+    \"\"\"Inner predict routine.\n+\n+    Parameters\n+    ----------\n+    model :\n+    data : dask array of shape = [n_samples, n_features]\n+        Input feature matrix.\n+    proba : bool\n+        Should method return results of predict_proba (proba == True) or predict (proba == False)\n+    dtype : np.dtype\n+        Dtype of the output\n+    kwargs : other parameters passed to predict or predict_proba method\n+    \"\"\"\n+    if isinstance(data, dd._Frame):\n+        return data.map_partitions(_predict_part, model=model, proba=proba, **kwargs).values\n+    elif isinstance(data, da.Array):\n+        if proba:\n+            kwargs['chunks'] = (data.chunks[0], (model.n_classes_,))\n+        else:\n+            kwargs['drop_axis'] = 1\n+        return data.map_blocks(_predict_part, model=model, proba=proba, dtype=dtype, **kwargs)\n+    else:\n+        raise TypeError('Data must be either Dask array or dataframe. Got %s.' % str(type(data)))\n+\n+\n+class _LGBMModel:\n+\n+    def _fit(self, model_factory, X, y=None, sample_weight=None, client=None, **kwargs):\n+        \"\"\"Docstring is inherited from the LGBMModel.\"\"\"\n+        if client is None:\n+            client = default_client()\n+\n+        params = self.get_params(True)\n+        model = _train(client, X, y, params, model_factory, sample_weight, **kwargs)\n+\n+        self.set_params(**model.get_params())\n+        self._copy_extra_params(model, self)\n+\n+        return self\n+\n+    def _to_local(self, model_factory):\n+        model = model_factory(**self.get_params())\n+        self._copy_extra_params(self, model)\n+        return model\n+\n+    @staticmethod\n+    def _copy_extra_params(source, dest):\n+        params = source.get_params()\n+        attributes = source.__dict__\n+        extra_param_names = set(attributes.keys()).difference(params.keys())\n+        for name in extra_param_names:\n+            setattr(dest, name, attributes[name])\n+\n+\n+class DaskLGBMClassifier(_LGBMModel, LGBMClassifier):\n+    \"\"\"Distributed version of lightgbm.LGBMClassifier.\"\"\"\n+\n+    def fit(self, X, y=None, sample_weight=None, client=None, **kwargs):\n+        \"\"\"Docstring is inherited from the LGBMModel.\"\"\"\n+        return self._fit(LGBMClassifier, X, y, sample_weight, client, **kwargs)\n+    fit.__doc__ = LGBMClassifier.fit.__doc__\n+\n+    def predict(self, X, **kwargs):\n+        \"\"\"Docstring is inherited from the lightgbm.LGBMClassifier.predict.\"\"\"\n+        return _predict(self.to_local(), X, dtype=self.classes_.dtype, **kwargs)\n+    predict.__doc__ = LGBMClassifier.predict.__doc__\n+\n+    def predict_proba(self, X, **kwargs):\n+        \"\"\"Docstring is inherited from the lightgbm.LGBMClassifier.predict_proba.\"\"\"\n+        return _predict(self.to_local(), X, proba=True, **kwargs)\n+    predict_proba.__doc__ = LGBMClassifier.predict_proba.__doc__\n+\n+    def to_local(self):\n+        \"\"\"Create regular version of lightgbm.LGBMClassifier from the distributed version.\n+\n+        Returns\n+        -------\n+        model : lightgbm.LGBMClassifier\n+        \"\"\"\n+        return self._to_local(LGBMClassifier)\n+\n+\n+class DaskLGBMRegressor(_LGBMModel, LGBMRegressor):\n+    \"\"\"Docstring is inherited from the lightgbm.LGBMRegressor.\"\"\"\n+\n+    def fit(self, X, y=None, sample_weight=None, client=None, **kwargs):\n+        \"\"\"Docstring is inherited from the lightgbm.LGBMRegressor.fit.\"\"\"\n+        return self._fit(LGBMRegressor, X, y, sample_weight, client, **kwargs)\n+    fit.__doc__ = LGBMRegressor.fit.__doc__\n+\n+    def predict(self, X, **kwargs):\n+        \"\"\"Docstring is inherited from the lightgbm.LGBMRegressor.predict.\"\"\"\n+        return _predict(self.to_local(), X, **kwargs)\n+    predict.__doc__ = LGBMRegressor.predict.__doc__\n+\n+    def to_local(self):\n+        \"\"\"Create regular version of lightgbm.LGBMRegressor from the distributed version.\n+\n+        Returns\n+        -------\n+        model : lightgbm.LGBMRegressor\n+        \"\"\"\n+        return self._to_local(LGBMRegressor)\ndiff --git a/python-package/setup.py b/python-package/setup.py\nindex a2e8a0cf3560..02ba32f3549c 100644\n--- a/python-package/setup.py\n+++ b/python-package/setup.py\n@@ -340,6 +340,14 @@ def run(self):\n               'scipy',\n               'scikit-learn!=0.22.0'\n           ],\n+          extras_require={\n+              'dask': [\n+                  'dask[array]>=2.0.0',\n+                  'dask[dataframe]>=2.0.0'\n+                  'dask[distributed]>=2.0.0',\n+                  'pandas',\n+              ],\n+          },\n           maintainer='Guolin Ke',\n           maintainer_email='guolin.ke@microsoft.com',\n           zip_safe=False,\ndiff --git a/tests/python_package_test/test_dask.py b/tests/python_package_test/test_dask.py\nnew file mode 100644\nindex 000000000000..d512cfcbda63\n--- /dev/null\n+++ b/tests/python_package_test/test_dask.py\n@@ -0,0 +1,212 @@\n+# coding: utf-8\n+import os\n+import sys\n+\n+import pytest\n+if not sys.platform.startswith(\"linux\"):\n+    pytest.skip(\"lightgbm.dask is currently supported in Linux environments\", allow_module_level=True)\n+\n+import dask.array as da\n+import dask.dataframe as dd\n+import numpy as np\n+import pandas as pd\n+import scipy.sparse\n+from dask.array.utils import assert_eq\n+from dask_ml.metrics import accuracy_score, r2_score\n+from distributed.utils_test import client, cluster_fixture, gen_cluster, loop\n+from sklearn.datasets import make_blobs, make_regression\n+\n+import lightgbm\n+import lightgbm.dask as dlgbm\n+\n+data_output = ['array', 'scipy_csr_matrix', 'dataframe']\n+data_centers = [[[-4, -4], [4, 4]], [[-4, -4], [4, 4], [-4, 4]]]\n+\n+pytestmark = [\n+    pytest.mark.skipif(os.getenv(\"TASK\", \"\") == \"mpi\", reason=\"Fails to run with MPI interface\")\n+]\n+\n+\n+@pytest.fixture()\n+def listen_port():\n+    listen_port.port += 10\n+    return listen_port.port\n+\n+\n+listen_port.port = 13000\n+\n+\n+def _create_data(objective, n_samples=100, centers=2, output='array', chunk_size=50):\n+    if objective == 'classification':\n+        X, y = make_blobs(n_samples=n_samples, centers=centers, random_state=42)\n+    elif objective == 'regression':\n+        X, y = make_regression(n_samples=n_samples, random_state=42)\n+    else:\n+        raise ValueError(objective)\n+    rnd = np.random.RandomState(42)\n+    weights = rnd.random(X.shape[0]) * 0.01\n+\n+    if output == 'array':\n+        dX = da.from_array(X, (chunk_size, X.shape[1]))\n+        dy = da.from_array(y, chunk_size)\n+        dw = da.from_array(weights, chunk_size)\n+    elif output == 'dataframe':\n+        X_df = pd.DataFrame(X, columns=['feature_%d' % i for i in range(X.shape[1])])\n+        y_df = pd.Series(y, name='target')\n+        dX = dd.from_pandas(X_df, chunksize=chunk_size)\n+        dy = dd.from_pandas(y_df, chunksize=chunk_size)\n+        dw = dd.from_array(weights, chunksize=chunk_size)\n+    elif output == 'scipy_csr_matrix':\n+        dX = da.from_array(X, chunks=(chunk_size, X.shape[1])).map_blocks(scipy.sparse.csr_matrix)\n+        dy = da.from_array(y, chunks=chunk_size)\n+        dw = da.from_array(weights, chunk_size)\n+    else:\n+        raise ValueError(\"Unknown output type %s\" % output)\n+\n+    return X, y, weights, dX, dy, dw\n+\n+\n+@pytest.mark.parametrize('output', data_output)\n+@pytest.mark.parametrize('centers', data_centers)\n+def test_classifier(output, centers, client, listen_port):\n+    X, y, w, dX, dy, dw = _create_data('classification', output=output, centers=centers)\n+\n+    dask_classifier = dlgbm.DaskLGBMClassifier(time_out=5, local_listen_port=listen_port)\n+    dask_classifier = dask_classifier.fit(dX, dy, sample_weight=dw, client=client)\n+    p1 = dask_classifier.predict(dX)\n+    s1 = accuracy_score(dy, p1)\n+    p1 = p1.compute()\n+\n+    local_classifier = lightgbm.LGBMClassifier()\n+    local_classifier.fit(X, y, sample_weight=w)\n+    p2 = local_classifier.predict(X)\n+    s2 = local_classifier.score(X, y)\n+\n+    assert_eq(s1, s2)\n+\n+    assert_eq(p1, p2)\n+    assert_eq(y, p1)\n+    assert_eq(y, p2)\n+\n+\n+@pytest.mark.parametrize('output', data_output)\n+@pytest.mark.parametrize('centers', data_centers)\n+def test_classifier_proba(output, centers, client, listen_port):\n+    X, y, w, dX, dy, dw = _create_data('classification', output=output, centers=centers)\n+\n+    dask_classifier = dlgbm.DaskLGBMClassifier(time_out=5, local_listen_port=listen_port)\n+    dask_classifier = dask_classifier.fit(dX, dy, sample_weight=dw, client=client)\n+    p1 = dask_classifier.predict_proba(dX)\n+    p1 = p1.compute()\n+\n+    local_classifier = lightgbm.LGBMClassifier()\n+    local_classifier.fit(X, y, sample_weight=w)\n+    p2 = local_classifier.predict_proba(X)\n+\n+    assert_eq(p1, p2, atol=0.3)\n+\n+\n+def test_classifier_local_predict(client, listen_port):\n+    X, y, w, dX, dy, dw = _create_data('classification', output='array')\n+\n+    dask_classifier = dlgbm.DaskLGBMClassifier(time_out=5, local_listen_port=listen_port)\n+    dask_classifier = dask_classifier.fit(dX, dy, sample_weight=dw, client=client)\n+    p1 = dask_classifier.to_local().predict(dX)\n+\n+    local_classifier = lightgbm.LGBMClassifier()\n+    local_classifier.fit(X, y, sample_weight=w)\n+    p2 = local_classifier.predict(X)\n+\n+    assert_eq(p1, p2)\n+    assert_eq(y, p1)\n+    assert_eq(y, p2)\n+\n+\n+@pytest.mark.parametrize('output', data_output)\n+def test_regressor(output, client, listen_port):\n+    X, y, w, dX, dy, dw = _create_data('regression', output=output)\n+\n+    dask_regressor = dlgbm.DaskLGBMRegressor(time_out=5, local_listen_port=listen_port, seed=42)\n+    dask_regressor = dask_regressor.fit(dX, dy, client=client, sample_weight=dw)\n+    p1 = dask_regressor.predict(dX)\n+    if output != 'dataframe':\n+        s1 = r2_score(dy, p1)\n+    p1 = p1.compute()\n+\n+    local_regressor = lightgbm.LGBMRegressor(seed=42)\n+    local_regressor.fit(X, y, sample_weight=w)\n+    s2 = local_regressor.score(X, y)\n+    p2 = local_regressor.predict(X)\n+\n+    # Scores should be the same\n+    if output != 'dataframe':\n+        assert_eq(s1, s2, atol=.01)\n+\n+    # Predictions should be roughly the same\n+    assert_eq(y, p1, rtol=1., atol=100.)\n+    assert_eq(y, p2, rtol=1., atol=50.)\n+\n+\n+@pytest.mark.parametrize('output', data_output)\n+@pytest.mark.parametrize('alpha', [.1, .5, .9])\n+def test_regressor_quantile(output, client, listen_port, alpha):\n+    X, y, w, dX, dy, dw = _create_data('regression', output=output)\n+\n+    dask_regressor = dlgbm.DaskLGBMRegressor(local_listen_port=listen_port, seed=42, objective='quantile', alpha=alpha)\n+    dask_regressor = dask_regressor.fit(dX, dy, client=client, sample_weight=dw)\n+    p1 = dask_regressor.predict(dX).compute()\n+    q1 = np.count_nonzero(y < p1) / y.shape[0]\n+\n+    local_regressor = lightgbm.LGBMRegressor(seed=42, objective='quantile', alpha=alpha)\n+    local_regressor.fit(X, y, sample_weight=w)\n+    p2 = local_regressor.predict(X)\n+    q2 = np.count_nonzero(y < p2) / y.shape[0]\n+\n+    # Quantiles should be right\n+    np.testing.assert_allclose(q1, alpha, atol=0.2)\n+    np.testing.assert_allclose(q2, alpha, atol=0.2)\n+\n+\n+def test_regressor_local_predict(client, listen_port):\n+    X, y, w, dX, dy, dw = _create_data('regression', output='array')\n+\n+    dask_regressor = dlgbm.DaskLGBMRegressor(local_listen_port=listen_port, seed=42)\n+    dask_regressor = dask_regressor.fit(dX, dy, sample_weight=dw, client=client)\n+    p1 = dask_regressor.predict(dX)\n+    p2 = dask_regressor.to_local().predict(X)\n+    s1 = r2_score(dy, p1)\n+    p1 = p1.compute()\n+    s2 = dask_regressor.to_local().score(X, y)\n+\n+    # Predictions and scores should be the same\n+    assert_eq(p1, p2)\n+    assert_eq(s1, s2)\n+\n+\n+def test_build_network_params():\n+    workers_ips = [\n+        'tcp://192.168.0.1:34545',\n+        'tcp://192.168.0.2:34346',\n+        'tcp://192.168.0.3:34347'\n+    ]\n+\n+    params = dlgbm._build_network_params(workers_ips, 'tcp://192.168.0.2:34346', 12400, 120)\n+    exp_params = {\n+        'machines': '192.168.0.1:12400,192.168.0.2:12401,192.168.0.3:12402',\n+        'local_listen_port': 12401,\n+        'num_machines': len(workers_ips),\n+        'time_out': 120\n+    }\n+    assert exp_params == params\n+\n+\n+@gen_cluster(client=True, timeout=None)\n+def test_errors(c, s, a, b):\n+    def f(part):\n+        raise Exception('foo')\n+\n+    df = dd.demo.make_timeseries()\n+    df = df.map_partitions(f, meta=df._meta)\n+    with pytest.raises(Exception) as info:\n+        yield dlgbm._train(c, df, df.x, params={}, model_factory=lightgbm.LGBMClassifier)\n+        assert 'foo' in str(info.value)\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "**Actionable Feedback:**\n\n1. **Ensure Git Commit Attribution:** Your commits appear anonymous. Reconfigure your Git with an email associated with your GitHub account to ensure you'll be credited as a contributor. \n\n2. **CI Builds:** The Windows CI failures stem from skipping `dask` installations. Modify `test_dask.py` to conditionally import `dask`:\n   ```python\n   if sys.platform.startswith(\"win\"):\n       pytest.skip(\"lightgbm.dask is not supported in Windows environments\", allow_module_level=True)\n   ```\n\n3. **Remove Python 2.7 Support:** The integration will require removing Python 2.7 from CI shortly, as compatibility issues arise with `lightgbm.dask`.\n\n4. **Package Structure:** Recommend keeping Dask integration within `lightgbm`, leveraging optional dependencies to minimize impact. Avoid creating a separate package (e.g., `lightgbm-dask`) to prevent user confusion.\n\n5. **Rerun CI Pipelines:** @jameslamb to rerun the Travis pipeline due to potential random failures."
      }
    ],
    "codediff_length": 20372
  },
  {
    "index": 10,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.appveyor.yml b/.appveyor.yml\nindex f27fa78fb89c..1fac92b57269 100644\n--- a/.appveyor.yml\n+++ b/.appveyor.yml\n@@ -15,8 +15,12 @@ environment:\n   matrix:\n     - COMPILER: MINGW\n       TASK: r-package\n-    - COMPILER: MSVC\n+      R_VERSION: 3.6\n+      TOOLCHAIN: MINGW\n+    - COMPILER: MSVC \n       TASK: r-package\n+      R_VERSION: 4.0\n+      TOOLCHAIN: MSVC\n       APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2019\n     - COMPILER: MSVC\n       TASK: python\ndiff --git a/.ci/test_r_package.sh b/.ci/test_r_package.sh\nindex 5fb35bb887b1..3788a1349770 100755\n--- a/.ci/test_r_package.sh\n+++ b/.ci/test_r_package.sh\n@@ -7,6 +7,26 @@ mkdir -p $R_LIB_PATH\n echo \"R_LIBS=$R_LIB_PATH\" > ${HOME}/.Renviron\n export PATH=\"$R_LIB_PATH/R/bin:$PATH\"\n \n+# Get details needed for installing R components\n+#\n+# NOTES:\n+#    * Linux builds on Azure use a container and don't need these details\n+if ! { [[ $AZURE == \"true\" ]] && [[ $OS_NAME == \"linux\" ]]; }; then\n+    R_MAJOR_VERSION=( ${R_VERSION//./ } )\n+    if [[ \"${R_MAJOR_VERSION}\" == \"3\" ]]; then\n+        export R_MAC_VERSION=3.6.3\n+        export R_LINUX_VERSION=\"3.6.3-1bionic\"\n+        export R_APT_REPO=\"bionic-cran35/\"\n+    elif [[ \"${R_MAJOR_VERSION}\" == \"4\" ]]; then\n+        export R_MAC_VERSION=4.0.0\n+        export R_LINUX_VERSION=\"4.0.0-1.1804.0\"\n+        export R_APT_REPO=\"bionic-cran40/\"\n+    else\n+        echo \"Unrecognized R version: ${R_VERSION}\"\n+        exit -1\n+    fi\n+fi\n+\n # installing precompiled R for Ubuntu\n # https://cran.r-project.org/bin/linux/ubuntu/#installation\n # adding steps from https://stackoverflow.com/a/56378217/3986677 to get latest version\n@@ -18,7 +38,7 @@ if [[ $AZURE != \"true\" ]] && [[ $OS_NAME == \"linux\" ]]; then\n         --keyserver keyserver.ubuntu.com \\\n         --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\n     sudo add-apt-repository \\\n-        \"deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/\"\n+        \"deb https://cloud.r-project.org/bin/linux/ubuntu ${R_APT_REPO}\"\n     sudo apt-get update\n     sudo apt-get install \\\n         --no-install-recommends \\\ndiff --git a/.ci/test_r_package_windows.ps1 b/.ci/test_r_package_windows.ps1\nindex 6ed536d4060b..61a51472d98b 100644\n--- a/.ci/test_r_package_windows.ps1\n+++ b/.ci/test_r_package_windows.ps1\n@@ -29,34 +29,60 @@ function Download-Miktex-Setup {\n     Download-File-With-Retries $FileToDownload $destfile\n }\n \n-$env:R_WINDOWS_VERSION = \"3.6.3\"\n $env:R_LIB_PATH = \"$env:BUILD_SOURCESDIRECTORY/RLibrary\" -replace '[\\\\]', '/'\n $env:R_LIBS = \"$env:R_LIB_PATH\"\n-$env:PATH = \"$env:R_LIB_PATH/Rtools/bin;\" + \"$env:R_LIB_PATH/R/bin/x64;\" + \"$env:R_LIB_PATH/miktex/texmfs/install/miktex/bin/x64;\" + $env:PATH\n+$env:PATH = \"$env:R_LIB_PATH/Rtools/bin;\" + \"$env:R_LIB_PATH/Rtools/usr/bin;\" + \"$env:R_LIB_PATH/R/bin/x64;\" + \"$env:R_LIB_PATH/miktex/texmfs/install/miktex/bin/x64;\" + $env:PATH\n $env:CRAN_MIRROR = \"https://cloud.r-project.org/\"\n $env:CTAN_MIRROR = \"https://ctan.math.illinois.edu/systems/win32/miktex\"\n $env:CTAN_MIKTEX_ARCHIVE = \"$env:CTAN_MIRROR/setup/windows-x64/\"\n $env:CTAN_PACKAGE_ARCHIVE = \"$env:CTAN_MIRROR/tm/packages/\"\n \n+# Get details needed for installing R components\n+#\n+# NOTES:\n+#    * some paths and file names are different on R4.0\n+$env:R_MAJOR_VERSION = $env:R_VERSION.split('.')[0]\n+if ($env:R_MAJOR_VERSION -eq \"3\") {\n+  $env:RTOOLS_MINGW_BIN = \"$env:R_LIB_PATH/Rtools/mingw_64/bin\"\n+  $env:RTOOLS_EXE_FILE = \"Rtools35.exe\"\n+  $env:R_WINDOWS_VERSION = \"3.6.3\"\n+} elseif ($env:R_MAJOR_VERSION -eq \"4\") {\n+  $env:RTOOLS_MINGW_BIN = \"$env:R_LIB_PATH/Rtools/mingw64/bin\"\n+  $env:RTOOLS_EXE_FILE = \"rtools40-x86_64.exe\"\n+  $env:R_WINDOWS_VERSION = \"4.0.0\"\n+} else {\n+  Write-Output \"[ERROR] Unrecognized R version: $env:R_VERSION\"\n+  Check-Output $false\n+}\n+\n if ($env:COMPILER -eq \"MINGW\") {\n-  $env:CXX = \"$env:R_LIB_PATH/Rtools/mingw_64/bin/g++.exe\"\n-  $env:CC = \"$env:R_LIB_PATH/Rtools/mingw_64/bin/gcc.exe\"\n+  $env:CXX = \"$env:RTOOLS_MINGW_BIN/g++.exe\"\n+  $env:CC = \"$env:RTOOLS_MINGW_BIN/gcc.exe\"\n }\n \n cd $env:BUILD_SOURCESDIRECTORY\n tzutil /s \"GMT Standard Time\"\n [Void][System.IO.Directory]::CreateDirectory($env:R_LIB_PATH)\n \n-if ($env:COMPILER -eq \"MINGW\") {\n+if ($env:TOOLCHAIN -eq \"MINGW\") {\n   Write-Output \"Telling R to use MinGW\"\n   $install_libs = \"$env:BUILD_SOURCESDIRECTORY/R-package/src/install.libs.R\"\n-  ((Get-Content -path $install_libs -Raw) -replace 'use_mingw <- FALSE','use_mingw <- TRUE') | Set-Content -Path $install_libs\n+  ((Get-Content -Path $install_libs -Raw) -Replace 'use_mingw <- FALSE','use_mingw <- TRUE') | Set-Content -Path $install_libs\n+} elseif ($env:TOOLCHAIN -eq \"MSYS\") {\n+  Write-Output \"Telling R to use MSYS\"\n+  $install_libs = \"$env:BUILD_SOURCESDIRECTORY/R-package/src/install.libs.R\"\n+  ((Get-Content -Path $install_libs -Raw) -Replace 'use_msys2 <- FALSE','use_msys2 <- TRUE') | Set-Content -Path $install_libs\n+} elseif ($env:TOOLCHAIN -eq \"MSVC\") {\n+  # no customization for MSVC\n+} else {\n+  Write-Output \"[ERROR] Unrecognized compiler: $env:TOOLCHAIN\"\n+  Check-Output $false\n }\n \n # download R and RTools\n Write-Output \"Downloading R and Rtools\"\n Download-File-With-Retries -url \"https://cloud.r-project.org/bin/windows/base/old/$env:R_WINDOWS_VERSION/R-$env:R_WINDOWS_VERSION-win.exe\" -destfile \"R-win.exe\"\n-Download-File-With-Retries -url \"https://cloud.r-project.org/bin/windows/Rtools/Rtools35.exe\" -destfile \"Rtools.exe\"\n+Download-File-With-Retries -url \"https://cloud.r-project.org/bin/windows/Rtools/$env:RTOOLS_EXE_FILE\" -destfile \"Rtools.exe\"\n \n # Install R\n Write-Output \"Installing R\"\n@@ -67,9 +93,9 @@ Write-Output \"Installing Rtools\"\n Start-Process -FilePath Rtools.exe -NoNewWindow -Wait -ArgumentList \"/VERYSILENT /DIR=$env:R_LIB_PATH/Rtools\" ; Check-Output $?\n Write-Output \"Done installing Rtools\"\n \n-# MiKTeX and pandoc can be skipped on non-MINGW builds, since we don't\n+# MiKTeX and pandoc can be skipped on MSVC builds, since we don't\n # build the package documentation for those\n-if ($env:COMPILER -eq \"MINGW\") {\n+if ($env:COMPILER -ne \"MSVC\") {\n     Download-Miktex-Setup \"$env:CTAN_MIKTEX_ARCHIVE\" \"miktexsetup-x64.zip\"\n     Add-Type -AssemblyName System.IO.Compression.FileSystem\n     [System.IO.Compression.ZipFile]::ExtractToDirectory(\"miktexsetup-x64.zip\", \"miktex\")\n@@ -115,7 +141,7 @@ if ($env:COMPILER -ne \"MSVC\") {\n   $note_str = Get-Content \"${LOG_FILE_NAME}\" | Select-String -Pattern ' NOTE' | Out-String ; Check-Output $?\n   $relevant_line = $note_str -match '.*Status: (\\d+) NOTE.*'\n   $NUM_CHECK_NOTES = $matches[1]\n-  $ALLOWED_CHECK_NOTES = 3\n+  $ALLOWED_CHECK_NOTES = 4\n   if ([int]$NUM_CHECK_NOTES -gt $ALLOWED_CHECK_NOTES) {\n       Write-Output \"Found ${NUM_CHECK_NOTES} NOTEs from R CMD check. Only ${ALLOWED_CHECK_NOTES} are allowed\"\n       Check-Output $False\n@@ -139,6 +165,16 @@ if ($checks.Matches.length -eq 0) {\n   Check-Output $False\n }\n \n+# Checking that we got the right toolchain for MinGW. If using MinGW, both\n+# MinGW and MSYS toolchains are supported\n+if ($env:COMPILER -eq \"MINGW\") {\n+  $checks = Select-String -Path \"${INSTALL_LOG_FILE_NAME}\" -Pattern \"Trying to build with.*$env:TOOLCHAIN\"\n+  if ($checks.Matches.length -eq 0) {\n+    Write-Output \"The wrong toolchain was used. Check the build logs.\"\n+    Check-Output $False\n+  }\n+}\n+\n if ($env:COMPILER -eq \"MSVC\") {\n   Write-Output \"Running tests with testthat.R\"\n   cd R-package/tests\ndiff --git a/.github/workflows/main.yml b/.github/workflows/main.yml\nindex eefebe2a9cb2..2547e17970b3 100644\n--- a/.github/workflows/main.yml\n+++ b/.github/workflows/main.yml\n@@ -10,7 +10,7 @@ on:\n \n jobs:\n   test:\n-    name: ${{ matrix.task }} (${{ matrix.os }}, ${{ matrix.compiler }})\n+    name: ${{ matrix.task }} (${{ matrix.os }}, ${{ matrix.compiler }}, R ${{ matrix.r_version }})\n     runs-on: ${{ matrix.os }}\n     strategy:\n       fail-fast: false\n@@ -19,15 +19,35 @@ jobs:\n           - os: ubuntu-latest\n             task: r-package\n             compiler: gcc\n+            r_version: 3.6\n+          - os: ubuntu-latest\n+            task: r-package\n+            compiler: gcc\n+            r_version: 4.0\n+          - os: ubuntu-latest\n+            task: r-package\n+            compiler: clang\n+            r_version: 3.6\n           - os: ubuntu-latest\n             task: r-package\n             compiler: clang\n+            r_version: 4.0\n           - os: macOS-latest\n             task: r-package\n             compiler: gcc\n+            r_version: 3.6\n+          - os: macOS-latest\n+            task: r-package\n+            compiler: gcc\n+            r_version: 4.0\n+          - os: macOS-latest\n+            task: r-package\n+            compiler: clang\n+            r_version: 3.6\n           - os: macOS-latest\n             task: r-package\n             compiler: clang\n+            r_version: 4.0\n     steps:\n       - name: Checkout repository\n         uses: actions/checkout@v1\n@@ -53,5 +73,6 @@ jobs:\n           export CONDA=\"$HOME/miniconda\"\n           export PATH=\"$CONDA/bin:${HOME}/.local/bin:$PATH\"\n           export LGB_VER=$(head -n 1 VERSION.txt)\n+          export R_VERSION=\"${{ matrix.r_version }}\"\n           $GITHUB_WORKSPACE/.ci/setup.sh\n           $GITHUB_WORKSPACE/.ci/test.sh\ndiff --git a/.gitignore b/.gitignore\nindex c5bcfa0337fa..86fe00d92750 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -406,6 +406,7 @@ R-package/src-i386\n lightgbm_r/*\n lightgbm*.tar.gz\n lightgbm.Rcheck/\n+*.def\n \n # Files created by R examples and tests\n **/lgb-Dataset.data\ndiff --git a/.vsts-ci.yml b/.vsts-ci.yml\nindex 7c4e71d2eb30..41265d470c3f 100644\n--- a/.vsts-ci.yml\n+++ b/.vsts-ci.yml\n@@ -109,11 +109,18 @@ jobs:\n   pool:\n     vmImage: 'vs2017-win2016'\n   strategy:\n-    maxParallel: 4\n+    maxParallel: 5\n     matrix:\n-      r_package:\n+      r_package_msvc:\n         TASK: r-package\n         COMPILER: MSVC\n+        R_VERSION: 3.6\n+        TOOLCHAIN: MSVC\n+      r_package_msys:\n+        TASK: r-package\n+        COMPILER: MINGW\n+        R_VERSION: 4.0\n+        TOOLCHAIN: MSYS\n       regular:\n         TASK: regular\n         PYTHON_VERSION: 3.6\ndiff --git a/R-package/README.md b/R-package/README.md\nindex d48aae2ee949..166f32501aa0 100644\n--- a/R-package/README.md\n+++ b/R-package/README.md\n@@ -20,14 +20,53 @@ Note: 32-bit (i386) R/Rtools is currently not supported.\n \n #### Windows Preparation\n \n-Installing [Rtools](https://cran.r-project.org/bin/windows/Rtools/) is mandatory, and only support the 64-bit version. It requires to add to PATH the Rtools MinGW64 folder, if it was not done automatically during installation.\n+Installing a 64-bit version of [Rtools](https://cran.r-project.org/bin/windows/Rtools/) is mandatory.\n \n-The default compiler is Visual Studio (or [VS Build Tools](https://visualstudio.microsoft.com/downloads/)) in Windows, with an automatic fallback to Rtools or any [MinGW64](https://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/) (x86_64-posix-seh) available (this means if you have only Rtools and CMake, it will compile fine).\n+After installing `Rtools` and `CMake`, be sure the following paths are added to the environment variable `PATH`. These may have been automatically added when installing other software.\n \n-To force the usage of Rtools / MinGW, you can set `use_mingw` to `TRUE` in `R-package/src/install.libs.R`.\n+* `Rtools`\n+    - If you have `Rtools` 3.x, example:\n+        - `C:\\Rtools\\mingw_64\\bin`\n+    - If you have `Rtools` 4.0, example:\n+        - `C:\\rtools40\\mingw64\\bin`\n+        - `C:\\rtools40\\usr\\bin`\n+* `CMake`\n+    - example: `C:\\Program Files\\CMake\\bin`\n+* `R`\n+    - example: `C:\\Program Files\\R\\R-3.6.1\\bin`\n+\n+NOTE: Two `Rtools` paths are required from `Rtools` 4.0 onwards because paths and the list of included software was changed in `Rtools` 4.0.\n+\n+#### Windows Toolchain Options\n+\n+A \"toolchain\" refers to the collection of software used to build the library. The R package can be built with three different toolchains.\n \n **Warning for Windows users**: it is recommended to use *Visual Studio* for its better multi-threading efficiency in Windows for many core systems. For very simple systems (dual core computers or worse), MinGW64 is recommended for maximum performance. If you do not know what to choose, it is recommended to use [Visual Studio](https://visualstudio.microsoft.com/downloads/), the default compiler. **Do not try using MinGW in Windows on many core systems. It may result in 10x slower results than Visual Studio.**\n \n+**Visual Studio (default)**\n+\n+By default, the package will be built with [Visual Studio Build Tools](https://visualstudio.microsoft.com/downloads/).\n+\n+**MinGW (R 3.x)**\n+\n+If you are using R 3.x and installation fails with Visual Studio, `LightGBM` will fall back to using [MinGW](http://mingw-w64.org/doku.php) bundled with `Rtools`.\n+\n+If you want to force `LightGBM` to use MinGW (for any R version), open `R-package/src/install.libs.R` and change `use_mingw`:\n+\n+```r\n+use_mingw <- TRUE\n+```\n+\n+**MSYS2 (R 4.x)**\n+\n+If you are using R 4.x and installation fails with Visual Studio, `LightGBM` will fall back to using [MSYS2](https://www.msys2.org/). This should work with the tools already bundled in `Rtools` 4.0.\n+\n+If you want to force `LightGBM` to use MSYS2 (for any R version), open `R-package/src/install.libs.R` and change `use_msys2`:\n+\n+```r\n+use_msys2 <- TRUE\n+```\n+\n #### Mac OS Preparation\n \n You can perform installation either with **Apple Clang** or **gcc**. In case you prefer **Apple Clang**, you should install **OpenMP** (details for installation can be found in [Installation Guide](https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#apple-clang)) first and **CMake** version 3.16 or higher is required. In case you prefer **gcc**, you need to install it (details for installation can be found in [Installation Guide](https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#gcc)) and set some environment variables to tell R to use `gcc` and `g++`. If you install these from Homebrew, your versions of `g++` and `gcc` are most likely in `/usr/local/bin`, as shown below.\ndiff --git a/R-package/inst/make-r-def.R b/R-package/inst/make-r-def.R\nnew file mode 100644\nindex 000000000000..94f548a51334\n--- /dev/null\n+++ b/R-package/inst/make-r-def.R\n@@ -0,0 +1,98 @@\n+# [description]\n+#     Create a definition file (.def) from a .dll file, using objdump.\n+#\n+# [usage]\n+#\n+#     Rscript make-r-def.R something.dll something.def\n+#\n+# [references]\n+#    * https://www.cs.colorado.edu/~main/cs1300/doc/mingwfaq.html\n+\n+args <- commandArgs(trailingOnly = TRUE)\n+\n+IN_DLL_FILE <- args[[1L]]\n+OUT_DEF_FILE <- args[[2L]]\n+DLL_BASE_NAME <- basename(IN_DLL_FILE)\n+\n+message(sprintf(\"Creating '%s' from '%s'\", OUT_DEF_FILE, IN_DLL_FILE))\n+\n+# system() will not raise an R exception if the process called\n+# fails. Wrapping it here to get that behavior.\n+#\n+# system() introduces a lot of overhead, at least on Windows,\n+# so trying processx if it is available\n+.pipe_shell_command_to_stdout <- function(command, args, out_file) {\n+    has_processx <- suppressMessages({\n+      suppressWarnings({\n+        require(\"processx\")  # nolint\n+      })\n+    })\n+    if (has_processx) {\n+        p <- processx::process$new(\n+            command = command\n+            , args = args\n+            , stdout = out_file\n+            , windows_verbatim_args = FALSE\n+        )\n+        invisible(p$wait())\n+    } else {\n+        message(paste0(\n+          \"Using system2() to run shell commands. Installing \"\n+          , \"'processx' with install.packages('processx') might \"\n+          , \"make this faster.\"\n+        ))\n+        # shQuote() is necessary here since one of the arguments\n+        # is a file-path to R.dll, which may have spaces. processx\n+        # does such quoting but system2() does not\n+        exit_code <- system2(\n+            command = command\n+            , args = shoQuote(args)\n+            , stdout = out_file\n+        )\n+        if (exit_code != 0L) {\n+            stop(paste0(\"Command failed with exit code: \", exit_code))\n+        }\n+    }\n+    return(invisible(NULL))\n+}\n+\n+# use objdump to dump all the symbols\n+OBJDUMP_FILE <- \"objdump-out.txt\"\n+.pipe_shell_command_to_stdout(\n+    command = \"objdump\"\n+    , args = c(\"-p\", IN_DLL_FILE)\n+    , out_file = OBJDUMP_FILE\n+)\n+\n+objdump_results <- readLines(OBJDUMP_FILE)\n+invisible(file.remove(OBJDUMP_FILE))\n+\n+# Only one table in the objdump results matters for our purposes,\n+# see https://www.cs.colorado.edu/~main/cs1300/doc/mingwfaq.html\n+start_index <- which(\n+    grepl(\n+        pattern = \"[Ordinal/Name Pointer] Table\"\n+        , x = objdump_results\n+        , fixed = TRUE\n+    )\n+)\n+empty_lines <- which(objdump_results == \"\")\n+end_of_table <- empty_lines[empty_lines > start_index][1L]\n+\n+# Read the contents of the table\n+exported_symbols <- objdump_results[(start_index + 1L):end_of_table]\n+exported_symbols <- gsub(\"\\t\", \"\", exported_symbols)\n+exported_symbols <- gsub(\".*\\\\] \", \"\", exported_symbols)\n+exported_symbols <- gsub(\" \", \"\", exported_symbols)\n+\n+# Write R.def file\n+writeLines(\n+    text = c(\n+        paste0(\"LIBRARY \\\"\", DLL_BASE_NAME, \"\\\"\")\n+        , \"EXPORTS\"\n+        , exported_symbols\n+    )\n+    , con = OUT_DEF_FILE\n+    , sep = \"\\n\"\n+)\n+message(sprintf(\"Successfully created '%s'\", OUT_DEF_FILE))\ndiff --git a/R-package/src/cmake/modules/FindLibR.cmake b/R-package/src/cmake/modules/FindLibR.cmake\nindex f07bf889d61e..81d7c3ad15e7 100644\n--- a/R-package/src/cmake/modules/FindLibR.cmake\n+++ b/R-package/src/cmake/modules/FindLibR.cmake\n@@ -41,20 +41,26 @@ function(create_rlib_for_msvc)\n     message(FATAL_ERROR \"LIBR_CORE_LIBRARY, '${LIBR_CORE_LIBRARY}', not found\")\n   endif()\n \n-  find_program(GENDEF_EXE gendef)\n   find_program(DLLTOOL_EXE dlltool)\n \n-  if(NOT GENDEF_EXE OR NOT DLLTOOL_EXE)\n-    message(FATAL_ERROR \"Either gendef.exe or dlltool.exe not found!\\\n+  if(NOT DLLTOOL_EXE)\n+    message(FATAL_ERROR \"dlltool.exe not found!\\\n       \\nDo you have Rtools installed with its MinGW's bin/ in PATH?\")\n   endif()\n \n   set(LIBR_MSVC_CORE_LIBRARY \"${CMAKE_CURRENT_BINARY_DIR}/R.lib\" CACHE PATH \"R.lib filepath\")\n \n-  # extract symbols from R.dll into R.def and R.lib import library\n-  execute_process(COMMAND ${GENDEF_EXE}\n-    \"-\" \"${LIBR_CORE_LIBRARY}\"\n-    OUTPUT_FILE \"${CMAKE_CURRENT_BINARY_DIR}/R.def\"\n+  get_filename_component(\n+    LIBR_RSCRIPT_EXECUTABLE_DIR\n+    ${LIBR_EXECUTABLE}\n+    DIRECTORY\n+  )\n+  set(LIBR_RSCRIPT_EXECUTABLE \"${LIBR_RSCRIPT_EXECUTABLE_DIR}/Rscript\")\n+\n+  execute_process(\n+    COMMAND ${LIBR_RSCRIPT_EXECUTABLE}\n+    \"${CMAKE_CURRENT_BINARY_DIR}/make-r-def.R\"\n+    \"${LIBR_CORE_LIBRARY}\" \"${CMAKE_CURRENT_BINARY_DIR}/R.def\"\n   )\n   execute_process(COMMAND ${DLLTOOL_EXE}\n     \"--input-def\" \"${CMAKE_CURRENT_BINARY_DIR}/R.def\"\ndiff --git a/R-package/src/install.libs.R b/R-package/src/install.libs.R\nindex b04eecc3317f..a2dc2018764c 100644\n--- a/R-package/src/install.libs.R\n+++ b/R-package/src/install.libs.R\n@@ -1,7 +1,15 @@\n # User options\n use_precompile <- FALSE\n use_gpu <- FALSE\n+\n+# For Windows, the package will be built with Visual Studio\n+# unless you set one of these to TRUE\n use_mingw <- FALSE\n+use_msys2 <- FALSE\n+\n+if (use_mingw && use_msys2) {\n+  stop(\"Cannot use both MinGW and MSYS2. Please choose only one.\")\n+}\n \n if (.Machine$sizeof.pointer != 8L) {\n   stop(\"LightGBM only supports 64-bit R, please check the version of R and Rtools.\")\n@@ -110,12 +118,55 @@ if (!use_precompile) {\n   )\n   setwd(build_dir)\n \n+  use_visual_studio <- !(use_mingw || use_msys2)\n+\n+  # If using MSVC to build, pull in the script used\n+  # to create R.def from R.dll\n+  if (WINDOWS && use_visual_studio) {\n+    write_succeeded <- file.copy(\n+      \"../../inst/make-r-def.R\"\n+      , file.path(build_dir, \"make-r-def.R\")\n+      , overwrite = TRUE\n+    )\n+    if (!write_succeeded) {\n+      stop(\"Copying make-r-def.R failed\")\n+    }\n+  }\n+\n   # Prepare installation steps\n   cmake_args <- NULL\n   build_cmd <- \"make\"\n   build_args <- \"_lightgbm\"\n   lib_folder <- file.path(source_dir, fsep = \"/\")\n \n+  WINDOWS_BUILD_TOOLS <- list(\n+    \"MinGW\" = c(\n+      build_tool = \"mingw32-make.exe\"\n+      , makefile_generator = \"MinGW Makefiles\"\n+    )\n+    , \"MSYS2\" = c(\n+      build_tool = \"make.exe\"\n+      , makefile_generator = \"MSYS Makefiles\"\n+    )\n+  )\n+\n+  if (use_mingw) {\n+    windows_toolchain <- \"MinGW\"\n+  } else if (use_msys2) {\n+    windows_toolchain <- \"MSYS2\"\n+  } else {\n+    # Rtools 4.0 moved from MinGW to MSYS toolchain. If user tries\n+    # Visual Studio install but that fails, fall back to the toolchain\n+    # supported in Rtools\n+    if (R_ver >= 4.0) {\n+      windows_toolchain <- \"MSYS2\"\n+    } else {\n+      windows_toolchain <- \"MinGW\"\n+    }\n+  }\n+  windows_build_tool <- WINDOWS_BUILD_TOOLS[[windows_toolchain]][[\"build_tool\"]]\n+  windows_makefile_generator <- WINDOWS_BUILD_TOOLS[[windows_toolchain]][[\"makefile_generator\"]]\n+\n   if (use_gpu) {\n     cmake_args <- c(cmake_args, \"-DUSE_GPU=ON\")\n   }\n@@ -139,21 +190,21 @@ if (!use_precompile) {\n \n   # Check if Windows installation (for gcc vs Visual Studio)\n   if (WINDOWS) {\n-    if (use_mingw) {\n-      message(\"Trying to build with MinGW\")\n+    if (!use_visual_studio) {\n+      message(sprintf(\"Trying to build with %s\", windows_toolchain))\n       # Must build twice for Windows due sh.exe in Rtools\n-      cmake_args <- c(cmake_args, \"-G\", shQuote(\"MinGW Makefiles\"))\n+      cmake_args <- c(cmake_args, \"-G\", shQuote(windows_makefile_generator))\n       .run_shell_command(\"cmake\", c(cmake_args, \"..\"), strict = FALSE)\n-      build_cmd <- \"mingw32-make.exe\"\n+      build_cmd <- windows_build_tool\n       build_args <- \"_lightgbm\"\n     } else {\n       visual_studio_succeeded <- .generate_vs_makefiles(cmake_args)\n       if (!isTRUE(visual_studio_succeeded)) {\n-        warning(\"Building with Visual Studio failed. Attempting with MinGW\")\n+        warning(sprintf(\"Building with Visual Studio failed. Attempting with %s\", windows_toolchain))\n         # Must build twice for Windows due sh.exe in Rtools\n-        cmake_args <- c(cmake_args, \"-G\", shQuote(\"MinGW Makefiles\"))\n+        cmake_args <- c(cmake_args, \"-G\", shQuote(windows_makefile_generator))\n         .run_shell_command(\"cmake\", c(cmake_args, \"..\"), strict = FALSE)\n-        build_cmd <- \"mingw32-make.exe\"\n+        build_cmd <- windows_build_tool\n         build_args <- \"_lightgbm\"\n       } else {\n         build_cmd <- \"cmake\"\n@@ -196,6 +247,7 @@ if (!use_precompile) {\n   }\n \n   # build the library\n+  message(\"Building lib_lightgbm\")\n   .run_shell_command(build_cmd, build_args)\n   src <- file.path(lib_folder, paste0(\"lib_lightgbm\", SHLIB_EXT), fsep = \"/\")\n \ndiff --git a/build_r.R b/build_r.R\nindex 27aada8fad05..20b130b79cba 100644\n--- a/build_r.R\n+++ b/build_r.R\n@@ -115,6 +115,13 @@ for (src_file in c(\"lightgbm_R.cpp\", \"lightgbm_R.h\", \"R_object_helper.h\")) {\n   .handle_result(result)\n }\n \n+result <- file.copy(\n+  from = file.path(\"R-package\", \"inst\", \"make-r-def.R\")\n+  , to = file.path(TEMP_R_DIR, \"inst\", \"bin/\")\n+  , overwrite = TRUE\n+)\n+.handle_result(result)\n+\n # NOTE: --keep-empty-dirs is necessary to keep the deep paths expected\n #       by CMake while also meeting the CRAN req to create object files\n #       on demand\ndiff --git a/docs/GPU-Windows.rst b/docs/GPU-Windows.rst\nindex 5184da2fd65c..f66355338753 100644\n--- a/docs/GPU-Windows.rst\n+++ b/docs/GPU-Windows.rst\n@@ -135,7 +135,7 @@ To check whether you need 32-bit or 64-bit MinGW for R, install LightGBM as usua\n If it says ``mingw_64`` then you need the 64-bit version (PATH with ``c:\\Rtools\\bin;c:\\Rtools\\mingw_64\\bin``),\n otherwise you need the 32-bit version (``c:\\Rtools\\bin;c:\\Rtools\\mingw_32\\bin``), the latter being a very rare and untested case.\n \n---------------\n+NOTE: If you are using `Rtools` 4.0 or later, the path will have `mingw64` instead of `mingw_64` (PATH with `C:\\rtools40\\mingw64\\bin`), and `mingw32` instead of `mingw_32` (`C:\\rtools40\\mingw32\\bin`). The 32-bit version remains an unsupported solution under Rtools 4.0.\n \n Download the prebuilt Boost\n ---------------------------\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Build Compatibility**: Ensure MinGW Makefiles are only used with the Windows command prompt and mingw32-make. Use MSYS Makefiles with the MSYS shell to avoid compatibility issues.\n\n2. **Toolchain Adjustments**:\n   - For R 3.x: Use MinGW Makefiles and `mingw32-make`.\n   - For R 4.x: Switch to MSYS Makefiles and `make`.\n\n3. **Manual `use_mingw` Handling**: If `use_mingw` is specified with R 4.0, require users to ensure `mingw32-make.exe` is in their PATH.\n\n4. **`R CMD check` NOTE**: Consider increasing allowed NOTEs to 4 to expedite review, with a follow-up PR to revert this after addressing test artifacts in the check directory.\n\n5. **CI Optimization**: Aim to migrate long-running Windows R jobs to GitHub Actions for efficiency; keep monitoring job statuses post-template changes to resolve duplication issues."
      }
    ],
    "codediff_length": 24078
  },
  {
    "index": 11,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.travis.yml b/.travis.yml\nindex 4b3c971c690f..d4a91b1e7d40 100644\n--- a/.travis.yml\n+++ b/.travis.yml\n@@ -5,46 +5,46 @@ dist: trusty\n compiler:\n   - gcc\n \n+os:\n+  - linux\n+  - osx\n+\n+env:\n+  matrix:\n+    - TASK=regular PYTHON_VERSION=3.6\n+    - TASK=mpi PYTHON_VERSION=3.6\n+    - TASK=pylint PYTHON_VERSION=3.6\n+    - TASK=if-else PYTHON_VERSION=3.6\n+    - TASK=sdist PYTHON_VERSION=3.6\n+    - TASK=bdist PYTHON_VERSION=3.6\n+    - TASK=gpu METHOD=source PYTHON_VERSION=3.6\n+    - TASK=gpu METHOD=pip PYTHON_VERSION=3.6\n+    - TASK=regular PYTHON_VERSION=2.7\n+    - TASK=regular PYTHON_VERSION=3.4\n+    - TASK=regular PYTHON_VERSION=3.5\n+\n matrix:\n-  include:\n-    - os: linux\n-      env: TASK=regular\n-    - os: linux\n-      env: TASK=mpi\n-    - os: linux\n-      env: TASK=gpu METHOD=source\n-    - os: linux\n-      env: TASK=sdist\n-    - os: linux\n-      env: TASK=gpu METHOD=pip\n-    - os: linux\n-      env: TASK=bdist\n-    - os: linux\n-      env: TASK=pylint\n-    - os: linux\n-      env: TASK=if-else\n-    - os: osx\n-      env: TASK=regular\n+  exclude:\n     - os: osx\n-      env: TASK=mpi\n+      env: TASK=gpu METHOD=source PYTHON_VERSION=3.6\n     - os: osx\n-      env: TASK=sdist\n+      env: TASK=gpu METHOD=pip PYTHON_VERSION=3.6\n     - os: osx\n-      env: TASK=bdist\n+      env: TASK=pylint PYTHON_VERSION=3.6\n \n before_install:\n-- test -n $CC  && unset CC\n-- test -n $CXX && unset CXX\n+  - test -n $CC  && unset CC\n+  - test -n $CXX && unset CXX\n \n install:\n-- bash .travis/setup.sh\n-- bash conda.sh -b -p $HOME/miniconda\n-- export PATH=\"$HOME/miniconda/bin:$PATH\"\n-- conda config --set always_yes yes --set changeps1 no\n-- conda update -q conda\n+  - bash .travis/setup.sh\n+  - bash conda.sh -b -p $HOME/miniconda\n+  - export PATH=\"$HOME/miniconda/bin:$PATH\"\n+  - conda config --set always_yes yes --set changeps1 no\n+  - conda update -q conda\n \n script:\n-- bash .travis/test.sh\n+  - bash .travis/test.sh\n \n notifications:\n   email: false\ndiff --git a/.travis/setup.sh b/.travis/setup.sh\nindex 5b7d82c7adfe..5a8edff94a77 100644\n--- a/.travis/setup.sh\n+++ b/.travis/setup.sh\n@@ -2,7 +2,7 @@\n \n if [[ $TRAVIS_OS_NAME == \"osx\" ]]; then\n     brew install openmpi  # use openmpi to install gcc\n-    wget -O conda.sh https://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh\n+    wget -O conda.sh https://repo.continuum.io/miniconda/Miniconda${PYTHON_VERSION:0:1}-latest-MacOSX-x86_64.sh\n else\n     if [[ ${TASK} != \"pylint\" ]]; then\n         sudo add-apt-repository ppa:george-edison55/cmake-3.x -y\n@@ -10,5 +10,5 @@ else\n         sudo apt-get install -y cmake\n         sudo apt-get install -y libopenmpi-dev openmpi-bin build-essential\n     fi\n-    wget -O conda.sh https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n+    wget -O conda.sh https://repo.continuum.io/miniconda/Miniconda${PYTHON_VERSION:0:1}-latest-Linux-x86_64.sh\n fi\ndiff --git a/.travis/test.sh b/.travis/test.sh\nindex 605f77731e5c..0dfa8c22800c 100644\n--- a/.travis/test.sh\n+++ b/.travis/test.sh\n@@ -1,4 +1,4 @@\n-if [[ ${TASK} == \"gpu\" ]]; then \n+if [[ ${TASK} == \"gpu\" ]]; then\n     bash .travis/amd_sdk.sh;\n     tar -xjf AMD-SDK.tar.bz2;\n     AMDAPPSDK=${HOME}/AMDAPPSDK;\n@@ -9,9 +9,9 @@ if [[ ${TASK} == \"gpu\" ]]; then\n     export LD_LIBRARY_PATH=${AMDAPPSDK}/lib/x86_64:${LD_LIBRARY_PATH};\n     chmod +x ${AMDAPPSDK}/bin/x86_64/clinfo;\n     ${AMDAPPSDK}/bin/x86_64/clinfo;\n-    export LIBRARY_PATH=\"$HOME/miniconda/lib:$LIBRARY_PATH\"\n-    export LD_RUN_PATH=\"$HOME/miniconda/lib:$LD_RUN_PATH\"\n-    export CPLUS_INCLUDE_PATH=\"$HOME/miniconda/include:$AMDAPPSDK/include/:$CPLUS_INCLUDE_PATH\"\n+    export LIBRARY_PATH=\"$HOME/miniconda/envs/test-env/lib:$LIBRARY_PATH\"\n+    export LD_RUN_PATH=\"$HOME/miniconda/envs/test-env/lib:$LD_RUN_PATH\"\n+    export CPLUS_INCLUDE_PATH=\"$HOME/miniconda/envs/test-env/include:$AMDAPPSDK/include/:$CPLUS_INCLUDE_PATH\"\n fi\n \n case ${TRAVIS_OS_NAME} in\n@@ -32,7 +32,8 @@ if [[ ${TASK} == \"pylint\" ]]; then\n fi\n \n if [[ ${TASK} == \"if-else\" ]]; then\n-    conda install --yes numpy\n+    conda create -q -n test-env python=$PYTHON_VERSION numpy\n+    source activate test-env\n     mkdir build && cd build && cmake .. && make lightgbm || exit -1\n     cd $TRAVIS_BUILD_DIR/tests/cpp_test && ../../lightgbm config=train.conf && ../../lightgbm config=predict.conf output_result=origin.pred || exit -1\n     cd $TRAVIS_BUILD_DIR/build && make lightgbm || exit -1\n@@ -40,8 +41,8 @@ if [[ ${TASK} == \"if-else\" ]]; then\n     exit 0\n fi\n \n-conda install --yes numpy nose scipy scikit-learn pandas matplotlib\n-pip install pytest\n+conda create -q -n test-env python=$PYTHON_VERSION numpy nose scipy scikit-learn pandas matplotlib pytest\n+source activate test-env\n \n if [[ ${TASK} == \"sdist\" ]]; then\n     LGB_VER=$(head -n 1 VERSION.txt)\n@@ -66,7 +67,7 @@ if [[ ${TASK} == \"gpu\" ]]; then\n     conda install --yes -c conda-forge boost=1.63.0\n     if [[ ${METHOD} == \"pip\" ]]; then\n         export PATH=\"$AMDAPPSDK/include/:$PATH\"\n-        export BOOST_ROOT=\"$HOME/miniconda/\"\n+        export BOOST_ROOT=\"$HOME/miniconda/envs/test-env/\"\n         LGB_VER=$(head -n 1 VERSION.txt)\n         sed -i 's/const std::string kDefaultDevice = \"cpu\";/const std::string kDefaultDevice = \"gpu\";/' ../include/LightGBM/config.h\n         cd $TRAVIS_BUILD_DIR/python-package && python setup.py sdist || exit -1\n@@ -81,7 +82,7 @@ mkdir build && cd build\n if [[ ${TASK} == \"mpi\" ]]; then\n     cmake -DUSE_MPI=ON ..\n elif [[ ${TASK} == \"gpu\" ]]; then\n-    cmake -DUSE_GPU=ON -DBOOST_ROOT=\"$HOME/miniconda/\" -DOpenCL_INCLUDE_DIR=$AMDAPPSDK/include/ ..\n+    cmake -DUSE_GPU=ON -DBOOST_ROOT=\"$HOME/miniconda/envs/test-env/\" -DOpenCL_INCLUDE_DIR=$AMDAPPSDK/include/ ..\n     sed -i 's/const std::string kDefaultDevice = \"cpu\";/const std::string kDefaultDevice = \"gpu\";/' ../include/LightGBM/config.h\n else\n     cmake ..\ndiff --git a/README.md b/README.md\nindex c4f805b31ad9..8763772e1f79 100644\n--- a/README.md\n+++ b/README.md\n@@ -8,6 +8,7 @@ LightGBM, Light Gradient Boosting Machine\n [![GitHub Issues](https://img.shields.io/github/issues/Microsoft/LightGBM.svg)](https://github.com/Microsoft/LightGBM/issues)\n [![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/Microsoft/LightGBM/blob/master/LICENSE)\n [![PyPI Version](https://badge.fury.io/py/lightgbm.svg)](https://badge.fury.io/py/lightgbm)\n+<!--- # Uncomment after updating PyPI [![Python Versions](https://img.shields.io/pypi/pyversions/lightgbm.svg)](https://pypi.python.org/pypi/lightgbm) -->\n \n LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n \ndiff --git a/appveyor.yml b/appveyor.yml\nindex b7e8eb1956f4..f411625bcec9 100644\n--- a/appveyor.yml\n+++ b/appveyor.yml\n@@ -1,15 +1,36 @@\n+version: 2.0.5.{build}\n+\n+configuration:  # A trick to construct a build matrix\n+  - 3.5\n+  - 3.6\n \n-version: 1.0.{build}\n environment:\n   matrix:\n-    - PYTHON: \"C:/Python36-x64\"\n-      PYTHON_VERSION: 3.6\n-      MINICONDA: \"C:/Miniconda36-x64\"\n+    - APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2017\n+      COMPILER: MSVC\n+    - APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2015\n+      COMPILER: MINGW\n \n clone_depth: 50\n \n-init:\n-  - \"ECHO %PYTHON_VERSION% %MINICONDA%\"\n+install:\n+  - set PATH=%PATH:C:\\Program Files\\Git\\usr\\bin;=%  # Delete sh.exe from PATH (mingw32-make fix)\n+  - set PATH=C:\\mingw-w64\\x86_64-6.3.0-posix-seh-rt_v5-rev1\\mingw64\\bin;%PATH%\n+  - set PYTHON_VERSION=%CONFIGURATION%\n+  - ps: >-\n+      switch ($env:PYTHON_VERSION) {\n+          \"2.7\" {$env:MINICONDA = \"\"\"C:\\Miniconda-x64\"\"\"}\n+          \"3.4\" {$env:MINICONDA = \"\"\"C:\\Miniconda3-x64\"\"\"}\n+          \"3.5\" {$env:MINICONDA = \"\"\"C:\\Miniconda35-x64\"\"\"}\n+          \"3.6\" {$env:MINICONDA = \"\"\"C:\\Miniconda36-x64\"\"\"}\n+          default {$env:MINICONDA = \"\"\"C:\\Miniconda36-x64\"\"\"}\n+      }\n+  - set PATH=%MINICONDA%;%MINICONDA%\\Scripts;%PATH%\n+  - ps: $env:LGB_VER = (Get-Content VERSION.txt).trim()\n+  - conda config --set always_yes yes --set changeps1 no\n+  - conda update -q conda\n+  - conda create -q -n test-env python=%PYTHON_VERSION% numpy nose scipy scikit-learn pandas matplotlib pep8 pytest\n+  - activate test-env\n \n build_script:\n   - mkdir build && cd build\n@@ -17,20 +38,19 @@ build_script:\n   - cd ..\n \n test_script:\n-  - \"set PATH=%MINICONDA%;%MINICONDA%/Scripts;%PATH%\"\n-  - conda config --set always_yes yes --set changeps1 no\n-  - conda update -q conda\n-  - conda info -a\n-  - conda install --yes numpy nose scipy scikit-learn pandas matplotlib\n-  - pip install pep8 pytest\n   - pytest tests/c_api_test/test_.py\n-  - \"set /p LGB_VER=< VERSION.txt\"\n   - cd python-package && python setup.py sdist --formats gztar\n-  - cd dist \n-  - \"pip install lightgbm-%LGB_VER%.tar.gz -v\"\n+  - cd dist\n+  - IF \"%COMPILER%\"==\"MINGW\" (\n+    pip install lightgbm-%LGB_VER%.tar.gz --install-option=--mingw -v)\n+    ELSE (\n+    pip install lightgbm-%LGB_VER%.tar.gz -v)\n   - cd ../..\n   - pytest tests/python_package_test\n+  - IF \"%COMPILER%\"==\"MINGW\" appveyor exit  # skip all further steps\n   - cd python-package && python setup.py bdist_wheel --plat-name=win-amd64 --universal\n+\n+after_test:\n   - cd ../.nuget\n   - python create_nuget.py\n   - nuget.exe pack LightGBM.nuspec\ndiff --git a/python-package/MANIFEST.in b/python-package/MANIFEST.in\nindex 49e867bdc25b..b02e8007db01 100644\n--- a/python-package/MANIFEST.in\n+++ b/python-package/MANIFEST.in\n@@ -5,5 +5,6 @@ recursive-include lightgbm *.py *.txt *.so\n recursive-include lightgbm/Release *.dll\n recursive-include lightgbm/include *\n recursive-include lightgbm/src *\n-global-exclude *.pyo\n-global-exclude *.pyc\n+recursive-include lightgbm/windows LightGBM.sln LightGBM.vcxproj LightGBM.vcxproj.filters\n+recursive-include lightgbm/windows/x64/DLL *.dll\n+global-exclude *.py[co]\ndiff --git a/python-package/README.rst b/python-package/README.rst\nindex a8c22fa092c2..b9c6481306f8 100644\n--- a/python-package/README.rst\n+++ b/python-package/README.rst\n@@ -1,8 +1,9 @@\n LightGBM Python Package\n =======================\n \n-|PyPI version|\n+|License| |PyPI Version|\n \n+.. # Uncomment after updating PyPI |Python Versions|\n \n Installation\n ------------\n@@ -16,63 +17,76 @@ For Mac OS X users, gcc with OpenMP support must be installed first. Refer to `w\n \n Note: 32-bit python is not supported. Please install 64-bit version.\n \n-Install from pip\n-''''''''''''''''\n+Install from `PyPI <https://pypi.python.org/pypi/lightgbm>`_ using ``pip``\n+''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n+For Windows users, `VC runtime <https://go.microsoft.com/fwlink/?LinkId=746572>`_ is needed if Visual Studio (2013, 2015 or 2017) is not installed.\n \n-Install `wheel <http://pythonwheels.com>`_ via ``pip install wheel`` first. For Windows user, `VC runtime <https://go.microsoft.com/fwlink/?LinkId=746572>`_ is needed if Visual Studio (2013, 2015 or 2017) is not installed.\n+Install `wheel <http://pythonwheels.com>`_ via ``pip install wheel`` first. After that download the wheel file and install from it:\n \n+.. code:: sh\n \n-``pip install lightgbm``\n+    pip install lightgbm\n \n+Build from sources\n+******************\n \n-Install source package from pip\n-*******************************\n+.. code:: sh\n \n-``pip install --no-binary :all: lightgbm``\n+    pip install --no-binary :all: lightgbm\n \n+For Linux and Mac OS X users, installation from sources requires installed `CMake <https://cmake.org/>`_.\n \n-Note: Installation from source package require installing `CMake <https://cmake.org/>`_ first.\n+For Mac OS X users, you need to specify compilers by runnig ``export CXX=g++-7 CC=gcc-7`` first.\n \n-For Windows user, Visual Studio (or `MS Build <https://www.visualstudio.com/downloads/#build-tools-for-visual-studio-2017>`_) is needed, and `CMake <https://cmake.org/>`_ must be version 3.8 or higher.\n+For Windows users, Visual Studio (or `MS Build <https://www.visualstudio.com/downloads/#build-tools-for-visual-studio-2017>`_) is needed. If you get any errors during installation, you may need to install `CMake <https://cmake.org/>`_ (version 3.8 or higher).\n \n-For OSX user, you need to run ```export CXX=g++-7 CC=gcc-7``` before running ```pip install ... ```.\n+Build GPU version\n+~~~~~~~~~~~~~~~~~\n \n-Install GPU version:\n+.. code:: sh\n \n-``pip install lightgbm --install-option=--gpu``\n+    pip install lightgbm --install-option=--gpu\n \n-Note: Boost and OpenCL are needed: details for installation can be found in `gpu-support <https://github.com/Microsoft/LightGBM/wiki/Installation-Guide#with-gpu-support>`_. Need to add OpenCL_INCLUDE_DIR to PATH and export BOOST_ROOT before installation.\n+For Windows users, `CMake <https://cmake.org/>`_ (version 3.8 or higher) is strongly required in this case.\n \n-Install with MinGW on Windows:\n+Note: Boost and OpenCL are needed: details for installation can be found in `gpu-support <https://github.com/Microsoft/LightGBM/wiki/Installation-Guide#with-gpu-support>`_. You need to add ``OpenCL_INCLUDE_DIR`` to the environmental variable **'PATH'** and export ``BOOST_ROOT`` before installation.\n \n-``pip install lightgbm --install-option=--mingw``\n+Build with MinGW-w64 on Windows\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. code:: sh\n+\n+    pip install lightgbm --install-option=--mingw\n+\n+Note: `CMake <https://cmake.org/>`_ and `MinGW-w64 <https://mingw-w64.org/>`_ should be installed first.\n \n Install from GitHub\n '''''''''''''''''''\n \n-Installation from GitHub require installing `CMake <https://cmake.org/>`_ first.\n+For Linux and Mac OS X users, installation from GitHub requires installed `CMake <https://cmake.org/>`_.\n \n-For Windows user, Visual Studio (or `MS Build <https://www.visualstudio.com/downloads/#build-tools-for-visual-studio-2017>`_) is needed, and `CMake <https://cmake.org/>`_ must be version 3.8 or higher.\n+For Windows users, Visual Studio (or `MS Build <https://www.visualstudio.com/downloads/#build-tools-for-visual-studio-2017>`_) is needed. If you get any errors during installation and there is the warning ``WARNING:LightGBM:Compilation with MSBuild from existing solution file failed.`` in the log, you should install `CMake <https://cmake.org/>`_ (version 3.8 or higher).\n \n .. code:: sh\n \n-    git clone --recursive https://github.com/Microsoft/LightGBM\n+    git clone --recursive https://github.com/Microsoft/LightGBM.git\n     cd LightGBM/python-package\n-    # export CXX=g++-7 CC=gcc-7 # for OSX\n+    # export CXX=g++-7 CC=gcc-7  # for Mac OS X users only\n     python setup.py install\n \n-``sudo`` (or administrator rights in Windows) may is needed to perform ``python setup.py install``.\n+Note: ``sudo`` (or administrator rights in Windows) may be needed to perform the command.\n \n-Use ``python setup.py install --mingw`` to use MinGW in Windows.\n+Run ``python setup.py install --mingw`` if you want to use MinGW-w64 on Windows instead of Visual Studio. `CMake <https://cmake.org/>`_ and `MinGW-w64 <https://mingw-w64.org/>`_ should be installed first.\n \n-Use ``python setup.py install --gpu`` to enable GPU support. Boost and OpenCL are needed: details for installation can be found in `gpu-support <https://github.com/Microsoft/LightGBM/wiki/Installation-Guide#with-gpu-support>`_.\n+Run ``python setup.py install --gpu`` to enable GPU support. For Windows users, `CMake <https://cmake.org/>`_ (version 3.8 or higher) is strongly required in this case. Boost and OpenCL are needed: details for installation can be found in `gpu-support <https://github.com/Microsoft/LightGBM/wiki/Installation-Guide#with-gpu-support>`_.\n+\n+If you get any errors during installation or due to any other reason, you may want to build dynamic library from sources by any method you prefer (see `Installation-Guide <https://github.com/Microsoft/LightGBM/wiki/Installation-Guide>`_) and then run ``python setup.py install --precompile``.\n \n Examples\n --------\n \n Refer to the walk through examples in `python-guide folder <https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide>`_.\n \n-\n Troubleshooting\n ---------------\n \n@@ -93,5 +107,9 @@ The code style of python package follows `pep8 <https://www.python.org/dev/peps/\n \n E501 can be ignored (line too long).\n \n-.. |PyPI version| image:: https://badge.fury.io/py/lightgbm.svg\n+.. |License| image:: https://img.shields.io/badge/license-MIT-blue.svg\n+   :target: https://github.com/Microsoft/LightGBM/blob/master/LICENSE\n+.. |Python Versions| image:: https://img.shields.io/pypi/pyversions/lightgbm.svg\n+   :target: https://pypi.python.org/pypi/lightgbm\n+.. |PyPI Version| image:: https://badge.fury.io/py/lightgbm.svg\n     :target: https://badge.fury.io/py/lightgbm\ndiff --git a/python-package/lightgbm/libpath.py b/python-package/lightgbm/libpath.py\nindex e16d1ee0cce3..d3c99f23f016 100644\n--- a/python-package/lightgbm/libpath.py\n+++ b/python-package/lightgbm/libpath.py\n@@ -19,6 +19,7 @@ def find_lib_path():\n     dll_path = [curr_path, os.path.join(curr_path, '../../'), os.path.join(curr_path, '../../lib/')]\n     if os.name == 'nt':\n         dll_path.append(os.path.join(curr_path, './Release/'))\n+        dll_path.append(os.path.join(curr_path, './windows/x64/DLL/'))\n         dll_path.append(os.path.join(curr_path, '../../Release/'))\n         dll_path.append(os.path.join(curr_path, '../../windows/x64/DLL/'))\n         dll_path = [os.path.join(p, 'lib_lightgbm.dll') for p in dll_path]\n@@ -27,5 +28,5 @@ def find_lib_path():\n     lib_path = [p for p in dll_path if os.path.exists(p) and os.path.isfile(p)]\n     if not lib_path:\n         dll_path = [os.path.realpath(p) for p in dll_path]\n-        raise Exception('Cannot find lightgbm Library in following paths: ' + ','.join(dll_path))\n+        raise Exception('Cannot find lightgbm library in following paths: ' + '\\n'.join(dll_path))\n     return lib_path\ndiff --git a/python-package/setup.py b/python-package/setup.py\nindex c512576002a9..ada8598b2edb 100644\n--- a/python-package/setup.py\n+++ b/python-package/setup.py\n@@ -4,9 +4,11 @@\n from __future__ import absolute_import\n \n import distutils\n+import logging\n import os\n import shutil\n import struct\n+import subprocess\n import sys\n \n from setuptools import find_packages, setup\n@@ -22,7 +24,7 @@ def find_lib():\n     exec(compile(open(libpath_py, \"rb\").read(), libpath_py, 'exec'), libpath, libpath)\n \n     LIB_PATH = [os.path.relpath(path, CURRENT_DIR) for path in libpath['find_lib_path']()]\n-    print(\"Install lib_lightgbm from: %s\" % LIB_PATH)\n+    logging.info(\"Installing lib_lightgbm from: %s\" % LIB_PATH)\n     return LIB_PATH\n \n \n@@ -40,6 +42,7 @@ def copy_files_helper(folder_name):\n     if not os.path.isfile('./_IS_SOURCE_PACKAGE.txt'):\n         copy_files_helper('include')\n         copy_files_helper('src')\n+        copy_files_helper('windows')\n         if use_gpu:\n             copy_files_helper('compute')\n         distutils.file_util.copy_file(\"../CMakeLists.txt\", \"./lightgbm/\")\n@@ -47,13 +50,25 @@ def copy_files_helper(folder_name):\n \n \n def clear_path(path):\n-    contents = os.listdir(path)\n-    for file in contents:\n-        file_path = os.path.join(path, file)\n-        if os.path.isfile(file_path):\n-            os.remove(file_path)\n-        else:\n-            shutil.rmtree(file_path)\n+    if os.path.isdir(path):\n+        contents = os.listdir(path)\n+        for file_name in contents:\n+            file_path = os.path.join(path, file_name)\n+            if os.path.isfile(file_path):\n+                os.remove(file_path)\n+            else:\n+                shutil.rmtree(file_path)\n+\n+\n+def silent_call(cmd, raise_error=False, error_msg=''):\n+    try:\n+        with open(os.devnull, \"w\") as shut_up:\n+            subprocess.check_output(cmd, stderr=shut_up)\n+            return 0\n+    except Exception:\n+        if raise_error:\n+            raise Exception(error_msg)\n+        return 1\n \n \n def compile_cpp(use_mingw=False, use_gpu=False):\n@@ -63,33 +78,53 @@ def compile_cpp(use_mingw=False, use_gpu=False):\n     os.makedirs(\"build_cpp\")\n     os.chdir(\"build_cpp\")\n \n-    cmake_cmd = \"cmake \"\n-    build_cmd = \"make _lightgbm\"\n+    logger.info(\"Starting to compile the library.\")\n+\n+    cmake_cmd = [\"cmake\", \"../lightgbm/\"]\n     if use_gpu:\n-        cmake_cmd += \" -DUSE_GPU=ON \"\n+        cmake_cmd.append(\"-DUSE_GPU=ON\")\n     if os.name == \"nt\":\n         if use_mingw:\n-            cmake_cmd += \" -G \\\"MinGW Makefiles\\\" \"\n-            os.system(cmake_cmd + \" ../lightgbm/\")\n-            build_cmd = \"mingw32-make.exe _lightgbm\"\n+            logger.info(\"Starting to compile with CMake and MinGW.\")\n+            silent_call(cmake_cmd + [\"-G\", \"MinGW Makefiles\"], raise_error=True,\n+                        error_msg='Please install CMake first')\n+            silent_call([\"mingw32-make.exe\", \"_lightgbm\"], raise_error=True,\n+                        error_msg='Please install MinGW first')\n         else:\n-            vs_versions = [\"Visual Studio 15 2017 Win64\", \"Visual Studio 14 2015 Win64\", \"Visual Studio 12 2013 Win64\"]\n-            try_vs = 1\n-            for vs in vs_versions:\n-                tmp_cmake_cmd = \"%s -G \\\"%s\\\"\" % (cmake_cmd, vs)\n-                try_vs = os.system(tmp_cmake_cmd + \" ../lightgbm/\")\n-                if try_vs == 0:\n-                    cmake_cmd = tmp_cmake_cmd\n-                    break\n-                else:\n-                    clear_path(\"./\")\n-            if try_vs != 0:\n-                raise Exception('Please install Visual Studio or MS Build first')\n-\n-            build_cmd = \"cmake --build . --target _lightgbm  --config Release\"\n-    print(\"Start to compile library.\")\n-    os.system(cmake_cmd + \" ../lightgbm/\")\n-    os.system(build_cmd)\n+            status = 1\n+            lib_path = \"../lightgbm/windows/x64/DLL/lib_lightgbm.dll\"\n+            if not use_gpu:\n+                logger.info(\"Starting to compile with MSBuild from existing solution file.\")\n+                platform_toolsets = (\"v141\", \"v140\", \"v120\")\n+                for pt in platform_toolsets:\n+                    status = silent_call([\"MSBuild\", \"../lightgbm/windows/LightGBM.sln\",\n+                                          \"/p:Configuration=DLL\",\n+                                          \"/p:Platform=x64\",\n+                                          \"/p:PlatformToolset={0}\".format(pt)])\n+                    if status == 0 and os.path.exists(lib_path):\n+                        break\n+                    else:\n+                        clear_path(\"../lightgbm/windows/x64\")\n+                if status != 0 or not os.path.exists(lib_path):\n+                    logger.warning(\"Compilation with MSBuild from existing solution file failed.\")\n+            if status != 0 or not os.path.exists(lib_path):\n+                vs_versions = (\"Visual Studio 15 2017 Win64\", \"Visual Studio 14 2015 Win64\", \"Visual Studio 12 2013 Win64\")\n+                for vs in vs_versions:\n+                    logger.info(\"Starting to compile with %s.\" % vs)\n+                    status = silent_call(cmake_cmd + [\"-G\", vs])\n+                    if status == 0:\n+                        break\n+                    else:\n+                        clear_path(\"./\")\n+                if status != 0:\n+                    raise Exception('Please install Visual Studio or MS Build first')\n+                silent_call([\"cmake\", \"--build\", \".\", \"--target\", \"_lightgbm\", \"--config\", \"Release\"], raise_error=True,\n+                            error_msg='Please install CMake first')\n+    else:  # Linux, Darwin (OS X), etc.\n+        logger.info(\"Starting to compile with CMake.\")\n+        silent_call(cmake_cmd, raise_error=True, error_msg='Please install CMake first')\n+        silent_call([\"make\", \"_lightgbm\"], raise_error=True,\n+                    error_msg='An error has occurred while building lightgbm library file')\n     os.chdir(\"..\")\n \n \n@@ -122,7 +157,6 @@ def run(self):\n         if not self.precompile:\n             copy_files(use_gpu=self.gpu)\n             compile_cpp(use_mingw=self.mingw, use_gpu=self.gpu)\n-        self.distribution.data_files = [('lightgbm', find_lib())]\n         install.run(self)\n \n \n@@ -149,11 +183,13 @@ def run(self):\n         distutils.file_util.copy_file(\n             os.path.join('..', 'VERSION.txt'),\n             os.path.join('.', 'lightgbm'))\n-    if os.path.isfile(os.path.join(dir_path, 'lightgbm', 'VERSION.txt')):\n-        version = open(os.path.join(dir_path, 'lightgbm', 'VERSION.txt')).read().strip()\n+    version = open(os.path.join(dir_path, 'lightgbm', 'VERSION.txt')).read().strip()\n \n     sys.path.insert(0, '.')\n \n+    logging.basicConfig(level=logging.INFO)\n+    logger = logging.getLogger('LightGBM')\n+\n     setup(name='lightgbm',\n           version=version,\n           description='LightGBM Python Package',\n@@ -173,6 +209,20 @@ def run(self):\n           },\n           packages=find_packages(),\n           include_package_data=True,\n-          data_files=[],\n           license='The MIT License (Microsoft)',\n-          url='https://github.com/Microsoft/LightGBM')\n+          url='https://github.com/Microsoft/LightGBM',\n+          classifiers=['Development Status :: 5 - Production/Stable',\n+                       'Intended Audience :: Science/Research',\n+                       'License :: OSI Approved :: MIT License',\n+                       'Natural Language :: English',\n+                       'Operating System :: MacOS',\n+                       'Operating System :: Microsoft :: Windows',\n+                       'Operating System :: POSIX',\n+                       'Operating System :: Unix',\n+                       'Programming Language :: Python :: 2',\n+                       'Programming Language :: Python :: 2.7',\n+                       'Programming Language :: Python :: 3',\n+                       'Programming Language :: Python :: 3.4',\n+                       'Programming Language :: Python :: 3.5',\n+                       'Programming Language :: Python :: 3.6',\n+                       'Topic :: Scientific/Engineering :: Artificial Intelligence'])\ndiff --git a/tests/c_api_test/test_.py b/tests/c_api_test/test_.py\nindex 3c8cc14169ec..bc91b1a8695e 100644\n--- a/tests/c_api_test/test_.py\n+++ b/tests/c_api_test/test_.py\n@@ -25,7 +25,7 @@ def find_lib_path():\n     lib_path = [p for p in dll_path if os.path.exists(p) and os.path.isfile(p)]\n     if not lib_path:\n         dll_path = [os.path.realpath(p) for p in dll_path]\n-        raise Exception('Cannot find lightgbm Library in following paths: ' + ','.join(dll_path))\n+        raise Exception('Cannot find lightgbm library in following paths: ' + '\\n'.join(dll_path))\n     return lib_path\n \n \ndiff --git a/tests/python_package_test/test_sklearn.py b/tests/python_package_test/test_sklearn.py\nindex fca5d442fdd2..0ee655d6799a 100644\n--- a/tests/python_package_test/test_sklearn.py\n+++ b/tests/python_package_test/test_sklearn.py\n@@ -13,8 +13,12 @@\n from sklearn.metrics import log_loss, mean_squared_error\n from sklearn.model_selection import GridSearchCV, train_test_split\n from sklearn.utils.estimator_checks import (_yield_all_checks, SkipTest,\n-                                            check_parameters_default_constructible,\n-                                            check_no_fit_attributes_set_in_init)\n+                                            check_parameters_default_constructible)\n+try:\n+    from sklearn.utils.estimator_checks import check_no_fit_attributes_set_in_init\n+    sklearn_at_least_019 = True\n+except ImportError:\n+    sklearn_at_least_019 = False\n \n \n def multi_error(y_true, y_pred):\n@@ -174,17 +178,19 @@ def test_sklearn_backward_compatibility(self):\n         np.testing.assert_allclose(y_pred_1, y_pred_2)\n \n     def test_sklearn_integration(self):\n-        # we cannot use `check_estimator` directly since there is no skip test mechanism\n-        for name, estimator in ((lgb.sklearn.LGBMClassifier.__name__, lgb.sklearn.LGBMClassifier),\n-                                (lgb.sklearn.LGBMRegressor.__name__, lgb.sklearn.LGBMRegressor)):\n-            check_parameters_default_constructible(name, estimator)\n-            check_no_fit_attributes_set_in_init(name, estimator)\n-            # we cannot leave default params (see https://github.com/Microsoft/LightGBM/issues/833)\n-            estimator = estimator(min_data=1, min_data_in_bin=1)\n-            for check in _yield_all_checks(name, estimator):\n-                if check.__name__ == 'check_estimators_nan_inf':\n-                    continue  # skip test because LightGBM deals with nan\n-                try:\n-                    check(name, estimator)\n-                except SkipTest as message:\n-                    warnings.warn(message, SkipTestWarning)\n+        # sklearn <0.19 cannot accept instance, but many tests could be passed only with min_data=1 and min_data_in_bin=1\n+        if sklearn_at_least_019:\n+            # we cannot use `check_estimator` directly since there is no skip test mechanism\n+            for name, estimator in ((lgb.sklearn.LGBMClassifier.__name__, lgb.sklearn.LGBMClassifier),\n+                                    (lgb.sklearn.LGBMRegressor.__name__, lgb.sklearn.LGBMRegressor)):\n+                check_parameters_default_constructible(name, estimator)\n+                check_no_fit_attributes_set_in_init(name, estimator)\n+                # we cannot leave default params (see https://github.com/Microsoft/LightGBM/issues/833)\n+                estimator = estimator(min_child_samples=1, min_data_in_bin=1)\n+                for check in _yield_all_checks(name, estimator):\n+                    if check.__name__ == 'check_estimators_nan_inf':\n+                        continue  # skip test because LightGBM deals with nan\n+                    try:\n+                        check(name, estimator)\n+                    except SkipTest as message:\n+                        warnings.warn(message, SkipTestWarning)\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. The line `self.distribution.data_files = [('lightgbm', find_lib())]` needs review; it currently copies DLLs to an unexpected folder. Ensure it aligns with standard practices for installation paths.\n\n2. The conditional statement checking for `VERSION.txt` is unnecessary and can be removed, as it will result in a `NameError` on accessing `version` later.\n\n3. Consider updating Appveyor tests to verify DLL compatibility with MinGW while ensuring artifacts generated by MSVC. \n\n4. Proposal: Use Python 2.7 for MPI version tests on Travis, while keeping Python 3.x for other tests to optimize coverage without extending test durations.\n\n5. Investigate failures in deprecated warnings on Travis for Python 2.7, aiming to understand the cause and potential resolutions."
      }
    ],
    "codediff_length": 29787
  },
  {
    "index": 12,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/python-package/lightgbm/dask.py b/python-package/lightgbm/dask.py\nindex ba84edca87c2..4251af78f8bc 100644\n--- a/python-package/lightgbm/dask.py\n+++ b/python-package/lightgbm/dask.py\n@@ -21,7 +21,7 @@\n from dask.distributed import Client, default_client, get_worker, wait\n \n from .basic import _ConfigAliases, _LIB, _safe_call\n-from .sklearn import LGBMClassifier, LGBMRegressor\n+from .sklearn import LGBMClassifier, LGBMRegressor, LGBMRanker\n \n logger = logging.getLogger(__name__)\n \n@@ -133,15 +133,24 @@ def _train_part(params, model_factory, list_of_parts, worker_address_to_port, re\n     }\n     params.update(network_params)\n \n+    is_ranker = issubclass(model_factory, LGBMRanker)\n+\n     # Concatenate many parts into one\n     parts = tuple(zip(*list_of_parts))\n     data = _concat(parts[0])\n     label = _concat(parts[1])\n-    weight = _concat(parts[2]) if len(parts) == 3 else None\n \n     try:\n         model = model_factory(**params)\n-        model.fit(data, label, sample_weight=weight, **kwargs)\n+\n+        if is_ranker:\n+            group = _concat(parts[-1])\n+            weight = _concat(parts[2]) if len(parts) == 4 else None\n+            model.fit(data, y=label, sample_weight=weight, group=group, **kwargs)\n+        else:\n+            weight = _concat(parts[2]) if len(parts) == 3 else None\n+            model.fit(data, y=label, sample_weight=weight, **kwargs)\n+\n     finally:\n         _safe_call(_LIB.LGBM_NetworkFree())\n \n@@ -156,7 +165,7 @@ def _split_to_parts(data, is_matrix):\n     return parts\n \n \n-def _train(client, data, label, params, model_factory, weight=None, **kwargs):\n+def _train(client, data, label, params, model_factory, sample_weight=None, group=None, **kwargs):\n     \"\"\"Inner train routine.\n \n     Parameters\n@@ -167,22 +176,36 @@ def _train(client, data, label, params, model_factory, weight=None, **kwargs):\n     y : dask array of shape = [n_samples]\n         The target values (class labels in classification, real numbers in regression).\n     params : dict\n-    model_factory : lightgbm.LGBMClassifier or lightgbm.LGBMRegressor class\n+    model_factory : lightgbm.LGBMClassifier, lightgbm.LGBMRegressor, or lightgbm.LGBMRanker class\n     sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n-            Weights of training data.\n+        Weights of training data.\n+    group : array-like or None, optional (default=None)\n+        Group/query data.\n+        Only used in the learning-to-rank task.\n+        sum(group) = n_samples.\n+        For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n+        where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n     \"\"\"\n     params = deepcopy(params)\n \n     # Split arrays/dataframes into parts. Arrange parts into tuples to enforce co-locality\n     data_parts = _split_to_parts(data, is_matrix=True)\n     label_parts = _split_to_parts(label, is_matrix=False)\n-    if weight is None:\n-        parts = list(map(delayed, zip(data_parts, label_parts)))\n+    weight_parts = _split_to_parts(sample_weight, is_matrix=False) if sample_weight is not None else None\n+    group_parts = _split_to_parts(group, is_matrix=False) if group is not None else None\n+\n+    # choose between four options of (sample_weight, group) being (un)specified\n+    if weight_parts is None and group_parts is None:\n+        parts = zip(data_parts, label_parts)\n+    elif weight_parts is not None and group_parts is None:\n+        parts = zip(data_parts, label_parts, weight_parts)\n+    elif weight_parts is None and group_parts is not None:\n+        parts = zip(data_parts, label_parts, group_parts)\n     else:\n-        weight_parts = _split_to_parts(weight, is_matrix=False)\n-        parts = list(map(delayed, zip(data_parts, label_parts, weight_parts)))\n+        parts = zip(data_parts, label_parts, weight_parts, group_parts)\n \n     # Start computation in the background\n+    parts = list(map(delayed, parts))\n     parts = client.compute(parts)\n     wait(parts)\n \n@@ -281,13 +304,13 @@ def _predict(model, data, proba=False, dtype=np.float32, **kwargs):\n \n     Parameters\n     ----------\n-    model :\n+    model : lightgbm.LGBMClassifier, lightgbm.LGBMRegressor, or lightgbm.LGBMRanker class\n     data : dask array of shape = [n_samples, n_features]\n         Input feature matrix.\n     proba : bool\n-        Should method return results of predict_proba (proba == True) or predict (proba == False)\n+        Should method return results of predict_proba (proba == True) or predict (proba == False).\n     dtype : np.dtype\n-        Dtype of the output\n+        Dtype of the output.\n     kwargs : other parameters passed to predict or predict_proba method\n     \"\"\"\n     if isinstance(data, dd._Frame):\n@@ -304,13 +327,14 @@ def _predict(model, data, proba=False, dtype=np.float32, **kwargs):\n \n class _LGBMModel:\n \n-    def _fit(self, model_factory, X, y=None, sample_weight=None, client=None, **kwargs):\n+    def _fit(self, model_factory, X, y=None, sample_weight=None, group=None, client=None, **kwargs):\n         \"\"\"Docstring is inherited from the LGBMModel.\"\"\"\n         if client is None:\n             client = default_client()\n \n         params = self.get_params(True)\n-        model = _train(client, X, y, params, model_factory, sample_weight, **kwargs)\n+        model = _train(client, data=X, label=y, params=params, model_factory=model_factory,\n+                       sample_weight=sample_weight, group=group, **kwargs)\n \n         self.set_params(**model.get_params())\n         self._copy_extra_params(model, self)\n@@ -335,8 +359,8 @@ class DaskLGBMClassifier(_LGBMModel, LGBMClassifier):\n     \"\"\"Distributed version of lightgbm.LGBMClassifier.\"\"\"\n \n     def fit(self, X, y=None, sample_weight=None, client=None, **kwargs):\n-        \"\"\"Docstring is inherited from the LGBMModel.\"\"\"\n-        return self._fit(LGBMClassifier, X, y, sample_weight, client, **kwargs)\n+        \"\"\"Docstring is inherited from the lightgbm.LGBMClassifier.fit.\"\"\"\n+        return self._fit(LGBMClassifier, X=X, y=y, sample_weight=sample_weight, client=client, **kwargs)\n     fit.__doc__ = LGBMClassifier.fit.__doc__\n \n     def predict(self, X, **kwargs):\n@@ -364,7 +388,7 @@ class DaskLGBMRegressor(_LGBMModel, LGBMRegressor):\n \n     def fit(self, X, y=None, sample_weight=None, client=None, **kwargs):\n         \"\"\"Docstring is inherited from the lightgbm.LGBMRegressor.fit.\"\"\"\n-        return self._fit(LGBMRegressor, X, y, sample_weight, client, **kwargs)\n+        return self._fit(LGBMRegressor, X=X, y=y, sample_weight=sample_weight, client=client, **kwargs)\n     fit.__doc__ = LGBMRegressor.fit.__doc__\n \n     def predict(self, X, **kwargs):\n@@ -380,3 +404,29 @@ def to_local(self):\n         model : lightgbm.LGBMRegressor\n         \"\"\"\n         return self._to_local(LGBMRegressor)\n+\n+\n+class DaskLGBMRanker(_LGBMModel, LGBMRanker):\n+    \"\"\"Docstring is inherited from the lightgbm.LGBMRanker.\"\"\"\n+\n+    def fit(self, X, y=None, sample_weight=None, init_score=None, group=None, client=None, **kwargs):\n+        \"\"\"Docstring is inherited from the lightgbm.LGBMRanker.fit.\"\"\"\n+        if init_score is not None:\n+            raise RuntimeError('init_score is not currently supported in lightgbm.dask')\n+\n+        return self._fit(LGBMRanker, X=X, y=y, sample_weight=sample_weight, group=group, client=client, **kwargs)\n+    fit.__doc__ = LGBMRanker.fit.__doc__\n+\n+    def predict(self, X, **kwargs):\n+        \"\"\"Docstring is inherited from the lightgbm.LGBMRanker.predict.\"\"\"\n+        return _predict(self.to_local(), X, **kwargs)\n+    predict.__doc__ = LGBMRanker.predict.__doc__\n+\n+    def to_local(self):\n+        \"\"\"Create regular version of lightgbm.LGBMRanker from the distributed version.\n+\n+        Returns\n+        -------\n+        model : lightgbm.LGBMRanker\n+        \"\"\"\n+        return self._to_local(LGBMRanker)\ndiff --git a/tests/python_package_test/test_dask.py b/tests/python_package_test/test_dask.py\nindex e793872ee4fb..960e1a56da63 100644\n--- a/tests/python_package_test/test_dask.py\n+++ b/tests/python_package_test/test_dask.py\n@@ -1,30 +1,37 @@\n # coding: utf-8\n+\"\"\"Tests for lightgbm.dask module\"\"\"\n+\n+import itertools\n import os\n import socket\n import sys\n \n import pytest\n-if not sys.platform.startswith(\"linux\"):\n-    pytest.skip(\"lightgbm.dask is currently supported in Linux environments\", allow_module_level=True)\n+if not sys.platform.startswith('linux'):\n+    pytest.skip('lightgbm.dask is currently supported in Linux environments', allow_module_level=True)\n \n import dask.array as da\n import dask.dataframe as dd\n import numpy as np\n import pandas as pd\n+from scipy.stats import spearmanr\n import scipy.sparse\n from dask.array.utils import assert_eq\n from dask_ml.metrics import accuracy_score, r2_score\n from distributed.utils_test import client, cluster_fixture, gen_cluster, loop\n from sklearn.datasets import make_blobs, make_regression\n+from sklearn.utils import check_random_state\n \n import lightgbm\n import lightgbm.dask as dlgbm\n \n data_output = ['array', 'scipy_csr_matrix', 'dataframe']\n data_centers = [[[-4, -4], [4, 4]], [[-4, -4], [4, 4], [-4, 4]]]\n+group_sizes = [5, 5, 5, 10, 10, 10, 20, 20, 20, 50, 50]\n \n pytestmark = [\n-    pytest.mark.skipif(os.getenv(\"TASK\", \"\") == \"mpi\", reason=\"Fails to run with MPI interface\")\n+    pytest.mark.skipif(os.getenv('TASK', '') == 'mpi', reason='Fails to run with MPI interface'),\n+    pytest.mark.skipif(os.getenv('TASK', '') == 'gpu', reason='Fails to run with GPU interface')\n ]\n \n \n@@ -37,6 +44,135 @@ def listen_port():\n listen_port.port = 13000\n \n \n+def _make_ranking(n_samples=100, n_features=20, n_informative=5, gmax=2,\n+                  group=None, random_gs=False, avg_gs=10, random_state=0):\n+    \"\"\"Generate a learning-to-rank dataset - feature vectors grouped together with\n+    integer-valued graded relevance scores. Replace this with a sklearn.datasets function\n+    if ranking objective becomes supported in sklearn.datasets module.\n+\n+    Parameters\n+    ----------\n+    n_samples : int, optional (default=100)\n+        Total number of documents (records) in the dataset.\n+    n_features : int, optional (default=20)\n+        Total number of features in the dataset.\n+    n_informative : int, optional (default=5)\n+        Number of features that are \"informative\" for ranking, as they are bias + beta * y\n+        where bias and beta are standard normal variates. If this is greater than n_features, the dataset will have\n+        n_features features, all will be informative.\n+    group : array-like, optional (default=None)\n+        1-d array or list of group sizes. When `group` is specified, this overrides n_samples, random_gs, and\n+        avg_gs by simply creating groups with sizes group[0], ..., group[-1].\n+    gmax : int, optional (default=2)\n+        Maximum graded relevance value for creating relevance/target vector. If you set this to 2, for example, all\n+        documents in a group will have relevance scores of either 0, 1, or 2.\n+    random_gs : bool, optional (default=False)\n+        True will make group sizes ~ Poisson(avg_gs), False will make group sizes == avg_gs.\n+    avg_gs : int, optional (default=10)\n+        Average number of documents (records) in each group.\n+\n+    Returns\n+    -------\n+    X : 2-d np.ndarray of shape = [n_samples (or np.sum(group)), n_features]\n+        Input feature matrix for ranking objective.\n+    y : 1-d np.array of shape = [n_samples (or np.sum(group))]\n+        Integer-graded relevance scores.\n+    group_ids : 1-d np.array of shape = [n_samples (or np.sum(group))]\n+        Array of group ids, each value indicates to which group each record belongs.\n+    \"\"\"\n+    rnd_generator = check_random_state(random_state)\n+\n+    y_vec, group_id_vec = np.empty((0,), dtype=int), np.empty((0,), dtype=int)\n+    gid = 0\n+\n+    # build target, group ID vectors.\n+    relvalues = range(gmax + 1)\n+\n+    # build y/target and group-id vectors with user-specified group sizes.\n+    if group is not None and hasattr(group, '__len__'):\n+        n_samples = np.sum(group)\n+\n+        for i, gsize in enumerate(group):\n+            y_vec = np.concatenate((y_vec, rnd_generator.choice(relvalues, size=gsize, replace=True)))\n+            group_id_vec = np.concatenate((group_id_vec, [i] * gsize))\n+\n+    # build y/target and group-id vectors according to n_samples, avg_gs, and random_gs.\n+    else:\n+        while len(y_vec) < n_samples:\n+            gsize = avg_gs if not random_gs else rnd_generator.poisson(avg_gs)\n+\n+            # groups should contain > 1 element for pairwise learning objective.\n+            if gsize < 1:\n+                continue\n+\n+            y_vec = np.append(y_vec, rnd_generator.choice(relvalues, size=gsize, replace=True))\n+            group_id_vec = np.append(group_id_vec, [gid] * gsize)\n+            gid += 1\n+\n+        y_vec, group_id_vec = y_vec[:n_samples], group_id_vec[:n_samples]\n+\n+    # build feature data, X. Transform first few into informative features.\n+    n_informative = max(min(n_features, n_informative), 0)\n+    X = rnd_generator.uniform(size=(n_samples, n_features))\n+\n+    for j in range(n_informative):\n+        bias, coef = rnd_generator.normal(size=2)\n+        X[:, j] = bias + coef * y_vec\n+\n+    return X, y_vec, group_id_vec\n+\n+\n+def _create_ranking_data(n_samples=100, output='array', chunk_size=50, **kwargs):\n+    X, y, g = _make_ranking(n_samples=n_samples, random_state=42, **kwargs)\n+    rnd = np.random.RandomState(42)\n+    w = rnd.rand(X.shape[0]) * 0.01\n+    g_rle = np.array([len(list(grp)) for _, grp in itertools.groupby(g)])\n+\n+    if output == 'dataframe':\n+\n+        # add target, weight, and group to DataFrame so that partitions abide by group boundaries.\n+        X_df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n+        X = X_df.copy()\n+        X_df = X_df.assign(y=y, g=g, w=w)\n+\n+        # set_index ensures partitions are based on group id.\n+        # See https://stackoverflow.com/questions/49532824/dask-dataframe-split-partitions-based-on-a-column-or-function.\n+        X_df.set_index('g', inplace=True)\n+        dX = dd.from_pandas(X_df, chunksize=chunk_size)\n+\n+        # separate target, weight from features.\n+        dy = dX['y']\n+        dw = dX['w']\n+        dX = dX.drop(columns=['y', 'w'])\n+        dg = dX.index.to_series()\n+\n+        # encode group identifiers into run-length encoding, the format LightGBMRanker is expecting\n+        # so that within each partition, sum(g) = n_samples.\n+        dg = dg.map_partitions(lambda p: p.groupby('g', sort=False).apply(lambda z: z.shape[0]))\n+\n+    elif output == 'array':\n+\n+        # ranking arrays: one chunk per group. Each chunk must include all columns.\n+        p = X.shape[1]\n+        dX, dy, dw, dg = [], [], [], []\n+        for g_idx, rhs in enumerate(np.cumsum(g_rle)):\n+            lhs = rhs - g_rle[g_idx]\n+            dX.append(da.from_array(X[lhs:rhs, :], chunks=(rhs - lhs, p)))\n+            dy.append(da.from_array(y[lhs:rhs]))\n+            dw.append(da.from_array(w[lhs:rhs]))\n+            dg.append(da.from_array(np.array([g_rle[g_idx]])))\n+\n+        dX = da.concatenate(dX, axis=0)\n+        dy = da.concatenate(dy, axis=0)\n+        dw = da.concatenate(dw, axis=0)\n+        dg = da.concatenate(dg, axis=0)\n+\n+    else:\n+        raise ValueError('Ranking data creation only supported for Dask arrays and dataframes')\n+\n+    return X, y, w, g_rle, dX, dy, dw, dg\n+\n+\n def _create_data(objective, n_samples=100, centers=2, output='array', chunk_size=50):\n     if objective == 'classification':\n         X, y = make_blobs(n_samples=n_samples, centers=centers, random_state=42)\n@@ -96,6 +232,8 @@ def test_classifier(output, centers, client, listen_port):\n     assert_eq(y, p2)\n     assert_eq(p1_proba, p2_proba, atol=0.3)\n \n+    client.close()\n+\n \n def test_training_does_not_fail_on_port_conflicts(client):\n     _, _, _, dX, dy, dw = _create_data('classification', output='array')\n@@ -118,6 +256,8 @@ def test_training_does_not_fail_on_port_conflicts(client):\n             )\n             assert dask_classifier.booster_\n \n+    client.close()\n+\n \n def test_classifier_local_predict(client, listen_port):\n     X, y, w, dX, dy, dw = _create_data('classification', output='array')\n@@ -139,6 +279,8 @@ def test_classifier_local_predict(client, listen_port):\n     assert_eq(y, p1)\n     assert_eq(y, p2)\n \n+    client.close()\n+\n \n @pytest.mark.parametrize('output', data_output)\n def test_regressor(output, client, listen_port):\n@@ -170,6 +312,8 @@ def test_regressor(output, client, listen_port):\n     assert_eq(y, p1, rtol=1., atol=100.)\n     assert_eq(y, p2, rtol=1., atol=50.)\n \n+    client.close()\n+\n \n @pytest.mark.parametrize('output', data_output)\n @pytest.mark.parametrize('alpha', [.1, .5, .9])\n@@ -204,6 +348,8 @@ def test_regressor_quantile(output, client, listen_port, alpha):\n     np.testing.assert_allclose(q1, alpha, atol=0.2)\n     np.testing.assert_allclose(q2, alpha, atol=0.2)\n \n+    client.close()\n+\n \n def test_regressor_local_predict(client, listen_port):\n     X, y, _, dX, dy, dw = _create_data('regression', output='array')\n@@ -226,6 +372,54 @@ def test_regressor_local_predict(client, listen_port):\n     assert_eq(p1, p2)\n     assert_eq(s1, s2)\n \n+    client.close()\n+\n+\n+@pytest.mark.parametrize('output', ['array', 'dataframe'])\n+@pytest.mark.parametrize('group', [None, group_sizes])\n+def test_ranker(output, client, listen_port, group):\n+\n+    X, y, w, g, dX, dy, dw, dg = _create_ranking_data(output=output, group=group)\n+\n+    # use many trees + leaves to overfit, help ensure that dask data-parallel strategy matches that of\n+    # serial learner. See https://github.com/microsoft/LightGBM/issues/3292#issuecomment-671288210.\n+    dask_ranker = dlgbm.DaskLGBMRanker(time_out=5, local_listen_port=listen_port, tree_learner_type='data_parallel',\n+                                       n_estimators=50, num_leaves=20, seed=42, min_child_samples=1)\n+    dask_ranker = dask_ranker.fit(dX, dy, sample_weight=dw, group=dg, client=client)\n+    rnkvec_dask = dask_ranker.predict(dX)\n+    rnkvec_dask = rnkvec_dask.compute()\n+\n+    local_ranker = lightgbm.LGBMRanker(n_estimators=50, num_leaves=20, seed=42, min_child_samples=1)\n+    local_ranker.fit(X, y, sample_weight=w, group=g)\n+    rnkvec_local = local_ranker.predict(X)\n+\n+    # distributed ranker should be able to rank decently well and should\n+    # have high rank correlation with scores from serial ranker.\n+    dcor = spearmanr(rnkvec_dask, y).correlation\n+    assert dcor > 0.6\n+    assert spearmanr(rnkvec_dask, rnkvec_local).correlation > 0.9\n+\n+    client.close()\n+\n+\n+@pytest.mark.parametrize('output', ['array', 'dataframe'])\n+@pytest.mark.parametrize('group', [None, group_sizes])\n+def test_ranker_local_predict(output, client, listen_port, group):\n+\n+    X, y, w, g, dX, dy, dw, dg = _create_ranking_data(output=output, group=group)\n+\n+    dask_ranker = dlgbm.DaskLGBMRanker(time_out=5, local_listen_port=listen_port, tree_learner='data',\n+                                       n_estimators=10, num_leaves=10, seed=42, min_child_samples=1)\n+    dask_ranker = dask_ranker.fit(dX, dy, group=dg, client=client)\n+    rnkvec_dask = dask_ranker.predict(dX)\n+    rnkvec_dask = rnkvec_dask.compute()\n+    rnkvec_local = dask_ranker.to_local().predict(X)\n+\n+    # distributed and to-local scores should be the same.\n+    assert_eq(rnkvec_dask, rnkvec_local)\n+\n+    client.close()\n+\n \n def test_find_open_port_works():\n     worker_ip = '127.0.0.1'\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Random Test Failures**: `test_dask.py` tests fail intermittently, especially on GPU builds and specific `ranker` tests. Focus on reproducing failures only in those contexts.\n\n2. **Socket Errors**: Observed `[LightGBM] [Fatal] Socket recv error, code: 104` in CI, possibly linked to networking issues. Monitor Docker container communication; consider increasing timeout settings.\n\n3. **Fixture Teardown Issues**: Test failures may stem from client teardown hanging. Investigate the `do_disconnect` method timeout as a potential cause. Implement a workaround using `pytest.skip()` on timeout exceptions during fixture teardown.\n\n4. **Testing Optimization**: Limit GPU tests for `LGBMRanker`, using `os.environ[\"TASK\"] == \"gpu\"` to conditionally skip them. This avoids issues without reducing test coverage.\n\n5. **Model Adjustments**: For `test_ranker`, increase `num_iterations` and `num_leaves` for better model behavior under parallel learning, and create simpler ranking datasets to stabilize results."
      }
    ],
    "codediff_length": 19597
  },
  {
    "index": 13,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.ci/test.sh b/.ci/test.sh\nindex 1b156eab7a71..3b9ee89ae3f5 100755\n--- a/.ci/test.sh\n+++ b/.ci/test.sh\n@@ -78,6 +78,11 @@ if [[ $TASK == \"if-else\" ]]; then\n     exit 0\n fi\n \n+if [[ $TASK == \"r-package\" ]]; then\n+    bash ${BUILD_DIRECTORY}/.ci/test_r_package.sh || exit -1\n+    exit 0\n+fi\n+\n conda install -q -y -n $CONDA_ENV joblib matplotlib numpy pandas psutil pytest python-graphviz scikit-learn scipy\n \n if [[ $OS_NAME == \"macos\" ]] && [[ $COMPILER == \"clang\" ]]; then\ndiff --git a/.ci/test_r_package.sh b/.ci/test_r_package.sh\nnew file mode 100755\nindex 000000000000..1570bdf021ec\n--- /dev/null\n+++ b/.ci/test_r_package.sh\n@@ -0,0 +1,90 @@\n+#!/bin/bash\n+\n+# set up R environment\n+R_LIB_PATH=~/Rlib\n+mkdir -p $R_LIB_PATH\n+echo \"R_LIBS=$R_LIB_PATH\" > ${HOME}/.Renviron\n+echo 'options(repos = \"https://cran.rstudio.com\")' > ${HOME}/.Rprofile\n+export PATH=\"$R_LIB_PATH/R/bin:$PATH\"\n+\n+# installing precompiled R for Ubuntu\n+# https://cran.r-project.org/bin/linux/ubuntu/#installation\n+# adding steps from https://stackoverflow.com/a/56378217/3986677 to get latest version\n+#\n+# This only needs to get run on Travis because R environment for Linux\n+# used by Azure pipelines is set up in https://github.com/guolinke/lightgbm-ci-docker\n+if [[ $TRAVIS == \"true\" ]] && [[ $OS_NAME == \"linux\" ]]; then\n+    sudo add-apt-repository \\\n+        \"deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/\"\n+    sudo apt-key adv \\\n+        --keyserver keyserver.ubuntu.com \\\n+        --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\n+    sudo apt-get update\n+    sudo apt-get install \\\n+        --no-install-recommends \\\n+        -y \\\n+            r-base-dev=${R_TRAVIS_LINUX_VERSION} \\\n+            texinfo \\\n+            texlive-latex-recommended \\\n+            texlive-fonts-recommended \\\n+            texlive-fonts-extra \\\n+            qpdf \\\n+            || exit -1\n+fi\n+\n+# Installing R precompiled for Mac OS 10.11 or higher\n+if [[ $OS_NAME == \"macos\" ]]; then\n+\n+    brew install qpdf\n+    brew cask install basictex\n+    export PATH=\"/Library/TeX/texbin:$PATH\"\n+    sudo tlmgr update --self\n+    sudo tlmgr install inconsolata helvetic\n+\n+    wget -q https://cran.r-project.org/bin/macosx/R-${R_MAC_VERSION}.pkg -O R.pkg\n+    sudo installer \\\n+        -pkg $(pwd)/R.pkg \\\n+        -target /\n+\n+    # Fix \"duplicate libomp versions\" issue on Mac\n+    # by replacing the R libomp.dylib with a symlink to the one installed with brew\n+    if [[ $COMPILER == \"clang\" ]]; then\n+        ver_arr=( ${R_MAC_VERSION//./ } )\n+        R_MAJOR_MINOR=\"${ver_arr[0]}.${ver_arr[1]}\"\n+        sudo ln -sf \\\n+            \"$(brew --cellar libomp)\"/*/lib/libomp.dylib \\\n+            /Library/Frameworks/R.framework/Versions/${R_MAJOR_MINOR}/Resources/lib/libomp.dylib\n+    fi\n+fi\n+\n+conda install \\\n+    -y \\\n+    -q \\\n+    --no-deps \\\n+        pandoc\n+\n+# Manually install Depends and Imports libraries + 'testthat'\n+# to avoid a CI-time dependency on devtools (for devtools::install_deps())\n+Rscript -e \"install.packages(c('data.table', 'jsonlite', 'Matrix', 'R6', 'testthat'))\" || exit -1\n+\n+cd ${BUILD_DIRECTORY}\n+Rscript build_r.R || exit -1\n+\n+PKG_TARBALL=\"lightgbm_${LGB_VER}.tar.gz\"\n+LOG_FILE_NAME=\"lightgbm.Rcheck/00check.log\"\n+\n+# suppress R CMD check warning from Suggests dependencies not being available\n+export _R_CHECK_FORCE_SUGGESTS_=0\n+\n+# fails tests if either ERRORs or WARNINGs are thrown by\n+# R CMD CHECK\n+R CMD check ${PKG_TARBALL} \\\n+    --as-cran \\\n+|| exit -1\n+\n+if grep -q -R \"WARNING\" \"$LOG_FILE_NAME\"; then\n+    echo \"WARNINGS have been found by R CMD check!\"\n+    exit -1\n+fi\n+\n+exit 0\ndiff --git a/.travis.yml b/.travis.yml\nindex b2066e653a3f..2941a47abd38 100644\n--- a/.travis.yml\n+++ b/.travis.yml\n@@ -24,6 +24,7 @@ env:\n     - TASK=mpi METHOD=pip\n     - TASK=gpu METHOD=source PYTHON_VERSION=3.5\n     - TASK=gpu METHOD=pip PYTHON_VERSION=3.6\n+    - TASK=r-package\n \n matrix:\n   exclude:\n@@ -44,9 +45,11 @@ before_install:\n   - if [[ $TRAVIS_OS_NAME == \"osx\" ]]; then\n         export OS_NAME=\"macos\";\n         export COMPILER=\"gcc\";\n+        export R_MAC_VERSION=3.6.1;\n     else\n         export OS_NAME=\"linux\";\n         export COMPILER=\"clang\";\n+        export R_TRAVIS_LINUX_VERSION=3.6.1-3bionic;\n     fi\n   - export CONDA=\"$HOME/miniconda\"\n   - export PATH=\"$CONDA/bin:$PATH\"\ndiff --git a/.vsts-ci.yml b/.vsts-ci.yml\nindex 9722d3e1518c..797a567a0213 100644\n--- a/.vsts-ci.yml\n+++ b/.vsts-ci.yml\n@@ -42,6 +42,8 @@ jobs:\n         TASK: gpu\n         METHOD: source\n         PYTHON_VERSION: 3.6\n+      r_package:\n+        TASK: r-package\n   steps:\n   - script: |\n       echo \"##vso[task.setvariable variable=HOME_DIRECTORY]$AGENT_HOMEDIRECTORY\"\n@@ -84,6 +86,8 @@ jobs:\n         PYTHON_VERSION: 3.5\n       bdist:\n         TASK: bdist\n+      r_package:\n+        TASK: r-package\n   steps:\n   - script: |\n       echo \"##vso[task.setvariable variable=HOME_DIRECTORY]$AGENT_HOMEDIRECTORY\"\n@@ -95,6 +99,7 @@ jobs:\n       echo \"##vso[task.setvariable variable=CONDA]$CONDA\"\n       echo \"##vso[task.prependpath]$CONDA/bin\"\n       echo \"##vso[task.setvariable variable=JAVA_HOME]$JAVA_HOME_8_X64\"\n+      echo \"##vso[task.setvariable variable=R_MAC_VERSION]3.6.1\"\n     displayName: 'Set variables'\n   - bash: $(Build.SourcesDirectory)/.ci/setup.sh\n     displayName: Setup\ndiff --git a/R-package/.Rbuildignore b/R-package/.Rbuildignore\nindex 92cef8e97c7b..309a82858cbc 100644\n--- a/R-package/.Rbuildignore\n+++ b/R-package/.Rbuildignore\n@@ -12,3 +12,14 @@\n \n # Code copied in at build time\n ^src/CMakeLists.txt$\n+\n+# unnecessary files from submodules\n+^src/compute/.appveyor.yml$\n+^src/compute/.coveralls.yml$\n+^src/compute/.travis.yml$\n+^src/compute/test/$\n+^src/compute/index.html$\n+^src/compute/.git$\n+^src/compute/.gitignore$\n+^src/compute/CONTRIBUTING.md$\n+^src/compute/README.md$\ndiff --git a/R-package/DESCRIPTION b/R-package/DESCRIPTION\nindex fcf994dbe39f..64386504ca72 100755\n--- a/R-package/DESCRIPTION\n+++ b/R-package/DESCRIPTION\n@@ -36,4 +36,4 @@ Imports:\n     jsonlite (>= 1.0),\n     Matrix (>= 1.1-0),\n     methods\n-RoxygenNote: 6.0.1\n+RoxygenNote: 7.0.2\ndiff --git a/R-package/man/lgb.cv.Rd b/R-package/man/lgb.cv.Rd\nindex a00c5632a21c..426488e3ca45 100644\n--- a/R-package/man/lgb.cv.Rd\n+++ b/R-package/man/lgb.cv.Rd\n@@ -53,6 +53,8 @@ lgb.cv(\n \n \\item{eval_freq}{evaluation output frequency, only effect when verbose > 0}\n \n+\\item{showsd}{\\code{boolean}, whether to show standard deviation of cross validation}\n+\n \\item{stratified}{a \\code{boolean} indicating whether sampling of folds should be stratified\n by the values of outcome labels.}\n \n@@ -88,8 +90,6 @@ into a predictor model which frees up memory and the original datasets}\n                        the number of real CPU cores, not the number of threads (most\n                        CPU using hyper-threading to generate 2 threads per CPU core).}\n }}\n-\n-\\item{showsd}{\\code{boolean}, whether to show standard deviation of cross validation}\n }\n \\value{\n a trained model \\code{lgb.CVBooster}.\ndiff --git a/R-package/man/lgb.prepare_rules2.Rd b/R-package/man/lgb.prepare_rules2.Rd\nindex 64ccd2041e1e..0b273dfd2e55 100644\n--- a/R-package/man/lgb.prepare_rules2.Rd\n+++ b/R-package/man/lgb.prepare_rules2.Rd\n@@ -24,3 +24,42 @@ This is useful if you have a specific need for integer dataset instead of numeri\n Note that there are programs which do not support integer-only input.\n Consider this as a half memory technique which is dangerous, especially for LightGBM.\n }\n+\\examples{\n+library(lightgbm)\n+data(iris)\n+\n+str(iris)\n+\n+new_iris <- lgb.prepare_rules2(data = iris) # Autoconverter\n+str(new_iris$data)\n+\n+data(iris) # Erase iris dataset\n+iris$Species[1L] <- \"NEW FACTOR\" # Introduce junk factor (NA)\n+\n+# Use conversion using known rules\n+# Unknown factors become 0, excellent for sparse datasets\n+newer_iris <- lgb.prepare_rules2(data = iris, rules = new_iris$rules)\n+\n+# Unknown factor is now zero, perfect for sparse datasets\n+newer_iris$data[1L, ] # Species became 0 as it is an unknown factor\n+\n+newer_iris$data[1L, 5L] <- 1.0 # Put back real initial value\n+\n+# Is the newly created dataset equal? YES!\n+all.equal(new_iris$data, newer_iris$data)\n+\n+# Can we test our own rules?\n+data(iris) # Erase iris dataset\n+\n+# We remapped values differently\n+personal_rules <- list(\n+  Species = c(\n+    \"setosa\" = 3L\n+    , \"versicolor\" = 2L\n+    , \"virginica\" = 1L\n+  )\n+)\n+newest_iris <- lgb.prepare_rules2(data = iris, rules = personal_rules)\n+str(newest_iris$data) # SUCCESS!\n+\n+}\ndiff --git a/R-package/src/install.libs.R b/R-package/src/install.libs.R\nindex b731ed60f706..b7aa4cb88ce6 100644\n--- a/R-package/src/install.libs.R\n+++ b/R-package/src/install.libs.R\n@@ -99,6 +99,32 @@ if (!use_precompile) {\n \n   # Install\n   system(paste0(cmake_cmd, \" ..\"))\n+\n+  # R CMD check complains about the .NOTPARALLEL directive created in the cmake\n+  # Makefile. We don't need it here anyway since targets are built serially, so trying\n+  # to remove it with this hack\n+  generated_makefile <- file.path(\n+    R_PACKAGE_SOURCE\n+    , \"src\"\n+    , \"build\"\n+    , \"Makefile\"\n+  )\n+  if (file.exists(generated_makefile)) {\n+    makefile_txt <- readLines(\n+      con = generated_makefile\n+    )\n+    makefile_txt <- gsub(\n+      pattern = \".*NOTPARALLEL.*\"\n+      , replacement = \"\"\n+      , x = makefile_txt\n+    )\n+    writeLines(\n+      text = makefile_txt\n+      , con = generated_makefile\n+      , sep = \"\\n\"\n+    )\n+  }\n+\n   system(build_cmd)\n   src <- file.path(lib_folder, paste0(\"lib_lightgbm\", SHLIB_EXT), fsep = \"/\")\n \ndiff --git a/R-package/tests/testthat.R b/R-package/tests/testthat.R\nindex 17f9e04cff8b..4a1d1268db36 100644\n--- a/R-package/tests/testthat.R\n+++ b/R-package/tests/testthat.R\n@@ -1,4 +1,8 @@\n library(testthat)\n library(lightgbm)\n \n-test_check(\"lightgbm\")\n+test_check(\n+    package = \"lightgbm\"\n+    , stop_on_failure = TRUE\n+    , stop_on_warning = FALSE\n+)\ndiff --git a/build_r.R b/build_r.R\nindex 74b025847366..88133c248071 100644\n--- a/build_r.R\n+++ b/build_r.R\n@@ -85,5 +85,5 @@ version <- gsub(\n )\n tarball <- file.path(getwd(), sprintf(\"lightgbm_%s.tar.gz\", version))\n \n-cmd <- sprintf(\"R CMD INSTALL %s --no-multiarch\", tarball)\n+cmd <- sprintf(\"R CMD INSTALL %s --no-multiarch --with-keep.source\", tarball)\n .run_shell_command(cmd)\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **GNU Extensions Warning**: Modify `src/build/Makefile` to remove GNU extensions causing portability issues, specifically `.NOTPARALLEL:`. \n\n2. **Performance Concern**: The `r-pkg` stage is taking 10-11 minutes. Investigate optimizations for faster builds without compromising quality control.\n\n3. **OpenMP Error**: Address `OMP: Error #15`. Multiple instances of `libomp.dylib` are linked, likely due to R's library including its own version. Validate linking to ensure a single OpenMP runtime is used.\n\n4. **Next Steps**: Test local builds with R 3.5.0 to assess discrepancies with Travis (using R 3.6.1). Reevaluate the need for pre-installing R to streamline CI processes. \n\n5. **General CI Improvements**: Consider removing conditions regarding `$AZURE == \"true\"` for more consistent behavior in all environments. \n\nEnsure all changes are validated before merging."
      }
    ],
    "codediff_length": 10257
  },
  {
    "index": 14,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.ci/lint_r_code.R b/.ci/lint_r_code.R\nindex cc83cb7c1cc9..d477a1a70b9c 100755\n--- a/.ci/lint_r_code.R\n+++ b/.ci/lint_r_code.R\n@@ -8,7 +8,7 @@ SOURCE_DIR <- args[[1L]]\n \n FILES_TO_LINT <- list.files(\n     path = SOURCE_DIR\n-    , pattern = \"\\\\.r$\"\n+    , pattern = \"\\\\.r$|\\\\.rmd$\"\n     , all.files = TRUE\n     , ignore.case = TRUE\n     , full.names = TRUE\ndiff --git a/.ci/test_r_package.sh b/.ci/test_r_package.sh\nindex a6656dfb83e6..aec25234c9fd 100755\n--- a/.ci/test_r_package.sh\n+++ b/.ci/test_r_package.sh\n@@ -92,13 +92,13 @@ if [[ $OS_NAME == \"macos\" ]]; then\n     fi\n fi\n \n-# Manually install Depends and Imports libraries + 'testthat'\n+# Manually install Depends and Imports libraries + 'knitr', 'rmarkdown', 'testthat'\n # to avoid a CI-time dependency on devtools (for devtools::install_deps())\n # NOTE: testthat is not required when running rchk\n if [[ \"${TASK}\" == \"r-rchk\" ]]; then\n-    packages=\"c('data.table', 'jsonlite', 'Matrix', 'R6')\"\n+    packages=\"c('data.table', 'jsonlite', 'knitr', 'Matrix', 'R6', 'rmarkdown')\"\n else\n-    packages=\"c('data.table', 'jsonlite', 'Matrix', 'R6', 'testthat')\"\n+    packages=\"c('data.table', 'jsonlite', 'knitr', 'Matrix', 'R6', 'rmarkdown', 'testthat')\"\n fi\n compile_from_source=\"both\"\n if [[ $OS_NAME == \"macos\" ]]; then\ndiff --git a/.ci/test_r_package_solaris.sh b/.ci/test_r_package_solaris.sh\nindex 1daabf08d91a..18ed6cb2f7ad 100755\n--- a/.ci/test_r_package_solaris.sh\n+++ b/.ci/test_r_package_solaris.sh\n@@ -5,7 +5,9 @@ apt-get install --no-install-recommends -y \\\n   libxml2-dev \\\n   libssl-dev\n \n-Rscript -e \"install.packages('rhub', dependencies = c('Depends', 'Imports', 'LinkingTo'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\" || exit -1\n+# installation of dependencies needs to happen before building the package,\n+# since `R CMD build` needs to install the package to build vignettes\n+Rscript -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'knitr', 'Matrix', 'rmarkdown', 'rhub', 'testthat'), dependencies = c('Depends', 'Imports', 'LinkingTo'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\" || exit -1\n \n sh build-cran-package.sh || exit -1\n \ndiff --git a/.ci/test_r_package_valgrind.sh b/.ci/test_r_package_valgrind.sh\nindex fc27689f9090..e7a6cb027d2d 100755\n--- a/.ci/test_r_package_valgrind.sh\n+++ b/.ci/test_r_package_valgrind.sh\n@@ -1,6 +1,6 @@\n #!/bin/bash\n \n-RDscriptvalgrind -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'Matrix', 'testthat'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\" || exit -1\n+RDscriptvalgrind -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'knitr', 'Matrix', 'rmarkdown', 'testthat'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\" || exit -1\n sh build-cran-package.sh \\\n   --r-executable=RDvalgrind \\\n   || exit -1\ndiff --git a/.ci/test_r_package_windows.ps1 b/.ci/test_r_package_windows.ps1\nindex 3c0f11ca58c6..3045937c0f2b 100644\n--- a/.ci/test_r_package_windows.ps1\n+++ b/.ci/test_r_package_windows.ps1\n@@ -122,7 +122,7 @@ Start-Process -FilePath Rtools.exe -NoNewWindow -Wait -ArgumentList \"/VERYSILENT\n Write-Output \"Done installing Rtools\"\n \n Write-Output \"Installing dependencies\"\n-$packages = \"c('data.table', 'jsonlite', 'Matrix', 'processx', 'R6', 'testthat'), dependencies = c('Imports', 'Depends', 'LinkingTo')\"\n+$packages = \"c('data.table', 'jsonlite', 'knitr', 'Matrix', 'processx', 'R6', 'rmarkdown', 'testthat'), dependencies = c('Imports', 'Depends', 'LinkingTo')\"\n Run-R-Code-Redirect-Stderr \"options(install.packages.check.source = 'no'); install.packages($packages, repos = '$env:CRAN_MIRROR', type = 'binary', lib = '$env:R_LIB_PATH', Ncpus = parallel::detectCores())\" ; Check-Output $?\n \n # MiKTeX and pandoc can be skipped on non-MinGW builds, since we don't\n@@ -165,7 +165,16 @@ if ($env:COMPILER -ne \"MSVC\") {\n     }\n     Run-R-Code-Redirect-Stderr \"commandArgs <- function(...){$env:BUILD_R_FLAGS}; source('build_r.R')\"; Check-Output $?\n   } elseif ($env:R_BUILD_TYPE -eq \"cran\") {\n+    # NOTE: gzip and tar are needed to create a CRAN package on Windows, but\n+    # some flavors of tar.exe can fail in some settings on Windows.\n+    # Putting the msys64 utilities at the beginning of PATH temporarily to be\n+    # sure they're used for that purpose.\n+    # $env:PATH = \"C:\\msys64\\usr\\bin;\" + $env:PATH\n+    if ($env:R_MAJOR_VERSION -eq \"3\") {\n+        $env:PATH = \"C:\\msys64\\usr\\bin;\" + $env:PATH\n+    }\n     Run-R-Code-Redirect-Stderr \"result <- processx::run(command = 'sh', args = 'build-cran-package.sh', echo = TRUE, windows_verbatim_args = FALSE, error_on_status = TRUE)\" ; Check-Output $?\n+    Remove-From-Path \".*msys64.*\"\n     # Test CRAN source .tar.gz in a directory that is not this repo or below it.\n     # When people install.packages('lightgbm'), they won't have the LightGBM\n     # git repo around. This is to protect against the use of relative paths\ndiff --git a/.github/workflows/r_package.yml b/.github/workflows/r_package.yml\nindex 8746297ba159..bff33548ce1d 100644\n--- a/.github/workflows/r_package.yml\n+++ b/.github/workflows/r_package.yml\n@@ -194,7 +194,7 @@ jobs:\n       - name: Install packages\n         shell: bash\n         run: |\n-          RDscript${{ matrix.r_customization }} -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'Matrix', 'testthat'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\"\n+          RDscript${{ matrix.r_customization }} -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'knitr', 'Matrix', 'rmarkdown', 'testthat'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\"\n           sh build-cran-package.sh --r-executable=RD${{ matrix.r_customization }}\n           RD${{ matrix.r_customization }} CMD INSTALL lightgbm_*.tar.gz || exit -1\n       - name: Run tests with sanitizers\n@@ -225,7 +225,7 @@ jobs:\n         shell: bash\n         run: |\n           export PATH=/opt/R-devel/bin/:${PATH}\n-          Rscript -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'Matrix', 'testthat'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\"\n+          Rscript -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'knitr', 'Matrix', 'rmarkdown', 'testthat'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\"\n           sh build-cran-package.sh\n           R CMD check --as-cran --run-donttest lightgbm_*.tar.gz || exit -1\n           if grep -q -E \"NOTE|WARNING|ERROR\" lightgbm.Rcheck/00check.log; then\ndiff --git a/.github/workflows/r_valgrind.yml b/.github/workflows/r_valgrind.yml\nindex d2e2fc0c2be9..56b9dac031fe 100644\n--- a/.github/workflows/r_valgrind.yml\n+++ b/.github/workflows/r_valgrind.yml\n@@ -7,7 +7,7 @@ on:\n jobs:\n   test-r-valgrind:\n     name: r-package (ubuntu-latest, R-devel, valgrind)\n-    timeout-minutes: 180\n+    timeout-minutes: 240\n     runs-on: ubuntu-latest\n     container: wch1/r-debug\n     env:\ndiff --git a/.github/workflows/static_analysis.yml b/.github/workflows/static_analysis.yml\nindex 77be3c89eae4..f631dfa89350 100644\n--- a/.github/workflows/static_analysis.yml\n+++ b/.github/workflows/static_analysis.yml\n@@ -57,7 +57,7 @@ jobs:\n       - name: Install packages\n         shell: bash\n         run: |\n-          Rscript -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'Matrix', 'roxygen2', 'testthat'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\"\n+          Rscript -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'Matrix', 'roxygen2', 'testthat', 'knitr', 'rmarkdown'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\"\n           sh build-cran-package.sh || exit -1\n           R CMD INSTALL --with-keep.source lightgbm_*.tar.gz || exit -1\n       - name: Test documentation\ndiff --git a/.vsts-ci.yml b/.vsts-ci.yml\nindex 059ebf9d35b4..e3f350eba594 100644\n--- a/.vsts-ci.yml\n+++ b/.vsts-ci.yml\n@@ -19,7 +19,7 @@ resources:\n     image: 'ubuntu:latest'\n     options: \"--name ci-container -v /usr/bin/docker:/tmp/docker:ro\"\n   - container: rbase\n-    image: rocker/r-base\n+    image: wch1/r-debug\n jobs:\n ###########################################\n - job: Linux\n@@ -300,6 +300,7 @@ jobs:\n   steps:\n   - script: |\n       LGB_VER=$(head -n 1 VERSION.txt | sed \"s/rc/-/g\")\n+      Rscript -e \"install.packages(c('R6', 'data.table', 'jsonlite', 'knitr', 'Matrix', 'rmarkdown', 'testthat'), dependencies = c('Depends', 'Imports', 'LinkingTo'), repos = 'https://cran.r-project.org', Ncpus = parallel::detectCores())\" || exit -1\n       sh build-cran-package.sh || exit -1\n       mv lightgbm_${LGB_VER}.tar.gz $(Build.ArtifactStagingDirectory)/lightgbm-${LGB_VER}-r-cran.tar.gz\n     displayName: 'Build CRAN R-package'\ndiff --git a/R-package/DESCRIPTION b/R-package/DESCRIPTION\nindex 490ca15b306a..e7993850f7c6 100755\n--- a/R-package/DESCRIPTION\n+++ b/R-package/DESCRIPTION\n@@ -45,8 +45,11 @@ URL: https://github.com/Microsoft/LightGBM\n BugReports: https://github.com/Microsoft/LightGBM/issues\n NeedsCompilation: yes\n Biarch: true\n+VignetteBuilder: knitr\n Suggests:\n+    knitr,\n     processx,\n+    rmarkdown,\n     testthat\n Depends:\n     R (>= 3.5),\ndiff --git a/R-package/README.md b/R-package/README.md\nindex 352071f0ad4b..d80a7f188025 100644\n--- a/R-package/README.md\n+++ b/R-package/README.md\n@@ -152,6 +152,7 @@ Rscript build_r.R\n \n The `build_r.R` script builds the package in a temporary directory called `lightgbm_r`. It will destroy and recreate that directory each time you run the script. That script supports the following command-line options:\n \n+- `--no-build-vignettes`: Skip building vignettes.\n - `--skip-install`: Build the package tarball, but do not install it.\n - `--use-gpu`: Build a GPU-enabled version of the library.\n - `--use-mingw`: Force the use of MinGW toolchain, regardless of R version.\n@@ -266,6 +267,11 @@ sh build-cran-package.sh\n \n This will create a file `lightgbm_${VERSION}.tar.gz`, where `VERSION` is the version of `LightGBM`.\n \n+That script supports the following command-line options:\n+\n+- `--no-build-vignettes`: Skip building vignettes.\n+- `--r-executable=[path-to-executable]`: use an alternative build of R\n+\n Also, CRAN package is generated with every commit to any repo's branch and can be found in \"Artifacts\" section of the associated Azure Pipelines run.\n \n ### Standard Installation from CRAN Package\ndiff --git a/R-package/pkgdown/_pkgdown.yml b/R-package/pkgdown/_pkgdown.yml\nindex b89ab96f3cd9..9e105d2c6bb5 100644\n--- a/R-package/pkgdown/_pkgdown.yml\n+++ b/R-package/pkgdown/_pkgdown.yml\n@@ -41,6 +41,8 @@ navbar:\n     href: ../\n   - icon: fa-home fa-lg\n     href: index.html\n+  - text: Articles\n+    href: articles/index.html\n   - text: Reference\n     href: reference/index.html\n   right:\ndiff --git a/R-package/vignettes/basic_walkthrough.Rmd b/R-package/vignettes/basic_walkthrough.Rmd\nnew file mode 100644\nindex 000000000000..f74f214e659f\n--- /dev/null\n+++ b/R-package/vignettes/basic_walkthrough.Rmd\n@@ -0,0 +1,115 @@\n+---\n+title:\n+  \"Basic Walkthrough\"\n+description: >\n+  This vignette describes how to train a LightGBM model for binary classification.\n+output: rmarkdown::html_vignette\n+vignette: >\n+  %\\VignetteIndexEntry{Basic Walkthrough}\n+  %\\VignetteEngine{knitr::rmarkdown}\n+  %\\VignetteEncoding{UTF-8}\n+---\n+\n+```{r, include = FALSE}\n+knitr::opts_chunk$set(\n+  collapse = TRUE\n+  , comment = \"#>\"\n+  , warning = FALSE\n+  , message = FALSE\n+)\n+```\n+\n+## Introduction\n+\n+Welcome to the world of [LightGBM](https://lightgbm.readthedocs.io/en/latest/), a highly efficient gradient boosting implementation (Ke et al. 2017).\n+\n+```{r setup}\n+library(lightgbm)\n+```\n+\n+This vignette will guide you through its basic usage. It will show how to build a simple binary classification model based on a subset of the `bank` dataset (Moro, Cortez, and Rita 2014). You will use the two input features \"age\" and \"balance\" to predict whether a client has subscribed a term deposit.\n+\n+## The dataset\n+\n+The dataset looks as follows.\n+\n+```{r}\n+data(bank, package = \"lightgbm\")\n+\n+bank[1L:5L, c(\"y\", \"age\", \"balance\")]\n+\n+# Distribution of the response\n+table(bank$y)\n+```\n+\n+## Training the model\n+\n+The R package of LightGBM offers two functions to train a model:\n+\n+- `lgb.train()`: This is the main training logic. It offers full flexibility but requires a `Dataset` object created by the `lgb.Dataset()` function.\n+- `lightgbm()`: Simpler, but less flexible. Data can be passed without having to bother with `lgb.Dataset()`.\n+\n+### Using the `lightgbm()` function\n+\n+In a first step, you need to convert data to numeric. Afterwards, you are ready to fit the model by the `lightgbm()` function.\n+\n+```{r}\n+# Numeric response and feature matrix\n+y <- as.numeric(bank$y == \"yes\")\n+X <- data.matrix(bank[, c(\"age\", \"balance\")])\n+\n+# Train\n+fit <- lightgbm(\n+  data = X\n+  , label = y\n+  , num_leaves = 4L\n+  , learning_rate = 1.0\n+  , nrounds = 10L\n+  , objective = \"binary\"\n+  , verbose = -1L\n+)\n+\n+# Result\n+summary(predict(fit, X))\n+```\n+\n+It seems to have worked! And the predictions are indeed probabilities between 0 and 1.\n+\n+### Using the `lgb.train()` function\n+\n+Alternatively, you can go for the more flexible interface `lgb.train()`. Here, as an additional step, you need to prepare `y` and `X` by the data API `lgb.Dataset()` of LightGBM. Parameters are passed to `lgb.train()` as a named list.\n+\n+```{r}\n+# Data interface\n+dtrain <- lgb.Dataset(X, label = y)\n+\n+# Parameters\n+params <- list(\n+  objective = \"binary\"\n+  , num_leaves = 4L\n+  , learning_rate = 1.0\n+)\n+\n+# Train\n+fit <- lgb.train(\n+  params\n+  , data = dtrain\n+  , nrounds = 10L\n+  , verbose = -1L\n+)\n+```\n+\n+Try it out! If stuck, visit LightGBM's [documentation](https://lightgbm.readthedocs.io/en/latest/R/index.html) for more details.\n+\n+```{r, echo = FALSE, results = \"hide\"}\n+# Cleanup\n+if (file.exists(\"lightgbm.model\")) {\n+  file.remove(\"lightgbm.model\")\n+}\n+```\n+\n+## References\n+\n+Ke, Guolin, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. \"LightGBM: A Highly Efficient Gradient Boosting Decision Tree.\" In Advances in Neural Information Processing Systems 30 (Nip 2017).\n+\n+Moro, S\u00e9rgio, Paulo Cortez, and Paulo Rita. 2014. \"A Data-Driven Approach to Predict the Success of Bank Telemarketing.\" Decision Support Systems 62: 22\u201331.\ndiff --git a/build-cran-package.sh b/build-cran-package.sh\nindex e4def4a14657..704edfbcc63e 100755\n--- a/build-cran-package.sh\n+++ b/build-cran-package.sh\n@@ -11,6 +11,11 @@\n #                    non-standard builds of R, such as those provided in\n #                    https://github.com/wch/r-debug.\n #\n+#     --no-build-vignettes Pass this flag to skip creating vignettes.\n+#                          You might want to do this to avoid installing\n+#                          vignette-only dependencies, or to avoid\n+#                          portability issues.\n+#\n # [usage]\n #\n #     # default usage\n@@ -18,9 +23,14 @@\n #\n #     # custom R build\n #     sh build-cran-package.sh --r-executable=RDvalgrind\n+#\n+#     # skip vignette building\n+#     sh build-cran-package.sh --no-build-vignettes\n \n set -e\n \n+# Default values of arguments\n+BUILD_VIGNETTES=true\n LGB_R_EXECUTABLE=R\n \n while [ $# -gt 0 ]; do\n@@ -28,6 +38,9 @@ while [ $# -gt 0 ]; do\n     --r-executable=*)\n       LGB_R_EXECUTABLE=\"${1#*=}\"\n       ;;\n+    --no-build-vignettes=*)\n+      BUILD_VIGNETTES=false\n+      ;;\n     *)\n       echo \"invalid argument '${1}'\"\n       exit -1\n@@ -57,6 +70,10 @@ cp -R R-package/* \"${TEMP_R_DIR}\"\n cp -R include \"${TEMP_R_DIR}/src/\"\n cp -R src/* \"${TEMP_R_DIR}/src/\"\n \n+if ${BUILD_VIGNETTES} ; then\n+    cp docs/logo/LightGBM_logo_black_text.svg \"${TEMP_R_DIR}/vignettes/\"\n+fi\n+\n cp \\\n     external_libs/fast_double_parser/include/fast_double_parser.h \\\n     \"${TEMP_R_DIR}/src/include/LightGBM\"\n@@ -169,8 +186,46 @@ cd \"${TEMP_R_DIR}\"\n \n cd \"${ORIG_WD}\"\n \n-\"${LGB_R_EXECUTABLE}\" CMD build \\\n-    --keep-empty-dirs \\\n-    lightgbm_r\n+if ${BUILD_VIGNETTES} ; then\n+    \"${LGB_R_EXECUTABLE}\" CMD build \\\n+        --keep-empty-dirs \\\n+        lightgbm_r\n+\n+    echo \"removing object files created by vignettes\"\n+    rm -rf ./_tmp\n+    mkdir _tmp\n+    TARBALL_NAME=\"lightgbm_${LGB_VERSION}.tar.gz\"\n+    mv \"${TARBALL_NAME}\" _tmp/\n+\n+    echo \"untarring ${TARBALL_NAME}\"\n+    cd _tmp\n+        tar -xvf \"${TARBALL_NAME}\" > /dev/null 2>&1\n+        rm -rf \"${TARBALL_NAME}\"\n+    cd ..\n+    echo \"done untarring ${TARBALL_NAME}\"\n+\n+    echo \"re-tarring ${TARBALL_NAME}\"\n+    tar \\\n+        -czv \\\n+        -C ./_tmp \\\n+        --exclude=*.a \\\n+        --exclude=*.dll \\\n+        --exclude=*.o \\\n+        --exclude=*.so \\\n+        --exclude=*.tar.gz \\\n+        --exclude=**/conftest.c \\\n+        --exclude=**/conftest.exe \\\n+        -f \"${TARBALL_NAME}\" \\\n+        lightgbm \\\n+    > /dev/null 2>&1\n+    echo \"Done creating ${TARBALL_NAME}\"\n+\n+    rm -rf ./_tmp\n+else\n+    \"${LGB_R_EXECUTABLE}\" CMD build \\\n+        --keep-empty-dirs \\\n+        --no-build-vignettes \\\n+        lightgbm_r\n+fi\n \n echo \"Done building R package\"\ndiff --git a/build_r.R b/build_r.R\nindex aa16c6fcdc6c..dc3f61e6efa1 100644\n--- a/build_r.R\n+++ b/build_r.R\n@@ -36,6 +36,7 @@ TEMP_SOURCE_DIR <- file.path(TEMP_R_DIR, \"src\")\n }\n parsed_args <- .parse_args(args)\n \n+SKIP_VIGNETTES <- \"--no-build-vignettes\" %in% parsed_args[[\"flags\"]]\n USING_GPU <- \"--use-gpu\" %in% parsed_args[[\"flags\"]]\n USING_MINGW <- \"--use-mingw\" %in% parsed_args[[\"flags\"]]\n USING_MSYS2 <- \"--use-msys2\" %in% parsed_args[[\"flags\"]]\n@@ -51,7 +52,8 @@ ARGS_TO_DEFINES <- c(\n )\n \n recognized_args <- c(\n-  \"--skip-install\"\n+  \"--no-build-vignettes\"\n+  , \"--skip-install\"\n   , \"--use-gpu\"\n   , \"--use-mingw\"\n   , \"--use-msys2\"\n@@ -407,7 +409,11 @@ writeLines(namespace_contents, NAMESPACE_FILE)\n # NOTE: --keep-empty-dirs is necessary to keep the deep paths expected\n #       by CMake while also meeting the CRAN req to create object files\n #       on demand\n-.run_shell_command(\"R\", c(\"CMD\", \"build\", TEMP_R_DIR, \"--keep-empty-dirs\"))\n+r_build_args <- c(\"CMD\", \"build\", TEMP_R_DIR, \"--keep-empty-dirs\")\n+if (isTRUE(SKIP_VIGNETTES)) {\n+  r_build_args <- c(r_build_args, \"--no-build-vignettes\")\n+}\n+.run_shell_command(\"R\", r_build_args)\n \n # Install the package\n version <- gsub(\ndiff --git a/docs/conf.py b/docs/conf.py\nindex b48ddce16c10..13751145d422 100644\n--- a/docs/conf.py\n+++ b/docs/conf.py\n@@ -273,8 +273,10 @@ def generate_r_docs(app: Sphinx) -> None:\n             r-base=4.1.0=hb67fd72_2 \\\n             r-data.table=1.14.0=r41hcfec24a_0 \\\n             r-jsonlite=1.7.2=r41hcfec24a_0 \\\n+            r-knitr=1.35=r41hc72bb7e_0 \\\n             r-matrix=1.3_4=r41he454529_0 \\\n             r-pkgdown=1.6.1=r41hc72bb7e_0 \\\n+            r-rmarkdown=2.11=r41hc72bb7e_0 \\\n             r-roxygen2=7.1.1=r41h03ef668_0\n     source /home/docs/.conda/bin/activate r_env\n     export TAR=/bin/tar\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Bug**: Object files (e.g., `*.o` files) should not be included in the source package. This raises a warning in `R CMD CHECK`.\n2. **Windows Error**: The command `nm.exe` fails with \"file format not recognized\" for several object files. Ensure object files are properly compiled.\n3. **Implementation Suggestion**: Review `.Rbuildignore` for syntax. Use `tools:::inRbuildignore` to test patterns.\n4. **Security Concern**: Address warnings for `qpdf`, as these should not be ignored to ensure CRAN compliance.\n5. **Action Item**: Test and resolve compression issues (e.g., `gzip` errors) affecting Windows builds. Install required dependencies to avoid build failures.\n6. **Next Steps**: Collaborate to push changes directly to the branch, resolve conflicts, and ensure CI tests, particularly for vignettes, pass successfully."
      }
    ],
    "codediff_length": 18850
  },
  {
    "index": 15,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.ci/setup.sh b/.ci/setup.sh\nindex f389b28e190d..7e9229d14447 100755\n--- a/.ci/setup.sh\n+++ b/.ci/setup.sh\n@@ -17,8 +17,10 @@ if [[ $OS_NAME == \"macos\" ]]; then\n     if [[ $TASK == \"swig\" ]]; then\n         brew install swig\n     fi\n-    brew install graphviz\n-    curl -sL -o conda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh\n+    curl \\\n+        -sL \\\n+        -o miniforge.sh \\\n+        https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-MacOSX-x86_64.sh\n else  # Linux\n     if [[ $IN_UBUNTU_LATEST_CONTAINER == \"true\" ]]; then\n         # fixes error \"unable to initialize frontend: Dialog\"\n@@ -42,9 +44,6 @@ else  # Linux\n             libicu66 \\\n             libssl1.1 \\\n             libunwind8 \\\n-            libxau6 \\\n-            libxext6 \\\n-            libxrender1 \\\n             locales \\\n             netcat \\\n             unzip \\\n@@ -81,16 +80,11 @@ else  # Linux\n         mv $AMDAPPSDK_PATH/lib/x86_64/sdk/* $AMDAPPSDK_PATH/lib/x86_64/\n         echo libamdocl64.so > $OPENCL_VENDOR_PATH/amdocl64.icd\n     fi\n-    ARCH=$(uname -m)\n     if [[ $TASK == \"cuda\" ]]; then\n         echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections\n         apt-get update\n         apt-get install --no-install-recommends -y \\\n             curl \\\n-            graphviz \\\n-            libxau6 \\\n-            libxext6 \\\n-            libxrender1 \\\n             lsb-release \\\n             software-properties-common\n         if [[ $COMPILER == \"clang\" ]]; then\n@@ -103,29 +97,19 @@ else  # Linux\n         apt-get update\n         apt-get install --no-install-recommends -y \\\n             cmake\n-    else\n-        if [[ $ARCH != \"x86_64\" ]]; then\n-            yum update -y\n-            yum install -y \\\n-                graphviz\n-        else\n-            sudo apt-get update\n-            sudo apt-get install --no-install-recommends -y \\\n-                graphviz\n-        fi\n     fi\n     if [[ $SETUP_CONDA != \"false\" ]]; then\n-        if [[ $ARCH == \"x86_64\" ]]; then\n-            curl -sL -o conda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n-        else\n-            curl -sL -o conda.sh https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-${ARCH}.sh\n-        fi\n+        ARCH=$(uname -m)\n+        curl \\\n+            -sL \\\n+            -o miniforge.sh \\\n+            https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-${ARCH}.sh\n     fi\n fi\n \n-if [[ \"${TASK}\" != \"r-package\" ]]; then\n+if [[ \"${TASK}\" != \"r-package\" ]] && [[ \"${TASK}\" != \"r-rchk\" ]]; then\n     if [[ $SETUP_CONDA != \"false\" ]]; then\n-        sh conda.sh -b -p $CONDA\n+        sh miniforge.sh -b -p $CONDA\n     fi\n     conda config --set always_yes yes --set changeps1 no\n     conda update -q -y conda\ndiff --git a/.ci/test.sh b/.ci/test.sh\nindex e3d385ab8b71..c94151ac1e51 100755\n--- a/.ci/test.sh\n+++ b/.ci/test.sh\n@@ -62,16 +62,13 @@ fi\n \n if [[ $TASK == \"lint\" ]]; then\n     conda install -q -y -n $CONDA_ENV \\\n+        cmakelint \\\n+        cpplint \\\n+        isort \\\n+        mypy \\\n         pycodestyle \\\n         pydocstyle \\\n-        r-stringi  # stringi needs to be installed separate from r-lintr to avoid issues like 'unable to load shared object stringi.so'\n-    # r-xfun below has to be upgraded because lintr requires > 0.19 for that package\n-    conda install -q -y -n $CONDA_ENV \\\n-        -c conda-forge \\\n-            libxml2 \\\n-            \"r-xfun>=0.19\" \\\n-            \"r-lintr>=2.0\"\n-    pip install --user cmakelint cpplint isort mypy\n+        \"r-lintr>=2.0\"\n     echo \"Linting Python code\"\n     pycodestyle --ignore=E501,W503 --exclude=./.nuget,./external_libs . || exit -1\n     pydocstyle --convention=numpy --add-ignore=D105 --match-dir=\"^(?!^external_libs|test|example).*\" --match=\"(?!^test_|setup).*\\.py\" . || exit -1\n@@ -114,8 +111,22 @@ if [[ $TASK == \"swig\" ]]; then\n     exit 0\n fi\n \n-conda install -q -y -n $CONDA_ENV cloudpickle \"dask=2021.9.1\" \"distributed=2021.9.1\" joblib matplotlib numpy pandas psutil pytest scikit-learn scipy\n-pip install graphviz  # python-graphviz from Anaconda is not allowed to be installed with Python 3.9\n+conda install -q -y -n $CONDA_ENV \\\n+    cloudpickle \\\n+    dask \\\n+    distributed \\\n+    joblib \\\n+    matplotlib \\\n+    numpy \\\n+    pandas \\\n+    psutil \\\n+    pytest \\\n+    scikit-learn \\\n+    scipy || exit -1\n+\n+# python-graphviz has to be installed separately to prevent conda from downgrading to pypy\n+conda install -q -y -n $CONDA_ENV \\\n+    python-graphviz || exit -1\n \n if [[ $OS_NAME == \"macos\" ]] && [[ $COMPILER == \"clang\" ]]; then\n     # fix \"OMP: Error #15: Initializing libiomp5.dylib, but found libomp.dylib already initialized.\" (OpenMP library conflict due to conda's MKL)\n@@ -229,7 +240,11 @@ import matplotlib\\\n matplotlib.use\\(\\\"Agg\\\"\\)\\\n ' plot_example.py  # prevent interactive window mode\n     sed -i'.bak' 's/graph.render(view=True)/graph.render(view=False)/' plot_example.py\n-    conda install -q -y -n $CONDA_ENV h5py ipywidgets notebook  # requirements for examples\n+    # requirements for examples\n+    conda install -q -y -n $CONDA_ENV \\\n+        h5py \\\n+        ipywidgets \\\n+        notebook\n     for f in *.py **/*.py; do python $f || exit -1; done  # run all examples\n     cd $BUILD_DIRECTORY/examples/python-guide/notebooks\n     sed -i'.bak' 's/INTERACTIVE = False/assert False, \\\\\"Interactive mode disabled\\\\\"/' interactive_plot_example.ipynb\ndiff --git a/.github/workflows/cuda.yml b/.github/workflows/cuda.yml\nindex 2100e171ee7b..52511e222db2 100644\n--- a/.github/workflows/cuda.yml\n+++ b/.github/workflows/cuda.yml\n@@ -81,7 +81,7 @@ jobs:\n             LGB_VER=$(head -n 1 VERSION.txt)\n             EOF\n             cat > docker-script.sh <<EOF\n-            export CONDA=\\$HOME/miniconda\n+            export CONDA=\\$HOME/miniforge\n             export PATH=\\$CONDA/bin:\\$PATH\n             nvidia-smi\n             $ROOT_DOCKER_FOLDER/.ci/setup.sh || exit -1\ndiff --git a/.github/workflows/linkchecker.yml b/.github/workflows/linkchecker.yml\nindex 0e570109518b..53b4319fbdef 100644\n--- a/.github/workflows/linkchecker.yml\n+++ b/.github/workflows/linkchecker.yml\n@@ -27,7 +27,7 @@ jobs:\n       - name: Setup and run tests\n         run: |\n           export BUILD_DIRECTORY=\"$GITHUB_WORKSPACE\"\n-          export CONDA=${HOME}/miniconda\n+          export CONDA=${HOME}/miniforge\n           export PATH=${CONDA}/bin:${HOME}/.local/bin:${PATH}\n           $GITHUB_WORKSPACE/.ci/setup.sh || exit -1\n           $GITHUB_WORKSPACE/.ci/test.sh || exit -1\ndiff --git a/.github/workflows/python_package.yml b/.github/workflows/python_package.yml\nindex 8c0e45b8fd3e..8db4c68fc355 100644\n--- a/.github/workflows/python_package.yml\n+++ b/.github/workflows/python_package.yml\n@@ -66,7 +66,7 @@ jobs:\n           fi\n           export BUILD_DIRECTORY=\"$GITHUB_WORKSPACE\"\n           export LGB_VER=$(head -n 1 VERSION.txt)\n-          export CONDA=${HOME}/miniconda\n+          export CONDA=${HOME}/miniforge\n           export PATH=${CONDA}/bin:${PATH}\n           $GITHUB_WORKSPACE/.ci/setup.sh || exit -1\n           $GITHUB_WORKSPACE/.ci/test.sh || exit -1\ndiff --git a/.github/workflows/static_analysis.yml b/.github/workflows/static_analysis.yml\nindex 123a93e2462b..1a9956a708f5 100644\n--- a/.github/workflows/static_analysis.yml\n+++ b/.github/workflows/static_analysis.yml\n@@ -39,7 +39,7 @@ jobs:\n         run: |\n           export TASK=\"${{ matrix.task }}\"\n           export BUILD_DIRECTORY=\"$GITHUB_WORKSPACE\"\n-          export CONDA=${HOME}/miniconda\n+          export CONDA=${HOME}/miniforge\n           export PATH=${CONDA}/bin:$HOME/.local/bin:${PATH}\n           $GITHUB_WORKSPACE/.ci/setup.sh || exit -1\n           $GITHUB_WORKSPACE/.ci/test.sh || exit -1\ndiff --git a/.vsts-ci.yml b/.vsts-ci.yml\nindex 605e7f4512b8..3d182891b73e 100644\n--- a/.vsts-ci.yml\n+++ b/.vsts-ci.yml\n@@ -14,7 +14,7 @@ variables:\n resources:\n   containers:\n   - container: ubuntu1404\n-    image: lightgbm/vsts-agent:ubuntu-14.04\n+    image: lightgbm/vsts-agent:ubuntu-14.04-dev\n   - container: ubuntu-latest\n     image: 'ubuntu:latest'\n     options: \"--name ci-container -v /usr/bin/docker:/tmp/docker:ro\"\n@@ -49,6 +49,9 @@ jobs:\n       gpu_source:\n         TASK: gpu\n         METHOD: source\n+        # on Ubuntu 14.04, gpu_source build segfaults with newer version of Python\n+        # (and newer version of scipy as a consequence)\n+        PYTHON_VERSION: 3.7\n       swig:\n         TASK: swig\n   steps:\n@@ -122,7 +125,7 @@ jobs:\n   - script: |\n       echo \"##vso[task.setvariable variable=BUILD_DIRECTORY]$BUILD_SOURCESDIRECTORY\"\n       echo \"##vso[task.setvariable variable=LGB_VER]$(head -n 1 VERSION.txt)\"\n-      CONDA=$HOME/miniconda\n+      CONDA=$HOME/miniforge\n       echo \"##vso[task.setvariable variable=CONDA]$CONDA\"\n       echo \"##vso[task.prependpath]$CONDA/bin\"\n       AMDAPPSDK_PATH=$BUILD_SOURCESDIRECTORY/AMDAPPSDK\n@@ -183,7 +186,7 @@ jobs:\n       BUILD_ARTIFACTSTAGINGDIRECTORY=$BUILD_ARTIFACTSTAGINGDIRECTORY\n       EOF\n       cat > docker-script.sh <<EOF\n-      export CONDA=\\$HOME/miniconda\n+      export CONDA=\\$HOME/miniforge\n       export PATH=\\$CONDA/bin:\\$PATH\n       $ROOT_DOCKER_FOLDER/.ci/setup.sh || exit -1\n       $ROOT_DOCKER_FOLDER/.ci/test.sh || exit -1\n@@ -236,7 +239,7 @@ jobs:\n   - script: |\n       echo \"##vso[task.setvariable variable=BUILD_DIRECTORY]$BUILD_SOURCESDIRECTORY\"\n       echo \"##vso[task.setvariable variable=LGB_VER]$(head -n 1 VERSION.txt)\"\n-      CONDA=$AGENT_HOMEDIRECTORY/miniconda\n+      CONDA=$AGENT_HOMEDIRECTORY/miniforge\n       echo \"##vso[task.setvariable variable=CONDA]$CONDA\"\n       echo \"##vso[task.prependpath]$CONDA/bin\"\n       echo \"##vso[task.setvariable variable=JAVA_HOME]$JAVA_HOME_8_X64\"\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Timeout Issue**: Jobs in `Linux sdist` are timing out, possibly related to the use of `pypy` with Python 3.7.12. Consider switching to CPython for CI tests to mitigate this.\n\n2. **Compiler Swaps**: Utilize different compilers as seen in recent commits. Address segfaults specifically in `Linux gpu_source` builds; logs indicate issues possibly related to compiler choice.\n\n3. **Mamba Integration**: Transition to using `mamba` in Windows CI jobs. There\u2019s a bug with `mamba config` not being supported; maintain existing `conda config` commands.\n\n4. **Cache Issues**: Investigate `mamba` cache handling, as logs show MD5 sum mismatches and truncated tar files. Implement `mamba clean` after package installations to manage potential cache corruption.\n\n5. **Next Steps**: Focus on stabilizing the builds with sequential test runs, document all changes made, and conduct thorough logging to isolate failures."
      }
    ],
    "codediff_length": 9770
  },
  {
    "index": 16,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/R-package/NAMESPACE b/R-package/NAMESPACE\nindex 99139fe99276..91f752e36dc7 100644\n--- a/R-package/NAMESPACE\n+++ b/R-package/NAMESPACE\n@@ -21,14 +21,17 @@ export(lgb.Dataset.set.categorical)\n export(lgb.Dataset.set.reference)\n export(lgb.convert_with_rules)\n export(lgb.cv)\n+export(lgb.drop_serialized)\n export(lgb.dump)\n export(lgb.get.eval.result)\n export(lgb.importance)\n export(lgb.interprete)\n export(lgb.load)\n+export(lgb.make_serializable)\n export(lgb.model.dt.tree)\n export(lgb.plot.importance)\n export(lgb.plot.interpretation)\n+export(lgb.restore_handle)\n export(lgb.save)\n export(lgb.train)\n export(lgb.unloader)\ndiff --git a/R-package/R/lgb.Booster.R b/R-package/R/lgb.Booster.R\nindex 0a3fee00e47c..c7c50864d7e0 100644\n--- a/R-package/R/lgb.Booster.R\n+++ b/R-package/R/lgb.Booster.R\n@@ -86,9 +86,9 @@ Booster <- R6::R6Class(\n \n         } else if (!is.null(model_str)) {\n \n-          # Do we have a model_str as character?\n-          if (!is.character(model_str)) {\n-            stop(\"lgb.Booster: Can only use a string as model_str\")\n+          # Do we have a model_str as character/raw?\n+          if (!is.raw(model_str) && !is.character(model_str)) {\n+            stop(\"lgb.Booster: Can only use a character/raw vector as model_str\")\n           }\n \n           # Create booster from model\n@@ -196,6 +196,8 @@ Booster <- R6::R6Class(\n       params <- utils::modifyList(params, additional_params)\n       params_str <- lgb.params2str(params = params)\n \n+      self$restore_handle()\n+\n       .Call(\n         LGBM_BoosterResetParameter_R\n         , private$handle\n@@ -289,6 +291,8 @@ Booster <- R6::R6Class(\n     # Return one iteration behind\n     rollback_one_iter = function() {\n \n+      self$restore_handle()\n+\n       .Call(\n         LGBM_BoosterRollbackOneIter_R\n         , private$handle\n@@ -306,6 +310,8 @@ Booster <- R6::R6Class(\n     # Get current iteration\n     current_iter = function() {\n \n+      self$restore_handle()\n+\n       cur_iter <- 0L\n       .Call(\n         LGBM_BoosterGetCurrentIteration_R\n@@ -319,6 +325,8 @@ Booster <- R6::R6Class(\n     # Get upper bound\n     upper_bound = function() {\n \n+      self$restore_handle()\n+\n       upper_bound <- 0.0\n       .Call(\n         LGBM_BoosterGetUpperBoundValue_R\n@@ -332,6 +340,8 @@ Booster <- R6::R6Class(\n     # Get lower bound\n     lower_bound = function() {\n \n+      self$restore_handle()\n+\n       lower_bound <- 0.0\n       .Call(\n         LGBM_BoosterGetLowerBoundValue_R\n@@ -423,6 +433,8 @@ Booster <- R6::R6Class(\n     # Save model\n     save_model = function(filename, num_iteration = NULL, feature_importance_type = 0L) {\n \n+      self$restore_handle()\n+\n       if (is.null(num_iteration)) {\n         num_iteration <- self$best_iter\n       }\n@@ -440,7 +452,9 @@ Booster <- R6::R6Class(\n       return(invisible(self))\n     },\n \n-    save_model_to_string = function(num_iteration = NULL, feature_importance_type = 0L) {\n+    save_model_to_string = function(num_iteration = NULL, feature_importance_type = 0L, as_char = TRUE) {\n+\n+      self$restore_handle()\n \n       if (is.null(num_iteration)) {\n         num_iteration <- self$best_iter\n@@ -453,6 +467,10 @@ Booster <- R6::R6Class(\n           , as.integer(feature_importance_type)\n       )\n \n+      if (as_char) {\n+        model_str <- rawToChar(model_str)\n+      }\n+\n       return(model_str)\n \n     },\n@@ -460,6 +478,8 @@ Booster <- R6::R6Class(\n     # Dump model in memory\n     dump_model = function(num_iteration = NULL, feature_importance_type = 0L) {\n \n+      self$restore_handle()\n+\n       if (is.null(num_iteration)) {\n         num_iteration <- self$best_iter\n       }\n@@ -487,6 +507,8 @@ Booster <- R6::R6Class(\n                        params = list(),\n                        ...) {\n \n+      self$restore_handle()\n+\n       additional_params <- list(...)\n       if (length(additional_params) > 0L) {\n         warning(paste0(\n@@ -531,17 +553,39 @@ Booster <- R6::R6Class(\n       return(Predictor$new(modelfile = private$handle))\n     },\n \n-    # Used for save\n-    raw = NA,\n+    # Used for serialization\n+    raw = NULL,\n \n-    # Save model to temporary file for in-memory saving\n-    save = function() {\n+    # Store serialized raw bytes in model object\n+    save_raw = function() {\n+      if (is.null(self$raw)) {\n+        self$raw <- self$save_model_to_string(NULL, as_char = FALSE)\n+      }\n+      return(invisible(NULL))\n \n-      # Overwrite model in object\n-      self$raw <- self$save_model_to_string(NULL)\n+    },\n \n+    drop_raw = function() {\n+      self$raw <- NULL\n       return(invisible(NULL))\n+    },\n \n+    check_null_handle = function() {\n+      return(lgb.is.null.handle(private$handle))\n+    },\n+\n+    restore_handle = function() {\n+      if (self$check_null_handle()) {\n+        if (is.null(self$raw)) {\n+          .Call(LGBM_NullBoosterHandleError_R)\n+        }\n+        private$handle <- .Call(LGBM_BoosterLoadModelFromString_R, self$raw)\n+      }\n+      return(invisible(NULL))\n+    },\n+\n+    get_handle = function() {\n+      return(private$handle)\n     }\n \n   ),\n@@ -640,6 +684,8 @@ Booster <- R6::R6Class(\n         stop(\"data_idx should not be greater than num_dataset\")\n       }\n \n+      self$restore_handle()\n+\n       private$get_eval_info()\n \n       ret <- list()\n@@ -878,7 +924,7 @@ summary.lgb.Booster <- function(object, ...) {\n #' @description Load LightGBM takes in either a file path or model string.\n #'              If both are provided, Load will default to loading from file\n #' @param filename path of model file\n-#' @param model_str a str containing the model\n+#' @param model_str a str containing the model (as a `character` or `raw` vector)\n #'\n #' @return lgb.Booster\n #'\n@@ -928,8 +974,8 @@ lgb.load <- function(filename = NULL, model_str = NULL) {\n   }\n \n   if (model_str_provided) {\n-    if (!is.character(model_str)) {\n-      stop(\"lgb.load: model_str should be character\")\n+    if (!is.raw(model_str) && !is.character(model_str)) {\n+      stop(\"lgb.load: model_str should be a character/raw vector\")\n     }\n     return(invisible(Booster$new(model_str = model_str)))\n   }\ndiff --git a/R-package/R/lgb.Predictor.R b/R-package/R/lgb.Predictor.R\nindex c27238825a17..3ca8ea98348e 100644\n--- a/R-package/R/lgb.Predictor.R\n+++ b/R-package/R/lgb.Predictor.R\n@@ -39,12 +39,17 @@ Predictor <- R6::R6Class(\n         )\n         private$need_free_handle <- TRUE\n \n-      } else if (methods::is(modelfile, \"lgb.Booster.handle\")) {\n+      } else if (methods::is(modelfile, \"lgb.Booster.handle\") || inherits(modelfile, \"externalptr\")) {\n \n         # Check if model file is a booster handle already\n         handle <- modelfile\n         private$need_free_handle <- FALSE\n \n+      } else if (lgb.is.Booster(modelfile)) {\n+\n+        handle <- modelfile$get_handle()\n+        private$need_free_handle <- FALSE\n+\n       } else {\n \n         stop(\"lgb.Predictor: modelfile must be either a character filename or an lgb.Booster.handle\")\ndiff --git a/R-package/R/lgb.cv.R b/R-package/R/lgb.cv.R\nindex 039411e4cf40..db30bbe9fe02 100644\n--- a/R-package/R/lgb.cv.R\n+++ b/R-package/R/lgb.cv.R\n@@ -98,6 +98,7 @@ lgb.cv <- function(params = list()\n                    , early_stopping_rounds = NULL\n                    , callbacks = list()\n                    , reset_data = FALSE\n+                   , serializable = TRUE\n                    , ...\n                    ) {\n \n@@ -456,6 +457,10 @@ lgb.cv <- function(params = list()\n     })\n   }\n \n+  if (serializable) {\n+    lapply(cv_booster$boosters, function(model) model$booster$save_raw())\n+  }\n+\n   return(cv_booster)\n \n }\ndiff --git a/R-package/R/lgb.drop_serialized.R b/R-package/R/lgb.drop_serialized.R\nnew file mode 100644\nindex 000000000000..1e1157ff997f\n--- /dev/null\n+++ b/R-package/R/lgb.drop_serialized.R\n@@ -0,0 +1,18 @@\n+#' @name lgb.drop_serialized\n+#' @title Drop serialized raw bytes in a LightGBM model object\n+#' @description If a LightGBM model object was produced with argument `serializable=TRUE`, the R object will keep\n+#' a copy of the underlying C++ object as raw bytes, which can be used to reconstruct such object after getting\n+#' serialized and de-serialized, but at the cost of extra memory usage. If these raw bytes are not needed anymore,\n+#' they can be dropped through this function in order to save memory. Note that the object will be modified in-place.\n+#' @param model \\code{lgb.Booster} object which was produced with `serializable=TRUE`.\n+#'\n+#' @return \\code{lgb.Booster} (the same `model` object that was passed as input, as invisible).\n+#' @seealso \\link{lgb.restore_handle}, \\link{lgb.make_serializable}.\n+#' @export\n+lgb.drop_serialized <- function(model) {\n+  if (!lgb.is.Booster(x = model)) {\n+    stop(\"lgb.drop_serialized: model should be an \", sQuote(\"lgb.Booster\"))\n+  }\n+  model$drop_raw()\n+  return(invisible(model))\n+}\ndiff --git a/R-package/R/lgb.make_serializable.R b/R-package/R/lgb.make_serializable.R\nnew file mode 100644\nindex 000000000000..515341f275e1\n--- /dev/null\n+++ b/R-package/R/lgb.make_serializable.R\n@@ -0,0 +1,18 @@\n+#' @name lgb.make_serializable\n+#' @title Make a LightGBM object serializable by keeping raw bytes\n+#' @description If a LightGBM model object was produced with argument `serializable=FALSE`, the R object will not\n+#' be serializable (e.g. cannot save and load with \\code{saveRDS} and \\code{readRDS}) as it will lack the raw bytes\n+#' needed to reconstruct its underlying C++ object. This function can be used to forcibly produce those serialized\n+#' raw bytes and make the object serializable. Note that the object will be modified in-place.\n+#' @param model \\code{lgb.Booster} object which was produced with `serializable=FALSE`.\n+#'\n+#' @return \\code{lgb.Booster} (the same `model` object that was passed as input, as invisible).\n+#' @seealso \\link{lgb.restore_handle}, \\link{lgb.drop_serialized}.\n+#' @export\n+lgb.make_serializable <- function(model) {\n+  if (!lgb.is.Booster(x = model)) {\n+    stop(\"lgb.make_serializable: model should be an \", sQuote(\"lgb.Booster\"))\n+  }\n+  model$save_raw()\n+  return(invisible(model))\n+}\ndiff --git a/R-package/R/lgb.restore_handle.R b/R-package/R/lgb.restore_handle.R\nnew file mode 100644\nindex 000000000000..be3036a52986\n--- /dev/null\n+++ b/R-package/R/lgb.restore_handle.R\n@@ -0,0 +1,36 @@\n+#' @name lgb.restore_handle\n+#' @title Restore the C++ component of a de-serialized LightGBM model\n+#' @description After a LightGBM model object is de-serialized through functions such as \\code{save} or\n+#' \\code{saveRDS}, its underlying C++ object will be blank and needs to be restored to able to use it. Such\n+#' object is restored automatically when calling functions such as \\code{predict}, but this function can be\n+#' used to forcibly restore it beforehand. Note that the object will be modified in-place.\n+#' @param model \\code{lgb.Booster} object which was de-serialized and whose underlying C++ object and R handle\n+#' need to be restored.\n+#'\n+#' @return \\code{lgb.Booster} (the same `model` object that was passed as input, invisibly).\n+#' @seealso \\link{lgb.make_serializable}, \\link{lgb.drop_serialized}.\n+#' @examples\n+#' library(lightgbm)\n+#' data(\"agaricus.train\")\n+#' model <- lightgbm(\n+#'   agaricus.train$data\n+#'   , agaricus.train$label\n+#'   , params = list(objective = \"binary\", nthreads = 1L)\n+#'   , nrounds = 5L\n+#'   , save_name = NULL\n+#'   , verbose = 0)\n+#' fname <- tempfile(fileext=\"rds\")\n+#' saveRDS(model, fname)\n+#'\n+#' model_new <- readRDS(fname)\n+#' model_new$check_null_handle()\n+#' lgb.restore_handle(model_new)\n+#' model_new$check_null_handle()\n+#' @export\n+lgb.restore_handle <- function(model) {\n+  if (!lgb.is.Booster(x = model)) {\n+    stop(\"lgb.restore_handle: model should be an \", sQuote(\"lgb.Booster\"))\n+  }\n+  model$restore_handle()\n+  return(invisible(model))\n+}\ndiff --git a/R-package/R/lgb.train.R b/R-package/R/lgb.train.R\nindex 6f602fe416a4..06ab8d94559b 100644\n--- a/R-package/R/lgb.train.R\n+++ b/R-package/R/lgb.train.R\n@@ -67,6 +67,7 @@ lgb.train <- function(params = list(),\n                       early_stopping_rounds = NULL,\n                       callbacks = list(),\n                       reset_data = FALSE,\n+                      serializable = TRUE,\n                       ...) {\n \n   # validate inputs early to avoid unnecessary computation\n@@ -395,6 +396,10 @@ lgb.train <- function(params = list(),\n \n   }\n \n+  if (serializable) {\n+    booster$save_raw()\n+  }\n+\n   return(booster)\n \n }\ndiff --git a/R-package/R/lightgbm.R b/R-package/R/lightgbm.R\nindex e2df9063ed26..6f7e538b5c20 100644\n--- a/R-package/R/lightgbm.R\n+++ b/R-package/R/lightgbm.R\n@@ -52,6 +52,8 @@\n #' @param params a list of parameters. See \\href{https://lightgbm.readthedocs.io/en/latest/Parameters.html}{\n #'               the \"Parameters\" section of the documentation} for a list of parameters and valid values.\n #' @param verbose verbosity for output, if <= 0, also will disable the print of evaluation during training\n+#' @param serializable whether to make the resulting objects serializable through functions such as\n+#' \\code{save} or \\code{saveRDS} (see section \"Model serialization\").\n #' @section Early Stopping:\n #'\n #'          \"early stopping\" refers to stopping the training process if the model's performance on a given\n@@ -66,6 +68,21 @@\n #'          in \\code{params}, that metric will be considered the \"first\" one. If you omit \\code{metric},\n #'          a default metric will be used based on your choice for the parameter \\code{obj} (keyword argument)\n #'          or \\code{objective} (passed into \\code{params}).\n+#' @section Model serialization:\n+#'\n+#'          LightGBM model objects can be serialized and de-serialized through functions such as \\code{save}\n+#'          or \\code{saveRDS}, but similarly to libraries such as 'xgboost', serialization works a bit differently\n+#'          from typical R objects. In order to make models serializable in R, a copy of the underlying C++ object\n+#'          as serialized raw bytes is produced and stored in the R model object, and when this R object is\n+#'          de-serialized, the underlying C++ model object gets reconstructed from these raw bytes, but will only\n+#'          do so once some function that uses it is called, such as \\code{predict}. In order to forcibly\n+#'          reconstruct the C++ object after deserialization (e.g. after calling \\code{readRDS} or similar), one\n+#'          can use the function \\link{lgb.restore_handle} (for example, if one makes predictions in parallel or in\n+#'          forked processes, it will be faster to restore the handle beforehand).\n+#'\n+#'          Producing and keeping these raw bytes however uses extra memory, and if they are not required,\n+#'          it is possible to avoid producing them by passing `serializable=FALSE`. In such cases, these raw\n+#'          bytes can be added to the model on demand through function \\link{lgb.make_serializable}.\n #' @keywords internal\n NULL\n \n@@ -76,6 +93,7 @@ NULL\n #' @param label Vector of labels, used if \\code{data} is not an \\code{\\link{lgb.Dataset}}\n #' @param weight vector of response values. If not NULL, will set to dataset\n #' @param save_name File name to use when writing the trained model to disk. Should end in \".model\".\n+#'                  If passing `NULL`, will not save the trained model to disk.\n #' @param ... Additional arguments passed to \\code{\\link{lgb.train}}. For example\n #'     \\itemize{\n #'        \\item{\\code{valids}: a list of \\code{lgb.Dataset} objects, used for validation}\n@@ -113,6 +131,7 @@ lightgbm <- function(data,\n                      save_name = \"lightgbm.model\",\n                      init_model = NULL,\n                      callbacks = list(),\n+                     serializable = TRUE,\n                      ...) {\n \n   # validate inputs early to avoid unnecessary computation\n@@ -137,6 +156,7 @@ lightgbm <- function(data,\n     , \"early_stopping_rounds\" = early_stopping_rounds\n     , \"init_model\" = init_model\n     , \"callbacks\" = callbacks\n+    , \"serializable\" = serializable\n   )\n   train_args <- append(train_args, list(...))\n \n@@ -156,7 +176,9 @@ lightgbm <- function(data,\n   )\n \n   # Store model under a specific name\n-  bst$save_model(filename = save_name)\n+  if (!is.null(save_name)) {\n+    bst$save_model(filename = save_name)\n+  }\n \n   return(bst)\n }\ndiff --git a/R-package/R/readRDS.lgb.Booster.R b/R-package/R/readRDS.lgb.Booster.R\nindex 4844abeb3aa9..a995d804adc5 100644\n--- a/R-package/R/readRDS.lgb.Booster.R\n+++ b/R-package/R/readRDS.lgb.Booster.R\n@@ -1,6 +1,9 @@\n #' @name readRDS.lgb.Booster\n-#' @title readRDS for \\code{lgb.Booster} models\n-#' @description Attempts to load a model stored in a \\code{.rds} file, using \\code{\\link[base]{readRDS}}\n+#' @title readRDS for \\code{lgb.Booster} models (DEPRECATED)\n+#' @description Calls \\code{readRDS} in what is expected to be a serialized \\code{lgb.Booster} object,\n+#'              and then restores its handle through \\code{lgb.restore_handle}.\n+#'\n+#'              \\bold{This function throws a warning and will be removed in future versions.}\n #' @param file a connection or the name of the file where the R object is saved to or read from.\n #' @param refhook a hook function for handling reference objects.\n #'\n@@ -36,27 +39,9 @@\n #' @export\n readRDS.lgb.Booster <- function(file, refhook = NULL) {\n \n-  object <- readRDS(file = file, refhook = refhook)\n-\n-  # Check if object has the model stored\n-  if (!is.na(object$raw)) {\n-\n-    # Create temporary model for the model loading\n-    object2 <- lgb.load(model_str = object$raw)\n-\n-    # Restore best iteration and recorded evaluations\n-    object2$best_iter <- object$best_iter\n-    object2$record_evals <- object$record_evals\n-    object2$params <- object$params\n-\n-    # Return newly loaded object\n-    return(object2)\n-\n-  } else {\n-\n-    # Return RDS loaded object\n-    return(object)\n-\n-  }\n+  warning(\"'readRDS.lgb.Booster' is deprecated and will be removed in a future release. Use readRDS() instead.\")\n \n+  object <- readRDS(file = file, refhook = refhook)\n+  lgb.restore_handle(object)\n+  return(object)\n }\ndiff --git a/R-package/R/saveRDS.lgb.Booster.R b/R-package/R/saveRDS.lgb.Booster.R\nindex 705cc266fcbb..eb71e7a2f08c 100644\n--- a/R-package/R/saveRDS.lgb.Booster.R\n+++ b/R-package/R/saveRDS.lgb.Booster.R\n@@ -1,7 +1,9 @@\n #' @name saveRDS.lgb.Booster\n-#' @title saveRDS for \\code{lgb.Booster} models\n-#' @description Attempts to save a model using RDS. Has an additional parameter (\\code{raw})\n-#'              which decides whether to save the raw model or not.\n+#' @title saveRDS for \\code{lgb.Booster} models (DEPRECATED)\n+#' @description Calls \\code{saveRDS} on an \\code{lgb.Booster} object, making it serializable before the call if\n+#'              it isn't already.\n+#'\n+#'              \\bold{This function throws a warning and will be removed in future versions.}\n #' @param object \\code{lgb.Booster} object to serialize.\n #' @param file a connection or the name of the file where the R object is saved to or read from.\n #' @param ascii a logical. If TRUE or NA, an ASCII representation is written; otherwise (default),\n@@ -52,38 +54,24 @@ saveRDS.lgb.Booster <- function(object,\n                                 refhook = NULL,\n                                 raw = TRUE) {\n \n-  # Check if object has a raw value (and if the user wants to store the raw)\n-  if (is.na(object$raw) && raw) {\n-\n-    object$save()\n-\n-    saveRDS(\n-      object\n-      , file = file\n-      , ascii = ascii\n-      , version = version\n-      , compress = compress\n-      , refhook = refhook\n-    )\n-\n-    # Free model from memory\n-    object$raw <- NA\n-\n-    return(invisible(NULL))\n+  warning(\"'saveRDS.lgb.Booster' is deprecated and will be removed in a future release. Use saveRDS() instead.\")\n \n-  } else {\n-\n-    saveRDS(\n-      object\n-      , file = file\n-      , ascii = ascii\n-      , version = version\n-      , compress = compress\n-      , refhook = refhook\n-    )\n-\n-    return(invisible(NULL))\n+  if (!lgb.is.Booster(x = object)) {\n+    stop(\"saveRDS.lgb.Booster: object should be an \", sQuote(\"lgb.Booster\"))\n+  }\n \n+  if (is.null(object$raw)) {\n+    lgb.make_serializable(object)\n   }\n \n+  saveRDS(\n+    object\n+    , file = file\n+    , ascii = ascii\n+    , version = version\n+    , compress = compress\n+    , refhook = refhook\n+  )\n+\n+  return(invisible(NULL))\n }\ndiff --git a/R-package/man/lgb.cv.Rd b/R-package/man/lgb.cv.Rd\nindex bd098a81dbdc..6a5f18a512be 100644\n--- a/R-package/man/lgb.cv.Rd\n+++ b/R-package/man/lgb.cv.Rd\n@@ -25,6 +25,7 @@ lgb.cv(\n   early_stopping_rounds = NULL,\n   callbacks = list(),\n   reset_data = FALSE,\n+  serializable = TRUE,\n   ...\n )\n }\n@@ -118,6 +119,9 @@ set to the iteration number of the best iteration.}\n \\item{reset_data}{Boolean, setting it to TRUE (not the default value) will transform the booster model\n into a predictor model which frees up memory and the original datasets}\n \n+\\item{serializable}{whether to make the resulting objects serializable through functions such as\n+\\code{save} or \\code{saveRDS} (see section \"Model serialization\").}\n+\n \\item{...}{other parameters, see Parameters.rst for more information. A few key parameters:\n \\itemize{\n     \\item{\\code{boosting}: Boosting type. \\code{\"gbdt\"}, \\code{\"rf\"}, \\code{\"dart\"} or \\code{\"goss\"}.}\ndiff --git a/R-package/man/lgb.drop_serialized.Rd b/R-package/man/lgb.drop_serialized.Rd\nnew file mode 100644\nindex 000000000000..3c7d08fe9aea\n--- /dev/null\n+++ b/R-package/man/lgb.drop_serialized.Rd\n@@ -0,0 +1,23 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/lgb.drop_serialized.R\n+\\name{lgb.drop_serialized}\n+\\alias{lgb.drop_serialized}\n+\\title{Drop serialized raw bytes in a LightGBM model object}\n+\\usage{\n+lgb.drop_serialized(model)\n+}\n+\\arguments{\n+\\item{model}{\\code{lgb.Booster} object which was produced with `serializable=TRUE`.}\n+}\n+\\value{\n+\\code{lgb.Booster} (the same `model` object that was passed as input, as invisible).\n+}\n+\\description{\n+If a LightGBM model object was produced with argument `serializable=TRUE`, the R object will keep\n+a copy of the underlying C++ object as raw bytes, which can be used to reconstruct such object after getting\n+serialized and de-serialized, but at the cost of extra memory usage. If these raw bytes are not needed anymore,\n+they can be dropped through this function in order to save memory. Note that the object will be modified in-place.\n+}\n+\\seealso{\n+\\link{lgb.restore_handle}, \\link{lgb.make_serializable}.\n+}\ndiff --git a/R-package/man/lgb.load.Rd b/R-package/man/lgb.load.Rd\nindex 55d241b2d670..775003c3279f 100644\n--- a/R-package/man/lgb.load.Rd\n+++ b/R-package/man/lgb.load.Rd\n@@ -9,7 +9,7 @@ lgb.load(filename = NULL, model_str = NULL)\n \\arguments{\n \\item{filename}{path of model file}\n \n-\\item{model_str}{a str containing the model}\n+\\item{model_str}{a str containing the model (as a `character` or `raw` vector)}\n }\n \\value{\n lgb.Booster\ndiff --git a/R-package/man/lgb.make_serializable.Rd b/R-package/man/lgb.make_serializable.Rd\nnew file mode 100644\nindex 000000000000..0a237c4eeb3e\n--- /dev/null\n+++ b/R-package/man/lgb.make_serializable.Rd\n@@ -0,0 +1,23 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/lgb.make_serializable.R\n+\\name{lgb.make_serializable}\n+\\alias{lgb.make_serializable}\n+\\title{Make a LightGBM object serializable by keeping raw bytes}\n+\\usage{\n+lgb.make_serializable(model)\n+}\n+\\arguments{\n+\\item{model}{\\code{lgb.Booster} object which was produced with `serializable=FALSE`.}\n+}\n+\\value{\n+\\code{lgb.Booster} (the same `model` object that was passed as input, as invisible).\n+}\n+\\description{\n+If a LightGBM model object was produced with argument `serializable=FALSE`, the R object will not\n+be serializable (e.g. cannot save and load with \\code{saveRDS} and \\code{readRDS}) as it will lack the raw bytes\n+needed to reconstruct its underlying C++ object. This function can be used to forcibly produce those serialized\n+raw bytes and make the object serializable. Note that the object will be modified in-place.\n+}\n+\\seealso{\n+\\link{lgb.restore_handle}, \\link{lgb.drop_serialized}.\n+}\ndiff --git a/R-package/man/lgb.restore_handle.Rd b/R-package/man/lgb.restore_handle.Rd\nnew file mode 100644\nindex 000000000000..199614241502\n--- /dev/null\n+++ b/R-package/man/lgb.restore_handle.Rd\n@@ -0,0 +1,42 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/lgb.restore_handle.R\n+\\name{lgb.restore_handle}\n+\\alias{lgb.restore_handle}\n+\\title{Restore the C++ component of a de-serialized LightGBM model}\n+\\usage{\n+lgb.restore_handle(model)\n+}\n+\\arguments{\n+\\item{model}{\\code{lgb.Booster} object which was de-serialized and whose underlying C++ object and R handle\n+need to be restored.}\n+}\n+\\value{\n+\\code{lgb.Booster} (the same `model` object that was passed as input, invisibly).\n+}\n+\\description{\n+After a LightGBM model object is de-serialized through functions such as \\code{save} or\n+\\code{saveRDS}, its underlying C++ object will be blank and needs to be restored to able to use it. Such\n+object is restored automatically when calling functions such as \\code{predict}, but this function can be\n+used to forcibly restore it beforehand. Note that the object will be modified in-place.\n+}\n+\\examples{\n+library(lightgbm)\n+data(\"agaricus.train\")\n+model <- lightgbm(\n+  agaricus.train$data\n+  , agaricus.train$label\n+  , params = list(objective = \"binary\", nthreads = 1L)\n+  , nrounds = 5L\n+  , save_name = NULL\n+  , verbose = 0)\n+fname <- tempfile(fileext=\"rds\")\n+saveRDS(model, fname)\n+\n+model_new <- readRDS(fname)\n+model_new$check_null_handle()\n+lgb.restore_handle(model_new)\n+model_new$check_null_handle()\n+}\n+\\seealso{\n+\\link{lgb.make_serializable}, \\link{lgb.drop_serialized}.\n+}\ndiff --git a/R-package/man/lgb.train.Rd b/R-package/man/lgb.train.Rd\nindex 4c8935df4f2d..be48d38f2738 100644\n--- a/R-package/man/lgb.train.Rd\n+++ b/R-package/man/lgb.train.Rd\n@@ -20,6 +20,7 @@ lgb.train(\n   early_stopping_rounds = NULL,\n   callbacks = list(),\n   reset_data = FALSE,\n+  serializable = TRUE,\n   ...\n )\n }\n@@ -99,6 +100,9 @@ set to the iteration number of the best iteration.}\n booster model into a predictor model which frees up memory and the\n original datasets}\n \n+\\item{serializable}{whether to make the resulting objects serializable through functions such as\n+\\code{save} or \\code{saveRDS} (see section \"Model serialization\").}\n+\n \\item{...}{other parameters, see \\href{https://lightgbm.readthedocs.io/en/latest/Parameters.html}{\n the \"Parameters\" section of the documentation} for more information. A few key parameters:\n \\itemize{\ndiff --git a/R-package/man/lgb_shared_params.Rd b/R-package/man/lgb_shared_params.Rd\nindex e5288e0450ae..b95c258e5f75 100644\n--- a/R-package/man/lgb_shared_params.Rd\n+++ b/R-package/man/lgb_shared_params.Rd\n@@ -64,6 +64,9 @@ set to the iteration number of the best iteration.}\n the \"Parameters\" section of the documentation} for a list of parameters and valid values.}\n \n \\item{verbose}{verbosity for output, if <= 0, also will disable the print of evaluation during training}\n+\n+\\item{serializable}{whether to make the resulting objects serializable through functions such as\n+\\code{save} or \\code{saveRDS} (see section \"Model serialization\").}\n }\n \\description{\n Parameter docs shared by \\code{lgb.train}, \\code{lgb.cv}, and \\code{lightgbm}\n@@ -85,4 +88,22 @@ Parameter docs shared by \\code{lgb.train}, \\code{lgb.cv}, and \\code{lightgbm}\n          or \\code{objective} (passed into \\code{params}).\n }\n \n+\\section{Model serialization}{\n+\n+\n+         LightGBM model objects can be serialized and de-serialized through functions such as \\code{save}\n+         or \\code{saveRDS}, but similarly to libraries such as 'xgboost', serialization works a bit differently\n+         from typical R objects. In order to make models serializable in R, a copy of the underlying C++ object\n+         as serialized raw bytes is produced and stored in the R model object, and when this R object is\n+         de-serialized, the underlying C++ model object gets reconstructed from these raw bytes, but will only\n+         do so once some function that uses it is called, such as \\code{predict}. In order to forcibly\n+         reconstruct the C++ object after deserialization (e.g. after calling \\code{readRDS} or similar), one\n+         can use the function \\link{lgb.restore_handle} (for example, if one makes predictions in parallel or in\n+         forked processes, it will be faster to restore the handle beforehand).\n+\n+         Producing and keeping these raw bytes however uses extra memory, and if they are not required,\n+         it is possible to avoid producing them by passing `serializable=FALSE`. In such cases, these raw\n+         bytes can be added to the model on demand through function \\link{lgb.make_serializable}.\n+}\n+\n \\keyword{internal}\ndiff --git a/R-package/man/lightgbm.Rd b/R-package/man/lightgbm.Rd\nindex 6512dbc6b23a..edd129e0e2ef 100644\n--- a/R-package/man/lightgbm.Rd\n+++ b/R-package/man/lightgbm.Rd\n@@ -16,6 +16,7 @@ lightgbm(\n   save_name = \"lightgbm.model\",\n   init_model = NULL,\n   callbacks = list(),\n+  serializable = TRUE,\n   ...\n )\n }\n@@ -43,12 +44,16 @@ fails to improve for \\code{early_stopping_rounds} consecutive boosting rounds.\n If training stops early, the returned model will have attribute \\code{best_iter}\n set to the iteration number of the best iteration.}\n \n-\\item{save_name}{File name to use when writing the trained model to disk. Should end in \".model\".}\n+\\item{save_name}{File name to use when writing the trained model to disk. Should end in \".model\".\n+If passing `NULL`, will not save the trained model to disk.}\n \n \\item{init_model}{path of model file of \\code{lgb.Booster} object, will continue training from this model}\n \n \\item{callbacks}{List of callback functions that are applied at each iteration.}\n \n+\\item{serializable}{whether to make the resulting objects serializable through functions such as\n+\\code{save} or \\code{saveRDS} (see section \"Model serialization\").}\n+\n \\item{...}{Additional arguments passed to \\code{\\link{lgb.train}}. For example\n \\itemize{\n    \\item{\\code{valids}: a list of \\code{lgb.Dataset} objects, used for validation}\ndiff --git a/R-package/man/readRDS.lgb.Booster.Rd b/R-package/man/readRDS.lgb.Booster.Rd\nindex 3592148ac128..5a1c647a0f74 100644\n--- a/R-package/man/readRDS.lgb.Booster.Rd\n+++ b/R-package/man/readRDS.lgb.Booster.Rd\n@@ -2,7 +2,7 @@\n % Please edit documentation in R/readRDS.lgb.Booster.R\n \\name{readRDS.lgb.Booster}\n \\alias{readRDS.lgb.Booster}\n-\\title{readRDS for \\code{lgb.Booster} models}\n+\\title{readRDS for \\code{lgb.Booster} models (DEPRECATED)}\n \\usage{\n readRDS.lgb.Booster(file, refhook = NULL)\n }\n@@ -15,7 +15,10 @@ readRDS.lgb.Booster(file, refhook = NULL)\n \\code{lgb.Booster}\n }\n \\description{\n-Attempts to load a model stored in a \\code{.rds} file, using \\code{\\link[base]{readRDS}}\n+Calls \\code{readRDS} in what is expected to be a serialized \\code{lgb.Booster} object,\n+             and then restores its handle through \\code{lgb.restore_handle}.\n+\n+             \\bold{This function throws a warning and will be removed in future versions.}\n }\n \\examples{\n \\donttest{\ndiff --git a/R-package/man/saveRDS.lgb.Booster.Rd b/R-package/man/saveRDS.lgb.Booster.Rd\nindex 02f5a715762c..e730f36b2caf 100644\n--- a/R-package/man/saveRDS.lgb.Booster.Rd\n+++ b/R-package/man/saveRDS.lgb.Booster.Rd\n@@ -2,7 +2,7 @@\n % Please edit documentation in R/saveRDS.lgb.Booster.R\n \\name{saveRDS.lgb.Booster}\n \\alias{saveRDS.lgb.Booster}\n-\\title{saveRDS for \\code{lgb.Booster} models}\n+\\title{saveRDS for \\code{lgb.Booster} models (DEPRECATED)}\n \\usage{\n saveRDS.lgb.Booster(\n   object,\n@@ -38,8 +38,10 @@ compression to be used. Ignored if file is a connection.}\n NULL invisibly.\n }\n \\description{\n-Attempts to save a model using RDS. Has an additional parameter (\\code{raw})\n-             which decides whether to save the raw model or not.\n+Calls \\code{saveRDS} on an \\code{lgb.Booster} object, making it serializable before the call if\n+             it isn't already.\n+\n+             \\bold{This function throws a warning and will be removed in future versions.}\n }\n \\examples{\n \\donttest{\ndiff --git a/R-package/src/lightgbm_R.cpp b/R-package/src/lightgbm_R.cpp\nindex 3a3582b12cf1..781fa0024d9c 100644\n--- a/R-package/src/lightgbm_R.cpp\n+++ b/R-package/src/lightgbm_R.cpp\n@@ -22,6 +22,7 @@\n #include <memory>\n #include <utility>\n #include <vector>\n+#include <algorithm>\n \n #define COL_MAJOR (0)\n \n@@ -60,6 +61,10 @@ SEXP wrapped_R_string(void *len) {\n   return Rf_allocVector(STRSXP, *(reinterpret_cast<R_xlen_t*>(len)));\n }\n \n+SEXP wrapped_R_raw(void *len) {\n+  return Rf_allocVector(RAWSXP, *(reinterpret_cast<R_xlen_t*>(len)));\n+}\n+\n SEXP wrapped_Rf_mkChar(void *txt) {\n   return Rf_mkChar(reinterpret_cast<char*>(txt));\n }\n@@ -75,6 +80,10 @@ SEXP safe_R_string(R_xlen_t len, SEXP *cont_token) {\n   return R_UnwindProtect(wrapped_R_string, reinterpret_cast<void*>(&len), throw_R_memerr, cont_token, *cont_token);\n }\n \n+SEXP safe_R_raw(R_xlen_t len, SEXP *cont_token) {\n+  return R_UnwindProtect(wrapped_R_raw, reinterpret_cast<void*>(&len), throw_R_memerr, cont_token, *cont_token);\n+}\n+\n SEXP safe_R_mkChar(char *txt, SEXP *cont_token) {\n   return R_UnwindProtect(wrapped_Rf_mkChar, reinterpret_cast<void*>(txt), throw_R_memerr, cont_token, *cont_token);\n }\n@@ -90,12 +99,17 @@ void _DatasetFinalizer(SEXP handle) {\n   LGBM_DatasetFree_R(handle);\n }\n \n+SEXP LGBM_NullBoosterHandleError_R() {\n+  Rf_error(\n+      \"Attempting to use a Booster which no longer exists and/or cannot be restored. \"\n+      \"This can happen if you have called Booster$finalize() \"\n+      \"or if this Booster was saved through saveRDS() using 'serializable=FALSE'.\");\n+  return R_NilValue;\n+}\n+\n void _AssertBoosterHandleNotNull(SEXP handle) {\n   if (Rf_isNull(handle) || !R_ExternalPtrAddr(handle)) {\n-    Rf_error(\n-      \"Attempting to use a Booster which no longer exists. \"\n-      \"This can happen if you have called Booster$finalize() or if this Booster was saved with saveRDS(). \"\n-      \"To avoid this error in the future, use saveRDS.lgb.Booster() or Booster$save_model() to save lightgbm Boosters.\");\n+    LGBM_NullBoosterHandleError_R();\n   }\n }\n \n@@ -462,13 +476,30 @@ SEXP LGBM_BoosterCreateFromModelfile_R(SEXP filename) {\n SEXP LGBM_BoosterLoadModelFromString_R(SEXP model_str) {\n   R_API_BEGIN();\n   SEXP ret = PROTECT(R_MakeExternalPtr(nullptr, R_NilValue, R_NilValue));\n+  SEXP temp = NULL;\n+  int n_protected = 1;\n   int out_num_iterations = 0;\n-  const char* model_str_ptr = CHAR(PROTECT(Rf_asChar(model_str)));\n+  const char* model_str_ptr = nullptr;\n+  switch (TYPEOF(model_str)) {\n+    case RAWSXP: {\n+      model_str_ptr = reinterpret_cast<const char*>(RAW(model_str));\n+      break;\n+    }\n+    case CHARSXP: {\n+      model_str_ptr = reinterpret_cast<const char*>(CHAR(model_str));\n+      break;\n+    }\n+    case STRSXP: {\n+      temp = PROTECT(STRING_ELT(model_str, 0));\n+      n_protected++;\n+      model_str_ptr = reinterpret_cast<const char*>(CHAR(temp));\n+    }\n+  }\n   BoosterHandle handle = nullptr;\n   CHECK_CALL(LGBM_BoosterLoadModelFromString(model_str_ptr, &out_num_iterations, &handle));\n   R_SetExternalPtrAddr(ret, handle);\n   R_RegisterCFinalizerEx(ret, _BoosterFinalizer, TRUE);\n-  UNPROTECT(2);\n+  UNPROTECT(n_protected);\n   return ret;\n   R_API_END();\n }\n@@ -828,20 +859,19 @@ SEXP LGBM_BoosterSaveModelToString_R(SEXP handle,\n   SEXP cont_token = PROTECT(R_MakeUnwindCont());\n   R_API_BEGIN();\n   _AssertBoosterHandleNotNull(handle);\n-  SEXP model_str;\n   int64_t out_len = 0;\n   int64_t buf_len = 1024 * 1024;\n   int num_iter = Rf_asInteger(num_iteration);\n   int importance_type = Rf_asInteger(feature_importance_type);\n   std::vector<char> inner_char_buf(buf_len);\n   CHECK_CALL(LGBM_BoosterSaveModelToString(R_ExternalPtrAddr(handle), 0, num_iter, importance_type, buf_len, &out_len, inner_char_buf.data()));\n-  // if the model string was larger than the initial buffer, allocate a bigger buffer and try again\n+  SEXP model_str = PROTECT(safe_R_raw(out_len, &cont_token));\n+  // if the model string was larger than the initial buffer, call the function again, writing directly to the R object\n   if (out_len > buf_len) {\n-    inner_char_buf.resize(out_len);\n-    CHECK_CALL(LGBM_BoosterSaveModelToString(R_ExternalPtrAddr(handle), 0, num_iter, importance_type, out_len, &out_len, inner_char_buf.data()));\n+    CHECK_CALL(LGBM_BoosterSaveModelToString(R_ExternalPtrAddr(handle), 0, num_iter, importance_type, out_len, &out_len, reinterpret_cast<char*>(RAW(model_str))));\n+  } else {\n+    std::copy(inner_char_buf.begin(), inner_char_buf.begin() + out_len, reinterpret_cast<char*>(RAW(model_str)));\n   }\n-  model_str = PROTECT(safe_R_string(static_cast<R_xlen_t>(1), &cont_token));\n-  SET_STRING_ELT(model_str, 0, safe_R_mkChar(inner_char_buf.data(), &cont_token));\n   UNPROTECT(2);\n   return model_str;\n   R_API_END();\n@@ -936,6 +966,7 @@ static const R_CallMethodDef CallEntries[] = {\n   {\"LGBM_BoosterSaveModel_R\"          , (DL_FUNC) &LGBM_BoosterSaveModel_R          , 4},\n   {\"LGBM_BoosterSaveModelToString_R\"  , (DL_FUNC) &LGBM_BoosterSaveModelToString_R  , 3},\n   {\"LGBM_BoosterDumpModel_R\"          , (DL_FUNC) &LGBM_BoosterDumpModel_R          , 3},\n+  {\"LGBM_NullBoosterHandleError_R\"    , (DL_FUNC) &LGBM_NullBoosterHandleError_R    , 0},\n   {\"LGBM_DumpParamAliases_R\"          , (DL_FUNC) &LGBM_DumpParamAliases_R          , 0},\n   {NULL, NULL, 0}\n };\ndiff --git a/R-package/src/lightgbm_R.h b/R-package/src/lightgbm_R.h\nindex 40032d7b44cb..562ebec2e7da 100644\n--- a/R-package/src/lightgbm_R.h\n+++ b/R-package/src/lightgbm_R.h\n@@ -20,6 +20,12 @@ LIGHTGBM_C_EXPORT SEXP LGBM_HandleIsNull_R(\n   SEXP handle\n );\n \n+/*!\n+* \\brief Throw a standardized error message when encountering a null Booster handle\n+* \\return No return, will throw an error\n+*/\n+LIGHTGBM_C_EXPORT SEXP LGBM_NullBoosterHandleError_R();\n+\n // --- start Dataset interface\n \n /*!\ndiff --git a/R-package/tests/testthat/test_basic.R b/R-package/tests/testthat/test_basic.R\nindex 92b11650c3e2..8bd67aac48f9 100644\n--- a/R-package/tests/testthat/test_basic.R\n+++ b/R-package/tests/testthat/test_basic.R\n@@ -293,6 +293,23 @@ test_that(\"lightgbm() performs evaluation on validation sets if they are provide\n   expect_true(abs(bst$record_evals[[\"valid2\"]][[\"binary_error\"]][[\"eval\"]][[1L]] - 0.02226317) < TOLERANCE)\n })\n \n+test_that(\"lightgbm() does not write model to disk if save_name=NULL\", {\n+  files_before <- list.files(getwd())\n+\n+  model <- lightgbm(\n+    data = train$data\n+    , label = train$label\n+    , nrounds = 5L\n+    , params = list(objective = \"binary\")\n+    , verbose = 0L\n+    , save_name = NULL\n+  )\n+\n+  files_after <- list.files(getwd())\n+\n+  expect_equal(files_before, files_after)\n+})\n+\n \n context(\"training continuation\")\n \ndiff --git a/R-package/tests/testthat/test_lgb.Booster.R b/R-package/tests/testthat/test_lgb.Booster.R\nindex 3ad1f0fcd6b2..290b4eb4f31f 100644\n--- a/R-package/tests/testthat/test_lgb.Booster.R\n+++ b/R-package/tests/testthat/test_lgb.Booster.R\n@@ -158,7 +158,7 @@ test_that(\"lgb.load() gives the expected error messages given different incorrec\n     # if given, model_str should be a string\n     expect_error({\n         lgb.load(model_str = c(4.0, 5.0, 6.0))\n-    }, regexp = \"model_str should be character\")\n+    }, regexp = \"lgb.load: model_str should be a character/raw vector\")\n \n })\n \n@@ -841,6 +841,7 @@ test_that(\"Booster: method calls Booster with a null handle should raise an info\n         , valids = list(\n             train = dtrain\n         )\n+        , serializable = FALSE\n     )\n     tmp_file <- tempfile(fileext = \".rds\")\n     saveRDS(bst, tmp_file)\n@@ -875,7 +876,7 @@ test_that(\"Booster: method calls Booster with a null handle should raise an info\n         bst$rollback_one_iter()\n     })\n     .expect_booster_error({\n-        bst$save()\n+        bst$save_raw()\n     })\n     .expect_booster_error({\n         bst$save_model(filename = tempfile(fileext = \".model\"))\n@@ -991,9 +992,9 @@ test_that(\"params (including dataset params) should be stored in .rds file for B\n         , train_set = dtrain\n     )\n     bst_file <- tempfile(fileext = \".rds\")\n-    saveRDS.lgb.Booster(bst, file = bst_file)\n+    expect_warning(saveRDS.lgb.Booster(bst, file = bst_file))\n \n-    bst_from_file <- readRDS.lgb.Booster(file = bst_file)\n+    expect_warning(bst_from_file <- readRDS.lgb.Booster(file = bst_file))\n     expect_identical(\n         bst_from_file$params\n         , list(\n@@ -1005,6 +1006,91 @@ test_that(\"params (including dataset params) should be stored in .rds file for B\n     )\n })\n \n+context(\"saveRDS and readRDS work on Booster\")\n+\n+test_that(\"params (including dataset params) should be stored in .rds file for Booster\", {\n+    data(agaricus.train, package = \"lightgbm\")\n+    dtrain <- lgb.Dataset(\n+        agaricus.train$data\n+        , label = agaricus.train$label\n+        , params = list(\n+            max_bin = 17L\n+        )\n+    )\n+    params <- list(\n+        objective = \"binary\"\n+        , max_depth = 4L\n+        , bagging_fraction = 0.8\n+    )\n+    bst <- Booster$new(\n+        params = params\n+        , train_set = dtrain\n+    )\n+    bst_file <- tempfile(fileext = \".rds\")\n+    saveRDS(bst, file = bst_file)\n+\n+    bst_from_file <- readRDS(file = bst_file)\n+    expect_identical(\n+        bst_from_file$params\n+        , list(\n+            objective = \"binary\"\n+            , max_depth = 4L\n+            , bagging_fraction = 0.8\n+            , max_bin = 17L\n+        )\n+    )\n+})\n+\n+test_that(\"Handle is automatically restored when calling predict\", {\n+    data(agaricus.train, package = \"lightgbm\")\n+    bst <- lightgbm(agaricus.train$data, agaricus.train$label, nrounds = 5L, obj = \"binary\")\n+    bst_file <- tempfile(fileext = \".rds\")\n+    saveRDS(bst, file = bst_file)\n+\n+    bst_from_file <- readRDS(file = bst_file)\n+\n+    pred_before <- predict(bst, agaricus.train$data)\n+    pred_after <- predict(bst_from_file, agaricus.train$data)\n+    expect_equal(pred_before, pred_after)\n+})\n+\n+test_that(\"boosters with linear models at leaves work with saveRDS.lgb.Booster and readRDS.lgb.Booster\", {\n+    X <- matrix(rnorm(100L), ncol = 1L)\n+    labels <- 2L * X + runif(nrow(X), 0L, 0.1)\n+    dtrain <- lgb.Dataset(\n+        data = X\n+        , label = labels\n+    )\n+\n+    params <- list(\n+        objective = \"regression\"\n+        , verbose = -1L\n+        , metric = \"mse\"\n+        , seed = 0L\n+        , num_leaves = 2L\n+    )\n+\n+    bst <- lgb.train(\n+        data = dtrain\n+        , nrounds = 10L\n+        , params = params\n+    )\n+    expect_true(lgb.is.Booster(bst))\n+\n+    # save predictions, then write the model to a file and destroy it in R\n+    preds <- predict(bst, X)\n+    model_file <- tempfile(fileext = \".rds\")\n+    expect_warning(saveRDS.lgb.Booster(bst, file = model_file))\n+    bst$finalize()\n+    expect_null(bst$.__enclos_env__$private$handle)\n+    rm(bst)\n+\n+    # load the booster and make predictions...should be the same\n+    expect_warning({bst2 <- readRDS.lgb.Booster(file = model_file)})\n+    preds2 <- predict(bst2, X)\n+    expect_identical(preds, preds2)\n+})\n+\n test_that(\"boosters with linear models at leaves can be written to RDS and re-loaded successfully\", {\n     X <- matrix(rnorm(100L), ncol = 1L)\n     labels <- 2L * X + runif(nrow(X), 0L, 0.1)\n@@ -1031,13 +1117,13 @@ test_that(\"boosters with linear models at leaves can be written to RDS and re-lo\n     # save predictions, then write the model to a file and destroy it in R\n     preds <- predict(bst, X)\n     model_file <- tempfile(fileext = \".rds\")\n-    saveRDS.lgb.Booster(bst, file = model_file)\n+    saveRDS(bst, file = model_file)\n     bst$finalize()\n     expect_null(bst$.__enclos_env__$private$handle)\n     rm(bst)\n \n     # load the booster and make predictions...should be the same\n-    bst2 <- readRDS.lgb.Booster(file = model_file)\n+    bst2 <- readRDS(file = model_file)\n     preds2 <- predict(bst2, X)\n     expect_identical(preds, preds2)\n })\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Lint Issue**: Add `#include <algorithm>` in `lightgbm_R.cpp` to resolve the current build failure related to the linter.\n   \n2. **R CMD Check NOTE**: Add an entry to `.Rbuildignore` to ignore `lightgbm.model` files which are being created during new examples in this PR. This is not an error but a warning that should be addressed.\n\n3. **Unit Test Requirement**: If you expand `lightgbm::lightgbm()` behavior, implement a unit test in `test_basic.R` to verify \u201cno model file\u201d logic when `save_name = NULL`. If unable to create the test, revert to a simpler approach (e.g., using a tempfile).\n\n4. **Valgrind Errors**: Investigate the valgrind failures originating from `LightGBM::Booster::LoadModelFromString`; uninitialized memory issues may relate to recent changes in the loading process. Check interactions with PR #4782 or involve unit testing to isolate faults."
      }
    ],
    "codediff_length": 43964
  },
  {
    "index": 17,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.ci/test-python-oldest.sh b/.ci/test-python-oldest.sh\nindex 3a0ea08dddda..40dfd393f1fe 100644\n--- a/.ci/test-python-oldest.sh\n+++ b/.ci/test-python-oldest.sh\n@@ -7,9 +7,11 @@\n #\n echo \"installing lightgbm's dependencies\"\n pip install \\\n+  'cffi==1.15.1' \\\n   'dataclasses' \\\n-  'numpy==1.12.0' \\\n+  'numpy==1.16.6' \\\n   'pandas==0.24.0' \\\n+  'pyarrow==6.0.1' \\\n   'scikit-learn==0.18.2' \\\n   'scipy==0.19.0' \\\n || exit -1\ndiff --git a/.ci/test.sh b/.ci/test.sh\nindex 37fbd19152d6..9ffd48efe452 100755\n--- a/.ci/test.sh\n+++ b/.ci/test.sh\n@@ -130,11 +130,13 @@ fi\n # including python=version[build=*cpython] to ensure that conda doesn't fall back to pypy\n mamba create -q -y -n $CONDA_ENV \\\n     ${CONSTRAINED_DEPENDENCIES} \\\n+    cffi \\\n     cloudpickle \\\n     joblib \\\n     matplotlib \\\n     numpy \\\n     psutil \\\n+    pyarrow \\\n     pytest \\\n     ${CONDA_PYTHON_REQUIREMENT} \\\n     python-graphviz \\\n@@ -315,11 +317,13 @@ matplotlib.use\\(\\\"Agg\\\"\\)\\\n \n     # importing the library should succeed even if all optional dependencies are not present\n     conda uninstall --force --yes \\\n+        cffi \\\n         dask \\\n         distributed \\\n         joblib \\\n         matplotlib \\\n         psutil \\\n+        pyarrow \\\n         python-graphviz \\\n         scikit-learn || exit -1\n     python -c \"import lightgbm\" || exit -1\ndiff --git a/.ci/test_windows.ps1 b/.ci/test_windows.ps1\nindex 413af821e065..6b02aed6ce8b 100644\n--- a/.ci/test_windows.ps1\n+++ b/.ci/test_windows.ps1\n@@ -52,12 +52,14 @@ conda install brotlipy\n \n conda update -q -y conda\n conda create -q -y -n $env:CONDA_ENV `\n+  cffi `\n   cloudpickle `\n   joblib `\n   matplotlib `\n   numpy `\n   pandas `\n   psutil `\n+  pyarrow `\n   pytest `\n   \"python=$env:PYTHON_VERSION[build=*cpython]\" `\n   python-graphviz `\ndiff --git a/include/LightGBM/arrow.h b/include/LightGBM/arrow.h\nnew file mode 100644\nindex 000000000000..3d1c74713bd3\n--- /dev/null\n+++ b/include/LightGBM/arrow.h\n@@ -0,0 +1,256 @@\n+/*!\n+ * Copyright (c) 2023 Microsoft Corporation. All rights reserved.\n+ * Licensed under the MIT License. See LICENSE file in the project root for license information.\n+ *\n+ * Author: Oliver Borchert\n+ */\n+\n+#ifndef LIGHTGBM_ARROW_H_\n+#define LIGHTGBM_ARROW_H_\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <functional>\n+#include <iterator>\n+#include <limits>\n+#include <memory>\n+#include <utility>\n+#include <vector>\n+\n+/* -------------------------------------- C DATA INTERFACE ------------------------------------- */\n+// The C data interface is taken from\n+// https://arrow.apache.org/docs/format/CDataInterface.html#structure-definitions\n+// and is available under Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0).\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+#define ARROW_FLAG_DICTIONARY_ORDERED 1\n+#define ARROW_FLAG_NULLABLE 2\n+#define ARROW_FLAG_MAP_KEYS_SORTED 4\n+\n+struct ArrowSchema {\n+  // Array type description\n+  const char* format;\n+  const char* name;\n+  const char* metadata;\n+  int64_t flags;\n+  int64_t n_children;\n+  struct ArrowSchema** children;\n+  struct ArrowSchema* dictionary;\n+\n+  // Release callback\n+  void (*release)(struct ArrowSchema*);\n+  // Opaque producer-specific data\n+  void* private_data;\n+};\n+\n+struct ArrowArray {\n+  // Array data description\n+  int64_t length;\n+  int64_t null_count;\n+  int64_t offset;\n+  int64_t n_buffers;\n+  int64_t n_children;\n+  const void** buffers;\n+  struct ArrowArray** children;\n+  struct ArrowArray* dictionary;\n+\n+  // Release callback\n+  void (*release)(struct ArrowArray*);\n+  // Opaque producer-specific data\n+  void* private_data;\n+};\n+\n+#ifdef __cplusplus\n+}\n+#endif\n+\n+/* --------------------------------------------------------------------------------------------- */\n+/*                                         CHUNKED ARRAY                                         */\n+/* --------------------------------------------------------------------------------------------- */\n+\n+namespace LightGBM {\n+\n+/**\n+ * @brief Arrow array-like container for a list of Arrow arrays.\n+ */\n+class ArrowChunkedArray {\n+  /* List of length `n` for `n` chunks containing the individual Arrow arrays. */\n+  std::vector<const ArrowArray*> chunks_;\n+  /* Schema for all chunks. */\n+  const ArrowSchema* schema_;\n+  /* List of length `n + 1` for `n` chunks containing the offsets for each chunk. */\n+  std::vector<int64_t> chunk_offsets_;\n+\n+  inline void construct_chunk_offsets() {\n+    chunk_offsets_.reserve(chunks_.size() + 1);\n+    chunk_offsets_.emplace_back(0);\n+    for (size_t k = 0; k < chunks_.size(); ++k) {\n+      chunk_offsets_.emplace_back(chunks_[k]->length + chunk_offsets_.back());\n+    }\n+  }\n+\n+ public:\n+  /**\n+   * @brief Construct a new Arrow Chunked Array object.\n+   *\n+   * @param chunks A list with the chunks.\n+   * @param schema The schema for all chunks.\n+   */\n+  inline ArrowChunkedArray(std::vector<const ArrowArray*> chunks, const ArrowSchema* schema) {\n+    chunks_ = chunks;\n+    schema_ = schema;\n+    construct_chunk_offsets();\n+  }\n+\n+  /**\n+   * @brief Construct a new Arrow Chunked Array object.\n+   *\n+   * @param n_chunks The number of chunks.\n+   * @param chunks A C-style array containing the chunks.\n+   * @param schema The schema for all chunks.\n+   */\n+  inline ArrowChunkedArray(int64_t n_chunks,\n+                           const struct ArrowArray* chunks,\n+                           const struct ArrowSchema* schema) {\n+    chunks_.reserve(n_chunks);\n+    for (auto k = 0; k < n_chunks; ++k) {\n+      chunks_.push_back(&chunks[k]);\n+    }\n+    schema_ = schema;\n+    construct_chunk_offsets();\n+  }\n+\n+  /**\n+   * @brief Get the length of the chunked array.\n+   * This method returns the cumulative length of all chunks.\n+   * Complexity: O(1)\n+   *\n+   * @return int64_t The number of elements in the chunked array.\n+   */\n+  inline int64_t get_length() const { return chunk_offsets_.back(); }\n+\n+  /* ----------------------------------------- ITERATOR ---------------------------------------- */\n+  template <typename T>\n+  class Iterator {\n+    using getter_fn = std::function<T(const ArrowArray*, int64_t)>;\n+\n+    /* Reference to the chunked array that this iterator iterates over. */\n+    const ArrowChunkedArray& array_;\n+    /* Function to fetch the value at a certain index from a single chunk. */\n+    getter_fn get_;\n+    /* The chunk the iterator currently points to. */\n+    int64_t ptr_chunk_;\n+    /* The index inside the current chunk that the iterator points to. */\n+    int64_t ptr_offset_;\n+\n+   public:\n+    using iterator_category = std::random_access_iterator_tag;\n+    using difference_type = int64_t;\n+    using value_type = T;\n+    using pointer = value_type*;\n+    using reference = value_type&;\n+\n+    /**\n+     * @brief Construct a new Iterator object.\n+     *\n+     * @param array Reference to the chunked array to iterator over.\n+     * @param get Function to fetch the value at a certain index from a single chunk.\n+     * @param ptr_chunk The index of the chunk to whose first index the iterator points to.\n+     */\n+    Iterator(const ArrowChunkedArray& array, getter_fn get, int64_t ptr_chunk);\n+\n+    T operator*() const;\n+    template <typename I>\n+    T operator[](I idx) const;\n+\n+    Iterator<T>& operator++();\n+    Iterator<T>& operator--();\n+    Iterator<T>& operator+=(int64_t c);\n+\n+    template <typename V>\n+    friend bool operator==(const Iterator<V>& a, const Iterator<V>& b);\n+    template <typename V>\n+    friend bool operator!=(const Iterator<V>& a, const Iterator<V>& b);\n+    template <typename V>\n+    friend int64_t operator-(const Iterator<V>& a, const Iterator<V>& b);\n+  };\n+\n+  /**\n+   * @brief Obtain an iterator to the beginning of the chunked array.\n+   *\n+   * @tparam T The value type of the iterator. May be any primitive type.\n+   * @return Iterator<T> The iterator.\n+   */\n+  template <typename T>\n+  inline Iterator<T> begin() const;\n+\n+  /**\n+   * @brief Obtain an iterator to the beginning of the chunked array.\n+   *\n+   * @tparam T The value type of the iterator. May be any primitive type.\n+   * @return Iterator<T> The iterator.\n+   */\n+  template <typename T>\n+  inline Iterator<T> end() const;\n+\n+  template <typename V>\n+  friend int64_t operator-(const Iterator<V>& a, const Iterator<V>& b);\n+};\n+\n+/**\n+ * @brief Arrow container for a list of chunked arrays.\n+ */\n+class ArrowTable {\n+  std::vector<ArrowChunkedArray> columns_;\n+\n+ public:\n+  /**\n+   * @brief Construct a new Arrow Table object.\n+   *\n+   * @param n_chunks The number of chunks.\n+   * @param chunks A C-style array containing the chunks.\n+   * @param schema The schema for all chunks.\n+   */\n+  inline ArrowTable(int64_t n_chunks, const ArrowArray* chunks, const ArrowSchema* schema) {\n+    columns_.reserve(schema->n_children);\n+    for (int64_t j = 0; j < schema->n_children; ++j) {\n+      std::vector<const ArrowArray*> children_chunks;\n+      children_chunks.reserve(n_chunks);\n+      for (int64_t k = 0; k < n_chunks; ++k) {\n+        children_chunks.push_back(chunks[k].children[j]);\n+      }\n+      columns_.emplace_back(children_chunks, schema->children[j]);\n+    }\n+  }\n+\n+  /**\n+   * @brief Get the number of rows in the table.\n+   *\n+   * @return int64_t The number of rows.\n+   */\n+  inline int64_t get_num_rows() const { return columns_.front().get_length(); }\n+\n+  /**\n+   * @brief Get the number of columns of this table.\n+   *\n+   * @return int64_t The column count.\n+   */\n+  inline int64_t get_num_columns() const { return columns_.size(); }\n+\n+  /**\n+   * @brief Get the column at a particular index.\n+   *\n+   * @param idx The index of the column, must me in the range `[0, num_columns)`.\n+   * @return const ArrowChunkedArray& The chunked array for the child at the provided index.\n+   */\n+  inline const ArrowChunkedArray& get_column(size_t idx) const { return this->columns_[idx]; }\n+};\n+\n+}  // namespace LightGBM\n+\n+#include \"arrow.tpp\"\n+\n+#endif /* LIGHTGBM_ARROW_H_ */\ndiff --git a/include/LightGBM/arrow.tpp b/include/LightGBM/arrow.tpp\nnew file mode 100644\nindex 000000000000..67b481c9497e\n--- /dev/null\n+++ b/include/LightGBM/arrow.tpp\n@@ -0,0 +1,190 @@\n+#include <LightGBM/arrow.h>\n+\n+#ifndef ARROW_TPP_\n+#define ARROW_TPP_\n+\n+namespace LightGBM {\n+\n+/**\n+ * @brief Obtain a function to access an index from an Arrow array.\n+ *\n+ * @tparam T The return type of the function, must be a primitive type.\n+ * @param dtype The Arrow format string describing the datatype of the Arrow array.\n+ * @return std::function<T(const ArrowArray*, size_t)> The index accessor function.\n+ */\n+template <typename T>\n+std::function<T(const ArrowArray*, size_t)> get_index_accessor(const char* dtype);\n+\n+/* ---------------------------------- ITERATOR INITIALIZATION ---------------------------------- */\n+\n+template <typename T>\n+inline ArrowChunkedArray::Iterator<T> ArrowChunkedArray::begin() const {\n+  return ArrowChunkedArray::Iterator<T>(*this, get_index_accessor<T>(schema_->format), 0);\n+}\n+\n+template <typename T>\n+inline ArrowChunkedArray::Iterator<T> ArrowChunkedArray::end() const {\n+  return ArrowChunkedArray::Iterator<T>(*this, get_index_accessor<T>(schema_->format),\n+                                        chunk_offsets_.size() - 1);\n+}\n+\n+/* ---------------------------------- ITERATOR IMPLEMENTATION ---------------------------------- */\n+\n+template <typename T>\n+ArrowChunkedArray::Iterator<T>::Iterator(const ArrowChunkedArray& array,\n+                                         getter_fn get,\n+                                         int64_t ptr_chunk)\n+    : array_(array), get_(get), ptr_chunk_(ptr_chunk) {\n+  this->ptr_offset_ = 0;\n+}\n+\n+template <typename T>\n+T ArrowChunkedArray::Iterator<T>::operator*() const {\n+  auto chunk = array_.chunks_[ptr_chunk_];\n+  return static_cast<T>(get_(chunk, ptr_offset_));\n+}\n+\n+template <typename T>\n+template <typename I>\n+T ArrowChunkedArray::Iterator<T>::operator[](I idx) const {\n+  auto it = std::lower_bound(array_.chunk_offsets_.begin(), array_.chunk_offsets_.end(), idx,\n+                             [](int64_t a, int64_t b) { return a <= b; });\n+\n+  auto chunk_idx = std::distance(array_.chunk_offsets_.begin() + 1, it);\n+  auto chunk = array_.chunks_[chunk_idx];\n+\n+  auto ptr_offset = static_cast<int64_t>(idx) - array_.chunk_offsets_[chunk_idx];\n+  return static_cast<T>(get_(chunk, ptr_offset));\n+}\n+\n+template <typename T>\n+ArrowChunkedArray::Iterator<T>& ArrowChunkedArray::Iterator<T>::operator++() {\n+  if (ptr_offset_ + 1 >= array_.chunks_[ptr_chunk_]->length) {\n+    ptr_offset_ = 0;\n+    ptr_chunk_++;\n+  } else {\n+    ptr_offset_++;\n+  }\n+  return *this;\n+}\n+\n+template <typename T>\n+ArrowChunkedArray::Iterator<T>& ArrowChunkedArray::Iterator<T>::operator--() {\n+  if (ptr_offset_ == 0) {\n+    ptr_chunk_--;\n+    ptr_offset_ = array_.chunks_[ptr_chunk_]->length - 1;\n+  } else {\n+    ptr_chunk_--;\n+  }\n+  return *this;\n+}\n+\n+template <typename T>\n+ArrowChunkedArray::Iterator<T>& ArrowChunkedArray::Iterator<T>::operator+=(int64_t c) {\n+  while (ptr_offset_ + c >= array_.chunks_[ptr_chunk_]->length) {\n+    c -= array_.chunks_[ptr_chunk_]->length - ptr_offset_;\n+    ptr_offset_ = 0;\n+    ptr_chunk_++;\n+  }\n+  ptr_offset_ += c;\n+  return *this;\n+}\n+\n+template <typename T>\n+bool operator==(const ArrowChunkedArray::Iterator<T>& a, const ArrowChunkedArray::Iterator<T>& b) {\n+  return a.ptr_chunk_ == b.ptr_chunk_ && a.ptr_offset_ == b.ptr_offset_;\n+}\n+\n+template <typename T>\n+bool operator!=(const ArrowChunkedArray::Iterator<T>& a, const ArrowChunkedArray::Iterator<T>& b) {\n+  return a.ptr_chunk_ != b.ptr_chunk_ || a.ptr_offset_ != b.ptr_offset_;\n+}\n+\n+template <typename T>\n+int64_t operator-(const ArrowChunkedArray::Iterator<T>& a,\n+                  const ArrowChunkedArray::Iterator<T>& b) {\n+  auto full_offset_a = a.array_.chunk_offsets_[a.ptr_chunk_] + a.ptr_offset_;\n+  auto full_offset_b = b.array_.chunk_offsets_[b.ptr_chunk_] + b.ptr_offset_;\n+  return full_offset_a - full_offset_b;\n+}\n+\n+/* --------------------------------------- INDEX ACCESSOR -------------------------------------- */\n+\n+/**\n+ * @brief The value of \"no value\" for a primitive type.\n+ *\n+ * @tparam T The type for which the missing value is defined.\n+ * @return T The missing value.\n+ */\n+template <typename T>\n+inline T arrow_primitive_missing_value() {\n+  return 0;\n+}\n+\n+template <>\n+inline double arrow_primitive_missing_value() {\n+  return std::numeric_limits<double>::quiet_NaN();\n+}\n+\n+template <>\n+inline float arrow_primitive_missing_value() {\n+  return std::numeric_limits<float>::quiet_NaN();\n+}\n+\n+template <typename T, typename V>\n+struct ArrayIndexAccessor {\n+  V operator()(const ArrowArray* array, size_t idx) {\n+    auto buffer_idx = idx + array->offset;\n+\n+    // For primitive types, buffer at idx 0 provides validity, buffer at idx 1 data, see:\n+    // https://arrow.apache.org/docs/format/Columnar.html#buffer-listing-for-each-layout\n+    auto validity = static_cast<const char*>(array->buffers[0]);\n+\n+    // Take return value from data buffer conditional on the validity of the index:\n+    //  - The structure of validity bitmasks is taken from here:\n+    //    https://arrow.apache.org/docs/format/Columnar.html#validity-bitmaps\n+    //  - If the bitmask is NULL, all indices are valid\n+    if (validity == nullptr || !(validity[buffer_idx / 8] & (1 << (buffer_idx % 8)))) {\n+      // In case the index is valid, we take it from the data buffer\n+      auto data = static_cast<const T*>(array->buffers[1]);\n+      return static_cast<double>(data[buffer_idx]);\n+    }\n+\n+    // In case the index is not valid, we return a default value\n+    return arrow_primitive_missing_value<T>();\n+  }\n+};\n+\n+template <typename T>\n+std::function<T(const ArrowArray*, size_t)> get_index_accessor(const char* dtype) {\n+  // Mapping obtained from:\n+  // https://arrow.apache.org/docs/format/CDataInterface.html#data-type-description-format-strings\n+  switch (dtype[0]) {\n+    case 'c':\n+      return ArrayIndexAccessor<int8_t, T>();\n+    case 'C':\n+      return ArrayIndexAccessor<uint8_t, T>();\n+    case 's':\n+      return ArrayIndexAccessor<int16_t, T>();\n+    case 'S':\n+      return ArrayIndexAccessor<uint16_t, T>();\n+    case 'i':\n+      return ArrayIndexAccessor<int32_t, T>();\n+    case 'I':\n+      return ArrayIndexAccessor<uint32_t, T>();\n+    case 'l':\n+      return ArrayIndexAccessor<int64_t, T>();\n+    case 'L':\n+      return ArrayIndexAccessor<uint64_t, T>();\n+    case 'f':\n+      return ArrayIndexAccessor<float, T>();\n+    case 'g':\n+      return ArrayIndexAccessor<double, T>();\n+    default:\n+      throw std::invalid_argument(\"unsupported Arrow datatype\");\n+  }\n+}\n+\n+}  // namespace LightGBM\n+\n+#endif\ndiff --git a/include/LightGBM/c_api.h b/include/LightGBM/c_api.h\nindex bba46a02a492..01f55d5ddfb4 100644\n--- a/include/LightGBM/c_api.h\n+++ b/include/LightGBM/c_api.h\n@@ -13,6 +13,7 @@\n #ifndef LIGHTGBM_C_API_H_\n #define LIGHTGBM_C_API_H_\n \n+#include <LightGBM/arrow.h>\n #include <LightGBM/export.h>\n \n #ifdef __cplusplus\n@@ -437,6 +438,23 @@ LIGHTGBM_C_EXPORT int LGBM_DatasetCreateFromMats(int32_t nmat,\n                                                  const DatasetHandle reference,\n                                                  DatasetHandle* out);\n \n+/*!\n+ * \\brief Create dataset from Arrow.\n+ * \\param n_chunks The number of Arrow arrays passed to this function\n+ * \\param chunks Pointer to the list of Arrow arrays\n+ * \\param schema Pointer to the schema of all Arrow arrays\n+ * \\param parameters Additional parameters\n+ * \\param reference Used to align bin mapper with other dataset, nullptr means isn't used\n+ * \\param[out] out Created dataset\n+ * \\return 0 when succeed, -1 when failure happens\n+ */\n+LIGHTGBM_C_EXPORT int LGBM_DatasetCreateFromArrow(int64_t n_chunks,\n+                                                  const ArrowArray* chunks,\n+                                                  const ArrowSchema* schema,\n+                                                  const char* parameters,\n+                                                  const DatasetHandle reference,\n+                                                  DatasetHandle *out);\n+\n /*!\n  * \\brief Create subset of a data.\n  * \\param handle Handle of full dataset\ndiff --git a/include/LightGBM/dataset.h b/include/LightGBM/dataset.h\nindex e7baa42dc2e6..e94e0d943a72 100644\n--- a/include/LightGBM/dataset.h\n+++ b/include/LightGBM/dataset.h\n@@ -5,6 +5,7 @@\n #ifndef LIGHTGBM_DATASET_H_\n #define LIGHTGBM_DATASET_H_\n \n+#include <LightGBM/arrow.h>\n #include <LightGBM/config.h>\n #include <LightGBM/feature_group.h>\n #include <LightGBM/meta.h>\n@@ -545,24 +546,29 @@ class Dataset {\n     }\n   }\n \n-  inline void PushOneRow(int tid, data_size_t row_idx, const std::vector<double>& feature_values) {\n-    if (is_finish_load_) { return; }\n-    for (size_t i = 0; i < feature_values.size() && i < static_cast<size_t>(num_total_features_); ++i) {\n-      int feature_idx = used_feature_map_[i];\n-      if (feature_idx >= 0) {\n-        const int group = feature2group_[feature_idx];\n-        const int sub_feature = feature2subfeature_[feature_idx];\n-        feature_groups_[group]->PushData(tid, sub_feature, row_idx, feature_values[i]);\n-        if (has_raw_) {\n-          int feat_ind = numeric_feature_map_[feature_idx];\n-          if (feat_ind >= 0) {\n-            raw_data_[feat_ind][row_idx] = static_cast<float>(feature_values[i]);\n-          }\n+  inline void PushOneValue(int tid, data_size_t row_idx, size_t col_idx, double value) {\n+    if (this->is_finish_load_)\n+      return;\n+    auto feature_idx = this->used_feature_map_[col_idx];\n+    if (feature_idx >= 0) {\n+      auto group = this->feature2group_[feature_idx];\n+      auto sub_feature = this->feature2subfeature_[feature_idx];\n+      this->feature_groups_[group]->PushData(tid, sub_feature, row_idx, value);\n+      if (this->has_raw_) {\n+        auto feat_ind = numeric_feature_map_[feature_idx];\n+        if (feat_ind >= 0) {\n+          raw_data_[feat_ind][row_idx] = static_cast<float>(value);\n         }\n       }\n     }\n   }\n \n+  inline void PushOneRow(int tid, data_size_t row_idx, const std::vector<double>& feature_values) {\n+    for (size_t i = 0; i < feature_values.size() && i < static_cast<size_t>(num_total_features_); ++i) {\n+      this->PushOneValue(tid, row_idx, i, feature_values[i]);\n+    }\n+  }\n+\n   inline void PushOneRow(int tid, data_size_t row_idx, const std::vector<std::pair<int, double>>& feature_values) {\n     if (is_finish_load_) { return; }\n     std::vector<bool> is_feature_added(num_features_, false);\ndiff --git a/python-package/lightgbm/basic.py b/python-package/lightgbm/basic.py\nindex 9b833afada84..d0d9f0b136f8 100644\n--- a/python-package/lightgbm/basic.py\n+++ b/python-package/lightgbm/basic.py\n@@ -18,7 +18,8 @@\n import numpy as np\n import scipy.sparse\n \n-from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n+from .compat import (PANDAS_INSTALLED, PYARROW_INSTALLED, arrow_cffi, arrow_is_floating, arrow_is_integer, concat,\n+                     dt_DataTable, pa_Table, pd_CategoricalDtype, pd_DataFrame, pd_Series)\n from .libpath import find_lib_path\n \n if TYPE_CHECKING:\n@@ -90,7 +91,8 @@\n     scipy.sparse.spmatrix,\n     \"Sequence\",\n     List[\"Sequence\"],\n-    List[np.ndarray]\n+    List[np.ndarray],\n+    pa_Table\n ]\n _LGBM_LabelType = Union[\n     List[float],\n@@ -351,6 +353,59 @@ def _is_2d_collection(data: Any) -> bool:\n     )\n \n \n+def _is_pyarrow_table(data: Any) -> bool:\n+    \"\"\"Check whether data is a PyArrow table.\"\"\"\n+    return isinstance(data, pa_Table)\n+\n+\n+class _ArrowCArray:\n+    \"\"\"Simple wrapper around the C representation of an Arrow type.\"\"\"\n+\n+    n_chunks: int\n+    chunks: arrow_cffi.CData\n+    schema: arrow_cffi.CData\n+\n+    def __init__(self, n_chunks: int, chunks: arrow_cffi.CData, schema: arrow_cffi.CData):\n+        self.n_chunks = n_chunks\n+        self.chunks = chunks\n+        self.schema = schema\n+\n+    @property\n+    def chunks_ptr(self) -> int:\n+        \"\"\"Returns the address of the pointer to the list of chunks making up the array.\"\"\"\n+        return int(arrow_cffi.cast(\"uintptr_t\", arrow_cffi.addressof(self.chunks[0])))\n+\n+    @property\n+    def schema_ptr(self) -> int:\n+        \"\"\"Returns the address of the pointer to the schema of the array.\"\"\"\n+        return int(arrow_cffi.cast(\"uintptr_t\", self.schema))\n+\n+\n+def _export_arrow_to_c(data: pa_Table) -> _ArrowCArray:\n+    \"\"\"Export an Arrow type to its C representation.\"\"\"\n+    # Obtain objects to export\n+    if isinstance(data, pa_Table):\n+        export_objects = data.to_batches()\n+    else:\n+        raise ValueError(f\"data of type '{type(data)}' cannot be exported to Arrow\")\n+\n+    # Prepare export\n+    chunks = arrow_cffi.new(\"struct ArrowArray[]\", len(export_objects))\n+    schema = arrow_cffi.new(\"struct ArrowSchema*\")\n+\n+    # Export all objects\n+    for i, obj in enumerate(export_objects):\n+        chunk_ptr = int(arrow_cffi.cast(\"uintptr_t\", arrow_cffi.addressof(chunks[i])))\n+        if i == 0:\n+            schema_ptr = int(arrow_cffi.cast(\"uintptr_t\", schema))\n+            obj._export_to_c(chunk_ptr, schema_ptr)\n+        else:\n+            obj._export_to_c(chunk_ptr)\n+\n+    return _ArrowCArray(len(chunks), chunks, schema)\n+\n+\n+\n def _data_to_2d_numpy(\n     data: Any,\n     dtype: \"np.typing.DTypeLike\",\n@@ -1562,7 +1617,7 @@ def __init__(\n \n         Parameters\n         ----------\n-        data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequence or list of numpy array\n+        data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequence, list of numpy array or pyarrow Table\n             Data source of Dataset.\n             If str or pathlib.Path, it represents the path to a text file (CSV, TSV, or LibSVM) or a LightGBM Dataset binary file.\n         label : list, numpy 1-D array, pandas Series / one-column DataFrame or None, optional (default=None)\n@@ -1581,7 +1636,7 @@ def __init__(\n             Init score for Dataset.\n         feature_name : list of str, or 'auto', optional (default=\"auto\")\n             Feature names.\n-            If 'auto' and data is pandas DataFrame, data columns names are used.\n+            If 'auto' and data is pandas DataFrame or pyarrow Table, data columns names are used.\n         categorical_feature : list of str or int, or 'auto', optional (default=\"auto\")\n             Categorical features.\n             If list of int, interpreted as indices.\n@@ -1938,6 +1993,9 @@ def _lazy_init(\n             self.__init_from_csc(data, params_str, ref_dataset)\n         elif isinstance(data, np.ndarray):\n             self.__init_from_np2d(data, params_str, ref_dataset)\n+        elif _is_pyarrow_table(data):\n+            self.__init_from_pyarrow_table(data, params_str, ref_dataset)\n+            feature_name = data.column_names\n         elif isinstance(data, list) and len(data) > 0:\n             if _is_list_of_numpy_arrays(data):\n                 self.__init_from_list_np2d(data, params_str, ref_dataset)\n@@ -2198,6 +2256,32 @@ def __init_from_csc(\n             ctypes.byref(self._handle)))\n         return self\n \n+    def __init_from_pyarrow_table(\n+        self,\n+        table: pa_Table,\n+        params_str: str,\n+        ref_dataset: Optional[_DatasetHandle]\n+    ) -> \"Dataset\":\n+        \"\"\"Initialize data from a PyArrow table.\"\"\"\n+        if not PYARROW_INSTALLED:\n+            raise LightGBMError(\"Cannot init dataframe from Arrow without `pyarrow` installed.\")\n+\n+        # Check that the input is valid: we only handle numbers (for now)\n+        if not all(arrow_is_integer(t) or arrow_is_floating(t) for t in table.schema.types):\n+            raise ValueError(\"Arrow table may only have integer or floating point datatypes\")\n+\n+        # Export Arrow table to C\n+        c_array = _export_arrow_to_c(table)\n+        self._handle = ctypes.c_void_p()\n+        _safe_call(_LIB.LGBM_DatasetCreateFromArrow(\n+            ctypes.c_int64(c_array.n_chunks),\n+            ctypes.c_void_p(c_array.chunks_ptr),\n+            ctypes.c_void_p(c_array.schema_ptr),\n+            _c_str(params_str),\n+            ref_dataset,\n+            ctypes.byref(self._handle)))\n+        return self\n+\n     @staticmethod\n     def _compare_params_for_warning(\n         params: Dict[str, Any],\ndiff --git a/python-package/lightgbm/compat.py b/python-package/lightgbm/compat.py\nindex 0a55ccd1e421..7be375e02e85 100644\n--- a/python-package/lightgbm/compat.py\n+++ b/python-package/lightgbm/compat.py\n@@ -185,6 +185,36 @@ class dask_Series:  # type: ignore\n         def __init__(self, *args, **kwargs):\n             pass\n \n+\"\"\"pyarrow\"\"\"\n+try:\n+    from pyarrow import Table as pa_Table\n+    from pyarrow.cffi import ffi as arrow_cffi\n+    from pyarrow.types import is_floating as arrow_is_floating\n+    from pyarrow.types import is_integer as arrow_is_integer\n+    PYARROW_INSTALLED = True\n+except ImportError:\n+    PYARROW_INSTALLED = False\n+\n+    class pa_Table:  # type: ignore\n+        \"\"\"Dummy class for pa.Table.\"\"\"\n+\n+        def __init__(self, *args, **kwargs):\n+            pass\n+\n+    class arrow_cffi:  # type: ignore\n+        \"\"\"Dummy class for pyarrow.cffi.ffi.\"\"\"\n+\n+        CData = None\n+        addressof = None\n+        cast = None\n+        new = None\n+\n+        def __init__(self, *args, **kwargs):\n+            pass\n+\n+    arrow_is_integer = None\n+    arrow_is_floating = None\n+\n \"\"\"cpu_count()\"\"\"\n try:\n     from joblib import cpu_count\ndiff --git a/python-package/pyproject.toml b/python-package/pyproject.toml\nindex 6e43dc242d1b..83520c5248cd 100644\n--- a/python-package/pyproject.toml\n+++ b/python-package/pyproject.toml\n@@ -33,6 +33,10 @@ requires-python = \">=3.6\"\n version = \"4.1.0.99\"\n \n [project.optional-dependencies]\n+arrow = [\n+    \"cffi>=1.15.1\",\n+    \"pyarrow>=6.0.1\"\n+]\n dask = [\n     \"dask[array,dataframe,distributed]>=2.0.0\",\n     \"pandas>=0.24.0\"\ndiff --git a/src/c_api.cpp b/src/c_api.cpp\nindex 5c98d7d24c01..6467bb54a8fe 100644\n--- a/src/c_api.cpp\n+++ b/src/c_api.cpp\n@@ -4,6 +4,7 @@\n  */\n #include <LightGBM/c_api.h>\n \n+#include <LightGBM/arrow.h>\n #include <LightGBM/boosting.h>\n #include <LightGBM/config.h>\n #include <LightGBM/dataset.h>\n@@ -832,6 +833,7 @@ class Booster {\n \n // explicitly declare symbols from LightGBM namespace\n using LightGBM::AllgatherFunction;\n+using LightGBM::ArrowTable;\n using LightGBM::Booster;\n using LightGBM::Common::CheckElementsIntervalClosed;\n using LightGBM::Common::RemoveQuotationSymbol;\n@@ -1567,6 +1569,98 @@ int LGBM_DatasetCreateFromCSC(const void* col_ptr,\n   API_END();\n }\n \n+int LGBM_DatasetCreateFromArrow(int64_t n_chunks,\n+                                const ArrowArray* chunks,\n+                                const ArrowSchema* schema,\n+                                const char* parameters,\n+                                const DatasetHandle reference,\n+                                DatasetHandle *out) {\n+  API_BEGIN();\n+\n+  auto param = Config::Str2Map(parameters);\n+  Config config;\n+  config.Set(param);\n+  OMP_SET_NUM_THREADS(config.num_threads);\n+\n+  std::unique_ptr<Dataset> ret;\n+\n+  // Prepare the Arrow data\n+  ArrowTable table(n_chunks, chunks, schema);\n+\n+  // Initialize the dataset\n+  if (reference == nullptr) {\n+    // If there is no reference dataset, we first sample indices\n+    auto sample_indices = CreateSampleIndices(static_cast<int32_t>(table.get_num_rows()), config);\n+    auto sample_count = static_cast<int>(sample_indices.size());\n+    std::vector<std::vector<double>> sample_values(table.get_num_columns());\n+    std::vector<std::vector<int>> sample_idx(table.get_num_columns());\n+\n+    // Then, we obtain sample values by parallelizing across columns\n+    OMP_INIT_EX();\n+    #pragma omp parallel for num_threads(OMP_NUM_THREADS()) schedule(static)\n+    for (int64_t j = 0; j < table.get_num_columns(); ++j) {\n+      OMP_LOOP_EX_BEGIN();\n+\n+      // Values need to be copied from the record batches.\n+      sample_values[j].reserve(sample_indices.size());\n+      sample_idx[j].reserve(sample_indices.size());\n+\n+      // The chunks are iterated over in the inner loop as columns can be treated independently.\n+      int last_idx = 0;\n+      int i = 0;\n+      auto it = table.get_column(j).begin<double>();\n+      for (auto idx : sample_indices) {\n+        std::advance(it, idx - last_idx);\n+        auto v = *it;\n+        if (std::fabs(v) > kZeroThreshold || std::isnan(v)) {\n+          sample_values[j].emplace_back(v);\n+          sample_idx[j].emplace_back(i);\n+        }\n+        last_idx = idx;\n+        i++;\n+      }\n+      OMP_LOOP_EX_END();\n+    }\n+    OMP_THROW_EX();\n+\n+    // Finally, we initialize a loader from the sampled values\n+    DatasetLoader loader(config, nullptr, 1, nullptr);\n+    ret.reset(loader.ConstructFromSampleData(Vector2Ptr<double>(&sample_values).data(),\n+                                             Vector2Ptr<int>(&sample_idx).data(),\n+                                             table.get_num_columns(),\n+                                             VectorSize<double>(sample_values).data(),\n+                                             sample_count,\n+                                             table.get_num_rows(),\n+                                             table.get_num_rows()));\n+  } else {\n+    ret.reset(new Dataset(static_cast<data_size_t>(table.get_num_rows())));\n+    ret->CreateValid(reinterpret_cast<const Dataset*>(reference));\n+    if (ret->has_raw()) {\n+      ret->ResizeRaw(static_cast<int>(table.get_num_rows()));\n+    }\n+  }\n+\n+  // After sampling and properly initializing all bins, we can add our data to the dataset. Here,\n+  // we parallelize across rows.\n+  OMP_INIT_EX();\n+  #pragma omp parallel for num_threads(OMP_NUM_THREADS()) schedule(static)\n+  for (int64_t j = 0; j < table.get_num_columns(); ++j) {\n+    OMP_LOOP_EX_BEGIN();\n+    const int tid = omp_get_thread_num();\n+    data_size_t idx = 0;\n+    auto column = table.get_column(j);\n+    for (auto it = column.begin<double>(), end = column.end<double>(); it != end; ++it) {\n+      ret->PushOneValue(tid, idx++, j, *it);\n+    }\n+    OMP_LOOP_EX_END();\n+  }\n+  OMP_THROW_EX();\n+\n+  ret->FinishLoad();\n+  *out = ret.release();\n+  API_END();\n+}\n+\n int LGBM_DatasetGetSubset(\n   const DatasetHandle handle,\n   const int32_t* used_row_indices,\ndiff --git a/tests/cpp_tests/test_arrow.cpp b/tests/cpp_tests/test_arrow.cpp\nnew file mode 100644\nindex 000000000000..7e3c57c401f4\n--- /dev/null\n+++ b/tests/cpp_tests/test_arrow.cpp\n@@ -0,0 +1,210 @@\n+/*!\n+ * Copyright (c) 2023 Microsoft Corporation. All rights reserved.\n+ * Licensed under the MIT License. See LICENSE file in the project root for license information.\n+ *\n+ * Author: Oliver Borchert\n+ */\n+\n+#include <gtest/gtest.h>\n+#include <LightGBM/arrow.h>\n+\n+#include <cstdlib>\n+#include <cmath>\n+\n+using LightGBM::ArrowChunkedArray;\n+using LightGBM::ArrowTable;\n+\n+class ArrowChunkedArrayTest : public testing::Test {\n+ protected:\n+  void SetUp() override {}\n+\n+  ArrowArray created_nested_array(const std::vector<ArrowArray*>& arrays) {\n+    ArrowArray arr;\n+    arr.buffers = nullptr;\n+    arr.children = (ArrowArray**)arrays.data();  // NOLINT\n+    arr.dictionary = nullptr;\n+    arr.length = arrays[0]->length;\n+    arr.n_buffers = 0;\n+    arr.n_children = arrays.size();\n+    arr.null_count = 0;\n+    arr.offset = 0;\n+    arr.private_data = nullptr;\n+    arr.release = nullptr;\n+    return arr;\n+  }\n+\n+  template <typename T>\n+  ArrowArray create_primitive_array(const std::vector<T>& values,\n+                                    int64_t offset = 0,\n+                                    std::vector<int64_t> null_indices = {}) {\n+    // NOTE: Arrow arrays have 64-bit alignment but we can safely ignore this in tests\n+    // 1) Create validity bitmap\n+    char* validity = nullptr;\n+    if (!null_indices.empty()) {\n+      validity = static_cast<char*>(calloc(values.size() + sizeof(char) - 1, sizeof(char)));\n+      for (size_t i = 0; i < values.size(); ++i) {\n+        if (std::find(null_indices.begin(), null_indices.end(), i) != null_indices.end()) {\n+          validity[i / 8] |= (1 << (i % 8));\n+        }\n+      }\n+    }\n+\n+    // 2) Create buffers\n+    const void** buffers = (const void**)malloc(sizeof(void*) * 2);\n+    buffers[0] = validity;\n+    buffers[1] = values.data() + offset;\n+\n+    // Create arrow array\n+    ArrowArray arr;\n+    arr.buffers = buffers;\n+    arr.children = nullptr;\n+    arr.dictionary = nullptr;\n+    arr.length = values.size() - offset;\n+    arr.null_count = 0;\n+    arr.offset = 0;\n+    arr.private_data = nullptr;\n+    arr.release = [](ArrowArray* arr) {\n+      if (arr->buffers[0] != nullptr)\n+        free((void*)(arr->buffers[0]));  // NOLINT\n+      free((void*)(arr->buffers));  // NOLINT\n+    };\n+    return arr;\n+  }\n+\n+  ArrowSchema create_nested_schema(const std::vector<ArrowSchema*>& arrays) {\n+    ArrowSchema schema;\n+    schema.format = \"+s\";\n+    schema.name = nullptr;\n+    schema.metadata = nullptr;\n+    schema.flags = 0;\n+    schema.n_children = arrays.size();\n+    schema.children = (ArrowSchema**)arrays.data();  // NOLINT\n+    schema.dictionary = nullptr;\n+    schema.private_data = nullptr;\n+    schema.release = nullptr;\n+    return schema;\n+  }\n+\n+  template <typename T>\n+  ArrowSchema create_primitive_schema() {\n+    std::logic_error(\"not implemented\");\n+  }\n+\n+  template <>\n+  ArrowSchema create_primitive_schema<float>() {\n+    ArrowSchema schema;\n+    schema.format = \"f\";\n+    schema.name = nullptr;\n+    schema.metadata = nullptr;\n+    schema.flags = 0;\n+    schema.n_children = 0;\n+    schema.children = nullptr;\n+    schema.dictionary = nullptr;\n+    schema.private_data = nullptr;\n+    schema.release = nullptr;\n+    return schema;\n+  }\n+};\n+\n+TEST_F(ArrowChunkedArrayTest, GetLength) {\n+  std::vector<float> dat1 = {1, 2};\n+  auto arr1 = create_primitive_array(dat1);\n+\n+  ArrowChunkedArray ca1(1, &arr1, nullptr);\n+  ASSERT_EQ(ca1.get_length(), 2);\n+\n+  std::vector<float> dat2 = {3, 4, 5, 6};\n+  auto arr2 = create_primitive_array<float>(dat2);\n+  ArrowArray arrs[2] = {arr1, arr2};\n+  ArrowChunkedArray ca2(2, arrs, nullptr);\n+  ASSERT_EQ(ca2.get_length(), 6);\n+\n+  arr1.release(&arr1);\n+  arr2.release(&arr2);\n+}\n+\n+TEST_F(ArrowChunkedArrayTest, GetColumns) {\n+  std::vector<float> dat1 = {1, 2, 3};\n+  auto arr1 = create_primitive_array(dat1);\n+  std::vector<float> dat2 = {4, 5, 6};\n+  auto arr2 = create_primitive_array(dat2);\n+  std::vector<ArrowArray*> arrs = {&arr1, &arr2};\n+  auto arr = created_nested_array(arrs);\n+\n+  auto schema1 = create_primitive_schema<float>();\n+  auto schema2 = create_primitive_schema<float>();\n+  std::vector<ArrowSchema*> schemas = {&schema1, &schema2};\n+  auto schema = create_nested_schema(schemas);\n+\n+  ArrowTable table(1, &arr, &schema);\n+  ASSERT_EQ(table.get_num_rows(), 3);\n+  ASSERT_EQ(table.get_num_columns(), 2);\n+\n+  auto ca1 = table.get_column(0);\n+  ASSERT_EQ(ca1.get_length(), 3);\n+  ASSERT_EQ(*ca1.begin<int32_t>(), 1);\n+\n+  auto ca2 = table.get_column(1);\n+  ASSERT_EQ(ca2.get_length(), 3);\n+  ASSERT_EQ(*ca2.begin<int32_t>(), 4);\n+\n+  arr1.release(&arr1);\n+  arr2.release(&arr2);\n+}\n+\n+TEST_F(ArrowChunkedArrayTest, IteratorArithmetic) {\n+  std::vector<float> dat1 = {1, 2};\n+  auto arr1 = create_primitive_array<float>(dat1);\n+  std::vector<float> dat2 = {3, 4, 5, 6};\n+  auto arr2 = create_primitive_array<float>(dat2);\n+  std::vector<float> dat3 = {7};\n+  auto arr3 = create_primitive_array<float>(dat3);\n+  auto schema = create_primitive_schema<float>();\n+\n+  ArrowArray arrs[3] = {arr1, arr2, arr3};\n+  ArrowChunkedArray ca(3, arrs, &schema);\n+\n+  // Arithmetic\n+  auto it = ca.begin<int32_t>();\n+  ASSERT_EQ(*it, 1);\n+  ++it;\n+  ASSERT_EQ(*it, 2);\n+  ++it;\n+  ASSERT_EQ(*it, 3);\n+  it += 2;\n+  ASSERT_EQ(*it, 5);\n+  it += 2;\n+  ASSERT_EQ(*it, 7);\n+  --it;\n+  ASSERT_EQ(*it, 6);\n+\n+  // Subscripts\n+  ASSERT_EQ(it[0], 1);\n+  ASSERT_EQ(it[1], 2);\n+  ASSERT_EQ(it[2], 3);\n+  ASSERT_EQ(it[6], 7);\n+\n+  // End\n+  auto end = ca.end<int32_t>();\n+  ASSERT_EQ(end - it, 2);\n+  ASSERT_EQ(end - ca.begin<int32_t>(), 7);\n+\n+  arr1.release(&arr1);\n+  arr2.release(&arr2);\n+  arr2.release(&arr3);\n+}\n+\n+TEST_F(ArrowChunkedArrayTest, OffsetAndValidity) {\n+  std::vector<float> dat = {0, 1, 2, 3, 4, 5, 6};\n+  auto arr = create_primitive_array(dat, 2, {0, 1});\n+  auto schema = create_primitive_schema<float>();\n+  ArrowChunkedArray ca(1, &arr, &schema);\n+\n+  auto it = ca.begin<double>();\n+  ASSERT_TRUE(std::isnan(*it));\n+  ASSERT_TRUE(std::isnan(*(++it)));\n+  ASSERT_EQ(it[2], 4);\n+  ASSERT_EQ(it[4], 6);\n+\n+  arr.release(&arr);\n+}\ndiff --git a/tests/python_package_test/test_arrow.py b/tests/python_package_test/test_arrow.py\nnew file mode 100644\nindex 000000000000..54ca945e1e53\n--- /dev/null\n+++ b/tests/python_package_test/test_arrow.py\n@@ -0,0 +1,99 @@\n+# coding: utf-8\n+import filecmp\n+from pathlib import Path\n+from typing import Any, Callable, Dict\n+\n+import numpy as np\n+import pyarrow as pa\n+import pytest\n+\n+import lightgbm as lgb\n+\n+# ----------------------------------------------------------------------------------------------- #\n+#                                            UTILITIES                                            #\n+# ----------------------------------------------------------------------------------------------- #\n+\n+\n+def generate_simple_arrow_table() -> pa.Table:\n+    columns = [\n+        pa.chunked_array([[1, 2, 3, 4, 5]], type=pa.uint8()),\n+        pa.chunked_array([[1, 2, 3, 4, 5]], type=pa.int8()),\n+        pa.chunked_array([[1, 2, 3, 4, 5]], type=pa.uint16()),\n+        pa.chunked_array([[1, 2, 3, 4, 5]], type=pa.int16()),\n+        pa.chunked_array([[1, 2, 3, 4, 5]], type=pa.uint32()),\n+        pa.chunked_array([[1, 2, 3, 4, 5]], type=pa.int32()),\n+        pa.chunked_array([[1, 2, 3, 4, 5]], type=pa.uint64()),\n+        pa.chunked_array([[1, 2, 3, 4, 5]], type=pa.int64()),\n+        pa.chunked_array([[1, 2, 3, 4, 5]], type=pa.float32()),\n+        pa.chunked_array([[1, 2, 3, 4, 5]], type=pa.float64()),\n+    ]\n+    return pa.Table.from_arrays(columns, names=[f\"col_{i}\" for i in range(len(columns))])\n+\n+\n+def generate_dummy_arrow_table() -> pa.Table:\n+    col1 = pa.chunked_array([[1, 2, 3], [4, 5]], type=pa.uint8())\n+    col2 = pa.chunked_array([[0.5, 0.6], [0.1, 0.8, 1.5]], type=pa.float32())\n+    return pa.Table.from_arrays([col1, col2], names=[\"a\", \"b\"])\n+\n+\n+def generate_random_arrow_table(num_columns: int, num_datapoints: int, seed: int) -> pa.Table:\n+    columns = [generate_random_arrow_array(num_datapoints, seed + i) for i in range(num_columns)]\n+    names = [f\"col_{i}\" for i in range(num_columns)]\n+    return pa.Table.from_arrays(columns, names=names)\n+\n+\n+def generate_random_arrow_array(num_datapoints: int, seed: int) -> pa.ChunkedArray:\n+    generator = np.random.default_rng(seed)\n+    data = generator.standard_normal(num_datapoints)\n+\n+    # Set random nulls\n+    indices = generator.choice(len(data), size=num_datapoints // 10)\n+    data[indices] = None\n+\n+    # Split data into <=2 random chunks\n+    split_points = np.sort(generator.choice(np.arange(1, num_datapoints), 2, replace=False))\n+    split_points = np.concatenate([[0], split_points, [num_datapoints]])\n+    chunks = [data[split_points[i] : split_points[i + 1]] for i in range(len(split_points) - 1)]\n+    chunks = [chunk for chunk in chunks if len(chunk) > 0]\n+\n+    # Turn chunks into array\n+    return pa.chunked_array([data], type=pa.float32())\n+\n+\n+def dummy_dataset_params() -> Dict[str, Any]:\n+    return {\n+        \"min_data_in_bin\": 1,\n+        \"min_data_in_leaf\": 1,\n+    }\n+\n+\n+# ----------------------------------------------------------------------------------------------- #\n+#                                            UNIT TESTS                                           #\n+# ----------------------------------------------------------------------------------------------- #\n+\n+# ------------------------------------------- DATASET ------------------------------------------- #\n+\n+\n+@pytest.mark.parametrize(\n+    (\"arrow_table_fn\", \"dataset_params\"),\n+    [  # Use lambda functions here to minimize memory consumption\n+        (lambda: generate_simple_arrow_table(), dummy_dataset_params()),\n+        (lambda: generate_dummy_arrow_table(), dummy_dataset_params()),\n+        (lambda: generate_random_arrow_table(3, 1000, 42), {}),\n+        (lambda: generate_random_arrow_table(100, 10000, 43), {}),\n+    ],\n+)\n+def test_dataset_construct_fuzzy(\n+    tmp_path: Path, arrow_table_fn: Callable[[], pa.Table], dataset_params: Dict[str, Any]\n+):\n+    arrow_table = arrow_table_fn()\n+\n+    arrow_dataset = lgb.Dataset(arrow_table, params=dataset_params)\n+    arrow_dataset.construct()\n+\n+    pandas_dataset = lgb.Dataset(arrow_table.to_pandas(), params=dataset_params)\n+    pandas_dataset.construct()\n+\n+    arrow_dataset._dump_text(tmp_path / \"arrow.txt\")\n+    pandas_dataset._dump_text(tmp_path / \"pandas.txt\")\n+    assert filecmp.cmp(tmp_path / \"arrow.txt\", tmp_path / \"pandas.txt\")\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Dependency Issue**: Avoid linking to `libarrow` due to increased dependencies and CI complexity. Stick to using `pyarrow` and C API for simplicity unless additional `libarrow` functionalities are required.\n\n2. **Debugging Tests**: Investigate the failure in `test_model_size`, which seems tied to memory allocation issues. Review logs from `#6140` for comparison to identify potential memory leaks or dependency version shifts due to the changes in this PR.\n\n3. **CI Guidance**: Specify which CI job is failing in discussions, providing direct links to relevant logs for clarity.\n\n4. **Conda Environment Setup**: Review the conda environment being set up and confirm reproducibility on different platforms, particularly focusing on dependencies like `cffi` and `pyarrow`.\n\n5. **Switching to Mamba**: Feel free to propose a PR for transitioning to `mamba`, but ensure compatibility with existing Docker images used in CI."
      }
    ],
    "codediff_length": 43046
  },
  {
    "index": 18,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/docs/Parameters.rst b/docs/Parameters.rst\nindex dcd1353e1525..ea2db3524cbd 100644\n--- a/docs/Parameters.rst\n+++ b/docs/Parameters.rst\n@@ -462,7 +462,7 @@ Learning Control Parameters\n \n    -  you need to specify all features in order. For example, ``mc=-1,0,1`` means decreasing for 1st feature, non-constraint for 2nd feature and increasing for the 3rd feature\n \n--  ``monotone_constraints_method`` :raw-html:`<a id=\"monotone_constraints_method\" title=\"Permalink to this parameter\" href=\"#monotone_constraints_method\">&#x1F517;&#xFE0E;</a>`, default = ``basic``, type = enum, options: ``basic``, ``intermediate``, aliases: ``monotone_constraining_method``, ``mc_method``\n+-  ``monotone_constraints_method`` :raw-html:`<a id=\"monotone_constraints_method\" title=\"Permalink to this parameter\" href=\"#monotone_constraints_method\">&#x1F517;&#xFE0E;</a>`, default = ``basic``, type = enum, options: ``basic``, ``intermediate``, ``advanced``, aliases: ``monotone_constraining_method``, ``mc_method``\n \n    -  used only if ``monotone_constraints`` is set\n \n@@ -472,6 +472,8 @@ Learning Control Parameters\n \n       -  ``intermediate``, a `more advanced method <https://github.com/microsoft/LightGBM/files/3457826/PR-monotone-constraints-report.pdf>`__, which may slow the library very slightly. However, this method is much less constraining than the basic method and should significantly improve the results\n \n+      -  ``advanced``, an `even more advanced method <https://github.com/microsoft/LightGBM/files/3457826/PR-monotone-constraints-report.pdf>`__, which may slow the library. However, this method is even less constraining than the intermediate method and should again significantly improve the results\n+\n -  ``monotone_penalty`` :raw-html:`<a id=\"monotone_penalty\" title=\"Permalink to this parameter\" href=\"#monotone_penalty\">&#x1F517;&#xFE0E;</a>`, default = ``0.0``, type = double, aliases: ``monotone_splits_penalty``, ``ms_penalty``, ``mc_penalty``, constraints: ``monotone_penalty >= 0.0``\n \n    -  used only if ``monotone_constraints`` is set\ndiff --git a/include/LightGBM/config.h b/include/LightGBM/config.h\nindex 5e1902613905..3bbe39ca8ace 100644\n--- a/include/LightGBM/config.h\n+++ b/include/LightGBM/config.h\n@@ -443,11 +443,12 @@ struct Config {\n \n   // type = enum\n   // alias = monotone_constraining_method, mc_method\n-  // options = basic, intermediate\n+  // options = basic, intermediate, advanced\n   // desc = used only if ``monotone_constraints`` is set\n   // desc = monotone constraints method\n   // descl2 = ``basic``, the most basic monotone constraints method. It does not slow the library at all, but over-constrains the predictions\n   // descl2 = ``intermediate``, a `more advanced method <https://github.com/microsoft/LightGBM/files/3457826/PR-monotone-constraints-report.pdf>`__, which may slow the library very slightly. However, this method is much less constraining than the basic method and should significantly improve the results\n+  // descl2 = ``advanced``, an `even more advanced method <https://github.com/microsoft/LightGBM/files/3457826/PR-monotone-constraints-report.pdf>`__, which may slow the library. However, this method is even less constraining than the intermediate method and should again significantly improve the results\n   std::string monotone_constraints_method = \"basic\";\n \n   // alias = monotone_splits_penalty, ms_penalty, mc_penalty\ndiff --git a/src/io/config.cpp b/src/io/config.cpp\nindex 6878896deb58..a3f7536267a3 100644\n--- a/src/io/config.cpp\n+++ b/src/io/config.cpp\n@@ -345,15 +345,15 @@ void Config::CheckParamConflict() {\n     min_data_in_leaf = 2;\n     Log::Warning(\"min_data_in_leaf has been increased to 2 because this is required when path smoothing is active.\");\n   }\n-  if (is_parallel && monotone_constraints_method == std::string(\"intermediate\")) {\n+  if (is_parallel && (monotone_constraints_method == std::string(\"intermediate\") || monotone_constraints_method == std::string(\"advanced\"))) {\n     // In distributed mode, local node doesn't have histograms on all features, cannot perform \"intermediate\" monotone constraints.\n-    Log::Warning(\"Cannot use \\\"intermediate\\\" monotone constraints in parallel learning, auto set to \\\"basic\\\" method.\");\n+    Log::Warning(\"Cannot use \\\"intermediate\\\" or \\\"advanced\\\" monotone constraints in parallel learning, auto set to \\\"basic\\\" method.\");\n     monotone_constraints_method = \"basic\";\n   }\n-  if (feature_fraction_bynode != 1.0 && monotone_constraints_method == std::string(\"intermediate\")) {\n+  if (feature_fraction_bynode != 1.0 && (monotone_constraints_method == std::string(\"intermediate\") || monotone_constraints_method == std::string(\"advanced\"))) {\n     // \"intermediate\" monotone constraints need to recompute splits. If the features are sampled when computing the\n     // split initially, then the sampling needs to be recorded or done once again, which is currently not supported\n-    Log::Warning(\"Cannot use \\\"intermediate\\\" monotone constraints with feature fraction different from 1, auto set monotone constraints to \\\"basic\\\" method.\");\n+    Log::Warning(\"Cannot use \\\"intermediate\\\" or \\\"advanced\\\" monotone constraints with feature fraction different from 1, auto set monotone constraints to \\\"basic\\\" method.\");\n     monotone_constraints_method = \"basic\";\n   }\n   if (max_depth > 0 && monotone_penalty >= max_depth) {\ndiff --git a/src/treelearner/feature_histogram.hpp b/src/treelearner/feature_histogram.hpp\nindex 7fa341c67acb..5d7595c35c3b 100644\n--- a/src/treelearner/feature_histogram.hpp\n+++ b/src/treelearner/feature_histogram.hpp\n@@ -84,7 +84,7 @@ class FeatureHistogram {\n \n   void FindBestThreshold(double sum_gradient, double sum_hessian,\n                          data_size_t num_data,\n-                         const ConstraintEntry& constraints,\n+                         const FeatureConstraint* constraints,\n                          double parent_output,\n                          SplitInfo* output) {\n     output->default_left = true;\n@@ -158,7 +158,7 @@ class FeatureHistogram {\n #define TEMPLATE_PREFIX USE_RAND, USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING\n #define LAMBDA_ARGUMENTS                                         \\\n   double sum_gradient, double sum_hessian, data_size_t num_data, \\\n-      const ConstraintEntry &constraints, double parent_output, SplitInfo *output\n+      const FeatureConstraint* constraints, double parent_output, SplitInfo *output\n #define BEFORE_ARGUMENTS sum_gradient, sum_hessian, parent_output, num_data, output, &rand_threshold\n #define FUNC_ARGUMENTS                                                      \\\n   sum_gradient, sum_hessian, num_data, constraints, min_gain_shift, \\\n@@ -278,7 +278,7 @@ class FeatureHistogram {\n   void FindBestThresholdCategoricalInner(double sum_gradient,\n                                          double sum_hessian,\n                                          data_size_t num_data,\n-                                         const ConstraintEntry& constraints,\n+                                         const FeatureConstraint* constraints,\n                                          double parent_output,\n                                          SplitInfo* output) {\n     is_splittable_ = false;\n@@ -288,6 +288,9 @@ class FeatureHistogram {\n     double best_sum_left_gradient = 0;\n     double best_sum_left_hessian = 0;\n     double gain_shift;\n+    if (USE_MC) {\n+      constraints->InitCumulativeConstraints(true);\n+    }\n     if (USE_SMOOTHING) {\n       gain_shift = GetLeafGainGivenOutput<USE_L1>(\n           sum_gradient, sum_hessian, meta_->config->lambda_l1, meta_->config->lambda_l2, parent_output);\n@@ -474,14 +477,14 @@ class FeatureHistogram {\n       output->left_output = CalculateSplittedLeafOutput<USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(\n           best_sum_left_gradient, best_sum_left_hessian,\n           meta_->config->lambda_l1, l2, meta_->config->max_delta_step,\n-          constraints, meta_->config->path_smooth, best_left_count, parent_output);\n+          constraints->LeftToBasicConstraint(), meta_->config->path_smooth, best_left_count, parent_output);\n       output->left_count = best_left_count;\n       output->left_sum_gradient = best_sum_left_gradient;\n       output->left_sum_hessian = best_sum_left_hessian - kEpsilon;\n       output->right_output = CalculateSplittedLeafOutput<USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(\n           sum_gradient - best_sum_left_gradient,\n           sum_hessian - best_sum_left_hessian, meta_->config->lambda_l1, l2,\n-          meta_->config->max_delta_step, constraints, meta_->config->path_smooth,\n+          meta_->config->max_delta_step, constraints->RightToBasicConstraint(), meta_->config->path_smooth,\n           num_data - best_left_count, parent_output);\n       output->right_count = num_data - best_left_count;\n       output->right_sum_gradient = sum_gradient - best_sum_left_gradient;\n@@ -763,7 +766,7 @@ class FeatureHistogram {\n   template <bool USE_MC, bool USE_L1, bool USE_MAX_OUTPUT, bool USE_SMOOTHING>\n   static double CalculateSplittedLeafOutput(\n       double sum_gradients, double sum_hessians, double l1, double l2,\n-      double max_delta_step, const ConstraintEntry& constraints,\n+      double max_delta_step, const BasicConstraint& constraints,\n       double smoothing, data_size_t num_data, double parent_output) {\n     double ret = CalculateSplittedLeafOutput<USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(\n         sum_gradients, sum_hessians, l1, l2, max_delta_step, smoothing, num_data, parent_output);\n@@ -784,7 +787,7 @@ class FeatureHistogram {\n                               double sum_right_gradients,\n                               double sum_right_hessians, double l1, double l2,\n                               double max_delta_step,\n-                              const ConstraintEntry& constraints,\n+                              const FeatureConstraint* constraints,\n                               int8_t monotone_constraint,\n                               double smoothing,\n                               data_size_t left_count,\n@@ -803,11 +806,11 @@ class FeatureHistogram {\n       double left_output =\n           CalculateSplittedLeafOutput<USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(\n               sum_left_gradients, sum_left_hessians, l1, l2, max_delta_step,\n-              constraints, smoothing, left_count, parent_output);\n+              constraints->LeftToBasicConstraint(), smoothing, left_count, parent_output);\n       double right_output =\n           CalculateSplittedLeafOutput<USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(\n               sum_right_gradients, sum_right_hessians, l1, l2, max_delta_step,\n-              constraints, smoothing, right_count, parent_output);\n+              constraints->RightToBasicConstraint(), smoothing, right_count, parent_output);\n       if (((monotone_constraint > 0) && (left_output > right_output)) ||\n           ((monotone_constraint < 0) && (left_output < right_output))) {\n         return 0;\n@@ -854,7 +857,7 @@ class FeatureHistogram {\n             bool REVERSE, bool SKIP_DEFAULT_BIN, bool NA_AS_MISSING>\n   void FindBestThresholdSequentially(double sum_gradient, double sum_hessian,\n                                      data_size_t num_data,\n-                                     const ConstraintEntry& constraints,\n+                                     const FeatureConstraint* constraints,\n                                      double min_gain_shift, SplitInfo* output,\n                                      int rand_threshold, double parent_output) {\n     const int8_t offset = meta_->offset;\n@@ -864,6 +867,16 @@ class FeatureHistogram {\n     data_size_t best_left_count = 0;\n     uint32_t best_threshold = static_cast<uint32_t>(meta_->num_bin);\n     const double cnt_factor = num_data / sum_hessian;\n+\n+    BasicConstraint best_right_constraints;\n+    BasicConstraint best_left_constraints;\n+    bool constraint_update_necessary =\n+        USE_MC && constraints->ConstraintDifferentDependingOnThreshold();\n+\n+    if (USE_MC) {\n+      constraints->InitCumulativeConstraints(REVERSE);\n+    }\n+\n     if (REVERSE) {\n       double sum_right_gradient = 0.0f;\n       double sum_right_hessian = kEpsilon;\n@@ -910,6 +923,11 @@ class FeatureHistogram {\n             continue;\n           }\n         }\n+\n+        if (USE_MC && constraint_update_necessary) {\n+          constraints->Update(t + offset);\n+        }\n+\n         // current split gain\n         double current_gain = GetSplitGains<USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(\n             sum_left_gradient, sum_left_hessian, sum_right_gradient,\n@@ -932,6 +950,10 @@ class FeatureHistogram {\n           // left is <= threshold, right is > threshold.  so this is t-1\n           best_threshold = static_cast<uint32_t>(t - 1 + offset);\n           best_gain = current_gain;\n+          if (USE_MC) {\n+            best_right_constraints = constraints->RightToBasicConstraint();\n+            best_left_constraints = constraints->LeftToBasicConstraint();\n+          }\n         }\n       }\n     } else {\n@@ -1016,6 +1038,10 @@ class FeatureHistogram {\n           best_sum_left_hessian = sum_left_hessian;\n           best_threshold = static_cast<uint32_t>(t + offset);\n           best_gain = current_gain;\n+          if (USE_MC) {\n+            best_right_constraints = constraints->RightToBasicConstraint();\n+            best_left_constraints = constraints->LeftToBasicConstraint();\n+          }\n         }\n       }\n     }\n@@ -1027,7 +1053,7 @@ class FeatureHistogram {\n           CalculateSplittedLeafOutput<USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(\n               best_sum_left_gradient, best_sum_left_hessian,\n               meta_->config->lambda_l1, meta_->config->lambda_l2,\n-              meta_->config->max_delta_step, constraints, meta_->config->path_smooth,\n+              meta_->config->max_delta_step, best_left_constraints, meta_->config->path_smooth,\n               best_left_count, parent_output);\n       output->left_count = best_left_count;\n       output->left_sum_gradient = best_sum_left_gradient;\n@@ -1037,7 +1063,7 @@ class FeatureHistogram {\n               sum_gradient - best_sum_left_gradient,\n               sum_hessian - best_sum_left_hessian, meta_->config->lambda_l1,\n               meta_->config->lambda_l2, meta_->config->max_delta_step,\n-              constraints, meta_->config->path_smooth, num_data - best_left_count,\n+              best_right_constraints, meta_->config->path_smooth, num_data - best_left_count,\n               parent_output);\n       output->right_count = num_data - best_left_count;\n       output->right_sum_gradient = sum_gradient - best_sum_left_gradient;\n@@ -1053,7 +1079,7 @@ class FeatureHistogram {\n   hist_t* data_;\n   bool is_splittable_ = true;\n \n-  std::function<void(double, double, data_size_t, const ConstraintEntry&,\n+  std::function<void(double, double, data_size_t, const FeatureConstraint*,\n                      double, SplitInfo*)>\n       find_best_threshold_fun_;\n };\ndiff --git a/src/treelearner/monotone_constraints.hpp b/src/treelearner/monotone_constraints.hpp\nindex dcad0d6d3288..fde4bfbf033d 100644\n--- a/src/treelearner/monotone_constraints.hpp\n+++ b/src/treelearner/monotone_constraints.hpp\n@@ -16,22 +16,60 @@\n \n namespace LightGBM {\n \n-struct ConstraintEntry {\n+class LeafConstraintsBase;\n+\n+struct BasicConstraint {\n   double min = -std::numeric_limits<double>::max();\n   double max = std::numeric_limits<double>::max();\n \n-  ConstraintEntry() {}\n+  BasicConstraint(double min, double max) : min(min), max(max) {}\n \n-  void Reset() {\n+  BasicConstraint() = default;\n+};\n+\n+struct FeatureConstraint {\n+  virtual void InitCumulativeConstraints(bool) const {}\n+  virtual void Update(int) const {}\n+  virtual BasicConstraint LeftToBasicConstraint() const = 0;\n+  virtual BasicConstraint RightToBasicConstraint() const = 0;\n+  virtual bool ConstraintDifferentDependingOnThreshold() const = 0;\n+  virtual ~FeatureConstraint() {}\n+};\n+\n+struct ConstraintEntry {\n+  virtual void Reset() = 0;\n+  virtual void UpdateMin(double new_min) = 0;\n+  virtual void UpdateMax(double new_max) = 0;\n+  virtual bool UpdateMinAndReturnBoolIfChanged(double new_min) = 0;\n+  virtual bool UpdateMaxAndReturnBoolIfChanged(double new_max) = 0;\n+  virtual ConstraintEntry *clone() const = 0;\n+\n+  virtual void RecomputeConstraintsIfNeeded(LeafConstraintsBase *, int, int,\n+                                            uint32_t) {}\n+\n+  virtual FeatureConstraint *GetFeatureConstraint(int feature_index) = 0;\n+};\n+\n+// used by both BasicLeafConstraints and IntermediateLeafConstraints\n+struct BasicConstraintEntry : ConstraintEntry,\n+                              FeatureConstraint,\n+                              BasicConstraint {\n+  bool ConstraintDifferentDependingOnThreshold() const final { return false; }\n+\n+  BasicConstraintEntry *clone() const final {\n+    return new BasicConstraintEntry(*this);\n+  };\n+\n+  void Reset() final {\n     min = -std::numeric_limits<double>::max();\n     max = std::numeric_limits<double>::max();\n   }\n \n-  void UpdateMin(double new_min) { min = std::max(new_min, min); }\n+  void UpdateMin(double new_min) final { min = std::max(new_min, min); }\n \n-  void UpdateMax(double new_max) { max = std::min(new_max, max); }\n+  void UpdateMax(double new_max) final { max = std::min(new_max, max); }\n \n-  bool UpdateMinAndReturnBoolIfChanged(double new_min) {\n+  bool UpdateMinAndReturnBoolIfChanged(double new_min) final {\n     if (new_min > min) {\n       min = new_min;\n       return true;\n@@ -39,29 +77,278 @@ struct ConstraintEntry {\n     return false;\n   }\n \n-  bool UpdateMaxAndReturnBoolIfChanged(double new_max) {\n+  bool UpdateMaxAndReturnBoolIfChanged(double new_max) final {\n     if (new_max < max) {\n       max = new_max;\n       return true;\n     }\n     return false;\n   }\n+\n+  BasicConstraint LeftToBasicConstraint() const final { return *this; }\n+\n+  BasicConstraint RightToBasicConstraint() const final { return *this; }\n+\n+  FeatureConstraint *GetFeatureConstraint(int) final { return this; }\n+};\n+\n+struct FeatureMinOrMaxConstraints {\n+  std::vector<double> constraints;\n+  // the constraint number i is valid on the slice\n+  // [thresholds[i]:threshold[i+1])\n+  // if threshold[i+1] does not exist, then it is valid for thresholds following\n+  // threshold[i]\n+  std::vector<uint32_t> thresholds;\n+\n+  FeatureMinOrMaxConstraints() {\n+    constraints.reserve(32);\n+    thresholds.reserve(32);\n+  }\n+\n+  size_t Size() const { return thresholds.size(); }\n+\n+  explicit FeatureMinOrMaxConstraints(double extremum) {\n+    constraints.reserve(32);\n+    thresholds.reserve(32);\n+\n+    constraints.push_back(extremum);\n+    thresholds.push_back(0);\n+  }\n+\n+  void Reset(double extremum) {\n+    constraints.resize(1);\n+    constraints[0] = extremum;\n+    thresholds.resize(1);\n+    thresholds[0] = 0;\n+  }\n+\n+  void UpdateMin(double min) {\n+    for (size_t j = 0; j < constraints.size(); ++j) {\n+      if (min > constraints[j]) {\n+        constraints[j] = min;\n+      }\n+    }\n+  }\n+\n+  void UpdateMax(double max) {\n+    for (size_t j = 0; j < constraints.size(); ++j) {\n+      if (max < constraints[j]) {\n+        constraints[j] = max;\n+      }\n+    }\n+  }\n+};\n+\n+struct CumulativeFeatureConstraint {\n+  std::vector<uint32_t> thresholds_min_constraints;\n+  std::vector<uint32_t> thresholds_max_constraints;\n+  std::vector<double> cumulative_min_constraints_left_to_right;\n+  std::vector<double> cumulative_min_constraints_right_to_left;\n+  std::vector<double> cumulative_max_constraints_left_to_right;\n+  std::vector<double> cumulative_max_constraints_right_to_left;\n+  size_t index_min_constraints_left_to_right;\n+  size_t index_min_constraints_right_to_left;\n+  size_t index_max_constraints_left_to_right;\n+  size_t index_max_constraints_right_to_left;\n+\n+  static void CumulativeExtremum(\n+      const double &(*extremum_function)(const double &, const double &),\n+      bool is_direction_from_left_to_right,\n+      std::vector<double>* cumulative_extremum) {\n+    if (cumulative_extremum->size() == 1) {\n+      return;\n+    }\n+\n+#ifdef DEBUG\n+    CHECK_NE(cumulative_extremum->size(), 0);\n+#endif\n+\n+    size_t n_exts = cumulative_extremum->size();\n+    int step = is_direction_from_left_to_right ? 1 : -1;\n+    size_t start = is_direction_from_left_to_right ? 0 : n_exts - 1;\n+    size_t end = is_direction_from_left_to_right ? n_exts - 1 : 0;\n+\n+    for (auto i = start; i != end; i = i + step) {\n+      (*cumulative_extremum)[i + step] = extremum_function(\n+          (*cumulative_extremum)[i + step], (*cumulative_extremum)[i]);\n+    }\n+  }\n+\n+  CumulativeFeatureConstraint() = default;\n+\n+  CumulativeFeatureConstraint(FeatureMinOrMaxConstraints min_constraints,\n+                              FeatureMinOrMaxConstraints max_constraints,\n+                              bool REVERSE) {\n+    thresholds_min_constraints = min_constraints.thresholds;\n+    thresholds_max_constraints = max_constraints.thresholds;\n+    cumulative_min_constraints_left_to_right = min_constraints.constraints;\n+    cumulative_min_constraints_right_to_left = min_constraints.constraints;\n+    cumulative_max_constraints_left_to_right = max_constraints.constraints;\n+    cumulative_max_constraints_right_to_left = max_constraints.constraints;\n+\n+    const double &(*min)(const double &, const double &) = std::min<double>;\n+    const double &(*max)(const double &, const double &) = std::max<double>;\n+    CumulativeExtremum(max, true, &cumulative_min_constraints_left_to_right);\n+    CumulativeExtremum(max, false, &cumulative_min_constraints_right_to_left);\n+    CumulativeExtremum(min, true, &cumulative_max_constraints_left_to_right);\n+    CumulativeExtremum(min, false, &cumulative_max_constraints_right_to_left);\n+\n+    if (REVERSE) {\n+      index_min_constraints_left_to_right =\n+          thresholds_min_constraints.size() - 1;\n+      index_min_constraints_right_to_left =\n+          thresholds_min_constraints.size() - 1;\n+      index_max_constraints_left_to_right =\n+          thresholds_max_constraints.size() - 1;\n+      index_max_constraints_right_to_left =\n+          thresholds_max_constraints.size() - 1;\n+    } else {\n+      index_min_constraints_left_to_right = 0;\n+      index_min_constraints_right_to_left = 0;\n+      index_max_constraints_left_to_right = 0;\n+      index_max_constraints_right_to_left = 0;\n+    }\n+  }\n+\n+  void Update(int threshold) {\n+    while (\n+        static_cast<int>(\n+            thresholds_min_constraints[index_min_constraints_left_to_right]) >\n+        threshold - 1) {\n+      index_min_constraints_left_to_right -= 1;\n+    }\n+    while (\n+        static_cast<int>(\n+            thresholds_min_constraints[index_min_constraints_right_to_left]) >\n+        threshold) {\n+      index_min_constraints_right_to_left -= 1;\n+    }\n+    while (\n+        static_cast<int>(\n+            thresholds_max_constraints[index_max_constraints_left_to_right]) >\n+        threshold - 1) {\n+      index_max_constraints_left_to_right -= 1;\n+    }\n+    while (\n+        static_cast<int>(\n+            thresholds_max_constraints[index_max_constraints_right_to_left]) >\n+        threshold) {\n+      index_max_constraints_right_to_left -= 1;\n+    }\n+  }\n+\n+  double GetRightMin() const {\n+    return cumulative_min_constraints_right_to_left\n+        [index_min_constraints_right_to_left];\n+  }\n+  double GetRightMax() const {\n+    return cumulative_max_constraints_right_to_left\n+        [index_max_constraints_right_to_left];\n+  }\n+  double GetLeftMin() const {\n+    return cumulative_min_constraints_left_to_right\n+        [index_min_constraints_left_to_right];\n+  }\n+  double GetLeftMax() const {\n+    return cumulative_max_constraints_left_to_right\n+        [index_max_constraints_left_to_right];\n+  }\n+};\n+\n+struct AdvancedFeatureConstraints : FeatureConstraint {\n+  FeatureMinOrMaxConstraints min_constraints;\n+  FeatureMinOrMaxConstraints max_constraints;\n+  mutable CumulativeFeatureConstraint cumulative_feature_constraint;\n+  bool min_constraints_to_be_recomputed = false;\n+  bool max_constraints_to_be_recomputed = false;\n+\n+  void InitCumulativeConstraints(bool REVERSE) const final {\n+    cumulative_feature_constraint =\n+        CumulativeFeatureConstraint(min_constraints, max_constraints, REVERSE);\n+  }\n+\n+  void Update(int threshold) const final {\n+    cumulative_feature_constraint.Update(threshold);\n+  }\n+\n+  FeatureMinOrMaxConstraints &GetMinConstraints() { return min_constraints; }\n+\n+  FeatureMinOrMaxConstraints &GetMaxConstraints() { return max_constraints; }\n+\n+  bool ConstraintDifferentDependingOnThreshold() const final {\n+    return min_constraints.Size() > 1 || max_constraints.Size() > 1;\n+  }\n+\n+  BasicConstraint RightToBasicConstraint() const final {\n+    return BasicConstraint(cumulative_feature_constraint.GetRightMin(),\n+                           cumulative_feature_constraint.GetRightMax());\n+  }\n+\n+  BasicConstraint LeftToBasicConstraint() const final {\n+    return BasicConstraint(cumulative_feature_constraint.GetLeftMin(),\n+                           cumulative_feature_constraint.GetLeftMax());\n+  }\n+\n+  void Reset() {\n+    min_constraints.Reset(-std::numeric_limits<double>::max());\n+    max_constraints.Reset(std::numeric_limits<double>::max());\n+  }\n+\n+  void UpdateMax(double new_max, bool trigger_a_recompute) {\n+    if (trigger_a_recompute) {\n+      max_constraints_to_be_recomputed = true;\n+    }\n+    max_constraints.UpdateMax(new_max);\n+  }\n+\n+  bool FeatureMaxConstraintsToBeUpdated() {\n+    return max_constraints_to_be_recomputed;\n+  }\n+\n+  bool FeatureMinConstraintsToBeUpdated() {\n+    return min_constraints_to_be_recomputed;\n+  }\n+\n+  void ResetUpdates() {\n+    min_constraints_to_be_recomputed = false;\n+    max_constraints_to_be_recomputed = false;\n+  }\n+\n+  void UpdateMin(double new_min, bool trigger_a_recompute) {\n+    if (trigger_a_recompute) {\n+      min_constraints_to_be_recomputed = true;\n+    }\n+    min_constraints.UpdateMin(new_min);\n+  }\n };\n \n class LeafConstraintsBase {\n  public:\n   virtual ~LeafConstraintsBase() {}\n-  virtual const ConstraintEntry& Get(int leaf_idx) const = 0;\n+  virtual const ConstraintEntry* Get(int leaf_idx) = 0;\n+  virtual FeatureConstraint* GetFeatureConstraint(int leaf_idx, int feature_index) = 0;\n   virtual void Reset() = 0;\n-  virtual void BeforeSplit(const Tree* tree, int leaf, int new_leaf,\n+  virtual void BeforeSplit(int leaf, int new_leaf,\n                            int8_t monotone_type) = 0;\n   virtual std::vector<int> Update(\n-      const Tree* tree, bool is_numerical_split,\n+      bool is_numerical_split,\n       int leaf, int new_leaf, int8_t monotone_type, double right_output,\n       double left_output, int split_feature, const SplitInfo& split_info,\n       const std::vector<SplitInfo>& best_split_per_leaf) = 0;\n \n-  inline static LeafConstraintsBase* Create(const Config* config, int num_leaves);\n+  virtual void GoUpToFindConstrainingLeaves(\n+      int, int,\n+      std::vector<int>*,\n+      std::vector<uint32_t>*,\n+      std::vector<bool>*,\n+      FeatureMinOrMaxConstraints*, bool ,\n+      uint32_t, uint32_t, uint32_t) {}\n+\n+  virtual void RecomputeConstraintsIfNeeded(\n+      LeafConstraintsBase *constraints_,\n+      int feature_for_constraint, int leaf_idx, uint32_t it_end) = 0;\n+\n+  inline static LeafConstraintsBase* Create(const Config* config, int num_leaves, int num_features);\n \n   double ComputeMonotoneSplitGainPenalty(int leaf_index, double penalization) {\n     int depth = tree_->leaf_depth(leaf_index);\n@@ -78,48 +365,148 @@ class LeafConstraintsBase {\n     tree_ = tree;\n   }\n \n- private:\n+ protected:\n   const Tree* tree_;\n };\n \n+// used by AdvancedLeafConstraints\n+struct AdvancedConstraintEntry : ConstraintEntry {\n+  std::vector<AdvancedFeatureConstraints> constraints;\n+\n+  AdvancedConstraintEntry *clone() const final {\n+    return new AdvancedConstraintEntry(*this);\n+  };\n+\n+  void RecomputeConstraintsIfNeeded(LeafConstraintsBase *constraints_,\n+                                    int feature_for_constraint, int leaf_idx,\n+                                    uint32_t it_end) final {\n+    if (constraints[feature_for_constraint]\n+            .FeatureMinConstraintsToBeUpdated() ||\n+        constraints[feature_for_constraint]\n+            .FeatureMaxConstraintsToBeUpdated()) {\n+      FeatureMinOrMaxConstraints &constraints_to_be_updated =\n+          constraints[feature_for_constraint].FeatureMinConstraintsToBeUpdated()\n+              ? constraints[feature_for_constraint].GetMinConstraints()\n+              : constraints[feature_for_constraint].GetMaxConstraints();\n+\n+      constraints_to_be_updated.Reset(\n+          constraints[feature_for_constraint].FeatureMinConstraintsToBeUpdated()\n+              ? -std::numeric_limits<double>::max()\n+              : std::numeric_limits<double>::max());\n+\n+      std::vector<int> features_of_splits_going_up_from_original_leaf =\n+          std::vector<int>();\n+      std::vector<uint32_t> thresholds_of_splits_going_up_from_original_leaf =\n+          std::vector<uint32_t>();\n+      std::vector<bool> was_original_leaf_right_child_of_split =\n+          std::vector<bool>();\n+      constraints_->GoUpToFindConstrainingLeaves(\n+          feature_for_constraint, leaf_idx,\n+          &features_of_splits_going_up_from_original_leaf,\n+          &thresholds_of_splits_going_up_from_original_leaf,\n+          &was_original_leaf_right_child_of_split, &constraints_to_be_updated,\n+          constraints[feature_for_constraint]\n+              .FeatureMinConstraintsToBeUpdated(),\n+          0, it_end, it_end);\n+      constraints[feature_for_constraint].ResetUpdates();\n+    }\n+  }\n+\n+  // for each feature, an array of constraints needs to be stored\n+  explicit AdvancedConstraintEntry(int num_features) {\n+    constraints.resize(num_features);\n+  }\n+\n+  void Reset() final {\n+    for (size_t i = 0; i < constraints.size(); ++i) {\n+      constraints[i].Reset();\n+    }\n+  }\n+\n+  void UpdateMin(double new_min) final {\n+    for (size_t i = 0; i < constraints.size(); ++i) {\n+      constraints[i].UpdateMin(new_min, false);\n+    }\n+  }\n+\n+  void UpdateMax(double new_max) final {\n+    for (size_t i = 0; i < constraints.size(); ++i) {\n+      constraints[i].UpdateMax(new_max, false);\n+    }\n+  }\n+\n+  bool UpdateMinAndReturnBoolIfChanged(double new_min) final {\n+    for (size_t i = 0; i < constraints.size(); ++i) {\n+      constraints[i].UpdateMin(new_min, true);\n+    }\n+    // even if nothing changed, this could have been unconstrained so it needs\n+    // to be recomputed from the beginning\n+    return true;\n+  }\n+\n+  bool UpdateMaxAndReturnBoolIfChanged(double new_max) final {\n+    for (size_t i = 0; i < constraints.size(); ++i) {\n+      constraints[i].UpdateMax(new_max, true);\n+    }\n+    // even if nothing changed, this could have been unconstrained so it needs\n+    // to be recomputed from the beginning\n+    return true;\n+  }\n+\n+  FeatureConstraint *GetFeatureConstraint(int feature_index) final {\n+    return &constraints[feature_index];\n+  }\n+};\n+\n class BasicLeafConstraints : public LeafConstraintsBase {\n  public:\n   explicit BasicLeafConstraints(int num_leaves) : num_leaves_(num_leaves) {\n-    entries_.resize(num_leaves_);\n+    for (int i = 0; i < num_leaves; ++i) {\n+      entries_.push_back(new BasicConstraintEntry());\n+    }\n   }\n \n   void Reset() override {\n-    for (auto& entry : entries_) {\n-      entry.Reset();\n+    for (auto entry : entries_) {\n+      entry->Reset();\n     }\n   }\n \n-  void BeforeSplit(const Tree*, int, int, int8_t) override {}\n+  void RecomputeConstraintsIfNeeded(\n+      LeafConstraintsBase* constraints_,\n+      int feature_for_constraint, int leaf_idx, uint32_t it_end) override {\n+    entries_[~leaf_idx]->RecomputeConstraintsIfNeeded(constraints_, feature_for_constraint, leaf_idx, it_end);\n+  }\n \n-  std::vector<int> Update(const Tree*,\n-                          bool is_numerical_split, int leaf, int new_leaf,\n+  void BeforeSplit(int, int, int8_t) override {}\n+\n+  std::vector<int> Update(bool is_numerical_split, int leaf, int new_leaf,\n                           int8_t monotone_type, double right_output,\n                           double left_output, int, const SplitInfo& ,\n                           const std::vector<SplitInfo>&) override {\n-    entries_[new_leaf] = entries_[leaf];\n+    entries_[new_leaf] = entries_[leaf]->clone();\n     if (is_numerical_split) {\n       double mid = (left_output + right_output) / 2.0f;\n       if (monotone_type < 0) {\n-        entries_[leaf].UpdateMin(mid);\n-        entries_[new_leaf].UpdateMax(mid);\n+        entries_[leaf]->UpdateMin(mid);\n+        entries_[new_leaf]->UpdateMax(mid);\n       } else if (monotone_type > 0) {\n-        entries_[leaf].UpdateMax(mid);\n-        entries_[new_leaf].UpdateMin(mid);\n+        entries_[leaf]->UpdateMax(mid);\n+        entries_[new_leaf]->UpdateMin(mid);\n       }\n     }\n     return std::vector<int>();\n   }\n \n-  const ConstraintEntry& Get(int leaf_idx) const override { return entries_[leaf_idx]; }\n+  const ConstraintEntry* Get(int leaf_idx) override { return entries_[leaf_idx]; }\n+\n+  FeatureConstraint* GetFeatureConstraint(int leaf_idx, int feature_index) final {\n+    return entries_[leaf_idx]->GetFeatureConstraint(feature_index);\n+  }\n \n  protected:\n   int num_leaves_;\n-  std::vector<ConstraintEntry> entries_;\n+  std::vector<ConstraintEntry*> entries_;\n };\n \n class IntermediateLeafConstraints : public BasicLeafConstraints {\n@@ -138,7 +525,7 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n     leaves_to_update_.clear();\n   }\n \n-  void BeforeSplit(const Tree* tree, int leaf, int new_leaf,\n+  void BeforeSplit(int leaf, int new_leaf,\n                    int8_t monotone_type) override {\n     if (monotone_type != 0 || leaf_is_in_monotone_subtree_[leaf]) {\n       leaf_is_in_monotone_subtree_[leaf] = true;\n@@ -148,36 +535,36 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n     CHECK_GE(new_leaf - 1, 0);\n     CHECK_LT(static_cast<size_t>(new_leaf - 1), node_parent_.size());\n #endif\n-    node_parent_[new_leaf - 1] = tree->leaf_parent(leaf);\n+    node_parent_[new_leaf - 1] = tree_->leaf_parent(leaf);\n   }\n \n   void UpdateConstraintsWithOutputs(bool is_numerical_split, int leaf,\n                                     int new_leaf, int8_t monotone_type,\n                                     double right_output, double left_output) {\n-    entries_[new_leaf] = entries_[leaf];\n+    entries_[new_leaf] = entries_[leaf]->clone();\n     if (is_numerical_split) {\n       if (monotone_type < 0) {\n-        entries_[leaf].UpdateMin(right_output);\n-        entries_[new_leaf].UpdateMax(left_output);\n+        entries_[leaf]->UpdateMin(right_output);\n+        entries_[new_leaf]->UpdateMax(left_output);\n       } else if (monotone_type > 0) {\n-        entries_[leaf].UpdateMax(right_output);\n-        entries_[new_leaf].UpdateMin(left_output);\n+        entries_[leaf]->UpdateMax(right_output);\n+        entries_[new_leaf]->UpdateMin(left_output);\n       }\n     }\n   }\n \n-  std::vector<int> Update(const Tree* tree, bool is_numerical_split, int leaf,\n+  std::vector<int> Update(bool is_numerical_split, int leaf,\n                           int new_leaf, int8_t monotone_type,\n                           double right_output, double left_output,\n                           int split_feature, const SplitInfo& split_info,\n-                          const std::vector<SplitInfo>& best_split_per_leaf) override {\n+                          const std::vector<SplitInfo>& best_split_per_leaf) final {\n     leaves_to_update_.clear();\n     if (leaf_is_in_monotone_subtree_[leaf]) {\n       UpdateConstraintsWithOutputs(is_numerical_split, leaf, new_leaf,\n                                    monotone_type, right_output, left_output);\n \n       // Initialize variables to store information while going up the tree\n-      int depth = tree->leaf_depth(new_leaf) - 1;\n+      int depth = tree_->leaf_depth(new_leaf) - 1;\n \n       std::vector<int> features_of_splits_going_up_from_original_leaf;\n       std::vector<uint32_t> thresholds_of_splits_going_up_from_original_leaf;\n@@ -187,7 +574,7 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n       thresholds_of_splits_going_up_from_original_leaf.reserve(depth);\n       was_original_leaf_right_child_of_split.reserve(depth);\n \n-      GoUpToFindLeavesToUpdate(tree, tree->leaf_parent(new_leaf),\n+      GoUpToFindLeavesToUpdate(tree_->leaf_parent(new_leaf),\n                                &features_of_splits_going_up_from_original_leaf,\n                                &thresholds_of_splits_going_up_from_original_leaf,\n                                &was_original_leaf_right_child_of_split,\n@@ -203,8 +590,6 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n       int inner_feature,\n       const std::vector<bool>& was_original_leaf_right_child_of_split,\n       bool is_in_right_child) {\n-    bool opposite_child_should_be_updated = true;\n-\n     // if the split is categorical, it is not handled by this optimisation,\n     // so the code will have to go down in the other child subtree to see if\n     // there are leaves to update\n@@ -221,18 +606,19 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n                 inner_feature &&\n             (was_original_leaf_right_child_of_split[split_idx] ==\n              is_in_right_child)) {\n-          opposite_child_should_be_updated = false;\n-          break;\n+          return false;\n         }\n       }\n+      return true;\n+    } else {\n+      return false;\n     }\n-    return opposite_child_should_be_updated;\n   }\n \n   // Recursive function that goes up the tree, and then down to find leaves that\n   // have constraints to be updated\n   void GoUpToFindLeavesToUpdate(\n-      const Tree* tree, int node_idx,\n+      int node_idx,\n       std::vector<int>* features_of_splits_going_up_from_original_leaf,\n       std::vector<uint32_t>* thresholds_of_splits_going_up_from_original_leaf,\n       std::vector<bool>* was_original_leaf_right_child_of_split,\n@@ -245,11 +631,11 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n     int parent_idx = node_parent_[node_idx];\n     // if not at the root\n     if (parent_idx != -1) {\n-      int inner_feature = tree->split_feature_inner(parent_idx);\n-      int feature = tree->split_feature(parent_idx);\n+      int inner_feature = tree_->split_feature_inner(parent_idx);\n+      int feature = tree_->split_feature(parent_idx);\n       int8_t monotone_type = config_->monotone_constraints[feature];\n-      bool is_in_right_child = tree->right_child(parent_idx) == node_idx;\n-      bool is_split_numerical = tree->IsNumericalSplit(node_idx);\n+      bool is_in_right_child = tree_->right_child(parent_idx) == node_idx;\n+      bool is_split_numerical = tree_->IsNumericalSplit(parent_idx);\n \n       // this is just an optimisation not to waste time going down in subtrees\n       // where there won't be any leaf to update\n@@ -264,8 +650,8 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n         if (monotone_type != 0) {\n           // these variables correspond to the current split we encounter going\n           // up the tree\n-          int left_child_idx = tree->left_child(parent_idx);\n-          int right_child_idx = tree->right_child(parent_idx);\n+          int left_child_idx = tree_->left_child(parent_idx);\n+          int right_child_idx = tree_->right_child(parent_idx);\n           bool left_child_is_curr_idx = (left_child_idx == node_idx);\n           int opposite_child_idx =\n               (left_child_is_curr_idx) ? right_child_idx : left_child_idx;\n@@ -277,7 +663,7 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n           // so the code needs to go down in the the opposite child\n           // to see which leaves' constraints need to be updated\n           GoDownToFindLeavesToUpdate(\n-              tree, opposite_child_idx,\n+              opposite_child_idx,\n               *features_of_splits_going_up_from_original_leaf,\n               *thresholds_of_splits_going_up_from_original_leaf,\n               *was_original_leaf_right_child_of_split,\n@@ -290,16 +676,16 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n         // is actually contiguous to the original 2 leaves and should be updated\n         // so the variables associated with the split need to be recorded\n         was_original_leaf_right_child_of_split->push_back(\n-            tree->right_child(parent_idx) == node_idx);\n+            tree_->right_child(parent_idx) == node_idx);\n         thresholds_of_splits_going_up_from_original_leaf->push_back(\n-            tree->threshold_in_bin(parent_idx));\n+            tree_->threshold_in_bin(parent_idx));\n         features_of_splits_going_up_from_original_leaf->push_back(\n-            tree->split_feature_inner(parent_idx));\n+            tree_->split_feature_inner(parent_idx));\n       }\n \n       // since current node is not the root, keep going up\n       GoUpToFindLeavesToUpdate(\n-          tree, parent_idx, features_of_splits_going_up_from_original_leaf,\n+          parent_idx, features_of_splits_going_up_from_original_leaf,\n           thresholds_of_splits_going_up_from_original_leaf,\n           was_original_leaf_right_child_of_split, split_feature, split_info,\n           split_threshold, best_split_per_leaf);\n@@ -307,7 +693,7 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n   }\n \n   void GoDownToFindLeavesToUpdate(\n-      const Tree* tree, int node_idx,\n+      int node_idx,\n       const std::vector<int>& features_of_splits_going_up_from_original_leaf,\n       const std::vector<uint32_t>&\n           thresholds_of_splits_going_up_from_original_leaf,\n@@ -345,18 +731,18 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n \n #ifdef DEBUG\n       if (update_max_constraints) {\n-        CHECK_GE(min_max_constraints.first, tree->LeafOutput(leaf_idx));\n+        CHECK_GE(min_max_constraints.first, tree_->LeafOutput(leaf_idx));\n       } else {\n-        CHECK_LE(min_max_constraints.second, tree->LeafOutput(leaf_idx));\n+        CHECK_LE(min_max_constraints.second, tree_->LeafOutput(leaf_idx));\n       }\n #endif\n       // depending on which split made the current leaf and the original leaves contiguous,\n       // either the min constraint or the max constraint of the current leaf need to be updated\n       if (!update_max_constraints) {\n-        something_changed = entries_[leaf_idx].UpdateMinAndReturnBoolIfChanged(\n+        something_changed = entries_[leaf_idx]->UpdateMinAndReturnBoolIfChanged(\n             min_max_constraints.second);\n       } else {\n-        something_changed = entries_[leaf_idx].UpdateMaxAndReturnBoolIfChanged(\n+        something_changed = entries_[leaf_idx]->UpdateMaxAndReturnBoolIfChanged(\n             min_max_constraints.first);\n       }\n       // If constraints were not updated, then there is no need to update the leaf\n@@ -368,12 +754,12 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n     } else {  // if node\n       // check if the children are contiguous with the original leaf\n       std::pair<bool, bool> keep_going_left_right = ShouldKeepGoingLeftRight(\n-          tree, node_idx, features_of_splits_going_up_from_original_leaf,\n+          node_idx, features_of_splits_going_up_from_original_leaf,\n           thresholds_of_splits_going_up_from_original_leaf,\n           was_original_leaf_right_child_of_split);\n-      int inner_feature = tree->split_feature_inner(node_idx);\n-      uint32_t threshold = tree->threshold_in_bin(node_idx);\n-      bool is_split_numerical = tree->IsNumericalSplit(node_idx);\n+      int inner_feature = tree_->split_feature_inner(node_idx);\n+      uint32_t threshold = tree_->threshold_in_bin(node_idx);\n+      bool is_split_numerical = tree_->IsNumericalSplit(node_idx);\n       bool use_left_leaf_for_update_right = true;\n       bool use_right_leaf_for_update_left = true;\n       // if the split is on the same feature (categorical variables not supported)\n@@ -392,7 +778,7 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n       // go down left\n       if (keep_going_left_right.first) {\n         GoDownToFindLeavesToUpdate(\n-            tree, tree->left_child(node_idx),\n+            tree_->left_child(node_idx),\n             features_of_splits_going_up_from_original_leaf,\n             thresholds_of_splits_going_up_from_original_leaf,\n             was_original_leaf_right_child_of_split, update_max_constraints,\n@@ -403,7 +789,7 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n       // go down right\n       if (keep_going_left_right.second) {\n         GoDownToFindLeavesToUpdate(\n-            tree, tree->right_child(node_idx),\n+            tree_->right_child(node_idx),\n             features_of_splits_going_up_from_original_leaf,\n             thresholds_of_splits_going_up_from_original_leaf,\n             was_original_leaf_right_child_of_split, update_max_constraints,\n@@ -415,14 +801,14 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n   }\n \n   std::pair<bool, bool> ShouldKeepGoingLeftRight(\n-      const Tree* tree, int node_idx,\n+      int node_idx,\n       const std::vector<int>& features_of_splits_going_up_from_original_leaf,\n       const std::vector<uint32_t>&\n           thresholds_of_splits_going_up_from_original_leaf,\n       const std::vector<bool>& was_original_leaf_right_child_of_split) {\n-    int inner_feature = tree->split_feature_inner(node_idx);\n-    uint32_t threshold = tree->threshold_in_bin(node_idx);\n-    bool is_split_numerical = tree->IsNumericalSplit(node_idx);\n+    int inner_feature = tree_->split_feature_inner(node_idx);\n+    uint32_t threshold = tree_->threshold_in_bin(node_idx);\n+    bool is_split_numerical = tree_->IsNumericalSplit(node_idx);\n \n     bool keep_going_right = true;\n     bool keep_going_left = true;\n@@ -456,7 +842,7 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n     return std::pair<bool, bool>(keep_going_left, keep_going_right);\n   }\n \n- private:\n+ protected:\n   const Config* config_;\n   std::vector<int> leaves_to_update_;\n   // add parent node information\n@@ -465,11 +851,330 @@ class IntermediateLeafConstraints : public BasicLeafConstraints {\n   std::vector<bool> leaf_is_in_monotone_subtree_;\n };\n \n+class AdvancedLeafConstraints : public IntermediateLeafConstraints {\n+ public:\n+  AdvancedLeafConstraints(const Config *config, int num_leaves,\n+                          int num_features)\n+      : IntermediateLeafConstraints(config, num_leaves) {\n+    for (int i = 0; i < num_leaves; ++i) {\n+      entries_[i] = new AdvancedConstraintEntry(num_features);\n+    }\n+  }\n+\n+  // at any point in time, for an index i, the constraint constraint[i] has to\n+  // be valid on [threshold[i]: threshold[i + 1]) (or [threshold[i]: +inf) if i\n+  // is the last index of the array)\n+  void UpdateConstraints(FeatureMinOrMaxConstraints* feature_constraint,\n+                         double extremum, uint32_t it_start, uint32_t it_end,\n+                         bool use_max_operator, uint32_t last_threshold) {\n+    bool start_done = false;\n+    bool end_done = false;\n+    // previous constraint have to be tracked\n+    // for example when adding a constraints cstr2 on thresholds [1:2),\n+    // on an existing constraints cstr1 on thresholds [0, +inf),\n+    // the thresholds and constraints must become\n+    // [0, 1, 2] and  [cstr1, cstr2, cstr1]\n+    // so since we loop through thresholds only once,\n+    // the previous constraint that still applies needs to be recorded\n+    double previous_constraint = use_max_operator\n+      ? -std::numeric_limits<double>::max()\n+      : std::numeric_limits<double>::max();\n+    double current_constraint;\n+    for (size_t i = 0; i < feature_constraint->thresholds.size(); ++i) {\n+      current_constraint = feature_constraint->constraints[i];\n+      // easy case when the thresholds match\n+      if (feature_constraint->thresholds[i] == it_start) {\n+        feature_constraint->constraints[i] =\n+            (use_max_operator)\n+                ? std::max(extremum, feature_constraint->constraints[i])\n+                : std::min(extremum, feature_constraint->constraints[i]);\n+        start_done = true;\n+      }\n+      if (feature_constraint->thresholds[i] > it_start) {\n+        // existing constraint is updated if there is a need for it\n+        if (feature_constraint->thresholds[i] < it_end) {\n+          feature_constraint->constraints[i] =\n+              (use_max_operator)\n+                  ? std::max(extremum, feature_constraint->constraints[i])\n+                  : std::min(extremum, feature_constraint->constraints[i]);\n+        }\n+        // when thresholds don't match, a new threshold\n+        // and a new constraint may need to be inserted\n+        if (!start_done) {\n+          start_done = true;\n+          if ((use_max_operator && extremum > previous_constraint) ||\n+              (!use_max_operator && extremum < previous_constraint)) {\n+            feature_constraint->constraints.insert(\n+                feature_constraint->constraints.begin() + i, extremum);\n+            feature_constraint->thresholds.insert(\n+                feature_constraint->thresholds.begin() + i, it_start);\n+            ++i;\n+          }\n+        }\n+      }\n+      // easy case when the end thresholds match\n+      if (feature_constraint->thresholds[i] == it_end) {\n+        end_done = true;\n+        break;\n+      }\n+      // if they don't then, the previous constraint needs to be added back\n+      // where the current one ends\n+      if (feature_constraint->thresholds[i] > it_end) {\n+        if (i != 0 &&\n+            previous_constraint != feature_constraint->constraints[i - 1]) {\n+          feature_constraint->constraints.insert(\n+              feature_constraint->constraints.begin() + i, previous_constraint);\n+          feature_constraint->thresholds.insert(\n+              feature_constraint->thresholds.begin() + i, it_end);\n+        }\n+        end_done = true;\n+        break;\n+      }\n+      // If 2 successive constraints are the same then the second one may as\n+      // well be deleted\n+      if (i != 0 && feature_constraint->constraints[i] ==\n+                        feature_constraint->constraints[i - 1]) {\n+        feature_constraint->constraints.erase(\n+            feature_constraint->constraints.begin() + i);\n+        feature_constraint->thresholds.erase(\n+            feature_constraint->thresholds.begin() + i);\n+        previous_constraint = current_constraint;\n+        --i;\n+      }\n+      previous_constraint = current_constraint;\n+    }\n+    // if the loop didn't get to an index greater than it_start, it needs to be\n+    // added at the end\n+    if (!start_done) {\n+      if ((use_max_operator &&\n+           extremum > feature_constraint->constraints.back()) ||\n+          (!use_max_operator &&\n+           extremum < feature_constraint->constraints.back())) {\n+        feature_constraint->constraints.push_back(extremum);\n+        feature_constraint->thresholds.push_back(it_start);\n+      } else {\n+        end_done = true;\n+      }\n+    }\n+    // if we didn't get to an index after it_end, then the previous constraint\n+    // needs to be set back, unless it_end goes up to the last bin of the feature\n+    if (!end_done && it_end != last_threshold &&\n+        previous_constraint != feature_constraint->constraints.back()) {\n+      feature_constraint->constraints.push_back(previous_constraint);\n+      feature_constraint->thresholds.push_back(it_end);\n+    }\n+  }\n+\n+  // this function is called only when computing constraints when the monotone\n+  // precise mode is set to true\n+  // it makes sure that it is worth it to visit a branch, as it could\n+  // not contain any relevant constraint (for example if the a branch\n+  // with bigger values is also constraining the original leaf, then\n+  // it is useless to visit the branch with smaller values)\n+  std::pair<bool, bool>\n+  LeftRightContainsRelevantInformation(bool min_constraints_to_be_updated,\n+                                       int feature,\n+                                       bool split_feature_is_inner_feature) {\n+    if (split_feature_is_inner_feature) {\n+      return std::pair<bool, bool>(true, true);\n+    }\n+    int8_t monotone_type = config_->monotone_constraints[feature];\n+    if (monotone_type == 0) {\n+      return std::pair<bool, bool>(true, true);\n+    }\n+    if ((monotone_type == -1 && min_constraints_to_be_updated) ||\n+        (monotone_type == 1 && !min_constraints_to_be_updated)) {\n+      return std::pair<bool, bool>(true, false);\n+    } else {\n+      //    Same as\n+      //    if ((monotone_type == 1 && min_constraints_to_be_updated) ||\n+      //        (monotone_type == -1 && !min_constraints_to_be_updated))\n+      return std::pair<bool, bool>(false, true);\n+    }\n+  }\n+\n+  // this function goes down in a subtree to find the\n+  // constraints that would apply on the original leaf\n+  void GoDownToFindConstrainingLeaves(\n+      int feature_for_constraint, int root_monotone_feature, int node_idx,\n+      bool min_constraints_to_be_updated, uint32_t it_start, uint32_t it_end,\n+      const std::vector<int> &features_of_splits_going_up_from_original_leaf,\n+      const std::vector<uint32_t> &\n+          thresholds_of_splits_going_up_from_original_leaf,\n+      const std::vector<bool> &was_original_leaf_right_child_of_split,\n+      FeatureMinOrMaxConstraints* feature_constraint, uint32_t last_threshold) {\n+    double extremum;\n+    // if leaf, then constraints need to be updated according to its value\n+    if (node_idx < 0) {\n+      extremum = tree_->LeafOutput(~node_idx);\n+#ifdef DEBUG\n+      CHECK(it_start < it_end);\n+#endif\n+      UpdateConstraints(feature_constraint, extremum, it_start, it_end,\n+                        min_constraints_to_be_updated, last_threshold);\n+    } else {  // if node, keep going down the tree\n+      // check if the children are contiguous to the original leaf and therefore\n+      // potentially constraining\n+      std::pair<bool, bool> keep_going_left_right = ShouldKeepGoingLeftRight(\n+          node_idx, features_of_splits_going_up_from_original_leaf,\n+          thresholds_of_splits_going_up_from_original_leaf,\n+          was_original_leaf_right_child_of_split);\n+      int inner_feature = tree_->split_feature_inner(node_idx);\n+      int feature = tree_->split_feature(node_idx);\n+      uint32_t threshold = tree_->threshold_in_bin(node_idx);\n+\n+      bool split_feature_is_inner_feature =\n+          (inner_feature == feature_for_constraint);\n+      bool split_feature_is_monotone_feature =\n+          (root_monotone_feature == feature_for_constraint);\n+      // make sure that both children contain values that could\n+      // potentially help determine the true constraints for the original leaf\n+      std::pair<bool, bool> left_right_contain_relevant_information =\n+          LeftRightContainsRelevantInformation(\n+              min_constraints_to_be_updated, feature,\n+              split_feature_is_inner_feature &&\n+                  !split_feature_is_monotone_feature);\n+      // if both children are contiguous to the original leaf\n+      // but one contains values greater than the other\n+      // then no need to go down in both\n+      if (keep_going_left_right.first &&\n+          (left_right_contain_relevant_information.first ||\n+           !keep_going_left_right.second)) {\n+        // update thresholds based on going left\n+        uint32_t new_it_end = split_feature_is_inner_feature\n+                                  ? std::min(threshold + 1, it_end)\n+                                  : it_end;\n+        GoDownToFindConstrainingLeaves(\n+            feature_for_constraint, root_monotone_feature,\n+            tree_->left_child(node_idx), min_constraints_to_be_updated,\n+            it_start, new_it_end,\n+            features_of_splits_going_up_from_original_leaf,\n+            thresholds_of_splits_going_up_from_original_leaf,\n+            was_original_leaf_right_child_of_split, feature_constraint,\n+            last_threshold);\n+      }\n+      if (keep_going_left_right.second &&\n+          (left_right_contain_relevant_information.second ||\n+           !keep_going_left_right.first)) {\n+        // update thresholds based on going right\n+        uint32_t new_it_start = split_feature_is_inner_feature\n+                                    ? std::max(threshold + 1, it_start)\n+                                    : it_start;\n+        GoDownToFindConstrainingLeaves(\n+            feature_for_constraint, root_monotone_feature,\n+            tree_->right_child(node_idx), min_constraints_to_be_updated,\n+            new_it_start, it_end,\n+            features_of_splits_going_up_from_original_leaf,\n+            thresholds_of_splits_going_up_from_original_leaf,\n+            was_original_leaf_right_child_of_split, feature_constraint,\n+            last_threshold);\n+      }\n+    }\n+  }\n+\n+  // this function is only used if the monotone precise mode is enabled\n+  // it recursively goes up the tree then down to find leaf that\n+  // are constraining the current leaf\n+  void GoUpToFindConstrainingLeaves(\n+      int feature_for_constraint, int node_idx,\n+      std::vector<int>* features_of_splits_going_up_from_original_leaf,\n+      std::vector<uint32_t>* thresholds_of_splits_going_up_from_original_leaf,\n+      std::vector<bool>* was_original_leaf_right_child_of_split,\n+      FeatureMinOrMaxConstraints* feature_constraint,\n+      bool min_constraints_to_be_updated, uint32_t it_start, uint32_t it_end,\n+      uint32_t last_threshold) final {\n+    int parent_idx =\n+        (node_idx < 0) ? tree_->leaf_parent(~node_idx) : node_parent_[node_idx];\n+    // if not at the root\n+    if (parent_idx != -1) {\n+      int inner_feature = tree_->split_feature_inner(parent_idx);\n+      int feature = tree_->split_feature(parent_idx);\n+      int8_t monotone_type = config_->monotone_constraints[feature];\n+      bool is_in_right_child = tree_->right_child(parent_idx) == node_idx;\n+      bool is_split_numerical = tree_->IsNumericalSplit(parent_idx);\n+      uint32_t threshold = tree_->threshold_in_bin(parent_idx);\n+\n+      // by going up, more information about the position of the\n+      // original leaf  are gathered so the starting and ending\n+      // thresholds can be updated, which will save some time later\n+      if ((feature_for_constraint == inner_feature) && is_split_numerical) {\n+        if (is_in_right_child) {\n+          it_start = std::max(threshold, it_start);\n+        } else {\n+          it_end = std::min(threshold + 1, it_end);\n+        }\n+#ifdef DEBUG\n+        CHECK(it_start < it_end);\n+#endif\n+      }\n+\n+      // this is just an optimisation not to waste time going down in subtrees\n+      // where there won't be any new constraining leaf\n+      bool opposite_child_necessary_to_update_constraints =\n+          OppositeChildShouldBeUpdated(\n+              is_split_numerical,\n+              *features_of_splits_going_up_from_original_leaf, inner_feature,\n+              *was_original_leaf_right_child_of_split, is_in_right_child);\n+\n+      if (opposite_child_necessary_to_update_constraints) {\n+        // if there is no monotone constraint on a split,\n+        // then there is no relationship between its left and right leaves'\n+        // values\n+        if (monotone_type != 0) {\n+          int left_child_idx = tree_->left_child(parent_idx);\n+          int right_child_idx = tree_->right_child(parent_idx);\n+          bool left_child_is_curr_idx = (left_child_idx == node_idx);\n+\n+          bool update_min_constraints_in_curr_child_leaf =\n+              (monotone_type < 0) ? left_child_is_curr_idx\n+                                  : !left_child_is_curr_idx;\n+          if (update_min_constraints_in_curr_child_leaf ==\n+              min_constraints_to_be_updated) {\n+            int opposite_child_idx =\n+                (left_child_is_curr_idx) ? right_child_idx : left_child_idx;\n+\n+            // go down in the opposite branch to find potential\n+            // constraining leaves\n+            GoDownToFindConstrainingLeaves(\n+                feature_for_constraint, inner_feature, opposite_child_idx,\n+                min_constraints_to_be_updated, it_start, it_end,\n+                *features_of_splits_going_up_from_original_leaf,\n+                *thresholds_of_splits_going_up_from_original_leaf,\n+                *was_original_leaf_right_child_of_split, feature_constraint,\n+                last_threshold);\n+          }\n+        }\n+        // if opposite_child_should_be_updated, then it means the path to come\n+        // up there was relevant,\n+        // i.e. that it will be helpful going down to determine which leaf\n+        // is actually contiguous to the original leaf and constraining\n+        // so the variables associated with the split need to be recorded\n+        was_original_leaf_right_child_of_split->push_back(is_in_right_child);\n+        thresholds_of_splits_going_up_from_original_leaf->push_back(threshold);\n+        features_of_splits_going_up_from_original_leaf->push_back(inner_feature);\n+      }\n+\n+      // since current node is not the root, keep going up\n+      if (parent_idx != 0) {\n+        GoUpToFindConstrainingLeaves(\n+            feature_for_constraint, parent_idx,\n+            features_of_splits_going_up_from_original_leaf,\n+            thresholds_of_splits_going_up_from_original_leaf,\n+            was_original_leaf_right_child_of_split, feature_constraint,\n+            min_constraints_to_be_updated, it_start, it_end, last_threshold);\n+      }\n+    }\n+  }\n+};\n+\n LeafConstraintsBase* LeafConstraintsBase::Create(const Config* config,\n-                                                 int num_leaves) {\n+                                                 int num_leaves, int num_features) {\n   if (config->monotone_constraints_method == \"intermediate\") {\n     return new IntermediateLeafConstraints(config, num_leaves);\n   }\n+  if (config->monotone_constraints_method == \"advanced\") {\n+    return new AdvancedLeafConstraints(config, num_leaves, num_features);\n+  }\n   return new BasicLeafConstraints(num_leaves);\n }\n \ndiff --git a/src/treelearner/serial_tree_learner.cpp b/src/treelearner/serial_tree_learner.cpp\nindex 8b3699667ad6..5426c394d91e 100644\n--- a/src/treelearner/serial_tree_learner.cpp\n+++ b/src/treelearner/serial_tree_learner.cpp\n@@ -46,7 +46,7 @@ void SerialTreeLearner::Init(const Dataset* train_data, bool is_constant_hessian\n \n   // push split information for all leaves\n   best_split_per_leaf_.resize(config_->num_leaves);\n-  constraints_.reset(LeafConstraintsBase::Create(config_, config_->num_leaves));\n+  constraints_.reset(LeafConstraintsBase::Create(config_, config_->num_leaves, train_data_->num_features()));\n \n   // initialize splits for leaf\n   smaller_leaf_splits_.reset(new LeafSplits(train_data_->num_data()));\n@@ -146,7 +146,7 @@ void SerialTreeLearner::ResetConfig(const Config* config) {\n     }\n     cegb_->Init();\n   }\n-  constraints_.reset(LeafConstraintsBase::Create(config_, config_->num_leaves));\n+  constraints_.reset(LeafConstraintsBase::Create(config_, config_->num_leaves, train_data_->num_features()));\n }\n \n Tree* SerialTreeLearner::Train(const score_t* gradients, const score_t *hessians) {\n@@ -561,7 +561,7 @@ void SerialTreeLearner::SplitInner(Tree* tree, int best_leaf, int* left_leaf,\n   auto next_leaf_id = tree->NextLeafId();\n \n   // update before tree split\n-  constraints_->BeforeSplit(tree, best_leaf, next_leaf_id,\n+  constraints_->BeforeSplit(best_leaf, next_leaf_id,\n                             best_split_info.monotone_type);\n \n   bool is_numerical_split =\n@@ -657,7 +657,7 @@ void SerialTreeLearner::SplitInner(Tree* tree, int best_leaf, int* left_leaf,\n                               best_split_info.left_output);\n   }\n   auto leaves_need_update = constraints_->Update(\n-      tree, is_numerical_split, *left_leaf, *right_leaf,\n+      is_numerical_split, *left_leaf, *right_leaf,\n       best_split_info.monotone_type, best_split_info.right_output,\n       best_split_info.left_output, inner_feature_index, best_split_info,\n       best_split_per_leaf_);\n@@ -711,20 +711,29 @@ void SerialTreeLearner::ComputeBestSplitForFeature(\n     FeatureHistogram* histogram_array_, int feature_index, int real_fidx,\n     bool is_feature_used, int num_data, const LeafSplits* leaf_splits,\n     SplitInfo* best_split) {\n+\n+  bool is_feature_numerical = train_data_->FeatureBinMapper(feature_index)\n+                                  ->bin_type() == BinType::NumericalBin;\n+  if (is_feature_numerical & !config_->monotone_constraints.empty()) {\n+    constraints_->RecomputeConstraintsIfNeeded(\n+        constraints_.get(), feature_index, ~(leaf_splits->leaf_index()),\n+        train_data_->FeatureNumBin(feature_index));\n+  }\n+\n   SplitInfo new_split;\n   double parent_output;\n   if (leaf_splits->leaf_index() == 0) {\n     // for root leaf the \"parent\" output is its own output because we don't apply any smoothing to the root\n-    parent_output = FeatureHistogram::CalculateSplittedLeafOutput<true, true, true, false>(\n+    parent_output = FeatureHistogram::CalculateSplittedLeafOutput<false, true, true, false>(\n         leaf_splits->sum_gradients(), leaf_splits->sum_hessians(), config_->lambda_l1,\n-        config_->lambda_l2, config_->max_delta_step, constraints_->Get(leaf_splits->leaf_index()),\n+        config_->lambda_l2, config_->max_delta_step, BasicConstraint(),\n         config_->path_smooth, static_cast<data_size_t>(num_data), 0);\n   } else {\n     parent_output = leaf_splits->weight();\n   }\n   histogram_array_[feature_index].FindBestThreshold(\n       leaf_splits->sum_gradients(), leaf_splits->sum_hessians(), num_data,\n-      constraints_->Get(leaf_splits->leaf_index()),  parent_output, &new_split);\n+      constraints_->GetFeatureConstraint(leaf_splits->leaf_index(), feature_index),  parent_output, &new_split);\n   new_split.feature = real_fidx;\n   if (cegb_ != nullptr) {\n     new_split.gain -=\ndiff --git a/tests/python_package_test/test_engine.py b/tests/python_package_test/test_engine.py\nindex c3d2794e228b..be10e35e8f48 100644\n--- a/tests/python_package_test/test_engine.py\n+++ b/tests/python_package_test/test_engine.py\n@@ -1202,7 +1202,7 @@ def is_correctly_constrained(learner, x3_to_category=True):\n \n         for test_with_categorical_variable in [True, False]:\n             trainset = self.generate_trainset_for_monotone_constraints_tests(test_with_categorical_variable)\n-            for monotone_constraints_method in [\"basic\", \"intermediate\"]:\n+            for monotone_constraints_method in [\"basic\", \"intermediate\", \"advanced\"]:\n                 params = {\n                     'min_data': 20,\n                     'num_leaves': 20,\n@@ -1236,7 +1236,7 @@ def are_there_monotone_splits(tree, monotone_constraints):\n         monotone_constraints = [1, -1, 0]\n         penalization_parameter = 2.0\n         trainset = self.generate_trainset_for_monotone_constraints_tests(x3_to_category=False)\n-        for monotone_constraints_method in [\"basic\", \"intermediate\"]:\n+        for monotone_constraints_method in [\"basic\", \"intermediate\", \"advanced\"]:\n             params = {\n                 'max_depth': max_depth,\n                 'monotone_constraints': monotone_constraints,\n@@ -1275,7 +1275,7 @@ def test_monotone_penalty_max(self):\n         unconstrained_model_predictions = unconstrained_model.\\\n             predict(x3_negatively_correlated_with_y.reshape(-1, 1))\n \n-        for monotone_constraints_method in [\"basic\", \"intermediate\"]:\n+        for monotone_constraints_method in [\"basic\", \"intermediate\", \"advanced\"]:\n             params_constrained_model[\"monotone_constraints_method\"] = monotone_constraints_method\n             # The penalization is so high that the first 2 features should not be used here\n             constrained_model = lgb.train(params_constrained_model, trainset_constrained_model, 10)\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Failing Tests**: All tests fail due to an R package size warning on macOS. Increment limits in `.ci/test_r_package.sh` for allowed check notes:\n\n   ```bash\n   if [[ $OS_NAME == \"linux\" ]] && [[ $R_BUILD_TYPE == \"cran\" ]]; then\n       ALLOWED_CHECK_NOTES=3\n   else\n       ALLOWED_CHECK_NOTES=2\n   fi\n   ```\n\n2. **Performance Enhancement**: Leverage `USE_MC` in split finding to improve speed when MC is not enabled.\n\n3. **Code Fixes**: Constraints in `feature_histogram.hpp` should be marked as const.\n\n4. **Merge Conflict**: Resolve the conflict with bug fix #3384 before merging.\n\n5. **Next Steps**: Address the failing check-doc task, which seems unrelated to the PR."
      }
    ],
    "codediff_length": 67969
  },
  {
    "index": 19,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/python-package/lightgbm/compat.py b/python-package/lightgbm/compat.py\nindex 06a7cf89bd4f..bfaa0f40a3db 100644\n--- a/python-package/lightgbm/compat.py\n+++ b/python-package/lightgbm/compat.py\n@@ -174,3 +174,21 @@ class dask_Series:  # type: ignore\n \n         def __init__(self, *args, **kwargs):\n             pass\n+\n+\"\"\"cpu_count()\"\"\"\n+try:\n+    from joblib import cpu_count\n+\n+    def _LGBMCpuCount(only_physical_cores: bool = True):\n+        return cpu_count(only_physical_cores=only_physical_cores)\n+except ImportError:\n+    try:\n+        from psutil import cpu_count\n+\n+        def _LGBMCpuCount(only_physical_cores: bool = True):\n+            return cpu_count(logical=not only_physical_cores)\n+    except ImportError:\n+        from multiprocessing import cpu_count\n+\n+        def _LGBMCpuCount(only_physical_cores: bool = True):\n+            return cpu_count()\ndiff --git a/python-package/lightgbm/dask.py b/python-package/lightgbm/dask.py\nindex 2157edecc02c..2152ac8e35cb 100644\n--- a/python-package/lightgbm/dask.py\n+++ b/python-package/lightgbm/dask.py\n@@ -1111,7 +1111,7 @@ def __init__(\n         reg_alpha: float = 0.,\n         reg_lambda: float = 0.,\n         random_state: Optional[Union[int, np.random.RandomState]] = None,\n-        n_jobs: int = -1,\n+        n_jobs: Optional[int] = None,\n         importance_type: str = 'split',\n         client: Optional[Client] = None,\n         **kwargs: Any\n@@ -1283,7 +1283,7 @@ def __init__(\n         reg_alpha: float = 0.,\n         reg_lambda: float = 0.,\n         random_state: Optional[Union[int, np.random.RandomState]] = None,\n-        n_jobs: int = -1,\n+        n_jobs: Optional[int] = None,\n         importance_type: str = 'split',\n         client: Optional[Client] = None,\n         **kwargs: Any\n@@ -1436,7 +1436,7 @@ def __init__(\n         reg_alpha: float = 0.,\n         reg_lambda: float = 0.,\n         random_state: Optional[Union[int, np.random.RandomState]] = None,\n-        n_jobs: int = -1,\n+        n_jobs: Optional[int] = None,\n         importance_type: str = 'split',\n         client: Optional[Client] = None,\n         **kwargs: Any\ndiff --git a/python-package/lightgbm/sklearn.py b/python-package/lightgbm/sklearn.py\nindex 7ebba0bc962c..2b65c875ec65 100644\n--- a/python-package/lightgbm/sklearn.py\n+++ b/python-package/lightgbm/sklearn.py\n@@ -10,8 +10,8 @@\n from .callback import record_evaluation\n from .compat import (SKLEARN_INSTALLED, LGBMNotFittedError, _LGBMAssertAllFinite, _LGBMCheckArray,\n                      _LGBMCheckClassificationTargets, _LGBMCheckSampleWeight, _LGBMCheckXY, _LGBMClassifierBase,\n-                     _LGBMComputeSampleWeight, _LGBMLabelEncoder, _LGBMModelBase, _LGBMRegressorBase, dt_DataTable,\n-                     pd_DataFrame)\n+                     _LGBMComputeSampleWeight, _LGBMCpuCount, _LGBMLabelEncoder, _LGBMModelBase, _LGBMRegressorBase,\n+                     dt_DataTable, pd_DataFrame)\n from .engine import train\n \n _EvalResultType = Tuple[str, float, bool]\n@@ -362,7 +362,7 @@ def __init__(\n         reg_alpha: float = 0.,\n         reg_lambda: float = 0.,\n         random_state: Optional[Union[int, np.random.RandomState]] = None,\n-        n_jobs: int = -1,\n+        n_jobs: Optional[int] = None,\n         importance_type: str = 'split',\n         **kwargs\n     ):\n@@ -425,8 +425,18 @@ def __init__(\n             If int, this number is used to seed the C++ code.\n             If RandomState object (numpy), a random integer is picked based on its state to seed the C++ code.\n             If None, default seeds in C++ code are used.\n-        n_jobs : int, optional (default=-1)\n-            Number of parallel threads to use for training (can be changed at prediction time).\n+        n_jobs : int or None, optional (default=None)\n+            Number of parallel threads to use for training (can be changed at prediction time by\n+            passing it as an extra keyword argument).\n+\n+            For better performance, it is recommended to set this to the number of physical cores\n+            in the CPU.\n+\n+            Negative integers are interpreted as following joblib's formula (n_cpus + 1 + n_jobs), just like\n+            scikit-learn (so e.g. -1 means using all threads). A value of zero corresponds the default number of\n+            threads configured for OpenMP in the system. A value of ``None`` (the default) corresponds\n+            to using the number of physical cores in the system (its correct detection requires\n+            either the ``joblib`` or the ``psutil`` util libraries to be installed).\n         importance_type : str, optional (default='split')\n             The type of feature importance to be filled into ``feature_importances_``.\n             If 'split', result contains numbers of times the feature is used in a model.\n@@ -635,8 +645,34 @@ def _process_params(self, stage: str) -> Dict[str, Any]:\n         # overwrite default metric by explicitly set metric\n         params = _choose_param_value(\"metric\", params, original_metric)\n \n+        # use joblib conventions for negative n_jobs, just like scikit-learn\n+        # at predict time, this is handled later due to the order of parameter updates\n+        if stage == \"fit\":\n+            params = _choose_param_value(\"num_threads\", params, self.n_jobs)\n+            params[\"num_threads\"] = self._process_n_jobs(params[\"num_threads\"])\n+\n         return params\n \n+    def _process_n_jobs(self, n_jobs: Optional[int]) -> int:\n+        \"\"\"Convert special values of n_jobs to their actual values according to the formulas that apply.\n+\n+        Parameters\n+        ----------\n+        n_jobs : int or None\n+            The original value of n_jobs, potentially having special values such as 'None' or\n+            negative integers.\n+\n+        Returns\n+        -------\n+        n_jobs : int\n+            The value of n_jobs with special values converted to actual number of threads.\n+        \"\"\"\n+        if n_jobs is None:\n+            n_jobs = _LGBMCpuCount(only_physical_cores=True)\n+        elif n_jobs < 0:\n+            n_jobs = max(_LGBMCpuCount(only_physical_cores=False) + 1 + n_jobs, 1)\n+        return n_jobs\n+\n     def fit(\n         self,\n         X,\n@@ -812,6 +848,15 @@ def predict(self, X, raw_score=False, start_iteration=0, num_iteration=None,\n         ):\n             predict_params.pop(alias, None)\n         predict_params.update(kwargs)\n+\n+        # number of threads can have values with special meaning which is only applied\n+        # in the scikit-learn interface, these should not reach the c++ side as-is\n+        n_jobs = self.n_jobs\n+        for alias in _ConfigAliases.get(\"num_threads\"):\n+            if alias in predict_params:\n+                n_jobs = predict_params.pop(alias)\n+        predict_params[\"num_threads\"] = self._process_n_jobs(n_jobs)\n+\n         return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **predict_params)\n \ndiff --git a/tests/python_package_test/test_consistency.py b/tests/python_package_test/test_consistency.py\nindex a9cb8436a847..bcc6f3834b1c 100644\n--- a/tests/python_package_test/test_consistency.py\n+++ b/tests/python_package_test/test_consistency.py\n@@ -21,7 +21,7 @@ def __init__(self, directory, prefix, config_file='train.conf'):\n                 if line and not line.startswith('#'):\n                     key, value = [token.strip() for token in line.split('=')]\n                     if 'early_stopping' not in key:  # disable early_stopping\n-                        self.params[key] = value if key != 'num_trees' else int(value)\n+                        self.params[key] = value if key not in {'num_trees', 'num_threads'} else int(value)\n \n     def load_dataset(self, suffix, is_sparse=False):\n         filename = str(self.path(suffix))\n@@ -84,7 +84,7 @@ def test_binary_linear():\n     X_test, _, X_test_fn = fd.load_dataset('.test')\n     weight_train = fd.load_field('.train.weight')\n     lgb_train = lgb.Dataset(X_train, y_train, params=fd.params, weight=weight_train)\n-    gbm = lgb.LGBMClassifier(**fd.params)\n+    gbm = lgb.LGBMClassifier(**fd.params, n_jobs=0)\n     gbm.fit(X_train, y_train, sample_weight=weight_train)\n     sk_pred = gbm.predict_proba(X_test)[:, 1]\n     fd.train_predict_check(lgb_train, X_test, X_test_fn, sk_pred)\ndiff --git a/tests/python_package_test/test_sklearn.py b/tests/python_package_test/test_sklearn.py\nindex 6b39592142b9..3f94321cbe66 100644\n--- a/tests/python_package_test/test_sklearn.py\n+++ b/tests/python_package_test/test_sklearn.py\n@@ -1,6 +1,7 @@\n # coding: utf-8\n import itertools\n import math\n+import re\n from os import getenv\n from pathlib import Path\n \n@@ -1301,3 +1302,29 @@ def test_multiclass_custom_objective():\n     np.testing.assert_allclose(builtin_obj_preds, custom_obj_preds, rtol=0.01)\n     assert not callable(builtin_obj_model.objective_)\n     assert callable(custom_obj_model.objective_)\n+\n+\n+def test_negative_n_jobs(tmp_path):\n+    n_threads = joblib.cpu_count()\n+    if n_threads <= 1:\n+        return None\n+    # 'val_minus_two' here is the expected number of threads for n_jobs=-2\n+    val_minus_two = n_threads - 1\n+    X, y = load_breast_cancer(return_X_y=True)\n+    # Note: according to joblib's formula, a value of n_jobs=-2 means\n+    # \"use all but one thread\" (formula: n_cpus + 1 + n_jobs)\n+    gbm = lgb.LGBMClassifier(n_estimators=2, verbose=-1, n_jobs=-2).fit(X, y)\n+    gbm.booster_.save_model(tmp_path / \"model.txt\")\n+    with open(tmp_path / \"model.txt\", \"r\") as f:\n+        model_txt = f.read()\n+    assert bool(re.search(rf\"\\[num_threads: {val_minus_two}\\]\", model_txt))\n+\n+\n+def test_default_n_jobs(tmp_path):\n+    n_cores = joblib.cpu_count(only_physical_cores=True)\n+    X, y = load_breast_cancer(return_X_y=True)\n+    gbm = lgb.LGBMClassifier(n_estimators=2, verbose=-1, n_jobs=None).fit(X, y)\n+    gbm.booster_.save_model(tmp_path / \"model.txt\")\n+    with open(tmp_path / \"model.txt\", \"r\") as f:\n+        model_txt = f.read()\n+    assert bool(re.search(rf\"\\[num_threads: {n_cores}\\]\", model_txt))\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Default CPU Count**: Change the default to use `joblib.cpu_count(only_physical_cores=True)`, ensuring negative values are interpreted as in scikit-learn.\n\n2. **Import Order Issue**: Resolve linter warnings by adjusting imports to match `isort` recommendations, ensuring PEP8 compliance when applicable.\n\n3. **Test Failures**: Modify the line in `test_consistency.py` to correctly convert string thread values to integers:\n   ```python\n   self.params[key] = value if key not in {'num_trees', 'num_threads'} else int(value)\n   ```\n\n4. **n_jobs Handling**: Reassess handling of `n_jobs` parameter for consistency between fit and prediction. Evaluate if it's beneficial to remove `n_jobs` from prediction to avoid conflicts with core assignment. Investigate issues with linear tree training as it may depend on threading behavior.\n\n5. **Follow-Up**: Engage @btrotta for deeper analysis on `test_consistency.py::test_binary_linear` failures."
      }
    ],
    "codediff_length": 10120
  },
  {
    "index": 20,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/include/LightGBM/c_api.h b/include/LightGBM/c_api.h\nindex 9e2607071979..8e9a6fc2500c 100644\n--- a/include/LightGBM/c_api.h\n+++ b/include/LightGBM/c_api.h\n@@ -555,23 +555,39 @@ LIGHTGBM_C_EXPORT int LGBM_BoosterGetEvalCounts(BoosterHandle handle,\n /*!\n  * \\brief Get names of evaluation datasets.\n  * \\param handle Handle of booster\n+ * \\param len Number of ``char*`` pointers stored at ``out_strs``.\n+ *            If smaller than the max size, only this many strings are copied\n  * \\param[out] out_len Total number of evaluation datasets\n+ * \\param buffer_len Size of pre-allocated strings. \n+ *                   Content is copied up to ``buffer_len - 1`` and null-terminated\n+ * \\param[out] out_buffer_len String sizes required to do the full string copies\n  * \\param[out] out_strs Names of evaluation datasets, should pre-allocate memory\n  * \\return 0 when succeed, -1 when failure happens\n  */\n LIGHTGBM_C_EXPORT int LGBM_BoosterGetEvalNames(BoosterHandle handle,\n+                                               const int len,\n                                                int* out_len,\n+                                               const size_t buffer_len,\n+                                               size_t* out_buffer_len,\n                                                char** out_strs);\n \n /*!\n  * \\brief Get names of features.\n  * \\param handle Handle of booster\n+ * \\param len Number of ``char*`` pointers stored at ``out_strs``.\n+ *            If smaller than the max size, only this many strings are copied\n  * \\param[out] out_len Total number of features\n+ * \\param buffer_len Size of pre-allocated strings.\n+ *                   Content is copied up to ``buffer_len - 1`` and null-terminated\n+ * \\param[out] out_buffer_len String sizes required to do the full string copies\n  * \\param[out] out_strs Names of features, should pre-allocate memory\n  * \\return 0 when succeed, -1 when failure happens\n  */\n LIGHTGBM_C_EXPORT int LGBM_BoosterGetFeatureNames(BoosterHandle handle,\n+                                                  const int len,\n                                                   int* out_len,\n+                                                  const size_t buffer_len,\n+                                                  size_t* out_buffer_len,\n                                                   char** out_strs);\n \n /*!\ndiff --git a/python-package/lightgbm/basic.py b/python-package/lightgbm/basic.py\nindex 6fcb37ff3c89..cd3288126474 100644\n--- a/python-package/lightgbm/basic.py\n+++ b/python-package/lightgbm/basic.py\n@@ -2711,14 +2711,24 @@ def feature_name(self):\n         num_feature = self.num_feature()\n         # Get name of features\n         tmp_out_len = ctypes.c_int(0)\n-        string_buffers = [ctypes.create_string_buffer(255) for i in range_(num_feature)]\n+        reserved_string_buffer_size = 255\n+        required_string_buffer_size = ctypes.c_size_t(0)\n+        string_buffers = [ctypes.create_string_buffer(reserved_string_buffer_size) for i in range_(num_feature)]\n         ptr_string_buffers = (ctypes.c_char_p * num_feature)(*map(ctypes.addressof, string_buffers))\n         _safe_call(_LIB.LGBM_BoosterGetFeatureNames(\n             self.handle,\n+            num_feature,\n             ctypes.byref(tmp_out_len),\n+            reserved_string_buffer_size,\n+            ctypes.byref(required_string_buffer_size),\n             ptr_string_buffers))\n         if num_feature != tmp_out_len.value:\n             raise ValueError(\"Length of feature names doesn't equal with num_feature\")\n+        if reserved_string_buffer_size < required_string_buffer_size.value:\n+            raise BufferError(\n+                \"Allocated feature name buffer size ({}) was inferior to the needed size ({}).\"\n+                .format(reserved_string_buffer_size, required_string_buffer_size.value)\n+            )\n         return [string_buffers[i].value.decode() for i in range_(num_feature)]\n \n     def feature_importance(self, importance_type='split', iteration=None):\n@@ -2898,14 +2908,26 @@ def __get_eval_info(self):\n             if self.__num_inner_eval > 0:\n                 # Get name of evals\n                 tmp_out_len = ctypes.c_int(0)\n-                string_buffers = [ctypes.create_string_buffer(255) for i in range_(self.__num_inner_eval)]\n+                reserved_string_buffer_size = 255\n+                required_string_buffer_size = ctypes.c_size_t(0)\n+                string_buffers = [\n+                    ctypes.create_string_buffer(reserved_string_buffer_size) for i in range_(self.__num_inner_eval)\n+                ]\n                 ptr_string_buffers = (ctypes.c_char_p * self.__num_inner_eval)(*map(ctypes.addressof, string_buffers))\n                 _safe_call(_LIB.LGBM_BoosterGetEvalNames(\n                     self.handle,\n+                    self.__num_inner_eval,\n                     ctypes.byref(tmp_out_len),\n+                    reserved_string_buffer_size,\n+                    ctypes.byref(required_string_buffer_size),\n                     ptr_string_buffers))\n                 if self.__num_inner_eval != tmp_out_len.value:\n                     raise ValueError(\"Length of eval names doesn't equal with num_evals\")\n+                if reserved_string_buffer_size < required_string_buffer_size.value:\n+                    raise BufferError(\n+                        \"Allocated eval name buffer size ({}) was inferior to the needed size ({}).\"\n+                        .format(reserved_string_buffer_size, required_string_buffer_size.value)\n+                    )\n                 self.__name_inner_eval = \\\n                     [string_buffers[i].value.decode() for i in range_(self.__num_inner_eval)]\n                 self.__higher_better_inner_eval = \\\ndiff --git a/src/c_api.cpp b/src/c_api.cpp\nindex 224c74d6c730..22d53937e337 100644\n--- a/src/c_api.cpp\n+++ b/src/c_api.cpp\n@@ -501,21 +501,31 @@ class Booster {\n     return ret;\n   }\n \n-  int GetEvalNames(char** out_strs) const {\n+  int GetEvalNames(char** out_strs, const int len, const size_t buffer_len, size_t *out_buffer_len) const {\n+    *out_buffer_len = 0;\n     int idx = 0;\n     for (const auto& metric : train_metric_) {\n       for (const auto& name : metric->GetName()) {\n-        std::memcpy(out_strs[idx], name.c_str(), name.size() + 1);\n+        if (idx < len) {\n+          std::memcpy(out_strs[idx], name.c_str(), std::min(name.size() + 1, buffer_len));\n+          out_strs[idx][buffer_len - 1] = '\\0';\n+        }\n+        *out_buffer_len = std::max(name.size() + 1, *out_buffer_len);\n         ++idx;\n       }\n     }\n     return idx;\n   }\n \n-  int GetFeatureNames(char** out_strs) const {\n+  int GetFeatureNames(char** out_strs, const int len, const size_t buffer_len, size_t *out_buffer_len) const {\n+    *out_buffer_len = 0;\n     int idx = 0;\n     for (const auto& name : boosting_->FeatureNames()) {\n-      std::memcpy(out_strs[idx], name.c_str(), name.size() + 1);\n+      if (idx < len) {\n+        std::memcpy(out_strs[idx], name.c_str(), std::min(name.size() + 1, buffer_len));\n+        out_strs[idx][buffer_len - 1] = '\\0';\n+      }\n+      *out_buffer_len = std::max(name.size() + 1, *out_buffer_len);\n       ++idx;\n     }\n     return idx;\n@@ -1356,17 +1366,27 @@ int LGBM_BoosterGetEvalCounts(BoosterHandle handle, int* out_len) {\n   API_END();\n }\n \n-int LGBM_BoosterGetEvalNames(BoosterHandle handle, int* out_len, char** out_strs) {\n+int LGBM_BoosterGetEvalNames(BoosterHandle handle,\n+                             const int len,\n+                             int* out_len,\n+                             const size_t buffer_len,\n+                             size_t* out_buffer_len,\n+                             char** out_strs) {\n   API_BEGIN();\n   Booster* ref_booster = reinterpret_cast<Booster*>(handle);\n-  *out_len = ref_booster->GetEvalNames(out_strs);\n+  *out_len = ref_booster->GetEvalNames(out_strs, len, buffer_len, out_buffer_len);\n   API_END();\n }\n \n-int LGBM_BoosterGetFeatureNames(BoosterHandle handle, int* out_len, char** out_strs) {\n+int LGBM_BoosterGetFeatureNames(BoosterHandle handle,\n+                                const int len,\n+                                int* out_len,\n+                                const size_t buffer_len,\n+                                size_t* out_buffer_len,\n+                                char** out_strs) {\n   API_BEGIN();\n   Booster* ref_booster = reinterpret_cast<Booster*>(handle);\n-  *out_len = ref_booster->GetFeatureNames(out_strs);\n+  *out_len = ref_booster->GetFeatureNames(out_strs, len, buffer_len, out_buffer_len);\n   API_END();\n }\n \ndiff --git a/src/lightgbm_R.cpp b/src/lightgbm_R.cpp\nindex 4ba70a5f1c22..9cb7a62d6947 100644\n--- a/src/lightgbm_R.cpp\n+++ b/src/lightgbm_R.cpp\n@@ -449,15 +449,25 @@ LGBM_SE LGBM_BoosterGetEvalNames_R(LGBM_SE handle,\n   R_API_BEGIN();\n   int len;\n   CHECK_CALL(LGBM_BoosterGetEvalCounts(R_GET_PTR(handle), &len));\n+\n+  const size_t reserved_string_size = 128;\n   std::vector<std::vector<char>> names(len);\n   std::vector<char*> ptr_names(len);\n   for (int i = 0; i < len; ++i) {\n-    names[i].resize(128);\n+    names[i].resize(reserved_string_size);\n     ptr_names[i] = names[i].data();\n   }\n+\n   int out_len;\n-  CHECK_CALL(LGBM_BoosterGetEvalNames(R_GET_PTR(handle), &out_len, ptr_names.data()));\n+  size_t required_string_size;\n+  CHECK_CALL(\n+    LGBM_BoosterGetEvalNames(\n+      R_GET_PTR(handle),\n+      len, &out_len,\n+      reserved_string_size, &required_string_size,\n+      ptr_names.data()));\n   CHECK_EQ(out_len, len);\n+  CHECK_GE(reserved_string_size, required_string_size);\n   auto merge_names = Common::Join<char*>(ptr_names, \"\\t\");\n   EncodeChar(eval_names, merge_names.c_str(), buf_len, actual_len, merge_names.size() + 1);\n   R_API_END();\ndiff --git a/swig/StringArray.hpp b/swig/StringArray.hpp\nnew file mode 100644\nindex 000000000000..4fef62a125e2\n--- /dev/null\n+++ b/swig/StringArray.hpp\n@@ -0,0 +1,150 @@\n+/*!\n+ * Copyright (c) 2020 Microsoft Corporation. All rights reserved.\n+ * Licensed under the MIT License. See LICENSE file in the project root for license information.\n+ */\n+#ifndef __STRING_ARRAY_H__\n+#define __STRING_ARRAY_H__\n+\n+#include <new>\n+#include <vector>\n+#include <algorithm>\n+\n+/**\n+ * Container that manages an array of fixed-length strings.\n+ *\n+ * To be compatible with SWIG's `various.i` extension module,\n+ * the array of pointers to char* must be NULL-terminated:\n+ *   [char*, char*, char*, ..., NULL]\n+ * This implies that the length of this array is bigger\n+ * by 1 element than the number of char* it stores.\n+ * I.e., _num_elements == _array.size()-1\n+ *\n+ * The class also takes care of allocation of the underlying\n+ * char* memory.\n+ */\n+class StringArray\n+{\n+  public:\n+    StringArray(size_t num_elements, size_t string_size)\n+      : _string_size(string_size),\n+        _array(num_elements + 1, nullptr)\n+    {\n+        _allocate_strings(num_elements, string_size);\n+    }\n+\n+    ~StringArray()\n+    {\n+        _release_strings();\n+    }\n+\n+    /**\n+     * Returns the pointer to the raw array.\n+     * Notice its size is greater than the number of stored strings by 1.\n+     *\n+     * @return char** pointer to raw data (null-terminated).\n+     */\n+    char **data() noexcept\n+    {\n+        return _array.data();\n+    }\n+\n+    /**\n+     * Return char* from the array of size _string_size+1.\n+     * Notice the last element in _array is already\n+     * considered out of bounds.\n+     *\n+     * @param index Index of the element to retrieve.\n+     * @return pointer or nullptr if index is out of bounds.\n+     */\n+    char *getitem(size_t index) noexcept\n+    {\n+        if (_in_bounds(index))\n+            return _array[index];\n+        else\n+            return nullptr;\n+    }\n+\n+    /**\n+     * Safely copies the full content data\n+     * into one of the strings in the array.\n+     * If that is not possible, returns error (-1).\n+     *\n+     * @param index index of the string in the array.\n+     * @param content content to store\n+     *\n+     * @return In case index results in out of bounds access,\n+     * or content + 1 (null-terminator byte) doesn't fit\n+     * into the target string (_string_size), it errors out\n+     * and returns -1.\n+     */\n+    int setitem(size_t index, std::string content) noexcept\n+    {\n+        if (_in_bounds(index) && content.size() < _string_size)\n+        {\n+            std::strcpy(_array[index], content.c_str());\n+            return 0;\n+        } else {\n+            return -1;\n+        }\n+    }\n+\n+    /**\n+     * @return number of stored strings.\n+     */\n+    size_t get_num_elements() noexcept\n+    {\n+        return _array.size() - 1;\n+    }\n+\n+  private:\n+\n+    /**\n+     * Returns true if and only if within bounds.\n+     * Notice that it excludes the last element of _array (NULL).\n+     *\n+     * @param index index of the element\n+     * @return bool true if within bounds\n+     */\n+    bool _in_bounds(size_t index) noexcept\n+    {\n+        return index < get_num_elements();\n+    }\n+\n+    /**\n+     * Allocate an array of fixed-length strings.\n+     *\n+     * Since a NULL-terminated array is required by SWIG's `various.i`,\n+     * the size of the array is actually `num_elements + 1` but only\n+     * num_elements are filled.\n+     *\n+     * @param num_elements Number of strings to store in the array.\n+     * @param string_size The size of each string in the array.\n+     */\n+    void _allocate_strings(int num_elements, int string_size)\n+    {\n+        for (int i = 0; i < num_elements; ++i)\n+        {\n+            // Leave space for \\0 terminator:\n+            _array[i] = new (std::nothrow) char[string_size + 1];\n+\n+            // Check memory allocation:\n+            if (! _array[i]) {\n+                _release_strings();\n+                throw std::bad_alloc();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Deletes the allocated strings.\n+     */\n+    void _release_strings() noexcept\n+    {\n+        std::for_each(_array.begin(), _array.end(), [](char* c) { delete[] c; });\n+    }\n+\n+    const size_t _string_size;\n+    std::vector<char*> _array;\n+};\n+\n+#endif // __STRING_ARRAY_H__\ndiff --git a/swig/StringArray.i b/swig/StringArray.i\nnew file mode 100644\nindex 000000000000..12f1a5d2b21c\n--- /dev/null\n+++ b/swig/StringArray.i\n@@ -0,0 +1,95 @@\n+/*!\n+ * Copyright (c) 2020 Microsoft Corporation. All rights reserved.\n+ * Licensed under the MIT License. See LICENSE file in the project root for license information.\n+ */\n+/**\n+ * This wraps the StringArray.hpp class for SWIG usage,\n+ * adding the basic C-style wrappers needed to make it \n+ * usable for the users of the low-level lightgbmJNI API.\n+ */\n+\n+%{\n+#include \"../swig/StringArray.hpp\"\n+%}\n+\n+// Use SWIG's `various.i` to get a String[] directly in one call:\n+%apply char **STRING_ARRAY {char **StringArrayHandle_get_strings};\n+\n+%inline %{\n+\n+    typedef void* StringArrayHandle;\n+\n+    /**\n+     * @brief Creates a new StringArray and returns its handle.\n+     * \n+     * @param num_strings number of strings to store.\n+     * @param string_size the maximum number of characters that can be stored in each string.\n+     * @return StringArrayHandle or nullptr in case of allocation failure.\n+     */\n+    StringArrayHandle StringArrayHandle_create(size_t num_strings, size_t string_size) {\n+        try {\n+            return new StringArray(num_strings, string_size);\n+        } catch (std::bad_alloc &e) {\n+            return nullptr;\n+        }\n+    }\n+\n+    /**\n+     * @brief Free the StringArray object.\n+     * \n+     * @param handle StringArray handle.\n+     */\n+    void StringArrayHandle_free(StringArrayHandle handle)\n+    {\n+        delete reinterpret_cast<StringArray *>(handle);\n+    }\n+\n+    /**\n+     * @brief Return the raw pointer to the array of strings.\n+     * Wrapped in Java into String[] automatically.\n+     * \n+     * @param handle StringArray handle.\n+     * @return Raw pointer to the string array which `various.i` maps to String[].\n+     */\n+    char **StringArrayHandle_get_strings(StringArrayHandle handle)\n+    {\n+        return reinterpret_cast<StringArray *>(handle)->data();\n+    }\n+\n+    /**\n+     * For the end user to extract a specific string from the StringArray object.\n+     * \n+     * @param handle StringArray handle.\n+     * @param index index of the string to retrieve from the array.\n+     * @return raw pointer to string at index, or nullptr if out of bounds.\n+     */\n+    char *StringArrayHandle_get_string(StringArrayHandle handle, int index)\n+    {\n+        return reinterpret_cast<StringArray *>(handle)->getitem(index);\n+    }\n+\n+    /**\n+     * @brief Replaces one string of the array at index with the new content.\n+     * \n+     * @param handle StringArray handle.\n+     * @param index Index of the string to replace\n+     * @param new_content The content to replace\n+     * @return 0 (success) or -1 (error) in case of out of bounds index or too large content.\n+     */\n+    int StringArrayHandle_set_string(StringArrayHandle handle, size_t index, const char* new_content)\n+    {\n+        return reinterpret_cast<StringArray *>(handle)->setitem(index, std::string(new_content));\n+    }\n+\n+    /**\n+     * @brief Retrieve the number of strings in the StringArray.\n+     * \n+     * @param handle StringArray handle.\n+     * @return number of strings that the array stores.\n+     */\n+    size_t StringArrayHandle_get_num_elements(StringArrayHandle handle)\n+    {\n+        return reinterpret_cast<StringArray *>(handle)->get_num_elements();\n+    }\n+\n+%}\ndiff --git a/swig/StringArray_API_extensions.i b/swig/StringArray_API_extensions.i\nnew file mode 100644\nindex 000000000000..b44f8f263793\n--- /dev/null\n+++ b/swig/StringArray_API_extensions.i\n@@ -0,0 +1,107 @@\n+/*!\n+ * Copyright (c) 2020 Microsoft Corporation. All rights reserved.\n+ * Licensed under the MIT License. See LICENSE file in the project root for license information.\n+ */\n+/**\n+ * This SWIG interface extension provides support to\n+ * allocate, return and manage arrays of strings through\n+ * the class StringArray.\n+ *\n+ * This is then used to generate wrappers that return newly-allocated\n+ * arrays of strings, so the user can them access them easily as a String[]\n+ * on the Java side by a single call to StringArray::data(), and even manipulate\n+ * them.\n+ *\n+ * It also implements working wrappers to:\n+ *  - LGBM_BoosterGetEvalNames    (re-implemented with new API)\n+ *  - LGBM_BoosterGetFeatureNames (original non-wrapped version didn't work).\n+ * where the wrappers names end with \"SWIG\".\n+ */\n+\n+\n+#include <memory>\n+\n+%include \"./StringArray.i\"\n+\n+%inline %{\n+\n+    #define API_OK_OR_VALUE(api_return, return_value) if (api_return == -1) return return_value\n+    #define API_OK_OR_NULL(api_return) API_OK_OR_VALUE(api_return, nullptr)\n+\n+    /**\n+     * @brief Wraps LGBM_BoosterGetEvalNames.\n+     *\n+     * In case of success a new StringArray is created and returned,\n+     * which you're responsible for freeing,\n+     * @see StringArrayHandle_free().\n+     * In case of failure such resource is freed and nullptr is returned.\n+     * Check for that case with null (lightgbmlib) or 0 (lightgbmlibJNI).\n+     *\n+     * @param handle Booster handle\n+     * @return StringArrayHandle with the eval names (or nullptr in case of error)\n+     */\n+    StringArrayHandle LGBM_BoosterGetEvalNamesSWIG(BoosterHandle handle)\n+    {\n+        int eval_counts;\n+        size_t string_size;\n+        std::unique_ptr<StringArray> strings(nullptr);\n+\n+        // Retrieve required allocation space:\n+        API_OK_OR_NULL(LGBM_BoosterGetEvalNames(handle,\n+                                                0, &eval_counts,\n+                                                0, &string_size,\n+                                                strings->data()));\n+\n+        try {\n+            strings.reset(new StringArray(eval_counts, string_size));\n+        } catch (std::bad_alloc &e) {\n+            LGBM_SetLastError(\"Failure to allocate memory.\");\n+            return nullptr;\n+        }\n+\n+        API_OK_OR_NULL(LGBM_BoosterGetEvalNames(handle,\n+                                                eval_counts, &eval_counts,\n+                                                string_size, &string_size,\n+                                                strings->data()));\n+\n+        return strings.release();\n+    }\n+\n+    /**\n+     * @brief Wraps LGBM_BoosterGetFeatureNames.\n+     *\n+     * Allocates a new StringArray. You must free it yourself if it succeeds.\n+     * @see StringArrayHandle_free().\n+     * In case of failure such resource is freed and nullptr is returned.\n+     * Check for that case with null (lightgbmlib) or 0 (lightgbmlibJNI).\n+     *\n+     * @param handle Booster handle\n+     * @return StringArrayHandle with the feature names (or nullptr in case of error)\n+     */\n+    StringArrayHandle LGBM_BoosterGetFeatureNamesSWIG(BoosterHandle handle)\n+    {\n+        int num_features;\n+        size_t max_feature_name_size;\n+        std::unique_ptr<StringArray> strings(nullptr);\n+\n+        // Retrieve required allocation space:\n+        API_OK_OR_NULL(LGBM_BoosterGetFeatureNames(handle,\n+                                                   0, &num_features,\n+                                                   0, &max_feature_name_size,\n+                                                   nullptr));\n+\n+        try {\n+            strings.reset(new StringArray(num_features, max_feature_name_size));\n+        } catch (std::bad_alloc &e) {\n+            LGBM_SetLastError(\"Failure to allocate memory.\");\n+            return nullptr;\n+        }\n+\n+        API_OK_OR_NULL(LGBM_BoosterGetFeatureNames(handle,\n+                                                   num_features, &num_features,\n+                                                   max_feature_name_size, &max_feature_name_size,\n+                                                   strings->data()));\n+\n+        return strings.release();\n+    }\n+%}\ndiff --git a/swig/lightgbmlib.i b/swig/lightgbmlib.i\nindex 34468dd805d1..5fba17e12adf 100644\n--- a/swig/lightgbmlib.i\n+++ b/swig/lightgbmlib.i\n@@ -6,6 +6,7 @@\n %module lightgbmlib\n %ignore LGBM_BoosterSaveModelToString;\n %ignore LGBM_BoosterGetEvalNames;\n+%ignore LGBM_BoosterGetFeatureNames;\n %{\n /* Includes the header in the wrapper code */\n #include \"../include/LightGBM/export.h\"\n@@ -73,19 +74,6 @@\n     return dst;\n   }\n \n-  char ** LGBM_BoosterGetEvalNamesSWIG(BoosterHandle handle,\n-                                       int eval_counts) {\n-    char** dst = new char*[eval_counts];\n-    for (int i = 0; i < eval_counts; ++i) {\n-      dst[i] = new char[128];\n-    }\n-    int result = LGBM_BoosterGetEvalNames(handle, &eval_counts, dst);\n-    if (result != 0) {\n-      return nullptr;\n-    }\n-    return dst;\n-  }\n-\n   int LGBM_BoosterPredictForMatSingle(JNIEnv *jenv,\n                                       jdoubleArray data,\n                                       BoosterHandle handle,\n@@ -249,10 +237,6 @@\n %array_functions(float, floatArray)\n %array_functions(int, intArray)\n %array_functions(long, longArray)\n-/* Note: there is a bug in the SWIG generated string arrays when creating\n-   a new array with strings where the strings are prematurely deallocated\n-*/\n-%array_functions(char *, stringArray)\n \n /* Custom pointer manipulation template */\n %define %pointer_manipulation(TYPE, NAME)\n@@ -301,3 +285,5 @@ TYPE *NAME##_handle();\n \n /* Allow retrieving handle to void** */\n %pointer_handle(void*, voidpp)\n+\n+%include \"StringArray_API_extensions.i\"\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Remove duplicated `StringArray.hpp` from `char_array_helpers.i`. Place it in a separate file, possibly within `src` + `include`, or simplify this to a separate `.i` file. Adjust CMake to include the new paths.\n\n2. Rename `char_array_helpers.i` to `StringArray_api_extensions.i` for clarity.\n\n3. Address the issue with `Lgbm_SetLastError` returning the default error message; ensure it's called on the same thread.\n\n4. Refactor `LGBM_BoosterGetEvalNamesSWIG` to prevent buffer overflow by implementing a `buffer_len` check as suggested. This allows the caller to reallocate if necessary.\n\n5. Investigate and resolve the segmentation fault occurring with `LGBM_BoosterGetEvalNamesSWIG`. Debug the new Scala code, focusing on the transition between Java and the C API.\n\n6. Rebase to master and squash all commits prior to merging."
      }
    ],
    "codediff_length": 23477
  },
  {
    "index": 21,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/cpp/CMakeLists.txt b/cpp/CMakeLists.txt\nindex fe8f6aa839..1e306ad593 100644\n--- a/cpp/CMakeLists.txt\n+++ b/cpp/CMakeLists.txt\n@@ -86,6 +86,8 @@ option (\"USE_LITE_METADATA\" \"Use lite metadata\" \"OFF\")\n option (\"USE_RE2\" \"Use RE2\" \"OFF\")\n option (\"USE_STD_MAP\" \"Force the use of std::map\" \"OFF\")\n option (\"BUILD_STATIC_LIB\" \"Build static libraries\" \"ON\")\n+option (\"USE_STDMUTEX\" \"Use C++ 2011 std::mutex for multi-threading\" \"OFF\")\n+option (\"USE_POSIX_THREAD\" \"Use Posix api for multi-threading\" \"OFF\")\n \n if (${USE_ALTERNATE_FORMATS} STREQUAL \"ON\")\n   add_definitions (\"-DI18N_PHONENUMBERS_USE_ALTERNATE_FORMATS\")\n@@ -104,6 +106,19 @@ if (${USE_BOOST} STREQUAL \"ON\")\n   include_directories (${Boost_INCLUDE_DIRS})\n endif ()\n \n+if (${USE_STDMUTEX} STREQUAL \"ON\")\n+  add_definitions (\"-DI18N_PHONENUMBERS_USE_STDMUTEX\")\n+endif ()\n+\n+if (${USE_POSIX_THREAD} STREQUAL \"ON\")\n+  add_definitions (\"-DI18N_PHONENUMBERS_HAVE_POSIX_THREAD\")\n+  find_package (Threads REQUIRED)\n+endif ()\n+\n+if (${USE_BOOST} STREQUAL \"OFF\" AND ${USE_STDMUTEX} STREQUAL \"OFF\")\n+  find_package (Threads)\n+endif()\n+\n find_or_build_gtest ()\n \n if (${USE_RE2} STREQUAL \"ON\")\n@@ -423,6 +438,15 @@ if (${USE_RE2} STREQUAL \"ON\")\n   list (APPEND LIBRARY_DEPS ${RE2_LIB})\n endif ()\n \n+if (${USE_POSIX_THREAD} STREQUAL \"ON\" OR ((APPLE OR UNIX) AND ${USE_BOOST} STREQUAL \"OFF\" AND ${USE_STDMUTEX} STREQUAL \"OFF\"))\n+  if(CMAKE_USE_PTHREADS_INIT)\n+    list (APPEND CMAKE_C_FLAGS \"-pthread\")\n+  endif()\n+  if(CMAKE_THREAD_LIBS_INIT)\n+    list (APPEND LIBRARY_DEPS ${CMAKE_THREAD_LIBS_INIT})\n+  endif()\n+endif ()\n+\n if (APPLE)\n   list (APPEND COMMON_DEPS ${COREFOUNDATION_LIB} ${FOUNDATION_LIB})\n endif ()\n@@ -579,13 +603,22 @@ install (\n install (FILES\n   \"src/phonenumbers/base/memory/scoped_ptr.h\"\n   \"src/phonenumbers/base/memory/singleton.h\"\n+  \"src/phonenumbers/base/memory/singleton_boost.h\"\n   \"src/phonenumbers/base/memory/singleton_posix.h\"\n+  \"src/phonenumbers/base/memory/singleton_stdmutex.h\"\n+  \"src/phonenumbers/base/memory/singleton_unsafe.h\"\n+  \"src/phonenumbers/base/memory/singleton_win32.h\"\n   DESTINATION include/phonenumbers/base/memory/\n )\n \n-install (FILES \"src/phonenumbers/base/synchronization/lock.h\"\n-         \"src/phonenumbers/base/synchronization/lock_posix.h\"\n-         DESTINATION include/phonenumbers/base/synchronization/)\n+install (FILES\n+  \"src/phonenumbers/base/synchronization/lock.h\"\n+  \"src/phonenumbers/base/synchronization/lock_boost.h\"\n+  \"src/phonenumbers/base/synchronization/lock_posix.h\"\n+  \"src/phonenumbers/base/synchronization/lock_stdmutex.h\"\n+  \"src/phonenumbers/base/synchronization/lock_unsafe.h\"\n+  \"src/phonenumbers/base/synchronization/lock_win32.h\"\n+  DESTINATION include/phonenumbers/base/synchronization/)\n \n set (LIBDIR ${CMAKE_INSTALL_LIBDIR})\n \ndiff --git a/cpp/README b/cpp/README\nindex 52f932d171..ac94bbcd57 100644\n--- a/cpp/README\n+++ b/cpp/README\n@@ -117,11 +117,17 @@ Requirements:\n     $ cd icu/source\n     $ ./configure && make && sudo make install\n \n-  - Boost\n-    Version 1.40 or more recent is required if you need libphonenumber to be\n-    thread-safe. If you access libphonenumber from a single thread, you can\n-    avoid the Boost dependency by disabling the USE_BOOST CMake option (see\n-    Troubleshooting section below for information about ccmake).\n+  - A thread synchronization solution or more recent is required if you need\n+    libphonenumber to be thread-safe. Supported solution are:\n+\t- Boost Version 1.40 or more recent\n+\t- Posix Thread. Linux or Apple (ios/mac) detection is automatic. On other\n+        Posix environnement, uses -DUSE_POSIX_THREAD = ON\n+    - C++ 2011 (and later) std::mutex. Uses -DUSE_STDMUTEX = ON to enable\n+        automatic C++ 2011 detection (if you prefer Posix or Win32 solution).\n+    - Windows Win32 synchronization API.\t\t\n+\n+\tIf you access libphonenumber from a single thread, you don't need one of\n+    these solution.\n \n     You can install it very easily on a Debian-based GNU/Linux distribution:\n     $ sudo apt-get install libboost-dev libboost-thread-dev libboost-system-dev\n@@ -350,10 +356,12 @@ Supported build parameters\n                                             multi-threaded environments that\n                                             are not Linux and Mac.\n                                             Libphonenumber relies on Boost for\n-                                            non-POSIX (e.g. Windows)\n+                                            non-POSIX, non-Windows and non-C++ 2011\n                                             multi-threading.\n   USE_ICU_REGEXP        = ON | OFF [ON]  -- Use ICU regexp engine.\n   USE_LITE_METADATA     = ON | OFF [OFF] -- Generates smaller metadata that\n                                             doesn't include example numbers.\n+  USE_POSIX_THREAD      = ON | OFF [OFF] -- Use Posix thread for multi-threading.\n   USE_RE2               = ON | OFF [OFF] -- Use RE2.\n   USE_STD_MAP           = ON | OFF [OFF] -- Force the use of std::map.\n+  USE_STDMUTEX          = ON | OFF [OFF] -- Detect and use C++2011 for multi-threading.\ndiff --git a/cpp/src/phonenumbers/asyoutypeformatter.cc b/cpp/src/phonenumbers/asyoutypeformatter.cc\nindex f12e18e686..d55ead6b97 100644\n--- a/cpp/src/phonenumbers/asyoutypeformatter.cc\n+++ b/cpp/src/phonenumbers/asyoutypeformatter.cc\n@@ -211,9 +211,11 @@ void AsYouTypeFormatter::NarrowDownPossibleFormats(\n       ++it;\n       continue;\n     }\n-    int last_leading_digits_pattern =\n-        std::min(index_of_leading_digits_pattern,\n-                 format.leading_digits_pattern_size() - 1);\n+    // We don't use std::min because there is stange symbol conflict\n+    // with including <windows.h> and protobuf symbols\n+    int last_leading_digits_pattern = format.leading_digits_pattern_size() - 1;\n+    if (last_leading_digits_pattern > index_of_leading_digits_pattern)\n+      last_leading_digits_pattern = index_of_leading_digits_pattern;\n     const scoped_ptr<RegExpInput> input(\n         regexp_factory_->CreateInput(leading_digits));\n     if (!regexp_cache_.GetRegExp(format.leading_digits_pattern().Get(\ndiff --git a/cpp/src/phonenumbers/base/memory/singleton.h b/cpp/src/phonenumbers/base/memory/singleton.h\nindex 5fd3e4c6e4..46b0620717 100644\n--- a/cpp/src/phonenumbers/base/memory/singleton.h\n+++ b/cpp/src/phonenumbers/base/memory/singleton.h\n@@ -18,78 +18,16 @@\n #define I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_H_\n \n #if defined(I18N_PHONENUMBERS_USE_BOOST)\n-\n-#include <boost/scoped_ptr.hpp>\n-#include <boost/thread/once.hpp>\n-#include <boost/utility.hpp>\n-\n-namespace i18n {\n-namespace phonenumbers {\n-\n-template <class T>\n-class Singleton : private boost::noncopyable {\n- public:\n-  virtual ~Singleton() {}\n-\n-  static T* GetInstance() {\n-    boost::call_once(Init, flag);\n-    return instance.get();\n-  }\n-\n- private:\n-  static void Init() {\n-    instance.reset(new T());\n-  }\n-\n-  static boost::scoped_ptr<T> instance;\n-  static boost::once_flag flag;\n-};\n-\n-template <class T> boost::scoped_ptr<T> Singleton<T>::instance;\n-template <class T> boost::once_flag Singleton<T>::flag = BOOST_ONCE_INIT;\n-\n-}  // namespace phonenumbers\n-}  // namespace i18n\n-\n-#else  // !I18N_PHONENUMBERS_USE_BOOST\n-\n-#include \"phonenumbers/base/logging.h\"\n-#include \"phonenumbers/base/thread_checker.h\"\n-\n-#if !defined(__linux__) && !defined(__APPLE__)\n-\n-namespace i18n {\n-namespace phonenumbers {\n-\n-// Note that this implementation is not thread-safe. For a thread-safe\n-// implementation on non-POSIX platforms, please compile with\n-// -DI18N_PHONENUMBERS_USE_BOOST.\n-template <class T>\n-class Singleton {\n- public:\n-  Singleton() : thread_checker_() {}\n-\n-  virtual ~Singleton() {}\n-\n-  static T* GetInstance() {\n-    static T* instance = NULL;\n-    if (!instance) {\n-      instance = new T();\n-    }\n-    DCHECK(instance->thread_checker_.CalledOnValidThread());\n-    return instance;\n-  }\n-\n- private:\n-  const ThreadChecker thread_checker_;\n-};\n-\n-}  // namespace phonenumbers\n-}  // namespace i18n\n-\n-#else\n+#include \"phonenumbers/base/memory/singleton_boost.h\"\n+#elif (__cplusplus >= 201103L) && defined(I18N_PHONENUMBERS_USE_STDMUTEX)\n+// C++11 Lock implementation based on std::mutex.\n+#include \"phonenumbers/base/memory/singleton_stdmutex.h\"\n+#elif defined(__linux__) || defined(__APPLE__) || defined(I18N_PHONENUMBERS_HAVE_POSIX_THREAD)\n #include \"phonenumbers/base/memory/singleton_posix.h\"\n-#endif  // !defined(__linux__) && !defined(__APPLE__)\n-\n+#elif defined(WIN32)\n+#include \"phonenumbers/base/memory/singleton_win32.h\"\n+#else\n+#include \"phonenumbers/base/memory/singleton_unsafe.h\"\n #endif  // !I18N_PHONENUMBERS_USE_BOOST\n+\n #endif  // I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_H_\ndiff --git a/cpp/src/phonenumbers/base/memory/singleton_boost.h b/cpp/src/phonenumbers/base/memory/singleton_boost.h\nnew file mode 100644\nindex 0000000000..a945e437d9\n--- /dev/null\n+++ b/cpp/src/phonenumbers/base/memory/singleton_boost.h\n@@ -0,0 +1,51 @@\n+// Copyright (C) 2020 The Libphonenumber Authors\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+#ifndef I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_BOOST_H_\n+#define I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_BOOST_H_\n+\n+#include <boost/scoped_ptr.hpp>\n+#include <boost/thread/once.hpp>\n+#include <boost/utility.hpp>\n+\n+namespace i18n {\n+namespace phonenumbers {\n+\n+template <class T>\n+class Singleton : private boost::noncopyable {\n+ public:\n+  Singleton() {}\n+  virtual ~Singleton() {}\n+\n+  static T* GetInstance() {\n+    boost::call_once(Init, flag_);\n+    return instance_.get();\n+  }\n+\n+ private:\n+  static void Init() {\n+    instance_.reset(new T());\n+  }\n+\n+  static boost::scoped_ptr<T> instance_;\n+  static boost::once_flag flag_;\n+};\n+\n+template <class T> boost::scoped_ptr<T> Singleton<T>::instance_;\n+template <class T> boost::once_flag Singleton<T>::flag_ = BOOST_ONCE_INIT;\n+\n+}  // namespace phonenumbers\n+}  // namespace i18n\n+\n+#endif  // I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_BOOST_H_\ndiff --git a/cpp/src/phonenumbers/base/memory/singleton_stdmutex.h b/cpp/src/phonenumbers/base/memory/singleton_stdmutex.h\nnew file mode 100644\nindex 0000000000..ce7fd45a61\n--- /dev/null\n+++ b/cpp/src/phonenumbers/base/memory/singleton_stdmutex.h\n@@ -0,0 +1,62 @@\n+// Copyright (C) 2020 The Libphonenumber Authors\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+#ifndef I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_STDMUTEX_H_\n+#define I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_STDMUTEX_H_\n+\n+#include <mutex>\n+\n+#include \"phonenumbers/base/basictypes.h\"\n+\n+namespace i18n {\n+namespace phonenumbers {\n+\n+template <class T>\n+class Singleton {\n+ public:\n+  Singleton() {}\n+  virtual ~Singleton() {}\n+\n+  static T* GetInstance() {\n+    if (once_init_) {\n+      singleton_mutex_.lock();\n+      if (once_init_) {\n+        Init();\n+        once_init_ = false;\n+      }\n+      singleton_mutex_.unlock();\n+    }\n+    return instance_;\n+  }\n+\n+ private:\n+  DISALLOW_COPY_AND_ASSIGN(Singleton);\n+\n+  static void Init() {\n+    instance_ = new T();\n+  }\n+\n+  static T* instance_;  // Leaky singleton.\n+  static std::mutex singleton_mutex_;\n+  static bool once_init_;\n+};\n+\n+template <class T> T* Singleton<T>::instance_;\n+template <class T> std::mutex Singleton<T>::singleton_mutex_;\n+template <class T> bool Singleton<T>::once_init_ = true;\n+\n+}  // namespace phonenumbers\n+}  // namespace i18n\n+\n+#endif  // I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_STDMUTEX_H_\ndiff --git a/cpp/src/phonenumbers/base/memory/singleton_unsafe.h b/cpp/src/phonenumbers/base/memory/singleton_unsafe.h\nnew file mode 100644\nindex 0000000000..972149fe57\n--- /dev/null\n+++ b/cpp/src/phonenumbers/base/memory/singleton_unsafe.h\n@@ -0,0 +1,49 @@\n+// Copyright (C) 2013 The Libphonenumber Authors\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+#ifndef I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_UNSAFE_H_\n+#define I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_UNSAFE_H_\n+\n+#include \"phonenumbers/base/logging.h\"\n+#include \"phonenumbers/base/thread_checker.h\"\n+\n+namespace i18n {\n+namespace phonenumbers {\n+\n+// Note that this implementation is not thread-safe. For a thread-safe\n+// implementation on non-POSIX platforms, please compile with\n+// -DI18N_PHONENUMBERS_USE_BOOST.\n+template <class T>\n+class Singleton {\n+ public:\n+  Singleton() : thread_checker_() {}\n+  virtual ~Singleton() {}\n+\n+  static T* GetInstance() {\n+    static T* instance = NULL;\n+    if (!instance) {\n+      instance = new T();\n+    }\n+    DCHECK(instance->thread_checker_.CalledOnValidThread());\n+    return instance;\n+  }\n+\n+ private:\n+  const ThreadChecker thread_checker_;\n+};\n+\n+}  // namespace phonenumbers\n+}  // namespace i18n\n+\n+#endif  // I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_UNSAFE_H_\ndiff --git a/cpp/src/phonenumbers/base/memory/singleton_win32.h b/cpp/src/phonenumbers/base/memory/singleton_win32.h\nnew file mode 100644\nindex 0000000000..7da69e8a11\n--- /dev/null\n+++ b/cpp/src/phonenumbers/base/memory/singleton_win32.h\n@@ -0,0 +1,69 @@\n+// Copyright (C) 2020 The Libphonenumber Authors\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+#ifndef I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_WIN32_H_\n+#define I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_WIN32_H_\n+\n+#include <windows.h>\n+#include <synchapi.h>\n+\n+#include \"phonenumbers/base/basictypes.h\"\n+\n+namespace i18n {\n+namespace phonenumbers {\n+\n+template <class T>\n+class Singleton {\n+ public:\n+  Singleton() {}\n+  virtual ~Singleton() {}\n+\n+  static T* GetInstance() {\n+    if (once_init_) {\n+      EnterCriticalSection(&critical_section_);\n+      if (once_init_) {\n+        Init();\n+        once_init_ = false;\n+      }\n+      LeaveCriticalSection(&critical_section_);\n+    }\n+    return instance_;\n+  }\n+\n+ private:\n+  DISALLOW_COPY_AND_ASSIGN(Singleton);\n+\n+  static void Init() {\n+    instance_ = new T();\n+  }\n+\n+  static T* instance_;  // Leaky singleton.\n+  static CRITICAL_SECTION critical_section_;\n+  static bool once_init_;\n+};\n+\n+static bool perform_init_crit(CRITICAL_SECTION& cs)\n+{\n+  InitializeCriticalSection(&cs);\n+  return true;\n+}\n+\n+template <class T> T* Singleton<T>::instance_;\n+template <class T> CRITICAL_SECTION Singleton<T>::critical_section_;\n+template <class T> bool Singleton<T>::once_init_=perform_init_crit(Singleton<T>::critical_section_);\n+\n+}  // namespace phonenumbers\n+}  // namespace i18n\n+\n+#endif  // I18N_PHONENUMBERS_BASE_MEMORY_SINGLETON_WIN32_H_\ndiff --git a/cpp/src/phonenumbers/base/synchronization/lock.h b/cpp/src/phonenumbers/base/synchronization/lock.h\nindex 1893f1b3ca..a13f0db158 100644\n--- a/cpp/src/phonenumbers/base/synchronization/lock.h\n+++ b/cpp/src/phonenumbers/base/synchronization/lock.h\n@@ -18,81 +18,20 @@\n #define I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_H_\n \n #if defined(I18N_PHONENUMBERS_USE_BOOST)\n-#include <boost/thread/mutex.hpp>\n-\n-namespace i18n {\n-namespace phonenumbers {\n-\n-typedef boost::mutex Lock;\n-typedef boost::mutex::scoped_lock AutoLock;\n-\n-}  // namespace phonenumbers\n-}  // namespace i18n\n-\n-#else  // I18N_PHONENUMBERS_USE_BOOST\n-\n-#include \"phonenumbers/base/logging.h\"\n-#include \"phonenumbers/base/thread_checker.h\"\n-\n+#include \"phonenumbers/base/synchronization/lock_boost.h\"\n+#elif (__cplusplus >= 201103L) && defined(I18N_PHONENUMBERS_USE_STDMUTEX)\n // C++11 Lock implementation based on std::mutex.\n-#if  __cplusplus>=201103L\n-#include <mutex>\n-\n-namespace i18n {\n-namespace phonenumbers {\n-\n-class Lock {\n-public:\n-  Lock() = default;\n-\n-  void Acquire() const {\n-    mutex_.lock();\n-  }\n-\n-  void Release() const {\n-    mutex_.unlock();\n-  }\n-\n-private:\n-  mutable std::mutex mutex_;\n-};\n-\n-}  // namespace phonenumbers\n-}  // namespace i18n\n-\n-// Dummy lock implementation on non-POSIX platforms. If you are running on a\n-// different platform and care about thread-safety, please compile with\n-// -DI18N_PHONENUMBERS_USE_BOOST.\n-#elif !defined(__linux__) && !defined(__APPLE__)\n-\n-namespace i18n {\n-namespace phonenumbers {\n-\n-class Lock {\n- public:\n-  Lock() {}\n-\n-  void Acquire() const {\n-    DCHECK(thread_checker_.CalledOnValidThread());\n-    IGNORE_UNUSED(thread_checker_);\n-  }\n-\n-  void Release() const {\n-    DCHECK(thread_checker_.CalledOnValidThread());\n-    IGNORE_UNUSED(thread_checker_);\n-  }\n-\n- private:\n-  const ThreadChecker thread_checker_;\n-};\n-\n-}  // namespace phonenumbers\n-}  // namespace i18n\n-\n-#else\n+#include \"phonenumbers/base/synchronization/lock_stdmutex.h\"\n+#elif defined(__linux__) || defined(__APPLE__) || defined(I18N_PHONENUMBERS_HAVE_POSIX_THREAD)\n #include \"phonenumbers/base/synchronization/lock_posix.h\"\n+#elif defined(WIN32)\n+#include \"phonenumbers/base/synchronization/lock_win32.h\"\n+#else\n+#include \"phonenumbers/base/synchronization/lock_unsafe.h\"\n #endif\n \n+// lock_boost.h comes with its own AutoLock.\n+#if !defined(I18N_PHONENUMBERS_USE_BOOST)\n namespace i18n {\n namespace phonenumbers {\n \n@@ -112,6 +51,6 @@ class AutoLock {\n \n }  // namespace phonenumbers\n }  // namespace i18n\n+#endif  // !I18N_PHONENUMBERS_USE_BOOST\n \n-#endif  // I18N_PHONENUMBERS_USE_BOOST\n #endif  // I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_H_\ndiff --git a/cpp/src/phonenumbers/base/synchronization/lock_boost.h b/cpp/src/phonenumbers/base/synchronization/lock_boost.h\nnew file mode 100644\nindex 0000000000..c3798e9dfc\n--- /dev/null\n+++ b/cpp/src/phonenumbers/base/synchronization/lock_boost.h\n@@ -0,0 +1,31 @@\n+// Copyright (C) 2020 The Libphonenumber Authors\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+// Author: Philippe Liard\n+\n+#ifndef I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_BOOST_H_\n+#define I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_BOOST_H_\n+\n+#include <boost/thread/mutex.hpp>\n+\n+namespace i18n {\n+namespace phonenumbers {\n+\n+typedef boost::mutex Lock;\n+typedef boost::mutex::scoped_lock AutoLock;\n+\n+}  // namespace phonenumbers\n+}  // namespace i18n\n+\n+#endif  // I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_BOOST_H_\ndiff --git a/cpp/src/phonenumbers/base/synchronization/lock_stdmutex.h b/cpp/src/phonenumbers/base/synchronization/lock_stdmutex.h\nnew file mode 100644\nindex 0000000000..1514d7e52b\n--- /dev/null\n+++ b/cpp/src/phonenumbers/base/synchronization/lock_stdmutex.h\n@@ -0,0 +1,47 @@\n+// Copyright (C) 2020 The Libphonenumber Authors\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+// Author: Philippe Liard\n+\n+#ifndef I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_STDMUTEX_H_\n+#define I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_STDMUTEX_H_\n+\n+#include <mutex>\n+\n+#include \"phonenumbers/base/basictypes.h\"\n+\n+namespace i18n {\n+namespace phonenumbers {\n+\n+class Lock {\n+ public:\n+  Lock() = default;\n+\n+  void Acquire() const {\n+    mutex_.lock();\n+  }\n+\n+  void Release() const {\n+    mutex_.unlock();\n+  }\n+\n+ private:\n+  DISALLOW_COPY_AND_ASSIGN(Lock);\n+  mutable std::mutex mutex_;\n+};\n+\n+}  // namespace phonenumbers\n+}  // namespace i18n\n+\n+#endif  // I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_STDMUTEX_H_\ndiff --git a/cpp/src/phonenumbers/base/synchronization/lock_unsafe.h b/cpp/src/phonenumbers/base/synchronization/lock_unsafe.h\nnew file mode 100644\nindex 0000000000..ad94fefb18\n--- /dev/null\n+++ b/cpp/src/phonenumbers/base/synchronization/lock_unsafe.h\n@@ -0,0 +1,51 @@\n+// Copyright (C) 2020 The Libphonenumber Authors\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+// Author: Philippe Liard\n+\n+#ifndef I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_UNSAFE_H_\n+#define I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_UNSAFE_H_\n+\n+#include \"phonenumbers/base/logging.h\"\n+#include \"phonenumbers/base/thread_checker.h\"\n+\n+// Dummy lock implementation on non-POSIX platforms. If you are running on a\n+// different platform and care about thread-safety, please compile with\n+// -DI18N_PHONENUMBERS_USE_BOOST.\n+namespace i18n {\n+namespace phonenumbers {\n+\n+class Lock {\n+ public:\n+  Lock() {}\n+\n+  void Acquire() const {\n+    DCHECK(thread_checker_.CalledOnValidThread());\n+    IGNORE_UNUSED(thread_checker_);\n+  }\n+\n+  void Release() const {\n+    DCHECK(thread_checker_.CalledOnValidThread());\n+    IGNORE_UNUSED(thread_checker_);\n+  }\n+\n+ private:\n+  DISALLOW_COPY_AND_ASSIGN(Lock);\n+  const ThreadChecker thread_checker_;\n+};\n+\n+}  // namespace phonenumbers\n+}  // namespace i18n\n+\n+#endif  // I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_UNSAFE_H_\ndiff --git a/cpp/src/phonenumbers/base/synchronization/lock_win32.h b/cpp/src/phonenumbers/base/synchronization/lock_win32.h\nnew file mode 100644\nindex 0000000000..dea1464dab\n--- /dev/null\n+++ b/cpp/src/phonenumbers/base/synchronization/lock_win32.h\n@@ -0,0 +1,54 @@\n+// Copyright (C) 2020 The Libphonenumber Authors\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+// Author: Philippe Liard\n+\n+#ifndef I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_WINDOWS_H_\n+#define I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_WINDOWS_H_\n+\n+#include <windows.h>\n+#include <synchapi.h>\n+\n+#include \"phonenumbers/base/basictypes.h\"\n+\n+namespace i18n {\n+namespace phonenumbers {\n+\n+class Lock {\n+ public:\n+  Lock() {\n+    InitializeCriticalSection(&cs_);\n+  }\n+\n+  ~Lock() {\n+    DeleteCriticalSection(&cs_);\n+  }\n+\n+  void Acquire() {\n+    EnterCriticalSection(&cs_);\n+  }\n+\n+  void Release() {\n+    LeaveCriticalSection(&cs_);\n+  }\n+\n+ private:\n+  DISALLOW_COPY_AND_ASSIGN(Lock);\n+  CRITICAL_SECTION cs_;\n+};\n+\n+}  // namespace phonenumbers\n+}  // namespace i18n\n+\n+#endif  // I18N_PHONENUMBERS_BASE_SYNCHRONIZATION_LOCK_POSIX_H_\ndiff --git a/cpp/src/phonenumbers/base/thread_checker.h b/cpp/src/phonenumbers/base/thread_checker.h\nindex b7a3523434..6679d9bb04 100644\n--- a/cpp/src/phonenumbers/base/thread_checker.h\n+++ b/cpp/src/phonenumbers/base/thread_checker.h\n@@ -22,8 +22,10 @@\n // Note that I18N_PHONENUMBERS_NO_THREAD_SAFETY must be defined only to let the\n // user of the library know that it can't be used in a thread-safe manner when\n // it is not depending on Boost.\n-#if !defined(__linux__) && !defined(__APPLE__) && \\\n-    !defined(I18N_PHONENUMBERS_NO_THREAD_SAFETY)\n+#if !defined(__linux__) && !defined(__APPLE__) && !defined(I18N_PHONENUMBERS_HAVE_POSIX_THREAD) && \\\n+    !defined(I18N_PHONENUMBERS_NO_THREAD_SAFETY) && \\\n+\t!((__cplusplus >= 201103L) && defined(I18N_PHONENUMBERS_USE_STDMUTEX)) && \\\n+\t!defined(WIN32)\n #error Building without Boost, please provide \\\n        -DI18N_PHONENUMBERS_NO_THREAD_SAFETY\n #endif\n@@ -31,7 +33,7 @@\n #endif\n \n #if !defined(NDEBUG) && !defined(I18N_PHONENUMBERS_USE_BOOST) && \\\n-    (defined(__linux__) || defined(__apple__))\n+    (defined(__linux__) || defined(__APPLE__) || defined(I18N_PHONENUMBERS_HAVE_POSIX_THREAD))\n \n #include <pthread.h>\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "- Ensure `PHONENUMBERS_HAVE_POSIX_THREAD` is defined for Unix systems in addition to Linux and macOS.\n- Correct symbol test: use `WIN32` without the underscore instead of `_WIN32`.\n- Fix compile error in `asyoutypeformatter.cc` caused by `std::min` conflict with Protobuf and `windows.h`; replace with a simple condition.\n- The CMake configuration appears outdated; further updates may be necessary to enable successful builds.\n- There\u2019s a linking issue on Linux confirmed without CMake. Attempt using `-lpthread` instead of `-pthread` to resolve linking errors.\n- Review the latest commit in the forked repository for additional issues; errors suggest problems with the input files and pthread linking."
      }
    ],
    "codediff_length": 26583
  },
  {
    "index": 22,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/boards/lilygo-t7-s3.json b/boards/lilygo-t7-s3.json\nnew file mode 100644\nindex 0000000000..4bf071fc7e\n--- /dev/null\n+++ b/boards/lilygo-t7-s3.json\n@@ -0,0 +1,47 @@\n+{\n+    \"build\": {\n+        \"arduino\":{\n+            \"ldscript\": \"esp32s3_out.ld\",\n+            \"memory_type\": \"qio_opi\",\n+            \"partitions\": \"default_16MB.csv\"\n+        },\n+        \"core\": \"esp32\",\n+        \"extra_flags\": [\n+\t\t\t\"-DARDUINO_TTGO_T7_S3\",\n+            \"-DBOARD_HAS_PSRAM\",\n+            \"-DARDUINO_USB_MODE=1\"\n+        ],\n+        \"f_cpu\": \"240000000L\",\n+        \"f_flash\": \"80000000L\",\n+        \"flash_mode\": \"qio\",\n+        \"hwids\": [\n+            [\n+                \"0X303A\",\n+                \"0x1001\"\n+            ]\n+        ],\n+        \"mcu\": \"esp32s3\",\n+        \"variant\": \"esp32s3\"\n+    },\n+    \"connectivity\": [\n+        \"wifi\",\n+        \"bluetooth\"\n+    ],\n+    \"debug\": {\n+        \"openocd_target\": \"esp32s3.cfg\"\n+    },\n+    \"frameworks\": [\n+        \"arduino\",\n+        \"espidf\"\n+    ],\n+    \"name\": \"LILYGO T3-S3\",\n+    \"upload\": {\n+        \"flash_size\": \"16MB\",\n+        \"maximum_ram_size\": 327680,\n+        \"maximum_size\": 16777216,\n+        \"require_upload_port\": true,\n+        \"speed\": 921600\n+    },\n+    \"url\": \"https://www.aliexpress.us/item/3256804591247074.html\",\n+    \"vendor\": \"LILYGO\"\n+}\n\\ No newline at end of file\ndiff --git a/platformio_override.ini b/platformio_override.ini\nnew file mode 100644\nindex 0000000000..98b84f2cc1\n--- /dev/null\n+++ b/platformio_override.ini\n@@ -0,0 +1,88 @@\n+# Example PlatformIO Project Configuration Override\n+# ------------------------------------------------------------------------------\n+# Copy to platformio_override.ini to activate overrides\n+# ------------------------------------------------------------------------------\n+# Please visit documentation: https://docs.platformio.org/page/projectconf.html\n+\n+[platformio]\n+default_envs = esp32dev_hub75, adafruit_matrixportal_esp32s3, esp32S3_PSRAM_HUB75, esp32dev_hub75_forum_pinout\n+\n+[env:esp32dev_hub75]\n+board = esp32dev\n+upload_speed = 921600\n+platform = ${esp32_idf_V4.platform}\n+platform_packages =\n+build_unflags = ${common.build_unflags}\n+build_flags = ${common.build_flags}\n+  -D WLED_RELEASE_NAME=\\\"ESP32_hub75\\\"\n+  -D WLED_ENABLE_HUB75MATRIX -D NO_GFX -D NO_CIE1931\n+  ; -D ESP32_FORUM_PINOUT ;; enable for SmartMatrix default pins\n+  ; -D WLED_DEBUG\n+lib_deps = ${esp32_idf_V4.lib_deps}\n+  https://github.com/mrfaptastic/ESP32-HUB75-MatrixPanel-DMA.git#3.0.11\n+\n+monitor_filters = esp32_exception_decoder\n+board_build.partitions = ${esp32.default_partitions}\n+board_build.flash_mode = dio\n+\n+[env:esp32dev_hub75_forum_pinout]\n+extends = env:esp32dev_hub75\n+build_flags = ${common.build_flags}\n+              -D WLED_RELEASE_NAME=\\\"ESP32_hub75_forum_pinout\\\"\n+              -D WLED_ENABLE_HUB75MATRIX -D NO_GFX -D NO_CIE1931\n+              -D ESP32_FORUM_PINOUT ;; enable for SmartMatrix default pins\n+; -D WLED_DEBUG\n+\n+\n+[env:adafruit_matrixportal_esp32s3]\n+; ESP32-S3 processor, 8 MB flash, 2 MB of PSRAM, dedicated driver pins for HUB75\n+board = lolin_s3_mini\n+platform = ${esp32s3.platform}\n+platform_packages =\n+upload_speed = 921600\n+build_unflags = ${common.build_unflags}\n+build_flags = ${common.build_flags} ${esp32s3.build_flags} -D WLED_RELEASE_NAME=\\\"ESP32-S3_4M_qspi\\\"\n+  -DARDUINO_USB_CDC_ON_BOOT=1 -DARDUINO_USB_MODE=1      ;; for boards with USB-OTG connector only (USBCDC or \"TinyUSB\")\n+  -DBOARD_HAS_PSRAM\n+  -DLOLIN_WIFI_FIX ; seems to work much better with this\n+  -D WLED_WATCHDOG_TIMEOUT=0\n+  ${esp32.AR_build_flags}\n+  -D WLED_ENABLE_HUB75MATRIX -D NO_GFX -D NO_CIE1931\n+  -D S3_LCD_DIV_NUM=20 ;; Attempt to fix wifi performance issue when panel active with S3 chips\n+  -D ARDUINO_ADAFRUIT_MATRIXPORTAL_ESP32S3\n+\n+lib_deps = ${esp32s3.lib_deps}\n+  ${esp32.AR_lib_deps}\n+  https://github.com/mrfaptastic/ESP32-HUB75-MatrixPanel-DMA.git#aa28e2a ;; S3_LCD_DIV_NUM fix\n+\n+board_build.partitions = ${esp32.default_partitions}\n+board_build.f_flash = 80000000L\n+board_build.flash_mode = qio\n+monitor_filters = esp32_exception_decoder\n+\n+[env:esp32S3_PSRAM_HUB75]\n+;; MOONHUB HUB75 adapter board\n+board = lilygo-t7-s3\n+platform = ${esp32s3.platform}\n+platform_packages =\n+upload_speed = 921600\n+build_unflags = ${common.build_unflags}\n+build_flags = ${common.build_flags} ${esp32s3.build_flags} -D WLED_RELEASE_NAME=\\\"esp32S3_16MB_PSRAM_HUB75\\\"\n+              -DARDUINO_USB_CDC_ON_BOOT=1 -DARDUINO_USB_MODE=1      ;; for boards with USB-OTG connector only (USBCDC or \"TinyUSB\")\n+              -DBOARD_HAS_PSRAM\n+              -DLOLIN_WIFI_FIX ; seems to work much better with this\n+              -D WLED_WATCHDOG_TIMEOUT=0\n+              ${esp32.AR_build_flags}\n+              -D WLED_ENABLE_HUB75MATRIX -D NO_GFX -D NO_CIE1931\n+              -D S3_LCD_DIV_NUM=20 ;; Attempt to fix wifi performance issue when panel active with S3 chips\n+              -D MOONHUB_S3_PINOUT ;; HUB75 pinout\n+\n+lib_deps = ${esp32s3.lib_deps}\n+           ${esp32.AR_lib_deps}\n+           https://github.com/mrfaptastic/ESP32-HUB75-MatrixPanel-DMA.git#aa28e2a ;; S3_LCD_DIV_NUM fix\n+\n+board_build.partitions = ${esp32.default_partitions}\n+board_build.f_flash = 80000000L\n+board_build.flash_mode = qio\n+monitor_filters = esp32_exception_decoder\n+\ndiff --git a/platformio_override.sample.ini b/platformio_override.sample.ini\nindex d11d1f50b8..f85626a409 100644\n--- a/platformio_override.sample.ini\n+++ b/platformio_override.sample.ini\n@@ -180,7 +180,7 @@ build_flags = ${common.build_flags} ${esp8266.build_flags}\n ;\n ; enable IR by setting remote type\n ;   -D IRTYPE=0   # 0 Remote disabled | 1 24-key RGB | 2 24-key with CT | 3 40-key blue | 4 40-key RGB | 5 21-key RGB | 6 6-key black | 7 9-key red | 8 JSON remote\n-;   \n+;\n ; use PSRAM on classic ESP32 rev.1 (rev.3 or above has no issues)\n ;   -DBOARD_HAS_PSRAM -mfix-esp32-psram-cache-issue   # needed only for classic ESP32 rev.1\n ;\n@@ -525,6 +525,48 @@ build_flags = ${common.build_flags} ${esp32.build_flags} -D WLED_DISABLE_BROWNOU\n   -D USER_SETUP_LOADED\n monitor_filters = esp32_exception_decoder\n \n+\n+[env:esp32dev_hub75]\n+board = esp32dev\n+upload_speed = 921600\n+platform = ${esp32_idf_V4.platform}\n+extends = esp32dev_V4\n+build_flags = ${common.build_flags}\n+  -D WLED_RELEASE_NAME=\\\"ESP32_hub75\\\"\n+  -D WLED_ENABLE_HUB75MATRIX -D NO_GFX -D NO_CIE1931\n+  ; -D ESP32_FORUM_PINOUT ;; enable for SmartMatrix default pins\n+  ; -D WLED_DEBUG\n+lib_deps = ${esp32_idf_V4.lib_deps}\n+  https://github.com/mrfaptastic/ESP32-HUB75-MatrixPanel-DMA.git#3.0.11\n+board_build.partitions = ${esp32.default_partitions}\n+board_build.flash_mode = dio\n+\n+\n+[env:adafruit_matrixportal_esp32s3]\n+; ESP32-S3 processor, 8 MB flash, 2 MB of PSRAM, dedicated driver pins for HUB75\n+board = lolin_s3_mini\n+platform = ${esp32s3.platform}\n+platform_packages = ${esp32s3.platform_packages}\n+upload_speed = 921600\n+build_unflags = ${common.build_unflags}\n+build_flags = ${common.build_flags} ${esp32s3.build_flags} -D WLED_RELEASE_NAME=\\\"ESP32-S3_4M_qspi\\\"\n+  -DARDUINO_USB_CDC_ON_BOOT=1 -DARDUINO_USB_MODE=1      ;; for boards with USB-OTG connector only (USBCDC or \"TinyUSB\")\n+  -DBOARD_HAS_PSRAM\n+  -DLOLIN_WIFI_FIX ; seems to work much better with this\n+  -D WLED_WATCHDOG_TIMEOUT=0\n+  ${esp32.AR_build_flags}\n+  -D WLED_ENABLE_HUB75MATRIX -D NO_GFX -D NO_CIE1931\n+  -D S3_LCD_DIV_NUM=20 ;; Attempt to fix wifi performance issue when panel active with S3 chips\n+  -D ARDUINO_ADAFRUIT_MATRIXPORTAL_ESP32S3\n+\n+lib_deps = ${esp32s3.lib_deps}\n+  ${esp32.AR_lib_deps}\n+  https://github.com/mrfaptastic/ESP32-HUB75-MatrixPanel-DMA.git#aa28e2a ;; S3_LCD_DIV_NUM fix\n+\n+board_build.partitions = ${esp32.default_partitions}\n+board_build.f_flash = 80000000L\n+board_build.flash_mode = qio\n+monitor_filters = esp32_exception_decoder\n # ------------------------------------------------------------------------------\n # Usermod examples\n # ------------------------------------------------------------------------------\n@@ -535,3 +577,86 @@ extends = env:esp32dev\n build_flags = ${env:esp32dev.build_flags} -D USERMOD_RF433\n lib_deps = ${env:esp32dev.lib_deps}\n   sui77/rc-switch @ 2.6.4\n+\n+# ------------------------------------------------------------------------------\n+# Hub75 examples\n+# ------------------------------------------------------------------------------\n+\n+[env:esp32dev_hub75]\n+board = esp32dev\n+upload_speed = 921600\n+platform = ${esp32_idf_V4.platform}\n+platform_packages =\n+build_unflags = ${common.build_unflags}\n+build_flags = ${common.build_flags}\n+  -D WLED_RELEASE_NAME=ESP32_hub75\n+  -D WLED_ENABLE_HUB75MATRIX -D NO_GFX -D NO_CIE1931\n+  ; -D ESP32_FORUM_PINOUT ;; enable for SmartMatrix default pins\n+  ; -D WLED_DEBUG\n+lib_deps = ${esp32_idf_V4.lib_deps}\n+  https://github.com/mrfaptastic/ESP32-HUB75-MatrixPanel-DMA.git#3.0.11\n+\n+monitor_filters = esp32_exception_decoder\n+board_build.partitions = ${esp32.default_partitions}\n+board_build.flash_mode = dio\n+\n+\n+[env:adafruit_matrixportal_esp32s3]\n+; ESP32-S3 processor, 8 MB flash, 2 MB of PSRAM, dedicated driver pins for HUB75\n+board = lolin_s3_mini\n+platform = ${esp32s3.platform}\n+platform_packages =\n+upload_speed = 921600\n+build_unflags = ${common.build_unflags}\n+build_flags = ${common.build_flags} ${esp32s3.build_flags} -D WLED_RELEASE_NAME=ESP32-S3_4M_qspi\n+  -DARDUINO_USB_CDC_ON_BOOT=1 -DARDUINO_USB_MODE=1      ;; for boards with USB-OTG connector only (USBCDC or \"TinyUSB\")\n+  -DBOARD_HAS_PSRAM\n+  -DLOLIN_WIFI_FIX ; seems to work much better with this\n+  -D WLED_WATCHDOG_TIMEOUT=0\n+  ${esp32.AR_build_flags}\n+  -D WLED_ENABLE_HUB75MATRIX -D NO_GFX -D NO_CIE1931\n+  -D S3_LCD_DIV_NUM=20 ;; Attempt to fix wifi performance issue when panel active with S3 chips\n+  -D ARDUINO_ADAFRUIT_MATRIXPORTAL_ESP32S3\n+\n+lib_deps = ${esp32s3.lib_deps}\n+  ${esp32.AR_lib_deps}\n+  https://github.com/mrfaptastic/ESP32-HUB75-MatrixPanel-DMA.git#aa28e2a ;; S3_LCD_DIV_NUM fix\n+\n+board_build.partitions = ${esp32.default_partitions}\n+board_build.f_flash = 80000000L\n+board_build.flash_mode = qio\n+monitor_filters = esp32_exception_decoder\n+\n+[env:esp32S3_PSRAM_HUB75]\n+;; MOONHUB HUB75 adapter board\n+board = lilygo-t7-s3\n+platform = ${esp32s3.platform}\n+platform_packages =\n+upload_speed = 921600\n+build_unflags = ${common.build_unflags}\n+build_flags = ${common.build_flags} ${esp32s3.build_flags} -D WLED_RELEASE_NAME=\\\"esp32S3_16MB_PSRAM_HUB75\\\"\n+              -DARDUINO_USB_CDC_ON_BOOT=1 -DARDUINO_USB_MODE=1      ;; for boards with USB-OTG connector only (USBCDC or \"TinyUSB\")\n+              -DBOARD_HAS_PSRAM\n+              -DLOLIN_WIFI_FIX ; seems to work much better with this\n+              -D WLED_WATCHDOG_TIMEOUT=0\n+              ${esp32.AR_build_flags}\n+              -D WLED_ENABLE_HUB75MATRIX -D NO_GFX -D NO_CIE1931\n+              -D S3_LCD_DIV_NUM=20 ;; Attempt to fix wifi performance issue when panel active with S3 chips\n+              -D MOONHUB_S3_PINOUT ;; HUB75 pinout\n+\n+lib_deps = ${esp32s3.lib_deps}\n+           ${esp32.AR_lib_deps}\n+           https://github.com/mrfaptastic/ESP32-HUB75-MatrixPanel-DMA.git#aa28e2a ;; S3_LCD_DIV_NUM fix\n+\n+board_build.partitions = ${esp32.default_partitions}\n+board_build.f_flash = 80000000L\n+board_build.flash_mode = qio\n+monitor_filters = esp32_exception_decoder\n+\n+[env:esp32dev_hub75_forum_pinout]\n+extends = env:esp32dev_hub75\n+build_flags = ${common.build_flags}\n+              -D WLED_RELEASE_NAME=\\\"ESP32_hub75_forum_pinout\\\"\n+              -D WLED_ENABLE_HUB75MATRIX -D NO_GFX -D NO_CIE1931\n+              -D ESP32_FORUM_PINOUT ;; enable for SmartMatrix default pins\n+; -D WLED_DEBUG\n\\ No newline at end of file\ndiff --git a/usermods/rgb-rotary-encoder/rgb-rotary-encoder.cpp b/usermods/rgb-rotary-encoder/rgb-rotary-encoder.cpp\nindex 1514e2307a..6be3a92640 100644\n--- a/usermods/rgb-rotary-encoder/rgb-rotary-encoder.cpp\n+++ b/usermods/rgb-rotary-encoder/rgb-rotary-encoder.cpp\n@@ -54,7 +54,11 @@ class RgbRotaryEncoderUsermod : public Usermod\n \n     void initLedBus()\n     {\n-      byte _pins[5] = {(byte)ledIo, 255, 255, 255, 255};\n+      // Initialize all pins to the sentinel value first\u2026\n+      byte _pins[OUTPUT_MAX_PINS];\n+      std::fill(std::begin(_pins), std::end(_pins), 255);\n+      // \u2026then set only the LED pin\n+      _pins[0] = static_cast<byte>(ledIo);\n       BusConfig busCfg = BusConfig(TYPE_WS2812_RGB, _pins, 0, numLeds, COL_ORDER_GRB, false, 0);\n \n       ledBus = new BusDigital(busCfg, WLED_MAX_BUSSES - 1);\ndiff --git a/wled00/bus_manager.cpp b/wled00/bus_manager.cpp\nindex 99523bba9f..3e80a17a51 100644\n--- a/wled00/bus_manager.cpp\n+++ b/wled00/bus_manager.cpp\n@@ -32,6 +32,36 @@ extern char cmDNS[];\n extern bool cctICused;\n extern bool useParallelI2S;\n \n+// functions to get/set bits in an array - based on functions created by Brandon for GOL\n+//  toDo : make this a class that's completely defined in a header file\n+bool getBitFromArray(const uint8_t* byteArray, size_t position) { // get bit value\n+  size_t byteIndex = position / 8;\n+  unsigned bitIndex = position % 8;\n+  uint8_t byteValue = byteArray[byteIndex];\n+  return (byteValue >> bitIndex) & 1;\n+}\n+\n+void setBitInArray(uint8_t* byteArray, size_t position, bool value) {  // set bit - with error handling for nullptr\n+    //if (byteArray == nullptr) return;\n+    size_t byteIndex = position / 8;\n+    unsigned bitIndex = position % 8;\n+    if (value)\n+        byteArray[byteIndex] |= (1 << bitIndex);\n+    else\n+        byteArray[byteIndex] &= ~(1 << bitIndex);\n+}\n+\n+size_t getBitArrayBytes(size_t num_bits) { // number of bytes needed for an array with num_bits bits\n+  return (num_bits + 7) / 8;\n+}\n+\n+void setBitArray(uint8_t* byteArray, size_t numBits, bool value) {  // set all bits to same value\n+  if (byteArray == nullptr) return;\n+  size_t len =  getBitArrayBytes(numBits);\n+  if (value) memset(byteArray, 0xFF, len);\n+  else memset(byteArray, 0x00, len);\n+}\n+\n //colors.cpp\n uint32_t colorBalanceFromKelvin(uint16_t kelvin, uint32_t rgb);\n \n@@ -760,6 +790,350 @@ void BusNetwork::cleanup() {\n   _valid = false;\n }\n \n+// ***************************************************************************\n+\n+#ifdef WLED_ENABLE_HUB75MATRIX\n+#warning \"HUB75 driver enabled (experimental)\"\n+#ifdef ESP8266\n+#error ESP8266 does not support HUB75\n+#endif\n+\n+BusHub75Matrix::BusHub75Matrix(const BusConfig &bc) : Bus(bc.type, bc.start, bc.autoWhite) {\n+  size_t lastHeap = ESP.getFreeHeap();\n+  _valid = false;\n+  _hasRgb = true;\n+  _hasWhite = false;\n+\n+  mxconfig.double_buff = false; // Use our own memory-optimised buffer rather than the driver's own double-buffer\n+\n+  // mxconfig.driver = HUB75_I2S_CFG::ICN2038S;  // experimental - use specific shift register driver\n+  // mxconfig.driver = HUB75_I2S_CFG::FM6124;    // try this driver in case you panel stays dark, or when colors look too pastel\n+\n+  // mxconfig.latch_blanking = 3;\n+  // mxconfig.i2sspeed = HUB75_I2S_CFG::HZ_10M;  // experimental - 5MHZ should be enugh, but colours looks slightly better at 10MHz\n+  //mxconfig.min_refresh_rate = 90;\n+  //mxconfig.min_refresh_rate = 120;\n+  mxconfig.clkphase = bc.reversed;\n+\n+  virtualDisp = nullptr;\n+\n+  if (bc.type == TYPE_HUB75MATRIX_HS) {\n+      mxconfig.mx_width = min((u_int8_t) 64, bc.pins[0]);\n+      mxconfig.mx_height = min((u_int8_t) 64, bc.pins[1]);\n+      if(bc.pins[2] > 1 &&  bc.pins[3] > 0 &&  bc.pins[4]) {\n+        virtualDisp = new VirtualMatrixPanel((*display), bc.pins[3], bc.pins[4], mxconfig.mx_width, mxconfig.mx_height, CHAIN_BOTTOM_LEFT_UP);\n+      }\n+  } else if (bc.type == TYPE_HUB75MATRIX_QS) {\n+      mxconfig.mx_width = min((u_int8_t) 64, bc.pins[0]) * 2;\n+      mxconfig.mx_height = min((u_int8_t) 64, bc.pins[1]) / 2;\n+      virtualDisp = new VirtualMatrixPanel((*display), 1, 1, bc.pins[0], bc.pins[1]);\n+      virtualDisp->setRotation(0);\n+      switch(bc.pins[1]) {\n+        case 16:\n+          virtualDisp->setPhysicalPanelScanRate(FOUR_SCAN_16PX_HIGH);\n+          break;\n+        case 32:\n+          virtualDisp->setPhysicalPanelScanRate(FOUR_SCAN_32PX_HIGH);\n+          break;\n+        case 64:\n+          virtualDisp->setPhysicalPanelScanRate(FOUR_SCAN_64PX_HIGH);\n+          break;\n+        default:\n+          DEBUGBUS_PRINTLN(\"Unsupported height\");\n+          return;\n+      }\n+  } else {\n+    DEBUGBUS_PRINTLN(\"Unknown type\");\n+    return;\n+  }\n+\n+#if defined(CONFIG_IDF_TARGET_ESP32) || defined(CONFIG_IDF_TARGET_ESP32S2)// classic esp32, or esp32-s2: reduce bitdepth for large panels\n+  if (mxconfig.mx_height >= 64) {\n+    if (mxconfig.chain_length * mxconfig.mx_width > 192) mxconfig.setPixelColorDepthBits(3);\n+    else if (mxconfig.chain_length * mxconfig.mx_width > 64)  mxconfig.setPixelColorDepthBits(4);\n+    else mxconfig.setPixelColorDepthBits(8);\n+  } else mxconfig.setPixelColorDepthBits(8);\n+#endif\n+\n+  mxconfig.chain_length = max((u_int8_t) 1, min(bc.pins[2], (u_int8_t) 4)); // prevent bad data preventing boot due to low memory\n+\n+  if(mxconfig.mx_height >= 64 && (mxconfig.chain_length > 1)) {\n+    DEBUGBUS_PRINTLN(\"WARNING, only single panel can be used of 64 pixel boards due to memory\");\n+    mxconfig.chain_length = 1;\n+  }\n+\n+\n+//  HUB75_I2S_CFG::i2s_pins _pins={R1_PIN, G1_PIN, B1_PIN, R2_PIN, G2_PIN, B2_PIN, A_PIN, B_PIN, C_PIN, D_PIN, E_PIN, LAT_PIN, OE_PIN, CLK_PIN};\n+\n+#if defined(ARDUINO_ADAFRUIT_MATRIXPORTAL_ESP32S3) // MatrixPortal ESP32-S3\n+\n+  // https://www.adafruit.com/product/5778\n+  DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA - Matrix Portal S3 config\");\n+  mxconfig.gpio = { 42, 41, 40, 38, 39, 37,  45, 36, 48, 35, 21, 47, 14, 2 };\n+\n+#elif defined(CONFIG_IDF_TARGET_ESP32S3) && defined(BOARD_HAS_PSRAM)// ESP32-S3 with PSRAM\n+\n+#if defined(MOONHUB_S3_PINOUT)\n+  DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA - T7 S3 with PSRAM, MOONHUB pinout\");\n+\n+  // HUB75_I2S_CFG::i2s_pins _pins={R1_PIN, G1_PIN, B1_PIN, R2_PIN, G2_PIN, B2_PIN, A_PIN, B_PIN, C_PIN, D_PIN, E_PIN, LAT_PIN, OE_PIN, CLK_PIN};\n+  mxconfig.gpio = { 1, 5, 6, 7, 13, 9, 16, 48, 47, 21, 38, 8, 4, 18 };\n+\n+#else\n+  DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA - S3 with PSRAM\");\n+  // HUB75_I2S_CFG::i2s_pins _pins={R1_PIN, G1_PIN, B1_PIN, R2_PIN, G2_PIN, B2_PIN, A_PIN, B_PIN, C_PIN, D_PIN, E_PIN, LAT_PIN, OE_PIN, CLK_PIN};\n+  mxconfig.gpio = {1, 2, 42, 41, 40, 39, 45, 48, 47, 21, 38, 8, 3, 18};\n+#endif\n+#elif defined(ESP32_FORUM_PINOUT) // Common format for boards designed for SmartMatrix\n+\n+  DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA - ESP32_FORUM_PINOUT\");\n+/*\n+    ESP32 with SmartMatrix's default pinout - ESP32_FORUM_PINOUT\n+    https://github.com/pixelmatix/SmartMatrix/blob/teensylc/src/MatrixHardware_ESP32_V0.h\n+    Can use a board like https://github.com/rorosaurus/esp32-hub75-driver\n+*/\n+\n+ mxconfig.gpio = { 2, 15, 4, 16, 27, 17, 5, 18, 19, 21, 12, 26, 25, 22 };\n+\n+#else\n+  DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA - Default pins\");\n+  /*\n+   https://github.com/mrfaptastic/ESP32-HUB75-MatrixPanel-DMA?tab=readme-ov-file\n+\n+   Boards\n+\n+   https://esp32trinity.com/\n+   https://www.electrodragon.com/product/rgb-matrix-panel-drive-interface-board-for-esp32-dma/\n+\n+  */\n+ mxconfig.gpio = { 25, 26, 27, 14, 12, 13, 23, 19, 5, 17, 18, 4, 15, 16 };\n+\n+#endif\n+\n+  int8_t pins[PIN_COUNT];\n+  memcpy(pins, &mxconfig.gpio, sizeof(mxconfig.gpio));\n+  if (!PinManager::allocateMultiplePins(pins, PIN_COUNT, PinOwner::HUB75, true)) {\n+    DEBUGBUS_PRINTLN(\"Failed to allocate pins for HUB75\");\n+    return;\n+  }\n+\n+  if(bc.colorOrder == COL_ORDER_RGB) {\n+    DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA = Default color order (RGB)\");\n+  } else if(bc.colorOrder == COL_ORDER_BGR) {\n+    DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA = color order BGR\");\n+    int8_t tmpPin;\n+    tmpPin = mxconfig.gpio.r1;\n+    mxconfig.gpio.r1 = mxconfig.gpio.b1;\n+    mxconfig.gpio.b1 = tmpPin;\n+    tmpPin = mxconfig.gpio.r2;\n+    mxconfig.gpio.r2 = mxconfig.gpio.b2;\n+    mxconfig.gpio.b2 = tmpPin;\n+  }\n+  else {\n+    DEBUGBUS_PRINTF(\"MatrixPanel_I2S_DMA = unsupported color order %u\\n\", bc.colorOrder);\n+  }\n+\n+  DEBUGBUS_PRINTF(\"MatrixPanel_I2S_DMA config - %ux%u length: %u\\n\", mxconfig.mx_width, mxconfig.mx_height, mxconfig.chain_length);\n+  DEBUGBUS_PRINTF(\"R1_PIN=%u, G1_PIN=%u, B1_PIN=%u, R2_PIN=%u, G2_PIN=%u, B2_PIN=%u, A_PIN=%u, B_PIN=%u, C_PIN=%u, D_PIN=%u, E_PIN=%u, LAT_PIN=%u, OE_PIN=%u, CLK_PIN=%u\\n\",\n+                mxconfig.gpio.r1, mxconfig.gpio.g1, mxconfig.gpio.b1, mxconfig.gpio.r2, mxconfig.gpio.g2, mxconfig.gpio.b2,\n+                mxconfig.gpio.a, mxconfig.gpio.b, mxconfig.gpio.c, mxconfig.gpio.d, mxconfig.gpio.e, mxconfig.gpio.lat, mxconfig.gpio.oe, mxconfig.gpio.clk);\n+\n+  // OK, now we can create our matrix object\n+  display = new MatrixPanel_I2S_DMA(mxconfig);\n+  if (display == nullptr) {\n+      DEBUGBUS_PRINTLN(\"****** MatrixPanel_I2S_DMA !KABOOM! driver allocation failed ***********\");\n+      DEBUGBUS_PRINT(F(\"heap usage: \")); DEBUGBUS_PRINTLN(lastHeap - ESP.getFreeHeap());\n+      return;\n+  }\n+\n+  this->_len = (display->width() * display->height());\n+  DEBUGBUS_PRINTF(\"Length: %u\\n\", _len);\n+  if(this->_len >= MAX_LEDS) {\n+    DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA Too many LEDS - playing safe\");\n+    return;\n+  }\n+\n+  DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA created\");\n+  // let's adjust default brightness\n+  display->setBrightness8(25);    // range is 0-255, 0 - 0%, 255 - 100%\n+\n+  delay(24); // experimental\n+  DEBUGBUS_PRINT(F(\"heap usage: \")); DEBUGBUS_PRINTLN(lastHeap - ESP.getFreeHeap());\n+  // Allocate memory and start DMA display\n+  if( not display->begin() ) {\n+      DEBUGBUS_PRINTLN(\"****** MatrixPanel_I2S_DMA !KABOOM! I2S memory allocation failed ***********\");\n+      DEBUGBUS_PRINT(F(\"heap usage: \")); DEBUGBUS_PRINTLN(lastHeap - ESP.getFreeHeap());\n+      return;\n+  }\n+  else {\n+    DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA begin ok\");\n+    DEBUGBUS_PRINT(F(\"heap usage: \")); DEBUGBUS_PRINTLN(lastHeap - ESP.getFreeHeap());\n+    delay(18);   // experiment - give the driver a moment (~ one full frame @ 60hz) to settle\n+    _valid = true;\n+    display->clearScreen();   // initially clear the screen buffer\n+    DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA clear ok\");\n+\n+    if (_ledBuffer) free(_ledBuffer);                 // should not happen\n+    if (_ledsDirty) free(_ledsDirty);                 // should not happen\n+    DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA allocate memory\");\n+    _ledsDirty = (byte*) malloc(getBitArrayBytes(_len));  // create LEDs dirty bits\n+    DEBUGBUS_PRINTLN(\"MatrixPanel_I2S_DMA allocate memory ok\");\n+\n+    if (_ledsDirty == nullptr) {\n+      display->stopDMAoutput();\n+      delete display; display = nullptr;\n+      _valid = false;\n+      DEBUGBUS_PRINTLN(F(\"MatrixPanel_I2S_DMA not started - not enough memory for dirty bits!\"));\n+      DEBUGBUS_PRINT(F(\"heap usage: \")); DEBUGBUS_PRINTLN(lastHeap - ESP.getFreeHeap());\n+      return;  //  fail is we cannot get memory for the buffer\n+    }\n+    setBitArray(_ledsDirty, _len, false);             // reset dirty bits\n+\n+    if (mxconfig.double_buff == false) {\n+      _ledBuffer = (CRGB*) calloc(_len, sizeof(CRGB));  // create LEDs buffer (initialized to BLACK)\n+    }\n+  }\n+\n+\n+  if (_valid) {\n+    _panelWidth = virtualDisp ? virtualDisp->width() : display->width();  // cache width - it will never change\n+  }\n+\n+  DEBUGBUS_PRINT(F(\"MatrixPanel_I2S_DMA \"));\n+  DEBUGBUS_PRINTF(\"%sstarted, width=%u, %u pixels.\\n\", _valid? \"\":\"not \", _panelWidth, _len);\n+\n+  if (mxconfig.double_buff == true) DEBUGBUS_PRINTLN(F(\"MatrixPanel_I2S_DMA driver native double-buffering enabled.\"));\n+  if (_ledBuffer != nullptr) DEBUGBUS_PRINTLN(F(\"MatrixPanel_I2S_DMA LEDS buffer enabled.\"));\n+  if (_ledsDirty != nullptr) DEBUGBUS_PRINTLN(F(\"MatrixPanel_I2S_DMA LEDS dirty bit optimization enabled.\"));\n+  if ((_ledBuffer != nullptr) || (_ledsDirty != nullptr)) {\n+    DEBUGBUS_PRINT(F(\"MatrixPanel_I2S_DMA LEDS buffer uses \"));\n+    DEBUGBUS_PRINT((_ledBuffer? _len*sizeof(CRGB) :0) + (_ledsDirty? getBitArrayBytes(_len) :0));\n+    DEBUGBUS_PRINTLN(F(\" bytes.\"));\n+  }\n+}\n+\n+void __attribute__((hot)) BusHub75Matrix::setPixelColor(unsigned pix, uint32_t c) {\n+  if (!_valid || pix >= _len) return;\n+  // if (_cct >= 1900) c = colorBalanceFromKelvin(_cct, c); //color correction from CCT\n+\n+  if (_ledBuffer) {\n+    CRGB fastled_col = CRGB(c);\n+    if (_ledBuffer[pix] != fastled_col) {\n+      _ledBuffer[pix] = fastled_col;\n+      setBitInArray(_ledsDirty, pix, true);  // flag pixel as \"dirty\"\n+    }\n+  }\n+  else {\n+    if ((c == IS_BLACK) && (getBitFromArray(_ledsDirty, pix) == false)) return; // ignore black if pixel is already black\n+    setBitInArray(_ledsDirty, pix, c != IS_BLACK);                              // dirty = true means \"color is not BLACK\"\n+\n+    #ifndef NO_CIE1931\n+    c = unGamma24(c); // to use the driver linear brightness feature, we first need to undo WLED gamma correction\n+    #endif\n+    uint8_t r = R(c);\n+    uint8_t g = G(c);\n+    uint8_t b = B(c);\n+\n+    if(virtualDisp != nullptr) {\n+      int x = pix % _panelWidth;\n+      int y = pix / _panelWidth;\n+      virtualDisp->drawPixelRGB888(int16_t(x), int16_t(y), r, g, b);\n+    } else {\n+      int x = pix % _panelWidth;\n+      int y = pix / _panelWidth;\n+      display->drawPixelRGB888(int16_t(x), int16_t(y), r, g, b);\n+    }\n+  }\n+}\n+\n+uint32_t BusHub75Matrix::getPixelColor(unsigned pix) const {\n+  if (!_valid || pix >= _len) return IS_BLACK;\n+  if (_ledBuffer)\n+    return uint32_t(_ledBuffer[pix].scale8(_bri)) & 0x00FFFFFF;  // scale8() is needed to mimic NeoPixelBus, which returns scaled-down colours\n+  else\n+    return getBitFromArray(_ledsDirty, pix) ? IS_DARKGREY: IS_BLACK;   // just a hack - we only know if the pixel is black or not\n+}\n+\n+void BusHub75Matrix::setBrightness(uint8_t b) {\n+  _bri = b;\n+  display->setBrightness(_bri);\n+}\n+\n+void BusHub75Matrix::show(void) {\n+  if (!_valid) return;\n+  display->setBrightness(_bri);\n+\n+  if (_ledBuffer) {\n+    // write out buffered LEDs\n+    bool isVirtualDisp = (virtualDisp != nullptr);\n+    unsigned height = isVirtualDisp ? virtualDisp->height() : display->height();\n+    unsigned width = _panelWidth;\n+\n+    //while(!previousBufferFree) delay(1);   // experimental - Wait before we allow any writing to the buffer. Stop flicker.\n+\n+    size_t pix = 0; // running pixel index\n+    for (int y=0; y<height; y++) for (int x=0; x<width; x++) {\n+      if (getBitFromArray(_ledsDirty, pix) == true) {        // only repaint the \"dirty\"  pixels\n+        uint32_t c = uint32_t(_ledBuffer[pix]) & 0x00FFFFFF; // get RGB color, removing FastLED \"alpha\" component\n+        #ifndef NO_CIE1931\n+        c = unGamma24(c); // to use the driver linear brightness feature, we first need to undo WLED gamma correction\n+        #endif\n+        uint8_t r = R(c);\n+        uint8_t g = G(c);\n+        uint8_t b = B(c);\n+        if (isVirtualDisp) virtualDisp->drawPixelRGB888(int16_t(x), int16_t(y), r, g, b);\n+        else display->drawPixelRGB888(int16_t(x), int16_t(y), r, g, b);\n+      }\n+      pix ++;\n+    }\n+    setBitArray(_ledsDirty, _len, false);  // buffer shown - reset all dirty bits\n+  }\n+\n+  if(mxconfig.double_buff) {\n+    display->flipDMABuffer(); // Show the back buffer, set current output buffer to the back (i.e. no longer being sent to LED panels)\n+    // while(!previousBufferFree) delay(1);   // experimental - Wait before we allow any writing to the buffer. Stop flicker.\n+    display->clearScreen();   // Now clear the back-buffer\n+    setBitArray(_ledsDirty, _len, false);  // dislay buffer is blank - reset all dirty bits\n+  }\n+}\n+\n+void BusHub75Matrix::cleanup() {\n+  if (display && _valid) display->stopDMAoutput();  // terminate DMA driver (display goes black)\n+  _valid = false;\n+  _panelWidth = 0;\n+  deallocatePins();\n+  DEBUGBUS_PRINTLN(\"HUB75 output ended.\");\n+\n+  //if (virtualDisp != nullptr) delete virtualDisp;  // warning: deleting object of polymorphic class type 'VirtualMatrixPanel' which has non-virtual destructor might cause undefined behavior\n+  delete display;\n+  display = nullptr;\n+  virtualDisp = nullptr;\n+  if (_ledBuffer != nullptr) free(_ledBuffer); _ledBuffer = nullptr;\n+  if (_ledsDirty != nullptr) free(_ledsDirty); _ledsDirty = nullptr;\n+}\n+\n+void BusHub75Matrix::deallocatePins() {\n+  uint8_t pins[PIN_COUNT];\n+  memcpy(pins, &mxconfig.gpio, sizeof(mxconfig.gpio));\n+  PinManager::deallocateMultiplePins(pins, PIN_COUNT, PinOwner::HUB75);\n+}\n+\n+std::vector<LEDType> BusHub75Matrix::getLEDTypes() {\n+  return {\n+    {TYPE_HUB75MATRIX_HS,     \"H\",     PSTR(\"HUB75 (Half Scan)\")},\n+    {TYPE_HUB75MATRIX_QS,     \"H\",     PSTR(\"HUB75 (Quarter Scan)\")},\n+  };\n+}\n+\n+size_t BusHub75Matrix::getPins(uint8_t* pinArray) const {\n+  pinArray[0] = mxconfig.mx_width;\n+  pinArray[1] = mxconfig.mx_height;\n+  pinArray[2] = mxconfig.chain_length;\n+  return 3;\n+}\n+\n+#endif\n+// ***************************************************************************\n \n //utility to get the approx. memory usage of a given BusConfig\n size_t BusConfig::memUsage(unsigned nr) const {\n@@ -816,6 +1190,10 @@ int BusManager::add(const BusConfig &bc) {\n   if (digital > WLED_MAX_DIGITAL_CHANNELS || analog > WLED_MAX_ANALOG_CHANNELS) return -1;\n   if (Bus::isVirtual(bc.type)) {\n     busses.push_back(make_unique<BusNetwork>(bc));\n+#ifdef WLED_ENABLE_HUB75MATRIX\n+  } else if (Bus::isHub75(bc.type)) {\n+    busses.push_back(make_unique<BusHub75Matrix>(bc));\n+#endif\n   } else if (Bus::isDigital(bc.type)) {\n     busses.push_back(make_unique<BusDigital>(bc, Bus::is2Pin(bc.type) ? twoPin : digital));\n   } else if (Bus::isOnOff(bc.type)) {\n@@ -847,6 +1225,10 @@ String BusManager::getLEDTypesJSONString() {\n   json += LEDTypesToJson(BusPwm::getLEDTypes());\n   json += LEDTypesToJson(BusNetwork::getLEDTypes());\n   //json += LEDTypesToJson(BusVirtual::getLEDTypes());\n+  #ifdef WLED_ENABLE_HUB75MATRIX\n+  json += LEDTypesToJson(BusHub75Matrix::getLEDTypes());\n+  #endif\n+\n   json.setCharAt(json.length()-1, ']'); // replace last comma with bracket\n   return json;\n }\ndiff --git a/wled00/bus_manager.h b/wled00/bus_manager.h\nindex fe70a05170..878f93e41a 100644\n--- a/wled00/bus_manager.h\n+++ b/wled00/bus_manager.h\n@@ -2,6 +2,13 @@\n #ifndef BusManager_h\n #define BusManager_h\n \n+#ifdef WLED_ENABLE_HUB75MATRIX\n+\n+#include <ESP32-HUB75-MatrixPanel-I2S-DMA.h>\n+#include <ESP32-VirtualMatrixPanel-I2S-DMA.h>\n+#include <FastLED.h>\n+\n+#endif\n /*\n  * Class for addressing various light types\n  */\n@@ -182,6 +189,7 @@ class Bus {\n     static constexpr bool  isOnOff(uint8_t type)      { return (type == TYPE_ONOFF); }\n     static constexpr bool  isPWM(uint8_t type)        { return (type >= TYPE_ANALOG_MIN && type <= TYPE_ANALOG_MAX); }\n     static constexpr bool  isVirtual(uint8_t type)    { return (type >= TYPE_VIRTUAL_MIN && type <= TYPE_VIRTUAL_MAX); }\n+    static constexpr bool  isHub75(uint8_t type)      { return (type >= TYPE_HUB75MATRIX_MIN && type <= TYPE_HUB75MATRIX_MAX); }\n     static constexpr bool  is16bit(uint8_t type)      { return type == TYPE_UCS8903 || type == TYPE_UCS8904 || type == TYPE_SM16825; }\n     static constexpr bool  mustRefresh(uint8_t type)  { return type == TYPE_TM1814; }\n     static constexpr int   numPWMPins(uint8_t type)   { return (type - 40); }\n@@ -363,6 +371,37 @@ class BusNetwork : public Bus {\n     #endif\n };\n \n+#ifdef WLED_ENABLE_HUB75MATRIX\n+class BusHub75Matrix : public Bus {\n+  public:\n+    BusHub75Matrix(const BusConfig &bc);\n+    [[gnu::hot]] void setPixelColor(unsigned pix, uint32_t c) override;\n+    [[gnu::hot]] uint32_t getPixelColor(unsigned pix) const override;\n+    void show() override;\n+    void setBrightness(uint8_t b) override;\n+    size_t getPins(uint8_t* pinArray = nullptr) const override;\n+    void deallocatePins();\n+    void cleanup();\n+\n+    ~BusHub75Matrix() {\n+      cleanup();\n+    }\n+\n+    static std::vector<LEDType> getLEDTypes(void);\n+\n+  private:\n+    MatrixPanel_I2S_DMA *display = nullptr;\n+    VirtualMatrixPanel  *virtualDisp = nullptr;\n+    HUB75_I2S_CFG mxconfig;\n+    unsigned _panelWidth = 0;\n+    CRGB *_ledBuffer = nullptr;\n+    byte *_ledsDirty = nullptr;\n+    // workaround for missing constants on include path for non-MM\n+    uint32_t IS_BLACK = 0x000000;\n+    uint32_t IS_DARKGREY = 0x333333;\n+    const int PIN_COUNT = 14;\n+};\n+#endif\n \n //temporary struct for passing bus configuration to bus\n struct BusConfig {\n@@ -374,7 +413,7 @@ struct BusConfig {\n   uint8_t skipAmount;\n   bool refreshReq;\n   uint8_t autoWhite;\n-  uint8_t pins[5] = {255, 255, 255, 255, 255};\n+  uint8_t pins[OUTPUT_MAX_PINS] = {255, 255, 255, 255, 255};\n   uint16_t frequency;\n   uint8_t milliAmpsPerLed;\n   uint16_t milliAmpsMax;\n@@ -394,7 +433,7 @@ struct BusConfig {\n   {\n     refreshReq = (bool) GET_BIT(busType,7);\n     type = busType & 0x7F;  // bit 7 may be/is hacked to include refresh info (1=refresh in off state, 0=no refresh)\n-    size_t nPins = Bus::getNumberOfPins(type);\n+    size_t nPins = OUTPUT_MAX_PINS;\n     for (size_t i = 0; i < nPins; i++) pins[i] = ppins[i];\n     DEBUGBUS_PRINTF_P(PSTR(\"Bus: Config (%d-%d, type:%d, CO:%d, rev:%d, skip:%d, AW:%d kHz:%d, mA:%d/%d)\\n\"),\n       (int)start, (int)(start+len),\ndiff --git a/wled00/cfg.cpp b/wled00/cfg.cpp\nindex eac6ea25a2..1d299848bb 100644\n--- a/wled00/cfg.cpp\n+++ b/wled00/cfg.cpp\n@@ -207,7 +207,7 @@ bool deserializeConfig(JsonObject doc, bool fromFS) {\n     int s = 0;  // bus iterator\n     for (JsonObject elm : ins) {\n       if (s >= WLED_MAX_BUSSES) break; // only counts physical buses\n-      uint8_t pins[5] = {255, 255, 255, 255, 255};\n+      uint8_t pins[OUTPUT_MAX_PINS] = {255, 255, 255, 255, 255};\n       JsonArray pinArr = elm[\"pin\"];\n       if (pinArr.size() == 0) continue;\n       //pins[0] = pinArr[0];\ndiff --git a/wled00/const.h b/wled00/const.h\nindex 1abf245396..f6867056a5 100644\n--- a/wled00/const.h\n+++ b/wled00/const.h\n@@ -316,6 +316,12 @@ static_assert(WLED_MAX_BUSSES <= 32, \"WLED_MAX_BUSSES exceeds hard limit\");\n #define TYPE_P9813               53\n #define TYPE_LPD6803             54\n #define TYPE_2PIN_MAX            63\n+\n+#define TYPE_HUB75MATRIX_MIN     64\n+#define TYPE_HUB75MATRIX_HS      65\n+#define TYPE_HUB75MATRIX_QS      66\n+#define TYPE_HUB75MATRIX_MAX     71\n+\n //Network types (master broadcast) (80-95)\n #define TYPE_VIRTUAL_MIN         80\n #define TYPE_NET_DDP_RGB         80            //network DDP RGB bus (master broadcast bus)\ndiff --git a/wled00/data/settings_leds.htm b/wled00/data/settings_leds.htm\nindex 928da11753..3ad468ce15 100644\n--- a/wled00/data/settings_leds.htm\n+++ b/wled00/data/settings_leds.htm\n@@ -17,6 +17,7 @@\n \t\tfunction isD2P(t)  { return gT(t).t === \"2P\"; }             // is digital 2 pin type\n \t\tfunction isNet(t)  { return gT(t).t === \"N\"; }              // is network type\n \t\tfunction isVir(t)  { return gT(t).t === \"V\" || isNet(t); }  // is virtual type\n+\t\tfunction isHub75(t){ return gT(t).t === \"H\"; }              // is HUB75 type\n \t\tfunction hasRGB(t) { return !!(gT(t).c & 0x01); }           // has RGB\n \t\tfunction hasW(t)   { return !!(gT(t).c & 0x02); }           // has white channel\n \t\tfunction hasCCT(t) { return !!(gT(t).c & 0x04); }           // is white CCT enabled\n@@ -64,6 +65,9 @@\n \t\t\t\tlet nm = LC.name.substring(0,2);\n \t\t\t\tlet n = LC.name.substring(2);\n \t\t\t\tlet t = parseInt(d.Sf[\"LT\"+n].value, 10); // LED type SELECT\n+\t\t\t\tif(isHub75(t)) {\n+\t\t\t\t\treturn;\n+\t\t\t\t}\n \t\t\t\t// ignore IP address\n \t\t\t\tif (nm==\"L0\" || nm==\"L1\" || nm==\"L2\" || nm==\"L3\") {\n \t\t\t\t\tif (isNet(t)) return;\n@@ -237,12 +241,15 @@\n \t\t\t\t\tcase 'V': // virtual/non-GPIO based\n \t\t\t\t\t\tp0d = \"Config:\"\n \t\t\t\t\t\tbreak;\n+\t\t\t\t\tcase 'H': // HUB75\n+\t\t\t\t\t\tp0d = \"Panel size (width x height), Panel count:\"\n+\t\t\t\t\t\tbreak;\n \t\t\t\t}\n \t\t\t\tgId(\"p0d\"+n).innerText = p0d;\n \t\t\t\tgId(\"p1d\"+n).innerText = p1d;\n \t\t\t\tgId(\"off\"+n).innerText = off;\n \t\t\t\t// secondary pins show/hide (type string length is equivalent to number of pins used; except for network and on/off)\n-\t\t\t\tlet pins = Math.max(gT(t).t.length,1) + 3*isNet(t); // fixes network pins to 4\n+\t\t\t\tlet pins = Math.max(gT(t).t.length,1) + 3*isNet(t) + 2*isHub75(t); // fixes network pins to 4\n \t\t\t\tfor (let p=1; p<5; p++) {\n \t\t\t\t\tvar LK = d.Sf[\"L\"+p+n];\n \t\t\t\t\tif (!LK) continue;\n@@ -272,13 +279,13 @@\n \t\t\t\t}\n \t\t\t\tgId(\"rf\"+n).onclick = mustR(t) ? (()=>{return false}) : (()=>{});           // prevent change change of \"Refresh\" checkmark when mandatory\n \t\t\t\tgRGBW |= hasW(t);                                                           // RGBW checkbox\n-\t\t\t\tgId(\"co\"+n).style.display = (isVir(t) || isAna(t)) ? \"none\":\"inline\";       // hide color order for PWM\n+\t\t\t\tgId(\"co\"+n).style.display = (isVir(t) || isAna(t) || isHub75(t)) ? \"none\":\"inline\";       // hide color order for PWM\n \t\t\t\tgId(\"dig\"+n+\"w\").style.display = (isDig(t) && hasW(t)) ? \"inline\":\"none\";   // show swap channels dropdown\n \t\t\t\tgId(\"dig\"+n+\"w\").querySelector(\"[data-opt=CCT]\").disabled = !hasCCT(t);     // disable WW/CW swapping\n \t\t\t\tif (!(isDig(t) && hasW(t))) d.Sf[\"WO\"+n].value = 0;                         // reset swapping\n-\t\t\t\tgId(\"dig\"+n+\"c\").style.display = (isAna(t)) ? \"none\":\"inline\";              // hide count for analog\n+\t\t\t\tgId(\"dig\"+n+\"c\").style.display = (isAna(t) || isHub75(t)) ? \"none\":\"inline\";              // hide count for analog\n \t\t\t\tgId(\"dig\"+n+\"r\").style.display = (isVir(t)) ? \"none\":\"inline\";              // hide reversed for virtual\n-\t\t\t\tgId(\"dig\"+n+\"s\").style.display = (isVir(t) || isAna(t)) ? \"none\":\"inline\";  // hide skip 1st for virtual & analog\n+\t\t\t\tgId(\"dig\"+n+\"s\").style.display = (isVir(t) || isAna(t) || isHub75(t)) ? \"none\":\"inline\";  // hide skip 1st for virtual & analog\n \t\t\t\tgId(\"dig\"+n+\"f\").style.display = (isDig(t) || (isPWM(t) && maxL>2048)) ? \"inline\":\"none\"; // hide refresh (PWM hijacks reffresh for dithering on ESP32)\n \t\t\t\tgId(\"dig\"+n+\"a\").style.display = (hasW(t)) ? \"inline\":\"none\";               // auto calculate white\n \t\t\t\tgId(\"dig\"+n+\"l\").style.display = (isD2P(t) || isPWM(t)) ? \"inline\":\"none\";  // bus clock speed / PWM speed (relative) (not On/Off)\n@@ -325,7 +332,13 @@\n \t\t\t\t}\n \t\t\t\t// do we have led pins for digital leds\n \t\t\t\tif (nm==\"L0\" || nm==\"L1\") {\n-\t\t\t\t\td.Sf[\"LC\"+n].max = maxPB; // update max led count value\n+\t\t\t\t\tif (!isHub75(t)) {\n+\t\t\t\t\t\td.Sf[\"LC\"+n].max = maxPB; // update max led count value\n+\t\t\t\t\t}\n+\t\t\t\t\telse {\n+\t\t\t\t\t\td.Sf[\"LC\"+n].min = undefined;\n+\t\t\t\t\t\td.Sf[\"LC\"+n].max = undefined;\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\t\t// ignore IP address (stored in pins for virtual busses)\n \t\t\t\tif (nm==\"L0\" || nm==\"L1\" || nm==\"L2\" || nm==\"L3\") {\n@@ -339,6 +352,20 @@\n \t\t\t\t\t\tLC.min = -1;\n \t\t\t\t\t}\n \t\t\t\t}\n+\t\t\t\tif (isHub75(t) && (nm==\"L0\" || nm==\"L1\")) {\n+\t\t\t\t\t// Matrix width and height\n+\t\t\t\t\tLC.max = 128;\n+\t\t\t\t\tLC.min = 16;\n+\t\t\t\t\tLC.style.color=\"#fff\";\n+\t\t\t\t\treturn; // do not check conflicts\n+\t\t\t\t}\n+\t\t\t\telse if (isHub75(t) && nm==\"L2\") {\n+\t\t\t\t\t// Chain length aka Panel Count\n+\t\t\t\t\tLC.max = 4;\n+\t\t\t\t\tLC.min = 1;\n+\t\t\t\t\tLC.style.color=\"#fff\";\n+\t\t\t\t\treturn; // do not check conflicts\n+\t\t\t\t}\n \t\t\t\t// check for pin conflicts & color fields\n \t\t\t\tif (nm==\"L0\" || nm==\"L1\" || nm==\"L2\" || nm==\"L3\" || nm==\"L4\")\n \t\t\t\t\tif (LC.value!=\"\" && LC.value!=\"-1\") {\ndiff --git a/wled00/pin_manager.cpp b/wled00/pin_manager.cpp\nindex 0c9f32e84a..709263e1a3 100644\n--- a/wled00/pin_manager.cpp\n+++ b/wled00/pin_manager.cpp\n@@ -139,6 +139,12 @@ bool PinManager::allocateMultiplePins(const managed_pin_type * mptArray, byte ar\n   return true;\n }\n \n+bool PinManager::allocateMultiplePins(const int8_t * mptArray, byte arrayElementCount, PinOwner tag, boolean output) {\n+  PinManagerPinType pins[arrayElementCount];\n+  for (int i=0; i<arrayElementCount; i++) pins[i] = {mptArray[i], output};\n+  return allocateMultiplePins(pins, arrayElementCount, tag);\n+}\n+\n bool PinManager::allocatePin(byte gpio, bool output, PinOwner tag)\n {\n   // HW I2C & SPI pins have to be allocated using allocateMultiplePins variant since there is always SCL/SDA pair\ndiff --git a/wled00/pin_manager.h b/wled00/pin_manager.h\nindex 662e499b2a..a488d24f70 100644\n--- a/wled00/pin_manager.h\n+++ b/wled00/pin_manager.h\n@@ -40,6 +40,7 @@ enum struct PinOwner : uint8_t {\n   HW_I2C        = 0x8B,   // 'I2C'       == hardware I2C pins (4&5 on ESP8266, 21&22 on ESP32)\n   HW_SPI        = 0x8C,   // 'SPI'       == hardware (V)SPI pins (13,14&15 on ESP8266, 5,18&23 on ESP32)\n   DMX_INPUT     = 0x8D,   // 'DMX_INPUT' == DMX input via serial\n+  HUB75         = 0x8E,   // 'Hub75' == Hub75 driver\n   // Use UserMod IDs from const.h here\n   UM_Unspecified       = USERMOD_ID_UNSPECIFIED,        // 0x01\n   UM_Example           = USERMOD_ID_EXAMPLE,            // 0x02 // Usermod \"usermod_v2_example.h\"\n@@ -86,6 +87,7 @@ namespace PinManager {\n   // using more than one pin, such as I2C, SPI, rotary encoders,\n   // ethernet, etc..\n   bool allocateMultiplePins(const managed_pin_type * mptArray, byte arrayElementCount, PinOwner tag );\n+  bool allocateMultiplePins(const int8_t * mptArray, byte arrayElementCount, PinOwner tag, boolean output);\n \n   [[deprecated(\"Replaced by three-parameter allocatePin(gpio, output, ownerTag), for improved debugging\")]]\n   inline bool allocatePin(byte gpio, bool output = true) { return allocatePin(gpio, output, PinOwner::None); }\n@@ -96,7 +98,7 @@ namespace PinManager {\n   bool isPinAllocated(byte gpio, PinOwner tag = PinOwner::None);\n   // will return false for reserved pins\n   bool isPinOk(byte gpio, bool output = true);\n-  \n+\n   bool isReadOnlyPin(byte gpio);\n \n   PinOwner getPinOwner(byte gpio);\ndiff --git a/wled00/set.cpp b/wled00/set.cpp\nindex 9d79467935..893081b986 100644\n--- a/wled00/set.cpp\n+++ b/wled00/set.cpp\n@@ -140,7 +140,7 @@ void handleSettingsSet(AsyncWebServerRequest *request, byte subPage)\n \n     unsigned colorOrder, type, skip, awmode, channelSwap, maPerLed;\n     unsigned length, start, maMax;\n-    uint8_t pins[5] = {255, 255, 255, 255, 255};\n+    uint8_t pins[OUTPUT_MAX_PINS] = {255, 255, 255, 255, 255};\n     String text;\n \n     // this will set global ABL max current used when per-port ABL is not used\ndiff --git a/wled00/wled.h b/wled00/wled.h\nindex 3f3fb27ca2..5362565929 100644\n--- a/wled00/wled.h\n+++ b/wled00/wled.h\n@@ -7,7 +7,7 @@\n  */\n \n // version code in format yymmddb (b = daily build)\n-#define VERSION 2412040\n+#define VERSION 2506160\n \n //uncomment this if you have a \"my_config.h\" file you'd like to use\n //#define WLED_USE_MY_CONFIG\ndiff --git a/wled00/wled_eeprom.cpp b/wled00/wled_eeprom.cpp\nindex fb63bc6460..e1309c94bb 100644\n--- a/wled00/wled_eeprom.cpp\n+++ b/wled00/wled_eeprom.cpp\n@@ -96,7 +96,7 @@ void loadSettingsFromEEPROM()\n   if (apHide > 1) apHide = 1;\n   uint16_t length = EEPROM.read(229) + ((EEPROM.read(398) << 8) & 0xFF00); //was ledCount\n   if (length > MAX_LEDS || length == 0) length = 30;\n-  uint8_t pins[5] = {2, 255, 255, 255, 255};\n+  uint8_t pins[OUTPUT_MAX_PINS] = {2, 255, 255, 255, 255};\n   uint8_t colorOrder = COL_ORDER_GRB;\n   if (lastEEPROMversion > 9) colorOrder = EEPROM.read(383);\n   if (colorOrder > COL_ORDER_GBR) colorOrder = COL_ORDER_GRB;\ndiff --git a/wled00/xml.cpp b/wled00/xml.cpp\nindex 40bd992443..dd3b4b1b95 100644\n--- a/wled00/xml.cpp\n+++ b/wled00/xml.cpp\n@@ -331,7 +331,7 @@ void getSettingsJS(byte subPage, Print& settingsScript)\n       char ma[4] = \"MA\"; ma[2] = offset+s; ma[3] = 0; //max per-port PSU current\n       char hs[4] = \"HS\"; hs[2] = offset+s; hs[3] = 0; //hostname (for network types, custom text for others)\n       settingsScript.print(F(\"addLEDs(1);\"));\n-      uint8_t pins[5];\n+      uint8_t pins[OUTPUT_MAX_PINS];\n       int nPins = bus->getPins(pins);\n       for (int i = 0; i < nPins; i++) {\n         lp[1] = '0'+i;\n@@ -457,8 +457,8 @@ void getSettingsJS(byte subPage, Print& settingsScript)\n     printSetFormCheckbox(settingsScript,PSTR(\"EM\"),e131Multicast);\n     printSetFormValue(settingsScript,PSTR(\"EU\"),e131Universe);\n #ifdef WLED_ENABLE_DMX\n-    settingsScript.print(SET_F(\"hideNoDMX();\"));  // hide \"not compiled in\" message    \n-#endif    \n+    settingsScript.print(SET_F(\"hideNoDMX();\"));  // hide \"not compiled in\" message\n+#endif\n #ifndef WLED_ENABLE_DMX_INPUT\n     settingsScript.print(SET_F(\"hideDMXInput();\"));  // hide \"dmx input\" settings\n #else\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Compile-Time Flags**: Change ESP32_FORUM_PINOUT and similar compile-time flags to runtime-selectable options (e.g., APA102 vs. WS2814). This would improve flexibility and simplify configurations for different boards.\n\n2. **Board Configuration**: Ensure compatibility of board = esp32dev with S3-specific configurations. A custom platform config for the S3 board may be necessary for optimal performance.\n\n3. **Error Resolution**: Address the redefinition warnings for \"ARDUINO_USB_CDC_ON_BOOT\" and resolve the missing sdkconfig.h error, which likely stems from incorrect platform configuration.\n\n4. **Binary Size Concerns**: Consider the impact of adding HUB75 panels on binary size, as current flash utilization is >95%. Prioritize critical features to avoid exceeding capacity.\n\n5. **Next Steps**: Evaluate community interest for this PR; maintain the \"keep\" label until a decision is reached."
      }
    ],
    "codediff_length": 43905
  },
  {
    "index": 23,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/usermods/audioreactive/audio_reactive.h b/usermods/audioreactive/audio_reactive.h\nindex ad449fc83a..9c463e0a19 100644\n--- a/usermods/audioreactive/audio_reactive.h\n+++ b/usermods/audioreactive/audio_reactive.h\n@@ -75,7 +75,7 @@ static uint8_t  soundAgc = 0;                   // Automagic gain control: 0 - n\n //static float    volumeSmth = 0.0f;              // either sampleAvg or sampleAgc depending on soundAgc; smoothed sample\n static float FFT_MajorPeak = 1.0f;              // FFT: strongest (peak) frequency\n static float FFT_Magnitude = 0.0f;              // FFT: volume (magnitude) of peak frequency\n-static bool samplePeak = false;      // Boolean flag for peak - used in effects. Responding routine may reset this flag. Auto-reset after strip.getMinShowDelay()\n+static bool samplePeak = false;      // Boolean flag for peak - used in effects. Responding routine may reset this flag. Auto-reset after strip.getFrameTime()\n static bool udpSamplePeak = false;   // Boolean flag for peak. Set at the same time as samplePeak, but reset by transmitAudioData\n static unsigned long timeOfPeak = 0; // time of last sample peak detection.\n static uint8_t fftResult[NUM_GEQ_CHANNELS]= {0};// Our calculated freq. channel result table to be used by effects\n@@ -536,8 +536,8 @@ static void detectSamplePeak(void) {\n #endif\n \n static void autoResetPeak(void) {\n-  uint16_t MinShowDelay = MAX(50, strip.getMinShowDelay());  // Fixes private class variable compiler error. Unsure if this is the correct way of fixing the root problem. -THATDONFC\n-  if (millis() - timeOfPeak > MinShowDelay) {          // Auto-reset of samplePeak after a complete frame has passed.\n+  uint16_t peakDelay = max(uint16_t(50), strip.getFrameTime());\n+  if (millis() - timeOfPeak > peakDelay) {          // Auto-reset of samplePeak after at least one complete frame has passed.\n     samplePeak = false;\n     if (audioSyncEnabled == 0) udpSamplePeak = false;  // this is normally reset by transmitAudioData\n   }\ndiff --git a/wled00/FX.h b/wled00/FX.h\nindex ad39a7c06d..c15500aa35 100644\n--- a/wled00/FX.h\n+++ b/wled00/FX.h\n@@ -46,6 +46,14 @@\n #define WLED_FPS         42\n #define FRAMETIME_FIXED  (1000/WLED_FPS)\n #define FRAMETIME        strip.getFrameTime()\n+#if defined(ARDUINO_ARCH_ESP32) && !defined(CONFIG_IDF_TARGET_ESP32C3) && !defined(CONFIG_IDF_TARGET_ESP32S2)\n+  #define MIN_FRAME_DELAY  2                                              // minimum wait between repaints, to keep other functions like WiFi alive \n+#elif defined(CONFIG_IDF_TARGET_ESP32S2) || defined(CONFIG_IDF_TARGET_ESP32C3)\n+  #define MIN_FRAME_DELAY  3                                              // S2/C3 are slower than normal esp32, and only have one core\n+#else\n+  #define MIN_FRAME_DELAY  8                                              // 8266 legacy MIN_SHOW_DELAY\n+#endif\n+#define FPS_UNLIMITED    0\n \n /* each segment uses 82 bytes of SRAM memory, so if you're application fails because of\n   insufficient memory, decreasing MAX_NUM_SEGMENTS may help */\n@@ -68,8 +76,6 @@\n   assuming each segment uses the same amount of data. 256 for ESP8266, 640 for ESP32. */\n #define FAIR_DATA_PER_SEG (MAX_SEGMENT_DATA / strip.getMaxSegments())\n \n-#define MIN_SHOW_DELAY   (_frametime < 16 ? 8 : 15)\n-\n #define NUM_COLORS       3 /* number of colors per segment */\n #define SEGMENT          strip._segments[strip.getCurrSegmentId()]\n #define SEGENV           strip._segments[strip.getCurrSegmentId()]\n@@ -739,6 +745,7 @@ class WS2812FX {  // 96 bytes\n       customMappingTable(nullptr),\n       customMappingSize(0),\n       _lastShow(0),\n+      _lastServiceShow(0),\n       _segment_index(0),\n       _mainSegment(0)\n     {\n@@ -837,7 +844,7 @@ class WS2812FX {  // 96 bytes\n       getMappedPixelIndex(uint16_t index) const;\n \n     inline uint16_t getFrameTime() const    { return _frametime; }        // returns amount of time a frame should take (in ms)\n-    inline uint16_t getMinShowDelay() const { return MIN_SHOW_DELAY; }    // returns minimum amount of time strip.service() can be delayed (constant)\n+    inline uint16_t getMinShowDelay() const { return MIN_FRAME_DELAY; }   // returns minimum amount of time strip.service() can be delayed (constant)\n     inline uint16_t getLength() const       { return _length; }           // returns actual amount of LEDs on a strip (2D matrix may have less LEDs than W*H)\n     inline uint16_t getTransition() const   { return _transitionDur; }    // returns currently set transition time (in ms)\n \n@@ -949,6 +956,7 @@ class WS2812FX {  // 96 bytes\n     uint16_t  customMappingSize;\n \n     unsigned long _lastShow;\n+    unsigned long _lastServiceShow;\n \n     uint8_t _segment_index;\n     uint8_t _mainSegment;\ndiff --git a/wled00/FX_fcn.cpp b/wled00/FX_fcn.cpp\nindex f45256f0fd..f4b46dade1 100644\n--- a/wled00/FX_fcn.cpp\n+++ b/wled00/FX_fcn.cpp\n@@ -1309,7 +1309,14 @@ void WS2812FX::finalizeInit() {\n void WS2812FX::service() {\n   unsigned long nowUp = millis(); // Be aware, millis() rolls over every 49 days\n   now = nowUp + timebase;\n-  if (nowUp - _lastShow < MIN_SHOW_DELAY || _suspend) return;\n+  if (_suspend) return;\n+  unsigned long elapsed = nowUp - _lastServiceShow;\n+\n+  if (elapsed <= MIN_FRAME_DELAY) return;                                        // keep wifi alive - no matter if triggered or unlimited\n+  if ( !_triggered && (_targetFps != FPS_UNLIMITED)) {                           // unlimited mode = no frametime\n+    if (elapsed < _frametime) return;                                            // too early for service\n+  }\n+\n   bool doShow = false;\n \n   _isServicing = true;\n@@ -1326,7 +1333,7 @@ void WS2812FX::service() {\n     if (!seg.isActive()) continue;\n \n     // last condition ensures all solid segments are updated at the same time\n-    if (nowUp > seg.next_time || _triggered || (doShow && seg.mode == FX_MODE_STATIC))\n+    if (nowUp >= seg.next_time || _triggered || (doShow && seg.mode == FX_MODE_STATIC))\n     {\n       doShow = true;\n       unsigned frameDelay = FRAMETIME;\n@@ -1376,15 +1383,16 @@ void WS2812FX::service() {\n   _triggered = false;\n \n   #ifdef WLED_DEBUG\n-  if (millis() - nowUp > _frametime) DEBUG_PRINTF_P(PSTR(\"Slow effects %u/%d.\\n\"), (unsigned)(millis()-nowUp), (int)_frametime);\n+  if ((_targetFps != FPS_UNLIMITED) && (millis() - nowUp > _frametime)) DEBUG_PRINTF_P(PSTR(\"Slow effects %u/%d.\\n\"), (unsigned)(millis()-nowUp), (int)_frametime);\n   #endif\n   if (doShow) {\n     yield();\n     Segment::handleRandomPalette(); // slowly transition random palette; move it into for loop when each segment has individual random palette\n     show();\n+    _lastServiceShow = nowUp; // update timestamp, for precise FPS control\n   }\n   #ifdef WLED_DEBUG\n-  if (millis() - nowUp > _frametime) DEBUG_PRINTF_P(PSTR(\"Slow strip %u/%d.\\n\"), (unsigned)(millis()-nowUp), (int)_frametime);\n+  if ((_targetFps != FPS_UNLIMITED) && (millis() - nowUp > _frametime)) DEBUG_PRINTF_P(PSTR(\"Slow strip %u/%d.\\n\"), (unsigned)(millis()-nowUp), (int)_frametime);\n   #endif\n }\n \n@@ -1404,13 +1412,13 @@ void WS2812FX::show() {\n   // avoid race condition, capture _callback value\n   show_callback callback = _callback;\n   if (callback) callback();\n+  unsigned long showNow = millis();\n \n   // some buses send asynchronously and this method will return before\n   // all of the data has been sent.\n   // See https://github.com/Makuna/NeoPixelBus/wiki/ESP32-NeoMethods#neoesp32rmt-methods\n   BusManager::show();\n \n-  unsigned long showNow = millis();\n   size_t diff = showNow - _lastShow;\n   size_t fpsCurr = 200;\n   if (diff > 0) fpsCurr = 1000 / diff;\n@@ -1436,8 +1444,9 @@ uint16_t WS2812FX::getFps() const {\n }\n \n void WS2812FX::setTargetFps(uint8_t fps) {\n-  if (fps > 0 && fps <= 120) _targetFps = fps;\n-  _frametime = 1000 / _targetFps;\n+  if (fps <= 250) _targetFps = fps;\n+  if (_targetFps > 0) _frametime = 1000 / _targetFps;\n+  else _frametime = MIN_FRAME_DELAY;     // unlimited mode\n }\n \n void WS2812FX::setMode(uint8_t segid, uint8_t m) {\n@@ -1485,7 +1494,7 @@ void WS2812FX::setBrightness(uint8_t b, bool direct) {\n   BusManager::setBrightness(b);\n   if (!direct) {\n     unsigned long t = millis();\n-    if (_segments[0].next_time > t + 22 && t - _lastShow > MIN_SHOW_DELAY) trigger(); //apply brightness change immediately if no refresh soon\n+    if (_segments[0].next_time > t + 22 && t - _lastShow > MIN_FRAME_DELAY) trigger(); //apply brightness change immediately if no refresh soon\n   }\n }\n \ndiff --git a/wled00/data/settings_leds.htm b/wled00/data/settings_leds.htm\nindex 6be5becd10..b467d5b9b6 100644\n--- a/wled00/data/settings_leds.htm\n+++ b/wled00/data/settings_leds.htm\n@@ -380,6 +380,11 @@\n \t\t\tgId('psu').innerHTML = s;\n \t\t\tgId('psu2').innerHTML = s2;\n \t\t\tgId(\"json\").style.display = d.Sf.IT.value==8 ? \"\" : \"none\";\n+\n+\t\t\t// show/hide FPS warning messages\n+\t\t\tgId('fpsNone').style.display = (d.Sf.FR.value == 0) ? 'block':'none';\n+\t\t\tgId('fpsWarn').style.display = (d.Sf.FR.value == 0) || (d.Sf.FR.value >= 80) ? 'block':'none';\n+\t\t\tgId('fpsHigh').style.display = (d.Sf.FR.value >= 80) ? 'block':'none';\n \t\t}\n \t\tfunction lastEnd(i) {\n \t\t\tif (i-- < 1) return 0;\n@@ -870,7 +875,10 @@ <h3>Advanced</h3>\n \t\t\t<option value=\"2\">Linear (never wrap)</option>\n \t\t\t<option value=\"3\">None (not recommended)</option>\n \t\t</select><br>\n-\t\tTarget refresh rate: <input type=\"number\" class=\"s\" min=\"1\" max=\"120\" name=\"FR\" required> FPS\n+\t\tTarget refresh rate: <input type=\"number\" class=\"s\" min=\"0\" max=\"250\" name=\"FR\" oninput=\"UI()\" required> FPS\n+\t\t<div id=\"fpsNone\" class=\"warn\" style=\"display: none;\">&#9888; Unlimited FPS Mode  is experimental &#9888;<br></div>\n+\t\t<div id=\"fpsHigh\" class=\"warn\" style=\"display: none;\">&#9888; High FPS Mode is experimental.<br></div>\n+\t\t<div id=\"fpsWarn\" class=\"warn\" style=\"display: none;\">Please <a class=\"lnk\" href=\"sec#backup\">backup</a> WLED configuration and presets first!<br></div>\n \t\t<hr class=\"sml\">\n \t\t<div id=\"cfg\">Config template: <input type=\"file\" name=\"data2\" accept=\".json\"><button type=\"button\" class=\"sml\" onclick=\"loadCfg(d.Sf.data2)\">Apply</button><br></div>\n \t\t<hr>\ndiff --git a/wled00/data/settings_sec.htm b/wled00/data/settings_sec.htm\nindex fa75882c0e..5181858d52 100644\n--- a/wled00/data/settings_sec.htm\n+++ b/wled00/data/settings_sec.htm\n@@ -57,7 +57,7 @@ <h2>Security & Update setup</h2>\n \t\t<h3>Software Update</h3>\n \t\t<button type=\"button\" onclick=\"U()\">Manual OTA Update</button><br>\n \t\tEnable ArduinoOTA: <input type=\"checkbox\" name=\"AO\">\n-\t\t<hr>\n+\t\t<hr id=\"backup\">\n \t\t<h3>Backup & Restore</h3>\n \t\t<div class=\"warn\">&#9888; Restoring presets/configuration will OVERWRITE your current presets/configuration.<br>\n \t\tIncorrect upload or configuration may require a factory reset or re-flashing of your ESP.</div>\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **FPS Calculation Adjustments**: Change the FPS calculation in `strip.show()` to use `esp_timer_get_time()` for improved precision; maintain fallback code for ESP8266. Avoid using `ESP.getCycleCount()` due to rollover concerns.\n\n2. **Effect Scheduling Optimization**: Current effect scheduling logic is too synchronous. Consider redesigning to handle variable frame rates dynamically without syncing all effects simultaneously, which could introduce stuttering.\n\n3. **PWM Update Rate**: Verify if the 8266 can handle analog PWM updates every 8ms due to potential high FPS settings.\n\n4. **Warning for High FPS**: Implement a user warning for setting FPS above 70 to prevent potential performance issues.\n\n5. **Testing on C3**: Run tests for the C3 version to evaluate behavior under high FPS conditions and check for any UI slowdown or preset saving issues."
      }
    ],
    "codediff_length": 10720
  },
  {
    "index": 24,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/pio-scripts/inject_syslog_ui.py b/pio-scripts/inject_syslog_ui.py\nnew file mode 100644\nindex 0000000000..08077cf636\n--- /dev/null\n+++ b/pio-scripts/inject_syslog_ui.py\n@@ -0,0 +1,153 @@\n+# pio-scripts/inject_syslog_ui.py\r\n+\r\n+\"\"\"\r\n+PlatformIO build script to conditionally inject Syslog UI elements into the settings HTML file.\r\n+\r\n+This script:\r\n+1. Injects Syslog UI elements when WLED_ENABLE_SYSLOG is defined in build flags\r\n+2. Restores the original HTML file after build completion\r\n+3. Tracks state between builds to force UI rebuilds when necessary\r\n+\"\"\"\r\n+\r\n+import os, re, shutil\r\n+from SCons.Script import Import\r\n+\r\n+Import(\"env\")\r\n+\r\n+# detect full vs. partial compile\r\n+is_full_build = env.get(\"PIOENV\") is not None\r\n+\r\n+# Track the state between builds\r\n+def get_previous_syslog_state(project_dir):\r\n+    state_file = os.path.join(project_dir, \"wled00/data/.syslog_state\")\r\n+    if os.path.exists(state_file):\r\n+        with open(state_file, 'r') as f:\r\n+            return f.read().strip() == \"1\"\r\n+    return None  # None means no previous state recorded\r\n+\r\n+def set_syslog_state(project_dir, enabled):\r\n+    state_file = os.path.join(project_dir, \"wled00/data/.syslog_state\")\r\n+    with open(state_file, 'w') as f:\r\n+        f.write(\"1\" if enabled else \"0\")\r\n+\r\n+# This is the HTML we want to inject\r\n+SYSLOG_HTML = \"\"\"<h3>Syslog</h3>\r\n+<div id=\"Syslog\">\r\n+  Enable Syslog: <input type=\"checkbox\" name=\"SL_en\"><br>\r\n+  Host: <input type=\"text\" name=\"SL_host\" maxlength=\"32\"><br>\r\n+  Port: <input type=\"number\" name=\"SL_port\" min=\"1\" max=\"65535\" value=\"%SL_port%\"><br>\r\n+</div>\"\"\"\r\n+\r\n+def inject_syslog_ui(source, target, env, retry_count=0):\r\n+    print(\"\\033[44m==== inject_syslog_ui.py (PRE BUILD) ====\\033[0m\")\r\n+    if not is_full_build:\r\n+        print(\"\\033[43mNot a full build, skipping Syslog UI operations.\\033[0m\")\r\n+        return\r\n+\r\n+    # Check for the define in BUILD_FLAGS\r\n+    build_flags = env.get(\"BUILD_FLAGS\", \"\")\r\n+    if isinstance(build_flags, list):\r\n+        build_flags = \" \".join(build_flags)\r\n+    has_syslog = bool(re.search(r'-D\\s*WLED_ENABLE_SYSLOG\\b', build_flags))\r\n+\r\n+    project_dir = env.subst(\"$PROJECT_DIR\")\r\n+    html_path = os.path.join(project_dir, \"wled00/data/settings_sync.htm\")\r\n+    bak = html_path + \".backup\"\r\n+\r\n+    # Detect state change \u2192 touch to force rebuild\r\n+    prev = get_previous_syslog_state(project_dir)\r\n+    if prev is not None and prev != has_syslog:\r\n+        print(f\"\\033[43mSYSLOG state changed from {prev} to {has_syslog}, forcing UI rebuild.\\033[0m\")\r\n+        if os.path.exists(html_path):\r\n+            with open(html_path, 'a'):\r\n+                os.utime(html_path, None)\r\n+\r\n+    set_syslog_state(project_dir, has_syslog)\r\n+\r\n+    if not has_syslog:\r\n+        print(\"\\033[43mWLED_ENABLE_SYSLOG not defined, skipping injection.\\033[0m\")\r\n+        # restore if backup exists\r\n+        if os.path.exists(bak):\r\n+            print(\"Restoring original file from backup...\")\r\n+            shutil.copy2(bak, html_path)\r\n+            os.remove(bak)\r\n+        return\r\n+\r\n+    # backup + inject only once\r\n+    if not os.path.exists(bak):\r\n+        print(\"Backing up and injecting Syslog UI...\")\r\n+        shutil.copyfile(html_path, bak)\r\n+        try:\r\n+            with open(html_path, 'r', encoding='utf8') as f:\r\n+                original = f.read()\r\n+            modified = original\r\n+\r\n+            # replace the single comment with HTML\r\n+            if '<!-- SYSLOG-INJECT -->' in modified:\r\n+                modified = modified.replace('<!-- SYSLOG-INJECT -->', SYSLOG_HTML)\r\n+            else:\r\n+                # insert before last <hr>\r\n+                idx = modified.rfind('<hr>')\r\n+                if idx == -1:\r\n+                    print(\"\\033[41mCould not find <hr> to insert Syslog UI!\\033[0m\")\r\n+                    # Clean up backup since injection failed\r\n+                    if os.path.exists(bak):\r\n+                        os.remove(bak)\r\n+                    return\r\n+                modified = (\r\n+                    modified[:idx]\r\n+                    + SYSLOG_HTML + '\\n'\r\n+                    + modified[idx:]\r\n+                )\r\n+\r\n+            with open(html_path, 'w', encoding='utf8') as f:\r\n+                f.write(modified)\r\n+            print(\"\\033[42mSyslog UI injected successfully!\\033[0m\")\r\n+            \r\n+        except (IOError, OSError) as e:\r\n+            print(f\"\\033[41mFile operation error during injection: {e}\\033[0m\")\r\n+            # injection failed \u2192 remove backup so we'll retry next time\r\n+            if os.path.exists(bak):\r\n+                os.remove(bak)\r\n+        except Exception as e:\r\n+            print(f\"\\033[41mUnexpected error during injection: {e}\\033[0m\")\r\n+            # injection failed \u2192 remove backup so we\u2019ll retry next time\r\n+            if os.path.exists(bak):\r\n+                os.remove(bak)\r\n+    else:\r\n+        print(\"Backup exists; assume already injected.\")\r\n+        # verify that SYSLOG markers really are in the file\r\n+        with open(html_path, 'r', encoding='utf8') as f:\r\n+            content = f.read()\r\n+        if '<h3>Syslog</h3>' not in content:\r\n+            print(\"Backup exists but SYSLOG markers missing\u2014forcing re-injection.\")\r\n+            os.remove(bak)\r\n+            # only retry up to 3 times\r\n+            if retry_count < 3:\r\n+                # Add a small delay before retrying\r\n+                import time\r\n+                time.sleep(0.5 * (retry_count + 1))  # Increasing delay with each retry\r\n+                inject_syslog_ui(source, target, env, retry_count + 1)\r\n+            else:\r\n+                print(\"\\033[41mToo many retry attempts. Manual intervention required.\\033[0m\")\r\n+        else:\r\n+            print(\"Backup exists and markers found; already injected.\")\r\n+\r\n+def restore_syslog_ui(source, target, env):\r\n+    print(\"\\033[44m==== inject_syslog_ui.py (POST BUILD) ====\\033[0m\")\r\n+    project_dir = env.subst(\"$PROJECT_DIR\")\r\n+    html_path = os.path.join(project_dir, \"wled00/data/settings_sync.htm\")\r\n+    bak = html_path + \".backup\"\r\n+\r\n+    # restore only if backup file is present\r\n+    if os.path.exists(bak):\r\n+        print(\"Restoring original file from backup...\")\r\n+        shutil.copy2(bak, html_path)\r\n+        os.remove(bak)\r\n+\r\n+# always register the post-action on checkprogsize so it runs every build\r\n+env.AddPostAction(\"checkprogsize\", restore_syslog_ui)\r\n+\r\n+# only inject on full build\r\n+if is_full_build:\r\n+    inject_syslog_ui(None, None, env)\n\\ No newline at end of file\ndiff --git a/platformio.ini b/platformio.ini\nindex a7485244cd..8cee7ea9b8 100644\n--- a/platformio.ini\n+++ b/platformio.ini\n@@ -115,6 +115,7 @@ extra_scripts =\n   post:pio-scripts/strip-floats.py\n   pre:pio-scripts/user_config_copy.py\n   pre:pio-scripts/load_usermods.py\n+  pre:pio-scripts/inject_syslog_ui.py\n   pre:pio-scripts/build_ui.py\n   ; post:pio-scripts/obj-dump.py  ;; convenience script to create a disassembly dump of the firmware (hardcore debugging)\n \ndiff --git a/wled00/bus_manager.h b/wled00/bus_manager.h\nindex 0570cc2d6c..b72560cddd 100644\n--- a/wled00/bus_manager.h\n+++ b/wled00/bus_manager.h\n@@ -24,7 +24,10 @@ make_unique(Args&&... args)\n #endif\n \n // enable additional debug output\n-#if defined(WLED_DEBUG_HOST)\n+#if defined(WLED_ENABLE_SYSLOG)\n+  #include \"syslog.h\"\n+  #define DEBUGOUT Syslog\n+#elif defined(WLED_DEBUG_HOST)\n   #include \"net_debug.h\"\n   #define DEBUGOUT NetDebug\n #else\ndiff --git a/wled00/cfg.cpp b/wled00/cfg.cpp\nindex fa0397fc65..5e06944920 100644\n--- a/wled00/cfg.cpp\n+++ b/wled00/cfg.cpp\n@@ -536,6 +536,13 @@ bool deserializeConfig(JsonObject doc, bool fromFS) {\n     CJSON(hueIP[i], if_hue_ip[i]);\n #endif\n \n+#ifdef WLED_ENABLE_SYSLOG\n+  JsonObject if_syslog = interfaces[\"syslog\"];\n+  CJSON(syslogEnabled, if_syslog[\"en\"]);\n+  getStringFromJson(syslogHost, if_syslog[F(\"host\")], 33);\n+  CJSON(syslogPort, if_syslog[\"port\"]);\n+#endif\n+\n   JsonObject if_ntp = interfaces[F(\"ntp\")];\n   CJSON(ntpEnabled, if_ntp[\"en\"]);\n   getStringFromJson(ntpServerName, if_ntp[F(\"host\")], 33); // \"1.wled.pool.ntp.org\"\n@@ -1051,6 +1058,13 @@ void serializeConfig(JsonObject root) {\n   }\n #endif\n \n+#ifdef WLED_ENABLE_SYSLOG\n+  JsonObject if_syslog = interfaces.createNestedObject(\"syslog\");\n+  if_syslog[\"en\"]    = syslogEnabled;\n+  if_syslog[\"host\"]  = syslogHost;\n+  if_syslog[\"port\"]  = syslogPort;\n+#endif\n+\n   JsonObject if_ntp = interfaces.createNestedObject(\"ntp\");\n   if_ntp[\"en\"] = ntpEnabled;\n   if_ntp[F(\"host\")] = ntpServerName;\ndiff --git a/wled00/data/settings_sync.htm b/wled00/data/settings_sync.htm\nindex ca6c0fb59c..983d0a6cbc 100644\n--- a/wled00/data/settings_sync.htm\n+++ b/wled00/data/settings_sync.htm\n@@ -237,6 +237,7 @@ <h3>Serial</h3>\n </select><br>\n <i>Keep at 115200 to use Improv. Some boards may not support high rates.</i>\n </div>\n+<!-- SYSLOG-INJECT -->\n <hr>\n <button type=\"button\" onclick=\"B()\">Back</button><button type=\"submit\">Save</button>\n </form>\ndiff --git a/wled00/json.cpp b/wled00/json.cpp\nindex c09b543f1c..ce9b3e7b8c 100644\n--- a/wled00/json.cpp\n+++ b/wled00/json.cpp\n@@ -298,7 +298,11 @@ bool deserializeState(JsonObject root, byte callMode, byte presetId)\n   bool stateResponse = root[F(\"v\")] | false;\n \n   #if defined(WLED_DEBUG) && defined(WLED_DEBUG_HOST)\n-  netDebugEnabled = root[F(\"debug\")] | netDebugEnabled;\n+    netDebugEnabled = root[F(\"debug\")] | netDebugEnabled;\n+  #elif defined(WLED_DEBUG) && defined(WLED_ENABLE_SYSLOG)\n+    syslogEnabled = root[F(\"debug\")] | syslogEnabled;\n+    configNeedsWrite = true;\n+    DEBUG_PRINTF_P(PSTR(\"Syslog: %s\\n\"), syslogEnabled ? PSTR(\"ENABLED\") : PSTR(\"DISABLED\") );\n   #endif\n \n   bool onBefore = bri;\n@@ -781,6 +785,9 @@ void serializeInfo(JsonObject root)\n     #ifdef WLED_DEBUG_HOST\n     os |= 0x0100;\n     if (!netDebugEnabled) os &= ~0x0080;\n+    #elif defined(WLED_ENABLE_SYSLOG)\n+    os |= 0x0100;\n+    if (!syslogEnabled) os &= ~0x0080;\n     #endif\n   #endif\n   #ifndef WLED_DISABLE_ALEXA\ndiff --git a/wled00/set.cpp b/wled00/set.cpp\nindex 725875023e..1db411af47 100644\n--- a/wled00/set.cpp\n+++ b/wled00/set.cpp\n@@ -472,6 +472,19 @@ void handleSettingsSet(AsyncWebServerRequest *request, byte subPage)\n     t = request->arg(F(\"BD\")).toInt();\n     if (t >= 96 && t <= 15000) serialBaud = t;\n     updateBaudRate(serialBaud *100);\n+\n+    #ifdef WLED_ENABLE_SYSLOG\n+    syslogEnabled   = request->hasArg(F(\"SL_en\"));\n+    strlcpy(syslogHost, request->arg(F(\"SL_host\")).c_str(), sizeof(syslogHost));\n+\n+    t = request->arg(F(\"SL_port\")).toInt();\n+    if (t > 0) syslogPort = t;\n+    \n+    Syslog.begin(syslogHost, syslogPort,\n+      syslogFacility, syslogSeverity, syslogProtocol);\n+\n+    Syslog.setAppName(\"WLED\");\n+    #endif\n   }\n \n   //TIME\ndiff --git a/wled00/syslog.cpp b/wled00/syslog.cpp\nnew file mode 100644\nindex 0000000000..384a937e4e\n--- /dev/null\n+++ b/wled00/syslog.cpp\n@@ -0,0 +1,195 @@\n+#include \"wled.h\"\r\n+#ifdef WLED_ENABLE_SYSLOG\r\n+\r\n+#include \"syslog.h\"\r\n+\r\n+SyslogPrinter::SyslogPrinter() : \r\n+  _lastOperationSucceeded(true),\r\n+  _lastErrorMessage(\"\"),\r\n+  _facility(SYSLOG_LOCAL0), \r\n+  _severity(SYSLOG_DEBUG), \r\n+  _protocol(SYSLOG_PROTO_BSD),\r\n+  _appName(\"WLED\"),\r\n+  _bufferIndex(0) {}\r\n+\r\n+void SyslogPrinter::begin(const char* host, uint16_t port,\r\n+\t\t\t\t\t  uint8_t facility, uint8_t severity, uint8_t protocol) {\r\n+\r\n+  DEBUG_PRINTF_P(PSTR(\"===== WLED SYSLOG CONFIGURATION =====\\n\"));\r\n+  DEBUG_PRINTF_P(PSTR(\" Hostname:  %s\\n\"), host);\r\n+  DEBUG_PRINTF_P(PSTR(\" Cached IP: %s\\n\"), syslogHostIP.toString().c_str());\r\n+  DEBUG_PRINTF_P(PSTR(\" Port:      %u\\n\"), (unsigned)port);\r\n+  DEBUG_PRINTF_P(PSTR(\"======================================\\n\"));\r\n+\r\n+  strlcpy(syslogHost, host, sizeof(syslogHost));\r\n+  syslogPort = port;\r\n+  _facility = facility;\r\n+  _severity = severity;\r\n+  _protocol = protocol;\r\n+\r\n+  // clear any cached IP so resolveHostname() will run next write()  \r\n+  syslogHostIP = IPAddress(0,0,0,0);\r\n+}\r\n+\r\n+void SyslogPrinter::setAppName(const String &appName) {\r\n+  _appName = appName;\r\n+}\r\n+\r\n+bool SyslogPrinter::resolveHostname() {\r\n+  if (!WLED_CONNECTED || !syslogEnabled) return false;\r\n+  \r\n+  // If we already have an IP or can parse the hostname as an IP, use that\r\n+  if (syslogHostIP || syslogHostIP.fromString(syslogHost)) {\r\n+    return true;\r\n+  }\r\n+  \r\n+  // Otherwise resolve the hostname\r\n+  #ifdef ESP8266\r\n+    WiFi.hostByName(syslogHost, syslogHostIP, 750);\r\n+  #else\r\n+    #ifdef WLED_USE_ETHERNET\r\n+      ETH.hostByName(syslogHost, syslogHostIP);\r\n+    #else\r\n+      WiFi.hostByName(syslogHost, syslogHostIP);\r\n+    #endif\r\n+  #endif\r\n+  \r\n+  return syslogHostIP != IPAddress(0, 0, 0, 0);\r\n+}\r\n+\r\n+void SyslogPrinter::flushBuffer() {\r\n+  if (_bufferIndex == 0) return;\r\n+\r\n+  // Skip pure \"#015\" lines\r\n+  if (_bufferIndex == 4 && memcmp(_buffer, \"#015\", 4) == 0) {\r\n+    _bufferIndex = 0;\r\n+    return;\r\n+  }\r\n+\r\n+  // Check if the message contains only whitespace\r\n+  bool onlyWhitespace = true;\r\n+  for (size_t i = 0; i < _bufferIndex; i++) {\r\n+    if (_buffer[i] != ' ' && _buffer[i] != '\\t') {\r\n+      onlyWhitespace = false;\r\n+      break;\r\n+    }\r\n+  }\r\n+  if (onlyWhitespace) {\r\n+    _bufferIndex = 0;\r\n+    return;\r\n+  }\r\n+\r\n+  // Null-terminate\r\n+  _buffer[_bufferIndex] = '\\0';\r\n+\r\n+  // Send the buffer with default severity\r\n+  write((const uint8_t*)_buffer, _bufferIndex, _severity);\r\n+\r\n+  // Reset buffer index\r\n+  _bufferIndex = 0;\r\n+}\r\n+\r\n+size_t SyslogPrinter::write(uint8_t c) {\r\n+  // Store in buffer regardless of connection status\r\n+  if (_bufferIndex < sizeof(_buffer) - 1) {\r\n+    _buffer[_bufferIndex++] = c;\r\n+  }\r\n+  \r\n+  // If newline or buffer full, flush buffer\r\n+  if (c == '\\n' || _bufferIndex >= sizeof(_buffer) - 1) {\r\n+    flushBuffer();\r\n+  }\r\n+  \r\n+  return 1;\r\n+}\r\n+\r\n+size_t SyslogPrinter::write(const uint8_t *buf, size_t size) {\r\n+  return write(buf, size, _severity);\r\n+}\r\n+\r\n+size_t SyslogPrinter::write(const uint8_t *buf, size_t size, uint8_t severity) {\r\n+  _lastOperationSucceeded = true;\r\n+  if (!WLED_CONNECTED) {\r\n+    _lastOperationSucceeded = false;\r\n+    _lastErrorMessage = F(\"Network not connected\");\r\n+    return 0;\r\n+  }\r\n+  if (buf == nullptr) {\r\n+    _lastOperationSucceeded = false;\r\n+    _lastErrorMessage = F(\"Null buffer provided\");\r\n+    return 0;\r\n+  }\r\n+  if (!syslogEnabled) {\r\n+    _lastOperationSucceeded = false;\r\n+    _lastErrorMessage = F(\"Syslog is disabled\");\r\n+    return 0;\r\n+  }\r\n+  if (!resolveHostname()) {\r\n+    _lastOperationSucceeded = false;\r\n+    _lastErrorMessage = F(\"Failed to resolve hostname\");\r\n+    return 0;\r\n+  }\r\n+\r\n+  // Check for special case - literal \"#015\" string\r\n+  if (size >= 4 && buf[0] == '#' && buf[1] == '0' && buf[2] == '1' && buf[3] == '5') {\r\n+    return size; // Skip sending this message\r\n+  }\r\n+\r\n+  // Skip empty messages\r\n+  if (size == 0) return 0;\r\n+\r\n+  // Check if the message contains only whitespace\r\n+  bool onlyWhitespace = true;\r\n+  for (size_t i = 0; i < size; i++) {\r\n+    if (buf[i] != ' ' && buf[i] != '\\t' && buf[i] != '\\r' && buf[i] != '\\n') {\r\n+      onlyWhitespace = false;\r\n+      break;\r\n+    }\r\n+  }\r\n+  if (onlyWhitespace) return size; // Skip sending this message\r\n+\r\n+  syslogUdp.beginPacket(syslogHostIP, syslogPort);\r\n+  \r\n+  // Calculate priority value\r\n+  uint8_t pri = (_facility << 3) | severity;\r\n+\r\n+  // Add hostname (replacing spaces with underscores) and app name\r\n+  String cleanHostname = String(serverDescription);\r\n+  cleanHostname.replace(' ', '_');\r\n+\r\n+  // Note: Only BSD protocol is currently implemented\r\n+  syslogUdp.printf(\"<%d>\", pri);\r\n+  \r\n+  if (ntpEnabled && ntpConnected) {\r\n+    // Month abbreviation\r\n+    static const char* const months[] = {\r\n+      \"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\r\n+      \"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"\r\n+    };\r\n+\r\n+    syslogUdp.printf(\"%s %2d %02d:%02d:%02d \", \r\n+                    months[month(localTime) - 1], \r\n+                    day(localTime),\r\n+                    hour(localTime), \r\n+                    minute(localTime), \r\n+                    second(localTime));\r\n+  } else {\r\n+    // No valid time available\r\n+    syslogUdp.print(F(\"Jan 01 00:00:00 \"));\r\n+  }\r\n+  \r\n+  // Add hostname and app name\r\n+  syslogUdp.print(cleanHostname);\r\n+  syslogUdp.print(\" \");\r\n+  syslogUdp.print(_appName);\r\n+  syslogUdp.print(\": \");\r\n+  \r\n+  // Add message content\r\n+  size = syslogUdp.write(buf, size);\r\n+  \r\n+  syslogUdp.endPacket();\r\n+  return size;\r\n+}\r\n+\r\n+SyslogPrinter Syslog;\r\n+#endif // WLED_ENABLE_SYSLOG\n\\ No newline at end of file\ndiff --git a/wled00/syslog.h b/wled00/syslog.h\nnew file mode 100644\nindex 0000000000..98b4e39134\n--- /dev/null\n+++ b/wled00/syslog.h\n@@ -0,0 +1,59 @@\n+#ifndef WLED_SYSLOG_H\r\n+#define WLED_SYSLOG_H\r\n+#include <WString.h>\r\n+#include <WiFiUdp.h>\r\n+\r\n+// Buffer management\r\n+#ifndef SYSLOG_BUFFER_SIZE\r\n+  #define SYSLOG_BUFFER_SIZE 128\r\n+#endif\r\n+\r\n+#define SYSLOG_LOCAL0   \t16 // local use 0\r\n+#define SYSLOG_DEBUG    7  // Debug: debug-level messages\r\n+\r\n+// Syslog protocol formats - commented out but preserved\r\n+#define SYSLOG_PROTO_BSD       0  // Legacy BSD format (RFC 3164)\r\n+\r\n+class SyslogPrinter : public Print {\r\n+  private:\r\n+    WiFiUDP syslogUdp; // needs to be here otherwise UDP messages get truncated upon destruction\r\n+    IPAddress syslogHostIP;\r\n+    bool resolveHostname();\r\n+    bool _lastOperationSucceeded;\r\n+    String _lastErrorMessage;\r\n+\r\n+    // Syslog configuration - using globals from wled.h\r\n+    uint8_t _facility;  // Internal copy of syslogFacility (from wled.h), fixed to SYSLOG_LOCAL0\r\n+    uint8_t _severity;  // Internal copy of syslogSeverity (from wled.h), fixed to SYSLOG_DEBUG\r\n+    uint8_t _protocol;  // Internal copy of syslogProtocol (from wled.h), fixed to SYSLOG_PROTO_BSD\r\n+    String _appName;\r\n+\r\n+    char _buffer[SYSLOG_BUFFER_SIZE]; // Buffer for collecting characters\r\n+\r\n+    size_t _bufferIndex;\r\n+    void flushBuffer();\r\n+\r\n+  public:\r\n+    SyslogPrinter();\r\n+\tvoid begin(const char* host, uint16_t port,\r\n+               uint8_t facility = SYSLOG_LOCAL0,\r\n+               uint8_t severity = SYSLOG_DEBUG,\r\n+               uint8_t protocol = SYSLOG_PROTO_BSD);\r\n+    void setAppName(const String &appName);\r\n+\r\n+    // Print interface implementation\r\n+    virtual size_t write(uint8_t c);\r\n+    virtual size_t write(const uint8_t *buf, size_t size);\r\n+\r\n+    // Severity override for specific messages\r\n+    size_t write(const uint8_t *buf, size_t size, uint8_t severity);\r\n+\r\n+    // Error handling\r\n+    bool lastOperationSucceeded() const { return _lastOperationSucceeded; }\r\n+    String getLastErrorMessage() const { return _lastErrorMessage; }\r\n+};\r\n+\r\n+// Default instance\r\n+extern SyslogPrinter Syslog;\r\n+\r\n+#endif\n\\ No newline at end of file\ndiff --git a/wled00/wled.cpp b/wled00/wled.cpp\nindex cc338d23f2..97d092ba61 100644\n--- a/wled00/wled.cpp\n+++ b/wled00/wled.cpp\n@@ -329,7 +329,7 @@ void WLED::setup()\n   #if defined(WLED_DEBUG) && defined(ARDUINO_ARCH_ESP32) && (defined(CONFIG_IDF_TARGET_ESP32S2) || defined(CONFIG_IDF_TARGET_ESP32C3) || ARDUINO_USB_CDC_ON_BOOT)\n   delay(2500);  // allow CDC USB serial to initialise\n   #endif\n-  #if !defined(WLED_DEBUG) && defined(ARDUINO_ARCH_ESP32) && !defined(WLED_DEBUG_HOST) && ARDUINO_USB_CDC_ON_BOOT\n+  #if !defined(WLED_DEBUG) && defined(ARDUINO_ARCH_ESP32) && !defined(WLED_DEBUG_HOST) && !defined(WLED_ENABLE_SYSLOG) && ARDUINO_USB_CDC_ON_BOOT\n   Serial.setDebugOutput(false); // switch off kernel messages when using USBCDC\n   #endif\n   DEBUG_PRINTLN();\n@@ -387,7 +387,7 @@ void WLED::setup()\n   usePWMFixedNMI(); // link the NMI fix\n #endif\n \n-#if defined(WLED_DEBUG) && !defined(WLED_DEBUG_HOST)\n+#if defined(WLED_DEBUG) && !defined(WLED_DEBUG_HOST) && !defined(WLED_ENABLE_SYSLOG)\n   PinManager::allocatePin(hardwareTX, true, PinOwner::DebugOut); // TX (GPIO1 on ESP32) reserved for debug output\n #endif\n #ifdef WLED_ENABLE_DMX //reserve GPIO2 as hardcoded DMX pin\n@@ -422,6 +422,13 @@ void WLED::setup()\n   WLED_SET_AP_SSID(); // otherwise it is empty on first boot until config is saved\n   multiWiFi.push_back(WiFiConfig(CLIENT_SSID,CLIENT_PASS)); // initialise vector with default WiFi\n \n+#ifdef WLED_ENABLE_SYSLOG\n+  // Configure and initialize Syslog client\n+  Syslog.begin(syslogHost, syslogPort,\n+    syslogFacility, syslogSeverity, syslogProtocol);\n+  Syslog.setAppName(\"WLED\");\n+#endif\n+\n   DEBUG_PRINTLN(F(\"Reading config\"));\n   deserializeConfigFromFS();\n   DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), ESP.getFreeHeap());\ndiff --git a/wled00/wled.h b/wled00/wled.h\nindex f8dc1252a8..e7a3c7a2fa 100644\n--- a/wled00/wled.h\n+++ b/wled00/wled.h\n@@ -964,7 +964,24 @@ WLED_GLOBAL JsonDocument *pDoc _INIT(&gDoc);\n WLED_GLOBAL volatile uint8_t jsonBufferLock _INIT(0);\n \n // enable additional debug output\n-#if defined(WLED_DEBUG_HOST)\n+#if defined(WLED_ENABLE_SYSLOG)\n+  #include \"syslog.h\"\n+  // On the host side, use a standard syslog server or tools like rsyslog\n+  // use -D WLED_ENABLE_SYSLOG and -D WLED_DEBUG\n+  #define DEBUGOUT Syslog\n+  WLED_GLOBAL bool syslogEnabled _INIT(true);\n+  #ifndef WLED_SYSLOG_HOST\n+    #define WLED_SYSLOG_HOST \"\"\n+  #endif\n+  WLED_GLOBAL char syslogHost[33] _INIT(WLED_SYSLOG_HOST);\n+  #ifndef WLED_SYSLOG_PORT\n+    #define WLED_SYSLOG_PORT 514\n+  #endif\n+  WLED_GLOBAL int syslogPort _INIT(WLED_SYSLOG_PORT);\n+  WLED_GLOBAL uint8_t syslogProtocol _INIT(SYSLOG_PROTO_BSD); // Direct initialization with hardcoded BSD protocol value\n+  WLED_GLOBAL uint8_t syslogFacility _INIT(SYSLOG_LOCAL0); // Direct initialization with hardcoded LOCAL0 facility value\n+  WLED_GLOBAL uint8_t syslogSeverity _INIT(SYSLOG_DEBUG); // Direct initialization with hardcoded DEBUG severity value\n+#elif defined(WLED_DEBUG_HOST)\n   #include \"net_debug.h\"\n   // On the host side, use netcat to receive the log statements: nc -l 7868 -u\n   // use -D WLED_DEBUG_HOST='\"192.168.xxx.xxx\"' or FQDN within quotes\ndiff --git a/wled00/xml.cpp b/wled00/xml.cpp\nindex de2f5590df..17303bf240 100644\n--- a/wled00/xml.cpp\n+++ b/wled00/xml.cpp\n@@ -105,7 +105,7 @@ void appendGPIOinfo(Print& settingsScript) {\n   settingsScript.print(2); // DMX hardcoded pin\n   firstPin = false;\n   #endif\n-  #if defined(WLED_DEBUG) && !defined(WLED_DEBUG_HOST)\n+  #if defined(WLED_DEBUG) && !defined(WLED_DEBUG_HOST) && !defined(WLED_ENABLE_SYSLOG)\n   if (!firstPin) settingsScript.print(',');\n   settingsScript.print(hardwareTX); // debug output (TX) pin\n   firstPin = false;\n@@ -516,6 +516,13 @@ void getSettingsJS(byte subPage, Print& settingsScript)\n     settingsScript.print(F(\"toggle('Hue');\"));    // hide Hue Sync settings\n     #endif\n     printSetFormValue(settingsScript,PSTR(\"BD\"),serialBaud);\n+\n+    #ifdef WLED_ENABLE_SYSLOG\n+    printSetFormCheckbox(settingsScript,PSTR(\"SL_en\"), syslogEnabled);     // enable/disable\n+    printSetFormValue   (settingsScript,PSTR(\"SL_host\"), syslogHost);      // host\n+    printSetFormValue   (settingsScript,PSTR(\"SL_port\"), syslogPort);      // port\n+    #endif\n+\n     #ifndef WLED_ENABLE_ADALIGHT\n     settingsScript.print(F(\"toggle('Serial');\"));\n     #endif\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Identify & Fix Bugs**: Ensure `os |= 0x0100;` and `os &= ~0x0080;` in `wled00/json.cpp` are correctly implemented; clarify their purpose.\n\n2. **Syslog Code Placement**: Place Syslog setup code in `wled00/wled.cpp` after WiFi initialization as discussed. \n\n3. **Storage Considerations**: Limit HTML component inclusion to when `-D WLED_ENABLE_SYSLOG` is defined to prevent increased binary size.\n\n4. **Log Level Configuration**: Remove configurable log levels and facility from the GUI; keep code for future flexibility, set default to `SYSLOG_DEBUG`.\n\n5. **Utilize Flash Memory**: Use `printf_P` and similar functions to move strings to flash memory for efficiency.\n\n6. **Cleanup Code**: Remove unused code and clarify the necessity of supporting multiple syslog formats; retain only valuable functionality."
      }
    ],
    "codediff_length": 22994
  },
  {
    "index": 25,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/wled00/FX.cpp b/wled00/FX.cpp\nindex 4a364ea654..c55844309f 100644\n--- a/wled00/FX.cpp\n+++ b/wled00/FX.cpp\n@@ -114,6 +114,7 @@ static um_data_t* getAudioData() {\n   return um_data;\n }\n \n+\n // effect functions\n \n /*\n@@ -125,6 +126,56 @@ uint16_t mode_static(void) {\n }\n static const char _data_FX_MODE_STATIC[] PROGMEM = \"Solid\";\n \n+/*\n+ * Copy a segment and perform (optional) color adjustments\n+ */\n+uint16_t mode_copy_segment(void) {\n+  uint32_t sourceid = SEGMENT.custom3;\n+  if (sourceid >= strip.getSegmentsNum() || sourceid == strip.getCurrSegmentId()) { // invalid source\n+    SEGMENT.fadeToBlackBy(5); // fade out\n+    return FRAMETIME;\n+  }\n+  Segment sourcesegment = strip.getSegment(sourceid);\n+  if (sourcesegment.isActive()) {\n+    uint32_t sourcecolor;\n+    uint32_t destcolor;\n+    if(sourcesegment.is2D()) { // 2D source, note: 2D to 1D just copies the first row (or first column if 'Switch axis' is checked in FX)\n+      for (unsigned y = 0; y < SEGMENT.vHeight(); y++) {\n+        for (unsigned x = 0; x < SEGMENT.vWidth(); x++) {\n+          unsigned sx = x; // source coordinates\n+          unsigned sy = y;\n+          if(SEGMENT.check1) std::swap(sx, sy); // flip axis\n+          if(SEGMENT.check2) {\n+            sourcecolor = strip.getPixelColorXY(sx + sourcesegment.start, sy + sourcesegment.startY); // read from global buffer (reads the last rendered frame)\n+          }\n+          else {\n+            sourcesegment.setDrawDimensions(); // set to source segment dimensions\n+            sourcecolor = sourcesegment.getPixelColorXY(sx, sy); // read from segment buffer\n+          }\n+          destcolor = adjust_color(sourcecolor, SEGMENT.intensity, SEGMENT.custom1, SEGMENT.custom2);\n+          SEGMENT.setDrawDimensions(); // reset to current segment dimensions\n+          SEGMENT.setPixelColorXY(x, y, destcolor);\n+        }\n+      }\n+    } else { // 1D source, source can be expanded into 2D\n+      for (unsigned i = 0; i < SEGMENT.vLength(); i++) {\n+        if(SEGMENT.check2) {\n+          sourcecolor = strip.getPixelColor(i + sourcesegment.start); // read from global buffer (reads the last rendered frame)\n+        }\n+        else {\n+          sourcesegment.setDrawDimensions(); // set to source segment dimensions\n+          sourcecolor = sourcesegment.getPixelColor(i);\n+        }\n+        destcolor = adjust_color(sourcecolor, SEGMENT.intensity, SEGMENT.custom1, SEGMENT.custom2);\n+        SEGMENT.setDrawDimensions(); // reset to current segment dimensions\n+        SEGMENT.setPixelColor(i, destcolor);\n+      }\n+    }\n+  }\n+  return FRAMETIME;\n+}\n+static const char _data_FX_MODE_COPY[] PROGMEM = \"Copy Segment@,Color shift,Lighten,Brighten,ID,Axis(2D),FullStack(last frame);;;12;ix=0,c1=0,c2=0,c3=0\";\n+\n \n /*\n  * Blink/strobe function\n@@ -10584,6 +10635,7 @@ void WS2812FX::setupEffectData() {\n     _modeData.push_back(_data_RESERVED);\n   }\n   // now replace all pre-allocated effects\n+  addEffect(FX_MODE_COPY, &mode_copy_segment, _data_FX_MODE_COPY);\n   // --- 1D non-audio effects ---\n   addEffect(FX_MODE_BLINK, &mode_blink, _data_FX_MODE_BLINK);\n   addEffect(FX_MODE_BREATH, &mode_breath, _data_FX_MODE_BREATH);\ndiff --git a/wled00/FX.h b/wled00/FX.h\nold mode 100755\nnew mode 100644\nindex 82213179bd..e630b7aa5c\n--- a/wled00/FX.h\n+++ b/wled00/FX.h\n@@ -228,6 +228,7 @@ extern byte realtimeMode;           // used in getMappedPixelIndex()\n #define FX_MODE_LAKE                    75\n #define FX_MODE_METEOR                  76\n //#define FX_MODE_METEOR_SMOOTH           77  // replaced by Meteor\n+#define FX_MODE_COPY                    77\n #define FX_MODE_RAILWAY                 78\n #define FX_MODE_RIPPLE                  79\n #define FX_MODE_TWINKLEFOX              80\ndiff --git a/wled00/colors.cpp b/wled00/colors.cpp\nindex ea5c9779c5..da52bd4f75 100644\n--- a/wled00/colors.cpp\n+++ b/wled00/colors.cpp\n@@ -86,6 +86,23 @@ uint32_t color_fade(uint32_t c1, uint8_t amount, bool video)\n   return scaledcolor;\n }\n \n+/*\n+ * color adjustment in HSV color space (converts RGB to HSV and back), color conversions are not 100% accurate!\n+   shifts hue, increase brightness, decreases saturation (if not black)\n+   note: inputs are 32bit to speed up the function, useful input value ranges are 0-255\n+ */\n+uint32_t adjust_color(uint32_t rgb, uint32_t hueShift, uint32_t lighten, uint32_t brighten) {\n+    if(rgb == 0 | hueShift + lighten + brighten == 0) return rgb; // black or no change\n+    CHSV32 hsv;\n+    rgb2hsv(rgb, hsv); //convert to HSV\n+    hsv.h += (hueShift << 8); // shift hue (hue is 16 bits)\n+    hsv.s =  max((int32_t)0, (int32_t)hsv.s - (int32_t)lighten); // desaturate\n+    hsv.v =  min((uint32_t)255, (uint32_t)hsv.v + brighten); // increase brightness\n+    uint32_t rgb_adjusted;\n+    hsv2rgb(hsv, rgb_adjusted); // convert back to RGB TODO: make this into 16 bit conversion\n+    return rgb_adjusted;\n+}\n+\n // 1:1 replacement of fastled function optimized for ESP, slightly faster, more accurate and uses less flash (~ -200bytes)\n uint32_t ColorFromPaletteWLED(const CRGBPalette16& pal, unsigned index, uint8_t brightness, TBlendType blendType)\n {\ndiff --git a/wled00/fcn_declare.h b/wled00/fcn_declare.h\nindex d2f62870d5..54a8c854f7 100644\n--- a/wled00/fcn_declare.h\n+++ b/wled00/fcn_declare.h\n@@ -174,6 +174,7 @@ class NeoGammaWLEDMethod {\n inline uint32_t color_blend16(uint32_t c1, uint32_t c2, uint16_t b) { return color_blend(c1, c2, b >> 8); };\n [[gnu::hot, gnu::pure]] uint32_t color_add(uint32_t, uint32_t, bool preserveCR = false);\n [[gnu::hot, gnu::pure]] uint32_t color_fade(uint32_t c1, uint8_t amount, bool video=false);\n+[[gnu::hot, gnu::pure]] uint32_t adjust_color(uint32_t rgb, uint32_t hueShift, uint32_t lighten, uint32_t brighten);\n [[gnu::hot, gnu::pure]] uint32_t ColorFromPaletteWLED(const CRGBPalette16 &pal, unsigned index, uint8_t brightness = (uint8_t)255U, TBlendType blendType = LINEARBLEND);\n CRGBPalette16 generateHarmonicRandomPalette(const CRGBPalette16 &basepalette);\n CRGBPalette16 generateRandomPalette();\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Issue**: When the source segment is mirrored, copying to a target segment results in only half the data being populated, leaving the rest black. This behavior is unexpected and seems incorrect.\n\n2. **Action**: Implement a `getRenderedPixelColor()` function to correctly access pixel data in a mirrored state, allowing copies to reflect the source's visible output.\n\n3. **Mirroring Logic**: Preserve the mirroring, reverse, and grouping properties when copying, but do not copy spacing, as it complicates interleaved segments.\n\n4. **Performance Concern**: The `fadeToBlackBy()` function reduces performance significantly in 1D setups, with FPS dropping to 8. Investigate and optimize this function.\n\n5. **Next Steps**: Test proposed solutions, ensure UI sync reflects segment settings correctly, and avoid modifying user settings in FX functions to prevent confusion in UI behavior."
      }
    ],
    "codediff_length": 6009
  },
  {
    "index": 26,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/wled00/FX.cpp b/wled00/FX.cpp\nindex e7429d19f1..1bc0ebdaaf 100644\n--- a/wled00/FX.cpp\n+++ b/wled00/FX.cpp\n@@ -1111,7 +1111,7 @@ uint16_t mode_running_random(void) {\n \n   unsigned z = it % zoneSize;\n   bool nzone = (!z && it != SEGENV.aux1);\n-  for (unsigned i=SEGLEN-1; i > 0; i--) {\n+  for (int i=SEGLEN-1; i > 0; i--) {\n     if (nzone || z >= zoneSize) {\n       unsigned lastrand = PRNG16 >> 8;\n       int16_t diff = 0;\ndiff --git a/wled00/FX_fcn.cpp b/wled00/FX_fcn.cpp\nindex 1bbfa365bd..1ec334661a 100644\n--- a/wled00/FX_fcn.cpp\n+++ b/wled00/FX_fcn.cpp\n@@ -637,37 +637,29 @@ uint16_t IRAM_ATTR_YN Segment::nrOfVStrips() const {\n \n // Constants for mapping mode \"Pinwheel\"\n #ifndef WLED_DISABLE_2D\n-constexpr int Pinwheel_Steps_Small = 72;       // no holes up to 16x16\n-constexpr int Pinwheel_Size_Small  = 16;       // larger than this -> use \"Medium\"\n-constexpr int Pinwheel_Steps_Medium = 192;     // no holes up to 32x32\n-constexpr int Pinwheel_Size_Medium  = 32;      // larger than this -> use \"Big\"\n-constexpr int Pinwheel_Steps_Big = 304;        // no holes up to 50x50\n-constexpr int Pinwheel_Size_Big  = 50;         // larger than this -> use \"XL\"\n-constexpr int Pinwheel_Steps_XL  = 368;\n-constexpr float Int_to_Rad_Small = (DEG_TO_RAD * 360) / Pinwheel_Steps_Small;  // conversion: from 0...72 to Radians\n-constexpr float Int_to_Rad_Med =   (DEG_TO_RAD * 360) / Pinwheel_Steps_Medium; // conversion: from 0...192 to Radians\n-constexpr float Int_to_Rad_Big =   (DEG_TO_RAD * 360) / Pinwheel_Steps_Big;    // conversion: from 0...304 to Radians\n-constexpr float Int_to_Rad_XL =    (DEG_TO_RAD * 360) / Pinwheel_Steps_XL;     // conversion: from 0...368 to Radians\n-\n-constexpr int Fixed_Scale = 512;               // fixpoint scaling factor (9bit for fraction)\n-\n-// Pinwheel helper function: pixel index to radians\n-static float getPinwheelAngle(int i, int vW, int vH) {\n-  int maxXY = max(vW, vH);\n-  if (maxXY <= Pinwheel_Size_Small)  return float(i) * Int_to_Rad_Small;\n-  if (maxXY <= Pinwheel_Size_Medium) return float(i) * Int_to_Rad_Med;\n-  if (maxXY <= Pinwheel_Size_Big)    return float(i) * Int_to_Rad_Big;\n-  // else\n-  return float(i) * Int_to_Rad_XL;\n-}\n+uint32_t* pinWheelBitMap = NULL;   // bit-map to track drawn pixels (managed in service() )\n+constexpr int Fixed_Scale = 16384; // fixpoint scaling factor (14bit for fraction)\n+constexpr float stepFactor = 1.6; // number of angle steps (rays = stepFacor * maxXY)\n+\n // Pinwheel helper function: matrix dimensions to number of rays\n-static int getPinwheelLength(int vW, int vH) {\n+static int getPinwheelSteps(int vW, int vH) {\n   int maxXY = max(vW, vH);\n-  if (maxXY <= Pinwheel_Size_Small)  return Pinwheel_Steps_Small;\n-  if (maxXY <= Pinwheel_Size_Medium) return Pinwheel_Steps_Medium;\n-  if (maxXY <= Pinwheel_Size_Big)    return Pinwheel_Steps_Big;\n-  // else\n-  return Pinwheel_Steps_XL;\n+  unsigned stepfactor = unsigned(stepFactor * Fixed_Scale);\n+  return (maxXY * stepfactor) / Fixed_Scale;\n+}\n+\n+static void setPinwheelParameters(int i, int vW, int vH, int& startx, int& starty, int* cosVal, int* sinVal, bool getPixel = false) {\n+  int steps = getPinwheelSteps(vW, vH);\n+  int baseAngle =  0xFFFF / steps; // 360\u00b0 / steps, in 16 bit scale\n+  int rotate = 0;\n+  if(getPixel) rotate = baseAngle / 2; // rotate by half a ray width when reading pixel color\n+  for(int k = 0; k < 2; k++) // angular steps for two consecutive rays\n+  {\n+    cosVal[k] = (cos16((i + k) * baseAngle + rotate) * Fixed_Scale) >> 15; // step per pixel in fixed point, cos16 output is -0x7FFF to +0x7FFF\n+    sinVal[k] = (sin16((i + k) * baseAngle + rotate) * Fixed_Scale) >> 15; // using explicit bit shifts as dividing negative numbers is not equivalent (rounding error is acceptable)\n+  }\n+  startx = (vW * Fixed_Scale) / 2 + cosVal[0] / 4; // starting position = center + 1/4 pixel (in fixed point)\n+  starty = (vH * Fixed_Scale) / 2 + sinVal[0] / 4;\n }\n #endif\n \n@@ -689,7 +681,7 @@ uint16_t IRAM_ATTR Segment::virtualLength() const {\n         vLen = sqrt16(vH*vH + vW*vW); // use diagonal\n         break;\n       case M12_sPinwheel:\n-        vLen = getPinwheelLength(vW, vH);\n+        vLen = getPinwheelSteps(vW, vH);\n         break;\n       default:\n         vLen = vW * vH; // use all pixels from segment\n@@ -763,51 +755,84 @@ void IRAM_ATTR_YN Segment::setPixelColor(int i, uint32_t col)\n         for (int y = 0; y <  i; y++) setPixelColorXY(i, y, col);\n         break;\n       case M12_sPinwheel: {\n-        // i = angle --> 0 - 296  (Big), 0 - 192  (Medium), 0 - 72 (Small)\n-        float centerX = roundf((vW-1) / 2.0f);\n-        float centerY = roundf((vH-1) / 2.0f);\n-        float angleRad = getPinwheelAngle(i, vW, vH); // angle in radians\n-        float cosVal = cos_t(angleRad);\n-        float sinVal = sin_t(angleRad);\n-\n-        // avoid re-painting the same pixel\n-        int lastX = INT_MIN; // impossible position\n-        int lastY = INT_MIN; // impossible position\n-        // draw line at angle, starting at center and ending at the segment edge\n-        // we use fixed point math for better speed. Starting distance is 0.5 for better rounding\n-        // int_fast16_t and int_fast32_t types changed to int, minimum bits commented\n-        int posx = (centerX + 0.5f * cosVal) * Fixed_Scale; // X starting position in fixed point 18 bit\n-        int posy = (centerY + 0.5f * sinVal) * Fixed_Scale; // Y starting position in fixed point 18 bit\n-        int inc_x = cosVal * Fixed_Scale; // X increment per step (fixed point) 10 bit\n-        int inc_y = sinVal * Fixed_Scale; // Y increment per step (fixed point) 10 bit\n-\n-        int32_t maxX = vW * Fixed_Scale; // X edge in fixedpoint\n-        int32_t maxY = vH * Fixed_Scale; // Y edge in fixedpoint\n-\n-        // Odd rays start further from center if prevRay started at center.\n-        static int prevRay = INT_MIN; // previous ray number\n-        if ((i % 2 == 1) && (i - 1 == prevRay || i + 1 == prevRay)) {\n-          int jump = min(vW/3, vH/3); // can add 2 if using medium pinwheel \n-          posx += inc_x * jump;\n-          posy += inc_y * jump;\n+        if(pinWheelBitMap == NULL) break; // safety check\n+        int startX, startY, cosVal[2], sinVal[2]; // in fixed point scale\n+        setPinwheelParameters(i, vW, vH, startX, startY, cosVal, sinVal);\n+\n+        unsigned maxLineLength = max(vW, vH) + 2; // pixels drawn is always smaller than dx or dy, +1 pair for rounding errors\n+        uint16_t lineCoords[2][maxLineLength]; // uint16_t to save ram\n+        int lineLength[2] = {0};\n+\n+        // draw two lines starting at at x0/y0, save the coordinates. based on idea by @Brandon502\n+        for (int lineNr = 0; lineNr < 2; lineNr++) {\n+          int x0 = startX; // x / y coordinates in fixed scale\n+          int y0 = startY;\n+          int x1 = (startX + (cosVal[lineNr] * vW)); // outside of grid\n+          int y1 = (startY + (sinVal[lineNr] * vH));\n+          const int dx =  abs(x1-x0), sx = x0<x1 ? 1 : -1;   // x distance & step\n+          const int dy = -abs(y1-y0), sy = y0<y1 ? 1 : -1;  // y distance & step\n+          uint16_t* coordinates = lineCoords[lineNr]; // 1D access is faster\n+          int* length = &lineLength[lineNr];     // faster access\n+          x0 /= Fixed_Scale; // convert to pixel coordinates\n+          y0 /= Fixed_Scale;\n+\n+          // Bresenham's algorithm\n+          int idx = 0;\n+          int err = dx + dy;\n+          while (true) {\n+            if (unsigned(x0) >= vW || unsigned(y0) >= vH) break; // stop if outside of grid (exploit unsigned int overflow)\n+            coordinates[idx++] = x0;\n+            coordinates[idx++] = y0;\n+            (*length)++;\n+            // note: since endpoint is out of grid, no need to check if endpoint is reached\n+            int e2 = 2 * err;\n+            if (e2 >= dy) { err += dy; x0 += sx; }\n+            if (e2 <= dx) { err += dx; y0 += sy; }\n+          }\n         }\n-        prevRay = i;\n-\n-        // draw ray until we hit any edge\n-        while ((posx >= 0) && (posy >= 0) && (posx < maxX)  && (posy < maxY))  {\n-          // scale down to integer (compiler will replace division with appropriate bitshift)\n-          int x = posx / Fixed_Scale;\n-          int y = posy / Fixed_Scale;\n-          // set pixel\n-          if (x != lastX || y != lastY) setPixelColorXY(x, y, col);  // only paint if pixel position is different\n-          lastX = x;\n-          lastY = y;\n-          // advance to next position\n-          posx += inc_x;\n-          posy += inc_y;\n+\n+        // fill up the shorter line with missing coordinates, so block filling works correctly and efficiently\n+        int diff = lineLength[0] - lineLength[1];\n+        int longLineIdx = (diff > 0) ? 0 : 1;\n+        int shortLineIdx = longLineIdx ? 0 : 1;\n+        if (diff != 0) {\n+          int idx = (lineLength[shortLineIdx] - 1) * 2; // last valid coordinate index\n+          int lastX = lineCoords[shortLineIdx][idx++];\n+          int lastY = lineCoords[shortLineIdx][idx++];\n+          bool keepX = lastX == 0 || lastX == vW - 1;\n+          for (int d = 0; d < abs(diff); d++) {\n+            lineCoords[shortLineIdx][idx] = keepX ? lastX :lineCoords[longLineIdx][idx];\n+            idx++;\n+            lineCoords[shortLineIdx][idx] =  keepX ? lineCoords[longLineIdx][idx] : lastY;\n+            idx++;\n+          }\n+        }\n+\n+        // draw and block-fill the line oordinates. Note: block filling only efficient if angle between lines is small\n+        for (int idx = 0; idx < lineLength[longLineIdx] * 2;) { //!! should be long line idx!\n+          int x1 = lineCoords[0][idx];\n+          int x2 = lineCoords[1][idx++];\n+          int y1 = lineCoords[0][idx];\n+          int y2 = lineCoords[1][idx++];\n+          int minX, maxX, minY, maxY;\n+          (x1 < x2) ? (minX = x1, maxX = x2) : (minX = x2, maxX = x1);\n+          (y1 < y2) ? (minY = y1, maxY = y2) : (minY = y2, maxY = y1);\n+          // fill the block between the two x,y points\n+          for (int x = minX; x <= maxX; x++) {\n+            for (int y = minY; y <= maxY; y++) {\n+              int index = y * vW + x;  // calculate bitmap index, int_index, and bitmask for the current (x, y)\n+              uint32_t int_index = index >> 5;          // equivalent to index / 32\n+              uint32_t bitmask = 1U << (index & 31);    // equivalent to index % 32\n+              // Check if the pixel has already been drawn\n+              if (!(pinWheelBitMap[int_index] & bitmask)) {\n+                  pinWheelBitMap[int_index] |= bitmask; // set bit in map\n+                  setPixelColorXY(x, y, col);\n+              }\n+            }\n+          }\n         }\n-        break;\n       }\n+      break;\n     }\n     return;\n   } else if (Segment::maxHeight!=1 && (width()==1 || height()==1)) {\n@@ -929,31 +954,17 @@ uint32_t IRAM_ATTR_YN Segment::getPixelColor(int i) const\n         break;\n       case M12_sPinwheel:\n         // not 100% accurate, returns pixel at outer edge\n-        // i = angle --> 0 - 296  (Big), 0 - 192  (Medium), 0 - 72 (Small)\n-        float centerX = roundf((vW-1) / 2.0f);\n-        float centerY = roundf((vH-1) / 2.0f);\n-        float angleRad = getPinwheelAngle(i, vW, vH); // angle in radians\n-        float cosVal = cos_t(angleRad);\n-        float sinVal = sin_t(angleRad);\n-\n-        int posx = (centerX + 0.5f * cosVal) * Fixed_Scale; // X starting position in fixed point 18 bit\n-        int posy = (centerY + 0.5f * sinVal) * Fixed_Scale; // Y starting position in fixed point 18 bit\n-        int inc_x = cosVal * Fixed_Scale; // X increment per step (fixed point) 10 bit\n-        int inc_y = sinVal * Fixed_Scale; // Y increment per step (fixed point) 10 bit\n-        int32_t maxX = vW * Fixed_Scale; // X edge in fixedpoint\n-        int32_t maxY = vH * Fixed_Scale; // Y edge in fixedpoint\n-\n-        // trace ray from center until we hit any edge - to avoid rounding problems, we use the same method as in setPixelColor\n-        int x = INT_MIN;\n-        int y = INT_MIN;\n-        while ((posx >= 0) && (posy >= 0) && (posx < maxX)  && (posy < maxY))  {\n-          // scale down to integer (compiler will replace division with appropriate bitshift)\n-          x = posx / Fixed_Scale;\n-          y = posy / Fixed_Scale;\n-          // advance to next position\n-          posx += inc_x;\n-          posy += inc_y;\n+        int x, y, cosVal[2], sinVal[2];\n+        setPinwheelParameters(i, vW, vH, x, y, cosVal, sinVal, true);\n+        int maxX = (vW-1) * Fixed_Scale;\n+        int maxY = (vH-1) * Fixed_Scale;\n+        // trace ray from center until we hit any edge - to avoid rounding problems, we use fixed point coordinates\n+        while ((x < maxX)  && (y < maxY) && (x > Fixed_Scale) && (y > Fixed_Scale)) {\n+          x += cosVal[0]; // advance to next position\n+          y += sinVal[0];\n         }\n+        x /= Fixed_Scale;\n+        y /= Fixed_Scale;\n         return getPixelColorXY(x, y);\n         break;\n       }\n@@ -1364,6 +1375,15 @@ void WS2812FX::service() {\n         // when cctFromRgb is true we implicitly calculate WW and CW from RGB values\n         if (cctFromRgb) BusManager::setSegmentCCT(-1);\n         else            BusManager::setSegmentCCT(seg.currentBri(true), correctWB);\n+\n+        #ifndef WLED_DISABLE_2D\n+        if (seg.is2D() && seg.map1D2D == M12_sPinwheel) {\n+          int bitArraySize = (seg.virtualHeight() * seg.virtualWidth() + 31) / 32;  // 1 bit per pixel\n+          //uint32_t tempmap[bitArraySize] = {0}; // put the bit-map for overdraw tracking on stack\n+          //pinWheelBitMap = tempmap; // assign global pointer Note: using stack leads to crashes on larger sizes (write access error)\n+          pinWheelBitMap = new uint32_t[bitArraySize](); // allocate the bit-map for overdraw tracking on heap and initialize to zero\n+        }\n+        #endif\n         // Effect blending\n         // When two effects are being blended, each may have different segment data, this\n         // data needs to be saved first and then restored before running previous mode.\n@@ -1392,6 +1412,10 @@ void WS2812FX::service() {\n       seg.next_time = nowUp + delay;\n     }\n     _segment_index++;\n+    #ifndef WLED_DISABLE_2D\n+    if(pinWheelBitMap != NULL) delete[] pinWheelBitMap; // free the memory\n+    pinWheelBitMap = NULL; // invalidate pointer\n+    #endif\n   }\n   _virtualSegmentLength = 0;\n   _isServicing = false;\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Identified Issues**:\n   - Significant increase in holes for larger matrices (24x24 in particular).\n   - Current optimizations led to performance degradation (20% slower).\n\n2. **Implementation Suggestions**:\n   - Consider maintaining odd ray skipping while optimizing for varied matrix sizes.\n   - Utilize Bresenham's line algorithm for improved accuracy and reduced pixel overwriting.\n   - Implement an array buffer for pre-calculating a color map if RAM allows.\n\n3. **Performance**:\n   - Aim for optimization values for common sizes (8x8, 16x16, 32x32) for speed gains.\n   - Explore reducing line lengths adaptively based on size to prevent artifacts.\n\n4. **Next Steps**:\n   - Push the most recent version for review.\n   - Continue refining the coloring and mapping strategies for better performance with least overhead."
      }
    ],
    "codediff_length": 14386
  },
  {
    "index": 27,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/usermods/adc_sensor_mqtt/README.md b/usermods/adc_sensor_mqtt/README.md\nnew file mode 100644\nindex 0000000000..1d952342be\n--- /dev/null\n+++ b/usermods/adc_sensor_mqtt/README.md\n@@ -0,0 +1,28 @@\n+# ADC sensor with MQTT & HASS support ## \n+This usermod will obtain readings from adc pin. This is useful for ldr for example for exterior lighting situations where you want the lights to only be on when it is dark out. but this mod is designed for more hass application. it will publish auto discovery message to hass mqtt and attach the sensor to the wled integration automatically\n+\n+# Installation\n+Add \"adc_sensor_mqtt\" to your platformio.ini environment's custom_usermods and build.\n+Example:\n+```\n+[env:adc_sensor_mqtt_esp32dev]\n+extends = env:esp32dev\n+custom_usermods = ${env:esp32dev.custom_usermods} \n+  adc_sensor_mqtt   # Enable  ADC sensor with MQTT\n+```\n+\n+# Usermod Settings\n+Setting | Description | Default\n+--- | --- | ---\n+Enabled | Enable/Disable the LDR functionality. | Disabled\n+Pin | The analog capable pin your LDR is connected to. | A0 is forced in esp8266 and its not optional\n+AdcUpdateInterval | update interval to read the analog pin ( in ms ) | 3000\n+Inverted | invert readings based on your own hardware setup ( invert mapping analog to digital value to  0V = 100%  or 3.3V = 100% ) | false\n+ChangeThreshold | the minimum limit to detect change and publish the value ; checks the raw value ( int ;  5 ) . | 1\n+HASS | Enable home assistant mqtt discovery message with wled integration | true \n+Raw | publish the ADC value as raw measurement (0-4096 for ESP32 / 0-1024 for ESP8266) | false\n+DeviceClass | HASS sensor discovery device class | voltage \n+UnitOfMeas | HASS sensor discovery device unit of measurements | V  \n+\n+## Author\n+[@rommo911] (https://github.com/rommo911)  \ndiff --git a/usermods/adc_sensor_mqtt/adc_sensor_mqtt.cpp b/usermods/adc_sensor_mqtt/adc_sensor_mqtt.cpp\nnew file mode 100644\nindex 0000000000..7563fa829a\n--- /dev/null\n+++ b/usermods/adc_sensor_mqtt/adc_sensor_mqtt.cpp\n@@ -0,0 +1,470 @@\n+#include \"wled.h\"\n+#ifndef UM_ADC_MQTT_PIN_MAX_NUMBER\n+#ifdef ESP8266\n+#define UM_ADC_MQTT_PIN_MAX_NUMBER 1\n+#else\n+#define UM_ADC_MQTT_PIN_MAX_NUMBER 3\n+#endif\n+#endif\n+\n+#ifdef ESP8266 // static assert\n+#if (UM_ADC_MQTT_PIN_MAX_NUMBER > 1)\n+#error UM_ADC_MQTT_PIN_MAX_NUMBER > 1 not supported on ESP8266\n+#endif\n+#endif\n+\n+#ifdef ARDUINO_ARCH_ESP32 // esp8266 always use A0 no use of pin choice\n+#if defined(CONFIG_IDF_TARGET_ESP32)\n+#define _valid_adc_pin(__pin) (__pin >= 32U && __pin <= 39U) // only ADC1 available on ESP32 with wifi\n+#define ADC_SUPPORTED_PINS F(\"32..39\")\n+#elif defined(CONFIG_IDF_TARGET_ESP32S3) || defined(CONFIG_IDF_TARGET_ESP32S2)\n+#define _valid_adc_pin(__pin) (__pin >= 1 && __pin <= 10) // only ADC1 available on ESP32-S2/ S3 with wifi\n+#define ADC_SUPPORTED_PINS F(\"1..10\")\n+#elif defined(CONFIG_IDF_TARGET_ESP32C3)\n+#define _valid_adc_pin(__pin) (__pin < 5 && __pin >= 0) // only ADC1 available on ESP32-C3 with wifi\n+#define ADC_SUPPORTED_PINS F(\"0..4\")\n+#else\n+#error \"Unknown ESP32 target\"\n+#endif\n+#endif\n+\n+class adc_sensor_mqtt : public Usermod\n+{\n+private:\n+  static const uint8_t NUMBER_OF_DEFAULT_SENSOR_CLASSES = 5; // number of default sensor classes\n+  uint16_t update_interval = 2000;                           // update interval in ms\n+  float change_threshold = 1.0f;                             // change threshold in mapped / raw value as needed\n+  bool HomeAssistantDiscovery = true;                        // is HA discovery turned on by default\n+  bool publishRawValue = false;                              // publish raw value to MQTT instead of mapped value\n+  bool hassDiscoverySent = false;                            // flag to check if discovery message was sent\n+  bool adc_enabled = false;                                  // flag to check if ADC is enabled\n+  bool initDone = false;                                     // flag to check if setup is done\n+  bool published_initial_value = false;                      // flag to check if initial value was published\n+  unsigned long lastTime = 0;                                // last time the value was published\n+\n+  int8_t adc_pin[UM_ADC_MQTT_PIN_MAX_NUMBER];         // ADC pin number (A0 for ESP8266, 32-39 for ESP32 ..etc checked in setup)\n+  uint16_t adc_value[UM_ADC_MQTT_PIN_MAX_NUMBER];     // raw ADC values\n+  float adc_mapped_value[UM_ADC_MQTT_PIN_MAX_NUMBER]; // mapped ADC values\n+  String device_class[UM_ADC_MQTT_PIN_MAX_NUMBER];\n+  String unit_of_meas[UM_ADC_MQTT_PIN_MAX_NUMBER];\n+  static const char *device_classes[NUMBER_OF_DEFAULT_SENSOR_CLASSES];\n+  static const char *device_unit_of_measurement[NUMBER_OF_DEFAULT_SENSOR_CLASSES];\n+  static const char MQTT_TOPIC[];\n+  static const char _name[];\n+  static bool inverted;\n+\n+  static float read_adc_mapping(uint16_t rawValue);\n+\n+  static inline float mapFloat(int x, int in_min, int in_max, float out_min, float out_max)\n+  {\n+    return ((float)(x - in_min) * (out_max - out_min)) / (float)(in_max - in_min) + out_min;\n+  }\n+\n+public:\n+  adc_sensor_mqtt()\n+  {\n+    for (uint8_t i = 0; i < UM_ADC_MQTT_PIN_MAX_NUMBER; i++)\n+    {\n+#ifdef ESP8266         // static assert\n+      adc_pin[0] = 17; // A0\n+#else\n+      adc_pin[i] = -1;\n+#endif\n+      adc_value[i] = 0;\n+      adc_mapped_value[i] = 0;\n+      device_class[i] = F(\"voltage\"); // default device class\n+      unit_of_meas[i] = F(\"V\");       // default unit of measurement\n+    }\n+    // customize here your hass adc device class and unit of measurement\n+  }\n+\n+  void setup()\n+  {\n+    uint8_t valid_pins = 0; // count valid pins so at least one pin is valid to enable adc , otherwise ignore invalud pins\n+    for (uint8_t i = 0; i < UM_ADC_MQTT_PIN_MAX_NUMBER; i++)\n+    {\n+      // register adc_pin\n+      if ((adc_pin[i] != -1) && adc_enabled)\n+      {\n+#ifdef ESP8266\n+        if (adc_pin[i] == 17) // only one Pin supported : A0 for esp8266 //\n+#else\n+        if ((_valid_adc_pin(adc_pin[i])) && PinManager::allocatePin(adc_pin[i], false, PinOwner::UM_ADC_MQTT)) // ESP32 only pins 32-39 are available for ADC\n+#endif\n+        {\n+          pinMode(adc_pin[i], INPUT); // alloc success -> configure pin for input\n+          valid_pins++;\n+        }\n+        else\n+        {\n+          DEBUG_PRINTLN(F(\"adc_sensor_mqtt: Pin allocation failed!\"));\n+          adc_pin[i] = -1; // invalid pin -> disable this pin\n+        }\n+      }\n+    }\n+    if (valid_pins > 0)\n+    {\n+      adc_enabled = true; // at least one pin is valid\n+    }\n+    else\n+    {\n+      adc_enabled = false; // no valid pin at all -> disable adc\n+    }\n+    initDone = true;\n+  }\n+\n+  void connected()\n+  {\n+    if (WLED_MQTT_CONNECTED && HomeAssistantDiscovery)\n+    {\n+      for (uint8_t i = 0; i < UM_ADC_MQTT_PIN_MAX_NUMBER; i++)\n+      {\n+        DEBUG_PRINT(F(\"Publishing discovery message...\"));\n+        publishDiscovery(i);\n+      }\n+    }\n+  }\n+\n+  void loop()\n+  {\n+    if (initDone && adc_enabled)\n+    {\n+      // force first update if mqtt is connected and no value was published yet\n+      bool force_update = (millis() - lastTime) > (update_interval * 100); // to keep the mqtt alive if the light is not changing\n+      bool regular_update = (millis() - lastTime) > update_interval;\n+      if (regular_update || force_update) // force update if the time is up or if the light is not changing to retain mqtt hass activity in case\n+      {\n+        bool force_first_update = ((published_initial_value == false) && WLED_MQTT_CONNECTED);\n+        lastTime = millis(); // reset lastTime to current time\n+        for (uint8_t i = 0; i < UM_ADC_MQTT_PIN_MAX_NUMBER; i++)\n+        {\n+          if (adc_pin[i] < 0)\n+          {\n+            // DEBUG_PRINTLN(F(\"adc_sensor_mqtt:loop Pin not valid!\"));\n+            continue; // skip if pin is not valid\n+          }\n+          bool changed = this->publishRawValue ? (abs(adc_value[i] - analogRead(adc_pin[i])) > change_threshold) : (abs(adc_mapped_value[i] - read_adc_mapping(analogRead(adc_pin[i]))) > change_threshold);\n+          if (changed || force_update || force_first_update)\n+          {\n+            adc_value[i] = analogRead(adc_pin[i]);\n+            adc_mapped_value[i] = read_adc_mapping(adc_value[i]); // read adc value and map it to percentage\n+            char buf[64];\n+            sprintf_P(buf, PSTR(\"adc %d: %d (%d)\"), i, static_cast<uint8_t>(adc_mapped_value[i]), adc_value[i]);\n+            DEBUG_PRINTLN(buf);\n+            if (WLED_MQTT_CONNECTED)\n+            {\n+              if (publishRawValue)\n+              {\n+                publishMqtt(i);\n+              }\n+              else\n+              {\n+                publishMqtt(i);\n+              }\n+              published_initial_value = true;\n+            }\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  void addToConfig(JsonObject &root)\n+  {\n+    JsonObject top = root.createNestedObject(FPSTR(_name));\n+    top[F(\"Enabled\")] = adc_enabled;\n+    top[F(\"AdcUpdateInterval\")] = update_interval;\n+    top[F(\"Inverted\")] = inverted;\n+    top[F(\"ChangeThreshold\")] = change_threshold;\n+    top[F(\"HASS\")] = HomeAssistantDiscovery;\n+    top[F(\"Raw\")] = publishRawValue;\n+    for (uint8_t i = 0; i < UM_ADC_MQTT_PIN_MAX_NUMBER; i++)\n+    {\n+      // debug\n+      DEBUG_PRINT(F(\"configuring adc_sensor_mqtt: Pin \"));\n+      DEBUG_PRINTLN(i);\n+      char str2[32];\n+      sprintf_P(str2, PSTR(\"ADC %d\"), i);\n+      JsonObject ADC_object = top.createNestedObject(str2);\n+#ifndef ESP8266                                                            // esp8266 always use A0 no use of pin choice\n+      ADC_object[F(\"Pin\")] = _valid_adc_pin(adc_pin[i]) ? adc_pin[i] : -1; // store pin number in config\n+#endif\n+      // debug print new pin\n+      ADC_object[F(\"DeviceClass\")] = device_class[i]; // store device class in config\n+      ADC_object[F(\"UnitOfMeas\")] = unit_of_meas[i];  // store unit of measurement in config\n+    }\n+    // print config\n+    // String jsonString;\n+    // serializeJson(top, jsonString);\n+    // DEBUG_PRINTLN(jsonString.c_str());\n+  }\n+\n+  bool readFromConfig(JsonObject &root)\n+  {\n+    JsonObject top = root[FPSTR(_name)];\n+    bool configComplete = !top.isNull();\n+    if (!configComplete)\n+    {\n+      return false;\n+    }\n+    // read config\n+    // debug\n+    int8_t __attribute__((unused)) oldLdrPin[UM_ADC_MQTT_PIN_MAX_NUMBER];\n+    for (uint8_t i = 0; i < UM_ADC_MQTT_PIN_MAX_NUMBER; i++)\n+    {\n+      // debug\n+      DEBUG_PRINT(F(\"adc_sensor_mqtt: old Pin \"));\n+      DEBUG_PRINTLN(adc_pin[i]);\n+      oldLdrPin[i] = adc_pin[i]; // store old pin for later deallocation\n+      char str[10];\n+      sprintf_P(str, PSTR(\"ADC %d\"), i);\n+      configComplete &= getJsonValue(top[str][F(\"DeviceClass\")], device_class[i]);\n+      configComplete &= getJsonValue(top[str][F(\"UnitOfMeas\")], unit_of_meas[i]);\n+\n+#ifdef ARDUINO_ARCH_ESP32 // esp8266 always use A0 no use of pin choice\n+      configComplete &= getJsonValue(top[str][F(\"Pin\")], adc_pin[i]);\n+      const bool valid_adc_pin = _valid_adc_pin(adc_pin[i]);         // only ADC1 available on ESP32 with wifi\n+      if (!valid_adc_pin || !PinManager::isPinOk(adc_pin[i], false)) // // ESP32 only pins 32-39 are available for ADC\n+      {\n+        DEBUG_PRINT(F(\"adc_sensor_mqtt: Pin \"));\n+        DEBUG_PRINT(i);\n+        DEBUG_PRINTLN(F(\" is not valid!\"));\n+        configComplete = false; // pin not valid -> disable usermod\n+        adc_pin[i] = -1;        // invalid pin -> disable usermod\n+      }\n+      else\n+      {\n+        if (initDone && oldLdrPin[i] != -1) // config changed & new pin is fine  // if old pin was possibly allocated before , try to de allocate it\n+        {\n+          DEBUG_PRINTLN(F(\"adc_sensor_mqtt: Pin changed , deallocating old pin...\"));\n+          PinManager::deallocatePin(oldLdrPin[i], PinOwner::UM_ADC_MQTT);\n+        }\n+      }\n+#endif // ESP8266 always use A0 no use of pin choice\n+    }\n+    configComplete &= getJsonValue(top[F(\"Enabled\")], adc_enabled);\n+    configComplete &= getJsonValue(top[F(\"AdcUpdateInterval\")], update_interval);\n+    configComplete &= getJsonValue(top[F(\"Inverted\")], inverted);\n+    configComplete &= getJsonValue(top[F(\"ChangeThreshold\")], change_threshold);\n+    configComplete &= getJsonValue(top[F(\"HASS\")], HomeAssistantDiscovery);\n+    configComplete &= getJsonValue(top[F(\"Raw\")], publishRawValue);\n+    // if pin changed after init -\n+    if (adc_enabled && initDone)\n+    {\n+      if (HomeAssistantDiscovery)\n+      {\n+        hassDiscoverySent = false; // reset discovery flag to publish again rework the config\n+      }\n+      DEBUG_PRINTLN(F(\"adc_sensor_mqtt: Pin changed , rerunning setup \"));\n+      setup(); // setup again\n+    }\n+    return configComplete;\n+  }\n+\n+  void appendConfigData(Print &uiScript) override\n+  {\n+    uiScript.print(F(\"addInfo('adc_sensor_mqtt:Enabled',1,'<i>ADC enabled</i>');\"));\n+    uiScript.print(F(\"addInfo('adc_sensor_mqtt:HASS',1,'<i>Home Assistant Sensor Discovery</i>');\"));\n+    uiScript.print(F(\"addInfo('adc_sensor_mqtt:AdcUpdateInterval',1,'<i>ADC update interval <small>(in ms)</small> </i>');\"));\n+    uiScript.print(F(\"addInfo('adc_sensor_mqtt:Inverted',1,'<i>ADC mapping voltage inverted</i>');\"));\n+    uiScript.print(F(\"addInfo('adc_sensor_mqtt:ChangeThreshold',1,'<i>ADC change threshold</i>');\"));\n+    uiScript.print(F(\"addInfo('adc_sensor_mqtt:Raw',1,'<i>ADC publish raw value</i> <small>(ignores UnitOfMeas)</small>');\"));\n+    uiScript.print(F(\"ux='adc_sensor_mqtt';\"));\n+    for (uint8_t i = 0; i < UM_ADC_MQTT_PIN_MAX_NUMBER; i++)\n+    {\n+      // Use consistent field name\n+      char str[128];\n+#ifndef ESP8266 // only A0 is supported on ESP8266\n+      sprintf_P(str, PSTR(\"addInfo('adc_sensor_mqtt:ADC %d:Pin',1,'<i>ADC pin <small>(%s)</small><i> ');\"), i, ADC_SUPPORTED_PINS);\n+      uiScript.print(str);\n+#endif\n+      sprintf_P(str, PSTR(\"addInfo('adc_sensor_mqtt:ADC %d:DeviceClass',1,'<i>Sensor Device Class</i>');\"), i);\n+      uiScript.print(str);\n+      sprintf_P(str, PSTR(\"addInfo('adc_sensor_mqtt:ADC %d:UnitOfMeas',1,'<i>the unit of measurement</i>');\"), i);\n+      uiScript.print(str);\n+      sprintf_P(str, PSTR(\"dd=addDropdown(ux,'ADC %d:DeviceClass');\"), i);\n+      uiScript.print(str);\n+      for (uint8_t j = 0; j < NUMBER_OF_DEFAULT_SENSOR_CLASSES; j++)\n+      {\n+        sprintf_P(str, PSTR(\"addOption(dd,'%s','%s');\"), device_classes[j], device_classes[j]);\n+        uiScript.print(str);\n+      }\n+      sprintf_P(str, PSTR(\"dd=addDropdown(ux,'ADC %d:UnitOfMeas');\"), i);\n+      uiScript.print(str);\n+      for (uint8_t j = 0; j < NUMBER_OF_DEFAULT_SENSOR_CLASSES; j++)\n+      {\n+        sprintf_P(str, PSTR(\"addOption(dd,'%s','%s');\"), device_unit_of_measurement[j], device_unit_of_measurement[j]);\n+        uiScript.print(str);\n+      }\n+    }\n+  }\n+\n+  void addToJsonInfo(JsonObject &root)\n+  {\n+    // If \"u\" object does not exist yet we need to create it\n+    JsonObject user = root[F(\"u\")];\n+    if (user.isNull())\n+      user = root.createNestedObject(F(\"u\"));\n+\n+    if (!adc_enabled)\n+    {\n+      JsonArray adc_Enabled = user.createNestedArray(F(\"ADC enabled\"));\n+      adc_Enabled.add(adc_enabled);\n+      return; // do not add more if usermod is disabled\n+    }\n+\n+    for (uint8_t i = 0; i < UM_ADC_MQTT_PIN_MAX_NUMBER; i++)\n+    {\n+      if (adc_pin[i] == -1)\n+      {\n+        // DEBUG_PRINTLN(F(\"addToJsonInfo adc_sensor_mqtt: Pin not valid!\"));\n+        continue; // skip if pin is not valid\n+      }\n+      String adc_pin_name = F(\"ADC Reading \");\n+      adc_pin_name += String(i);\n+      adc_pin_name += F(\":\");\n+      JsonArray adc_Reading = user.createNestedArray(adc_pin_name);\n+      String adc_pin_value;\n+      if (HomeAssistantDiscovery)\n+      {\n+        adc_pin_value += F(\"(\");\n+        adc_pin_value += device_class[i];\n+        adc_pin_value += F(\"):\");\n+      }\n+      if (publishRawValue)\n+      {\n+        adc_pin_value += F(\"raw:\");\n+        adc_pin_value += String(adc_value[i]);\n+      }\n+      else\n+      {\n+        adc_pin_value += String(adc_mapped_value[i], 2);\n+        adc_pin_value += unit_of_meas[i];\n+      }\n+      adc_Reading.add(adc_pin_value);\n+    }\n+    // debug\n+    // String jsonString;\n+    // serializeJson(adc_Reading, jsonString);\n+    // DEBUG_PRINTLN(jsonString.c_str());\n+  }\n+\n+  uint16_t getId()\n+  {\n+    return USERMOD_ID_ADC_MQTT;\n+  }\n+\n+  void publishMqtt(int index)\n+  {\n+    if (WLED_MQTT_CONNECTED)\n+    {\n+      DEBUG_PRINTLN(F(\"Publishing MQTT message...\"));\n+      if (!hassDiscoverySent && HomeAssistantDiscovery)\n+      {\n+        // publish all discovery message if not already done\n+        for (uint8_t i = 0; i < UM_ADC_MQTT_PIN_MAX_NUMBER; i++)\n+        {\n+          publishDiscovery(i);\n+        }\n+      }\n+      String mqtt_stat_topic = mqttDeviceTopic;\n+      mqtt_stat_topic += MQTT_TOPIC;\n+      mqtt_stat_topic += String(index);\n+      mqtt->publish(mqtt_stat_topic.c_str(), 0, true, publishRawValue ? String(adc_value[index]).c_str() : String(adc_mapped_value[index], 2).c_str());\n+      published_initial_value = true;\n+      DEBUG_PRINT(F(\"MQTT message sent: on topic \"));\n+      DEBUG_PRINT(mqtt_stat_topic.c_str());\n+      DEBUG_PRINT(F(\" -> \"));\n+      DEBUG_PRINTLN(publishRawValue ? String(adc_value[index]).c_str() : String(adc_mapped_value[index], 2).c_str());\n+    }\n+  }\n+\n+  void publishDiscovery(uint8_t pin_number)\n+  {\n+    StaticJsonDocument<700> doc;\n+    String uid = escapedMac.c_str();\n+    uid += F(\"_adc_\");\n+    uid += String(pin_number);\n+    doc[F(\"uniq_id\")] = uid;\n+    String name = F(\"ADC Sensor \");\n+    name += String(pin_number);\n+    doc[F(\"name\")] = name.c_str();\n+    String mqtt_stat_topic = mqttDeviceTopic;\n+    mqtt_stat_topic += MQTT_TOPIC;\n+    mqtt_stat_topic += String(pin_number);\n+    doc[F(\"stat_t\")] = mqtt_stat_topic;\n+    doc[F(\"dev_cla\")] = device_class[pin_number].c_str();\n+    if (publishRawValue == false)\n+    {\n+      doc[F(\"unit_of_meas\")] = unit_of_meas[pin_number].c_str();\n+    }\n+    doc[F(\"val_tpl\")] = F(\"{{ value }}\");\n+    // availablity topic\n+    String mqtt_avail_topic = mqttDeviceTopic;\n+    mqtt_avail_topic += F(\"/status\");\n+    doc[F(\"avty_t\")] = mqtt_avail_topic.c_str();\n+    doc[F(\"pl_on\")] = F(\"online\");\n+    doc[F(\"pl_off\")] = F(\"offline\");\n+    JsonObject device = doc.createNestedObject(F(\"device\")); // attach the sensor to the same device\n+    device[F(\"name\")] = serverDescription;\n+    device[F(\"ids\")] = serverDescription;\n+    device[F(\"mf\")] = F(WLED_BRAND);\n+    device[F(\"mdl\")] = F(WLED_PRODUCT_NAME);\n+    device[F(\"sw\")] = versionString;\n+#ifdef ESP32\n+    device[F(\"hw_version\")] = F(\"esp32\");\n+#elif defined(ESP8266)\n+    device[F(\"hw_version\")] = F(\"esp8266\");\n+#else\n+    device[F(\"hw_version\")] = F(\"unknown\");\n+#endif\n+    JsonArray connections = device[F(\"connections\")].createNestedArray();\n+    connections.add(F(\"mac\"));\n+    connections.add(WiFi.macAddress());\n+    connections.add(F(\"ip\"));\n+    connections.add(WiFi.localIP().toString());\n+    String discovery_topic = F(\"homeassistant/sensor/\");\n+    discovery_topic += uid;\n+    discovery_topic += F(\"/config\");\n+    char json_str[700];\n+    size_t payload_size = serializeJson(doc, json_str);\n+    hassDiscoverySent = mqtt->publish(discovery_topic.c_str(), 1, true, json_str, payload_size) > 0; // publish discovery message\n+  }\n+};\n+\n+// Usermod static const variables\n+const char adc_sensor_mqtt::_name[] PROGMEM = \"adc_sensor_mqtt\";\n+const char adc_sensor_mqtt::MQTT_TOPIC[] PROGMEM = \"/adc_\";\n+bool adc_sensor_mqtt::inverted = false;\n+\n+// customization settings for the usermod\n+//  default device class and unit of measurement // edit those for your own needs\n+const char *adc_sensor_mqtt::device_classes[NUMBER_OF_DEFAULT_SENSOR_CLASSES] = {\"illuminance\", \"current\", \"power\", \"temperature\", \"voltage\"}; // default device class\n+const char *adc_sensor_mqtt::device_unit_of_measurement[NUMBER_OF_DEFAULT_SENSOR_CLASSES] = {\"lx\", \"A\", \"W\", \"\u00b0C\", \"V\"};                       // default unit of measurement\n+\n+/**\n+ * @brief Map the raw ADC value to a percentage value or add your own custom mapping.\n+ *\n+ * @param rawValue\n+ * @return float\n+ */\n+float adc_sensor_mqtt::read_adc_mapping(uint16_t rawValue)\n+{\n+#ifdef ESP32\n+  const uint16_t mapping = 4096; // ESP32 ADC resolution is 12 bit, so 4096 values\n+#else\n+  const uint16_t mapping = 1024; // ESP8266 ADC resolution is 10 bit, so 1024 values\n+#endif\n+  if (adc_sensor_mqtt::inverted) // default mapping value to 0-100  -- replace here your own mapping for your own unit of measurement\n+  {\n+    return mapFloat(rawValue, 0, mapping, 100, 0); // map raw value to percentage\n+  }\n+  else\n+  {\n+    return mapFloat(rawValue, 0, mapping, 0, 100); // map raw value to percentage\n+  }\n+}\n+\n+// Register the usermod in the usermod manager\n+static adc_sensor_mqtt adc_sensor_mqtt_instance;\n+REGISTER_USERMOD(adc_sensor_mqtt_instance);\n\\ No newline at end of file\ndiff --git a/usermods/adc_sensor_mqtt/library.json b/usermods/adc_sensor_mqtt/library.json\nnew file mode 100644\nindex 0000000000..ef017095d5\n--- /dev/null\n+++ b/usermods/adc_sensor_mqtt/library.json\n@@ -0,0 +1,3 @@\n+{\n+  \"name:\": \"adc_sensor_mqtt\"\n+}\n\\ No newline at end of file\ndiff --git a/wled00/const.h b/wled00/const.h\nindex 2b460f3f18..74916d5ff0 100644\n--- a/wled00/const.h\n+++ b/wled00/const.h\n@@ -210,7 +210,7 @@\n #define USERMOD_ID_DEEP_SLEEP            55     //Usermod \"usermod_deep_sleep.h\"\n #define USERMOD_ID_RF433                 56     //Usermod \"usermod_v2_RF433.h\"\n #define USERMOD_ID_BRIGHTNESS_FOLLOW_SUN 57     //Usermod \"usermod_v2_brightness_follow_sun.h\"\n-\n+#define USERMOD_ID_ADC_MQTT 58     //Usermod \"usermod_photoresistor_sensor_mqtt_v2.h\"\n //Access point behavior\n #define AP_BEHAVIOR_BOOT_NO_CONN          0     //Open AP when no connection after boot\n #define AP_BEHAVIOR_NO_CONN               1     //Open when no connection (either after boot or if connection is lost)\ndiff --git a/wled00/pin_manager.h b/wled00/pin_manager.h\nindex b285b6ee5d..a6ce99af29 100644\n--- a/wled00/pin_manager.h\n+++ b/wled00/pin_manager.h\n@@ -73,7 +73,8 @@ enum struct PinOwner : uint8_t {\n   UM_LDR_DUSK_DAWN     = USERMOD_ID_LDR_DUSK_DAWN,      // 0x2B // Usermod \"usermod_LDR_Dusk_Dawn_v2.h\"\n   UM_MAX17048          = USERMOD_ID_MAX17048,           // 0x2F // Usermod \"usermod_max17048.h\"\n   UM_BME68X            = USERMOD_ID_BME68X,             // 0x31 // Usermod \"usermod_bme68x.h -- Uses \"standard\" HW_I2C pins\n-  UM_PIXELS_DICE_TRAY  = USERMOD_ID_PIXELS_DICE_TRAY    // 0x35 // Usermod \"pixels_dice_tray.h\" -- Needs compile time specified 6 pins for display including SPI.\n+  UM_PIXELS_DICE_TRAY  = USERMOD_ID_PIXELS_DICE_TRAY,    // 0x35 // Usermod \"pixels_dice_tray.h\" -- Needs compile time specified 6 pins for display including SPI.\n+  UM_ADC_MQTT  = USERMOD_ID_ADC_MQTT    // 0x3A // Usermod \"photoresistor_sensor_mqtt_v2.cpp\" -- Uses default pin (ldrPin = A0), but could be easily updated with  pinManager from ui\n };\n static_assert(0u == static_cast<uint8_t>(PinOwner::None), \"PinOwner::None must be zero, so default array initialization works as expected\");\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Rename the usermod (UM) to \"generic ADC MQTT sensor\" for clarity; it should not be limited to a photoresistor.\n2. Implement multiple pin support and remove the current pin choice restriction for ESP8266, allowing pin A0 to be dynamically allocated.\n3. Streamline code formatting to adhere to standard WLED guidelines.\n4. Add a dropdown in UM settings for HA sensor type selection and ensure HA discovery can be customized.\n5. Assess if pin manager should support pin 17 for ESP8266 in input-only mode or if workarounds are sufficient.\n6. Confirm ADC pin allocations for ESP32-C3, S2, and S3. \n7. Ensure value publishing options are clear and user-friendly, considering threshold metrics for ease of use."
      }
    ],
    "codediff_length": 23103
  },
  {
    "index": 28,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/usermods/audioreactive/audio_reactive.cpp b/usermods/audioreactive/audio_reactive.cpp\nindex 06268560a7..25b8135209 100644\n--- a/usermods/audioreactive/audio_reactive.cpp\n+++ b/usermods/audioreactive/audio_reactive.cpp\n@@ -224,8 +224,8 @@ void FFTcode(void * parameter)\n   DEBUGSR_PRINT(\"FFT started on core: \"); DEBUGSR_PRINTLN(xPortGetCoreID());\n \n   // allocate FFT buffers on first call\n-  if (vReal == nullptr) vReal = (float*) calloc(sizeof(float), samplesFFT);\n-  if (vImag == nullptr) vImag = (float*) calloc(sizeof(float), samplesFFT);\n+  if (vReal == nullptr) vReal = (float*) calloc(samplesFFT, sizeof(float));\n+  if (vImag == nullptr) vImag = (float*) calloc(samplesFFT, sizeof(float));\n   if ((vReal == nullptr) || (vImag == nullptr)) {\n     // something went wrong\n     if (vReal) free(vReal); vReal = nullptr;\ndiff --git a/wled00/FX.h b/wled00/FX.h\nindex 097c857caf..692927a610 100644\n--- a/wled00/FX.h\n+++ b/wled00/FX.h\n@@ -88,23 +88,22 @@ extern byte realtimeMode;           // used in getMappedPixelIndex()\n #endif\n #define FPS_CALC_SHIFT 7 // bit shift for fixed point math\n \n-/* each segment uses 82 bytes of SRAM memory, so if you're application fails because of\n-  insufficient memory, decreasing MAX_NUM_SEGMENTS may help */\n+// heap memory limit for effects data, pixel buffers try to reserve it if PSRAM is available\n #ifdef ESP8266\n   #define MAX_NUM_SEGMENTS  16\n   /* How much data bytes all segments combined may allocate */\n-  #define MAX_SEGMENT_DATA  5120\n+  #define MAX_SEGMENT_DATA  (6*1024) // 6k by default\n #elif defined(CONFIG_IDF_TARGET_ESP32S2)\n-  #define MAX_NUM_SEGMENTS  20\n-  #define MAX_SEGMENT_DATA  (MAX_NUM_SEGMENTS*512)  // 10k by default (S2 is short on free RAM)\n+  #define MAX_NUM_SEGMENTS  32\n+  #define MAX_SEGMENT_DATA  (20*1024) // 20k by default (S2 is short on free RAM), limit does not apply if PSRAM is available\n #else\n-  #define MAX_NUM_SEGMENTS  32  // warning: going beyond 32 may consume too much RAM for stable operation\n-  #define MAX_SEGMENT_DATA  (MAX_NUM_SEGMENTS*1280) // 40k by default\n+  #define MAX_NUM_SEGMENTS  64\n+  #define MAX_SEGMENT_DATA  (64*1024) // 64k by default, limit does not apply if PSRAM is available\n #endif\n \n /* How much data bytes each segment should max allocate to leave enough space for other segments,\n   assuming each segment uses the same amount of data. 256 for ESP8266, 640 for ESP32. */\n-#define FAIR_DATA_PER_SEG (MAX_SEGMENT_DATA / WS2812FX::getMaxSegments())\n+#define FAIR_DATA_PER_SEG (MAX_SEGMENT_DATA / MAX_NUM_SEGMENTS)\n \n #define MIN_SHOW_DELAY   (_frametime < 16 ? 8 : 15)\n \n@@ -533,7 +532,6 @@ class Segment {\n \n   protected:\n \n-    inline static unsigned getUsedSegmentData()            { return Segment::_usedSegmentData; }\n     inline static void     addUsedSegmentData(int len)     { Segment::_usedSegmentData += len; }\n \n     inline uint32_t *getPixels() const                              { return pixels; }\n@@ -600,8 +598,8 @@ class Segment {\n     , _t(nullptr)\n     {\n       DEBUGFX_PRINTF_P(PSTR(\"-- Creating segment: %p [%d,%d:%d,%d]\\n\"), this, (int)start, (int)stop, (int)startY, (int)stopY);\n-      // allocate render buffer (always entire segment)\n-      pixels = static_cast<uint32_t*>(d_calloc(sizeof(uint32_t), length())); // error handling is also done in isActive()\n+      // allocate render buffer (always entire segment), prefer PSRAM if DRAM is running low. Note: impact on FPS with PSRAM buffer is low (<2% with QSPI PSRAM)\n+      pixels = static_cast<uint32_t*>(allocate_buffer(length() * sizeof(uint32_t), BFRALLOC_PREFER_PSRAM | BFRALLOC_NOBYTEACCESS | BFRALLOC_CLEAR));\n       if (!pixels) {\n         DEBUGFX_PRINTLN(F(\"!!! Not enough RAM for pixel buffer !!!\"));\n         extern byte errorFlag;\n@@ -623,7 +621,7 @@ class Segment {\n       #endif\n       clearName();\n       deallocateData();\n-      d_free(pixels);\n+      p_free(pixels);\n     }\n \n     Segment& operator= (const Segment &orig); // copy assignment\n@@ -672,6 +670,7 @@ class Segment {\n     inline uint16_t dataSize() const { return _dataLen; }\n     bool allocateData(size_t len);  // allocates effect data buffer in heap and clears it\n     void deallocateData();          // deallocates (frees) effect data buffer from heap\n+    inline static unsigned getUsedSegmentData()            { return Segment::_usedSegmentData; }\n     /**\n       * Flags that before the next effect is calculated,\n       * the internal segment state should be reset.\ndiff --git a/wled00/FX_fcn.cpp b/wled00/FX_fcn.cpp\nold mode 100644\nnew mode 100755\nindex 2f8d5515fd..95a347b66d\n--- a/wled00/FX_fcn.cpp\n+++ b/wled00/FX_fcn.cpp\n@@ -68,10 +68,10 @@ Segment::Segment(const Segment &orig) {\n   if (!stop) return;  // nothing to do if segment is inactive/invalid\n   if (orig.pixels) {\n     // allocate pixel buffer: prefer IRAM/PSRAM\n-    pixels = static_cast<uint32_t*>(d_malloc(sizeof(uint32_t) * orig.length()));\n+    pixels = static_cast<uint32_t*>(allocate_buffer(orig.length() * sizeof(uint32_t), BFRALLOC_PREFER_PSRAM | BFRALLOC_NOBYTEACCESS));\n     if (pixels) {\n       memcpy(pixels, orig.pixels, sizeof(uint32_t) * orig.length());\n-      if (orig.name) { name = static_cast<char*>(d_malloc(strlen(orig.name)+1)); if (name) strcpy(name, orig.name); }\n+      if (orig.name) { name = static_cast<char*>(allocate_buffer(strlen(orig.name)+1, BFRALLOC_PREFER_PSRAM)); if (name) strcpy(name, orig.name); }\n       if (orig.data) { if (allocateData(orig._dataLen)) memcpy(data, orig.data, orig._dataLen); }\n     } else {\n       DEBUGFX_PRINTLN(F(\"!!! Not enough RAM for pixel buffer !!!\"));\n@@ -97,10 +97,10 @@ Segment& Segment::operator= (const Segment &orig) {\n   //DEBUG_PRINTF_P(PSTR(\"-- Copying segment: %p -> %p\\n\"), &orig, this);\n   if (this != &orig) {\n     // clean destination\n-    if (name) { d_free(name); name = nullptr; }\n+    if (name) { p_free(name); name = nullptr; }\n     if (_t) stopTransition(); // also erases _t\n     deallocateData();\n-    d_free(pixels);\n+    p_free(pixels);\n     // copy source\n     memcpy((void*)this, (void*)&orig, sizeof(Segment));\n     // erase pointers to allocated data\n@@ -111,10 +111,10 @@ Segment& Segment::operator= (const Segment &orig) {\n     // copy source data\n     if (orig.pixels) {\n       // allocate pixel buffer: prefer IRAM/PSRAM\n-      pixels = static_cast<uint32_t*>(d_malloc(sizeof(uint32_t) * orig.length()));\n+      pixels = static_cast<uint32_t*>(allocate_buffer(orig.length() * sizeof(uint32_t), BFRALLOC_PREFER_PSRAM | BFRALLOC_NOBYTEACCESS));\n       if (pixels) {\n         memcpy(pixels, orig.pixels, sizeof(uint32_t) * orig.length());\n-        if (orig.name) { name = static_cast<char*>(d_malloc(strlen(orig.name)+1)); if (name) strcpy(name, orig.name); }\n+        if (orig.name) { name = static_cast<char*>(allocate_buffer(strlen(orig.name)+1, BFRALLOC_PREFER_PSRAM)); if (name) strcpy(name, orig.name); }\n         if (orig.data) { if (allocateData(orig._dataLen)) memcpy(data, orig.data, orig._dataLen); }\n       } else {\n         DEBUG_PRINTLN(F(\"!!! Not enough RAM for pixel buffer !!!\"));\n@@ -130,10 +130,10 @@ Segment& Segment::operator= (const Segment &orig) {\n Segment& Segment::operator= (Segment &&orig) noexcept {\n   //DEBUG_PRINTF_P(PSTR(\"-- Moving segment: %p -> %p\\n\"), &orig, this);\n   if (this != &orig) {\n-    if (name) { d_free(name); name = nullptr; } // free old name\n+    if (name) { p_free(name); name = nullptr; } // free old name\n     if (_t) stopTransition(); // also erases _t\n     deallocateData(); // free old runtime data\n-    d_free(pixels);   // free old pixel buffer\n+    p_free(pixels);   // free old pixel buffer\n     // move source data\n     memcpy((void*)this, (void*)&orig, sizeof(Segment));\n     orig.name = nullptr;\n@@ -147,35 +147,38 @@ Segment& Segment::operator= (Segment &&orig) noexcept {\n \n // allocates effect data buffer on heap and initialises (erases) it\n bool Segment::allocateData(size_t len) {\n-  if (len == 0) return false; // nothing to do\n-  if (data && _dataLen >= len) {          // already allocated enough (reduce fragmentation)\n+  if (len == 0) return false;    // nothing to do\n+  if (data && _dataLen >= len) { // already allocated enough (reduce fragmentation)\n     if (call == 0) {\n-      //DEBUG_PRINTF_P(PSTR(\"--   Clearing data (%d): %p\\n\"), len, this);\n-      memset(data, 0, len);  // erase buffer if called during effect initialisation\n+      if (_dataLen < FAIR_DATA_PER_SEG) { // segment data is small\n+        //DEBUG_PRINTF_P(PSTR(\"--   Clearing data (%d): %p\\n\"), len, this);\n+        memset(data, 0, len);  // erase buffer if called during effect initialisation\n+        return true; // no need to reallocate\n+      }\n     }\n-    return true;\n+    else\n+      return true;\n   }\n   //DEBUG_PRINTF_P(PSTR(\"--   Allocating data (%d): %p\\n\"), len, this);\n+  // limit to MAX_SEGMENT_DATA if there is no PSRAM, otherwise prefer functionality over speed\n+  #ifndef BOARD_HAS_PSRAM\n   if (Segment::getUsedSegmentData() + len - _dataLen > MAX_SEGMENT_DATA) {\n     // not enough memory\n-    DEBUG_PRINTF_P(PSTR(\"!!! Not enough RAM: %d/%d !!!\\n\"), len, Segment::getUsedSegmentData());\n+    DEBUG_PRINTF_P(PSTR(\"SegmentData limit reached: %d/%d\\n\"), len, Segment::getUsedSegmentData());\n     errorFlag = ERR_NORAM;\n     return false;\n   }\n-  // prefer DRAM over SPI RAM on ESP32 since it is slow\n+  #endif\n+\n   if (data) {\n-    data = (byte*)d_realloc_malloc(data, len); // realloc with malloc fallback\n-    if (!data) {\n-      data = nullptr;\n-      Segment::addUsedSegmentData(-_dataLen); // subtract original buffer size\n-      _dataLen = 0;   // reset data length\n-    }\n+    d_free(data); // free data and try to allocate again (segment buffer may be blocking contiguous heap)\n+    Segment::addUsedSegmentData(-_dataLen); // subtract buffer size\n   }\n-  else data = (byte*)d_malloc(len);\n+\n+  data = static_cast<byte*>(allocate_buffer(len, BFRALLOC_PREFER_DRAM | BFRALLOC_CLEAR)); // prefer DRAM over PSRAM for speed\n \n   if (data) {\n-    memset(data, 0, len);  // erase buffer\n-    Segment::addUsedSegmentData(len - _dataLen);\n+    Segment::addUsedSegmentData(len);\n     _dataLen = len;\n     //DEBUG_PRINTF_P(PSTR(\"---  Allocated data (%p): %d/%d -> %p\\n\"), this, len, Segment::getUsedSegmentData(), data);\n     return true;\n@@ -209,7 +212,11 @@ void Segment::deallocateData() {\n void Segment::resetIfRequired() {\n   if (!reset || !isActive()) return;\n   //DEBUG_PRINTF_P(PSTR(\"-- Segment reset: %p\\n\"), this);\n-  if (data && _dataLen > 0) memset(data, 0, _dataLen);  // prevent heap fragmentation (just erase buffer instead of deallocateData())\n+  if (data && _dataLen > 0) {\n+    if (_dataLen > FAIR_DATA_PER_SEG) deallocateData(); // do not keep large allocations\n+    else memset(data, 0, _dataLen);  // can prevent heap fragmentation\n+    DEBUG_PRINTF_P(PSTR(\"-- Segment %p reset, data cleared\\n\"), this);\n+  }\n   if (pixels) for (size_t i = 0; i < length(); i++) pixels[i] = BLACK; // clear pixel buffer\n   next_time = 0; step = 0; call = 0; aux0 = 0; aux1 = 0;\n   reset = false;\n@@ -466,7 +473,7 @@ void Segment::setGeometry(uint16_t i1, uint16_t i2, uint8_t grp, uint8_t spc, ui\n   if (length() != oldLength) {\n     // allocate render buffer (always entire segment), prefer IRAM/PSRAM. Note: impact on FPS with PSRAM buffer is low (<2% with QSPI PSRAM) on S2/S3\n     p_free(pixels);\n-    pixels = static_cast<uint32_t*>(d_malloc(sizeof(uint32_t) * length()));\n+    pixels = static_cast<uint32_t*>(allocate_buffer(length() * sizeof(uint32_t), BFRALLOC_PREFER_PSRAM | BFRALLOC_NOBYTEACCESS));\n     if (!pixels) {\n       DEBUGFX_PRINTLN(F(\"!!! Not enough RAM for pixel buffer !!!\"));\n       deallocateData();\n@@ -581,8 +588,8 @@ Segment &Segment::setName(const char *newName) {\n   if (newName) {\n     const int newLen = min(strlen(newName), (size_t)WLED_MAX_SEGNAME_LEN);\n     if (newLen) {\n-      if (name) d_free(name); // free old name\n-      name = static_cast<char*>(d_malloc(newLen+1));\n+      if (name) p_free(name); // free old name\n+      name = static_cast<char*>(allocate_buffer(newLen+1, BFRALLOC_PREFER_PSRAM));\n       if (mode == FX_MODE_2DSCROLLTEXT) startTransition(strip.getTransition(), true); // if the name changes in scrolling text mode, we need to copy the segment for blending\n       if (name) strlcpy(name, newName, newLen+1);\n       return *this;\n@@ -1177,7 +1184,10 @@ void WS2812FX::finalizeInit() {\n     mem += bus.memUsage(Bus::isDigital(bus.type) && !Bus::is2Pin(bus.type) ? digitalCount++ : 0); // includes global buffer\n     if (mem <= MAX_LED_MEMORY) {\n       if (BusManager::add(bus) == -1) break;\n-    } else DEBUG_PRINTF_P(PSTR(\"Out of LED memory! Bus %d (%d) #%u not created.\"), (int)bus.type, (int)bus.count, digitalCount);\n+    } else {\n+      errorFlag = ERR_NORAM_PX; // alert UI\n+      DEBUG_PRINTF_P(PSTR(\"Out of LED memory! Bus %d (%d) #%u not created.\"), (int)bus.type, (int)bus.count, digitalCount);\n+    }\n   }\n   busConfigs.clear();\n   busConfigs.shrink_to_fit();\n@@ -1209,10 +1219,11 @@ void WS2812FX::finalizeInit() {\n   deserializeMap();     // (re)load default ledmap (will also setUpMatrix() if ledmap does not exist)\n \n   // allocate frame buffer after matrix has been set up (gaps!)\n-  d_free(_pixels); // using realloc on large buffers can cause additional fragmentation instead of reducing it\n-  _pixels = static_cast<uint32_t*>(d_malloc(getLengthTotal() * sizeof(uint32_t)));\n+  p_free(_pixels); // using realloc on large buffers can cause additional fragmentation instead of reducing it\n+  // use PSRAM if available: there is no measurable perfomance impact between PSRAM and DRAM on S2/S3 with QSPI PSRAM for this buffer\n+  _pixels = static_cast<uint32_t*>(allocate_buffer(getLengthTotal() * sizeof(uint32_t), BFRALLOC_ENFORCE_PSRAM | BFRALLOC_NOBYTEACCESS | BFRALLOC_CLEAR));\n   DEBUG_PRINTF_P(PSTR(\"strip buffer size: %uB\\n\"), getLengthTotal() * sizeof(uint32_t));\n-  DEBUG_PRINTF_P(PSTR(\"Heap after strip init: %uB\\n\"), ESP.getFreeHeap());\n+  DEBUG_PRINTF_P(PSTR(\"Heap after strip init: %uB\\n\"), getFreeHeapSize());\n }\n \n void WS2812FX::service() {\n@@ -1552,7 +1563,11 @@ void WS2812FX::blendSegment(const Segment &topSegment) const {\n }\n \n void WS2812FX::show() {\n-  if (!_pixels) return; // no pixels allocated, nothing to show\n+  if (!_pixels) {\n+    DEBUGFX_PRINTLN(F(\"Error: no _pixels!\"));\n+    errorFlag = ERR_NORAM;\n+    return; // no pixels allocated, nothing to show\n+  }\n \n   unsigned long showNow = millis();\n   size_t diff = showNow - _lastShow;\n@@ -1562,7 +1577,7 @@ void WS2812FX::show() {\n   // we need to keep track of each pixel's CCT when blending segments (if CCT is present)\n   // and then set appropriate CCT from that pixel during paint (see below).\n   if ((hasCCTBus() || correctWB) && !cctFromRgb)\n-    _pixelCCT = static_cast<uint8_t*>(d_malloc(totalLen * sizeof(uint8_t))); // allocate CCT buffer if necessary\n+    _pixelCCT = static_cast<uint8_t*>(allocate_buffer(totalLen * sizeof(uint8_t), BFRALLOC_PREFER_PSRAM)); // allocate CCT buffer if necessary, prefer PSRAM\n   if (_pixelCCT) memset(_pixelCCT, 127, totalLen); // set neutral (50:50) CCT\n \n   if (realtimeMode == REALTIME_MODE_INACTIVE || useMainSegmentOnly || realtimeOverride > REALTIME_OVERRIDE_NONE) {\n@@ -1596,7 +1611,7 @@ void WS2812FX::show() {\n   }\n   Bus::setCCT(oldCCT);  // restore old CCT for ABL adjustments\n \n-  d_free(_pixelCCT);\n+  p_free(_pixelCCT);\n   _pixelCCT = nullptr;\n \n   // some buses send asynchronously and this method will return before\ndiff --git a/wled00/bus_manager.cpp b/wled00/bus_manager.cpp\nindex 99523bba9f..612c0f3aa8 100644\n--- a/wled00/bus_manager.cpp\n+++ b/wled00/bus_manager.cpp\n@@ -39,35 +39,29 @@ uint32_t colorBalanceFromKelvin(uint16_t kelvin, uint32_t rgb);\n uint8_t realtimeBroadcast(uint8_t type, IPAddress client, uint16_t length, const byte *buffer, uint8_t bri=255, bool isRGBW=false);\n \n //util.cpp\n-// PSRAM allocation wrappers\n-#if !defined(ESP8266) && !defined(CONFIG_IDF_TARGET_ESP32C3)\n+// memory allocation wrappers\n extern \"C\" {\n-  void *p_malloc(size_t);           // prefer PSRAM over DRAM\n-  void *p_calloc(size_t, size_t);   // prefer PSRAM over DRAM\n-  void *p_realloc(void *, size_t);  // prefer PSRAM over DRAM\n-  void *p_realloc_malloc(void *ptr, size_t size); // realloc with malloc fallback, prefer PSRAM over DRAM\n-  inline void p_free(void *ptr) { heap_caps_free(ptr); }\n-  void *d_malloc(size_t);           // prefer DRAM over PSRAM\n-  void *d_calloc(size_t, size_t);   // prefer DRAM over PSRAM\n-  void *d_realloc(void *, size_t);  // prefer DRAM over PSRAM\n-  void *d_realloc_malloc(void *ptr, size_t size); // realloc with malloc fallback, prefer DRAM over PSRAM\n+  // prefer DRAM over PSRAM (if available) in d_ alloc functions\n+  void *d_malloc(size_t);\n+  void *d_calloc(size_t, size_t);\n+  void *d_realloc_malloc(void *ptr, size_t size);\n+  #ifndef ESP8266\n   inline void d_free(void *ptr) { heap_caps_free(ptr); }\n+  #else\n+  inline void d_free(void *ptr) { free(ptr); }\n+  #endif\n+  #if defined(BOARD_HAS_PSRAM)\n+  // prefer PSRAM over DRAM in p_ alloc functions\n+  void *p_malloc(size_t);\n+  void *p_calloc(size_t, size_t);\n+  void *p_realloc_malloc(void *ptr, size_t size);\n+  inline void p_free(void *ptr) { heap_caps_free(ptr); }\n+  #else\n+  #define p_malloc d_malloc\n+  #define p_calloc d_calloc\n+  #define p_free d_free\n+  #endif\n }\n-#else\n-extern \"C\" {\n-  void *realloc_malloc(void *ptr, size_t size);\n-}\n-#define p_malloc malloc\n-#define p_calloc calloc\n-#define p_realloc realloc\n-#define p_realloc_malloc realloc_malloc\n-#define p_free free\n-#define d_malloc malloc\n-#define d_calloc calloc\n-#define d_realloc realloc\n-#define d_realloc_malloc realloc_malloc\n-#define d_free free\n-#endif\n \n //color mangling macros\n #define RGBW32(r,g,b,w) (uint32_t((byte(w) << 24) | (byte(r) << 16) | (byte(g) << 8) | (byte(b))))\n@@ -902,7 +896,7 @@ void BusManager::esp32RMTInvertIdle() {\n     else if (lvl == RMT_IDLE_LEVEL_LOW) lvl = RMT_IDLE_LEVEL_HIGH;\n     else continue;\n     rmt_set_idle_level(ch, idle_out, lvl);\n-    u++\n+    u++;\n   }\n }\n #endif\ndiff --git a/wled00/cfg.cpp b/wled00/cfg.cpp\nindex eac6ea25a2..9d7477c7a7 100644\n--- a/wled00/cfg.cpp\n+++ b/wled00/cfg.cpp\n@@ -201,7 +201,7 @@ bool deserializeConfig(JsonObject doc, bool fromFS) {\n   }\n   #endif\n \n-  DEBUG_PRINTF_P(PSTR(\"Heap before buses: %d\\n\"), ESP.getFreeHeap());\n+  DEBUG_PRINTF_P(PSTR(\"Heap before buses: %d\\n\"), getFreeHeapSize());\n   JsonArray ins = hw_led[\"ins\"];\n   if (!ins.isNull()) {\n     int s = 0;  // bus iterator\ndiff --git a/wled00/const.h b/wled00/const.h\nindex 1abf245396..7a7ca976c6 100644\n--- a/wled00/const.h\n+++ b/wled00/const.h\n@@ -546,8 +546,21 @@ static_assert(WLED_MAX_BUSSES <= 32, \"WLED_MAX_BUSSES exceeds hard limit\");\n   #endif\n #endif\n \n-// minimum heap size required to process web requests\n-#define MIN_HEAP_SIZE 8192\n+// minimum heap size required to process web requests: try to keep free heap above this value\n+#ifdef ESP8266\n+  #define MIN_HEAP_SIZE (9*1024)\n+#else\n+  #define MIN_HEAP_SIZE (15*1024) // WLED allocation functions (util.cpp) try to keep this much contiguous heap free for other tasks\n+#endif\n+// threshold for PSRAM use: if heap is running low, requests to allocate_buffer(prefer DRAM) above PSRAM_THRESHOLD may be put in PSRAM\n+// if heap is depleted, PSRAM will be used regardless of threshold\n+#if defined(CONFIG_IDF_TARGET_ESP32S3)\n+  #define PSRAM_THRESHOLD (12*1024) // S3 has plenty of DRAM\n+#elif defined(CONFIG_IDF_TARGET_ESP32)\n+  #define PSRAM_THRESHOLD (5*1024)\n+#else\n+  #define PSRAM_THRESHOLD (2*1024) // S2 does not have a lot of RAM. C3 and ESP8266 do not support PSRAM: the value is not used\n+#endif\n \n // Web server limits\n #ifdef ESP8266\ndiff --git a/wled00/data/settings_leds.htm b/wled00/data/settings_leds.htm\nindex 928da11753..6424815cc2 100644\n--- a/wled00/data/settings_leds.htm\n+++ b/wled00/data/settings_leds.htm\n@@ -195,7 +195,6 @@\n \t\t\tif (isAna(t)) return 5;\t// analog\n \t\t\tlet len = parseInt(d.getElementsByName(\"LC\"+n)[0].value);\n \t\t\tlen += parseInt(d.getElementsByName(\"SL\"+n)[0].value); // skipped LEDs are allocated too\n-\t\t\tlet dbl = 0;\n \t\t\tlet ch = 3*hasRGB(t) + hasW(t) + hasCCT(t);\n \t\t\tlet mul = 1;\n \t\t\tif (isDig(t)) {\n@@ -207,7 +206,7 @@\n \t\t\t\t\tmul = 2;\n \t\t\t\t}\n \t\t\t}\n-\t\t\treturn len * ch * mul + dbl;\n+\t\t\treturn len * ch * mul + len * 4; // add 4 bytes per LED for segment buffer (TODO: how to account for global buffer?)\n \t\t}\n \n \t\tfunction UI(change=false)\ndiff --git a/wled00/fcn_declare.h b/wled00/fcn_declare.h\nindex 77e112362e..87d16c4e96 100644\n--- a/wled00/fcn_declare.h\n+++ b/wled00/fcn_declare.h\n@@ -432,35 +432,44 @@ inline uint8_t hw_random8() { return HW_RND_REGISTER; };\n inline uint8_t hw_random8(uint32_t upperlimit) { return (hw_random8() * upperlimit) >> 8; }; // input range 0-255\n inline uint8_t hw_random8(uint32_t lowerlimit, uint32_t upperlimit) { uint32_t range = upperlimit - lowerlimit; return lowerlimit + hw_random8(range); }; // input range 0-255\n \n-// PSRAM allocation wrappers\n-#if !defined(ESP8266) && !defined(CONFIG_IDF_TARGET_ESP32C3)\n+// memory allocation wrappers (util.cpp)\n extern \"C\" {\n-  void *p_malloc(size_t);           // prefer PSRAM over DRAM\n-  void *p_calloc(size_t, size_t);   // prefer PSRAM over DRAM\n-  void *p_realloc(void *, size_t);  // prefer PSRAM over DRAM\n-  void *p_realloc_malloc(void *ptr, size_t size); // realloc with malloc fallback, prefer PSRAM over DRAM\n-  inline void p_free(void *ptr) { heap_caps_free(ptr); }\n-  void *d_malloc(size_t);           // prefer DRAM over PSRAM\n-  void *d_calloc(size_t, size_t);   // prefer DRAM over PSRAM\n-  void *d_realloc(void *, size_t);  // prefer DRAM over PSRAM\n-  void *d_realloc_malloc(void *ptr, size_t size); // realloc with malloc fallback, prefer DRAM over PSRAM\n+  // prefer DRAM in d_xalloc functions, PSRAM as fallback\n+  void *d_malloc(size_t);\n+  void *d_calloc(size_t, size_t);\n+  void *d_realloc_malloc(void *ptr, size_t size);\n+  #ifndef ESP8266\n   inline void d_free(void *ptr) { heap_caps_free(ptr); }\n+  #else\n+  inline void d_free(void *ptr) { free(ptr); }\n+  #endif\n+  #if defined(BOARD_HAS_PSRAM)\n+  // prefer PSRAM in p_xalloc functions, DRAM as fallback\n+  void *p_malloc(size_t);\n+  void *p_calloc(size_t, size_t);\n+  void *p_realloc_malloc(void *ptr, size_t size);\n+  inline void p_free(void *ptr) { heap_caps_free(ptr); }\n+  #else\n+  #define p_malloc d_malloc\n+  #define p_calloc d_calloc\n+  #define p_realloc_malloc d_realloc_malloc\n+  #define p_free d_free\n+  #endif\n }\n+#ifndef ESP8266\n+inline size_t getFreeHeapSize() { return heap_caps_get_free_size(MALLOC_CAP_INTERNAL | MALLOC_CAP_8BIT); } // returns free heap (ESP.getFreeHeap() can include other memory types)\n+inline size_t getContiguousFreeHeap() { return heap_caps_get_largest_free_block(MALLOC_CAP_INTERNAL | MALLOC_CAP_8BIT); } // returns largest contiguous free block\n #else\n-extern \"C\" {\n-  void *realloc_malloc(void *ptr, size_t size);\n-}\n-#define p_malloc malloc\n-#define p_calloc calloc\n-#define p_realloc realloc\n-#define p_realloc_malloc realloc_malloc\n-#define p_free free\n-#define d_malloc malloc\n-#define d_calloc calloc\n-#define d_realloc realloc\n-#define d_realloc_malloc realloc_malloc\n-#define d_free free\n+inline size_t getFreeHeapSize() { return ESP.getFreeHeap(); } // returns free heap\n+inline size_t getContiguousFreeHeap() { return ESP.getMaxFreeBlockSize(); } // returns largest contiguous free block\n #endif\n+#define BFRALLOC_NOBYTEACCESS    (1 << 0) // ESP32 has 32bit accessible DRAM (usually ~50kB free) that must not be byte-accessed\n+#define BFRALLOC_PREFER_DRAM     (1 << 1) // prefer DRAM over PSRAM\n+#define BFRALLOC_ENFORCE_DRAM    (1 << 2) // use DRAM only, no PSRAM\n+#define BFRALLOC_PREFER_PSRAM    (1 << 3) // prefer PSRAM over DRAM\n+#define BFRALLOC_ENFORCE_PSRAM   (1 << 4) // use PSRAM if available, otherwise uses DRAM\n+#define BFRALLOC_CLEAR           (1 << 5) // clear allocated buffer after allocation\n+void *allocate_buffer(size_t size, uint32_t type);\n \n void handleBootLoop();   // detect and handle bootloops\n #ifndef ESP8266\ndiff --git a/wled00/file.cpp b/wled00/file.cpp\nindex 108c41bd44..9f1dd62256 100644\n--- a/wled00/file.cpp\n+++ b/wled00/file.cpp\n@@ -422,8 +422,8 @@ bool handleFileRead(AsyncWebServerRequest* request, String path){\n   DEBUGFS_PRINT(F(\"WS FileRead: \")); DEBUGFS_PRINTLN(path);\n   if(path.endsWith(\"/\")) path += \"index.htm\";\n   if(path.indexOf(F(\"sec\")) > -1) return false;\n-  #ifdef ARDUINO_ARCH_ESP32\n-  if (psramSafe && psramFound() && path.endsWith(FPSTR(getPresetsFileName()))) {\n+  #ifdef BOARD_HAS_PSRAM\n+  if (path.endsWith(FPSTR(getPresetsFileName()))) {\n     size_t psize;\n     const uint8_t *presets = getPresetCache(psize);\n     if (presets) {\ndiff --git a/wled00/json.cpp b/wled00/json.cpp\nindex e8ebaaba29..5f4c3cfe00 100644\n--- a/wled00/json.cpp\n+++ b/wled00/json.cpp\n@@ -812,7 +812,7 @@ void serializeInfo(JsonObject root)\n   root[F(\"clock\")] = ESP.getCpuFreqMHz();\n   root[F(\"flash\")] = (ESP.getFlashChipSize()/1024)/1024;\n   #ifdef WLED_DEBUG\n-  root[F(\"maxalloc\")] = ESP.getMaxAllocHeap();\n+  root[F(\"maxalloc\")] = getContiguousFreeHeap();\n   root[F(\"resetReason0\")] = (int)rtc_get_reset_reason(0);\n   root[F(\"resetReason1\")] = (int)rtc_get_reset_reason(1);\n   #endif\n@@ -823,15 +823,15 @@ void serializeInfo(JsonObject root)\n   root[F(\"clock\")] = ESP.getCpuFreqMHz();\n   root[F(\"flash\")] = (ESP.getFlashChipSize()/1024)/1024;\n   #ifdef WLED_DEBUG\n-  root[F(\"maxalloc\")] = ESP.getMaxFreeBlockSize();\n+  root[F(\"maxalloc\")] = getContiguousFreeHeap();\n   root[F(\"resetReason\")] = (int)ESP.getResetInfoPtr()->reason;\n   #endif\n   root[F(\"lwip\")] = LWIP_VERSION_MAJOR;\n #endif\n \n-  root[F(\"freeheap\")] = ESP.getFreeHeap();\n-  #if defined(ARDUINO_ARCH_ESP32)\n-  if (psramFound()) root[F(\"psram\")] = ESP.getFreePsram();\n+  root[F(\"freeheap\")] = getFreeHeapSize();\n+  #if defined(BOARD_HAS_PSRAM)\n+  root[F(\"psram\")] = ESP.getFreePsram();\n   #endif\n   root[F(\"uptime\")] = millis()/1000 + rolloverMillis*4294967;\n \ndiff --git a/wled00/util.cpp b/wled00/util.cpp\nindex 84473ce711..cfe32a2f15 100644\n--- a/wled00/util.cpp\n+++ b/wled00/util.cpp\n@@ -629,92 +629,181 @@ int32_t hw_random(int32_t lowerlimit, int32_t upperlimit) {\n   return hw_random(diff) + lowerlimit;\n }\n \n-#if !defined(ESP8266) && !defined(CONFIG_IDF_TARGET_ESP32C3) // ESP8266 does not support PSRAM, ESP32-C3 does not have PSRAM\n-// p_x prefer PSRAM, d_x prefer DRAM\n-void *p_malloc(size_t size) {\n-  int caps1 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n-  int caps2 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n-  if (psramSafe) {\n-    if (heap_caps_get_free_size(caps2) > 3*MIN_HEAP_SIZE && size < 512) std::swap(caps1, caps2);  // use DRAM for small alloactions & when heap is plenty\n-    return heap_caps_malloc_prefer(size, 2, caps1, caps2); // otherwise prefer PSRAM if it exists\n+// PSRAM compile time checks to provide info for misconfigured env\n+#if defined(BOARD_HAS_PSRAM)\n+  #if defined(IDF_TARGET_ESP32C3) || defined(ESP8266)\n+    #error \"ESP32-C3 and ESP8266 with PSRAM is not supported, please remove BOARD_HAS_PSRAM definition\"\n+  #else\n+    // BOARD_HAS_PSRAM also means that compiler flag \"-mfix-esp32-psram-cache-issue\" has to be used\n+    #warning \"BOARD_HAS_PSRAM defined, make sure to use -mfix-esp32-psram-cache-issue to prevent issues on rev.1 ESP32 boards \\\n+              see https://docs.espressif.com/projects/esp-idf/en/stable/esp32/api-guides/external-ram.html#esp32-rev-v1-0\"\n+  #endif\n+#else\n+  #if !defined(IDF_TARGET_ESP32C3) && !defined(ESP8266)\n+    #pragma message(\"BOARD_HAS_PSRAM not defined, not using PSRAM.\")\n+  #endif\n+#endif\n+\n+// memory allocation functions with minimum free heap size check\n+#ifdef ESP8266\n+static void *validateFreeHeap(void *buffer) {\n+  // make sure there is enough free heap left if buffer was allocated in DRAM region, free it if not\n+  if (getContiguousFreeHeap() < MIN_HEAP_SIZE) {\n+    free(buffer);\n+    return nullptr;\n   }\n-  return heap_caps_malloc(size, caps2);\n+  return buffer;\n }\n \n-void *p_realloc(void *ptr, size_t size) {\n-  int caps1 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n-  int caps2 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n-  if (psramSafe) {\n-    if (heap_caps_get_free_size(caps2) > 3*MIN_HEAP_SIZE && size < 512) std::swap(caps1, caps2);  // use DRAM for small alloactions & when heap is plenty\n-    return heap_caps_realloc_prefer(ptr, size, 2, caps1, caps2); // otherwise prefer PSRAM if it exists\n-  }\n-  return heap_caps_realloc(ptr, size, caps2);\n+void *d_malloc(size_t size) {\n+  // note: using \"if (getContiguousFreeHeap() > MIN_HEAP_SIZE + size)\" did perform worse in tests with regards to keeping heap healthy and UI working\n+  void *buffer = malloc(size);\n+  return validateFreeHeap(buffer);\n }\n \n-// realloc with malloc fallback, original buffer is freed if realloc fails but not copied!\n-void *p_realloc_malloc(void *ptr, size_t size) {\n-  void *newbuf = p_realloc(ptr, size); // try realloc first\n-  if (newbuf) return newbuf; // realloc successful\n-  p_free(ptr); // free old buffer if realloc failed\n-  return p_malloc(size); // fallback to malloc\n+void *d_calloc(size_t count, size_t size) {\n+  void *buffer = calloc(count, size);\n+  return validateFreeHeap(buffer);\n }\n \n-void *p_calloc(size_t count, size_t size) {\n-  int caps1 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n-  int caps2 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n-  if (psramSafe) {\n-    if (heap_caps_get_free_size(caps2) > 3*MIN_HEAP_SIZE && size < 512) std::swap(caps1, caps2);  // use DRAM for small alloactions & when heap is plenty\n-    return heap_caps_calloc_prefer(count, size, 2, caps1, caps2); // otherwise prefer PSRAM if it exists\n+// realloc with malloc fallback, note: on ESPS8266 there is no safe way to ensure MIN_HEAP_SIZE during realloc()s, free buffer and allocate new one\n+void *d_realloc_malloc(void *ptr, size_t size) {\n+  free(ptr);\n+  return d_malloc(size);\n+}\n+#else\n+static void *validateFreeHeap(void *buffer) {\n+  // make sure there is enough free heap left if buffer was allocated in DRAM region, free it if not\n+  // TODO: between allocate and free, heap can run low (async web access), only IDF V5 allows for a pre-allocation-check of all free blocks\n+  if ((uintptr_t)buffer > SOC_DRAM_LOW && (uintptr_t)buffer < SOC_DRAM_HIGH && getContiguousFreeHeap() < MIN_HEAP_SIZE) {\n+    free(buffer);\n+    return nullptr;\n   }\n-  return heap_caps_calloc(count, size, caps2);\n+  return buffer;\n }\n \n void *d_malloc(size_t size) {\n-  int caps1 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n-  int caps2 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n-  if (psramSafe) {\n-    if (heap_caps_get_largest_free_block(caps1) < 3*MIN_HEAP_SIZE && size > MIN_HEAP_SIZE) std::swap(caps1, caps2);  // prefer PSRAM for large alloactions & when DRAM is low\n-    return heap_caps_malloc_prefer(size, 2, caps1, caps2); // otherwise prefer DRAM\n-  }\n-  return heap_caps_malloc(size, caps1);\n+  void *buffer;\n+  #if defined(CONFIG_IDF_TARGET_ESP32C3) || defined(CONFIG_IDF_TARGET_ESP32S2) || defined(CONFIG_IDF_TARGET_ESP32S3)\n+  // the newer ESP32 variants have byte-accessible fast RTC memory that can be used as heap, access speed is on-par with DRAM\n+  // the system does prefer normal DRAM until full, since free RTC memory is ~7.5k only, its below the minimum heap threshold and needs to be allocated explicitly\n+  // use RTC RAM for small allocations to improve fragmentation or if DRAM is running low\n+  if (size < 256 || getContiguousFreeHeap() < 2*MIN_HEAP_SIZE + size)\n+    buffer = heap_caps_malloc_prefer(size, 2, MALLOC_CAP_RTCRAM, MALLOC_CAP_INTERNAL | MALLOC_CAP_8BIT);\n+  else\n+  #endif\n+  buffer = heap_caps_malloc(size, MALLOC_CAP_INTERNAL | MALLOC_CAP_8BIT); // allocate in any available heap memory\n+  buffer = validateFreeHeap(buffer); // make sure there is enough free heap left\n+  #ifdef BOARD_HAS_PSRAM\n+  if (!buffer)\n+    return heap_caps_malloc(size, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT); // DRAM failed, use PSRAM if available\n+  #endif\n+  return buffer;\n }\n \n-void *d_realloc(void *ptr, size_t size) {\n-  int caps1 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n-  int caps2 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n-  if (psramSafe) {\n-    if (heap_caps_get_largest_free_block(caps1) < 3*MIN_HEAP_SIZE && size > MIN_HEAP_SIZE) std::swap(caps1, caps2);  // prefer PSRAM for large alloactions & when DRAM is low\n-    return heap_caps_realloc_prefer(ptr, size, 2, caps1, caps2); // otherwise prefer DRAM\n-  }\n-  return heap_caps_realloc(ptr, size, caps1);\n+void *d_calloc(size_t count, size_t size) {\n+  void *buffer = d_malloc(count * size);\n+  if (buffer) memset(buffer, 0, count * size); // clear allocated buffer\n+  return buffer;\n }\n \n // realloc with malloc fallback, original buffer is freed if realloc fails but not copied!\n void *d_realloc_malloc(void *ptr, size_t size) {\n-  void *newbuf = d_realloc(ptr, size); // try realloc first\n-  if (newbuf) return newbuf; // realloc successful\n-  d_free(ptr); // free old buffer if realloc failed\n+  void *buffer = heap_caps_realloc(ptr, size, MALLOC_CAP_INTERNAL | MALLOC_CAP_8BIT);\n+  buffer = validateFreeHeap(buffer);\n+  if (buffer) return buffer; // realloc successful\n+  d_free(ptr); // free old buffer if realloc failed (or min heap was exceeded)\n   return d_malloc(size); // fallback to malloc\n }\n \n-void *d_calloc(size_t count, size_t size) {\n-  int caps1 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n-  int caps2 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n-  if (psramSafe) {\n-    if (size > MIN_HEAP_SIZE) std::swap(caps1, caps2);  // prefer PSRAM for large alloactions\n-    return heap_caps_calloc_prefer(count, size, 2, caps1, caps2); // otherwise prefer DRAM\n-  }\n-  return heap_caps_calloc(count, size, caps1);\n+#ifdef BOARD_HAS_PSRAM\n+// p_xalloc: prefer PSRAM, use DRAM as fallback\n+void *p_malloc(size_t size) {\n+  void *buffer = heap_caps_malloc_prefer(size, 2, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT, MALLOC_CAP_INTERNAL | MALLOC_CAP_8BIT);\n+  return validateFreeHeap(buffer);\n }\n-#else // ESP8266 & ESP32-C3\n+\n+void *p_calloc(size_t count, size_t size) {\n+  void *buffer = p_malloc(count * size);\n+  if (buffer) memset(buffer, 0, count * size); // clear allocated buffer\n+  return buffer;\n+}\n+\n // realloc with malloc fallback, original buffer is freed if realloc fails but not copied!\n-void *realloc_malloc(void *ptr, size_t size) {\n-  void *newbuf = realloc(ptr, size); // try realloc first\n-  if (newbuf) return newbuf; // realloc successful\n-  free(ptr); // free old buffer if realloc failed\n-  return malloc(size); // fallback to malloc\n+void *p_realloc_malloc(void *ptr, size_t size) {\n+  void *buffer = heap_caps_realloc(ptr, size, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);\n+  if (buffer) return buffer; // realloc successful\n+  p_free(ptr); // free old buffer if realloc failed\n+  return p_malloc(size); // fallback to malloc\n }\n #endif\n+#endif\n+\n+// allocation function for buffers like pixel-buffers and segment data\n+// optimises the use of memory types to balance speed and heap availability, always favours DRAM if possible\n+// if multiple conflicting types are defined, the lowest bits of \"type\" take priority (see fcn_declare.h for types)\n+void *allocate_buffer(size_t size, uint32_t type) {\n+  void *buffer = nullptr;\n+  #ifdef CONFIG_IDF_TARGET_ESP32\n+  // only classic ESP32 has \"32bit accessible only\" aka IRAM type. Using it frees up normal DRAM for other purposes\n+  // this memory region is used for IRAM_ATTR functions, whatever is left is unused and can be used for pixel buffers\n+  // prefer this type over PSRAM as it is slightly faster, except for _pixels where it is on-par as PSRAM-caching does a good job for mostly sequential access\n+  if (type & BFRALLOC_NOBYTEACCESS) {\n+    // prefer 32bit region, then PSRAM, fallback to any heap. Note: if adding \"INTERNAL\"-flag this wont work\n+    buffer = heap_caps_malloc_prefer(size, 3, MALLOC_CAP_32BIT, MALLOC_CAP_SPIRAM, MALLOC_CAP_8BIT);\n+    buffer = validateFreeHeap(buffer);\n+  }\n+  else\n+  #endif\n+  #if !defined(BOARD_HAS_PSRAM)\n+  buffer = d_malloc(size);\n+  #else\n+  if (type & BFRALLOC_PREFER_DRAM) {\n+    if (getContiguousFreeHeap() < 3*(MIN_HEAP_SIZE/2) + size && size > PSRAM_THRESHOLD)\n+      buffer = p_malloc(size); // prefer PSRAM for large allocations & when DRAM is low\n+    else\n+      buffer = d_malloc(size); // allocate in DRAM if enough free heap is available, PSRAM as fallback\n+  }\n+  else if (type & BFRALLOC_ENFORCE_DRAM)\n+    buffer = heap_caps_malloc(size, MALLOC_CAP_INTERNAL | MALLOC_CAP_8BIT); // use DRAM only, otherwise return nullptr\n+  else if (type & BFRALLOC_PREFER_PSRAM) {\n+    // if DRAM is plenty, prefer it over PSRAM for speed, reserve enough DRAM for segment data: if MAX_SEGMENT_DATA is exceeded, always uses PSRAM\n+    if (getContiguousFreeHeap() > 4*MIN_HEAP_SIZE + size + ((uint32_t)(MAX_SEGMENT_DATA - Segment::getUsedSegmentData())))\n+      buffer = d_malloc(size);\n+    else\n+      buffer = p_malloc(size); // prefer PSRAM\n+  }\n+  else if (type & BFRALLOC_ENFORCE_PSRAM)\n+    buffer = heap_caps_malloc(size, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT); // use PSRAM only, otherwise return nullptr\n+  buffer = validateFreeHeap(buffer);\n+  #endif\n+  if (buffer && (type & BFRALLOC_CLEAR))\n+    memset(buffer, 0, size); // clear allocated buffer\n+  /*\n+  #if !defined(ESP8266) && defined(WLED_DEBUG)\n+  if (buffer) {\n+    DEBUG_PRINTF_P(PSTR(\"*Buffer allocated: size:%d, address:%p\"), size, (uintptr_t)buffer);\n+    if ((uintptr_t)buffer > SOC_DRAM_LOW && (uintptr_t)buffer < SOC_DRAM_HIGH)\n+      DEBUG_PRINTLN(F(\" in DRAM\"));\n+    #ifndef CONFIG_IDF_TARGET_ESP32C3\n+    else if ((uintptr_t)buffer > SOC_EXTRAM_DATA_LOW && (uintptr_t)buffer < SOC_EXTRAM_DATA_HIGH)\n+      DEBUG_PRINTLN(F(\" in PSRAM\"));\n+    #endif\n+    #ifdef CONFIG_IDF_TARGET_ESP32\n+    else if ((uintptr_t)buffer > SOC_IRAM_LOW && (uintptr_t)buffer < SOC_IRAM_HIGH)\n+      DEBUG_PRINTLN(F(\" in IRAM\"));   // only used on ESP32 (MALLOC_CAP_32BIT)\n+    #else\n+    else if ((uintptr_t)buffer > SOC_RTC_DRAM_LOW && (uintptr_t)buffer < SOC_RTC_DRAM_HIGH)\n+      DEBUG_PRINTLN(F(\" in RTCRAM\")); // not available on ESP32\n+    #endif\n+    else\n+      DEBUG_PRINTLN(F(\" in ???\")); // unknown (check soc.h for other memory regions)\n+  } else\n+    DEBUG_PRINTF_P(PSTR(\"Buffer allocation failed: size:%d\\n\"), size);\n+  #endif \n+  */\n+  return buffer;\n+}\n \n // bootloop detection and handling\n // checks if the ESP reboots multiple times due to a crash or watchdog timeout\ndiff --git a/wled00/wled.cpp b/wled00/wled.cpp\nindex 9b15f7a32a..95b48319d2 100644\n--- a/wled00/wled.cpp\n+++ b/wled00/wled.cpp\n@@ -171,7 +171,7 @@ void WLED::loop()\n \n   // reconnect WiFi to clear stale allocations if heap gets too low\n   if (millis() - heapTime > 15000) {\n-    uint32_t heap = ESP.getFreeHeap();\n+    uint32_t heap = getContiguousFreeHeap();\n     if (heap < MIN_HEAP_SIZE && lastHeap < MIN_HEAP_SIZE) {\n       DEBUG_PRINTF_P(PSTR(\"Heap too low! %u\\n\"), heap);\n       forceReconnect = true;\n@@ -241,13 +241,37 @@ void WLED::loop()\n     DEBUG_PRINTLN(F(\"---DEBUG INFO---\"));\n     DEBUG_PRINTF_P(PSTR(\"Runtime: %lu\\n\"),  millis());\n     DEBUG_PRINTF_P(PSTR(\"Unix time: %u,%03u\\n\"), toki.getTime().sec, toki.getTime().ms);\n-    DEBUG_PRINTF_P(PSTR(\"Free heap: %u\\n\"), ESP.getFreeHeap());\n     #if defined(ARDUINO_ARCH_ESP32)\n+    DEBUG_PRINTLN(F(\"=== Memory Info ===\"));\n+    // Internal DRAM (standard 8-bit accessible heap)\n+    size_t dram_free = heap_caps_get_free_size(MALLOC_CAP_8BIT | MALLOC_CAP_INTERNAL);\n+    size_t dram_largest = heap_caps_get_largest_free_block(MALLOC_CAP_8BIT | MALLOC_CAP_INTERNAL);\n+    DEBUG_PRINTF_P(PSTR(\"DRAM 8-bit:   Free: %7u bytes | Largest block: %7u bytes\\n\"), dram_free, dram_largest);\n+    #ifdef BOARD_HAS_PSRAM\n+    size_t psram_free = heap_caps_get_free_size(MALLOC_CAP_SPIRAM);\n+    size_t psram_largest = heap_caps_get_largest_free_block(MALLOC_CAP_SPIRAM);\n+    DEBUG_PRINTF_P(PSTR(\"PSRAM:        Free: %7u bytes | Largest block: %6u bytes\\n\"), psram_free, psram_largest);\n+    #endif\n+    #if defined(CONFIG_IDF_TARGET_ESP32)\n+    // 32-bit DRAM (not byte accessible, only available on ESP32)\n+    size_t dram32_free = heap_caps_get_free_size(MALLOC_CAP_32BIT | MALLOC_CAP_INTERNAL) - dram_free; // returns all 32bit DRAM, subtract 8bit DRAM\n+    //size_t dram32_largest = heap_caps_get_largest_free_block(MALLOC_CAP_32BIT | MALLOC_CAP_INTERNAL); // returns largest DRAM block -> not useful\n+    DEBUG_PRINTF_P(PSTR(\"DRAM 32-bit:  Free: %7u bytes | Largest block: N/A\\n\"), dram32_free);\n+    #else\n+    // Fast RTC Memory (not available on ESP32)\n+    size_t rtcram_free = heap_caps_get_free_size(MALLOC_CAP_RTCRAM);\n+    size_t rtcram_largest = heap_caps_get_largest_free_block(MALLOC_CAP_RTCRAM);\n+    DEBUG_PRINTF_P(PSTR(\"RTC RAM:      Free: %7u bytes | Largest block: %7u bytes\\n\"), rtcram_free, rtcram_largest);\n+    #endif\n     if (psramFound()) {\n       DEBUG_PRINTF_P(PSTR(\"PSRAM: %dkB/%dkB\\n\"), ESP.getFreePsram()/1024, ESP.getPsramSize()/1024);\n-      if (!psramSafe) DEBUG_PRINTLN(F(\"Not using PSRAM.\"));\n+    #ifndef BOARD_HAS_PSRAM\n+      DEBUG_PRINTLN(F(\"BOARD_HAS_PSRAM not defined, not using PSRAM.\"));\n+    #endif\n     }\n     DEBUG_PRINTF_P(PSTR(\"TX power: %d/%d\\n\"), WiFi.getTxPower(), txPower);\n+    #else // ESP8266\n+    DEBUG_PRINTF_P(PSTR(\"Free heap/contiguous: %u/%u\\n\"), getFreeHeapSize(), getContiguousFreeHeap());\n     #endif\n     DEBUG_PRINTF_P(PSTR(\"Wifi state: %d\\n\"), WiFi.status());\n     #ifndef WLED_DISABLE_ESPNOW\n@@ -367,20 +391,16 @@ void WLED::setup()\n   DEBUG_PRINTF_P(PSTR(\"esp8266 @ %u MHz.\\nCore: %s\\n\"), ESP.getCpuFreqMHz(), ESP.getCoreVersion());\n   DEBUG_PRINTF_P(PSTR(\"FLASH: %u MB\\n\"), (ESP.getFlashChipSize()/1024)/1024);\n #endif\n-  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), ESP.getFreeHeap());\n+  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), getFreeHeapSize());\n+\n+#if defined(BOARD_HAS_PSRAM)\n+  // if JSON buffer allocation fails requestJsonBufferLock() will always return false preventing crashes\n+  pDoc = new PSRAMDynamicJsonDocument(2 * JSON_BUFFER_SIZE);\n+  DEBUG_PRINTF_P(PSTR(\"JSON buffer size: %ubytes\\n\"), (2 * JSON_BUFFER_SIZE));\n+  DEBUG_PRINTF_P(PSTR(\"PSRAM: %dkB/%dkB\\n\"), ESP.getFreePsram()/1024, ESP.getPsramSize()/1024);\n+#endif\n \n #if defined(ARDUINO_ARCH_ESP32)\n-  // BOARD_HAS_PSRAM also means that a compiler flag \"-mfix-esp32-psram-cache-issue\" was used and so PSRAM is safe to use on rev.1 ESP32\n-  #if !defined(BOARD_HAS_PSRAM) && !(defined(CONFIG_IDF_TARGET_ESP32S2) || defined(CONFIG_IDF_TARGET_ESP32S3) || defined(CONFIG_IDF_TARGET_ESP32C3))\n-  if (psramFound() && ESP.getChipRevision() < 3) psramSafe = false;\n-  if (!psramSafe) DEBUG_PRINTLN(F(\"Not using PSRAM.\"));\n-  #endif\n-  pDoc = new PSRAMDynamicJsonDocument((psramSafe && psramFound() ? 2 : 1)*JSON_BUFFER_SIZE);\n-  DEBUG_PRINTF_P(PSTR(\"JSON buffer allocated: %u\\n\"), (psramSafe && psramFound() ? 2 : 1)*JSON_BUFFER_SIZE);\n-  // if the above fails requestJsonBufferLock() will always return false preventing crashes\n-  if (psramFound()) {\n-    DEBUG_PRINTF_P(PSTR(\"PSRAM: %dkB/%dkB\\n\"), ESP.getFreePsram()/1024, ESP.getPsramSize()/1024);\n-  }\n   DEBUG_PRINTF_P(PSTR(\"TX power: %d/%d\\n\"), WiFi.getTxPower(), txPower);\n #endif\n \n@@ -395,7 +415,7 @@ void WLED::setup()\n   PinManager::allocatePin(2, true, PinOwner::DMX);\n #endif\n \n-  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), ESP.getFreeHeap());\n+  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), getFreeHeapSize());\n \n   bool fsinit = false;\n   DEBUGFS_PRINTLN(F(\"Mount FS\"));\n@@ -433,7 +453,7 @@ void WLED::setup()\n   }\n   DEBUG_PRINTLN(F(\"Reading config\"));\n   bool needsCfgSave = deserializeConfigFromFS();\n-  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), ESP.getFreeHeap());\n+  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), getFreeHeapSize());\n \n #if defined(STATUSLED) && STATUSLED>=0\n   if (!PinManager::isPinAllocated(STATUSLED)) {\n@@ -445,12 +465,12 @@ void WLED::setup()\n \n   DEBUG_PRINTLN(F(\"Initializing strip\"));\n   beginStrip();\n-  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), ESP.getFreeHeap());\n+  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), getFreeHeapSize());\n \n   DEBUG_PRINTLN(F(\"Usermods setup\"));\n   userSetup();\n   UsermodManager::setup();\n-  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), ESP.getFreeHeap());\n+  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), getFreeHeapSize());\n \n   if (needsCfgSave) serializeConfigToFS(); // usermods required new parameters; need to wait for strip to be initialised #4752\n \n@@ -515,13 +535,13 @@ void WLED::setup()\n   // HTTP server page init\n   DEBUG_PRINTLN(F(\"initServer\"));\n   initServer();\n-  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), ESP.getFreeHeap());\n+  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), getFreeHeapSize());\n \n #ifndef WLED_DISABLE_INFRARED\n   // init IR\n   DEBUG_PRINTLN(F(\"initIR\"));\n   initIR();\n-  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), ESP.getFreeHeap());\n+  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), getFreeHeapSize());\n #endif\n \n   // Seed FastLED random functions with an esp random value, which already works properly at this point.\ndiff --git a/wled00/wled.h b/wled00/wled.h\nindex 3f3fb27ca2..c99662fc57 100644\n--- a/wled00/wled.h\n+++ b/wled00/wled.h\n@@ -167,16 +167,13 @@\n // The following is a construct to enable code to compile without it.\n // There is a code that will still not use PSRAM though:\n //    AsyncJsonResponse is a derived class that implements DynamicJsonDocument (AsyncJson-v6.h)\n-#if defined(ARDUINO_ARCH_ESP32)\n-extern bool psramSafe;\n+#if defined(BOARD_HAS_PSRAM)\n struct PSRAM_Allocator {\n   void* allocate(size_t size) {\n-    if (psramSafe && psramFound()) return ps_malloc(size); // use PSRAM if it exists\n-    else                           return malloc(size);    // fallback\n+    return ps_malloc(size); // use PSRAM\n   }\n   void* reallocate(void* ptr, size_t new_size) {\n-    if (psramSafe && psramFound()) return ps_realloc(ptr, new_size); // use PSRAM if it exists\n-    else                           return realloc(ptr, new_size);    // fallback\n+    return ps_realloc(ptr, new_size); // use PSRAM\n   }\n   void deallocate(void* pointer) {\n     free(pointer);\n@@ -894,8 +891,6 @@ WLED_GLOBAL byte optionType;\n WLED_GLOBAL bool configNeedsWrite  _INIT(false);        // flag to initiate saving of config\n WLED_GLOBAL bool doReboot          _INIT(false);        // flag to initiate reboot from async handlers\n \n-WLED_GLOBAL bool psramSafe         _INIT(true);         // is it safe to use PSRAM (on ESP32 rev.1; compiler fix used \"-mfix-esp32-psram-cache-issue\")\n-\n // status led\n #if defined(STATUSLED)\n WLED_GLOBAL unsigned long ledStatusLastMillis _INIT(0);\n@@ -969,8 +964,11 @@ WLED_GLOBAL int8_t spi_sclk  _INIT(SPISCLKPIN);\n \n // global ArduinoJson buffer\n #if defined(ARDUINO_ARCH_ESP32)\n-WLED_GLOBAL JsonDocument *pDoc _INIT(nullptr);\n WLED_GLOBAL SemaphoreHandle_t jsonBufferLockMutex _INIT(xSemaphoreCreateRecursiveMutex());\n+#endif\n+#ifdef BOARD_HAS_PSRAM\n+// if board has PSRAM, use it for JSON document (allocated in setup())\n+WLED_GLOBAL JsonDocument *pDoc _INIT(nullptr);\n #else\n WLED_GLOBAL StaticJsonDocument<JSON_BUFFER_SIZE> gDoc;\n WLED_GLOBAL JsonDocument *pDoc _INIT(&gDoc);\ndiff --git a/wled00/wled_server.cpp b/wled00/wled_server.cpp\nindex 12e2862953..65d9585900 100644\n--- a/wled00/wled_server.cpp\n+++ b/wled00/wled_server.cpp\n@@ -368,7 +368,7 @@ void initServer()\n   });\n \n   server.on(F(\"/freeheap\"), HTTP_GET, [](AsyncWebServerRequest *request){\n-    request->send(200, FPSTR(CONTENT_TYPE_PLAIN), (String)ESP.getFreeHeap());\n+    request->send(200, FPSTR(CONTENT_TYPE_PLAIN), (String)getFreeHeapSize());\n   });\n \n #ifdef WLED_ENABLE_USERMOD_PAGE\ndiff --git a/wled00/ws.cpp b/wled00/ws.cpp\nindex 45640b68ce..4522e1815f 100644\n--- a/wled00/ws.cpp\n+++ b/wled00/ws.cpp\n@@ -124,8 +124,8 @@ void sendDataWs(AsyncWebSocketClient * client)\n   DEBUG_PRINTF_P(PSTR(\"JSON buffer size: %u for WS request (%u).\\n\"), pDoc->memoryUsage(), len);\n \n   // the following may no longer be necessary as heap management has been fixed by @willmmiles in AWS\n-  size_t heap1 = ESP.getFreeHeap();\n-  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), ESP.getFreeHeap());\n+  size_t heap1 = getFreeHeapSize();\n+  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), getFreeHeapSize());\n   #ifdef ESP8266\n   if (len>heap1) {\n     DEBUG_PRINTLN(F(\"Out of memory (WS)!\"));\n@@ -134,8 +134,8 @@ void sendDataWs(AsyncWebSocketClient * client)\n   #endif\n   AsyncWebSocketBuffer buffer(len);\n   #ifdef ESP8266\n-  size_t heap2 = ESP.getFreeHeap();\n-  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), ESP.getFreeHeap());\n+  size_t heap2 = getFreeHeapSize();\n+  DEBUG_PRINTF_P(PSTR(\"heap %u\\n\"), getFreeHeapSize());\n   #else\n   size_t heap2 = 0; // ESP32 variants do not have the same issue and will work without checking heap allocation\n   #endif\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Heap Management Issues**: The heap is inaccurately reported on ESP32 unless PR changes are applied. Investigate heap fragmentation to prevent the UI from becoming unresponsive at low contiguous block sizes (~8k). \n\n2. **PSRAM Utilization**: Use PSRAM strategically for handling pixels. Adjust allocation parameters to keep pixel buffers in DRAM as needed.\n\n3. **Defrag Function**: The defragmentation function leads to temporary heap blocking and should be in a separate PR to mitigate potential bugs. \n\n4. **Large Allocation Strategy**: Consider pre-allocating larger memory chunks at boot to combat fragmentation, but be aware of allocation failures.\n\n5. **OOM Management**: Implement prevention for new segment creation when available heap drops below a threshold to manage OOM issues effectively. \n\n6. **Next Steps**: Plan to test code updates post-integration of insights from contributors; open GitHub issues to track unresolved heap concerns."
      }
    ],
    "codediff_length": 48447
  },
  {
    "index": 29,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/usermods/audioreactive/audio_reactive.h b/usermods/audioreactive/audio_reactive.h\nindex 8741eb14ce..088ac880b8 100644\n--- a/usermods/audioreactive/audio_reactive.h\n+++ b/usermods/audioreactive/audio_reactive.h\n@@ -1,6 +1,9 @@\n #pragma once\n \n #include \"wled.h\"\n+\n+#ifdef ARDUINO_ARCH_ESP32\n+\n #include <driver/i2s.h>\n #include <driver/adc.h>\n \n@@ -8,11 +11,9 @@\n   #error This audio reactive usermod is not compatible with DMX Out.\n #endif\n \n-#ifndef ARDUINO_ARCH_ESP32\n-  #error This audio reactive usermod does not support the ESP8266.\n #endif\n \n-#if defined(WLED_DEBUG) || defined(SR_DEBUG)\n+#if defined(ARDUINO_ARCH_ESP32) && (defined(WLED_DEBUG) || defined(SR_DEBUG))\n #include <esp_timer.h>\n #endif\n \n@@ -57,6 +58,50 @@\n \n #define MAX_PALETTES 3\n \n+static volatile bool disableSoundProcessing = false;      // if true, sound processing (FFT, filters, AGC) will be suspended. \"volatile\" as its shared between tasks.\n+static uint8_t audioSyncEnabled = 0;          // bit field: bit 0 - send, bit 1 - receive (config value)\n+static bool udpSyncConnected = false;         // UDP connection status -> true if connected to multicast group\n+\n+#define NUM_GEQ_CHANNELS 16                                           // number of frequency channels. Don't change !!\n+\n+// audioreactive variables\n+#ifdef ARDUINO_ARCH_ESP32\n+static float    micDataReal = 0.0f;             // MicIn data with full 24bit resolution - lowest 8bit after decimal point\n+static float    multAgc = 1.0f;                 // sample * multAgc = sampleAgc. Our AGC multiplier\n+static float    sampleAvg = 0.0f;               // Smoothed Average sample - sampleAvg < 1 means \"quiet\" (simple noise gate)\n+static float    sampleAgc = 0.0f;               // Smoothed AGC sample\n+static uint8_t  soundAgc = 0;                   // Automagic gain control: 0 - none, 1 - normal, 2 - vivid, 3 - lazy (config value)\n+#endif\n+//static float    volumeSmth = 0.0f;              // either sampleAvg or sampleAgc depending on soundAgc; smoothed sample\n+static float FFT_MajorPeak = 1.0f;              // FFT: strongest (peak) frequency\n+static float FFT_Magnitude = 0.0f;              // FFT: volume (magnitude) of peak frequency\n+static bool samplePeak = false;      // Boolean flag for peak - used in effects. Responding routine may reset this flag. Auto-reset after strip.getMinShowDelay()\n+static bool udpSamplePeak = false;   // Boolean flag for peak. Set at the same time as samplePeak, but reset by transmitAudioData\n+static unsigned long timeOfPeak = 0; // time of last sample peak detection.\n+static uint8_t fftResult[NUM_GEQ_CHANNELS]= {0};// Our calculated freq. channel result table to be used by effects\n+\n+// TODO: probably best not used by receive nodes\n+//static float agcSensitivity = 128;            // AGC sensitivity estimation, based on agc gain (multAgc). calculated by getSensitivity(). range 0..255\n+\n+// user settable parameters for limitSoundDynamics()\n+#ifdef UM_AUDIOREACTIVE_DYNAMICS_LIMITER_OFF\n+static bool limiterOn = false;                 // bool: enable / disable dynamics limiter\n+#else\n+static bool limiterOn = true;\n+#endif\n+static uint16_t attackTime =  80;             // int: attack time in milliseconds. Default 0.08sec\n+static uint16_t decayTime = 1400;             // int: decay time in milliseconds.  Default 1.40sec\n+\n+// peak detection\n+#ifdef ARDUINO_ARCH_ESP32\n+static void detectSamplePeak(void);  // peak detection function (needs scaled FFT results in vReal[]) - no used for 8266 receive-only mode\n+#endif\n+static void autoResetPeak(void);     // peak auto-reset function\n+static uint8_t maxVol = 31;          // (was 10) Reasonable value for constant volume for 'peak detector', as it won't always trigger  (deprecated)\n+static uint8_t binNum = 8;           // Used to select the bin for FFT based beat detection  (deprecated)\n+\n+#ifdef ARDUINO_ARCH_ESP32\n+\n // use audio source class (ESP32 specific)\n #include \"audio_source.h\"\n constexpr i2s_port_t I2S_PORT = I2S_NUM_0;       // I2S port to use (do not change !)\n@@ -74,18 +119,6 @@ static uint8_t inputLevel = 128;              // UI slider value\n #else\n   uint8_t sampleGain = SR_GAIN;               // sample gain (config value)\n #endif\n-static uint8_t soundAgc = 1;                  // Automagic gain control: 0 - none, 1 - normal, 2 - vivid, 3 - lazy (config value)\n-static uint8_t audioSyncEnabled = 0;          // bit field: bit 0 - send, bit 1 - receive (config value)\n-static bool udpSyncConnected = false;         // UDP connection status -> true if connected to multicast group\n-\n-// user settable parameters for limitSoundDynamics()\n-#ifdef UM_AUDIOREACTIVE_DYNAMICS_LIMITER_OFF\n-static bool limiterOn = false;                 // bool: enable / disable dynamics limiter\n-#else\n-static bool limiterOn = true;\n-#endif\n-static uint16_t attackTime =  80;             // int: attack time in milliseconds. Default 0.08sec\n-static uint16_t decayTime = 1400;             // int: decay time in milliseconds.  Default 1.40sec\n // user settable options for FFTResult scaling\n static uint8_t FFTScalingMode = 3;            // 0 none; 1 optimized logarithmic; 2 optimized linear; 3 optimized square root\n \n@@ -109,25 +142,8 @@ const float agcSampleSmooth[AGC_NUM_PRESETS]  = {  1/12.f,   1/6.f,  1/16.f}; //\n // AGC presets end\n \n static AudioSource *audioSource = nullptr;\n-static volatile bool disableSoundProcessing = false;      // if true, sound processing (FFT, filters, AGC) will be suspended. \"volatile\" as its shared between tasks.\n static bool useBandPassFilter = false;                    // if true, enables a bandpass filter 80Hz-16Khz to remove noise. Applies before FFT.\n \n-// audioreactive variables shared with FFT task\n-static float    micDataReal = 0.0f;             // MicIn data with full 24bit resolution - lowest 8bit after decimal point\n-static float    multAgc = 1.0f;                 // sample * multAgc = sampleAgc. Our AGC multiplier\n-static float    sampleAvg = 0.0f;               // Smoothed Average sample - sampleAvg < 1 means \"quiet\" (simple noise gate)\n-static float    sampleAgc = 0.0f;               // Smoothed AGC sample\n-\n-// peak detection\n-static bool samplePeak = false;      // Boolean flag for peak - used in effects. Responding routine may reset this flag. Auto-reset after strip.getMinShowDelay()\n-static uint8_t maxVol = 31;          // Reasonable value for constant volume for 'peak detector', as it won't always trigger (deprecated)\n-static uint8_t binNum = 8;           // Used to select the bin for FFT based beat detection  (deprecated)\n-static bool udpSamplePeak = false;   // Boolean flag for peak. Set at the same time as samplePeak, but reset by transmitAudioData\n-static unsigned long timeOfPeak = 0; // time of last sample peak detection.\n-static void detectSamplePeak(void);  // peak detection function (needs scaled FFT results in vReal[])\n-static void autoResetPeak(void);     // peak auto-reset function\n-\n-\n ////////////////////\n // Begin FFT Code //\n ////////////////////\n@@ -139,17 +155,12 @@ void FFTcode(void * parameter);      // audio processing task: read samples, run\n static void runMicFilter(uint16_t numSamples, float *sampleBuffer);          // pre-filtering of raw samples (band-pass)\n static void postProcessFFTResults(bool noiseGateOpen, int numberOfChannels); // post-processing and post-amp of GEQ channels\n \n-#define NUM_GEQ_CHANNELS 16                                           // number of frequency channels. Don't change !!\n-\n static TaskHandle_t FFT_Task = nullptr;\n \n // Table of multiplication factors so that we can even out the frequency response.\n static float fftResultPink[NUM_GEQ_CHANNELS] = { 1.70f, 1.71f, 1.73f, 1.78f, 1.68f, 1.56f, 1.55f, 1.63f, 1.79f, 1.62f, 1.80f, 2.06f, 2.47f, 3.35f, 6.83f, 9.55f };\n \n // globals and FFT Output variables shared with animations\n-static float FFT_MajorPeak = 1.0f;              // FFT: strongest (peak) frequency\n-static float FFT_Magnitude = 0.0f;              // FFT: volume (magnitude) of peak frequency\n-static uint8_t fftResult[NUM_GEQ_CHANNELS]= {0};// Our calculated freq. channel result table to be used by effects\n #if defined(WLED_DEBUG) || defined(SR_DEBUG)\n static uint64_t fftTime = 0;\n static uint64_t sampleTime = 0;\n@@ -522,6 +533,8 @@ static void detectSamplePeak(void) {\n   }\n }\n \n+#endif\n+\n static void autoResetPeak(void) {\n   uint16_t MinShowDelay = MAX(50, strip.getMinShowDelay());  // Fixes private class variable compiler error. Unsure if this is the correct way of fixing the root problem. -THATDONFC\n   if (millis() - timeOfPeak > MinShowDelay) {          // Auto-reset of samplePeak after a complete frame has passed.\n@@ -539,6 +552,8 @@ static void autoResetPeak(void) {\n class AudioReactive : public Usermod {\n \n   private:\n+#ifdef ARDUINO_ARCH_ESP32\n+\n     #ifndef AUDIOPIN\n     int8_t audioPin = -1;\n     #else\n@@ -570,20 +585,23 @@ class AudioReactive : public Usermod {\n     #else\n     int8_t mclkPin = MCLK_PIN;\n     #endif\n+#endif\n \n-    // new \"V2\" audiosync struct - 40 Bytes\n-    struct audioSyncPacket {\n-      char    header[6];      //  06 Bytes\n-      float   sampleRaw;      //  04 Bytes  - either \"sampleRaw\" or \"rawSampleAgc\" depending on soundAgc setting\n-      float   sampleSmth;     //  04 Bytes  - either \"sampleAvg\" or \"sampleAgc\" depending on soundAgc setting\n-      uint8_t samplePeak;     //  01 Bytes  - 0 no peak; >=1 peak detected. In future, this will also provide peak Magnitude\n-      uint8_t reserved1;      //  01 Bytes  - for future extensions - not used yet\n-      uint8_t fftResult[16];  //  16 Bytes\n-      float  FFT_Magnitude;   //  04 Bytes\n-      float  FFT_MajorPeak;   //  04 Bytes\n+    // new \"V2\" audiosync struct - 44 Bytes\n+    struct __attribute__ ((packed)) audioSyncPacket {  // \"packed\" ensures that there are no additional gaps\n+      char    header[6];      //  06 Bytes  offset 0\n+      uint8_t reserved1[2];   //  02 Bytes, offset 6  - gap required by the compiler - not used yet \n+      float   sampleRaw;      //  04 Bytes  offset 8  - either \"sampleRaw\" or \"rawSampleAgc\" depending on soundAgc setting\n+      float   sampleSmth;     //  04 Bytes  offset 12 - either \"sampleAvg\" or \"sampleAgc\" depending on soundAgc setting\n+      uint8_t samplePeak;     //  01 Bytes  offset 16 - 0 no peak; >=1 peak detected. In future, this will also provide peak Magnitude\n+      uint8_t reserved2;      //  01 Bytes  offset 17 - for future extensions - not used yet\n+      uint8_t fftResult[16];  //  16 Bytes  offset 18\n+      uint16_t reserved3;     //  02 Bytes, offset 34 - gap required by the compiler - not used yet\n+      float  FFT_Magnitude;   //  04 Bytes  offset 36\n+      float  FFT_MajorPeak;   //  04 Bytes  offset 40\n     };\n \n-    // old \"V1\" audiosync struct - 83 Bytes - for backwards compatibility\n+    // old \"V1\" audiosync struct - 83 Bytes payload, 88 bytes total (with padding added by compiler) - for backwards compatibility\n     struct audioSyncPacket_v1 {\n       char header[6];         //  06 Bytes\n       uint8_t myVals[32];     //  32 Bytes\n@@ -596,6 +614,8 @@ class AudioReactive : public Usermod {\n       double FFT_MajorPeak;   //  08 Bytes\n     };\n \n+    #define UDPSOUND_MAX_PACKET 88 // max packet size for audiosync\n+\n     // set your config variables to their boot default value (this can also be done in readFromConfig() or a constructor if you prefer)\n     #ifdef UM_AUDIOREACTIVE_ENABLE\n     bool     enabled = true;\n@@ -613,10 +633,14 @@ class AudioReactive : public Usermod {\n     const uint16_t delayMs = 10;  // I don't want to sample too often and overload WLED\n     uint16_t audioSyncPort= 11988;// default port for UDP sound sync\n \n+    bool updateIsRunning = false; // true during OTA.\n+\n+#ifdef ARDUINO_ARCH_ESP32\n     // used for AGC\n     int      last_soundAgc = -1;   // used to detect AGC mode change (for resetting AGC internal error buffers)\n     double   control_integrated = 0.0;   // persistent across calls to agcAvg(); \"integrator control\" = accumulated error\n \n+\n     // variables used by getSample() and agcAvg()\n     int16_t  micIn = 0;           // Current sample starts with negative values and large values, which is why it's 16 bit signed\n     double   sampleMax = 0.0;     // Max sample over a few seconds. Needed for AGC controller.\n@@ -625,6 +649,7 @@ class AudioReactive : public Usermod {\n     float    sampleReal = 0.0f;\t  // \"sampleRaw\" as float, to provide bits that are lost otherwise (before amplification by sampleGain or inputLevel). Needed for AGC.\n     int16_t  sampleRaw = 0;       // Current sample. Must only be updated ONCE!!! (amplified mic value by sampleGain and inputLevel)\n     int16_t  rawSampleAgc = 0;    // not smoothed AGC sample\n+#endif\n \n     // variables used in effects\n     float   volumeSmth = 0.0f;    // either sampleAvg or sampleAgc depending on soundAgc; smoothed sample\n@@ -645,7 +670,9 @@ class AudioReactive : public Usermod {\n     static const char _dynamics[];\n     static const char _frequency[];\n     static const char _inputLvl[];\n+#if defined(ARDUINO_ARCH_ESP32) && !defined(CONFIG_IDF_TARGET_ESP32S2) && !defined(CONFIG_IDF_TARGET_ESP32C3) && !defined(CONFIG_IDF_TARGET_ESP32S3)\n     static const char _analogmic[];\n+#endif\n     static const char _digitalmic[];\n     static const char _addPalettes[];\n     static const char UDP_SYNC_HEADER[];\n@@ -672,11 +699,13 @@ class AudioReactive : public Usermod {\n       //PLOT_PRINT(\"sampleAgc:\");   PLOT_PRINT(sampleAgc);   PLOT_PRINT(\"\\t\");\n       //PLOT_PRINT(\"sampleAvg:\");   PLOT_PRINT(sampleAvg);   PLOT_PRINT(\"\\t\");\n       //PLOT_PRINT(\"sampleReal:\");  PLOT_PRINT(sampleReal);  PLOT_PRINT(\"\\t\");\n+    #ifdef ARDUINO_ARCH_ESP32\n       //PLOT_PRINT(\"micIn:\");       PLOT_PRINT(micIn);       PLOT_PRINT(\"\\t\");\n       //PLOT_PRINT(\"sample:\");      PLOT_PRINT(sample);      PLOT_PRINT(\"\\t\");\n       //PLOT_PRINT(\"sampleMax:\");   PLOT_PRINT(sampleMax);   PLOT_PRINT(\"\\t\");\n       //PLOT_PRINT(\"samplePeak:\");  PLOT_PRINT((samplePeak!=0) ? 128:0);   PLOT_PRINT(\"\\t\");\n       //PLOT_PRINT(\"multAgc:\");     PLOT_PRINT(multAgc, 4);  PLOT_PRINT(\"\\t\");\n+    #endif\n       PLOT_PRINTLN();\n     #endif\n \n@@ -732,6 +761,7 @@ class AudioReactive : public Usermod {\n     } // logAudio()\n \n \n+#ifdef ARDUINO_ARCH_ESP32\n     //////////////////////\n     // Audio Processing //\n     //////////////////////\n@@ -902,6 +932,7 @@ class AudioReactive : public Usermod {\n       sampleAvg = fabsf(sampleAvg);                            // make sure we have a positive value\n     } // getSample()\n \n+#endif\n \n     /* Limits the dynamics of volumeSmth (= sampleAvg or sampleAgc). \n      * does not affect FFTResult[] or volumeRaw ( = sample or rawSampleAgc) \n@@ -948,12 +979,14 @@ class AudioReactive : public Usermod {\n       if (udpSyncConnected) return;                                          // already connected\n       if (!(apActive || interfacesInited)) return;                           // neither AP nor other connections availeable\n       if (millis() - last_connection_attempt < 15000) return;                // only try once in 15 seconds\n+      if (updateIsRunning) return; \n \n       // if we arrive here, we need a UDP connection but don't have one\n       last_connection_attempt = millis();\n       connected(); // try to start UDP\n     }\n \n+#ifdef ARDUINO_ARCH_ESP32\n     void transmitAudioData()\n     {\n       if (!udpSyncConnected) return;\n@@ -968,7 +1001,6 @@ class AudioReactive : public Usermod {\n       transmitData.sampleSmth  = (soundAgc) ? sampleAgc   : sampleAvg;\n       transmitData.samplePeak  = udpSamplePeak ? 1:0;\n       udpSamplePeak            = false;           // Reset udpSamplePeak after we've transmitted it\n-      transmitData.reserved1   = 0;\n \n       for (int i = 0; i < NUM_GEQ_CHANNELS; i++) {\n         transmitData.fftResult[i] = (uint8_t)constrain(fftResult[i], 0, 254);\n@@ -984,37 +1016,44 @@ class AudioReactive : public Usermod {\n       return;\n     } // transmitAudioData()\n \n+#endif\n+\n     static bool isValidUdpSyncVersion(const char *header) {\n-      return strncmp_P(header, PSTR(UDP_SYNC_HEADER), 6) == 0;\n+      return strncmp_P(header, UDP_SYNC_HEADER, 6) == 0;\n     }\n     static bool isValidUdpSyncVersion_v1(const char *header) {\n-      return strncmp_P(header, PSTR(UDP_SYNC_HEADER_v1), 6) == 0;\n+      return strncmp_P(header, UDP_SYNC_HEADER_v1, 6) == 0;\n     }\n \n     void decodeAudioData(int packetSize, uint8_t *fftBuff) {\n-      audioSyncPacket *receivedPacket = reinterpret_cast<audioSyncPacket*>(fftBuff);\n+      audioSyncPacket receivedPacket;\n+      memset(&receivedPacket, 0, sizeof(receivedPacket));                                  // start clean\n+      memcpy(&receivedPacket, fftBuff, min((unsigned)packetSize, (unsigned)sizeof(receivedPacket))); // don't violate alignment - thanks @willmmiles#\n+\n       // update samples for effects\n-      volumeSmth   = fmaxf(receivedPacket->sampleSmth, 0.0f);\n-      volumeRaw    = fmaxf(receivedPacket->sampleRaw, 0.0f);\n+      volumeSmth   = fmaxf(receivedPacket.sampleSmth, 0.0f);\n+      volumeRaw    = fmaxf(receivedPacket.sampleRaw, 0.0f);\n+#ifdef ARDUINO_ARCH_ESP32\n       // update internal samples\n       sampleRaw    = volumeRaw;\n       sampleAvg    = volumeSmth;\n       rawSampleAgc = volumeRaw;\n       sampleAgc    = volumeSmth;\n       multAgc      = 1.0f;   \n+#endif\n       // Only change samplePeak IF it's currently false.\n       // If it's true already, then the animation still needs to respond.\n       autoResetPeak();\n       if (!samplePeak) {\n-            samplePeak = receivedPacket->samplePeak >0 ? true:false;\n+            samplePeak = receivedPacket.samplePeak >0 ? true:false;\n             if (samplePeak) timeOfPeak = millis();\n             //userVar1 = samplePeak;\n       }\n-      //These values are only available on the ESP32\n-      for (int i = 0; i < NUM_GEQ_CHANNELS; i++) fftResult[i] = receivedPacket->fftResult[i];\n-      my_magnitude  = fmaxf(receivedPacket->FFT_Magnitude, 0.0f);\n+      //These values are only computed by ESP32\n+      for (int i = 0; i < NUM_GEQ_CHANNELS; i++) fftResult[i] = receivedPacket.fftResult[i];\n+      my_magnitude  = fmaxf(receivedPacket.FFT_Magnitude, 0.0f);\n       FFT_Magnitude = my_magnitude;\n-      FFT_MajorPeak = constrain(receivedPacket->FFT_MajorPeak, 1.0f, 11025.0f);  // restrict value to range expected by effects\n+      FFT_MajorPeak = constrain(receivedPacket.FFT_MajorPeak, 1.0f, 11025.0f);  // restrict value to range expected by effects\n     }\n \n     void decodeAudioData_v1(int packetSize, uint8_t *fftBuff) {\n@@ -1022,12 +1061,14 @@ class AudioReactive : public Usermod {\n       // update samples for effects\n       volumeSmth   = fmaxf(receivedPacket->sampleAgc, 0.0f);\n       volumeRaw    = volumeSmth;   // V1 format does not have \"raw\" AGC sample\n+#ifdef ARDUINO_ARCH_ESP32\n       // update internal samples\n       sampleRaw    = fmaxf(receivedPacket->sampleRaw, 0.0f);\n       sampleAvg    = fmaxf(receivedPacket->sampleAvg, 0.0f);;\n       sampleAgc    = volumeSmth;\n       rawSampleAgc = volumeRaw;\n-      multAgc      = 1.0f;   \n+      multAgc      = 1.0f;\n+#endif \n       // Only change samplePeak IF it's currently false.\n       // If it's true already, then the animation still needs to respond.\n       autoResetPeak();\n@@ -1049,9 +1090,12 @@ class AudioReactive : public Usermod {\n       bool haveFreshData = false;\n \n       size_t packetSize = fftUdp.parsePacket();\n-      if (packetSize > 5) {\n+#ifdef ARDUINO_ARCH_ESP32\n+      if ((packetSize > 0) && ((packetSize < 5) || (packetSize > UDPSOUND_MAX_PACKET))) fftUdp.flush(); // discard invalid packets (too small or too big) - only works on esp32\n+#endif\n+      if ((packetSize > 5) && (packetSize <= UDPSOUND_MAX_PACKET)) {\n         //DEBUGSR_PRINTLN(\"Received UDP Sync Packet\");\n-        uint8_t fftBuff[packetSize];\n+        uint8_t fftBuff[UDPSOUND_MAX_PACKET+1] = { 0 }; // fixed-size buffer for receiving (stack), to avoid heap fragmentation caused by variable sized arrays\n         fftUdp.read(fftBuff, packetSize);\n \n         // VERIFY THAT THIS IS A COMPATIBLE PACKET\n@@ -1113,6 +1157,9 @@ class AudioReactive : public Usermod {\n         um_data->u_type[7] = UMT_BYTE;\n       }\n \n+\n+#ifdef ARDUINO_ARCH_ESP32\n+\n       // Reset I2S peripheral for good measure\n       i2s_driver_uninstall(I2S_NUM_0);   // E (696) I2S: i2s_driver_uninstall(2006): I2S port 0 has not installed\n       #if !defined(CONFIG_IDF_TARGET_ESP32C3)\n@@ -1190,10 +1237,12 @@ class AudioReactive : public Usermod {\n       delay(250); // give microphone enough time to initialise\n \n       if (!audioSource) enabled = false;                 // audio failed to initialise\n-      if (enabled) onUpdateBegin(false);                 // create FFT task\n-      if (FFT_Task == nullptr) enabled = false;          // FFT task creation failed\n-      if (enabled) disableSoundProcessing = false;       // all good - enable audio processing\n+#endif\n+      if (enabled) onUpdateBegin(false);                 // create FFT task, and initialize network\n+\n \n+#ifdef ARDUINO_ARCH_ESP32\n+      if (FFT_Task == nullptr) enabled = false;          // FFT task creation failed\n       if((!audioSource) || (!audioSource->isInitialized())) {  // audio source failed to initialize. Still stay \"enabled\", as there might be input arriving via UDP Sound Sync \n       #ifdef WLED_DEBUG\n         DEBUG_PRINTLN(F(\"AR: Failed to initialize sound input driver. Please check input PIN settings.\"));\n@@ -1202,7 +1251,8 @@ class AudioReactive : public Usermod {\n       #endif\n         disableSoundProcessing = true;\n       }\n-\n+#endif\n+      if (enabled) disableSoundProcessing = false;       // all good - enable audio processing\n       if (enabled) connectUDPSoundSync();\n       if (enabled && addPalettes) createAudioPalettes();\n       initDone = true;\n@@ -1221,7 +1271,7 @@ class AudioReactive : public Usermod {\n       }\n       \n       if (audioSyncPort > 0 && (audioSyncEnabled & 0x03)) {\n-      #ifndef ESP8266\n+      #ifdef ARDUINO_ARCH_ESP32\n         udpSyncConnected = fftUdp.beginMulticast(IPAddress(239, 0, 0, 1), audioSyncPort);\n       #else\n         udpSyncConnected = fftUdp.beginMulticast(WiFi.localIP(), IPAddress(239, 0, 0, 1), audioSyncPort);\n@@ -1260,7 +1310,7 @@ class AudioReactive : public Usermod {\n             ||(realtimeMode == REALTIME_MODE_ADALIGHT)\n             ||(realtimeMode == REALTIME_MODE_ARTNET) ) )  // please add other modes here if needed\n       {\n-        #ifdef WLED_DEBUG\n+        #if defined(ARDUINO_ARCH_ESP32) && defined(WLED_DEBUG)\n         if ((disableSoundProcessing == false) && (audioSyncEnabled == 0)) {  // we just switched to \"disabled\"\n           DEBUG_PRINTLN(F(\"[AR userLoop]  realtime mode active - audio processing suspended.\"));\n           DEBUG_PRINTF_P(PSTR(\"               RealtimeMode = %d; RealtimeOverride = %d\\n\"), int(realtimeMode), int(realtimeOverride));\n@@ -1268,7 +1318,7 @@ class AudioReactive : public Usermod {\n         #endif\n         disableSoundProcessing = true;\n       } else {\n-        #ifdef WLED_DEBUG\n+        #if defined(ARDUINO_ARCH_ESP32) && defined(WLED_DEBUG)\n         if ((disableSoundProcessing == true) && (audioSyncEnabled == 0) && audioSource->isInitialized()) {    // we just switched to \"enabled\"\n           DEBUG_PRINTLN(F(\"[AR userLoop]  realtime mode ended - audio processing resumed.\"));\n           DEBUG_PRINTF_P(PSTR(\"               RealtimeMode = %d; RealtimeOverride = %d\\n\"), int(realtimeMode), int(realtimeOverride));\n@@ -1280,6 +1330,7 @@ class AudioReactive : public Usermod {\n \n       if (audioSyncEnabled & 0x02) disableSoundProcessing = true;   // make sure everything is disabled IF in audio Receive mode\n       if (audioSyncEnabled & 0x01) disableSoundProcessing = false;  // keep running audio IF we're in audio Transmit mode\n+#ifdef ARDUINO_ARCH_ESP32\n       if (!audioSource->isInitialized()) disableSoundProcessing = true;  // no audio source\n \n \n@@ -1319,6 +1370,7 @@ class AudioReactive : public Usermod {\n \n         limitSampleDynamics();\n       }  // if (!disableSoundProcessing)\n+#endif\n \n       autoResetPeak();          // auto-reset sample peak after strip minShowDelay\n       if (!udpSyncConnected) udpSamplePeak = false;  // reset UDP samplePeak while UDP is unconnected\n@@ -1352,6 +1404,7 @@ class AudioReactive : public Usermod {\n       #endif\n \n       // Info Page: keep max sample from last 5 seconds\n+#ifdef ARDUINO_ARCH_ESP32\n       if ((millis() -  sampleMaxTimer) > CYCLE_SAMPLEMAX) {\n         sampleMaxTimer = millis();\n         maxSample5sec = (0.15f * maxSample5sec) + 0.85f *((soundAgc) ? sampleAgc : sampleAvg); // reset, and start with some smoothing\n@@ -1359,13 +1412,25 @@ class AudioReactive : public Usermod {\n       } else {\n          if ((sampleAvg >= 1)) maxSample5sec = fmaxf(maxSample5sec, (soundAgc) ? rawSampleAgc : sampleRaw); // follow maximum volume\n       }\n+#else  // similar functionality for 8266 receive only - use VolumeSmth instead of raw sample data\n+      if ((millis() -  sampleMaxTimer) > CYCLE_SAMPLEMAX) {\n+        sampleMaxTimer = millis();\n+        maxSample5sec = (0.15 * maxSample5sec) + 0.85 * volumeSmth; // reset, and start with some smoothing\n+        if (volumeSmth < 1.0f) maxSample5sec = 0; // noise gate\n+        if (maxSample5sec < 0.0f) maxSample5sec = 0; // avoid negative values\n+      } else {\n+         if (volumeSmth >= 1.0f) maxSample5sec = fmaxf(maxSample5sec, volumeRaw); // follow maximum volume\n+      }\n+#endif\n \n+#ifdef ARDUINO_ARCH_ESP32\n       //UDP Microphone Sync  - transmit mode\n       if ((audioSyncEnabled & 0x01) && (millis() - lastTime > 20)) {\n         // Only run the transmit code IF we're in Transmit mode\n         transmitAudioData();\n         lastTime = millis();\n       }\n+#endif\n \n       fillAudioPalettes();\n     }\n@@ -1378,7 +1443,7 @@ class AudioReactive : public Usermod {\n       return true;\n     }\n \n-\n+#ifdef ARDUINO_ARCH_ESP32\n     void onUpdateBegin(bool init) override\n     {\n #ifdef WLED_DEBUG\n@@ -1427,9 +1492,32 @@ class AudioReactive : public Usermod {\n       }\n       micDataReal = 0.0f;                     // just to be sure\n       if (enabled) disableSoundProcessing = false;\n+      updateIsRunning = init;\n     }\n \n+#else // reduced function for 8266\n+    void onUpdateBegin(bool init)\n+    {\n+      // gracefully suspend audio (if running)\n+      disableSoundProcessing = true;\n+      // reset sound data\n+      volumeRaw = 0; volumeSmth = 0;\n+      for(int i=(init?0:1); i<NUM_GEQ_CHANNELS; i+=2) fftResult[i] = 16; // make a tiny pattern\n+      autoResetPeak();\n+      if (init) {\n+        if (udpSyncConnected) {   // close UDP sync connection (if open)\n+          udpSyncConnected = false;\n+          fftUdp.stop();\n+          DEBUGSR_PRINTLN(F(\"AR onUpdateBegin(true): UDP connection closed.\"));\n+          receivedFormat = 0;\n+        }\n+      }\n+      if (enabled) disableSoundProcessing = init; // init = true means that OTA is just starting --> don't process audio\n+      updateIsRunning = init;\n+    }\n+#endif\n \n+#ifdef ARDUINO_ARCH_ESP32\n     /**\n      * handleButton() can be used to override default button behaviour. Returning true\n      * will prevent button working in a default way.\n@@ -1447,7 +1535,7 @@ class AudioReactive : public Usermod {\n       return false;\n     }\n \n-\n+#endif\n     ////////////////////////////\n     // Settings and Info Page //\n     ////////////////////////////\n@@ -1459,7 +1547,9 @@ class AudioReactive : public Usermod {\n      */\n     void addToJsonInfo(JsonObject& root) override\n     {\n-      char myStringBuffer[16]; // buffer for snprintf()\n+#ifdef ARDUINO_ARCH_ESP32\n+      char myStringBuffer[16]; // buffer for snprintf() - not used yet on 8266\n+#endif\n       JsonObject user = root[\"u\"];\n       if (user.isNull()) user = root.createNestedObject(\"u\");\n \n@@ -1477,6 +1567,7 @@ class AudioReactive : public Usermod {\n       infoArr.add(uiDomString);\n \n       if (enabled) {\n+#ifdef ARDUINO_ARCH_ESP32\n         // Input Level Slider\n         if (disableSoundProcessing == false) {                                 // only show slider when audio processing is running\n           if (soundAgc > 0) {\n@@ -1493,7 +1584,7 @@ class AudioReactive : public Usermod {\n           uiDomString += F(\" /><div class=\\\"sliderdisplay\\\"></div></div></div>\"); //<output class=\\\"sliderbubble\\\"></output>\n           infoArr.add(uiDomString);\n         } \n-\n+#endif\n         // The following can be used for troubleshooting user errors and is so not enclosed in #ifdef WLED_DEBUG\n \n         // current Audio input\n@@ -1509,6 +1600,11 @@ class AudioReactive : public Usermod {\n           } else {\n             infoArr.add(F(\" - no connection\"));\n           }\n+#ifndef ARDUINO_ARCH_ESP32  // substitute for 8266\n+        } else {\n+          infoArr.add(F(\"sound sync Off\"));\n+        }\n+#else  // ESP32 only\n         } else {\n           // Analog or I2S digital input\n           if (audioSource && (audioSource->isInitialized())) {\n@@ -1553,7 +1649,7 @@ class AudioReactive : public Usermod {\n           infoArr.add(roundf(multAgc*100.0f) / 100.0f);\n           infoArr.add(\"x\");\n         }\n-\n+#endif\n         // UDP Sound Sync status\n         infoArr = user.createNestedArray(F(\"UDP Sound Sync\"));\n         if (audioSyncEnabled) {\n@@ -1572,6 +1668,7 @@ class AudioReactive : public Usermod {\n         }\n \n         #if defined(WLED_DEBUG) || defined(SR_DEBUG)\n+        #ifdef ARDUINO_ARCH_ESP32\n         infoArr = user.createNestedArray(F(\"Sampling time\"));\n         infoArr.add(float(sampleTime)/100.0f);\n         infoArr.add(\" ms\");\n@@ -1588,6 +1685,7 @@ class AudioReactive : public Usermod {\n         DEBUGSR_PRINTF(\"AR Sampling time: %5.2f ms\\n\", float(sampleTime)/100.0f);\n         DEBUGSR_PRINTF(\"AR FFT time     : %5.2f ms\\n\", float(fftTime)/100.0f);\n         #endif\n+        #endif\n       }\n     }\n \n@@ -1626,9 +1724,11 @@ class AudioReactive : public Usermod {\n             if (!prevEnabled && enabled) createAudioPalettes();\n           }\n         }\n+#ifdef ARDUINO_ARCH_ESP32\n         if (usermod[FPSTR(_inputLvl)].is<int>()) {\n           inputLevel = min(255,max(0,usermod[FPSTR(_inputLvl)].as<int>()));\n         }\n+#endif\n       }\n       if (root.containsKey(F(\"rmcpal\")) && root[F(\"rmcpal\")].as<bool>()) {\n         // handle removal of custom palettes from JSON call so we don't break things\n@@ -1684,6 +1784,7 @@ class AudioReactive : public Usermod {\n       top[FPSTR(_enabled)] = enabled;\n       top[FPSTR(_addPalettes)] = addPalettes;\n \n+#ifdef ARDUINO_ARCH_ESP32\n     #if !defined(CONFIG_IDF_TARGET_ESP32S2) && !defined(CONFIG_IDF_TARGET_ESP32C3) && !defined(CONFIG_IDF_TARGET_ESP32S3)\n       JsonObject amic = top.createNestedObject(FPSTR(_analogmic));\n       amic[\"pin\"] = audioPin;\n@@ -1702,14 +1803,15 @@ class AudioReactive : public Usermod {\n       cfg[F(\"gain\")] = sampleGain;\n       cfg[F(\"AGC\")] = soundAgc;\n \n+      JsonObject freqScale = top.createNestedObject(FPSTR(_frequency));\n+      freqScale[F(\"scale\")] = FFTScalingMode;\n+#endif\n+\n       JsonObject dynLim = top.createNestedObject(FPSTR(_dynamics));\n       dynLim[F(\"limiter\")] = limiterOn;\n       dynLim[F(\"rise\")] = attackTime;\n       dynLim[F(\"fall\")] = decayTime;\n \n-      JsonObject freqScale = top.createNestedObject(FPSTR(_frequency));\n-      freqScale[F(\"scale\")] = FFTScalingMode;\n-\n       JsonObject sync = top.createNestedObject(\"sync\");\n       sync[\"port\"] = audioSyncPort;\n       sync[\"mode\"] = audioSyncEnabled;\n@@ -1741,6 +1843,7 @@ class AudioReactive : public Usermod {\n       configComplete &= getJsonValue(top[FPSTR(_enabled)], enabled);\n       configComplete &= getJsonValue(top[FPSTR(_addPalettes)], addPalettes);\n \n+#ifdef ARDUINO_ARCH_ESP32\n     #if !defined(CONFIG_IDF_TARGET_ESP32S2) && !defined(CONFIG_IDF_TARGET_ESP32C3) && !defined(CONFIG_IDF_TARGET_ESP32S3)\n       configComplete &= getJsonValue(top[FPSTR(_analogmic)][\"pin\"], audioPin);\n     #else\n@@ -1764,12 +1867,12 @@ class AudioReactive : public Usermod {\n       configComplete &= getJsonValue(top[FPSTR(_config)][F(\"gain\")],    sampleGain);\n       configComplete &= getJsonValue(top[FPSTR(_config)][F(\"AGC\")],     soundAgc);\n \n+      configComplete &= getJsonValue(top[FPSTR(_frequency)][F(\"scale\")], FFTScalingMode);\n+\n       configComplete &= getJsonValue(top[FPSTR(_dynamics)][F(\"limiter\")], limiterOn);\n       configComplete &= getJsonValue(top[FPSTR(_dynamics)][F(\"rise\")],  attackTime);\n       configComplete &= getJsonValue(top[FPSTR(_dynamics)][F(\"fall\")],  decayTime);\n-\n-      configComplete &= getJsonValue(top[FPSTR(_frequency)][F(\"scale\")], FFTScalingMode);\n-\n+#endif\n       configComplete &= getJsonValue(top[\"sync\"][\"port\"], audioSyncPort);\n       configComplete &= getJsonValue(top[\"sync\"][\"mode\"], audioSyncEnabled);\n \n@@ -1784,6 +1887,7 @@ class AudioReactive : public Usermod {\n \n     void appendConfigData() override\n     {\n+#ifdef ARDUINO_ARCH_ESP32   \n       oappend(SET_F(\"dd=addDropdown('AudioReactive','digitalmic:type');\"));\n     #if  !defined(CONFIG_IDF_TARGET_ESP32S2) && !defined(CONFIG_IDF_TARGET_ESP32C3) && !defined(CONFIG_IDF_TARGET_ESP32S3)\n       oappend(SET_F(\"addOption(dd,'Generic Analog',0);\"));\n@@ -1815,11 +1919,15 @@ class AudioReactive : public Usermod {\n       oappend(SET_F(\"addOption(dd,'Linear (Amplitude)',2);\"));\n       oappend(SET_F(\"addOption(dd,'Square Root (Energy)',3);\"));\n       oappend(SET_F(\"addOption(dd,'Logarithmic (Loudness)',1);\"));\n+#endif\n \n       oappend(SET_F(\"dd=addDropdown('AudioReactive','sync:mode');\"));\n       oappend(SET_F(\"addOption(dd,'Off',0);\"));\n+#ifdef ARDUINO_ARCH_ESP32\n       oappend(SET_F(\"addOption(dd,'Send',1);\"));\n+#endif\n       oappend(SET_F(\"addOption(dd,'Receive',2);\"));\n+#ifdef ARDUINO_ARCH_ESP32\n       oappend(SET_F(\"addInfo('AudioReactive:digitalmic:type',1,'<i>requires reboot!</i>');\"));  // 0 is field type, 1 is actual field\n       oappend(SET_F(\"addInfo('AudioReactive:digitalmic:pin[]',0,'<i>sd/data/dout</i>','I2S SD');\"));\n       oappend(SET_F(\"addInfo('AudioReactive:digitalmic:pin[]',1,'<i>ws/clk/lrck</i>','I2S WS');\"));\n@@ -1829,6 +1937,7 @@ class AudioReactive : public Usermod {\n       #else\n         oappend(SET_F(\"addInfo('AudioReactive:digitalmic:pin[]',3,'<i>master clock</i>','I2S MCLK');\"));\n       #endif\n+#endif\n     }\n \n \n@@ -1907,8 +2016,8 @@ CRGB AudioReactive::getCRGBForBand(int x, int pal) {\n void AudioReactive::fillAudioPalettes() {\n   if (!palettes) return;\n   size_t lastCustPalette = strip.customPalettes.size();\n-  if (lastCustPalette >= palettes) lastCustPalette -= palettes;\n-  for (size_t pal=0; pal<palettes; pal++) {\n+  if (int(lastCustPalette) >= palettes) lastCustPalette -= palettes;\n+  for (int pal=0; pal<palettes; pal++) {\n     uint8_t tcp[16];  // Needs to be 4 times however many colors are being used.\n                       // 3 colors = 12, 4 colors = 16, etc.\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Identified Problems:**\n   - Crashes occur with PWM strips and may relate to timing issues or CPU overload.\n   - Frequent reboots observed, especially under high loads or increased brightness.\n   - UDP traffic bursts lead to multiple dropped packets.\n\n2. **Implementation Suggestions:**\n   - Consider adding `yield()` calls around UDP operations to ensure timely execution and prevent watchdog resets.\n   - Change the static buffer in `receiveAudioData()` to a fixed size to prevent potential stack issues.\n\n3. **Performance and Security Concerns:**\n   - Fix buffer size handling to mitigate large packet risks.\n   - Currently, multicast handling issues may arise from modem sleep settings; suggest indicating this in the UI.\n\n4. **Next Steps:**\n   - Investigate whether the Wi-Fi module discards old multicast packets or requires a manual flush of the receive buffer.\n   - Optimize timing in packet processing to handle bursts effectively."
      }
    ],
    "codediff_length": 34753
  },
  {
    "index": 30,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/wled00/FX_fcn.cpp b/wled00/FX_fcn.cpp\nindex ab9ab8d950..2e25a17a44 100755\n--- a/wled00/FX_fcn.cpp\n+++ b/wled00/FX_fcn.cpp\n@@ -159,8 +159,16 @@ bool Segment::allocateData(size_t len) {\n     return false;\n   }\n   // prefer DRAM over SPI RAM on ESP32 since it is slow\n-  if (data) data = (byte*)d_realloc(data, len);\n-  else      data = (byte*)d_malloc(len);\n+  if (data) {\n+    data = (byte*)d_realloc_malloc(data, len); // realloc with malloc fallback\n+    if (!data) {\n+      data = nullptr;\n+      Segment::addUsedSegmentData(-_dataLen); // subtract original buffer size\n+      _dataLen = 0;   // reset data length\n+    }\n+  }\n+  else data = (byte*)d_malloc(len);\n+\n   if (data) {\n     memset(data, 0, len);  // erase buffer\n     Segment::addUsedSegmentData(len - _dataLen);\n@@ -170,7 +178,6 @@ bool Segment::allocateData(size_t len) {\n   }\n   // allocation failed\n   DEBUG_PRINTLN(F(\"!!! Allocation failed. !!!\"));\n-  Segment::addUsedSegmentData(-_dataLen); // subtract original buffer size\n   errorFlag = ERR_NORAM;\n   return false;\n }\n@@ -449,8 +456,8 @@ void Segment::setGeometry(uint16_t i1, uint16_t i2, uint8_t grp, uint8_t spc, ui\n   }\n   // re-allocate FX render buffer\n   if (length() != oldLength) {\n-    if (pixels) pixels = static_cast<uint32_t*>(d_realloc(pixels, sizeof(uint32_t) * length()));\n-    else        pixels = static_cast<uint32_t*>(d_malloc(sizeof(uint32_t) * length()));\n+    if (pixels) d_free(pixels); // using realloc on large buffers can cause additional fragmentation instead of reducing it\n+    pixels = static_cast<uint32_t*>(d_malloc(sizeof(uint32_t) * length()));\n     if (!pixels) {\n       DEBUG_PRINTLN(F(\"!!! Not enough RAM for pixel buffer !!!\"));\n       errorFlag = ERR_NORAM_PX;\n@@ -563,8 +570,8 @@ Segment &Segment::setName(const char *newName) {\n   if (newName) {\n     const int newLen = min(strlen(newName), (size_t)WLED_MAX_SEGNAME_LEN);\n     if (newLen) {\n-      if (name) name = static_cast<char*>(d_realloc(name, newLen+1));\n-      else      name = static_cast<char*>(d_malloc(newLen+1));\n+      if (name) d_free(name); // free old name\n+      name = static_cast<char*>(d_malloc(newLen+1));\n       if (name) strlcpy(name, newName, newLen+1);\n       name[newLen] = 0;\n       return *this;\n@@ -729,8 +736,8 @@ void IRAM_ATTR_YN Segment::setPixelColor(int i, uint32_t col) const\n         }\n         break;\n       case M12_pCorner:\n-        for (int x = 0; x <= i; x++) setPixelColorRaw(XY(x, i), col);\n-        for (int y = 0; y <  i; y++) setPixelColorRaw(XY(i, y), col);\n+        for (int x = 0; x <= i; x++) setPixelColorXY(x, i, col); // note: <= to include i=0. Relies on overflow check in sPC()\n+        for (int y = 0; y <  i; y++) setPixelColorXY(i, y, col);\n         break;\n       case M12_sPinwheel: {\n         // Uses Bresenham's algorithm to place coordinates of two lines in arrays then draws between them\n@@ -1189,8 +1196,8 @@ void WS2812FX::finalizeInit() {\n   deserializeMap();     // (re)load default ledmap (will also setUpMatrix() if ledmap does not exist)\n \n   // allocate frame buffer after matrix has been set up (gaps!)\n-  if (_pixels) _pixels = static_cast<uint32_t*>(d_realloc(_pixels, getLengthTotal() * sizeof(uint32_t)));\n-  else         _pixels = static_cast<uint32_t*>(d_malloc(getLengthTotal() * sizeof(uint32_t)));\n+  if (_pixels) d_free(_pixels); // using realloc on large buffers can cause additional fragmentation instead of reducing it\n+  _pixels = static_cast<uint32_t*>(d_malloc(getLengthTotal() * sizeof(uint32_t)));\n   DEBUG_PRINTF_P(PSTR(\"strip buffer size: %uB\\n\"), getLengthTotal() * sizeof(uint32_t));\n \n   DEBUG_PRINTF_P(PSTR(\"Heap after strip init: %uB\\n\"), ESP.getFreeHeap());\n@@ -1677,7 +1684,7 @@ void WS2812FX::setTransitionMode(bool t) {\n \n // wait until frame is over (service() has finished or time for 1 frame has passed; yield() crashes on 8266)\n void WS2812FX::waitForIt() {\n-  unsigned long maxWait = millis() + getFrameTime();\n+  unsigned long maxWait = millis() + getFrameTime() + 100; // TODO: this needs a proper fix for timeout!\n   while (isServicing() && maxWait > millis()) delay(1);\n   #ifdef WLED_DEBUG\n   if (millis() >= maxWait) DEBUG_PRINTLN(F(\"Waited for strip to finish servicing.\"));\ndiff --git a/wled00/bus_manager.cpp b/wled00/bus_manager.cpp\nindex 3193af4cd0..a83b29bdee 100644\n--- a/wled00/bus_manager.cpp\n+++ b/wled00/bus_manager.cpp\n@@ -36,25 +36,32 @@ uint8_t realtimeBroadcast(uint8_t type, IPAddress client, uint16_t length, const\n \n //util.cpp\n // PSRAM allocation wrappers\n-#ifndef ESP8266\n+#if !defined(ESP8266) && !defined(CONFIG_IDF_TARGET_ESP32C3)\n extern \"C\" {\n   void *p_malloc(size_t);           // prefer PSRAM over DRAM\n   void *p_calloc(size_t, size_t);   // prefer PSRAM over DRAM\n   void *p_realloc(void *, size_t);  // prefer PSRAM over DRAM\n+  void *p_realloc_malloc(void *ptr, size_t size); // realloc with malloc fallback, prefer PSRAM over DRAM\n   inline void p_free(void *ptr) { heap_caps_free(ptr); }\n   void *d_malloc(size_t);           // prefer DRAM over PSRAM\n   void *d_calloc(size_t, size_t);   // prefer DRAM over PSRAM\n   void *d_realloc(void *, size_t);  // prefer DRAM over PSRAM\n+  void *d_realloc_malloc(void *ptr, size_t size); // realloc with malloc fallback, prefer DRAM over PSRAM\n   inline void d_free(void *ptr) { heap_caps_free(ptr); }\n }\n #else\n+extern \"C\" {\n+  void *realloc_malloc(void *ptr, size_t size);\n+}\n #define p_malloc malloc\n #define p_calloc calloc\n #define p_realloc realloc\n+#define p_realloc_malloc realloc_malloc\n #define p_free free\n #define d_malloc malloc\n #define d_calloc calloc\n #define d_realloc realloc\n+#define d_realloc_malloc realloc_malloc\n #define d_free free\n #endif\n \ndiff --git a/wled00/const.h b/wled00/const.h\nindex c19843c422..1abf245396 100644\n--- a/wled00/const.h\n+++ b/wled00/const.h\n@@ -546,8 +546,8 @@ static_assert(WLED_MAX_BUSSES <= 32, \"WLED_MAX_BUSSES exceeds hard limit\");\n   #endif\n #endif\n \n-//#define MIN_HEAP_SIZE\n-#define MIN_HEAP_SIZE 2048\n+// minimum heap size required to process web requests\n+#define MIN_HEAP_SIZE 8192\n \n // Web server limits\n #ifdef ESP8266\ndiff --git a/wled00/data/index.js b/wled00/data/index.js\nindex 295a3403b4..f23b5949fd 100644\n--- a/wled00/data/index.js\n+++ b/wled00/data/index.js\n@@ -1527,6 +1527,9 @@ function readState(s,command=false)\n \t\t\tcase  3:\n \t\t\t\terrstr = \"Buffer locked!\";\n \t\t\t\tbreak;\n+\t\t\tcase  7:\n+\t\t\t\terrstr = \"No RAM for buffer!\";\n+\t\t\t\tbreak;\n \t\t\tcase  8:\n \t\t\t\terrstr = \"Effect RAM depleted!\";\n \t\t\t\tbreak;\ndiff --git a/wled00/fcn_declare.h b/wled00/fcn_declare.h\nindex 0b73c90acf..d19f89b27d 100644\n--- a/wled00/fcn_declare.h\n+++ b/wled00/fcn_declare.h\n@@ -551,25 +551,32 @@ inline uint8_t hw_random8(uint32_t upperlimit) { return (hw_random8() * upperlim\n inline uint8_t hw_random8(uint32_t lowerlimit, uint32_t upperlimit) { uint32_t range = upperlimit - lowerlimit; return lowerlimit + hw_random8(range); }; // input range 0-255\n \n // PSRAM allocation wrappers\n-#ifndef ESP8266\n+#if !defined(ESP8266) && !defined(CONFIG_IDF_TARGET_ESP32C3)\n extern \"C\" {\n   void *p_malloc(size_t);           // prefer PSRAM over DRAM\n   void *p_calloc(size_t, size_t);   // prefer PSRAM over DRAM\n   void *p_realloc(void *, size_t);  // prefer PSRAM over DRAM\n+  void *p_realloc_malloc(void *ptr, size_t size); // realloc with malloc fallback, prefer PSRAM over DRAM\n   inline void p_free(void *ptr) { heap_caps_free(ptr); }\n   void *d_malloc(size_t);           // prefer DRAM over PSRAM\n   void *d_calloc(size_t, size_t);   // prefer DRAM over PSRAM\n   void *d_realloc(void *, size_t);  // prefer DRAM over PSRAM\n+  void *d_realloc_malloc(void *ptr, size_t size); // realloc with malloc fallback, prefer DRAM over PSRAM\n   inline void d_free(void *ptr) { heap_caps_free(ptr); }\n }\n #else\n+extern \"C\" {\n+  void *realloc_malloc(void *ptr, size_t size);\n+}\n #define p_malloc malloc\n #define p_calloc calloc\n #define p_realloc realloc\n+#define p_realloc_malloc realloc_malloc\n #define p_free free\n #define d_malloc malloc\n #define d_calloc calloc\n #define d_realloc realloc\n+#define d_realloc_malloc realloc_malloc\n #define d_free free\n #endif\n \ndiff --git a/wled00/util.cpp b/wled00/util.cpp\nindex 97e1e3b035..6ff7b05dfc 100644\n--- a/wled00/util.cpp\n+++ b/wled00/util.cpp\n@@ -619,7 +619,8 @@ int32_t hw_random(int32_t lowerlimit, int32_t upperlimit) {\n   return hw_random(diff) + lowerlimit;\n }\n \n-#ifndef ESP8266\n+#if !defined(ESP8266) && !defined(CONFIG_IDF_TARGET_ESP32C3) // ESP8266 does not support PSRAM, ESP32-C3 does not have PSRAM\n+// p_x prefer PSRAM, d_x prefer DRAM\n void *p_malloc(size_t size) {\n   int caps1 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n   int caps2 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n@@ -640,6 +641,14 @@ void *p_realloc(void *ptr, size_t size) {\n   return heap_caps_realloc(ptr, size, caps2);\n }\n \n+// realloc with malloc fallback, original buffer is freed if realloc fails but not copied!\n+void *p_realloc_malloc(void *ptr, size_t size) {\n+  void *newbuf = p_realloc(ptr, size); // try realloc first\n+  if (newbuf) return newbuf; // realloc successful\n+  p_free(ptr); // free old buffer if realloc failed\n+  return p_malloc(size); // fallback to malloc\n+}\n+\n void *p_calloc(size_t count, size_t size) {\n   int caps1 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n   int caps2 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n@@ -654,7 +663,7 @@ void *d_malloc(size_t size) {\n   int caps1 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n   int caps2 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n   if (psramSafe) {\n-    if (size > MIN_HEAP_SIZE) std::swap(caps1, caps2);  // prefer PSRAM for large alloactions\n+    if (heap_caps_get_largest_free_block(caps1) < 3*MIN_HEAP_SIZE && size > MIN_HEAP_SIZE) std::swap(caps1, caps2);  // prefer PSRAM for large alloactions & when DRAM is low\n     return heap_caps_malloc_prefer(size, 2, caps1, caps2); // otherwise prefer DRAM\n   }\n   return heap_caps_malloc(size, caps1);\n@@ -664,12 +673,20 @@ void *d_realloc(void *ptr, size_t size) {\n   int caps1 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n   int caps2 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n   if (psramSafe) {\n-    if (size > MIN_HEAP_SIZE) std::swap(caps1, caps2);  // prefer PSRAM for large alloactions\n+    if (heap_caps_get_largest_free_block(caps1) < 3*MIN_HEAP_SIZE && size > MIN_HEAP_SIZE) std::swap(caps1, caps2);  // prefer PSRAM for large alloactions & when DRAM is low\n     return heap_caps_realloc_prefer(ptr, size, 2, caps1, caps2); // otherwise prefer DRAM\n   }\n   return heap_caps_realloc(ptr, size, caps1);\n }\n \n+// realloc with malloc fallback, original buffer is freed if realloc fails but not copied!\n+void *d_realloc_malloc(void *ptr, size_t size) {\n+  void *newbuf = d_realloc(ptr, size); // try realloc first\n+  if (newbuf) return newbuf; // realloc successful\n+  d_free(ptr); // free old buffer if realloc failed\n+  return d_malloc(size); // fallback to malloc\n+}\n+\n void *d_calloc(size_t count, size_t size) {\n   int caps1 = MALLOC_CAP_DEFAULT | MALLOC_CAP_8BIT;\n   int caps2 = MALLOC_CAP_SPIRAM  | MALLOC_CAP_8BIT;\n@@ -679,6 +696,14 @@ void *d_calloc(size_t count, size_t size) {\n   }\n   return heap_caps_calloc(count, size, caps1);\n }\n+#else // ESP8266 & ESP32-C3\n+// realloc with malloc fallback, original buffer is freed if realloc fails but not copied!\n+void *realloc_malloc(void *ptr, size_t size) {\n+  void *newbuf = realloc(ptr, size); // try realloc first\n+  if (newbuf) return newbuf; // realloc successful\n+  free(ptr); // free old buffer if realloc failed\n+  return malloc(size); // fallback to malloc\n+}\n #endif\n \n /*\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Bugs and Errors:\n   - Reallocation failures (freeing old buffer on realloc failure) may lead to UI instability. \n\n2. Implementation Suggestions:\n   - Update `p_realloc()` to ensure in-place reallocations; if not, free old pointer and allocate new block.\n   - Add check `&& segO->isActive()` in `service()` to prevent crashes when FX divide by zero.\n\n3. Security/Performance Concerns:\n   - Keep `MIN_HEAP_SIZE` at 8k to prevent UI crashes; previously set at 2k is insufficient.\n   - Monitor free heap and largest contiguous block sizes to optimize PSRAM vs. DRAM allocation preferences.\n\n4. Next Steps:\n   - Review and test proposed `deallocateData()` for inactive segments and release FX data on low RAM.\n   - Consider separating fixes for inactive segments into a new PR."
      }
    ],
    "codediff_length": 11514
  },
  {
    "index": 31,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/wled00/FX.cpp b/wled00/FX.cpp\nindex 5e43430aef..5839389ed0 100644\n--- a/wled00/FX.cpp\n+++ b/wled00/FX.cpp\n@@ -197,7 +197,7 @@ static const char _data_FX_MODE_STROBE_RAINBOW[] PROGMEM = \"Strobe Rainbow@!;,!;\n  * if (bool rev == true) then LEDs are turned off in reverse order\n  */\n uint16_t color_wipe(bool rev, bool useRandomColors) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   uint32_t cycleTime = 750 + (255 - SEGMENT.speed)*150;\n   uint32_t perc = strip.now % cycleTime;\n   unsigned prog = (perc * 65535) / cycleTime;\n@@ -410,7 +410,7 @@ static const char _data_FX_MODE_FADE[] PROGMEM = \"Fade@!;!,!;!;01\";\n  * Scan mode parent function\n  */\n uint16_t scan(bool dual) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   uint32_t cycleTime = 750 + (255 - SEGMENT.speed)*150;\n   uint32_t perc = strip.now % cycleTime;\n   int prog = (perc * 65535) / cycleTime;\n@@ -1023,7 +1023,7 @@ static const char _data_FX_MODE_COLORFUL[] PROGMEM = \"Colorful@!,Saturation;1,2,\n  * Emulates a traffic light.\n  */\n uint16_t mode_traffic_light(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   for (unsigned i=0; i < SEGLEN; i++)\n     SEGMENT.setPixelColor(i, SEGMENT.color_from_palette(i, true, PALETTE_SOLID_WRAP, 1));\n   uint32_t mdelay = 500;\n@@ -1056,7 +1056,7 @@ static const char _data_FX_MODE_TRAFFIC_LIGHT[] PROGMEM = \"Traffic Light@!,US st\n  */\n #define FLASH_COUNT 4\n uint16_t mode_chase_flash(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   unsigned flash_step = SEGENV.call % ((FLASH_COUNT * 2) + 1);\n \n   for (unsigned i = 0; i < SEGLEN; i++) {\n@@ -1086,7 +1086,7 @@ static const char _data_FX_MODE_CHASE_FLASH[] PROGMEM = \"Chase Flash@!;Bg,Fx;!\";\n  * Prim flashes running, followed by random color.\n  */\n uint16_t mode_chase_flash_random(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   unsigned flash_step = SEGENV.call % ((FLASH_COUNT * 2) + 1);\n \n   for (int i = 0; i < SEGENV.aux1; i++) {\n@@ -1168,7 +1168,7 @@ static const char _data_FX_MODE_RUNNING_RANDOM[] PROGMEM = \"Stream@!,Zone size;;\n  * K.I.T.T.\n  */\n uint16_t mode_larson_scanner(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n \n   const unsigned speed  = FRAMETIME * map(SEGMENT.speed, 0, 255, 96, 2); // map into useful range\n   const unsigned pixels = SEGLEN / speed; // how many pixels to advance per frame\n@@ -1226,7 +1226,7 @@ static const char _data_FX_MODE_DUAL_LARSON_SCANNER[] PROGMEM = \"Scanner Dual@!,\n  * Firing comets from one end. \"Lighthouse\"\n  */\n uint16_t mode_comet(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   unsigned counter = (strip.now * ((SEGMENT.speed >>2) +1)) & 0xFFFF;\n   unsigned index = (counter * SEGLEN) >> 16;\n   if (SEGENV.call == 0) SEGENV.aux0 = index;\n@@ -1254,7 +1254,7 @@ static const char _data_FX_MODE_COMET[] PROGMEM = \"Lighthouse@!,Fade rate;!,!;!\"\n  * Fireworks function.\n  */\n uint16_t mode_fireworks() {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   const uint16_t width  = SEGMENT.is2D() ? SEG_W : SEGLEN;\n   const uint16_t height = SEG_H;\n \n@@ -1296,7 +1296,7 @@ static const char _data_FX_MODE_FIREWORKS[] PROGMEM = \"Fireworks@,Frequency;!,!;\n \n //Twinkling LEDs running. Inspired by https://github.com/kitesurfer1404/WS2812FX/blob/master/src/custom/Rain.h\n uint16_t mode_rain() {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   const unsigned width  = SEG_W;\n   const unsigned height = SEG_H;\n   SEGENV.step += FRAMETIME;\n@@ -1362,7 +1362,7 @@ static const char _data_FX_MODE_FIRE_FLICKER[] PROGMEM = \"Fire Flicker@!,!;!;!;0\n  * Gradient run base function\n  */\n uint16_t gradient_base(bool loading) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   uint16_t counter = strip.now * ((SEGMENT.speed >> 2) + 1);\n   uint16_t pp = (counter * SEGLEN) >> 16;\n   if (SEGENV.call == 0) pp = 0;\n@@ -1407,7 +1407,7 @@ static const char _data_FX_MODE_LOADING[] PROGMEM = \"Loading@!,Fade;!,!;!;;ix=16\n  * Two dots running\n  */\n uint16_t mode_two_dots() {\n- if (SEGLEN == 1) return mode_static();\n+ if (SEGLEN <= 1) return mode_static();\n   unsigned delay = 1 + (FRAMETIME<<3) / SEGLEN;  // longer segments should change faster\n   uint32_t it = strip.now / map(SEGMENT.speed, 0, 255, delay<<4, delay);\n   unsigned offset = it % SEGLEN;\n@@ -1858,7 +1858,7 @@ static const char _data_FX_MODE_OSCILLATE[] PROGMEM = \"Oscillate\";\n \n //TODO\n uint16_t mode_lightning(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   unsigned ledstart = hw_random16(SEGLEN);               // Determine starting location of flash\n   unsigned ledlen = 1 + hw_random16(SEGLEN -ledstart);   // Determine length of flash (not to go beyond NUM_LEDS-1)\n   uint8_t bri = 255/hw_random8(1, 3);\n@@ -1944,7 +1944,7 @@ static const char _data_FX_MODE_PRIDE_2015[] PROGMEM = \"Pride 2015@!;;\";\n \n //eight colored dots, weaving in and out of sync with each other\n uint16_t mode_juggle(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n \n   SEGMENT.fadeToBlackBy(192 - (3*SEGMENT.intensity/4));\n   CRGB fastled_col;\n@@ -2089,7 +2089,7 @@ static const char _data_FX_MODE_PALETTE[] PROGMEM = \"Palette@Shift,Size,Rotation\n // feel of your fire: COOLING (used in step 1 above) (Speed = COOLING), and SPARKING (used\n // in step 3 above) (Effect Intensity = Sparking).\n uint16_t mode_fire_2012() {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   const unsigned strips = SEGMENT.nrOfVStrips();\n   if (!SEGENV.allocateData(strips * SEGLEN)) return mode_static(); //allocation failed\n   byte* heat = SEGENV.data;\n@@ -2369,7 +2369,7 @@ static const char _data_FX_MODE_LAKE[] PROGMEM = \"Lake@!;Fx;!\";\n // send a meteor from begining to to the end of the strip with a trail that randomly decays.\n // adapted from https://www.tweaking4all.com/hardware/arduino/adruino-led-strip-effects/#LEDStripEffectMeteorRain\n uint16_t mode_meteor() {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   if (!SEGENV.allocateData(SEGLEN)) return mode_static(); //allocation failed\n   const bool meteorSmooth = SEGMENT.check3;\n   byte* trail = SEGENV.data;\n@@ -2436,7 +2436,7 @@ static const char _data_FX_MODE_METEOR[] PROGMEM = \"Meteor@!,Trail,,,,Gradient,,\n \n //Railway Crossing / Christmas Fairy lights\n uint16_t mode_railway() {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   unsigned dur = (256 - SEGMENT.speed) * 40;\n   uint16_t rampdur = (dur * SEGMENT.intensity) >> 8;\n   if (SEGENV.step > dur)\n@@ -2537,7 +2537,7 @@ static uint16_t ripple_base(uint8_t blurAmount = 0) {\n \n \n uint16_t mode_ripple(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   if(SEGMENT.custom1 || SEGMENT.check2) // blur or overlay\n     SEGMENT.fade_out(250);\n   else\n@@ -2549,7 +2549,7 @@ static const char _data_FX_MODE_RIPPLE[] PROGMEM = \"Ripple@!,Wave #,Blur,,,,Over\n \n \n uint16_t mode_ripple_rainbow(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   if (SEGENV.call ==0) {\n     SEGENV.aux0 = hw_random8();\n     SEGENV.aux1 = hw_random8();\n@@ -2727,7 +2727,7 @@ uint16_t mode_halloween_eyes()\n     uint32_t blinkEndTime;\n   };\n \n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   const unsigned maxWidth = strip.isMatrix ? SEG_W : SEGLEN;\n   const unsigned HALLOWEEN_EYE_SPACE = MAX(2, strip.isMatrix ? SEG_W>>4: SEGLEN>>5);\n   const unsigned HALLOWEEN_EYE_WIDTH = HALLOWEEN_EYE_SPACE/2;\n@@ -2912,7 +2912,7 @@ static const char _data_FX_MODE_TRI_STATIC_PATTERN[] PROGMEM = \"Solid Pattern Tr\n \n static uint16_t spots_base(uint16_t threshold)\n {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   if (!SEGMENT.check2) SEGMENT.fill(SEGCOLOR(1));\n \n   unsigned maxZones = SEGLEN >> 2;\n@@ -2968,7 +2968,7 @@ typedef struct Ball {\n *  Bouncing Balls Effect\n */\n uint16_t mode_bouncing_balls(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   //allocate segment data\n   const unsigned strips = SEGMENT.nrOfVStrips(); // adapt for 2D\n   const size_t maxNumBalls = 16;\n@@ -3146,7 +3146,7 @@ static const char _data_FX_MODE_ROLLINGBALLS[] PROGMEM = \"Rolling Balls@!,# of b\n * Sinelon stolen from FASTLED examples\n */\n static uint16_t sinelon_base(bool dual, bool rainbow=false) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   SEGMENT.fade_out(SEGMENT.intensity);\n   unsigned pos = beatsin16_t(SEGMENT.speed/10,0,SEGLEN-1);\n   if (SEGENV.call == 0) SEGENV.aux0 = pos;\n@@ -3251,7 +3251,7 @@ typedef struct Spark {\n *  modified from https://github.com/kitesurfer1404/WS2812FX/blob/master/src/custom/Popcorn.h\n */\n uint16_t mode_popcorn(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   //allocate segment data\n   unsigned strips = SEGMENT.nrOfVStrips();\n   unsigned usablePopcorns = maxNumPopcorn;\n@@ -3426,7 +3426,7 @@ typedef struct particle {\n } star;\n \n uint16_t mode_starburst(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   unsigned maxData = FAIR_DATA_PER_SEG; //ESP8266: 256 ESP32: 640\n   unsigned segs = strip.getActiveSegmentsNum();\n   if (segs <= (strip.getMaxSegments() /2)) maxData *= 2; //ESP8266: 512 if <= 8 segs ESP32: 1280 if <= 16 segs\n@@ -3545,7 +3545,7 @@ static const char _data_FX_MODE_STARBURST[] PROGMEM = \"Fireworks Starburst@Chanc\n  */\n uint16_t mode_exploding_fireworks(void)\n {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   const int cols = SEGMENT.is2D() ? SEG_W : 1;\n   const int rows = SEGMENT.is2D() ? SEG_H : SEGLEN;\n \n@@ -3683,7 +3683,7 @@ static const char _data_FX_MODE_EXPLODING_FIREWORKS[] PROGMEM = \"Fireworks 1D@Gr\n  */\n uint16_t mode_drip(void)\n {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   //allocate segment data\n   unsigned strips = SEGMENT.nrOfVStrips();\n   const int maxNumDrops = 4;\n@@ -3779,7 +3779,7 @@ typedef struct Tetris {\n } tetris;\n \n uint16_t mode_tetrix(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   unsigned strips = SEGMENT.nrOfVStrips(); // allow running on virtual strips (columns in 2D segment)\n   unsigned dataSize = sizeof(tetris);\n   if (!SEGENV.allocateData(dataSize * strips)) return mode_static(); //allocation failed\n@@ -3990,7 +3990,7 @@ static const char _data_FX_MODE_HEARTBEAT[] PROGMEM = \"Heartbeat@!,!;!,!;!;01;m1\n // Modified for WLED, based on https://github.com/FastLED/FastLED/blob/master/examples/Pacifica/Pacifica.ino\n //\n // Add one layer of waves into the led array\n-static CRGB pacifica_one_layer(uint16_t i, CRGBPalette16& p, uint16_t cistart, uint16_t wavescale, uint8_t bri, uint16_t ioff)\n+static CRGB pacifica_one_layer(uint16_t i, const CRGBPalette16& p, uint16_t cistart, uint16_t wavescale, uint8_t bri, uint16_t ioff)\n {\n   unsigned ci = cistart;\n   unsigned waveangle = ioff;\n@@ -4086,7 +4086,7 @@ static const char _data_FX_MODE_PACIFICA[] PROGMEM = \"Pacifica@!,Angle;;!;;pal=5\n  * Mode simulates a gradual sunrise\n  */\n uint16_t mode_sunrise() {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   //speed 0 - static sun\n   //speed 1 - 60: sunrise time in minutes\n   //speed 60 - 120 : sunset time in minutes - 60;\n@@ -4293,7 +4293,7 @@ static const char _data_FX_MODE_FLOW[] PROGMEM = \"Flow@!,Zones;;!;;m12=1\"; //ver\n  */\n uint16_t mode_chunchun(void)\n {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   SEGMENT.fade_out(254); // add a bit of trail\n   unsigned counter = strip.now * (6 + (SEGMENT.speed >> 4));\n   unsigned numBirds = 2 + (SEGLEN >> 3);  // 2 + 1/8 of a segment\n@@ -4344,7 +4344,7 @@ typedef struct Spotlight {\n  */\n uint16_t mode_dancing_shadows(void)\n {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   unsigned numSpotlights = map(SEGMENT.intensity, 0, 255, 2, SPOT_MAX_COUNT);  // 49 on 32 segment ESP32, 17 on 16 segment ESP8266\n   bool initialize = SEGENV.aux0 != numSpotlights;\n   SEGENV.aux0 = numSpotlights;\n@@ -4806,7 +4806,7 @@ static const char _data_FX_MODE_AURORA[] PROGMEM = \"Aurora@!,!;1,2,3;!;;sx=24,pa\n // 16 bit perlinmove. Use Perlin Noise instead of sinewaves for movement. By Andrew Tuline.\n // Controls are speed, # of pixels, faderate.\n uint16_t mode_perlinmove(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   SEGMENT.fade_out(255-SEGMENT.custom1);\n   for (int i = 0; i < SEGMENT.intensity/16 + 1; i++) {\n     unsigned locn = inoise16(strip.now*128/(260-SEGMENT.speed)+i*15000, strip.now*128/(260-SEGMENT.speed)); // Get a new pixel location from moving noise.\n@@ -4842,7 +4842,7 @@ static const char _data_FX_MODE_WAVESINS[] PROGMEM = \"Wavesins@!,Brightness vari\n //////////////////////////////\n // By: ldirko  https://editor.soulmatelights.com/gallery/392-flow-led-stripe , modifed by: Andrew Tuline\n uint16_t mode_FlowStripe(void) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   const int hl = SEGLEN * 10 / 13;\n   uint8_t hue = strip.now / (SEGMENT.speed+1);\n   uint32_t t = strip.now / (SEGMENT.intensity/8+1);\n@@ -6596,7 +6596,7 @@ static const char _data_FX_MODE_MATRIPIX[] PROGMEM = \"Matripix@!,Brightness;!,!;\n //   * MIDNOISE     //\n //////////////////////\n uint16_t mode_midnoise(void) {                  // Midnoise. By Andrew Tuline.\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n // Changing xdist to SEGENV.aux0 and ydist to SEGENV.aux1.\n \n   um_data_t *um_data = getAudioData();\n@@ -6687,7 +6687,7 @@ static const char _data_FX_MODE_NOISEMETER[] PROGMEM = \"Noisemeter@Fade rate,Wid\n //   * PIXELWAVE    //\n //////////////////////\n uint16_t mode_pixelwave(void) {                 // Pixelwave. By Andrew Tuline.\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   // even with 1D effect we have to take logic for 2D segments for allocation as fill_solid() fills whole segment\n \n   if (SEGENV.call == 0) {\n@@ -6755,7 +6755,7 @@ static const char _data_FX_MODE_PLASMOID[] PROGMEM = \"Plasmoid@Phase,# of pixels\n //////////////////////\n // Puddles/Puddlepeak By Andrew Tuline. Merged by @dedehai\n uint16_t mode_puddles_base(bool peakdetect) {\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   unsigned size = 0;\n   uint8_t fadeVal = map(SEGMENT.speed, 0, 255, 224, 254);\n   unsigned pos = hw_random16(SEGLEN);                          // Set a random starting position.\n@@ -6805,7 +6805,7 @@ static const char _data_FX_MODE_PUDDLES[] PROGMEM = \"Puddles@Fade rate,Puddle si\n //     * PIXELS     //\n //////////////////////\n uint16_t mode_pixels(void) {                    // Pixels. By Andrew Tuline.\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n \n   if (!SEGENV.allocateData(32*sizeof(uint8_t))) return mode_static(); //allocation failed\n   uint8_t *myVals = reinterpret_cast<uint8_t*>(SEGENV.data); // Used to store a pile of samples because WLED frame rate and WLED sample rate are not synchronized. Frame rate is too low.\n@@ -6833,7 +6833,7 @@ static const char _data_FX_MODE_PIXELS[] PROGMEM = \"Pixels@Fade rate,# of pixels\n //    ** Blurz      //\n //////////////////////\n uint16_t mode_blurz(void) {                    // Blurz. By Andrew Tuline.\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   // even with 1D effect we have to take logic for 2D segments for allocation as fill_solid() fills whole segment\n \n   um_data_t *um_data = getAudioData();\n@@ -6897,7 +6897,7 @@ static const char _data_FX_MODE_DJLIGHT[] PROGMEM = \"DJ Light@Speed;;;01f;m12=2,\n //   ** Freqmap   //\n ////////////////////\n uint16_t mode_freqmap(void) {                   // Map FFT_MajorPeak to SEGLEN. Would be better if a higher framerate.\n-  if (SEGLEN == 1) return mode_static();\n+  if (SEGLEN <= 1) return mode_static();\n   // Start frequency = 60 Hz and log10(60) = 1.78\n   // End frequency = MAX_FREQUENCY in Hz and lo10(MAX_FREQUENCY) = MAX_FREQ_LOG10\n \ndiff --git a/wled00/FX.h b/wled00/FX.h\nindex 57df58549b..f54b3ba5c7 100644\n--- a/wled00/FX.h\n+++ b/wled00/FX.h\n@@ -79,9 +79,9 @@ extern byte realtimeMode;           // used in getMappedPixelIndex()\n     #define MAX_NUM_SEGMENTS  32\n   #endif\n   #if defined(ARDUINO_ARCH_ESP32S2)\n-    #define MAX_SEGMENT_DATA  MAX_NUM_SEGMENTS*768 // 24k by default (S2 is short on free RAM)\n+    #define MAX_SEGMENT_DATA  (MAX_NUM_SEGMENTS*768)  // 24k by default (S2 is short on free RAM)\n   #else\n-    #define MAX_SEGMENT_DATA  MAX_NUM_SEGMENTS*1280 // 40k by default\n+    #define MAX_SEGMENT_DATA  (MAX_NUM_SEGMENTS*1280) // 40k by default\n   #endif\n #endif\n \n@@ -460,7 +460,7 @@ typedef struct Segment {\n       {}\n     } *_t;\n \n-    [[gnu::hot]] void _setPixelColorXY_raw(int& x, int& y, uint32_t& col); // set pixel without mapping (internal use only)\n+    [[gnu::hot]] void _setPixelColorXY_raw(const int& x, const int& y, uint32_t& col) const; // set pixel without mapping (internal use only)\n \n   public:\n \n@@ -518,7 +518,7 @@ typedef struct Segment {\n       //if (data) Serial.printf(\" %d->(%p)\", (int)_dataLen, data);\n       //Serial.println();\n       #endif\n-      if (name) { delete[] name; name = nullptr; }\n+      if (name) { free(name); name = nullptr; }\n       stopTransition();\n       deallocateData();\n     }\n@@ -534,7 +534,6 @@ typedef struct Segment {\n     inline bool     isSelected()         const { return selected; }\n     inline bool     isInTransition()     const { return _t != nullptr; }\n     inline bool     isActive()           const { return stop > start; }\n-    inline bool     is2D()               const { return (width()>1 && height()>1); }\n     inline bool     hasRGB()             const { return _isRGB; }\n     inline bool     hasWhite()           const { return _hasW; }\n     inline bool     isCCT()              const { return _isCCT; }\n@@ -588,10 +587,10 @@ typedef struct Segment {\n     inline void handleTransition() { updateTransitionProgress(); if (progress() == 0xFFFFU) stopTransition(); }\n     #ifndef WLED_DISABLE_MODE_BLEND\n     void     swapSegenv(tmpsegd_t &tmpSegD);    // copies segment data into specifed buffer, if buffer is not a transition buffer, segment data is overwritten from transition buffer\n-    void     restoreSegenv(tmpsegd_t &tmpSegD); // restores segment data from buffer, if buffer is not transition buffer, changed values are copied to transition buffer\n+    void     restoreSegenv(const tmpsegd_t &tmpSegD); // restores segment data from buffer, if buffer is not transition buffer, changed values are copied to transition buffer\n     #endif\n     [[gnu::hot]] void updateTransitionProgress();            // set current progression of transition\n-    inline uint16_t progress() const { return _transitionprogress; };  // transition progression between 0-65535\n+    inline uint16_t progress() const { return Segment::_transitionprogress; }  // transition progression between 0-65535\n     [[gnu::hot]] uint8_t  currentBri(bool useCct = false) const; // current segment brightness/CCT (blended while in transition)\n     uint8_t  currentMode() const;                            // currently active effect/mode (while in transition)\n     [[gnu::hot]] uint32_t currentColor(uint8_t slot) const;  // currently active segment color (blended while in transition)\n@@ -599,14 +598,14 @@ typedef struct Segment {\n \n     // 1D strip\n     [[gnu::hot]] uint16_t virtualLength() const;\n-    [[gnu::hot]] void setPixelColor(int n, uint32_t c); // set relative pixel within segment with color\n-    inline void setPixelColor(unsigned n, uint32_t c)                    { setPixelColor(int(n), c); }\n-    inline void setPixelColor(int n, byte r, byte g, byte b, byte w = 0) { setPixelColor(n, RGBW32(r,g,b,w)); }\n-    inline void setPixelColor(int n, CRGB c)                             { setPixelColor(n, RGBW32(c.r,c.g,c.b,0)); }\n+    [[gnu::hot]] void setPixelColor(int i, uint32_t c) const; // set relative pixel within segment with color\n+    inline void setPixelColor(unsigned n, uint32_t c) const                    { setPixelColor(int(n), c); }\n+    inline void setPixelColor(int n, byte r, byte g, byte b, byte w = 0) const { setPixelColor(n, RGBW32(r,g,b,w)); }\n+    inline void setPixelColor(int n, CRGB c) const                             { setPixelColor(n, RGBW32(c.r,c.g,c.b,0)); }\n     #ifdef WLED_USE_AA_PIXELS\n-    void setPixelColor(float i, uint32_t c, bool aa = true);\n-    inline void setPixelColor(float i, uint8_t r, uint8_t g, uint8_t b, uint8_t w = 0, bool aa = true) { setPixelColor(i, RGBW32(r,g,b,w), aa); }\n-    inline void setPixelColor(float i, CRGB c, bool aa = true)                                         { setPixelColor(i, RGBW32(c.r,c.g,c.b,0), aa); }\n+    void setPixelColor(float i, uint32_t c, bool aa = true) const;\n+    inline void setPixelColor(float i, uint8_t r, uint8_t g, uint8_t b, uint8_t w = 0, bool aa = true) const { setPixelColor(i, RGBW32(r,g,b,w), aa); }\n+    inline void setPixelColor(float i, CRGB c, bool aa = true) const                                         { setPixelColor(i, RGBW32(c.r,c.g,c.b,0), aa); }\n     #endif\n     [[gnu::hot]] uint32_t getPixelColor(int i) const;\n     // 1D support functions (some implement 2D as well)\n@@ -642,16 +641,17 @@ typedef struct Segment {\n     #endif\n     }\n   #ifndef WLED_DISABLE_2D\n-    [[gnu::hot]] uint16_t XY(int x, int y);      // support function to get relative index within segment\n-    [[gnu::hot]] void setPixelColorXY(int x, int y, uint32_t c); // set relative pixel within segment with color\n-    inline void setPixelColorXY(unsigned x, unsigned y, uint32_t c)               { setPixelColorXY(int(x), int(y), c); }\n-    inline void setPixelColorXY(int x, int y, byte r, byte g, byte b, byte w = 0) { setPixelColorXY(x, y, RGBW32(r,g,b,w)); }\n-    inline void setPixelColorXY(int x, int y, CRGB c)                             { setPixelColorXY(x, y, RGBW32(c.r,c.g,c.b,0)); }\n-    inline void setPixelColorXY(unsigned x, unsigned y, CRGB c)                   { setPixelColorXY(int(x), int(y), RGBW32(c.r,c.g,c.b,0)); }\n+    inline bool is2D() const                                                            { return (width()>1 && height()>1); }\n+    [[gnu::hot]] int  XY(int x, int y) const; // support function to get relative index within segment\n+    [[gnu::hot]] void setPixelColorXY(int x, int y, uint32_t c) const; // set relative pixel within segment with color\n+    inline void setPixelColorXY(unsigned x, unsigned y, uint32_t c) const               { setPixelColorXY(int(x), int(y), c); }\n+    inline void setPixelColorXY(int x, int y, byte r, byte g, byte b, byte w = 0) const { setPixelColorXY(x, y, RGBW32(r,g,b,w)); }\n+    inline void setPixelColorXY(int x, int y, CRGB c) const                             { setPixelColorXY(x, y, RGBW32(c.r,c.g,c.b,0)); }\n+    inline void setPixelColorXY(unsigned x, unsigned y, CRGB c) const                   { setPixelColorXY(int(x), int(y), RGBW32(c.r,c.g,c.b,0)); }\n     #ifdef WLED_USE_AA_PIXELS\n-    void setPixelColorXY(float x, float y, uint32_t c, bool aa = true);\n-    inline void setPixelColorXY(float x, float y, byte r, byte g, byte b, byte w = 0, bool aa = true) { setPixelColorXY(x, y, RGBW32(r,g,b,w), aa); }\n-    inline void setPixelColorXY(float x, float y, CRGB c, bool aa = true)                             { setPixelColorXY(x, y, RGBW32(c.r,c.g,c.b,0), aa); }\n+    void setPixelColorXY(float x, float y, uint32_t c, bool aa = true) const;\n+    inline void setPixelColorXY(float x, float y, byte r, byte g, byte b, byte w = 0, bool aa = true) const { setPixelColorXY(x, y, RGBW32(r,g,b,w), aa); }\n+    inline void setPixelColorXY(float x, float y, CRGB c, bool aa = true) const                             { setPixelColorXY(x, y, RGBW32(c.r,c.g,c.b,0), aa); }\n     #endif\n     [[gnu::hot]] uint32_t getPixelColorXY(int x, int y) const;\n     // 2D support functions\n@@ -678,7 +678,8 @@ typedef struct Segment {\n     void wu_pixel(uint32_t x, uint32_t y, CRGB c);\n     inline void fill_solid(CRGB c) { fill(RGBW32(c.r,c.g,c.b,0)); }\n   #else\n-    inline uint16_t XY(int x, int y)                                              { return x; }\n+    inline constexpr bool is2D() const                                            { return false; }\n+    inline int  XY(int x, int y) const                                            { return x; }\n     inline void setPixelColorXY(int x, int y, uint32_t c)                         { setPixelColor(x, c); }\n     inline void setPixelColorXY(unsigned x, unsigned y, uint32_t c)               { setPixelColor(int(x), c); }\n     inline void setPixelColorXY(int x, int y, byte r, byte g, byte b, byte w = 0) { setPixelColor(x, RGBW32(r,g,b,w)); }\n@@ -778,7 +779,7 @@ class WS2812FX {  // 96 bytes\n     }\n \n     ~WS2812FX() {\n-      if (customMappingTable) delete[] customMappingTable;\n+      if (customMappingTable) free(customMappingTable);\n       _mode.clear();\n       _modeData.clear();\n       _segments.clear();\n@@ -804,7 +805,7 @@ class WS2812FX {  // 96 bytes\n       resetSegments(),                            // marks all segments for reset\n       makeAutoSegments(bool forceReset = false),  // will create segments based on configured outputs\n       fixInvalidSegments(),                       // fixes incorrect segment configuration\n-      setPixelColor(unsigned n, uint32_t c),      // paints absolute strip pixel with index n and color c\n+      setPixelColor(unsigned i, uint32_t c) const,      // paints absolute strip pixel with index n and color c\n       show(),                                     // initiates LED output\n       setTargetFps(unsigned fps),\n       setupEffectData();                          // add default effects to the list; defined in FX.cpp\n@@ -812,9 +813,9 @@ class WS2812FX {  // 96 bytes\n     inline void resetTimebase()           { timebase = 0UL - millis(); }\n     inline void restartRuntime()          { for (Segment &seg : _segments) { seg.markForReset().resetIfRequired(); } }\n     inline void setTransitionMode(bool t) { for (Segment &seg : _segments) seg.startTransition(t ? _transitionDur : 0); }\n-    inline void setPixelColor(unsigned n, uint8_t r, uint8_t g, uint8_t b, uint8_t w = 0) { setPixelColor(n, RGBW32(r,g,b,w)); }\n-    inline void setPixelColor(unsigned n, CRGB c)                                         { setPixelColor(n, c.red, c.green, c.blue); }\n-    inline void fill(uint32_t c)          { for (unsigned i = 0; i < getLengthTotal(); i++) setPixelColor(i, c); } // fill whole strip with color (inline)\n+    inline void setPixelColor(unsigned n, uint8_t r, uint8_t g, uint8_t b, uint8_t w = 0) const { setPixelColor(n, RGBW32(r,g,b,w)); }\n+    inline void setPixelColor(unsigned n, CRGB c) const                                         { setPixelColor(n, c.red, c.green, c.blue); }\n+    inline void fill(uint32_t c) const    { for (unsigned i = 0; i < getLengthTotal(); i++) setPixelColor(i, c); } // fill whole strip with color (inline)\n     inline void trigger()                                     { _triggered = true; }  // Forces the next frame to be computed on all active segments.\n     inline void setShowCallback(show_callback cb)             { _callback = cb; }\n     inline void setTransition(uint16_t t)                     { _transitionDur = t; } // sets transition time (in ms)\n@@ -824,7 +825,7 @@ class WS2812FX {  // 96 bytes\n \n     bool\n       paletteFade,\n-      checkSegmentAlignment(),\n+      checkSegmentAlignment() const,\n       hasRGBWBus() const,\n       hasCCTBus() const,\n       deserializeMap(unsigned n = 0);\n@@ -869,7 +870,7 @@ class WS2812FX {  // 96 bytes\n     };\n \n     unsigned long now, timebase;\n-    uint32_t getPixelColor(unsigned) const;\n+    uint32_t getPixelColor(unsigned i) const;\n \n     inline uint32_t getLastShow() const   { return _lastShow; }           // returns millis() timestamp of last strip.show() call\n \n@@ -918,11 +919,11 @@ class WS2812FX {  // 96 bytes\n     void setUpMatrix();     // sets up automatic matrix ledmap from panel configuration\n \n     // outsmart the compiler :) by correctly overloading\n-    inline void setPixelColorXY(int x, int y, uint32_t c)   { setPixelColor((unsigned)(y * Segment::maxWidth + x), c); }\n-    inline void setPixelColorXY(int x, int y, byte r, byte g, byte b, byte w = 0) { setPixelColorXY(x, y, RGBW32(r,g,b,w)); }\n-    inline void setPixelColorXY(int x, int y, CRGB c)       { setPixelColorXY(x, y, RGBW32(c.r,c.g,c.b,0)); }\n+    inline void setPixelColorXY(int x, int y, uint32_t c) const { setPixelColor((unsigned)(y * Segment::maxWidth + x), c); }\n+    inline void setPixelColorXY(int x, int y, byte r, byte g, byte b, byte w = 0) const { setPixelColorXY(x, y, RGBW32(r,g,b,w)); }\n+    inline void setPixelColorXY(int x, int y, CRGB c) const     { setPixelColorXY(x, y, RGBW32(c.r,c.g,c.b,0)); }\n \n-    inline uint32_t getPixelColorXY(int x, int y) const     { return getPixelColor(isMatrix ? y * Segment::maxWidth + x : x); }\n+    inline uint32_t getPixelColorXY(int x, int y) const         { return getPixelColor(isMatrix ? y * Segment::maxWidth + x : x); }\n \n   // end 2D support\n \n@@ -936,7 +937,7 @@ class WS2812FX {  // 96 bytes\n     };\n \n     std::vector<segment> _segments;\n-    friend class Segment;\n+    friend struct Segment;\n \n   private:\n     volatile bool _suspend;\ndiff --git a/wled00/FX_2Dfcn.cpp b/wled00/FX_2Dfcn.cpp\nindex f00e7147d2..0d38578a32 100644\n--- a/wled00/FX_2Dfcn.cpp\n+++ b/wled00/FX_2Dfcn.cpp\n@@ -50,8 +50,8 @@ void WS2812FX::setUpMatrix() {\n \n     customMappingSize = 0; // prevent use of mapping if anything goes wrong\n \n-    if (customMappingTable) delete[] customMappingTable;\n-    customMappingTable = new uint16_t[getLengthTotal()];\n+    if (customMappingTable) free(customMappingTable);\n+    customMappingTable = static_cast<uint16_t*>(malloc(sizeof(uint16_t)*getLengthTotal()));\n \n     if (customMappingTable) {\n       customMappingSize = getLengthTotal();\n@@ -68,7 +68,7 @@ void WS2812FX::setUpMatrix() {\n       // content of the file is just raw JSON array in the form of [val1,val2,val3,...]\n       // there are no other \"key\":\"value\" pairs in it\n       // allowed values are: -1 (missing pixel/no LED attached), 0 (inactive/unused pixel), 1 (active/used pixel)\n-      char    fileName[32]; strcpy_P(fileName, PSTR(\"/2d-gaps.json\")); // reduce flash footprint\n+      char    fileName[32]; strcpy_P(fileName, PSTR(\"/2d-gaps.json\"));\n       bool    isFile = WLED_FS.exists(fileName);\n       size_t  gapSize = 0;\n       int8_t *gapTable = nullptr;\n@@ -85,7 +85,7 @@ void WS2812FX::setUpMatrix() {\n           JsonArray map = pDoc->as<JsonArray>();\n           gapSize = map.size();\n           if (!map.isNull() && gapSize >= matrixSize) { // not an empty map\n-            gapTable = new int8_t[gapSize];\n+            gapTable = static_cast<int8_t*>(malloc(gapSize));\n             if (gapTable) for (size_t i = 0; i < gapSize; i++) {\n               gapTable[i] = constrain(map[i], -1, 1);\n             }\n@@ -113,7 +113,7 @@ void WS2812FX::setUpMatrix() {\n       }\n \n       // delete gap array as we no longer need it\n-      if (gapTable) delete[] gapTable;\n+      if (gapTable) free(gapTable);\n \n       #ifdef WLED_DEBUG\n       DEBUG_PRINT(F(\"Matrix ledmap:\"));\n@@ -146,7 +146,7 @@ void WS2812FX::setUpMatrix() {\n #ifndef WLED_DISABLE_2D\n \n // XY(x,y) - gets pixel index within current segment (often used to reference leds[] array element)\n-uint16_t IRAM_ATTR_YN Segment::XY(int x, int y)\n+int IRAM_ATTR_YN Segment::XY(int x, int y) const\n {\n   const int vW = vWidth();   // segment width in logical pixels (can be 0 if segment is inactive)\n   const int vH = vHeight();  // segment height in logical pixels (is always >= 1)\n@@ -154,7 +154,7 @@ uint16_t IRAM_ATTR_YN Segment::XY(int x, int y)\n }\n \n // raw setColor function without checks (checks are done in setPixelColorXY())\n-void IRAM_ATTR_YN Segment::_setPixelColorXY_raw(int& x, int& y, uint32_t& col)\n+void IRAM_ATTR_YN Segment::_setPixelColorXY_raw(const int& x, const int& y, uint32_t& col) const\n {\n   const int baseX = start + x;\n   const int baseY = startY + y;\n@@ -179,7 +179,7 @@ void IRAM_ATTR_YN Segment::_setPixelColorXY_raw(int& x, int& y, uint32_t& col)\n   }\n }\n \n-void IRAM_ATTR_YN Segment::setPixelColorXY(int x, int y, uint32_t col)\n+void IRAM_ATTR_YN Segment::setPixelColorXY(int x, int y, uint32_t col) const\n {\n   if (!isActive()) return; // not active\n \n@@ -215,7 +215,7 @@ void IRAM_ATTR_YN Segment::setPixelColorXY(int x, int y, uint32_t col)\n \n #ifdef WLED_USE_AA_PIXELS\n // anti-aliased version of setPixelColorXY()\n-void Segment::setPixelColorXY(float x, float y, uint32_t col, bool aa)\n+void Segment::setPixelColorXY(float x, float y, uint32_t col, bool aa) const\n {\n   if (!isActive()) return; // not active\n   if (x<0.0f || x>1.0f || y<0.0f || y>1.0f) return; // not normalized\n@@ -276,7 +276,7 @@ void Segment::blur2D(uint8_t blur_x, uint8_t blur_y, bool smear) {\n   if (!isActive()) return; // not active\n   const unsigned cols = vWidth();\n   const unsigned rows = vHeight();\n-  uint32_t lastnew;\n+  uint32_t lastnew;   // not necessary to initialize lastnew and last, as both will be initialized by the first loop iteration\n   uint32_t last;\n   if (blur_x) {\n     const uint8_t keepx = smear ? 255 : 255 - blur_x;\ndiff --git a/wled00/FX_fcn.cpp b/wled00/FX_fcn.cpp\nindex b9a62bb2ca..5ad2314df8 100644\n--- a/wled00/FX_fcn.cpp\n+++ b/wled00/FX_fcn.cpp\n@@ -94,7 +94,7 @@ Segment::Segment(const Segment &orig) {\n   name = nullptr;\n   data = nullptr;\n   _dataLen = 0;\n-  if (orig.name) { name = new char[strlen(orig.name)+1]; if (name) strcpy(name, orig.name); }\n+  if (orig.name) { name = static_cast<char*>(malloc(strlen(orig.name)+1)); if (name) strcpy(name, orig.name); }\n   if (orig.data) { if (allocateData(orig._dataLen)) memcpy(data, orig.data, orig._dataLen); }\n }\n \n@@ -113,7 +113,7 @@ Segment& Segment::operator= (const Segment &orig) {\n   //DEBUG_PRINTF_P(PSTR(\"-- Copying segment: %p -> %p\\n\"), &orig, this);\n   if (this != &orig) {\n     // clean destination\n-    if (name) { delete[] name; name = nullptr; }\n+    if (name) { free(name); name = nullptr; }\n     stopTransition();\n     deallocateData();\n     // copy source\n@@ -122,7 +122,7 @@ Segment& Segment::operator= (const Segment &orig) {\n     data = nullptr;\n     _dataLen = 0;\n     // copy source data\n-    if (orig.name) { name = new char[strlen(orig.name)+1]; if (name) strcpy(name, orig.name); }\n+    if (orig.name) { name = static_cast<char*>(malloc(strlen(orig.name)+1)); if (name) strcpy(name, orig.name); }\n     if (orig.data) { if (allocateData(orig._dataLen)) memcpy(data, orig.data, orig._dataLen); }\n   }\n   return *this;\n@@ -132,7 +132,7 @@ Segment& Segment::operator= (const Segment &orig) {\n Segment& Segment::operator= (Segment &&orig) noexcept {\n   //DEBUG_PRINTF_P(PSTR(\"-- Moving segment: %p -> %p\\n\"), &orig, this);\n   if (this != &orig) {\n-    if (name) { delete[] name; name = nullptr; } // free old name\n+    if (name) { free(name); name = nullptr; } // free old name\n     stopTransition();\n     deallocateData(); // free old runtime data\n     memcpy((void*)this, (void*)&orig, sizeof(Segment));\n@@ -253,7 +253,7 @@ void Segment::startTransition(uint16_t dur) {\n   if (isInTransition()) return; // already in transition no need to store anything\n \n   // starting a transition has to occur before change so we get current values 1st\n-  _t = new Transition(dur); // no previous transition running\n+  _t = new(std::nothrow) Transition(dur); // no previous transition running\n   if (!_t) return; // failed to allocate data\n \n   //DEBUG_PRINTF_P(PSTR(\"-- Started transition: %p (%p)\\n\"), this, _t);\n@@ -296,6 +296,7 @@ void Segment::stopTransition() {\n     delete _t;\n     _t = nullptr;\n   }\n+  _transitionprogress = 0xFFFFU; // stop means stop - transition has ended\n }\n \n // transition progression between 0-65535\n@@ -326,7 +327,7 @@ void Segment::swapSegenv(tmpsegd_t &tmpSeg) {\n   tmpSeg._callT      = call;\n   tmpSeg._dataT      = data;\n   tmpSeg._dataLenT   = _dataLen;\n-  if (_t && &tmpSeg != &(_t->_segT)) {\n+  if (isInTransition() && &tmpSeg != &(_t->_segT)) {\n     // swap SEGENV with transitional data\n     options   = _t->_segT._optionsT;\n     for (size_t i=0; i<NUM_COLORS; i++) colors[i] = _t->_segT._colorT[i];\n@@ -347,9 +348,9 @@ void Segment::swapSegenv(tmpsegd_t &tmpSeg) {\n   }\n }\n \n-void Segment::restoreSegenv(tmpsegd_t &tmpSeg) {\n+void Segment::restoreSegenv(const tmpsegd_t &tmpSeg) {\n   //DEBUG_PRINTF_P(PSTR(\"--  Restoring temp seg: %p->(%p) [%d->%p]\\n\"), &tmpSeg, this, _dataLen, data);\n-  if (_t && &(_t->_segT) != &tmpSeg) {\n+  if (isInTransition() && &(_t->_segT) != &tmpSeg) {\n     // update possibly changed variables to keep old effect running correctly\n     _t->_segT._aux0T = aux0;\n     _t->_segT._aux1T = aux1;\n@@ -379,8 +380,8 @@ void Segment::restoreSegenv(tmpsegd_t &tmpSeg) {\n #endif\n \n uint8_t Segment::currentBri(bool useCct) const {\n-  unsigned prog = progress();\n-  if (prog < 0xFFFFU) {\n+  unsigned prog = isInTransition() ? progress() : 0xFFFFU;\n+  if (prog < 0xFFFFU) { // progress() < 0xFFFF implies that _t is a valid pointer\n     unsigned curBri = (useCct ? cct : (on ? opacity : 0)) * prog;\n     curBri += (useCct ? _t->_cctT : _t->_briT) * (0xFFFFU - prog);\n     return curBri / 0xFFFFU;\n@@ -390,8 +391,8 @@ uint8_t Segment::currentBri(bool useCct) const {\n \n uint8_t Segment::currentMode() const {\n #ifndef WLED_DISABLE_MODE_BLEND\n-  unsigned prog = progress();\n-  if (modeBlending && prog < 0xFFFFU) return _t->_modeT;\n+  unsigned prog = isInTransition() ? progress() : 0xFFFFU;\n+  if (modeBlending && prog < 0xFFFFU) return _t->_modeT;  // progress() < 0xFFFF implies that _t is a valid pointer\n #endif\n   return mode;\n }\n@@ -411,18 +412,18 @@ void Segment::beginDraw() {\n   _vHeight = virtualHeight();\n   _vLength = virtualLength();\n   _segBri  = currentBri();\n+  unsigned prog = isInTransition() ? progress() : 0xFFFFU;  // transition progress; 0xFFFFU = no transition active\n   // adjust gamma for effects\n   for (unsigned i = 0; i < NUM_COLORS; i++) {\n     #ifndef WLED_DISABLE_MODE_BLEND\n-    uint32_t col = isInTransition() ? color_blend16(_t->_segT._colorT[i], colors[i], progress()) : colors[i];\n+    uint32_t col = isInTransition() ? color_blend16(_t->_segT._colorT[i], colors[i], prog) : colors[i];\n     #else\n-    uint32_t col = isInTransition() ? color_blend16(_t->_colorT[i], colors[i], progress()) : colors[i];\n+    uint32_t col = isInTransition() ? color_blend16(_t->_colorT[i], colors[i], prog) : colors[i];\n     #endif\n     _currentColors[i] = gamma32(col);\n   }\n   // load palette into _currentPalette\n   loadPalette(_currentPalette, palette);\n-  unsigned prog = progress();\n   if (strip.paletteFade && prog < 0xFFFFU) {\n     // blend palettes\n     // there are about 255 blend passes of 48 \"blends\" to completely blend two palettes (in _dur time)\n@@ -696,7 +697,7 @@ uint16_t Segment::virtualLength() const {\n   return vLength;\n }\n \n-void IRAM_ATTR_YN Segment::setPixelColor(int i, uint32_t col)\n+void IRAM_ATTR_YN Segment::setPixelColor(int i, uint32_t col) const\n {\n   if (!isActive() || i < 0) return; // not active or invalid index\n #ifndef WLED_DISABLE_2D\n@@ -869,7 +870,7 @@ void IRAM_ATTR_YN Segment::setPixelColor(int i, uint32_t col)\n \n #ifdef WLED_USE_AA_PIXELS\n // anti-aliased normalized version of setPixelColor()\n-void Segment::setPixelColor(float i, uint32_t col, bool aa)\n+void Segment::setPixelColor(float i, uint32_t col, bool aa) const\n {\n   if (!isActive()) return; // not active\n   int vStrip = int(i/10.0f); // hack to allow running on virtual strips (2D segment columns/rows)\n@@ -1134,7 +1135,7 @@ void Segment::blur(uint8_t blur_amount, bool smear) {\n   uint8_t seep = blur_amount >> 1;\n   unsigned vlength = vLength();\n   uint32_t carryover = BLACK;\n-  uint32_t lastnew;\n+  uint32_t lastnew;       // not necessary to initialize lastnew and last, as both will be initialized by the first loop iteration\n   uint32_t last;\n   uint32_t curnew = BLACK;\n   for (unsigned i = 0; i < vlength; i++) {\n@@ -1413,7 +1414,7 @@ void WS2812FX::service() {\n   #endif\n }\n \n-void IRAM_ATTR WS2812FX::setPixelColor(unsigned i, uint32_t col) {\n+void IRAM_ATTR WS2812FX::setPixelColor(unsigned i, uint32_t col) const {\n   i = getMappedPixelIndex(i);\n   if (i >= _length) return;\n   BusManager::setPixelColor(i, col);\n@@ -1694,9 +1695,9 @@ void WS2812FX::fixInvalidSegments() {\n \n //true if all segments align with a bus, or if a segment covers the total length\n //irrelevant in 2D set-up\n-bool WS2812FX::checkSegmentAlignment() {\n+bool WS2812FX::checkSegmentAlignment() const {\n   bool aligned = false;\n-  for (segment &seg : _segments) {\n+  for (const segment &seg : _segments) {\n     for (unsigned b = 0; b<BusManager::getNumBusses(); b++) {\n       Bus *bus = BusManager::getBus(b);\n       if (seg.start == bus->getStart() && seg.stop == bus->getStart() + bus->getLength()) aligned = true;\n@@ -1808,8 +1809,8 @@ bool WS2812FX::deserializeMap(unsigned n) {\n     Segment::maxHeight = min(max(root[F(\"height\")].as<int>(), 1), 128);\n   }\n \n-  if (customMappingTable) delete[] customMappingTable;\n-  customMappingTable = new uint16_t[getLengthTotal()];\n+  if (customMappingTable) free(customMappingTable);\n+  customMappingTable = static_cast<uint16_t*>(malloc(sizeof(uint16_t)*getLengthTotal()));\n \n   if (customMappingTable) {\n     DEBUG_PRINT(F(\"Reading LED map from \")); DEBUG_PRINTLN(fileName);\ndiff --git a/wled00/bus_manager.cpp b/wled00/bus_manager.cpp\nindex 2c0ba41a9a..6e159a82b2 100644\n--- a/wled00/bus_manager.cpp\n+++ b/wled00/bus_manager.cpp\n@@ -27,7 +27,7 @@ extern bool cctICused;\n uint32_t colorBalanceFromKelvin(uint16_t kelvin, uint32_t rgb);\n \n //udp.cpp\n-uint8_t realtimeBroadcast(uint8_t type, IPAddress client, uint16_t length, byte *buffer, uint8_t bri=255, bool isRGBW=false);\n+uint8_t realtimeBroadcast(uint8_t type, IPAddress client, uint16_t length, const uint8_t* buffer, uint8_t bri=255, bool isRGBW=false);\n \n // enable additional debug output\n #if defined(WLED_DEBUG_HOST)\n@@ -121,7 +121,7 @@ uint8_t *Bus::allocateData(size_t size) {\n }\n \n \n-BusDigital::BusDigital(BusConfig &bc, uint8_t nr, const ColorOrderMap &com)\n+BusDigital::BusDigital(const BusConfig &bc, uint8_t nr, const ColorOrderMap &com)\n : Bus(bc.type, bc.start, bc.autoWhite, bc.count, bc.reversed, (bc.refreshReq || bc.type == TYPE_TM1814))\n , _skip(bc.skipAmount) //sacrificial pixels\n , _colorOrder(bc.colorOrder)\n@@ -448,7 +448,7 @@ void BusDigital::cleanup() {\n   #endif\n #endif\n \n-BusPwm::BusPwm(BusConfig &bc)\n+BusPwm::BusPwm(const BusConfig &bc)\n : Bus(bc.type, bc.start, bc.autoWhite, 1, bc.reversed, bc.refreshReq) // hijack Off refresh flag to indicate usage of dithering\n {\n   if (!isPWM(bc.type)) return;\n@@ -646,7 +646,7 @@ void BusPwm::deallocatePins() {\n }\n \n \n-BusOnOff::BusOnOff(BusConfig &bc)\n+BusOnOff::BusOnOff(const BusConfig &bc)\n : Bus(bc.type, bc.start, bc.autoWhite, 1, bc.reversed)\n , _onoffdata(0)\n {\n@@ -699,7 +699,7 @@ std::vector<LEDType> BusOnOff::getLEDTypes() {\n   };\n }\n \n-BusNetwork::BusNetwork(BusConfig &bc)\n+BusNetwork::BusNetwork(const BusConfig &bc)\n : Bus(bc.type, bc.start, bc.autoWhite, bc.count)\n , _broadcastLock(false)\n {\n@@ -778,7 +778,7 @@ void BusNetwork::cleanup() {\n \n \n //utility to get the approx. memory usage of a given BusConfig\n-uint32_t BusManager::memUsage(BusConfig &bc) {\n+uint32_t BusManager::memUsage(const BusConfig &bc) {\n   if (Bus::isOnOff(bc.type) || Bus::isPWM(bc.type)) return OUTPUT_MAX_PINS;\n \n   unsigned len = bc.count + bc.skipAmount;\n@@ -803,7 +803,7 @@ uint32_t BusManager::memUsage(unsigned maxChannels, unsigned maxCount, unsigned\n   return (maxChannels * maxCount * minBuses * multiplier);\n }\n \n-int BusManager::add(BusConfig &bc) {\n+int BusManager::add(const BusConfig &bc) {\n   if (getNumBusses() - getNumVirtualBusses() >= WLED_MAX_BUSSES) return -1;\n   if (Bus::isVirtual(bc.type)) {\n     busses[numBusses] = new BusNetwork(bc);\ndiff --git a/wled00/bus_manager.h b/wled00/bus_manager.h\nindex d90a661511..9aed013089 100644\n--- a/wled00/bus_manager.h\n+++ b/wled00/bus_manager.h\n@@ -198,7 +198,7 @@ class Bus {\n \n class BusDigital : public Bus {\n   public:\n-    BusDigital(BusConfig &bc, uint8_t nr, const ColorOrderMap &com);\n+    BusDigital(const BusConfig &bc, uint8_t nr, const ColorOrderMap &com);\n     ~BusDigital() { cleanup(); }\n \n     void show() override;\n@@ -250,7 +250,7 @@ class BusDigital : public Bus {\n \n class BusPwm : public Bus {\n   public:\n-    BusPwm(BusConfig &bc);\n+    BusPwm(const BusConfig &bc);\n     ~BusPwm() { cleanup(); }\n \n     void setPixelColor(unsigned pix, uint32_t c) override;\n@@ -277,7 +277,7 @@ class BusPwm : public Bus {\n \n class BusOnOff : public Bus {\n   public:\n-    BusOnOff(BusConfig &bc);\n+    BusOnOff(const BusConfig &bc);\n     ~BusOnOff() { cleanup(); }\n \n     void setPixelColor(unsigned pix, uint32_t c) override;\n@@ -296,7 +296,7 @@ class BusOnOff : public Bus {\n \n class BusNetwork : public Bus {\n   public:\n-    BusNetwork(BusConfig &bc);\n+    BusNetwork(const BusConfig &bc);\n     ~BusNetwork() { cleanup(); }\n \n     bool canShow() const override  { return !_broadcastLock; } // this should be a return value from UDP routine if it is still sending data out\n@@ -379,12 +379,12 @@ class BusManager {\n     BusManager() {};\n \n     //utility to get the approx. memory usage of a given BusConfig\n-    static uint32_t memUsage(BusConfig &bc);\n+    static uint32_t memUsage(const BusConfig &bc);\n     static uint32_t memUsage(unsigned channels, unsigned count, unsigned buses = 1);\n     static uint16_t currentMilliamps() { return _milliAmpsUsed + MA_FOR_ESP; }\n     static uint16_t ablMilliampsMax()  { return _milliAmpsMax; }\n \n-    static int add(BusConfig &bc);\n+    static int add(const BusConfig &bc);\n     static void useParallelOutput(); // workaround for inaccessible PolyBus\n \n     //do not call this method from system context (network callback)\ndiff --git a/wled00/button.cpp b/wled00/button.cpp\nindex 4d6f954f60..a02b29b31f 100644\n--- a/wled00/button.cpp\n+++ b/wled00/button.cpp\n@@ -90,12 +90,12 @@ void doublePressAction(uint8_t b)\n #endif\n }\n \n-bool isButtonPressed(uint8_t i)\n+bool isButtonPressed(uint8_t b)\n {\n-  if (btnPin[i]<0) return false;\n-  unsigned pin = btnPin[i];\n+  if (btnPin[b]<0) return false;\n+  unsigned pin = btnPin[b];\n \n-  switch (buttonType[i]) {\n+  switch (buttonType[b]) {\n     case BTN_TYPE_NONE:\n     case BTN_TYPE_RESERVED:\n       break;\n@@ -113,7 +113,7 @@ bool isButtonPressed(uint8_t i)\n         #ifdef SOC_TOUCH_VERSION_2 //ESP32 S2 and S3 provide a function to check touch state (state is updated in interrupt)\n         if (touchInterruptGetLastStatus(pin)) return true;\n         #else\n-        if (digitalPinToTouchChannel(btnPin[i]) >= 0 && touchRead(pin) <= touchThreshold) return true;\n+        if (digitalPinToTouchChannel(btnPin[b]) >= 0 && touchRead(pin) <= touchThreshold) return true;\n         #endif\n       #endif\n      break;\ndiff --git a/wled00/colors.cpp b/wled00/colors.cpp\nindex e64cf67588..f154a1aea0 100644\n--- a/wled00/colors.cpp\n+++ b/wled00/colors.cpp\n@@ -122,7 +122,7 @@ void setRandomColor(byte* rgb)\n  * generates a random palette based on harmonic color theory\n  * takes a base palette as the input, it will choose one color of the base palette and keep it\n  */\n-CRGBPalette16 generateHarmonicRandomPalette(CRGBPalette16 &basepalette)\n+CRGBPalette16 generateHarmonicRandomPalette(const CRGBPalette16 &basepalette)\n {\n   CHSV palettecolors[4]; // array of colors for the new palette\n   uint8_t keepcolorposition = hw_random8(4); // color position of current random palette to keep\n@@ -391,7 +391,7 @@ void colorXYtoRGB(float x, float y, byte* rgb) //coordinates to rgb (https://www\n   rgb[2] = byte(255.0f*b);\n }\n \n-void colorRGBtoXY(byte* rgb, float* xy) //rgb to coordinates (https://www.developers.meethue.com/documentation/color-conversions-rgb-xy)\n+void colorRGBtoXY(const byte* rgb, float* xy) //rgb to coordinates (https://www.developers.meethue.com/documentation/color-conversions-rgb-xy)\n {\n   float X = rgb[0] * 0.664511f + rgb[1] * 0.154324f + rgb[2] * 0.162028f;\n   float Y = rgb[0] * 0.283881f + rgb[1] * 0.668433f + rgb[2] * 0.047685f;\n@@ -402,7 +402,7 @@ void colorRGBtoXY(byte* rgb, float* xy) //rgb to coordinates (https://www.develo\n #endif // WLED_DISABLE_HUESYNC\n \n //RRGGBB / WWRRGGBB order for hex\n-void colorFromDecOrHexString(byte* rgb, char* in)\n+void colorFromDecOrHexString(byte* rgb, const char* in)\n {\n   if (in[0] == 0) return;\n   char first = in[0];\ndiff --git a/wled00/fcn_declare.h b/wled00/fcn_declare.h\nindex bc5206b7ae..2292488d52 100644\n--- a/wled00/fcn_declare.h\n+++ b/wled00/fcn_declare.h\n@@ -161,12 +161,12 @@ class NeoGammaWLEDMethod {\n };\n #define gamma32(c) NeoGammaWLEDMethod::Correct32(c)\n #define gamma8(c)  NeoGammaWLEDMethod::rawGamma8(c)\n-[[gnu::hot]] uint32_t color_blend(uint32_t c1, uint32_t c2 , uint8_t blend);\n+[[gnu::hot, gnu::pure]] uint32_t color_blend(uint32_t c1, uint32_t c2 , uint8_t blend);\n inline uint32_t color_blend16(uint32_t c1, uint32_t c2, uint16_t b) { return color_blend(c1, c2, b >> 8); };\n-[[gnu::hot]] uint32_t color_add(uint32_t, uint32_t, bool preserveCR = false);\n-[[gnu::hot]] uint32_t color_fade(uint32_t c1, uint8_t amount, bool video=false);\n-[[gnu::hot]] uint32_t ColorFromPaletteWLED(const CRGBPalette16 &pal, unsigned index, uint8_t brightness = (uint8_t)255U, TBlendType blendType = LINEARBLEND);\n-CRGBPalette16 generateHarmonicRandomPalette(CRGBPalette16 &basepalette);\n+[[gnu::hot, gnu::pure]] uint32_t color_add(uint32_t, uint32_t, bool preserveCR = false);\n+[[gnu::hot, gnu::pure]] uint32_t color_fade(uint32_t c1, uint8_t amount, bool video=false);\n+[[gnu::hot, gnu::pure]] uint32_t ColorFromPaletteWLED(const CRGBPalette16 &pal, unsigned index, uint8_t brightness = (uint8_t)255U, TBlendType blendType = LINEARBLEND);\n+CRGBPalette16 generateHarmonicRandomPalette(const CRGBPalette16 &basepalette);\n CRGBPalette16 generateRandomPalette();\n inline uint32_t colorFromRgbw(byte* rgbw) { return uint32_t((byte(rgbw[3]) << 24) | (byte(rgbw[0]) << 16) | (byte(rgbw[1]) << 8) | (byte(rgbw[2]))); }\n void hsv2rgb(const CHSV32& hsv, uint32_t& rgb);\n@@ -176,8 +176,8 @@ inline CHSV rgb2hsv(const CRGB c) { CHSV32 hsv; rgb2hsv((uint32_t((byte(c.r) <<\n void colorKtoRGB(uint16_t kelvin, byte* rgb);\n void colorCTtoRGB(uint16_t mired, byte* rgb); //white spectrum to rgb\n void colorXYtoRGB(float x, float y, byte* rgb); // only defined if huesync disabled TODO\n-void colorRGBtoXY(byte* rgb, float* xy); // only defined if huesync disabled TODO\n-void colorFromDecOrHexString(byte* rgb, char* in);\n+void colorRGBtoXY(const byte* rgb, float* xy); // only defined if huesync disabled TODO\n+void colorFromDecOrHexString(byte* rgb, const char* in);\n bool colorFromHexString(byte* rgb, const char* in);\n uint32_t colorBalanceFromKelvin(uint16_t kelvin, uint32_t rgb);\n uint16_t approximateKelvinFromRGB(uint32_t rgb);\n@@ -195,14 +195,14 @@ void sendArtnetPollReply(ArtPollReply* reply, IPAddress ipAddress, uint16_t port\n \n //file.cpp\n bool handleFileRead(AsyncWebServerRequest*, String path);\n-bool writeObjectToFileUsingId(const char* file, uint16_t id, JsonDocument* content);\n-bool writeObjectToFile(const char* file, const char* key, JsonDocument* content);\n+bool writeObjectToFileUsingId(const char* file, uint16_t id, const JsonDocument* content);\n+bool writeObjectToFile(const char* file, const char* key, const JsonDocument* content);\n bool readObjectFromFileUsingId(const char* file, uint16_t id, JsonDocument* dest);\n bool readObjectFromFile(const char* file, const char* key, JsonDocument* dest);\n void updateFSInfo();\n void closeFile();\n-inline bool writeObjectToFileUsingId(const String &file, uint16_t id, JsonDocument* content) { return writeObjectToFileUsingId(file.c_str(), id, content); };\n-inline bool writeObjectToFile(const String &file, const char* key, JsonDocument* content) { return writeObjectToFile(file.c_str(), key, content); };\n+inline bool writeObjectToFileUsingId(const String &file, uint16_t id, const JsonDocument* content) { return writeObjectToFileUsingId(file.c_str(), id, content); };\n+inline bool writeObjectToFile(const String &file, const char* key, const JsonDocument* content) { return writeObjectToFile(file.c_str(), key, content); };\n inline bool readObjectFromFileUsingId(const String &file, uint16_t id, JsonDocument* dest) { return readObjectFromFileUsingId(file.c_str(), id, dest); };\n inline bool readObjectFromFile(const String &file, const char* key, JsonDocument* dest) { return readObjectFromFile(file.c_str(), key, dest); };\n \n@@ -243,11 +243,11 @@ void handleIR();\n \n bool deserializeSegment(JsonObject elem, byte it, byte presetId = 0);\n bool deserializeState(JsonObject root, byte callMode = CALL_MODE_DIRECT_CHANGE, byte presetId = 0);\n-void serializeSegment(JsonObject& root, Segment& seg, byte id, bool forPreset = false, bool segmentBounds = true);\n+void serializeSegment(const JsonObject& root, const Segment& seg, byte id, bool forPreset = false, bool segmentBounds = true);\n void serializeState(JsonObject root, bool forPreset = false, bool includeBri = true, bool segmentBounds = true, bool selectedSegmentsOnly = false);\n void serializeInfo(JsonObject root);\n-void serializeModeNames(JsonArray root);\n-void serializeModeData(JsonArray root);\n+void serializeModeNames(JsonArray arr);\n+void serializeModeData(JsonArray fxdata);\n void serveJson(AsyncWebServerRequest* request);\n #ifdef WLED_ENABLE_JSONLIVE\n bool serveLiveLeds(AsyncWebServerRequest* request, uint32_t wsClient = 0);\n@@ -327,7 +327,7 @@ bool handleSet(AsyncWebServerRequest *request, const String& req, bool apply=tru\n \n //udp.cpp\n void notify(byte callMode, bool followUp=false);\n-uint8_t realtimeBroadcast(uint8_t type, IPAddress client, uint16_t length, uint8_t *buffer, uint8_t bri=255, bool isRGBW=false);\n+uint8_t realtimeBroadcast(uint8_t type, IPAddress client, uint16_t length, const uint8_t* buffer, uint8_t bri=255, bool isRGBW=false);\n void realtimeLock(uint32_t timeoutMs, byte md = REALTIME_MODE_GENERIC);\n void exitRealtime();\n void handleNotifications();\n@@ -464,10 +464,10 @@ void userLoop();\n #include \"soc/wdev_reg.h\"\n #define HW_RND_REGISTER REG_READ(WDEV_RND_REG)\n #endif\n-int getNumVal(const String* req, uint16_t pos);\n+[[gnu::pure]] int getNumVal(const String* req, uint16_t pos);\n void parseNumber(const char* str, byte* val, byte minv=0, byte maxv=255);\n-bool getVal(JsonVariant elem, byte* val, byte minv=0, byte maxv=255); // getVal supports inc/decrementing and random (\"X~Y(r|~[w][-][Z])\" form)\n-bool getBoolVal(JsonVariant elem, bool dflt);\n+bool getVal(JsonVariant elem, byte* val, byte vmin=0, byte vmax=255); // getVal supports inc/decrementing and random (\"X~Y(r|[w]~[-][Z])\" form)\n+[[gnu::pure]] bool getBoolVal(const JsonVariant &elem, bool dflt);\n bool updateVal(const char* req, const char* key, byte* val, byte minv=0, byte maxv=255);\n size_t printSetFormCheckbox(Print& settingsScript, const char* key, int val);\n size_t printSetFormValue(Print& settingsScript, const char* key, int val);\n@@ -475,8 +475,8 @@ size_t printSetFormValue(Print& settingsScript, const char* key, const char* val\n size_t printSetFormIndex(Print& settingsScript, const char* key, int index);\n size_t printSetClassElementHTML(Print& settingsScript, const char* key, const int index, const char* val);\n void prepareHostname(char* hostname);\n-bool isAsterisksOnly(const char* str, byte maxLen);\n-bool requestJSONBufferLock(uint8_t module=255);\n+[[gnu::pure]] bool isAsterisksOnly(const char* str, byte maxLen);\n+bool requestJSONBufferLock(uint8_t moduleID=255);\n void releaseJSONBufferLock();\n uint8_t extractModeName(uint8_t mode, const char *src, char *dest, uint8_t maxLen);\n uint8_t extractModeSlider(uint8_t mode, uint8_t slider, char *dest, uint8_t maxLen, uint8_t *var = nullptr);\n@@ -488,8 +488,8 @@ uint16_t beatsin16_t(accum88 beats_per_minute, uint16_t lowest = 0, uint16_t hig\n uint8_t beatsin8_t(accum88 beats_per_minute, uint8_t lowest = 0, uint8_t highest = 255, uint32_t timebase = 0, uint8_t phase_offset = 0);\n um_data_t* simulateSound(uint8_t simulationId);\n void enumerateLedmaps();\n-uint8_t get_random_wheel_index(uint8_t pos);\n-float mapf(float x, float in_min, float in_max, float out_min, float out_max);\n+[[gnu::hot]] uint8_t get_random_wheel_index(uint8_t pos);\n+[[gnu::hot, gnu::pure]] float mapf(float x, float in_min, float in_max, float out_min, float out_max);\n \n // fast (true) random numbers using hardware RNG, all functions return values in the range lowerlimit to upperlimit-1\n // note: for true random numbers with high entropy, do not call faster than every 200ns (5MHz)\ndiff --git a/wled00/file.cpp b/wled00/file.cpp\nindex bc34672023..46df8d380c 100644\n--- a/wled00/file.cpp\n+++ b/wled00/file.cpp\n@@ -176,7 +176,7 @@ static void writeSpace(size_t l)\n   if (knownLargestSpace < l) knownLargestSpace = l;\n }\n \n-bool appendObjectToFile(const char* key, JsonDocument* content, uint32_t s, uint32_t contentLen = 0)\n+static bool appendObjectToFile(const char* key, const JsonDocument* content, uint32_t s, uint32_t contentLen = 0)\n {\n   #ifdef WLED_DEBUG_FS\n     DEBUGFS_PRINTLN(F(\"Append\"));\n@@ -255,14 +255,14 @@ bool appendObjectToFile(const char* key, JsonDocument* content, uint32_t s, uint\n   return true;\n }\n \n-bool writeObjectToFileUsingId(const char* file, uint16_t id, JsonDocument* content)\n+bool writeObjectToFileUsingId(const char* file, uint16_t id, const JsonDocument* content)\n {\n   char objKey[10];\n   sprintf(objKey, \"\\\"%d\\\":\", id);\n   return writeObjectToFile(file, objKey, content);\n }\n \n-bool writeObjectToFile(const char* file, const char* key, JsonDocument* content)\n+bool writeObjectToFile(const char* file, const char* key, const JsonDocument* content)\n {\n   uint32_t s = 0; //timing\n   #ifdef WLED_DEBUG_FS\ndiff --git a/wled00/json.cpp b/wled00/json.cpp\nindex cc25d5f89d..c63da08546 100644\n--- a/wled00/json.cpp\n+++ b/wled00/json.cpp\n@@ -68,7 +68,7 @@ bool deserializeSegment(JsonObject elem, byte it, byte presetId)\n   if (elem[\"n\"]) {\n     // name field exists\n     if (seg.name) { //clear old name\n-      delete[] seg.name;\n+      free(seg.name);\n       seg.name = nullptr;\n     }\n \n@@ -77,7 +77,7 @@ bool deserializeSegment(JsonObject elem, byte it, byte presetId)\n     if (name != nullptr) len = strlen(name);\n     if (len > 0) {\n       if (len > WLED_MAX_SEGNAME_LEN) len = WLED_MAX_SEGNAME_LEN;\n-      seg.name = new char[len+1];\n+      seg.name = static_cast<char*>(malloc(len+1));\n       if (seg.name) strlcpy(seg.name, name, WLED_MAX_SEGNAME_LEN+1);\n     } else {\n       // but is empty (already deleted above)\n@@ -86,7 +86,7 @@ bool deserializeSegment(JsonObject elem, byte it, byte presetId)\n   } else if (start != seg.start || stop != seg.stop) {\n     // clearing or setting segment without name field\n     if (seg.name) {\n-      delete[] seg.name;\n+      free(seg.name);\n       seg.name = nullptr;\n     }\n   }\n@@ -493,7 +493,7 @@ bool deserializeState(JsonObject root, byte callMode, byte presetId)\n   return stateResponse;\n }\n \n-void serializeSegment(JsonObject& root, Segment& seg, byte id, bool forPreset, bool segmentBounds)\n+void serializeSegment(const JsonObject& root, const Segment& seg, byte id, bool forPreset, bool segmentBounds)\n {\n   root[\"id\"] = id;\n   if (segmentBounds) {\ndiff --git a/wled00/lx_parser.cpp b/wled00/lx_parser.cpp\nindex 7fd91ea029..1318686ceb 100644\n--- a/wled00/lx_parser.cpp\n+++ b/wled00/lx_parser.cpp\n@@ -22,7 +22,7 @@ bool parseLx(int lxValue, byte* rgbw)\n   } else if ((lxValue >= 200000000) && (lxValue <= 201006500)) {\n     // Loxone Lumitech\n     ok = true;\n-    float tmpBri = floor((lxValue - 200000000) / 10000); ;\n+    float tmpBri = floor((lxValue - 200000000) / 10000);\n     uint16_t ct = (lxValue - 200000000) - (((uint8_t)tmpBri) * 10000);\n \n     tmpBri *= 2.55f;\ndiff --git a/wled00/mqtt.cpp b/wled00/mqtt.cpp\nindex a476db87a7..925e075552 100644\n--- a/wled00/mqtt.cpp\n+++ b/wled00/mqtt.cpp\n@@ -64,8 +64,8 @@ static void onMqttMessage(char* topic, char* payload, AsyncMqttClientMessageProp\n   }\n \n   if (index == 0) {                       // start (1st partial packet or the only packet)\n-    if (payloadStr) delete[] payloadStr;  // fail-safe: release buffer\n-    payloadStr = new char[total+1];       // allocate new buffer\n+    if (payloadStr) free(payloadStr);     // fail-safe: release buffer\n+    payloadStr = static_cast<char*>(malloc(total+1)); // allocate new buffer\n   }\n   if (payloadStr == nullptr) return;      // buffer not allocated\n \n@@ -90,7 +90,7 @@ static void onMqttMessage(char* topic, char* payload, AsyncMqttClientMessageProp\n     } else {\n       // Non-Wled Topic used here. Probably a usermod subscribed to this topic.\n       UsermodManager::onMqttMessage(topic, payloadStr);\n-      delete[] payloadStr;\n+      free(payloadStr);\n       payloadStr = nullptr;\n       return;\n     }\n@@ -120,7 +120,7 @@ static void onMqttMessage(char* topic, char* payload, AsyncMqttClientMessageProp\n     // topmost topic (just wled/MAC)\n     parseMQTTBriPayload(payloadStr);\n   }\n-  delete[] payloadStr;\n+  free(payloadStr);\n   payloadStr = nullptr;\n }\n \ndiff --git a/wled00/ntp.cpp b/wled00/ntp.cpp\nindex 8d44e634ec..12b698f445 100644\n--- a/wled00/ntp.cpp\n+++ b/wled00/ntp.cpp\n@@ -224,7 +224,7 @@ void sendNTPPacket()\n   ntpUdp.endPacket();\n }\n \n-static bool isValidNtpResponse(byte * ntpPacket) {\n+static bool isValidNtpResponse(const byte* ntpPacket) {\n   // Perform a few validity checks on the packet\n   //   based on https://github.com/taranais/NTPClient/blob/master/NTPClient.cpp\n   if((ntpPacket[0] & 0b11000000) == 0b11000000) return false; //reject LI=UNSYNC\ndiff --git a/wled00/playlist.cpp b/wled00/playlist.cpp\nindex 36235ab9ea..7f11e2bf0f 100644\n--- a/wled00/playlist.cpp\n+++ b/wled00/playlist.cpp\n@@ -61,7 +61,7 @@ int16_t loadPlaylist(JsonObject playlistObj, byte presetId) {\n   if (playlistLen == 0) return -1;\n   if (playlistLen > 100) playlistLen = 100;\n \n-  playlistEntries = new PlaylistEntry[playlistLen];\n+  playlistEntries = new(std::nothrow) PlaylistEntry[playlistLen];\n   if (playlistEntries == nullptr) return -1;\n \n   byte it = 0;\ndiff --git a/wled00/presets.cpp b/wled00/presets.cpp\nindex 1abcb52b93..15eed3e466 100644\n--- a/wled00/presets.cpp\n+++ b/wled00/presets.cpp\n@@ -76,8 +76,8 @@ static void doSaveState() {\n   // clean up\n   saveLedmap   = -1;\n   presetToSave = 0;\n-  delete[] saveName;\n-  delete[] quickLoad;\n+  free(saveName);\n+  free(quickLoad);\n   saveName = nullptr;\n   quickLoad = nullptr;\n   playlistSave = false;\n@@ -216,8 +216,8 @@ void handlePresets()\n //called from handleSet(PS=) [network callback (sObj is empty), IR (irrational), deserializeState, UDP] and deserializeState() [network callback (filedoc!=nullptr)]\n void savePreset(byte index, const char* pname, JsonObject sObj)\n {\n-  if (!saveName) saveName = new char[33];\n-  if (!quickLoad) quickLoad = new char[9];\n+  if (!saveName) saveName = static_cast<char*>(malloc(33));\n+  if (!quickLoad) quickLoad = static_cast<char*>(malloc(9));\n   if (!saveName || !quickLoad) return;\n \n   if (index == 0 || (index > 250 && index < 255)) return;\n@@ -263,8 +263,8 @@ void savePreset(byte index, const char* pname, JsonObject sObj)\n         presetsModifiedTime = toki.second(); //unix time\n         updateFSInfo();\n       }\n-      delete[] saveName;\n-      delete[] quickLoad;\n+      free(saveName);\n+      free(quickLoad);\n       saveName = nullptr;\n       quickLoad = nullptr;\n     } else {\ndiff --git a/wled00/set.cpp b/wled00/set.cpp\nindex 160eb48f07..6fc3292779 100644\n--- a/wled00/set.cpp\n+++ b/wled00/set.cpp\n@@ -209,7 +209,7 @@ void handleSettingsSet(AsyncWebServerRequest *request, byte subPage)\n       // actual finalization is done in WLED::loop() (removing old busses and adding new)\n       // this may happen even before this loop is finished so we do \"doInitBusses\" after the loop\n       if (busConfigs[s] != nullptr) delete busConfigs[s];\n-      busConfigs[s] = new BusConfig(type, pins, start, length, colorOrder | (channelSwap<<4), request->hasArg(cv), skip, awmode, freq, useGlobalLedBuffer, maPerLed, maMax);\n+      busConfigs[s] = new(std::nothrow) BusConfig(type, pins, start, length, colorOrder | (channelSwap<<4), request->hasArg(cv), skip, awmode, freq, useGlobalLedBuffer, maPerLed, maMax);\n       busesChanged = true;\n     }\n     //doInitBusses = busesChanged; // we will do that below to ensure all input data is processed\n@@ -982,18 +982,18 @@ bool handleSet(AsyncWebServerRequest *request, const String& req, bool apply)\n   //set color from HEX or 32bit DEC\n   pos = req.indexOf(F(\"CL=\"));\n   if (pos > 0) {\n-    colorFromDecOrHexString(colIn, (char*)req.substring(pos + 3).c_str());\n+    colorFromDecOrHexString(colIn, req.substring(pos + 3).c_str());\n     col0Changed = true;\n   }\n   pos = req.indexOf(F(\"C2=\"));\n   if (pos > 0) {\n-    colorFromDecOrHexString(colInSec, (char*)req.substring(pos + 3).c_str());\n+    colorFromDecOrHexString(colInSec, req.substring(pos + 3).c_str());\n     col1Changed = true;\n   }\n   pos = req.indexOf(F(\"C3=\"));\n   if (pos > 0) {\n     byte tmpCol[4];\n-    colorFromDecOrHexString(tmpCol, (char*)req.substring(pos + 3).c_str());\n+    colorFromDecOrHexString(tmpCol, req.substring(pos + 3).c_str());\n     col2 = RGBW32(tmpCol[0], tmpCol[1], tmpCol[2], tmpCol[3]);\n     selseg.setColor(2, col2); // defined above (SS= or main)\n     col2Changed = true;\ndiff --git a/wled00/udp.cpp b/wled00/udp.cpp\nindex 47398bc8a2..e993150d1c 100644\n--- a/wled00/udp.cpp\n+++ b/wled00/udp.cpp\n@@ -206,7 +206,7 @@ void notify(byte callMode, bool followUp)\n   notificationCount = followUp ? notificationCount + 1 : 0;\n }\n \n-void parseNotifyPacket(uint8_t *udpIn) {\n+static void parseNotifyPacket(const uint8_t *udpIn) {\n   //ignore notification if received within a second after sending a notification ourselves\n   if (millis() - notificationSentTime < 1000) return;\n   if (udpIn[1] > 199) return; //do not receive custom versions\n@@ -810,7 +810,7 @@ static       size_t sequenceNumber = 0; // this needs to be shared across all ou\n static const size_t ART_NET_HEADER_SIZE = 12;\n static const byte   ART_NET_HEADER[] PROGMEM = {0x41,0x72,0x74,0x2d,0x4e,0x65,0x74,0x00,0x00,0x50,0x00,0x0e};\n \n-uint8_t realtimeBroadcast(uint8_t type, IPAddress client, uint16_t length, uint8_t *buffer, uint8_t bri, bool isRGBW)  {\n+uint8_t realtimeBroadcast(uint8_t type, IPAddress client, uint16_t length, const uint8_t* buffer, uint8_t bri, bool isRGBW)  {\n   if (!(apActive || interfacesInited) || !client[0] || !length) return 1;  // network not initialised or dummy/unset IP address  031522 ajn added check for ap\n \n   WiFiUDP ddpUdp;\ndiff --git a/wled00/util.cpp b/wled00/util.cpp\nindex d9f1c00b94..ed38ae180b 100644\n--- a/wled00/util.cpp\n+++ b/wled00/util.cpp\n@@ -73,7 +73,7 @@ bool getVal(JsonVariant elem, byte* val, byte vmin, byte vmax) {\n }\n \n \n-bool getBoolVal(JsonVariant elem, bool dflt) {\n+bool getBoolVal(const JsonVariant &elem, bool dflt) {\n   if (elem.is<const char*>() && elem.as<const char*>()[0] == 't') {\n     return !dflt;\n   } else {\n@@ -151,7 +151,7 @@ bool isAsterisksOnly(const char* str, byte maxLen)\n \n \n //threading/network callback details: https://github.com/Aircoookie/WLED/pull/2336#discussion_r762276994\n-bool requestJSONBufferLock(uint8_t module)\n+bool requestJSONBufferLock(uint8_t moduleID)\n {\n   if (pDoc == nullptr) {\n     DEBUG_PRINTLN(F(\"ERROR: JSON buffer not allocated!\"));\n@@ -175,14 +175,14 @@ bool requestJSONBufferLock(uint8_t module)\n #endif  \n   // If the lock is still held - by us, or by another task\n   if (jsonBufferLock) {\n-    DEBUG_PRINTF_P(PSTR(\"ERROR: Locking JSON buffer (%d) failed! (still locked by %d)\\n\"), module, jsonBufferLock);\n+    DEBUG_PRINTF_P(PSTR(\"ERROR: Locking JSON buffer (%d) failed! (still locked by %d)\\n\"), moduleID, jsonBufferLock);\n #ifdef ARDUINO_ARCH_ESP32\n     xSemaphoreGiveRecursive(jsonBufferLockMutex);\n #endif\n     return false;\n   }\n \n-  jsonBufferLock = module ? module : 255;\n+  jsonBufferLock = moduleID ? moduleID : 255;\n   DEBUG_PRINTF_P(PSTR(\"JSON buffer locked. (%d)\\n\"), jsonBufferLock);\n   pDoc->clear();\n   return true;\n@@ -265,16 +265,16 @@ uint8_t extractModeSlider(uint8_t mode, uint8_t slider, char *dest, uint8_t maxL\n   if (mode < strip.getModeCount()) {\n     String lineBuffer = FPSTR(strip.getModeData(mode));\n     if (lineBuffer.length() > 0) {\n-      unsigned start = lineBuffer.indexOf('@');\n-      unsigned stop  = lineBuffer.indexOf(';', start);\n+      int start = lineBuffer.indexOf('@');   // String::indexOf() returns an int, not an unsigned; -1 means \"not found\"\n+      int stop  = lineBuffer.indexOf(';', start);\n       if (start>0 && stop>0) {\n         String names = lineBuffer.substring(start, stop); // include @\n-        unsigned nameBegin = 1, nameEnd, nameDefault;\n+        int nameBegin = 1, nameEnd, nameDefault;\n         if (slider < 10) {\n           for (size_t i=0; i<=slider; i++) {\n             const char *tmpstr;\n             dest[0] = '\\0'; //clear dest buffer\n-            if (nameBegin == 0) break; // there are no more names\n+            if (nameBegin <= 0) break; // there are no more names\n             nameEnd = names.indexOf(',', nameBegin);\n             if (i == slider) {\n               nameDefault = names.indexOf('=', nameBegin); // find default value\n@@ -470,7 +470,7 @@ um_data_t* simulateSound(uint8_t simulationId)\n       for (int i = 0; i<16; i++)\n         fftResult[i] = beatsin8_t(120 / (i+1), 0, 255);\n         // fftResult[i] = (beatsin8_t(120, 0, 255) + (256/16 * i)) % 256;\n-        volumeSmth = fftResult[8];\n+      volumeSmth = fftResult[8];\n       break;\n     case UMS_WeWillRockYou:\n       if (ms%2000 < 200) {\n@@ -507,7 +507,7 @@ um_data_t* simulateSound(uint8_t simulationId)\n     case UMS_10_13:\n       for (int i = 0; i<16; i++)\n         fftResult[i] = inoise8(beatsin8_t(90 / (i+1), 0, 200)*15 + (ms>>10), ms>>3);\n-        volumeSmth = fftResult[8];\n+      volumeSmth = fftResult[8];\n       break;\n     case UMS_14_3:\n       for (int i = 0; i<16; i++)\n@@ -538,7 +538,7 @@ void enumerateLedmaps() {\n \n     #ifndef ESP8266\n     if (ledmapNames[i-1]) { //clear old name\n-      delete[] ledmapNames[i-1];\n+      free(ledmapNames[i-1]);\n       ledmapNames[i-1] = nullptr;\n     }\n     #endif\n@@ -556,7 +556,7 @@ void enumerateLedmaps() {\n             const char *name = root[\"n\"].as<const char*>();\n             if (name != nullptr) len = strlen(name);\n             if (len > 0 && len < 33) {\n-              ledmapNames[i-1] = new char[len+1];\n+              ledmapNames[i-1] = static_cast<char*>(malloc(len+1));\n               if (ledmapNames[i-1]) strlcpy(ledmapNames[i-1], name, 33);\n             }\n           }\n@@ -564,7 +564,7 @@ void enumerateLedmaps() {\n             char tmp[33];\n             snprintf_P(tmp, 32, s_ledmap_tmpl, i);\n             len = strlen(tmp);\n-            ledmapNames[i-1] = new char[len+1];\n+            ledmapNames[i-1] = static_cast<char*>(malloc(len+1));\n             if (ledmapNames[i-1]) strlcpy(ledmapNames[i-1], tmp, 33);\n           }\n         }\ndiff --git a/wled00/wled_serial.cpp b/wled00/wled_serial.cpp\nindex ad9bb1413c..a0e59c531f 100644\n--- a/wled00/wled_serial.cpp\n+++ b/wled00/wled_serial.cpp\n@@ -113,8 +113,8 @@ void handleSerial()\n             //only send response if TX pin is unused for other purposes\n             if (verboseResponse && serialCanTX) {\n               pDoc->clear();\n-              JsonObject state = pDoc->createNestedObject(\"state\");\n-              serializeState(state);\n+              JsonObject stateDoc = pDoc->createNestedObject(\"state\");\n+              serializeState(stateDoc);\n               JsonObject info  = pDoc->createNestedObject(\"info\");\n               serializeInfo(info);\n \ndiff --git a/wled00/wled_server.cpp b/wled00/wled_server.cpp\nindex e8cbb41ae5..8768b2b4e7 100644\n--- a/wled00/wled_server.cpp\n+++ b/wled00/wled_server.cpp\n@@ -21,7 +21,7 @@ static const char s_accessdenied[]   PROGMEM = \"Access Denied\";\n static const char _common_js[]       PROGMEM = \"/common.js\";\n \n //Is this an IP?\n-static bool isIp(String str) {\n+static bool isIp(const String &str) {\n   for (size_t i = 0; i < str.length(); i++) {\n     int c = str.charAt(i);\n     if (c != '.' && (c < '0' || c > '9')) {\n@@ -152,9 +152,9 @@ static String msgProcessor(const String& var)\n   return String();\n }\n \n-static void handleUpload(AsyncWebServerRequest *request, const String& filename, size_t index, uint8_t *data, size_t len, bool final) {\n+static void handleUpload(AsyncWebServerRequest *request, const String& filename, size_t index, uint8_t *data, size_t len, bool isFinal) {\n   if (!correctPIN) {\n-    if (final) request->send(401, FPSTR(CONTENT_TYPE_PLAIN), FPSTR(s_unlock_cfg));\n+    if (isFinal) request->send(401, FPSTR(CONTENT_TYPE_PLAIN), FPSTR(s_unlock_cfg));\n     return;\n   }\n   if (!index) {\n@@ -170,7 +170,7 @@ static void handleUpload(AsyncWebServerRequest *request, const String& filename,\n   if (len) {\n     request->_tempFile.write(data,len);\n   }\n-  if (final) {\n+  if (isFinal) {\n     request->_tempFile.close();\n     if (filename.indexOf(F(\"cfg.json\")) >= 0) { // check for filename with or without slash\n       doReboot = true;\n@@ -359,7 +359,7 @@ void initServer()\n \n   server.on(F(\"/upload\"), HTTP_POST, [](AsyncWebServerRequest *request) {},\n         [](AsyncWebServerRequest *request, const String& filename, size_t index, uint8_t *data,\n-                      size_t len, bool final) {handleUpload(request, filename, index, data, len, final);}\n+                      size_t len, bool isFinal) {handleUpload(request, filename, index, data, len, isFinal);}\n   );\n \n   createEditHandler(correctPIN);\n@@ -389,7 +389,7 @@ void initServer()\n       serveMessage(request, 200, F(\"Update successful!\"), F(\"Rebooting...\"), 131);\n       doReboot = true;\n     }\n-  },[](AsyncWebServerRequest *request, String filename, size_t index, uint8_t *data, size_t len, bool final){\n+  },[](AsyncWebServerRequest *request, String filename, size_t index, uint8_t *data, size_t len, bool isFinal){\n     if (!correctPIN || otaLock) return;\n     if(!index){\n       DEBUG_PRINTLN(F(\"OTA Update Start\"));\n@@ -406,7 +406,7 @@ void initServer()\n       Update.begin((ESP.getFreeSketchSpace() - 0x1000) & 0xFFFFF000);\n     }\n     if(!Update.hasError()) Update.write(data, len);\n-    if(final){\n+    if(isFinal){\n       if(Update.end(true)){\n         DEBUG_PRINTLN(F(\"Update Success\"));\n       } else {\ndiff --git a/wled00/xml.cpp b/wled00/xml.cpp\nindex 2a19cdfabc..097c6d959a 100644\n--- a/wled00/xml.cpp\n+++ b/wled00/xml.cpp\n@@ -26,7 +26,7 @@ void XML_response(Print& dest)\n   );\n }\n \n-static void extractPin(Print& settingsScript, JsonObject &obj, const char *key) {\n+static void extractPin(Print& settingsScript, const JsonObject &obj, const char *key) {\n   if (obj[key].is<JsonArray>()) {\n     JsonArray pins = obj[key].as<JsonArray>();\n     for (JsonVariant pv : pins) {\n@@ -38,7 +38,7 @@ static void extractPin(Print& settingsScript, JsonObject &obj, const char *key)\n }\n \n // print used pins by scanning JsonObject (1 level deep)\n-static void fillUMPins(Print& settingsScript, JsonObject &mods)\n+static void fillUMPins(Print& settingsScript, const JsonObject &mods)\n {\n   for (JsonPair kv : mods) {\n     // kv.key() is usermod name or subobject key\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Change pointer/references in function parameters to `const` for better compiler optimization and to prevent unintended modifications.\n\n2. Fix `extractModeSlider()` handling of `String::indexOf()`, ensuring that \"-1\" correctly indicates \"not found\" instead of converting to `UINT_MAX`.\n\n3. Change `setPixelColorXY()` to `const` to enhance performance.\n\n4. Initialize local variables to avoid potential reads from uninitialized states.\n\n5. Replace occurrences of C++ keywords `final` and `module` to ensure compatibility with future compiler versions.\n\n6. Update conditional check from `if (SEGLEN == 1)` to `if (SEGLEN <= 1)` for increased robustness.\n\n7. Review `new(std::nothrow)` usage; consider replacing with `malloc()` where applicable to avoid exception handling complications.\n\n8. Investigate and address SonarQube warnings related to uninitialized variables and comparisons. Consider changing function parameters from pointers to references for improved safety."
      }
    ],
    "codediff_length": 75816
  },
  {
    "index": 32,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/wled00/FX_fcn.cpp b/wled00/FX_fcn.cpp\nindex b2ec9ab34a..12faaebd6b 100644\n--- a/wled00/FX_fcn.cpp\n+++ b/wled00/FX_fcn.cpp\n@@ -44,8 +44,8 @@\n */\n \n //factory defaults LED setup\n-//#define PIXEL_COUNTS 30, 30, 30, 30\n-//#define DATA_PINS 16, 1, 3, 4\n+//#define PIXEL_COUNTS 30\n+//#define DATA_PINS 2 (8266/C3) or 16 \n //#define DEFAULT_LED_TYPE TYPE_WS2812_RGB\n \n #ifndef PIXEL_COUNTS\n@@ -53,11 +53,11 @@\n #endif\n \n #ifndef DATA_PINS\n-  #define DATA_PINS LEDPIN\n+  #define DATA_PINS DEFAULT_LED_PIN\n #endif\n \n-#ifndef DEFAULT_LED_TYPE\n-  #define DEFAULT_LED_TYPE TYPE_WS2812_RGB\n+#ifndef LED_TYPES\n+  #define LED_TYPES DEFAULT_LED_TYPE\n #endif\n \n #ifndef DEFAULT_LED_COLOR_ORDER\n@@ -69,6 +69,18 @@\n   #error \"Max segments must be at least max number of busses!\"\n #endif\n \n+static constexpr unsigned sumPinsRequired(const unsigned* current, size_t count) {\n+ return (count > 0) ? (Bus::getNumberOfPins(*current) + sumPinsRequired(current+1,count-1)) : 0;\n+}\n+\n+static constexpr bool validatePinsAndTypes(const unsigned* types, unsigned numTypes, unsigned numPins ) {\n+  // Pins provided < pins required -> always invalid\n+  // Pins provided = pins required -> always valid\n+  // Pins provided > pins required -> valid if excess pins are a product of last type pins since it will be repeated\n+  return (sumPinsRequired(types, numTypes) > numPins) ? false :\n+          (numPins - sumPinsRequired(types, numTypes)) % Bus::getNumberOfPins(types[numTypes-1]) == 0;\n+}\n+\n \n ///////////////////////////////////////////////////////////////////////////////\n // Segment class implementation\n@@ -1215,28 +1227,68 @@ void WS2812FX::finalizeInit() {\n   //if busses failed to load, add default (fresh install, FS issue, ...)\n   if (BusManager::getNumBusses() == 0) {\n     DEBUG_PRINTLN(F(\"No busses, init default\"));\n-    const unsigned defDataPins[] = {DATA_PINS};\n-    const unsigned defCounts[] = {PIXEL_COUNTS};\n-    const unsigned defNumPins = ((sizeof defDataPins) / (sizeof defDataPins[0]));\n-    const unsigned defNumCounts = ((sizeof defCounts) / (sizeof defCounts[0]));\n-    // if number of pins is divisible by counts, use number of counts to determine number of buses, otherwise use pins\n-    const unsigned defNumBusses = defNumPins > defNumCounts && defNumPins%defNumCounts == 0 ? defNumCounts : defNumPins;\n-    const unsigned pinsPerBus = defNumPins / defNumBusses;\n+    constexpr unsigned defDataTypes[] = {LED_TYPES};\n+    constexpr unsigned defDataPins[] = {DATA_PINS};\n+    constexpr unsigned defCounts[] = {PIXEL_COUNTS};\n+    constexpr unsigned defNumTypes = ((sizeof defDataTypes) / (sizeof defDataTypes[0]));\n+    constexpr unsigned defNumPins = ((sizeof defDataPins) / (sizeof defDataPins[0]));\n+    constexpr unsigned defNumCounts = ((sizeof defCounts) / (sizeof defCounts[0]));\n+\n+    static_assert(validatePinsAndTypes(defDataTypes, defNumTypes, defNumPins),\n+                  \"The default pin list defined in DATA_PINS does not match the pin requirements for the default buses defined in LED_TYPES\");\n+    \n     unsigned prevLen = 0;\n-    for (unsigned i = 0; i < defNumBusses && i < WLED_MAX_BUSSES+WLED_MIN_VIRTUAL_BUSSES; i++) {\n-      uint8_t defPin[5]; // max 5 pins\n-      for (unsigned j = 0; j < pinsPerBus; j++) defPin[j] = defDataPins[i*pinsPerBus + j];\n-      // when booting without config (1st boot) we need to make sure GPIOs defined for LED output don't clash with hardware\n-      // i.e. DEBUG (GPIO1), DMX (2), SPI RAM/FLASH (16&17 on ESP32-WROVER/PICO), etc\n-      if (pinManager.isPinAllocated(defPin[0])) {\n-        defPin[0] = 1; // start with GPIO1 and work upwards\n-        while (pinManager.isPinAllocated(defPin[0]) && defPin[0] < WLED_NUM_PINS) defPin[0]++;\n+    unsigned pinsIndex = 0;\n+    for (unsigned i = 0; i < WLED_MAX_BUSSES+WLED_MIN_VIRTUAL_BUSSES; i++) {\n+      uint8_t defPin[OUTPUT_MAX_PINS];\n+      // if we have less types than requested outputs and they do not align, use last known type to set current type\n+      unsigned dataType = defDataTypes[(i < defNumTypes) ? i : defNumTypes -1];\n+      unsigned busPins = Bus::getNumberOfPins(dataType);\n+\n+      // if we need more pins than available all outputs have been configured\n+      if (pinsIndex + busPins > defNumPins) break;\n+      \n+      // Assign all pins first so we can check for conflicts on this bus\n+      for (unsigned j = 0; j < busPins && j < OUTPUT_MAX_PINS; j++) defPin[j] = defDataPins[pinsIndex + j];\n+\n+      for (unsigned j = 0; j < busPins && j < OUTPUT_MAX_PINS; j++) {\n+        bool validPin = true;\n+        // When booting without config (1st boot) we need to make sure GPIOs defined for LED output don't clash with hardware\n+        // i.e. DEBUG (GPIO1), DMX (2), SPI RAM/FLASH (16&17 on ESP32-WROVER/PICO), read/only pins, etc.\n+        // Pin should not be already allocated, read/only or defined for current bus\n+        while (pinManager.isPinAllocated(defPin[j]) || !pinManager.isPinOk(defPin[j],true)) {\n+          if (validPin) {\n+            DEBUG_PRINTLN(F(\"Some of the provided pins cannot be used to configure this LED output.\"));\n+            defPin[j] = 1; // start with GPIO1 and work upwards\n+            validPin = false;\n+          } else if (defPin[j] < WLED_NUM_PINS) {\n+            defPin[j]++;\n+          } else {\n+            DEBUG_PRINTLN(F(\"No available pins left! Can't configure output.\"));\n+            return;\n+          }\n+          // is the newly assigned pin already defined? try next in line until there are no clashes\n+          bool clash;\n+          do {\n+            clash = false;\n+            for (const auto &pin : defDataPins) {\n+              if (pin == defPin[j]) {\n+                defPin[j]++;\n+                if (defPin[j] < WLED_NUM_PINS) clash = true;\n+              }\n+            }\n+          } while (clash);\n+        }\n       }\n+      pinsIndex += busPins;\n+\n       unsigned start = prevLen;\n       // if we have less counts than pins and they do not align, use last known count to set current count\n       unsigned count = defCounts[(i < defNumCounts) ? i : defNumCounts -1];\n+      // analog always has length 1\n+      if (Bus::isPWM(dataType)) count = 1;\n       prevLen += count;\n-      BusConfig defCfg = BusConfig(DEFAULT_LED_TYPE, defPin, start, count, DEFAULT_LED_COLOR_ORDER, false, 0, RGBW_MODE_MANUAL_ONLY, 0, useGlobalLedBuffer);\n+      BusConfig defCfg = BusConfig(dataType, defPin, start, count, DEFAULT_LED_COLOR_ORDER, false, 0, RGBW_MODE_MANUAL_ONLY, 0, useGlobalLedBuffer);\n       if (BusManager::add(defCfg) == -1) break;\n     }\n   }\ndiff --git a/wled00/bus_manager.cpp b/wled00/bus_manager.cpp\nindex 7232971787..b20095d4c9 100644\n--- a/wled00/bus_manager.cpp\n+++ b/wled00/bus_manager.cpp\n@@ -787,7 +787,7 @@ void BusNetwork::cleanup() {\n \n //utility to get the approx. memory usage of a given BusConfig\n uint32_t BusManager::memUsage(BusConfig &bc) {\n-  if (Bus::isOnOff(bc.type) || Bus::isPWM(bc.type)) return 5;\n+  if (Bus::isOnOff(bc.type) || Bus::isPWM(bc.type)) return OUTPUT_MAX_PINS;\n \n   unsigned len = bc.count + bc.skipAmount;\n   unsigned channels = Bus::getNumberOfChannels(bc.type);\ndiff --git a/wled00/bus_manager.h b/wled00/bus_manager.h\nindex bf4657d8b7..24f10f0a77 100644\n--- a/wled00/bus_manager.h\n+++ b/wled00/bus_manager.h\n@@ -259,8 +259,8 @@ class BusPwm : public Bus {\n     static std::vector<LEDType> getLEDTypes();\n \n   private:\n-    uint8_t _pins[5];\n-    uint8_t _pwmdata[5];\n+    uint8_t _pins[OUTPUT_MAX_PINS];\n+    uint8_t _pwmdata[OUTPUT_MAX_PINS];\n     #ifdef ARDUINO_ARCH_ESP32\n     uint8_t _ledcStart;\n     #endif\ndiff --git a/wled00/const.h b/wled00/const.h\nindex a73d4a222b..47ec02c6a9 100644\n--- a/wled00/const.h\n+++ b/wled00/const.h\n@@ -466,6 +466,9 @@\n #define NTP_PACKET_SIZE 48       // size of NTP receive buffer\n #define NTP_MIN_PACKET_SIZE 48   // min expected size - NTP v4 allows for \"extended information\" appended to the standard fields\n \n+// Maximum number of pins per output. 5 for RGBCCT analog LEDs.\n+#define OUTPUT_MAX_PINS 5\n+\n //maximum number of rendered LEDs - this does not have to match max. physical LEDs, e.g. if there are virtual busses\n #ifndef MAX_LEDS\n #ifdef ESP8266\n@@ -564,15 +567,6 @@\n   #define WLED_MAX_NODES 150\n #endif\n \n-//this is merely a default now and can be changed at runtime\n-#ifndef LEDPIN\n-#if defined(ESP8266) || defined(CONFIG_IDF_TARGET_ESP32C3)  //|| (defined(ARDUINO_ARCH_ESP32) && defined(BOARD_HAS_PSRAM)) || defined(ARDUINO_ESP32_PICO)\n-  #define LEDPIN 2    // GPIO2 (D4) on Wemos D1 mini compatible boards, safe to use on any board\n-#else\n-  #define LEDPIN 16   // aligns with GPIO2 (D4) on Wemos D1 mini32 compatible boards (if it is unusable it will be reassigned in WS2812FX::finalizeInit())\n-#endif\n-#endif\n-\n #ifdef WLED_ENABLE_DMX\n #if (LEDPIN == 2)\n   #undef LEDPIN\n@@ -581,9 +575,14 @@\n #endif\n #endif\n \n-#ifndef DEFAULT_LED_COUNT\n-  #define DEFAULT_LED_COUNT 30\n+// Defaults pins, type and counts to configure LED output\n+#if defined(ESP8266) || defined(CONFIG_IDF_TARGET_ESP32C3)\n+  #define DEFAULT_LED_PIN 2    // GPIO2 (D4) on Wemos D1 mini compatible boards, safe to use on any board\n+#else\n+  #define DEFAULT_LED_PIN 16   // aligns with GPIO2 (D4) on Wemos D1 mini32 compatible boards (if it is unusable it will be reassigned in WS2812FX::finalizeInit())\n #endif\n+#define DEFAULT_LED_TYPE TYPE_WS2812_RGB\n+#define DEFAULT_LED_COUNT 30\n \n #define INTERFACE_UPDATE_COOLDOWN 1000 // time in ms to wait between websockets, alexa, and MQTT updates\n \ndiff --git a/wled00/data/settings_leds.htm b/wled00/data/settings_leds.htm\nindex b3188f0d8b..206d4a8c75 100644\n--- a/wled00/data/settings_leds.htm\n+++ b/wled00/data/settings_leds.htm\n@@ -671,7 +671,7 @@\n \t\t\t\tif (i.type === \"number\" && fields.includes(i.name)) { //select all pin select elements\n \t\t\t\t\tlet v = parseInt(i.value);\n \t\t\t\t\tlet sel = addDropdown(i.name,0);\n-\t\t\t\t\tfor (var j = -1; j <= d.max_gpio; j++) {\n+\t\t\t\t\tfor (var j = -1; j < d.max_gpio; j++) {\n \t\t\t\t\t\tif (d.rsvd.includes(j)) continue;\n \t\t\t\t\t\tlet foundPin = d.um_p.indexOf(j);\n \t\t\t\t\t\tlet txt = (j === -1) ? \"unused\" : `${j}`;\ndiff --git a/wled00/data/settings_um.htm b/wled00/data/settings_um.htm\nindex 686c881d93..e2fbd5eb74 100644\n--- a/wled00/data/settings_um.htm\n+++ b/wled00/data/settings_um.htm\n@@ -32,8 +32,8 @@\n \t\t\tGetV();\n \t\t\tfor (let r of d.rsvd) { pins.push(r); pinO.push(\"rsvd\"); } // reserved pins\n \t\t\tif (d.um_p[0]==-1) d.um_p.shift();\t// remove filler\n-\t\t\td.Sf.SDA.max = d.Sf.SCL.max = d.Sf.MOSI.max = d.Sf.SCLK.max = d.Sf.MISO.max = d.max_gpio;\n-\t\t\t//for (let i of d.getElementsByTagName(\"input\")) if (i.type === \"number\" && i.name.replace(\"[]\",\"\").substr(-3) === \"pin\") i.max = d.max_gpio;\n+\t\t\td.Sf.SDA.max = d.Sf.SCL.max = d.Sf.MOSI.max = d.Sf.SCLK.max = d.Sf.MISO.max = d.max_gpio-1;\n+\t\t\t//for (let i of d.getElementsByTagName(\"input\")) if (i.type === \"number\" && i.name.replace(\"[]\",\"\").substr(-3) === \"pin\") i.max = d.max_gpio-1;\n \t\t\tpinDD(); // convert INPUT to SELECT for pins\n \t\t});\n \t\t// error event\n@@ -80,7 +80,7 @@\n \t\t\tfor (var i=0; i<pins.length; i++) {\n \t\t\t\tif (k==pinO[i]) continue;\n \t\t\t\tif (o.value==pins[i] && pinO[i]===\"if\") { o.style.color=\"lime\"; break; }\n-\t\t\t\tif (o.value==pins[i] || o.value<-1 || o.value>d.max_gpio) { o.style.color=\"red\"; break; } else o.style.color=d.ro_gpio.some((e)=>e==parseInt(o.value,10))?\"orange\":\"#fff\";\n+\t\t\t\tif (o.value==pins[i] || o.value<-1 || o.value>d.max_gpio-1) { o.style.color=\"red\"; break; } else o.style.color=d.ro_gpio.some((e)=>e==parseInt(o.value,10))?\"orange\":\"#fff\";\n \t\t\t}\n \t\t} else {\n \t\t\tswitch (o.name) {\n@@ -94,7 +94,7 @@\n \t\t\tfor (var i=0; i<pins.length; i++) {\n \t\t\t\t//if (k==pinO[i]) continue; // same owner\n \t\t\t\tif (o.value==pins[i] && pinO[i]===\"if\") { o.style.color=\"tomato\"; break; }\n-\t\t\t\tif (o.value==pins[i] || o.value<-1 || o.value>d.max_gpio) { o.style.color=\"red\"; break; } else o.style.color=d.ro_gpio.some((e)=>e==parseInt(o.value,10))?\"orange\":\"#fff\";\n+\t\t\t\tif (o.value==pins[i] || o.value<-1 || o.value>d.max_gpio-1) { o.style.color=\"red\"; break; } else o.style.color=d.ro_gpio.some((e)=>e==parseInt(o.value,10))?\"orange\":\"#fff\";\n \t\t\t}\n \t\t}\n \t\t*/\n@@ -148,7 +148,7 @@\n \t\t\t\tcase \"number\":\n \t\t\t\t\tc = `value=\"${o}\"`;\n \t\t\t\t\tif (f.substr(-3)===\"pin\") {\n-\t\t\t\t\t\tc += ` max=\"${d.max_gpio}\" min=\"-1\" class=\"s\"`;\n+\t\t\t\t\t\tc += ` max=\"${d.max_gpio-1}\" min=\"-1\" class=\"s\"`;\n \t\t\t\t\t\tt = \"int\";\n \t\t\t\t\t} else {\n \t\t\t\t\t\tc += ' step=\"any\" class=\"xxl\"';\n@@ -170,7 +170,7 @@\n \t\t\tif (i.type === \"number\" && (i.name.includes(\"pin\") || [\"SDA\",\"SCL\",\"MOSI\",\"MISO\",\"SCLK\"].includes(i.name))) { //select all pin select elements\n \t\t\t\tlet v = parseInt(i.value);\n \t\t\t\tlet sel = addDD(i.name,0);\n-\t\t\t\tfor (var j = -1; j <= d.max_gpio; j++) {\n+\t\t\t\tfor (var j = -1; j < d.max_gpio; j++) {\n \t\t\t\t\tif (d.rsvd.includes(j)) continue;\n \t\t\t\t\tlet foundPin = pins.indexOf(j);\n \t\t\t\t\tlet txt = (j === -1) ? \"unused\" : `${j}`;\ndiff --git a/wled00/pin_manager.cpp b/wled00/pin_manager.cpp\nindex 8db61361cc..47cba2ec63 100644\n--- a/wled00/pin_manager.cpp\n+++ b/wled00/pin_manager.cpp\n@@ -267,6 +267,14 @@ bool PinManagerClass::isPinOk(byte gpio, bool output) const\n   return false;\n }\n \n+bool PinManagerClass::isReadOnlyPin(byte gpio)\n+{\n+#ifdef ARDUINO_ARCH_ESP32\n+  if (gpio < WLED_NUM_PINS) return (digitalPinIsValid(gpio) && !digitalPinCanOutput(gpio));\n+#endif\n+  return false;\n+}\n+\n PinOwner PinManagerClass::getPinOwner(byte gpio) const\n {\n   if (!isPinOk(gpio, false)) return PinOwner::None;\ndiff --git a/wled00/pin_manager.h b/wled00/pin_manager.h\nindex 986964a7f5..a8ddf5f751 100644\n--- a/wled00/pin_manager.h\n+++ b/wled00/pin_manager.h\n@@ -111,6 +111,8 @@ class PinManagerClass {\n   bool isPinAllocated(byte gpio, PinOwner tag = PinOwner::None) const;\n   // will return false for reserved pins\n   bool isPinOk(byte gpio, bool output = true) const;\n+  \n+  static bool isReadOnlyPin(byte gpio);\n \n   PinOwner getPinOwner(byte gpio) const;\n \ndiff --git a/wled00/xml.cpp b/wled00/xml.cpp\nindex b45da3ad44..079c0a91bd 100644\n--- a/wled00/xml.cpp\n+++ b/wled00/xml.cpp\n@@ -121,6 +121,7 @@ void fillUMPins(JsonObject &mods)\n void appendGPIOinfo() {\n   char nS[8];\n \n+  // add usermod pins as d.um_p array\n   oappend(SET_F(\"d.um_p=[-1\")); // has to have 1 element\n   if (i2c_sda > -1 && i2c_scl > -1) {\n     oappend(\",\"); oappend(itoa(i2c_sda,nS,10));\n@@ -140,83 +141,58 @@ void appendGPIOinfo() {\n   }\n   oappend(SET_F(\"];\"));\n \n-  // add reserved and usermod pins as d.um_p array\n-  #if defined(CONFIG_IDF_TARGET_ESP32S2)\n-  oappend(SET_F(\"d.rsvd=[22,23,24,25,26,27,28,29,30,31,32\"));\n-  #elif defined(CONFIG_IDF_TARGET_ESP32S3)\n-  oappend(SET_F(\"d.rsvd=[19,20,22,23,24,25,26,27,28,29,30,31,32\"));  // includes 19+20 for USB OTG (JTAG)\n-  if (psramFound()) oappend(SET_F(\",33,34,35,36,37\")); // in use for \"octal\" PSRAM or \"octal\" FLASH -seems that octal PSRAM is very common on S3.\n-  #elif defined(CONFIG_IDF_TARGET_ESP32C3)\n-  oappend(SET_F(\"d.rsvd=[11,12,13,14,15,16,17\"));\n-  #elif defined(ESP32)\n-  oappend(SET_F(\"d.rsvd=[6,7,8,9,10,11,24,28,29,30,31,37,38\"));\n-  if (!pinManager.isPinOk(16,false)) oappend(SET_F(\",16\")); // covers PICO & WROVER\n-  if (!pinManager.isPinOk(17,false)) oappend(SET_F(\",17\")); // covers PICO & WROVER\n-  #else\n-  oappend(SET_F(\"d.rsvd=[6,7,8,9,10,11\"));\n-  #endif\n-\n+  // add reserved (unusable) pins\n+  oappend(SET_F(\"d.rsvd=[\"));\n+  for (unsigned i = 0; i < WLED_NUM_PINS; i++) {\n+    if (!pinManager.isPinOk(i, false)) {  // include readonly pins\n+      oappendi(i); oappend(\",\");\n+    }\n+  }\n   #ifdef WLED_ENABLE_DMX\n-  oappend(SET_F(\",2\")); // DMX hardcoded pin\n+  oappend(SET_F(\"2,\")); // DMX hardcoded pin\n   #endif\n-\n   #if defined(WLED_DEBUG) && !defined(WLED_DEBUG_HOST)\n-  oappend(SET_F(\",\")); oappend(itoa(hardwareTX,nS,10)); // debug output (TX) pin\n+  oappend(itoa(hardwareTX,nS,10)); oappend(\",\"); // debug output (TX) pin\n   #endif\n-\n   //Note: Using pin 3 (RX) disables Adalight / Serial JSON\n-\n   #ifdef WLED_USE_ETHERNET\n   if (ethernetType != WLED_ETH_NONE && ethernetType < WLED_NUM_ETH_TYPES) {\n-    for (unsigned p=0; p<WLED_ETH_RSVD_PINS_COUNT; p++) { oappend(\",\"); oappend(itoa(esp32_nonconfigurable_ethernet_pins[p].pin,nS,10)); }\n-    if (ethernetBoards[ethernetType].eth_power>=0)     { oappend(\",\"); oappend(itoa(ethernetBoards[ethernetType].eth_power,nS,10)); }\n-    if (ethernetBoards[ethernetType].eth_mdc>=0)       { oappend(\",\"); oappend(itoa(ethernetBoards[ethernetType].eth_mdc,nS,10)); }\n-    if (ethernetBoards[ethernetType].eth_mdio>=0)      { oappend(\",\"); oappend(itoa(ethernetBoards[ethernetType].eth_mdio,nS,10)); }\n-    switch (ethernetBoards[ethernetType].eth_clk_mode) {\n+    for (unsigned p=0; p<WLED_ETH_RSVD_PINS_COUNT; p++) { oappend(itoa(esp32_nonconfigurable_ethernet_pins[p].pin,nS,10)); oappend(\",\"); }\n+    if (ethernetBoards[ethernetType].eth_power>=0)      { oappend(itoa(ethernetBoards[ethernetType].eth_power,nS,10)); oappend(\",\"); }\n+    if (ethernetBoards[ethernetType].eth_mdc>=0)        { oappend(itoa(ethernetBoards[ethernetType].eth_mdc,nS,10)); oappend(\",\"); }\n+    if (ethernetBoards[ethernetType].eth_mdio>=0)       { oappend(itoa(ethernetBoards[ethernetType].eth_mdio,nS,10)); oappend(\",\"); }\n+    switch (ethernetBoards[ethernetType].eth_clk_mode)  {\n       case ETH_CLOCK_GPIO0_IN:\n       case ETH_CLOCK_GPIO0_OUT:\n-        oappend(SET_F(\",0\"));\n+        oappend(SET_F(\"0\"));\n         break;\n       case ETH_CLOCK_GPIO16_OUT:\n-        oappend(SET_F(\",16\"));\n+        oappend(SET_F(\"16\"));\n         break;\n       case ETH_CLOCK_GPIO17_OUT:\n-        oappend(SET_F(\",17\"));\n+        oappend(SET_F(\"17\"));\n         break;\n     }\n   }\n   #endif\n-\n-  oappend(SET_F(\"];\"));\n+  oappend(SET_F(\"];\")); // rsvd\n \n   // add info for read-only GPIO\n   oappend(SET_F(\"d.ro_gpio=[\"));\n-  #if defined(CONFIG_IDF_TARGET_ESP32S2)\n-  oappendi(46);\n-  #elif defined(CONFIG_IDF_TARGET_ESP32S3)\n-  // none for S3\n-  #elif defined(CONFIG_IDF_TARGET_ESP32C3)\n-  // none for C3\n-  #elif defined(ESP32)\n-  oappend(SET_F(\"34,35,36,37,38,39\"));\n-  #else\n-  // none for ESP8266\n-  #endif\n+  bool firstPin = true;\n+  for (unsigned i = 0; i < WLED_NUM_PINS; i++) {\n+    if (pinManager.isReadOnlyPin(i)) {\n+      // No comma before the first pin\n+      if (!firstPin) oappend(SET_F(\",\"));\n+      oappendi(i);\n+      firstPin = false;\n+    }\n+  }\n   oappend(SET_F(\"];\"));\n \n   // add info about max. # of pins\n   oappend(SET_F(\"d.max_gpio=\"));\n-  #if defined(CONFIG_IDF_TARGET_ESP32S2)\n-  oappendi(46);\n-  #elif defined(CONFIG_IDF_TARGET_ESP32S3)\n-  oappendi(48);\n-  #elif defined(CONFIG_IDF_TARGET_ESP32C3)\n-  oappendi(21);\n-  #elif defined(ESP32)\n-  oappendi(39);\n-  #else\n-  oappendi(16);\n-  #endif\n+  oappendi(WLED_NUM_PINS);\n   oappend(SET_F(\";\"));\n }\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Bug**: Fixed the configuration issue causing PWM output with length > 1. Implement a check: `if (IS_PWM(dataType)) count = 1;`.\n\n2. **Error Handling**: Implement static assertions using `static_assert()` for mismatches in LED types and pin counts. Use `Bus::getRequiredPins()` to determine pin requirements.\n\n3. **Logic Improvements**: Ensure only one WS2812 bus is created or an error raised for incorrect configurations. Prioritize compile-time errors over runtime checks for invalid pin usage on controllers.\n\n4. **Code Efficiency**: Replace `sizeof(pins) / sizeof(pins[0])` with `std::size(pins)` if using STL or C++17 for clarity. Use range-based for-loops with `const auto&` for efficiency in iterating over collections.\n\n5. **Further Enhancements**: Consider implementing color order logic if multiple LED types are configured, but only if applicable. "
      }
    ],
    "codediff_length": 18616
  },
  {
    "index": 33,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/wled00/bus_manager.cpp b/wled00/bus_manager.cpp\nindex 7aa3351cf3..fcefe929bc 100644\n--- a/wled00/bus_manager.cpp\n+++ b/wled00/bus_manager.cpp\n@@ -377,6 +377,30 @@ void BusDigital::cleanup() {\n   pinManager.deallocatePin(_pins[0], PinOwner::BusDigital);\n }\n \n+std::vector<LEDType> BusDigital::getLEDTypes() {\n+  return {\n+    {TYPE_WS2812_RGB, \"D\", PSTR(\"WS281x\")},\n+    {TYPE_SK6812_RGBW, \"D\", PSTR(\"SK6812/WS2814 RGBW\")},\n+    {TYPE_TM1814, \"D\", PSTR(\"TM1814\")},\n+    {TYPE_WS2811_400KHZ, \"D\", PSTR(\"400kHz\")},\n+    {TYPE_TM1829, \"D\", PSTR(\"TM1829\")},\n+    {TYPE_UCS8903, \"D\", PSTR(\"UCS8903\")},\n+    {TYPE_APA106, \"D\", PSTR(\"APA106/PL9823\")},\n+    {TYPE_TM1914, \"D\", PSTR(\"TM1914\")},\n+    {TYPE_FW1906, \"D\", PSTR(\"FW1906 GRBCW\")},\n+    {TYPE_UCS8904, \"D\", PSTR(\"UCS8904 RGBW\")},\n+    {TYPE_WS2805, \"D\", PSTR(\"WS2805 RGBCW\")},\n+    {TYPE_WS2812_1CH_X3, \"D\", PSTR(\"WS2811 White\")},\n+      //{TYPE_WS2812_2CH_X3, \"D\", PSTR(\"WS2811 CCT\")},\n+      //{TYPE_WS2812_WWA, \"D\", PSTR(\"WS2811 WWA\")},\n+    {TYPE_WS2801, \"2P\", PSTR(\"WS2801\")},\n+    {TYPE_APA102, \"2P\", PSTR(\"APA102\")},\n+    {TYPE_LPD8806, \"2P\", PSTR(\"LPD8806\")},\n+    {TYPE_LPD6803, \"2P\", PSTR(\"LPD6803\")},\n+    {TYPE_P9813, \"2P\", PSTR(\"PP9813\")}\n+  };\n+}\n+\n \n BusPwm::BusPwm(BusConfig &bc)\n : Bus(bc.type, bc.start, bc.autoWhite, 1, bc.reversed)\n@@ -555,6 +579,17 @@ void BusPwm::deallocatePins() {\n   #endif\n }\n \n+std::vector<LEDType> BusPwm::getLEDTypes() {\n+  return {\n+    {TYPE_ANALOG_1CH, \"A\", PSTR(\"PWM White\")},\n+    {TYPE_ANALOG_2CH, \"AA\", PSTR(\"PWM CCT\")},\n+    {TYPE_ANALOG_3CH, \"AAA\", PSTR(\"PWM RGB\")},\n+    {TYPE_ANALOG_4CH, \"AAAA\", PSTR(\"PWM RGBW\")},\n+    {TYPE_ANALOG_5CH, \"AAAAA\", PSTR(\"PWM RGB+CCT\")},\n+      //{TYPE_ANALOG_6CH, \"AAAAAA\", PSTR(\"PWM RGB+DCCT\")},\n+  };\n+}\n+\n \n BusOnOff::BusOnOff(BusConfig &bc)\n : Bus(bc.type, bc.start, bc.autoWhite, 1, bc.reversed)\n@@ -599,6 +634,12 @@ uint8_t BusOnOff::getPins(uint8_t* pinArray) {\n   return 1;\n }\n \n+std::vector<LEDType> BusOnOff::getLEDTypes() {\n+  return {\n+    {TYPE_ONOFF, \"\", PSTR(\"On/Off\")}\n+  };\n+}\n+\n \n BusNetwork::BusNetwork(BusConfig &bc)\n : Bus(bc.type, bc.start, bc.autoWhite, bc.count)\n@@ -659,6 +700,15 @@ uint8_t BusNetwork::getPins(uint8_t* pinArray) {\n   return 4;\n }\n \n+std::vector<LEDType> BusNetwork::getLEDTypes() {\n+  return {\n+    {TYPE_NET_DDP_RGB, \"V\", PSTR(\"DDP RGB (network)\")},\n+    {TYPE_NET_ARTNET_RGB, \"V\", PSTR(\"Art-Net RGB (network)\")},\n+    {TYPE_NET_DDP_RGBW, \"V\", PSTR(\"DDP RGBW (network)\")},\n+    {TYPE_NET_ARTNET_RGBW, \"V\", PSTR(\"Art-Net RGBW (network)\")}\n+  };\n+}\n+\n void BusNetwork::cleanup() {\n   _type = I_NONE;\n   _valid = false;\n@@ -706,6 +756,29 @@ int BusManager::add(BusConfig &bc) {\n   return numBusses++;\n }\n \n+static String LEDTypesToJson(const std::vector<LEDType>& types) {\n+  String json;\n+  for(auto& type: types) {\n+    String id = String(type.id);\n+    json += \"{i:\" + id + F(\",t:\\\"\") + FPSTR(type.type) + F(\"\\\",n:\\\"\") + FPSTR(type.name) + F(\"\\\"},\");\n+  }\n+  return json;\n+}\n+\n+String BusManager::getLEDTypes() {\n+  std::vector<LEDType> types;\n+  String json = \"[\";\n+\n+  json += LEDTypesToJson(BusDigital::getLEDTypes());\n+  json += LEDTypesToJson(BusOnOff::getLEDTypes());\n+  json += LEDTypesToJson(BusPwm::getLEDTypes());\n+  json += LEDTypesToJson(BusNetwork::getLEDTypes());\n+\n+  json += \"]\";\n+  return json;\n+}\n+\n+\n void BusManager::useParallelOutput(void) {\n   _parallelOutputs = 8; // hardcoded since we use NPB I2S x8 methods\n   PolyBus::setParallelI2S1Output();\n@@ -859,6 +932,7 @@ uint16_t BusManager::getTotalLength() {\n   return len;\n }\n \n+\n bool PolyBus::useParallelI2S = false;\n \n // Bus static member definition\ndiff --git a/wled00/bus_manager.h b/wled00/bus_manager.h\nindex e1bacd5556..7504af18e3 100644\n--- a/wled00/bus_manager.h\n+++ b/wled00/bus_manager.h\n@@ -6,6 +6,7 @@\n  */\n \n #include \"const.h\"\n+#include <vector>\n \n //colors.cpp\n uint16_t approximateKelvinFromRGB(uint32_t rgb);\n@@ -103,6 +104,11 @@ struct ColorOrderMap {\n     ColorOrderMapEntry _mappings[WLED_MAX_COLOR_ORDER_MAPPINGS];\n };\n \n+typedef struct {\n+  uint8_t id;\n+  const char *type;\n+  const char *name;\n+} LEDType;\n \n //parent class of BusDigital, BusPwm, and BusNetwork\n class Bus {\n@@ -258,6 +264,7 @@ class BusDigital : public Bus {\n     uint16_t getMaxCurrent() override  { return _milliAmpsMax; }\n     void reinit();\n     void cleanup();\n+    static std::vector<LEDType> getLEDTypes();\n \n   private:\n     uint8_t _skip;\n@@ -296,6 +303,7 @@ class BusPwm : public Bus {\n     uint16_t getFrequency() override { return _frequency; }\n     void show() override;\n     void cleanup() { deallocatePins(); }\n+    static std::vector<LEDType> getLEDTypes();\n \n   private:\n     uint8_t _pins[5];\n@@ -320,6 +328,7 @@ class BusOnOff : public Bus {\n     uint8_t  getPins(uint8_t* pinArray) override;\n     void show() override;\n     void cleanup() { pinManager.deallocatePin(_pin, PinOwner::BusOnOff); }\n+    static std::vector<LEDType> getLEDTypes();\n \n   private:\n     uint8_t _pin;\n@@ -340,6 +349,7 @@ class BusNetwork : public Bus {\n     uint8_t  getPins(uint8_t* pinArray) override;\n     void show() override;\n     void cleanup();\n+    static std::vector<LEDType> getLEDTypes();\n \n   private:\n     IPAddress _client;\n@@ -386,6 +396,7 @@ class BusManager {\n     //semi-duplicate of strip.getLengthTotal() (though that just returns strip._length, calculated in finalizeInit())\n     static uint16_t getTotalLength();\n     static uint8_t getNumBusses() { return numBusses; }\n+    static String getLEDTypes();\n \n     static void                 updateColorOrderMap(const ColorOrderMap &com) { memcpy(&colorOrderMap, &com, sizeof(ColorOrderMap)); }\n     static const ColorOrderMap& getColorOrderMap() { return colorOrderMap; }\ndiff --git a/wled00/data/settings_leds.htm b/wled00/data/settings_leds.htm\nindex 2ce5be148f..266e3e8438 100644\n--- a/wled00/data/settings_leds.htm\n+++ b/wled00/data/settings_leds.htm\n@@ -408,35 +408,7 @@\n <hr class=\"sml\">\n ${i+1}:\n <select name=\"LT${s}\" onchange=\"UI(true)\">${i>=maxB && false ? '' :\n-'<option value=\"22\" data-type=\"D\">WS281x</option>\\\n-<option value=\"30\" data-type=\"D\">SK6812/WS2814 RGBW</option>\\\n-<option value=\"31\" data-type=\"D\">TM1814</option>\\\n-<option value=\"24\" data-type=\"D\">400kHz</option>\\\n-<option value=\"25\" data-type=\"D\">TM1829</option>\\\n-<option value=\"26\" data-type=\"D\">UCS8903</option>\\\n-<option value=\"27\" data-type=\"D\">APA106/PL9823</option>\\\n-<option value=\"33\" data-type=\"D\">TM1914</option>\\\n-<option value=\"28\" data-type=\"D\">FW1906 GRBCW</option>\\\n-<option value=\"29\" data-type=\"D\">UCS8904 RGBW</option>\\\n-<option value=\"32\" data-type=\"D\">WS2805 RGBCW</option>\\\n-<option value=\"50\" data-type=\"2P\">WS2801</option>\\\n-<option value=\"51\" data-type=\"2P\">APA102</option>\\\n-<option value=\"52\" data-type=\"2P\">LPD8806</option>\\\n-<option value=\"54\" data-type=\"2P\">LPD6803</option>\\\n-<option value=\"53\" data-type=\"2P\">P9813</option>\\\n-<option value=\"19\" data-type=\"D\">WS2811 White</option>\\\n-<option value=\"40\">On/Off</option>\\\n-<option value=\"41\" data-type=\"A\">PWM White</option>\\\n-<option value=\"42\" data-type=\"AA\">PWM CCT</option>\\\n-<option value=\"43\" data-type=\"AAA\">PWM RGB</option>\\\n-<option value=\"44\" data-type=\"AAAA\">PWM RGBW</option>\\\n-<option value=\"45\" data-type=\"AAAAA\">PWM RGB+CCT</option>\\\n-<!--option value=\"46\" data-type=\"AAAAAA\">PWM RGB+DCCT</option-->'}\n-<option value=\"80\" data-type=\"V\">DDP RGB (network)</option>\n-<!--option value=\"81\" data-type=\"V\">E1.31 RGB (network)</option-->\n-<option value=\"82\" data-type=\"V\">Art-Net RGB (network)</option>\n-<option value=\"88\" data-type=\"V\">DDP RGBW (network)</option>\n-<option value=\"89\" data-type=\"V\">Art-Net RGBW (network)</option>\n+''}\n </select><br>\n <div id=\"abl${s}\">\n mA/LED: <select name=\"LAsel${s}\" onchange=\"enLA(this,'${s}');UI();\">\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "- Replace `std::vector` with `std::array` for compile-time initialization, avoiding unnecessary overhead from dynamic memory management.\n- Ensure all static data initialization uses appropriate types to avoid unnecessary copies and reallocations.\n- Consider using `std::stringstream` or `std::format` for JSON string construction to prevent heap fragmentation associated with Arduino String.\n- Use range-based loops (e.g., `for (const auto& bus : busses)`) to improve readability and allow better optimization by compilers.\n- If using arrays, prefer `const LEDType types[]` for initialization over `std::array` unless STL features are required.\n- Review the compiler's narrowing conversion warnings and utilize `unsigned` or appropriate fixed-width types only when necessary.\n- Incorporate changes and extract improvements into a separate PR targeting the `0_15` branch based on identified issues and proposals."
      }
    ],
    "codediff_length": 7730
  },
  {
    "index": 34,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/wled00/FX.h b/wled00/FX.h\nindex 6e458fceaf..38d4749a1b 100644\n--- a/wled00/FX.h\n+++ b/wled00/FX.h\n@@ -324,7 +324,8 @@ typedef enum mapping1D2D {\n   M12_Pixels = 0,\n   M12_pBar = 1,\n   M12_pArc = 2,\n-  M12_pCorner = 3\n+  M12_pCorner = 3,\n+  M12_sPinwheel = 4\n } mapping1D2D_t;\n \n // segment, 80 bytes\ndiff --git a/wled00/FX_fcn.cpp b/wled00/FX_fcn.cpp\nindex ce510f16e6..ef710b0b89 100644\n--- a/wled00/FX_fcn.cpp\n+++ b/wled00/FX_fcn.cpp\n@@ -637,6 +637,42 @@ uint16_t IRAM_ATTR Segment::nrOfVStrips() const {\n   return vLen;\n }\n \n+// Constants for mapping mode \"Pinwheel\"\n+#ifndef WLED_DISABLE_2D\n+constexpr int Pinwheel_Steps_Small = 72;       // no holes up to 16x16\n+constexpr int Pinwheel_Size_Small  = 16;       // larger than this -> use \"Medium\"\n+constexpr int Pinwheel_Steps_Medium = 192;     // no holes up to 32x32\n+constexpr int Pinwheel_Size_Medium  = 32;      // larger than this -> use \"Big\"\n+constexpr int Pinwheel_Steps_Big = 304;        // no holes up to 50x50\n+constexpr int Pinwheel_Size_Big  = 50;         // larger than this -> use \"XL\"\n+constexpr int Pinwheel_Steps_XL  = 368;\n+constexpr float Int_to_Rad_Small = (DEG_TO_RAD * 360) / Pinwheel_Steps_Small;  // conversion: from 0...72 to Radians\n+constexpr float Int_to_Rad_Med =   (DEG_TO_RAD * 360) / Pinwheel_Steps_Medium; // conversion: from 0...192 to Radians\n+constexpr float Int_to_Rad_Big =   (DEG_TO_RAD * 360) / Pinwheel_Steps_Big;    // conversion: from 0...304 to Radians\n+constexpr float Int_to_Rad_XL =    (DEG_TO_RAD * 360) / Pinwheel_Steps_XL;     // conversion: from 0...368 to Radians\n+\n+constexpr int Fixed_Scale = 512;               // fixpoint scaling factor (9bit for fraction)\n+\n+// Pinwheel helper function: pixel index to radians\n+static float getPinwheelAngle(int i, int vW, int vH) {\n+  int maxXY = max(vW, vH);\n+  if (maxXY <= Pinwheel_Size_Small)  return float(i) * Int_to_Rad_Small;\n+  if (maxXY <= Pinwheel_Size_Medium) return float(i) * Int_to_Rad_Med;\n+  if (maxXY <= Pinwheel_Size_Big)    return float(i) * Int_to_Rad_Big;\n+  // else\n+  return float(i) * Int_to_Rad_XL;\n+}\n+// Pinwheel helper function: matrix dimensions to number of rays\n+static int getPinwheelLength(int vW, int vH) {\n+  int maxXY = max(vW, vH);\n+  if (maxXY <= Pinwheel_Size_Small)  return Pinwheel_Steps_Small;\n+  if (maxXY <= Pinwheel_Size_Medium) return Pinwheel_Steps_Medium;\n+  if (maxXY <= Pinwheel_Size_Big)    return Pinwheel_Steps_Big;\n+  // else\n+  return Pinwheel_Steps_XL;\n+}\n+#endif\n+\n // 1D strip\n uint16_t IRAM_ATTR Segment::virtualLength() const {\n #ifndef WLED_DISABLE_2D\n@@ -652,6 +688,9 @@ uint16_t IRAM_ATTR Segment::virtualLength() const {\n       case M12_pArc:\n         vLen = max(vW,vH); // get the longest dimension\n         break;\n+      case M12_sPinwheel:\n+        vLen = getPinwheelLength(vW, vH);\n+        break;\n     }\n     return vLen;\n   }\n@@ -718,6 +757,52 @@ void IRAM_ATTR Segment::setPixelColor(int i, uint32_t col)\n         for (int x = 0; x <= i; x++) setPixelColorXY(x, i, col);\n         for (int y = 0; y <  i; y++) setPixelColorXY(i, y, col);\n         break;\n+      case M12_sPinwheel: {\n+        // i = angle --> 0 - 296  (Big), 0 - 192  (Medium), 0 - 72 (Small)\n+        float centerX = roundf((vW-1) / 2.0f);\n+        float centerY = roundf((vH-1) / 2.0f);\n+        float angleRad = getPinwheelAngle(i, vW, vH); // angle in radians\n+        float cosVal = cos_t(angleRad);\n+        float sinVal = sin_t(angleRad);\n+\n+        // avoid re-painting the same pixel\n+        int lastX = INT_MIN; // impossible position\n+        int lastY = INT_MIN; // impossible position\n+        // draw line at angle, starting at center and ending at the segment edge\n+        // we use fixed point math for better speed. Starting distance is 0.5 for better rounding\n+        // int_fast16_t and int_fast32_t types changed to int, minimum bits commented\n+        int posx = (centerX + 0.5f * cosVal) * Fixed_Scale; // X starting position in fixed point 18 bit\n+        int posy = (centerY + 0.5f * sinVal) * Fixed_Scale; // Y starting position in fixed point 18 bit\n+        int inc_x = cosVal * Fixed_Scale; // X increment per step (fixed point) 10 bit\n+        int inc_y = sinVal * Fixed_Scale; // Y increment per step (fixed point) 10 bit\n+\n+        int32_t maxX = vW * Fixed_Scale; // X edge in fixedpoint\n+        int32_t maxY = vH * Fixed_Scale; // Y edge in fixedpoint\n+\n+        // Odd rays start further from center if prevRay started at center.\n+        static int prevRay = INT_MIN; // previous ray number\n+        if ((i % 2 == 1) && (i - 1 == prevRay || i + 1 == prevRay)) {\n+          int jump = min(vW/3, vH/3); // can add 2 if using medium pinwheel \n+          posx += inc_x * jump;\n+          posy += inc_y * jump;\n+        }\n+        prevRay = i;\n+\n+        // draw ray until we hit any edge\n+        while ((posx >= 0) && (posy >= 0) && (posx < maxX)  && (posy < maxY))  {\n+          // scale down to integer (compiler will replace division with appropriate bitshift)\n+          int x = posx / Fixed_Scale;\n+          int y = posy / Fixed_Scale;\n+          // set pixel\n+          if (x != lastX || y != lastY) setPixelColorXY(x, y, col);  // only paint if pixel position is different\n+          lastX = x;\n+          lastY = y;\n+          // advance to next position\n+          posx += inc_x;\n+          posy += inc_y;\n+        }\n+        break;\n+      }\n     }\n     return;\n   } else if (Segment::maxHeight!=1 && (width()==1 || height()==1)) {\n@@ -833,7 +918,36 @@ uint32_t IRAM_ATTR Segment::getPixelColor(int i)\n         // use longest dimension\n         return vW>vH ? getPixelColorXY(i, 0) : getPixelColorXY(0, i);\n         break;\n-    }\n+      case M12_sPinwheel:\n+        // not 100% accurate, returns pixel at outer edge\n+        // i = angle --> 0 - 296  (Big), 0 - 192  (Medium), 0 - 72 (Small)\n+        float centerX = roundf((vW-1) / 2.0f);\n+        float centerY = roundf((vH-1) / 2.0f);\n+        float angleRad = getPinwheelAngle(i, vW, vH); // angle in radians\n+        float cosVal = cos_t(angleRad);\n+        float sinVal = sin_t(angleRad);\n+\n+        int posx = (centerX + 0.5f * cosVal) * Fixed_Scale; // X starting position in fixed point 18 bit\n+        int posy = (centerY + 0.5f * sinVal) * Fixed_Scale; // Y starting position in fixed point 18 bit\n+        int inc_x = cosVal * Fixed_Scale; // X increment per step (fixed point) 10 bit\n+        int inc_y = sinVal * Fixed_Scale; // Y increment per step (fixed point) 10 bit\n+        int32_t maxX = vW * Fixed_Scale; // X edge in fixedpoint\n+        int32_t maxY = vH * Fixed_Scale; // Y edge in fixedpoint\n+\n+        // trace ray from center until we hit any edge - to avoid rounding problems, we use the same method as in setPixelColor\n+        int x = INT_MIN;\n+        int y = INT_MIN;\n+        while ((posx >= 0) && (posy >= 0) && (posx < maxX)  && (posy < maxY))  {\n+          // scale down to integer (compiler will replace division with appropriate bitshift)\n+          x = posx / Fixed_Scale;\n+          y = posy / Fixed_Scale;\n+          // advance to next position\n+          posx += inc_x;\n+          posy += inc_y;\n+        }\n+        return getPixelColorXY(x, y);\n+        break;\n+      }\n     return 0;\n   }\n #endif\ndiff --git a/wled00/data/index.js b/wled00/data/index.js\nindex d33fb63f70..26d78b2848 100644\n--- a/wled00/data/index.js\n+++ b/wled00/data/index.js\n@@ -801,6 +801,7 @@ function populateSegments(s)\n \t\t\t\t\t\t\t`<option value=\"1\" ${inst.m12==1?' selected':''}>Bar</option>`+\n \t\t\t\t\t\t\t`<option value=\"2\" ${inst.m12==2?' selected':''}>Arc</option>`+\n \t\t\t\t\t\t\t`<option value=\"3\" ${inst.m12==3?' selected':''}>Corner</option>`+\n+\t\t\t\t\t\t\t`<option value=\"4\" ${inst.m12==4?' selected':''}>Pinwheel</option>`+\n \t\t\t\t\t\t`</select></div>`+\n \t\t\t\t\t`</div>`;\n \t\tlet sndSim = `<div data-snd=\"si\" class=\"lbl-s hide\">Sound sim<br>`+\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Replace `sinf/cosf` with `sin_t/cos_t` in all occurrences, particularly in `getpixelcolor()`, but note accuracy/performance trade-offs and ensure impacts are evaluated.\n\n2. Change `int_fast32_t` and `int_fast16_t` in `setPixelColor()` to `int`, add a comment indicating the minimum required bit resolution (18 bits) for accuracy.\n\n3. For the 32x32 case, modify `Pinwheel_Size_Medium` to 30 to reduce rendering issues. Investigate rounding adjustments for high pixel counts to minimize rendering holes.\n\n4. Optimize `setPixelColor()` calls: limit calls to when the x or y values change vs. previous iterations, and consider using temporary arrays for tracking painted pixels to reduce duplicate calls.\n\n5. Test and evaluate code changes on various matrix sizes to enhance performance and functionality."
      }
    ],
    "codediff_length": 7839
  },
  {
    "index": 35,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/platformio.ini b/platformio.ini\nindex f32475e755..c1011be4af 100644\n--- a/platformio.ini\n+++ b/platformio.ini\n@@ -8,12 +8,15 @@\n # Please uncomment one of the lines below to select your board(s)\n # ------------------------------------------------------------------------------\n \n-# Travis CI binaries (comment this out with a ';' when building for your own board)\n-;default_envs = travis_esp8266, travis_esp32\n+# Travis CI binaries (use `platformio_override.ini` when building for your own board; see `platformio_override.ini.sample` for an example)\n+; default_envs = travis_esp8266, travis_esp32\n \n # Release binaries\n default_envs = nodemcuv2, esp01_1m_full, esp32dev, esp32_eth\n \n+# Build everything\n+; default_envs = esp32dev, esp8285_4CH_MagicHome, esp8285_4CH_H801, codm-controller-0.6-rev2, codm-controller-0.6, esp32s2_saola, d1_mini_5CH_Shojo_PCB, d1_mini, sp501e, travis_esp8266, travis_esp32, nodemcuv2, esp32_eth, anavi_miracle_controller, esp07, esp01_1m_full, m5atom, h803wf, d1_mini_ota, heltec_wifi_kit_8, esp8285_5CH_H801, d1_mini_debug, wemos_shield_esp32, elekstube_ips\n+\n # Single binaries (uncomment your board)\n ; default_envs = elekstube_ips\n ; default_envs = nodemcuv2\n@@ -399,7 +402,7 @@ build_flags = ${common.build_flags_esp32}\n   -D TEMPERATURE_PIN=23\n lib_deps = ${esp32.lib_deps}\n   OneWire@~2.3.5\n-  U8g2@~2.28.11\n+  olikraus/U8g2 @ ^2.28.8\n \n [env:m5atom]\n board = esp32dev\n@@ -482,4 +485,6 @@ build_flags = ${common.build_flags_esp32} -D WLED_DISABLE_BROWNOUT_DET -D WLED_D\n   -D SPI_FREQUENCY=40000000\n   -D USER_SETUP_LOADED\n monitor_filters = esp32_exception_decoder\n-lib_deps = ${esp32.lib_deps} TFT_eSPI\n+lib_deps =\n+  ${esp32.lib_deps}\n+  TFT_eSPI @ ^2.3.70\ndiff --git a/usermods/Animated_Staircase/Animated_Staircase.h b/usermods/Animated_Staircase/Animated_Staircase.h\nindex 9bd2a8a39d..707b60da1c 100644\n--- a/usermods/Animated_Staircase/Animated_Staircase.h\n+++ b/usermods/Animated_Staircase/Animated_Staircase.h\n@@ -306,22 +306,26 @@ class Animated_Staircase : public Usermod {\n \n   public:\n     void setup() {\n+      // standardize invalid pin numbers to -1\n+      if (topPIRorTriggerPin    < 0) topPIRorTriggerPin    = -1;\n+      if (topEchoPin            < 0) topEchoPin            = -1;\n+      if (bottomPIRorTriggerPin < 0) bottomPIRorTriggerPin = -1;\n+      if (bottomEchoPin         < 0) bottomEchoPin         = -1;\n       // allocate pins\n-      if (topPIRorTriggerPin >= 0) {\n-        if (!pinManager.allocatePin(topPIRorTriggerPin,useUSSensorTop))\n-          topPIRorTriggerPin = -1;\n-      }\n-      if (topEchoPin >= 0) {\n-        if (!pinManager.allocatePin(topEchoPin,false))\n-          topEchoPin = -1;\n-      }\n-      if (bottomPIRorTriggerPin >= 0) {\n-        if (!pinManager.allocatePin(bottomPIRorTriggerPin,useUSSensorBottom))\n-          bottomPIRorTriggerPin = -1;\n-      }\n-      if (bottomEchoPin >= 0) {\n-        if (!pinManager.allocatePin(bottomEchoPin,false))\n-          bottomEchoPin = -1;\n+      PinManagerPinType pins[4] = {\n+        { topPIRorTriggerPin, useUSSensorTop },\n+        { topEchoPin, false },\n+        { bottomPIRorTriggerPin, useUSSensorBottom },\n+        { bottomEchoPin, false },\n+      };\n+      // NOTE: this *WILL* return TRUE if all the pins are set to -1.\n+      //       this is *BY DESIGN*.\n+      if (!pinManager.allocateMultiplePins(pins, 4, PinOwner::UM_AnimatedStaircase)) {\n+        topPIRorTriggerPin = -1;\n+        topEchoPin = -1;\n+        bottomPIRorTriggerPin = -1;\n+        bottomEchoPin = -1;\n+        enabled = false;\n       }\n       enable(enabled);\n       initDone = true;\n@@ -480,10 +484,10 @@ class Animated_Staircase : public Usermod {\n             (oldBottomAPin != bottomPIRorTriggerPin) ||\n             (oldBottomBPin != bottomEchoPin)) {\n           changed = true;\n-          pinManager.deallocatePin(oldTopAPin);\n-          pinManager.deallocatePin(oldTopBPin);\n-          pinManager.deallocatePin(oldBottomAPin);\n-          pinManager.deallocatePin(oldBottomBPin);\n+          pinManager.deallocatePin(oldTopAPin, PinOwner::UM_AnimatedStaircase);\n+          pinManager.deallocatePin(oldTopBPin, PinOwner::UM_AnimatedStaircase);\n+          pinManager.deallocatePin(oldBottomAPin, PinOwner::UM_AnimatedStaircase);\n+          pinManager.deallocatePin(oldBottomBPin, PinOwner::UM_AnimatedStaircase);\n         }\n         if (changed) setup();\n       }\ndiff --git a/usermods/EleksTube_IPS/ChipSelect.h b/usermods/EleksTube_IPS/ChipSelect.h\nindex c58b285496..ced5eb8ea8 100644\n--- a/usermods/EleksTube_IPS/ChipSelect.h\n+++ b/usermods/EleksTube_IPS/ChipSelect.h\n@@ -58,12 +58,12 @@ class ChipSelect {\n   void setMinutesTens()                           { setDigit(MINUTES_TENS); }\n   void setHoursOnes()                             { setDigit(HOURS_ONES); }\n   void setHoursTens()                             { setDigit(HOURS_TENS); }\n-  bool isSecondsOnes()                            { return (digits_map&SECONDS_ONES_MAP > 0); }\n-  bool isSecondsTens()                            { return (digits_map&SECONDS_TENS_MAP > 0); }\n-  bool isMinutesOnes()                            { return (digits_map&MINUTES_ONES_MAP > 0); }\n-  bool isMinutesTens()                            { return (digits_map&MINUTES_TENS_MAP > 0); }\n-  bool isHoursOnes()                              { return (digits_map&HOURS_ONES_MAP > 0); }\n-  bool isHoursTens()                              { return (digits_map&HOURS_TENS_MAP > 0); }\n+  bool isSecondsOnes()                            { return ((digits_map & SECONDS_ONES_MAP) > 0); }\n+  bool isSecondsTens()                            { return ((digits_map & SECONDS_TENS_MAP) > 0); }\n+  bool isMinutesOnes()                            { return ((digits_map & MINUTES_ONES_MAP) > 0); }\n+  bool isMinutesTens()                            { return ((digits_map & MINUTES_TENS_MAP) > 0); }\n+  bool isHoursOnes()                              { return ((digits_map & HOURS_ONES_MAP) > 0); }\n+  bool isHoursTens()                              { return ((digits_map & HOURS_TENS_MAP) > 0); }\n };\n \n \ndiff --git a/usermods/PIR_sensor_switch/usermod_PIR_sensor_switch.h b/usermods/PIR_sensor_switch/usermod_PIR_sensor_switch.h\nindex 95e5799260..3f737a6b06 100644\n--- a/usermods/PIR_sensor_switch/usermod_PIR_sensor_switch.h\n+++ b/usermods/PIR_sensor_switch/usermod_PIR_sensor_switch.h\n@@ -200,12 +200,14 @@ class PIRsensorSwitch : public Usermod\n   {\r\n     if (enabled) {\r\n       // pin retrieved from cfg.json (readFromConfig()) prior to running setup()\r\n-      if (PIRsensorPin >= 0 && pinManager.allocatePin(PIRsensorPin,false)) {\r\n+      if (PIRsensorPin >= 0 && pinManager.allocatePin(PIRsensorPin, false, PinOwner::UM_PIR)) {\r\n         // PIR Sensor mode INPUT_PULLUP\r\n         pinMode(PIRsensorPin, INPUT_PULLUP);\r\n         sensorPinState = digitalRead(PIRsensorPin);\r\n       } else {\r\n-        if (PIRsensorPin >= 0) DEBUG_PRINTLN(F(\"PIRSensorSwitch pin allocation failed.\"));\r\n+        if (PIRsensorPin >= 0) {\r\n+          DEBUG_PRINTLN(F(\"PIRSensorSwitch pin allocation failed.\"));\r\n+        }\r\n         PIRsensorPin = -1;  // allocation failed\r\n         enabled = false;\r\n       }\r\n@@ -366,8 +368,8 @@ class PIRsensorSwitch : public Usermod\n         if (oldPin != PIRsensorPin && oldPin >= 0) {\r\n           // if we are changing pin in settings page\r\n           // deallocate old pin\r\n-          pinManager.deallocatePin(oldPin);\r\n-          if (pinManager.allocatePin(PIRsensorPin,false)) {\r\n+          pinManager.deallocatePin(oldPin, PinOwner::UM_PIR);\r\n+          if (pinManager.allocatePin(PIRsensorPin, false, PinOwner::UM_PIR)) {\r\n             pinMode(PIRsensorPin, INPUT_PULLUP);\r\n           } else {\r\n             // allocation failed\r\ndiff --git a/usermods/Temperature/usermod_temperature.h b/usermods/Temperature/usermod_temperature.h\nindex af509a67cf..c422904742 100644\n--- a/usermods/Temperature/usermod_temperature.h\n+++ b/usermods/Temperature/usermod_temperature.h\n@@ -115,14 +115,19 @@ class UsermodTemperature : public Usermod {\n         // config says we are enabled\n         DEBUG_PRINTLN(F(\"Allocating temperature pin...\"));\n         // pin retrieved from cfg.json (readFromConfig()) prior to running setup()\n-        if (temperaturePin >= 0 && pinManager.allocatePin(temperaturePin)) {\n+        if (temperaturePin >= 0 && pinManager.allocatePin(temperaturePin, true, PinOwner::UM_Temperature)) {\n           oneWire = new OneWire(temperaturePin);\n-          if (!oneWire->reset())\n+          if (!oneWire->reset()) {\n             sensorFound = false;   // resetting 1-Wire bus yielded an error\n-          else\n-            while ((sensorFound=findSensor()) && retries--) delay(25); // try to find sensor\n+          } else {\n+            while ((sensorFound=findSensor()) && retries--) {\n+              delay(25); // try to find sensor\n+            }\n+          }\n         } else {\n-          if (temperaturePin >= 0) DEBUG_PRINTLN(F(\"Temperature pin allocation failed.\"));\n+          if (temperaturePin >= 0) {\n+            DEBUG_PRINTLN(F(\"Temperature pin allocation failed.\"));\n+          }\n           temperaturePin = -1;  // allocation failed\n           sensorFound = false;\n         }\n@@ -273,7 +278,7 @@ class UsermodTemperature : public Usermod {\n           DEBUG_PRINTLN(F(\"Re-init temperature.\"));\n           // deallocate pin and release memory\n           delete oneWire;\n-          pinManager.deallocatePin(temperaturePin);\n+          pinManager.deallocatePin(temperaturePin, PinOwner::UM_Temperature);\n           temperaturePin = newTemperaturePin;\n           // initialise\n           setup();\ndiff --git a/usermods/multi_relay/usermod_multi_relay.h b/usermods/multi_relay/usermod_multi_relay.h\nindex 22a499b0e1..cd3e01c78e 100644\n--- a/usermods/multi_relay/usermod_multi_relay.h\n+++ b/usermods/multi_relay/usermod_multi_relay.h\n@@ -258,7 +258,7 @@ class MultiRelay : public Usermod {\n       // pins retrieved from cfg.json (readFromConfig()) prior to running setup()\n       for (uint8_t i=0; i<MULTI_RELAY_MAX_RELAYS; i++) {\n         if (_relay[i].pin<0) continue;\n-        if (!pinManager.allocatePin(_relay[i].pin,true)) {\n+        if (!pinManager.allocatePin(_relay[i].pin,true, PinOwner::UM_MultiRelay)) {\n           _relay[i].pin = -1;  // allocation failed\n         } else {\n           switchRelay(i, _relay[i].state = (bool)bri);\n@@ -380,12 +380,14 @@ class MultiRelay : public Usermod {\n         // deallocate all pins 1st\n         for (uint8_t i=0; i<MULTI_RELAY_MAX_RELAYS; i++)\n           if (oldPin[i]>=0) {\n-            pinManager.deallocatePin(oldPin[i]);\n+            pinManager.deallocatePin(oldPin[i], PinOwner::UM_MultiRelay);\n           }\n         // allocate new pins\n         for (uint8_t i=0; i<MULTI_RELAY_MAX_RELAYS; i++) {\n-          if (_relay[i].pin>=0 && pinManager.allocatePin(_relay[i].pin,true)) {\n-            if (!_relay[i].external) switchRelay(i, _relay[i].state = (bool)bri);\n+          if (_relay[i].pin>=0 && pinManager.allocatePin(_relay[i].pin, true, PinOwner::UM_MultiRelay)) {\n+            if (!_relay[i].external) {\n+              switchRelay(i, _relay[i].state = (bool)bri);\n+            }\n           } else {\n             _relay[i].pin = -1;\n           }\ndiff --git a/usermods/rgb-rotary-encoder/rgb-rotary-encoder.h b/usermods/rgb-rotary-encoder/rgb-rotary-encoder.h\nindex ab680a8f3d..cde220121a 100644\n--- a/usermods/rgb-rotary-encoder/rgb-rotary-encoder.h\n+++ b/usermods/rgb-rotary-encoder/rgb-rotary-encoder.h\n@@ -13,7 +13,7 @@ class RgbRotaryEncoderUsermod : public Usermod\n     BusDigital *ledBus;\n     /*\n     * Green - eb - Q4 - 32\n-    * Red - ea - Q1 - 15\n+    * Red   - ea - Q1 - 15\n     * Black - sw - Q2 - 12\n     */\n     ESPRotary *rotaryEncoder;\n@@ -39,13 +39,10 @@ class RgbRotaryEncoderUsermod : public Usermod\n \n     void initRotaryEncoder()\n     {\n-      if (!pinManager.allocatePin(eaIo, false)) {\n+      PinManagerPinType pins[2] = { { eaIo, false }, { ebIo, false } };\n+      if (!pinManager.allocateMultiplePins(pins, 2, UM_RGBRotaryEncoder)) {\n         eaIo = -1;\n-      }\n-      if (!pinManager.allocatePin(ebIo, false)) {\n         ebIo = -1;\n-      }\n-      if (eaIo == -1 || ebIo == -1) {\n         cleanup();\n         return;\n       }\n@@ -111,10 +108,12 @@ class RgbRotaryEncoderUsermod : public Usermod\n     {\n       // Only deallocate pins if we allocated them ;)\n       if (eaIo != -1) {\n-        pinManager.deallocatePin(eaIo);\n+        pinManager.deallocatePin(eaIo, PinOwner::UM_RGBRotaryEncoder);\n+        eaIo = -1;\n       }\n       if (ebIo != -1) {\n-        pinManager.deallocatePin(ebIo);\n+        pinManager.deallocatePin(ebIo, PinOwner::UM_RGBRotaryEncoder);\n+        ebIo = -1;\n       }\n \n       delete rotaryEncoder;\n@@ -304,8 +303,8 @@ class RgbRotaryEncoderUsermod : public Usermod\n           }\n \n           if (eaIo != oldEaIo || ebIo != oldEbIo || stepsPerClick != oldStepsPerClick || incrementPerClick != oldIncrementPerClick) {\n-            pinManager.deallocatePin(oldEaIo);\n-            pinManager.deallocatePin(oldEbIo);\n+            pinManager.deallocatePin(oldEaIo, PinOwner::UM_RGBRotaryEncoder);\n+            pinManager.deallocatePin(oldEbIo, PinOwner::UM_RGBRotaryEncoder);\n             \n             delete rotaryEncoder;\n             initRotaryEncoder();\ndiff --git a/usermods/usermod_v2_four_line_display/usermod_v2_four_line_display.h b/usermods/usermod_v2_four_line_display/usermod_v2_four_line_display.h\nindex 833ed10107..b7a88eb412 100644\n--- a/usermods/usermod_v2_four_line_display/usermod_v2_four_line_display.h\n+++ b/usermods/usermod_v2_four_line_display/usermod_v2_four_line_display.h\n@@ -168,14 +168,13 @@ class FourLineDisplayUsermod : public Usermod {\n     // network here\n     void setup() {\n       if (type == NONE) return;\n-      bool allocated = false;\n       byte i;\n       if (type == SSD1306_SPI || type == SSD1306_SPI64) {\n-        for (i=0; i<5; i++) if (!pinManager.allocatePin(ioPin[i])) { allocated=true; break; }\n-        if (i<5 && allocated) { for (byte i=0; i<5; i++) pinManager.deallocatePin(ioPin[i]); type=NONE; return; }\n+        PinManagerPinType pins[5] = { { ioPin[0], true }, { ioPin[1], true}, { ioPin[2], true }, { ioPin[3], true}, { ioPin[4], true }};\n+        if (!pinManager.allocateMultiplePins(pins, 5, PinOwner::UM_FourLineDisplay)) { type=NONE; return; }\n       } else {\n-        for (i=0; i<2; i++) if (!pinManager.allocatePin(ioPin[i])) { allocated=true; break; }\n-        if (i<2 && allocated) { for (byte i=0; i<5; i++) pinManager.deallocatePin(ioPin[i]); type=NONE; return; }\n+        PinManagerPinType pins[2] = { { ioPin[0], true }, { ioPin[1], true} };\n+        if (!pinManager.allocateMultiplePins(pins, 2, PinOwner::UM_FourLineDisplay)) { type=NONE; return; }\n       }\n       DEBUG_PRINTLN(F(\"Allocating display.\"));\n       switch (type) {\n@@ -240,18 +239,20 @@ class FourLineDisplayUsermod : public Usermod {\n           break;\n         default:\n           u8x8 = nullptr;\n+      }\n+      if (nullptr == u8x8) {\n+          DEBUG_PRINTLN(F(\"Display init failed.\"));\n+          pinManager.deallocatePin(sclPin, PinOwner::UM_FourLineDisplay);\n+          pinManager.deallocatePin(sdaPin, PinOwner::UM_FourLineDisplay);\n+          sclPin = -1;\n+          sdaPin = -1;\n           type = NONE;\n           return;\n       }\n+\n       initDone = true;\n-      if (u8x8 != nullptr) {\n-        DEBUG_PRINTLN(F(\"Starting display.\"));\n-        (static_cast<U8X8*>(u8x8))->begin();\n-      } else {\n-        DEBUG_PRINTLN(F(\"Display init failed.\"));\n-        type = NONE;\n-        return;\n-      }\n+      DEBUG_PRINTLN(F(\"Starting display.\"));\n+      (static_cast<U8X8*>(u8x8))->begin(); // why a static cast here?  variable is of this type...\n       setFlipMode(flip);\n       setContrast(contrast); //Contrast setup will help to preserve OLED lifetime. In case OLED need to be brighter increase number up to 255\n       setPowerSave(0);\n@@ -727,7 +728,7 @@ class FourLineDisplayUsermod : public Usermod {\n         if (pinsChanged || type!=newType) {\n           if (type != NONE) delete (static_cast<U8X8*>(u8x8));\n           for (byte i=0; i<5; i++) {\n-            if (ioPin[i]>=0) pinManager.deallocatePin(ioPin[i]);\n+            if (ioPin[i]>=0) pinManager.deallocatePin(ioPin[i], PinOwner::UM_FourLineDisplay);\n             ioPin[i] = newPin[i];\n           }\n           if (ioPin[0]<0 || ioPin[1]<0) { // data & clock must be > -1\n@@ -735,7 +736,9 @@ class FourLineDisplayUsermod : public Usermod {\n             return true;\n           } else type = newType;\n           setup();\n-          needsRedraw |= true;\n+          if (sclPin >= 0 && sdaPin >= 0) {\n+            needsRedraw |= true;\n+          }\n         }\n         setContrast(contrast);\n         setFlipMode(flip);\ndiff --git a/usermods/usermod_v2_rotary_encoder_ui/usermod_v2_rotary_encoder_ui.h b/usermods/usermod_v2_rotary_encoder_ui/usermod_v2_rotary_encoder_ui.h\nindex 5c8dd70ea2..bf909bdca4 100644\n--- a/usermods/usermod_v2_rotary_encoder_ui/usermod_v2_rotary_encoder_ui.h\n+++ b/usermods/usermod_v2_rotary_encoder_ui/usermod_v2_rotary_encoder_ui.h\n@@ -76,7 +76,7 @@ class RotaryEncoderUIUsermod : public Usermod {\n   unsigned char Enc_B;\n   unsigned char Enc_A_prev = 0;\n \n-  bool currentEffectAndPaleeteInitialized = false;\n+  bool currentEffectAndPaletteInitialized = false;\n   uint8_t effectCurrentIndex = 0;\n   uint8_t effectPaletteIndex = 0;\n \n@@ -97,9 +97,17 @@ class RotaryEncoderUIUsermod : public Usermod {\n      */\n   void setup()\n   {\n-    if (!pinManager.allocatePin(pinA)) { enabled = false; return;}\n-    if (!pinManager.allocatePin(pinB)) { pinManager.deallocatePin(pinA); enabled = false; return; }\n-    if (!pinManager.allocatePin(pinC)) { pinManager.deallocatePin(pinA); pinManager.deallocatePin(pinB); enabled = false; return; }\n+    PinManagerPinType pins[3] = { { pinA, false }, { pinB, false }, { pinC, false } };\n+    if (!pinManager.allocateMultiplePins(pins, 3, PinOwner::UM_RotaryEncoderUI)) {\n+      // BUG: configuring this usermod with conflicting pins\n+      //      will cause it to de-allocate pins it does not own\n+      //      (at second config)\n+      //      This is the exact type of bug solved by pinManager\n+      //      tracking the owner tags....\n+      pinA = pinB = pinC = -1;\n+      enabled = false;\n+      return;\n+    }\n \n     pinMode(pinA, INPUT_PULLUP);\n     pinMode(pinB, INPUT_PULLUP);\n@@ -152,7 +160,7 @@ class RotaryEncoderUIUsermod : public Usermod {\n     // Initialize effectCurrentIndex and effectPaletteIndex to\n     // current state. We do it here as (at least) effectCurrent\n     // is not yet initialized when setup is called.\n-    if (!currentEffectAndPaleeteInitialized) {\n+    if (!currentEffectAndPaletteInitialized) {\n       findCurrentEffectAndPalette();\n     }\n \n@@ -248,7 +256,7 @@ class RotaryEncoderUIUsermod : public Usermod {\n   }\n \n   void findCurrentEffectAndPalette() {\n-    currentEffectAndPaleeteInitialized = true;\n+    currentEffectAndPaletteInitialized = true;\n     for (uint8_t i = 0; i < strip.getModeCount(); i++) {\n       //byte value = modes_alpha_indexes[i];\n       if (modes_alpha_indexes[i] == effectCurrent) {\n@@ -455,9 +463,9 @@ class RotaryEncoderUIUsermod : public Usermod {\n       DEBUG_PRINTLN(F(\" config (re)loaded.\"));\n       // changing parameters from settings page\n       if (pinA!=newDTpin || pinB!=newCLKpin || pinC!=newSWpin) {\n-        pinManager.deallocatePin(pinA);\n-        pinManager.deallocatePin(pinB);\n-        pinManager.deallocatePin(pinC);\n+        pinManager.deallocatePin(pinA, PinOwner::UM_RotaryEncoderUI);\n+        pinManager.deallocatePin(pinB, PinOwner::UM_RotaryEncoderUI);\n+        pinManager.deallocatePin(pinC, PinOwner::UM_RotaryEncoderUI);\n         pinA = newDTpin;\n         pinB = newCLKpin;\n         pinC = newSWpin;\ndiff --git a/wled00/bus_manager.h b/wled00/bus_manager.h\nindex 295a84e52a..55d929e0d3 100644\n--- a/wled00/bus_manager.h\n+++ b/wled00/bus_manager.h\n@@ -119,10 +119,10 @@ class BusDigital : public Bus {\n   public:\n   BusDigital(BusConfig &bc, uint8_t nr) : Bus(bc.type, bc.start) {\n     if (!IS_DIGITAL(bc.type) || !bc.count) return;\n-    if (!pinManager.allocatePin(bc.pins[0])) return;\n+    if (!pinManager.allocatePin(bc.pins[0], true, PinOwner::BusDigital)) return;\n     _pins[0] = bc.pins[0];\n     if (IS_2PIN(bc.type)) {\n-      if (!pinManager.allocatePin(bc.pins[1])) {\n+      if (!pinManager.allocatePin(bc.pins[1], true, PinOwner::BusDigital)) {\n         cleanup(); return;\n       }\n       _pins[1] = bc.pins[1];\n@@ -206,8 +206,8 @@ class BusDigital : public Bus {\n     _iType = I_NONE;\n     _valid = false;\n     _busPtr = nullptr;\n-    pinManager.deallocatePin(_pins[0]);\n-    pinManager.deallocatePin(_pins[1]);\n+    pinManager.deallocatePin(_pins[1], PinOwner::BusDigital);\n+    pinManager.deallocatePin(_pins[0], PinOwner::BusDigital);\n   }\n \n   ~BusDigital() {\n@@ -242,7 +242,7 @@ class BusPwm : public Bus {\n \n     for (uint8_t i = 0; i < numPins; i++) {\n       uint8_t currentPin = bc.pins[i];\n-      if (!pinManager.allocatePin(currentPin)) {\n+      if (!pinManager.allocatePin(currentPin, true, PinOwner::BusPwm)) {\n         deallocatePins(); return;\n       }\n       _pins[i] = currentPin; // store only after allocatePin() succeeds\n@@ -334,7 +334,7 @@ class BusPwm : public Bus {\n       #else\n       if (_ledcStart < 16) ledcDetachPin(_pins[i]);\n       #endif\n-      pinManager.deallocatePin(_pins[i]);\n+      pinManager.deallocatePin(_pins[i], PinOwner::BusPwm);\n     }\n     #ifdef ARDUINO_ARCH_ESP32\n     pinManager.deallocateLedc(_ledcStart, numPins);\n@@ -457,4 +457,4 @@ class BusManager {\n   uint8_t numBusses = 0;\n   Bus* busses[WLED_MAX_BUSSES];\n };\n-#endif\n\\ No newline at end of file\n+#endif\ndiff --git a/wled00/cfg.cpp b/wled00/cfg.cpp\nindex bdceb3a4c2..2214584cd8 100644\n--- a/wled00/cfg.cpp\n+++ b/wled00/cfg.cpp\n@@ -18,6 +18,13 @@ bool deserializeConfig(JsonObject doc, bool fromFS) {\n \n   //long vid = doc[F(\"vid\")]; // 2010020\n \n+  #ifdef WLED_USE_ETHERNET\n+  JsonObject ethernet = doc[F(\"eth\")];\n+  CJSON(ethernetType, ethernet[\"type\"]);\n+  // NOTE: Ethernet configuration takes priority over other use of pins\n+  WLED::instance().initEthernet();\n+  #endif\n+\n   JsonObject id = doc[\"id\"];\n   getStringFromJson(cmDNS, id[F(\"mdns\")], 33);\n   getStringFromJson(serverDescription, id[F(\"name\")], 33);\n@@ -53,10 +60,6 @@ bool deserializeConfig(JsonObject doc, bool fromFS) {\n \n   CJSON(apBehavior, ap[F(\"behav\")]);\n   \n-  #ifdef WLED_USE_ETHERNET\n-  JsonObject ethernet = doc[F(\"eth\")];\n-  CJSON(ethernetType, ethernet[\"type\"]);\n-  #endif\n \n   /*\n   JsonArray ap_ip = ap[\"ip\"];\n@@ -71,7 +74,7 @@ bool deserializeConfig(JsonObject doc, bool fromFS) {\n \n   JsonObject hw = doc[F(\"hw\")];\n \n-  // initialize LED pins and lengths prior to other HW\n+  // initialize LED pins and lengths prior to other HW (except for ethernet)\n   JsonObject hw_led = hw[F(\"led\")];\n \n   CJSON(ledCount, hw_led[F(\"total\")]);\n@@ -130,7 +133,7 @@ bool deserializeConfig(JsonObject doc, bool fromFS) {\n     for (JsonObject btn : hw_btn_ins) {\n       CJSON(buttonType[s], btn[\"type\"]);\n       int8_t pin = btn[\"pin\"][0] | -1;\n-      if (pin > -1 && pinManager.allocatePin(pin,false)) {\n+      if (pin > -1 && pinManager.allocatePin(pin, false, PinOwner::Button)) {\n         btnPin[s] = pin;\n         pinMode(btnPin[s], INPUT_PULLUP);\n       } else {\n@@ -155,7 +158,7 @@ bool deserializeConfig(JsonObject doc, bool fromFS) {\n     if (fromFS) {\n       // relies upon only being called once with fromFS == true, which is currently true.\n       uint8_t s = 0;\n-      if (pinManager.allocatePin(btnPin[0],false)) { // initialized to #define value BTNPIN, or zero if not defined(!)\n+      if (pinManager.allocatePin(btnPin[0], false, PinOwner::Button)) { // initialized to #define value BTNPIN, or zero if not defined(!)\n         ++s; // do not clear default button if allocated successfully \n       }\n       for (; s<WLED_MAX_BUTTONS; s++) {\n@@ -172,7 +175,7 @@ bool deserializeConfig(JsonObject doc, bool fromFS) {\n \n   int hw_ir_pin = hw[\"ir\"][\"pin\"] | -2; // 4\n   if (hw_ir_pin > -2) {\n-    if (pinManager.allocatePin(hw_ir_pin,false)) {\n+    if (pinManager.allocatePin(hw_ir_pin, false, PinOwner::IR)) {\n       irPin = hw_ir_pin;\n     } else {\n       irPin = -1;\n@@ -183,7 +186,7 @@ bool deserializeConfig(JsonObject doc, bool fromFS) {\n   JsonObject relay = hw[F(\"relay\")];\n   int hw_relay_pin = relay[\"pin\"] | -2;\n   if (hw_relay_pin > -2) {\n-    if (pinManager.allocatePin(hw_relay_pin,true)) {\n+    if (pinManager.allocatePin(hw_relay_pin,true, PinOwner::Relay)) {\n       rlyPin = hw_relay_pin;\n       pinMode(rlyPin, OUTPUT);\n     } else {\n@@ -437,6 +440,8 @@ void deserializeConfigFromFS() {\n     return;\n   }\n \n+  // NOTE: This routine deserializes *and* applies the configuration\n+  //       Therefore, must also initialize ethernet from this function\n   deserializeConfig(doc.as<JsonObject>(), true);  \n }\n \ndiff --git a/wled00/const.h b/wled00/const.h\nindex 1a4fe2a805..b8b54dc546 100644\n--- a/wled00/const.h\n+++ b/wled00/const.h\n@@ -291,7 +291,7 @@\n #ifdef ESP8266\n   #define LEDPIN 2    // GPIO2 (D4) on Wemod D1 mini compatible boards\n #else\n-  #define LEDPIN 16   // alligns with GPIO2 (D4) on Wemos D1 mini32 compatible boards\n+  #define LEDPIN 16   // aligns with GPIO2 (D4) on Wemos D1 mini32 compatible boards\n #endif\n #endif\n \ndiff --git a/wled00/overlay.cpp b/wled00/overlay.cpp\nindex a4caa85ee9..983396863f 100644\n--- a/wled00/overlay.cpp\n+++ b/wled00/overlay.cpp\n@@ -359,7 +359,7 @@ void _drawOverlayCronixie()\n }\n \n #else // WLED_DISABLE_CRONIXIE\n-byte getSameCodeLength(char code, int index, char const cronixieDisplay[]) {}\n+byte getSameCodeLength(char code, int index, char const cronixieDisplay[]) { return 0; }\n void setCronixie() {}\n void _overlayCronixie() {}\n void _drawOverlayCronixie() {}\ndiff --git a/wled00/pin_manager.cpp b/wled00/pin_manager.cpp\nindex d260ae95e6..38e6e1621f 100644\n--- a/wled00/pin_manager.cpp\n+++ b/wled00/pin_manager.cpp\n@@ -1,35 +1,110 @@\n #include \"pin_manager.h\"\n #include \"wled.h\"\n \n-void PinManagerClass::deallocatePin(byte gpio)\n+static void DebugPrintOwnerTag(PinOwner tag)\n {\n-  if (!isPinOk(gpio, false)) return;\n+  uint32_t q = static_cast<uint8_t>(tag);\n+  if (q) {\n+    DEBUG_PRINTF(\"0x%02x (%d)\", q, q);\n+  } else {\n+    DEBUG_PRINT(F(\"(no owner)\"));\n+  }\n+}\n+\n+/// Actual allocation/deallocation routines\n+bool PinManagerClass::deallocatePin(byte gpio, PinOwner tag)\n+{\n+  if (gpio == 0xFF) return true;           // explicitly allow clients to free -1 as a no-op\n+  if (!isPinOk(gpio, false)) return false; // but return false for any other invalid pin\n+\n+  // if a non-zero ownerTag, only allow de-allocation if the owner's tag is provided\n+  if ((ownerTag[gpio] != PinOwner::None) && (ownerTag[gpio] != tag)) {\n+    DEBUG_PRINT(F(\"PIN DEALLOC: IO \"));\n+    DEBUG_PRINT(gpio);\n+    DEBUG_PRINT(F(\" allocated by \"));\n+    DebugPrintOwnerTag(ownerTag[gpio]);\n+    DEBUG_PRINT(F(\", but attempted de-allocation by \"));\n+    DebugPrintOwnerTag(tag);\n+    return false;\n+  }\n   \n   byte by = gpio >> 3;\n   byte bi = gpio - 8*by;\n   bitWrite(pinAlloc[by], bi, false);\n+  ownerTag[gpio] = PinOwner::None;\n+  return true;\n }\n+bool PinManagerClass::allocateMultiplePins(const managed_pin_type * mptArray, byte arrayElementCount, PinOwner tag)\n+{\n+  bool shouldFail = false;\n+  // first verify the pins are OK and not already allocated\n+  for (int i = 0; i < arrayElementCount; i++) {\n+    byte gpio = mptArray[i].pin;\n+    if (gpio == 0xFF) {\n+      // explicit support for io -1 as a no-op (no allocation of pin),\n+      // as this can greatly simplify configuration arrays\n+      continue;\n+    }\n+    if (!isPinOk(gpio, mptArray[i].isOutput)) {\n+      DEBUG_PRINT(F(\"PIN ALLOC: Invalid pin attempted to be allocated: \"));\n+      DEBUG_PRINT(gpio);\n+      DEBUG_PRINTLN(F(\"\"));\n+      shouldFail = true;\n+    }\n+    if (isPinAllocated(gpio)) {\n+      DEBUG_PRINT(F(\"PIN ALLOC: FAIL: IO \")); \n+      DEBUG_PRINT(gpio);\n+      DEBUG_PRINT(F(\" already allocated by \"));\n+      DebugPrintOwnerTag(ownerTag[gpio]);\n+      DEBUG_PRINTLN(F(\"\"));\n+      shouldFail = true;\n+    }\n+  }\n+  if (shouldFail) {\n+    return false;\n+  }\n \n-bool PinManagerClass::allocatePin(byte gpio, bool output)\n+  // all pins are available .. track each one\n+  for (int i = 0; i < arrayElementCount; i++) {\n+    byte gpio = mptArray[i].pin;\n+    if (gpio == 0xFF) {\n+      // allow callers to include -1 value as non-requested pin\n+      // as this can greatly simplify configuration arrays\n+      continue;\n+    }\n+    byte by = gpio >> 3;\n+    byte bi = gpio - 8*by;\n+    bitWrite(pinAlloc[by], bi, true);\n+    ownerTag[gpio] = tag;\n+  }\n+  return true;\n+}\n+bool PinManagerClass::allocatePin(byte gpio, bool output, PinOwner tag)\n {\n   if (!isPinOk(gpio, output)) return false;\n   if (isPinAllocated(gpio)) {\n-    DEBUG_PRINT(F(\"Attempted duplicate allocation of pin \"));\n-    DEBUG_PRINTLN(gpio);\n+    DEBUG_PRINT(F(\"PIN ALLOC: Pin \")); \n+    DEBUG_PRINT(gpio);\n+    DEBUG_PRINT(F(\" already allocated by \"));\n+    DebugPrintOwnerTag(ownerTag[gpio]);\n+    DEBUG_PRINTLN(F(\"\"));\n     return false;\n   }\n \n   byte by = gpio >> 3;\n   byte bi = gpio - 8*by;\n   bitWrite(pinAlloc[by], bi, true);\n+  ownerTag[gpio] = tag;\n   \n   return true;\n }\n \n-bool PinManagerClass::isPinAllocated(byte gpio)\n+// if tag is set to PinOwner::None, checks for ANY owner of the pin.\n+// if tag is set to any other value, checks if that tag is the current owner of the pin.\n+bool PinManagerClass::isPinAllocated(byte gpio, PinOwner tag)\n {\n   if (!isPinOk(gpio, false)) return true;\n-  \n+  if ((tag != PinOwner::None) && (ownerTag[gpio] != tag)) return false;\n   byte by = gpio >> 3;\n   byte bi = gpio - 8*by;\n   return bitRead(pinAlloc[by], bi);\n@@ -46,7 +121,7 @@ bool PinManagerClass::isPinOk(byte gpio, bool output)\n   if (gpio < 34) return true;\n   if (gpio < 40 && !output) return true; //34-39 input only\n   #endif\n-  \n+\n   return false;\n }\n \n@@ -88,4 +163,4 @@ void PinManagerClass::deallocateLedc(byte pos, byte channels)\n }\n #endif\n \n-PinManagerClass pinManager = PinManagerClass();\n\\ No newline at end of file\n+PinManagerClass pinManager = PinManagerClass();\ndiff --git a/wled00/pin_manager.h b/wled00/pin_manager.h\nindex 601c4be396..1dab2b09a2 100644\n--- a/wled00/pin_manager.h\n+++ b/wled00/pin_manager.h\n@@ -4,21 +4,93 @@\n  * Registers pins so there is no attempt for two interfaces to use the same pin\n  */\n #include <Arduino.h>\n+#include \"const.h\" // for USERMOD_* values\n+\n+typedef struct PinManagerPinType {\n+  int8_t  pin;\n+  uint8_t isOutput;\n+} managed_pin_type;\n+\n+/*\n+ * Allows PinManager to \"lock\" an allocation to a specific\n+ * owner, so someone else doesn't accidentally de-allocate\n+ * a pin it hasn't allocated.  Also enhances debugging.\n+ * \n+ * RAM Cost:\n+ *     17 bytes on ESP8266\n+ *     40 bytes on ESP32\n+ */\n+enum struct PinOwner : uint8_t {\n+  None          = 0,            // default == legacy == unspecified owner\n+  // High bit is set for all built-in pin owners\n+  // StatusLED  -- THIS SHOULD NEVER BE ALLOCATED -- see handleStatusLED()\n+  Ethernet      = 0x81,\n+  BusDigital    = 0x82,\n+  BusDigital2   = 0x83,\n+  BusPwm        = 0x84,   // 'BusP' == PWM output using BusPwm\n+  Button        = 0x85,   // 'Butn' == button from configuration\n+  IR            = 0x86,   // 'IR'   == IR receiver pin from configuration\n+  Relay         = 0x87,   // 'Rly'  == Relay pin from configuration\n+  SPI_RAM       = 0x88,   // 'SpiR' == SPI RAM\n+  DebugOut      = 0x89,   // 'Dbg'  == debug output always IO1\n+  DMX           = 0x8A,   // 'DMX'  == hard-coded to IO2\n+  // Use UserMod IDs from const.h here\n+  UM_Unspecified       = USERMOD_ID_UNSPECIFIED,        // 0x01\n+  UM_RGBRotaryEncoder  = USERMOD_ID_UNSPECIFIED,        // 0x01 // No define in const.h for this user module -- consider adding?\n+  UM_Example           = USERMOD_ID_EXAMPLE,            // 0x02 // Usermod \"usermod_v2_example.h\"\n+  UM_Temperature       = USERMOD_ID_TEMPERATURE,        // 0x03 // Usermod \"usermod_temperature.h\"\n+  // #define USERMOD_ID_FIXNETSERVICES                  // 0x04 // Usermod \"usermod_Fix_unreachable_netservices.h\" -- Does not allocate pins\n+  UM_PIR               = USERMOD_ID_PIRSWITCH,          // 0x05 // Usermod \"usermod_PIR_sensor_switch.h\"\n+  // #define USERMOD_ID_IMU                             // 0x06 // Usermod \"usermod_mpu6050_imu.h\" -- Uses \"standard\" I2C pins ... TODO -- enable shared I2C bus use\n+  UM_FourLineDisplay   = USERMOD_ID_FOUR_LINE_DISP,     // 0x07 // Usermod \"usermod_v2_four_line_display.h\n+  UM_RotaryEncoderUI   = USERMOD_ID_ROTARY_ENC_UI,      // 0x08 // Usermod \"usermod_v2_rotary_encoder_ui.h\"\n+  // #define USERMOD_ID_AUTO_SAVE                       // 0x09 // Usermod \"usermod_v2_auto_save.h\" -- Does not allocate pins\n+  // #define USERMOD_ID_DHT                             // 0x0A // Usermod \"usermod_dht.h\" -- Statically allocates pins, not compatible with pinManager?\n+  // #define USERMOD_ID_MODE_SORT                       // 0x0B // Usermod \"usermod_v2_mode_sort.h\" -- Does not allocate pins\n+  // #define USERMOD_ID_VL53L0X                         // 0x0C // Usermod \"usermod_vl53l0x_gestures.h\" -- Uses \"standard\" I2C pins ... TODO -- enable shared I2C bus use\n+  UM_MultiRelay        = USERMOD_ID_MULTI_RELAY,        // 0x0D // Usermod \"usermod_multi_relay.h\"\n+  UM_AnimatedStaircase = USERMOD_ID_ANIMATED_STAIRCASE, // 0x0E // Usermod \"Animated_Staircase.h\"\n+  // #define USERMOD_ID_RTC                             // 0x0F // Usermod \"usermod_rtc.h\" -- Uses \"standard\" I2C pins ... TODO -- enable shared I2C bus use\n+  // #define USERMOD_ID_ELEKSTUBE_IPS                   // 0x10 // Usermod \"usermod_elekstube_ips.h\" -- Uses quite a few pins ... see Hardware.h and User_Setup.h\n+  // #define USERMOD_ID_SN_PHOTORESISTOR                // 0x11 // Usermod \"usermod_sn_photoresistor.h\" -- Uses hard-coded pin (PHOTORESISTOR_PIN == A0), but could be easily updated to use pinManager\n+};\n+static_assert(0u == static_cast<uint8_t>(PinOwner::None), \"PinOwner::None must be zero, so default array initialization works as expected\");\n \n class PinManagerClass {\n   private:\n   #ifdef ESP8266\n   uint8_t pinAlloc[3] = {0x00, 0x00, 0x00}; //24bit, 1 bit per pin, we use first 17bits\n+  PinOwner ownerTag[17] = { PinOwner::None };\n   #else\n   uint8_t pinAlloc[5] = {0x00, 0x00, 0x00, 0x00, 0x00}; //40bit, 1 bit per pin, we use all bits\n   uint8_t ledcAlloc[2] = {0x00, 0x00}; //16 LEDC channels\n+  PinOwner ownerTag[40] = { PinOwner::None };\n   #endif\n \n   public:\n-  void deallocatePin(byte gpio);\n-  bool allocatePin(byte gpio, bool output = true);\n-  bool isPinAllocated(byte gpio);\n+  // De-allocates a single pin\n+  bool deallocatePin(byte gpio, PinOwner tag);\n+  // Allocates a single pin, with an owner tag.\n+  // De-allocation requires the same owner tag (or override)\n+  bool allocatePin(byte gpio, bool output, PinOwner tag);\n+  // Allocates all the pins, or allocates none of the pins, with owner tag.\n+  // Provided to simplify error condition handling in clients \n+  // using more than one pin, such as I2C, SPI, rotary encoders,\n+  // ethernet, etc..\n+  bool allocateMultiplePins(const managed_pin_type * mptArray, byte arrayElementCount, PinOwner tag );\n+\n+  #if !defined(ESP8266) // ESP8266 compiler doesn't understand deprecated attribute\n+  [[deprecated(\"Replaced by three-parameter allocatePin(gpio, output, ownerTag), for improved debugging\")]]\n+  #endif\n+  inline bool allocatePin(byte gpio, bool output = true) { return allocatePin(gpio, output, PinOwner::None); }\n+  #if !defined(ESP8266) // ESP8266 compiler doesn't understand deprecated attribute\n+  [[deprecated(\"Replaced by three-parameter deallocatePin(gpio, output, ownerTag), for improved debugging\")]]\n+  #endif\n+  inline void deallocatePin(byte gpio) { deallocatePin(gpio, PinOwner::None); }\n+\n+  bool isPinAllocated(byte gpio, PinOwner tag = PinOwner::None);\n   bool isPinOk(byte gpio, bool output = true);\n+\n   #ifdef ARDUINO_ARCH_ESP32\n   byte allocateLedc(byte channels);\n   void deallocateLedc(byte pos, byte channels);\n@@ -26,4 +98,4 @@ class PinManagerClass {\n };\n \n extern PinManagerClass pinManager;\n-#endif\n\\ No newline at end of file\n+#endif\ndiff --git a/wled00/set.cpp b/wled00/set.cpp\nindex 358f979856..080fea9ceb 100644\n--- a/wled00/set.cpp\n+++ b/wled00/set.cpp\n@@ -54,6 +54,7 @@ void handleSettingsSet(AsyncWebServerRequest *request, byte subPage)\n \n     #ifdef WLED_USE_ETHERNET\n     ethernetType = request->arg(F(\"ETH\")).toInt();\n+    WLED::instance().initEthernet();\n     #endif\n \n     char k[3]; k[2] = 0;\n@@ -77,11 +78,17 @@ void handleSettingsSet(AsyncWebServerRequest *request, byte subPage)\n   {\n     int t = 0;\n \n-    if (rlyPin>=0 && pinManager.isPinAllocated(rlyPin)) pinManager.deallocatePin(rlyPin);\n-    if (irPin>=0 && pinManager.isPinAllocated(irPin)) pinManager.deallocatePin(irPin);\n-    for (uint8_t s=0; s<WLED_MAX_BUTTONS; s++)\n-      if (btnPin[s]>=0 && pinManager.isPinAllocated(btnPin[s]))\n-        pinManager.deallocatePin(btnPin[s]);\n+    if (rlyPin>=0 && pinManager.isPinAllocated(rlyPin, PinOwner::Relay)) {\n+       pinManager.deallocatePin(rlyPin, PinOwner::Relay);\n+    }\n+    if (irPin>=0 && pinManager.isPinAllocated(irPin, PinOwner::IR)) {\n+       pinManager.deallocatePin(irPin, PinOwner::IR);\n+    }\n+    for (uint8_t s=0; s<WLED_MAX_BUTTONS; s++) {\n+      if (btnPin[s]>=0 && pinManager.isPinAllocated(btnPin[s], PinOwner::Button)) {\n+        pinManager.deallocatePin(btnPin[s], PinOwner::Button);\n+      }\n+    }\n \n     strip.isRgbw = false;\n     uint8_t colorOrder, type, skip;\n@@ -127,7 +134,7 @@ void handleSettingsSet(AsyncWebServerRequest *request, byte subPage)\n \n     // upate other pins\n     int hw_ir_pin = request->arg(F(\"IR\")).toInt();\n-    if (pinManager.allocatePin(hw_ir_pin,false)) {\n+    if (pinManager.allocatePin(hw_ir_pin,false, PinOwner::IR)) {\n       irPin = hw_ir_pin;\n     } else {\n       irPin = -1;\n@@ -135,7 +142,7 @@ void handleSettingsSet(AsyncWebServerRequest *request, byte subPage)\n     irEnabled = request->arg(F(\"IT\")).toInt();\n \n     int hw_rly_pin = request->arg(F(\"RL\")).toInt();\n-    if (pinManager.allocatePin(hw_rly_pin,true)) {\n+    if (pinManager.allocatePin(hw_rly_pin,true, PinOwner::Relay)) {\n       rlyPin = hw_rly_pin;\n     } else {\n       rlyPin = -1;\n@@ -146,7 +153,7 @@ void handleSettingsSet(AsyncWebServerRequest *request, byte subPage)\n       char bt[4] = \"BT\"; bt[2] = 48+i; bt[3] = 0; // button pin\n       char be[4] = \"BE\"; be[2] = 48+i; be[3] = 0; // button type\n       int hw_btn_pin = request->arg(bt).toInt();\n-      if (pinManager.allocatePin(hw_btn_pin,false)) {\n+      if (pinManager.allocatePin(hw_btn_pin,false,PinOwner::Button)) {\n         btnPin[i] = hw_btn_pin;\n         pinMode(btnPin[i], INPUT_PULLUP);\n         buttonType[i] = request->arg(be).toInt();\ndiff --git a/wled00/wled.cpp b/wled00/wled.cpp\nindex 05b060cb20..03eaddf0a3 100644\n--- a/wled00/wled.cpp\n+++ b/wled00/wled.cpp\n@@ -105,6 +105,11 @@ void WiFiEvent(WiFiEvent_t event)\n       break;\n     case SYSTEM_EVENT_ETH_DISCONNECTED:\n       DEBUG_PRINT(F(\"ETH Disconnected\"));\n+      // This doesn't really affect ethernet per se,\n+      // as it's only configured once.  Rather, it\n+      // may be necessary to reconnect the WiFi when\n+      // ethernet disconnects, as a way to provide\n+      // alternative access to the device.\n       forceReconnect = true;\n       break;\n #endif\n@@ -275,20 +280,21 @@ void WLED::setup()\n   registerUsermods();\n \n   #if defined(ARDUINO_ARCH_ESP32) && defined(WLED_USE_PSRAM)\n-    if (psramFound()) {\n-      pinManager.allocatePin(16); // GPIO16 reserved for SPI RAM\n-      pinManager.allocatePin(17); // GPIO17 reserved for SPI RAM\n-    }\n+  if (psramFound()) {\n+    // GPIO16/GPIO17 reserved for SPI RAM\n+    managed_pin_type pins[2] = { {16, true}, {17, true} };\n+    pinManager.allocateMultiplePins(pins, 2, PinOwner::SPI_RAM);\n+  }\n   #endif\n \n   //DEBUG_PRINT(F(\"LEDs inited. heap usage ~\"));\n   //DEBUG_PRINTLN(heapPreAlloc - ESP.getFreeHeap());\n \n #ifdef WLED_DEBUG\n-  pinManager.allocatePin(1,true); // GPIO1 reserved for debug output\n+  pinManager.allocatePin(1, true, PinOwner::DebugOut); // GPIO1 reserved for debug output\n #endif\n #ifdef WLED_USE_DMX //reserve GPIO2 as hardcoded DMX pin\n-  pinManager.allocatePin(2);\n+  pinManager.allocatePin(2, true, PinOwner::DMX);\n #endif\n \n   for (uint8_t i=1; i<WLED_MAX_BUTTONS; i++) btnPin[i] = -1;\n@@ -310,7 +316,11 @@ void WLED::setup()\n   deserializeConfigFromFS();\n \n #if STATUSLED\n-  if (!pinManager.isPinAllocated(STATUSLED)) pinMode(STATUSLED, OUTPUT);\n+  if (!pinManager.isPinAllocated(STATUSLED)) {\n+    // NOTE: Special case: The status LED should *NOT* be allocated.\n+    //       See comments in handleStatusLed().\n+    pinMode(STATUSLED, OUTPUT);\n+  }\n #endif\n \n   DEBUG_PRINTLN(F(\"Initializing strip\"));\n@@ -436,80 +446,105 @@ void WLED::initAP(bool resetAP)\n   apActive = true;\n }\n \n-void WLED::initConnection()\n+bool WLED::initEthernet()\n {\n-  #ifdef WLED_ENABLE_WEBSOCKETS\n-  ws.onEvent(wsEvent);\n-  #endif\n-\n #if defined(ARDUINO_ARCH_ESP32) && defined(WLED_USE_ETHERNET)\n-  // Only initialize ethernet board if not NONE\n-  if (ethernetType != WLED_ETH_NONE && ethernetType < WLED_NUM_ETH_TYPES) {\n-    ethernet_settings es = ethernetBoards[ethernetType];\n-    // Use PinManager to ensure pins are available for\n-    // ethernet AND to prevent other uses of these pins.\n-    bool s = true;\n-    byte pinsAllocated[4] { 255, 255, 255, 255 };\n-\n-    if (s && (s = pinManager.allocatePin((byte)es.eth_power))) {\n-      pinsAllocated[0] = (byte)es.eth_power;\n-    }\n-    if (s && (s = pinManager.allocatePin((byte)es.eth_mdc))) {\n-      pinsAllocated[1] = (byte)es.eth_mdc;\n-    }\n-    if (s && (s = pinManager.allocatePin((byte)es.eth_mdio))) {\n-      pinsAllocated[2] = (byte)es.eth_mdio;\n-    }\n-    switch(es.eth_clk_mode) {\n-      case ETH_CLOCK_GPIO0_IN:\n-        s = pinManager.allocatePin(0, false);\n-        pinsAllocated[3] = 0;\n-        break;\n-      case ETH_CLOCK_GPIO0_OUT:\n-        s = pinManager.allocatePin(0);\n-        pinsAllocated[3] = 0;\n-        break;\n-      case ETH_CLOCK_GPIO16_OUT:\n-        s = pinManager.allocatePin(16);\n-        pinsAllocated[3] = 16;\n-        break;\n-      case ETH_CLOCK_GPIO17_OUT:\n-        s = pinManager.allocatePin(17);\n-        pinsAllocated[3] = 17;\n-        break;\n-      default:\n-        s = false;\n-        break;\n-    }\n \n-    if (s) {\n-      s = ETH.begin(\n-        (uint8_t) es.eth_address, \n-        (int)     es.eth_power, \n-        (int)     es.eth_mdc, \n-        (int)     es.eth_mdio, \n-        (eth_phy_type_t)   es.eth_type,\n-        (eth_clock_mode_t) es.eth_clk_mode\n-      );\n-    }\n-    \n-    if (!s) {\n-      DEBUG_PRINTLN(F(\"Ethernet init failed\"));\n-      // de-allocate only those pins allocated before the failure\n-      for (byte p : pinsAllocated) {\n-        pinManager.deallocatePin(p);\n-      }\n+  static bool successfullyConfiguredEthernet = false;\n+\n+  if (successfullyConfiguredEthernet) {\n+    // DEBUG_PRINTLN(F(\"initE: ETH already successfully configured, ignoring\"));\n+    return false;\n+  }\n+  if (ethernetType == WLED_ETH_NONE) {\n+    return false;\n+  }\n+  if (ethernetType >= WLED_NUM_ETH_TYPES) {\n+    DEBUG_PRINT(F(\"initE: Ignoring attempt for invalid ethernetType \")); DEBUG_PRINTLN(ethernetType);\n+    return false;\n+  }\n+\n+  DEBUG_PRINT(F(\"initE: Attempting ETH config: \")); DEBUG_PRINTLN(ethernetType);\n+\n+  // Ethernet initialization should only succeed once -- else reboot required\n+  ethernet_settings es = ethernetBoards[ethernetType];\n+  managed_pin_type pinsToAllocate[10] = {\n+    // first six pins are non-configurable\n+    esp32_nonconfigurable_ethernet_pins[0],\n+    esp32_nonconfigurable_ethernet_pins[1],\n+    esp32_nonconfigurable_ethernet_pins[2],\n+    esp32_nonconfigurable_ethernet_pins[3],\n+    esp32_nonconfigurable_ethernet_pins[4],\n+    esp32_nonconfigurable_ethernet_pins[5],\n+    { (int8_t)es.eth_mdc,   true },  // [6] = MDC  is output and mandatory\n+    { (int8_t)es.eth_mdio,  true },  // [7] = MDIO is bidirectional and mandatory\n+    { (int8_t)es.eth_power, true },  // [8] = optional pin, not all boards use\n+    { ((int8_t)0xFE),       false }, // [9] = replaced with eth_clk_mode, mandatory\n+  };\n+  // update the clock pin....\n+  if (es.eth_clk_mode == ETH_CLOCK_GPIO0_IN) {\n+    pinsToAllocate[9].pin = 0;\n+    pinsToAllocate[9].isOutput = false;\n+  } else if (es.eth_clk_mode == ETH_CLOCK_GPIO0_OUT) {\n+    pinsToAllocate[9].pin = 0;\n+    pinsToAllocate[9].isOutput = true;\n+  } else if (es.eth_clk_mode == ETH_CLOCK_GPIO16_OUT) {\n+    pinsToAllocate[9].pin = 16;\n+    pinsToAllocate[9].isOutput = true;\n+  } else if (es.eth_clk_mode == ETH_CLOCK_GPIO17_OUT) {\n+    pinsToAllocate[9].pin = 17;\n+    pinsToAllocate[9].isOutput = true;\n+  } else {\n+    DEBUG_PRINT(F(\"initE: Failing due to invalid eth_clk_mode (\"));\n+    DEBUG_PRINT(es.eth_clk_mode);\n+    DEBUG_PRINTLN(F(\")\"));\n+    return false;\n+  }\n+\n+  if (!pinManager.allocateMultiplePins(pinsToAllocate, 10, PinOwner::Ethernet)) {\n+    DEBUG_PRINTLN(F(\"initE: Failed to allocate ethernet pins\"));\n+    return false;\n+  }\n+\n+  if (!ETH.begin(\n+                (uint8_t) es.eth_address, \n+                (int)     es.eth_power, \n+                (int)     es.eth_mdc, \n+                (int)     es.eth_mdio, \n+                (eth_phy_type_t)   es.eth_type,\n+                (eth_clock_mode_t) es.eth_clk_mode\n+                )) {\n+    DEBUG_PRINTLN(F(\"initC: ETH.begin() failed\"));\n+    // de-allocate the allocated pins\n+    for (managed_pin_type mpt : pinsToAllocate) {\n+      pinManager.deallocatePin(mpt.pin, PinOwner::Ethernet);\n     }\n+    return false;\n   }\n+\n+  successfullyConfiguredEthernet = true;\n+  DEBUG_PRINTLN(F(\"initC: *** Ethernet successfully configured! ***\"));\n+  return true;\n+#else\n+  return false; // Ethernet not enabled for build\n #endif\n \n+}\n+\n+void WLED::initConnection()\n+{\n+  #ifdef WLED_ENABLE_WEBSOCKETS\n+  ws.onEvent(wsEvent);\n+  #endif\n+\n+\n   WiFi.disconnect(true);        // close old connections\n #ifdef ESP8266\n   WiFi.setPhyMode(WIFI_PHY_MODE_11N);\n #endif\n \n   if (staticIP[0] != 0 && staticGateway[0] != 0) {\n-    WiFi.config(staticIP, staticGateway, staticSubnet, IPAddress(8, 8, 8, 8));\n+    WiFi.config(staticIP, staticGateway, staticSubnet, IPAddress(1, 1, 1, 1));\n   } else {\n     WiFi.config(0U, 0U, 0U);\n   }\n@@ -692,14 +727,25 @@ void WLED::handleConnection()\n   }\n }\n \n+// If status LED pin is allocated for other uses, does nothing\n+// else blink at 1Hz when WLED_CONNECTED is false (no WiFi, ?? no Ethernet ??)\n+// else blink at 2Hz when MQTT is enabled but not connected\n+// else turn the status LED off\n void WLED::handleStatusLED()\n {\n   #if STATUSLED\n-  if (pinManager.isPinAllocated(STATUSLED)) return; //lower priority if something else uses the same pin\n+  static unsigned long ledStatusLastMillis = 0;\n+  static unsigned short ledStatusType = 0; // current status type - corresponds to number of blinks per second\n+  static bool ledStatusState = 0; // the current LED state\n+\n+  if (pinManager.isPinAllocated(STATUSLED)) {\n+    return; //lower priority if something else uses the same pin\n+  }\n \n   ledStatusType = WLED_CONNECTED ? 0 : 2;\n-  if (mqttEnabled && ledStatusType != 2) // Wi-Fi takes presendence over MQTT\n+  if (mqttEnabled && ledStatusType != 2) { // Wi-Fi takes precendence over MQTT\n     ledStatusType = WLED_MQTT_CONNECTED ? 0 : 4;\n+  }\n   if (ledStatusType) {\n     if (millis() - ledStatusLastMillis >= (1000/ledStatusType)) {\n       ledStatusLastMillis = millis();\n@@ -715,4 +761,4 @@ void WLED::handleStatusLED()\n \n   }\n   #endif\n-}\n\\ No newline at end of file\n+}\ndiff --git a/wled00/wled.h b/wled00/wled.h\nindex a92c4f09ea..4148478b77 100644\n--- a/wled00/wled.h\n+++ b/wled00/wled.h\n@@ -594,12 +594,6 @@ WLED_GLOBAL bool doInitBusses _INIT(false);\n // Usermod manager\n WLED_GLOBAL UsermodManager usermods _INIT(UsermodManager());\n \n-// Status LED\n-#if STATUSLED\n-  WLED_GLOBAL unsigned long ledStatusLastMillis _INIT(0);\n-  WLED_GLOBAL unsigned short ledStatusType _INIT(0); // current status type - corresponds to number of blinks per second\n-  WLED_GLOBAL bool ledStatusState _INIT(0); // the current LED state\n-#endif\n \n // enable additional debug output\n #ifdef WLED_DEBUG\n@@ -663,6 +657,7 @@ class WLED {\n \n   void beginStrip();\n   void handleConnection();\n+  bool initEthernet(); // result is informational\n   void initAP(bool resetAP = false);\n   void initConnection();\n   void initInterfaces();\ndiff --git a/wled00/wled_ethernet.h b/wled00/wled_ethernet.h\nindex 753e02899c..4332ef5663 100644\n--- a/wled00/wled_ethernet.h\n+++ b/wled00/wled_ethernet.h\n@@ -2,7 +2,32 @@\n #define WLED_ETHERNET_H\n \n #ifdef WLED_USE_ETHERNET\n-// settings for various ethernet boards\n+#include \"pin_manager.h\"\n+\n+// The following six pins are neither configurable nor\n+// can they be re-assigned through IOMUX / GPIO matrix.\n+// See https://docs.espressif.com/projects/esp-idf/en/latest/esp32/hw-reference/esp32/get-started-ethernet-kit-v1.1.html#ip101gri-phy-interface\n+const managed_pin_type esp32_nonconfigurable_ethernet_pins[6] = {\n+    { 21, true  }, // RMII EMAC TX EN  == When high, clocks the data on TXD0 and TXD1 to transmitter\n+    { 19, true  }, // RMII EMAC TXD0   == First bit of transmitted data\n+    { 22, true  }, // RMII EMAC TXD1   == Second bit of transmitted data\n+    { 25, false }, // RMII EMAC RXD0   == First bit of received data\n+    { 26, false }, // RMII EMAC RXD1   == Second bit of received data\n+    { 27, true  }, // RMII EMAC CRS_DV == Carrier Sense and RX Data Valid\n+};\n+\n+// For ESP32, the remaining five pins are at least somewhat configurable.\n+// eth_address  is in range [0..31], indicates which PHY (MAC?) address should be allocated to the interface\n+// eth_power    is an output GPIO pin used to enable/disable the ethernet port (and/or external oscillator)\n+// eth_mdc      is an output GPIO pin used to provide the clock for the management data\n+// eth_mdio     is an input/output GPIO pin used to transfer management data\n+// eth_type     is the physical ethernet module's type (ETH_PHY_LAN8720, ETH_PHY_TLK110)\n+// eth_clk_mode defines the GPIO pin and GPIO mode for the clock signal\n+//              However, there are really only four configurable options on ESP32:\n+//              ETH_CLOCK_GPIO0_IN    == External oscillator, clock input  via GPIO0\n+//              ETH_CLOCK_GPIO0_OUT   == ESP32 provides 50MHz clock output via GPIO0\n+//              ETH_CLOCK_GPIO16_OUT  == ESP32 provides 50MHz clock output via GPIO16\n+//              ETH_CLOCK_GPIO17_OUT  == ESP32 provides 50MHz clock output via GPIO17\n typedef struct EthernetSettings {\n   uint8_t        eth_address;\n   int            eth_power;\n@@ -18,18 +43,9 @@ ethernet_settings ethernetBoards[] = {\n   },\n   \n   // WT32-EHT01\n-  // Please note, from my testing only these pins work for LED outputs:\n-  //   IO2, IO4, IO12, IO14, IO15\n-  // Pins IO34 through IO39 are input-only on ESP32, so\n-  // the following exposed pins won't work to drive WLEDs\n-  //   IO35(*), IO36, IO39\n-  // The following pins are also exposed via the headers,\n-  // and likely can be used as general purpose IO:\n-  //   IO05(*), IO32 (CFG), IO33 (485_EN), IO33 (TXD)\n-  //\n-  //   (*) silkscreen on board revision v1.2 may be wrong:\n-  //       IO5 silkscreen on v1.2 says IO35\n-  //       IO35 silkscreen on v1.2 says RXD\n+  //   (*) NOTE: silkscreen on board revision v1.2 may be wrong:\n+  //       silkscreen on v1.2 says IO35, but appears to be IO5\n+  //       silkscreen on v1.2 says RXD,  and appears to be IO35\n   {\n     1,                 // eth_address, \n     16,                // eth_power, \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "- Remove the macros for allocate/deallocate functions as their purpose is no longer relevant. \n- Enhance the `PinManager` API; avoid allowing a default for `PinOwner`. Users should consciously specify pin ownership. \n- Address Ethernet initialization issue: call `initEthernet()` in `set.cpp` after saving settings.\n- Add Ethernet pin configuration to `cfg.json` via `serializeConfig()`. Sample code provided outlines how to capture pin usage.\n- Consider implementing a JSON API to return currently allocated pins and their owners for easier debugging.\n- Explore adding iterators for `pinManager` to simplify code when listing used pins.\n- Clarify the number of pins for ESP8266 vs. ESP32 for implementation consistency."
      }
    ],
    "codediff_length": 51638
  },
  {
    "index": 36,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/wled00/FX.cpp b/wled00/FX.cpp\nindex a27fc4fbe0..1b95086d5c 100644\n--- a/wled00/FX.cpp\n+++ b/wled00/FX.cpp\n@@ -1929,22 +1929,102 @@ static const char _data_FX_MODE_JUGGLE[] PROGMEM = \"Juggle@!,Trail;;!;;sx=64,ix=\n \n \n uint16_t mode_palette() {\n-  uint16_t counter = 0;\n-  if (SEGMENT.speed != 0)\n-  {\n-    counter = (strip.now * ((SEGMENT.speed >> 3) +1)) & 0xFFFF;\n-    counter = counter >> 8;\n-  }\n-\n-  for (int i = 0; i < SEGLEN; i++)\n-  {\n-    uint8_t colorIndex = (i * 255 / SEGLEN) - counter;\n-    SEGMENT.setPixelColor(i, SEGMENT.color_from_palette(colorIndex, false, PALETTE_MOVING_WRAP, 255));\n+  // Set up some compile time constants so that we can handle integer and float based modes using the same code base.\n+#ifdef ESP8266\n+  using mathType = int32_t;\n+  using wideMathType = int64_t;\n+  using angleType = uint16_t;\n+  constexpr mathType sInt16Scale             = 0x7FFF;\n+  constexpr mathType maxAngle                = 0x8000;\n+  constexpr mathType staticRotationScale     = 256;\n+  constexpr mathType animatedRotationScale   = 1;\n+  constexpr int16_t (*sinFunction)(uint16_t) = &sin16;\n+  constexpr int16_t (*cosFunction)(uint16_t) = &cos16;\n+#else\n+  using mathType = float;\n+  using wideMathType = float;\n+  using angleType = float;\n+  constexpr mathType sInt16Scale           = 1.0f;\n+  constexpr mathType maxAngle              = M_PI / 256.0;\n+  constexpr mathType staticRotationScale   = 1.0f;\n+  constexpr mathType animatedRotationScale = M_TWOPI / double(0xFFFF);\n+  constexpr float (*sinFunction)(float)    = &sin_t;\n+  constexpr float (*cosFunction)(float)    = &cos_t;\n+#endif\n+  const bool isMatrix = strip.isMatrix;\n+  const int cols = SEGMENT.virtualWidth();\n+  const int rows = isMatrix ? SEGMENT.virtualHeight() : strip.getActiveSegmentsNum();\n+\n+  const int  inputShift           = SEGMENT.speed;\n+  const int  inputSize            = SEGMENT.intensity;\n+  const int  inputRotation        = SEGMENT.custom1;\n+  const bool inputAnimateShift    = SEGMENT.check1;\n+  const bool inputAnimateRotation = SEGMENT.check2;\n+  const bool inputAssumeSquare    = SEGMENT.check3;\n+\n+  const angleType theta = (!inputAnimateRotation) ? (inputRotation * maxAngle / staticRotationScale) : (((strip.now * ((inputRotation >> 4) +1)) & 0xFFFF) * animatedRotationScale);\n+  const mathType sinTheta = sinFunction(theta);\n+  const mathType cosTheta = cosFunction(theta);\n+\n+  const mathType maxX    = std::max(1, cols-1);\n+  const mathType maxY    = std::max(1, rows-1);\n+  // Set up some parameters according to inputAssumeSquare, so that we can handle anamorphic mode using the same code base.\n+  const mathType maxXIn  =  inputAssumeSquare ? maxX : mathType(1);\n+  const mathType maxYIn  =  inputAssumeSquare ? maxY : mathType(1);\n+  const mathType maxXOut = !inputAssumeSquare ? maxX : mathType(1);\n+  const mathType maxYOut = !inputAssumeSquare ? maxY : mathType(1);\n+  const mathType centerX = sInt16Scale * maxXOut / mathType(2);\n+  const mathType centerY = sInt16Scale * maxYOut / mathType(2);\n+  // The basic idea for this effect is to rotate a rectangle that is filled with the palette along one axis, then map our\n+  // display to it, to find what color a pixel should have.\n+  // However, we want a) no areas of solid color (in front of or behind the palette), and b) we want to make use of the full palette.\n+  // So the rectangle needs to have exactly the right size. That size depends on the rotation.\n+  // This scale computation here only considers one dimension. You can think of it like the rectangle is always scaled so that\n+  // the left and right most points always match the left and right side of the display.\n+  const mathType scale   = std::abs(sinTheta) + (std::abs(cosTheta) * maxYOut / maxXOut);\n+  // 2D simulation:\n+  // If we are dealing with a 1D setup, we assume that each segment represents one line on a 2-dimensional display.\n+  // The function is called once per segments, so we need to handle one line at a time.\n+  const int yFrom = isMatrix ? 0 : strip.getCurrSegmentId();\n+  const int yTo   = isMatrix ? maxY : yFrom;\n+  for (int y = yFrom; y <= yTo; ++y) {\n+    // translate, scale, rotate\n+    const mathType ytCosTheta = mathType((wideMathType(cosTheta) * wideMathType(y * sInt16Scale - centerY * maxYIn))/wideMathType(maxYIn * scale));\n+    for (int x = 0; x < cols; ++x) {\n+      // translate, scale, rotate\n+      const mathType xtSinTheta = mathType((wideMathType(sinTheta) * wideMathType(x * sInt16Scale - centerX * maxXIn))/wideMathType(maxXIn * scale));\n+      // Map the pixel coordinate to an imaginary-rectangle-coordinate.\n+      // The y coordinate doesn't actually matter, as our imaginary rectangle is filled with the palette from left to right,\n+      // so all points at a given x-coordinate have the same color.\n+      const mathType sourceX = xtSinTheta + ytCosTheta + centerX;\n+      // The computation was scaled just right so that the result should always be in range [0, maxXOut], but enforce this anyway\n+      // to account for imprecision. Then scale it so that the range is [0, 255], which we can use with the palette.\n+      int colorIndex = (std::min(std::max(sourceX, mathType(0)), maxXOut * sInt16Scale) * 255) / (sInt16Scale * maxXOut);\n+      // inputSize determines by how much we want to scale the palette:\n+      // values < 128 display a fraction of a palette,\n+      // values > 128 display multiple palettes.\n+      if (inputSize <= 128) {\n+        colorIndex = (colorIndex * inputSize) / 128;\n+      } else {\n+        // Linear function that maps colorIndex 128=>1, 256=>9.\n+        // With this function every full palette repetition is exactly 16 configuration steps wide.\n+        // That allows displaying exactly 2 repetitions for example.\n+        colorIndex = ((inputSize - 112) * colorIndex) / 16;\n+      }\n+      // Finally, shift the palette a bit.\n+      const int paletteOffset = (!inputAnimateShift) ? (inputShift-128) : (((strip.now * ((inputShift >> 3) +1)) & 0xFFFF) >> 8);\n+      colorIndex += paletteOffset;\n+      const uint32_t color = SEGMENT.color_wheel((uint8_t)colorIndex);\n+      if (isMatrix) {\n+        SEGMENT.setPixelColorXY(x, y, color);\n+      } else {\n+        SEGMENT.setPixelColor(x, color);\n+      }\n+    }\n   }\n-\n   return FRAMETIME;\n }\n-static const char _data_FX_MODE_PALETTE[] PROGMEM = \"Palette@Cycle speed;;!;;c3=0,o2=0\";\n+static const char _data_FX_MODE_PALETTE[] PROGMEM = \"Palette@Shift,Size,Rotation,,,Animate Shift,Animate Rotation,Anamorphic;;!;12;c1=128,c2=128,c3=128,o1=1,o2=1,o3=0\";\n \n \n // WLED limitation: Analog Clock overlay will NOT work when Fire2012 is active\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. The new effect isn't behaving closely enough to the original in 1D mode; revise to ensure it aligns better without needing to be identical. \n2. The breaking change due to differing default behaviors should be clearly marked.\n3. Address broken 2D emulation and incorrect bounds, which impair functionality in 2D setups.\n4. Consider revising the Rainbow effect to slow down and stop at speed 0 for consistency.\n5. Avoid creating multiple similar effects; ensure clarity for users.\n6. The `getCurrentSegmentId()` should be optional; be cautious about the impacts on user presets.\n7. Test changes thoroughly before pushing updates. \n8. Maintain consistent behavior across animations to reduce potential user complaints about discrepancies."
      }
    ],
    "codediff_length": 6624
  },
  {
    "index": 37,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/cores/esp8266/Tone.cpp b/cores/esp8266/Tone.cpp\nindex 064fdad5df..601b1df51d 100644\n--- a/cores/esp8266/Tone.cpp\n+++ b/cores/esp8266/Tone.cpp\n@@ -25,10 +25,6 @@\n #include \"core_esp8266_waveform.h\"\n #include \"user_interface.h\"\n \n-// Which pins have a tone running on them?\n-static uint32_t _toneMap = 0;\n-\n-\n static void _startTone(uint8_t _pin, uint32_t high, uint32_t low, uint32_t duration) {\n   if (_pin > 16) {\n     return;\n@@ -42,9 +38,7 @@ static void _startTone(uint8_t _pin, uint32_t high, uint32_t low, uint32_t durat\n   duration = microsecondsToClockCycles(duration * 1000UL);\n   duration += high + low - 1;\n   duration -= duration % (high + low);\n-  if (startWaveformClockCycles(_pin, high, low, duration)) {\n-    _toneMap |= 1 << _pin;\n-  }\n+  startWaveformClockCycles(_pin, high, low, duration);\n }\n \n \n@@ -86,6 +80,5 @@ void noTone(uint8_t _pin) {\n     return;\n   }\n   stopWaveform(_pin);\n-  _toneMap &= ~(1 << _pin);\n   digitalWrite(_pin, 0);\n }\ndiff --git a/cores/esp8266/core_esp8266_waveform.cpp b/cores/esp8266/core_esp8266_waveform.cpp\nindex 597a8e88ab..952e1fd197 100644\n--- a/cores/esp8266/core_esp8266_waveform.cpp\n+++ b/cores/esp8266/core_esp8266_waveform.cpp\n@@ -3,6 +3,7 @@\n                      supporting outputs on all pins in parallel.\n \n   Copyright (c) 2018 Earle F. Philhower, III.  All rights reserved.\n+  Copyright (c) 2020 Dirk O. Kaar.\n \n   The core idea is to have a programmable waveform generator with a unique\n   high and low period (defined in microseconds or CPU clock cycles).  TIMER1 is\n@@ -19,8 +20,8 @@\n \n   This replaces older tone(), analogWrite(), and the Servo classes.\n \n-  Everywhere in the code where \"cycles\" is used, it means ESP.getCycleCount()\n-  clock cycle count, or an interval measured in CPU clock cycles, but not TIMER1\n+  Everywhere in the code where \"ccy\" or \"ccys\" is used, it means ESP.getCycleCount()\n+  clock cycle time, or an interval measured in clock cycles, but not TIMER1\n   cycles (which may be 2 CPU clock cycles @ 160MHz).\n \n   This library is free software; you can redistribute it and/or\n@@ -38,275 +39,398 @@\n   Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n */\n \n+#include \"core_esp8266_waveform.h\"\n #include <Arduino.h>\n #include \"ets_sys.h\"\n-#include \"core_esp8266_waveform.h\"\n-\n-extern \"C\" {\n-\n-// Maximum delay between IRQs\n-#define MAXIRQUS (10000)\n-\n-// Set/clear GPIO 0-15 by bitmask\n-#define SetGPIO(a) do { GPOS = a; } while (0)\n-#define ClearGPIO(a) do { GPOC = a; } while (0)\n+#include <atomic>\n+\n+// Timer is 80MHz fixed. 160MHz CPU frequency need scaling.\n+constexpr bool ISCPUFREQ160MHZ = clockCyclesPerMicrosecond() == 160;\n+// Maximum delay between IRQs, Timer1, <= 2^23 / 80MHz\n+constexpr int32_t MAXIRQTICKSCCYS = microsecondsToClockCycles(10000);\n+// Maximum servicing time for any single IRQ\n+constexpr uint32_t ISRTIMEOUTCCYS = microsecondsToClockCycles(18);\n+// The latency between in-ISR rearming of the timer and the earliest firing\n+constexpr int32_t IRQLATENCYCCYS = microsecondsToClockCycles(2);\n+// The SDK and hardware take some time to actually get to our NMI code\n+constexpr int32_t DELTAIRQCCYS = ISCPUFREQ160MHZ ?\n+  microsecondsToClockCycles(2) >> 1 : microsecondsToClockCycles(2);\n+\n+// for INFINITE, the NMI proceeds on the waveform without expiry deadline.\n+// for EXPIRES, the NMI expires the waveform automatically on the expiry ccy.\n+// for UPDATEEXPIRY, the NMI recomputes the exact expiry ccy and transitions to EXPIRES.\n+// for INIT, the NMI initializes nextPeriodCcy, and if expiryCcy != 0 includes UPDATEEXPIRY.\n+enum class WaveformMode : uint8_t {INFINITE = 0, EXPIRES = 1, UPDATEEXPIRY = 2, INIT = 3};\n \n // Waveform generator can create tones, PWM, and servos\n typedef struct {\n-  uint32_t nextServiceCycle;   // ESP cycle timer when a transition required\n-  uint32_t expiryCycle;        // For time-limited waveform, the cycle when this waveform must stop\n-  uint32_t nextTimeHighCycles; // Copy over low->high to keep smooth waveform\n-  uint32_t nextTimeLowCycles;  // Copy over high->low to keep smooth waveform\n+  uint32_t nextPeriodCcy; // ESP clock cycle when a period begins. If WaveformMode::INIT, temporarily holds positive phase offset ccy count\n+  uint32_t endDutyCcy;    // ESP clock cycle when going from duty to off\n+  int32_t dutyCcys;       // Set next off cycle at low->high to maintain phase\n+  int32_t adjDutyCcys;    // Temporary correction for next period\n+  int32_t periodCcys;     // Set next phase cycle at low->high to maintain phase\n+  uint32_t expiryCcy;     // For time-limited waveform, the CPU clock cycle when this waveform must stop. If WaveformMode::UPDATE, temporarily holds relative ccy count\n+  WaveformMode mode;\n+  int8_t alignPhase;      // < 0 no phase alignment, otherwise starts waveform in relative phase offset to given pin\n+  bool autoPwm;           // perform PWM duty to idle cycle ratio correction under high load at the expense of precise timings\n } Waveform;\n \n-static Waveform waveform[17];        // State of all possible pins\n-static volatile uint32_t waveformState = 0;   // Is the pin high or low, updated in NMI so no access outside the NMI code\n-static volatile uint32_t waveformEnabled = 0; // Is it actively running, updated in NMI so no access outside the NMI code\n+namespace {\n \n-// Enable lock-free by only allowing updates to waveformState and waveformEnabled from IRQ service routine\n-static volatile uint32_t waveformToEnable = 0;  // Message to the NMI handler to start a waveform on a inactive pin\n-static volatile uint32_t waveformToDisable = 0; // Message to the NMI handler to disable a pin from waveform generation\n+  static struct {\n+    Waveform pins[17];             // State of all possible pins\n+    uint32_t states = 0;           // Is the pin high or low, updated in NMI so no access outside the NMI code\n+    uint32_t enabled = 0; // Is it actively running, updated in NMI so no access outside the NMI code\n \n-static uint32_t (*timer1CB)() = NULL;\n+    // Enable lock-free by only allowing updates to waveform.states and waveform.enabled from IRQ service routine\n+    int32_t toSetBits = 0;     // Message to the NMI handler to start/modify exactly one waveform\n+    int32_t toDisableBits = 0; // Message to the NMI handler to disable exactly one pin from waveform generation\n \n+    uint32_t(*timer1CB)() = nullptr;\n \n-// Non-speed critical bits\n-#pragma GCC optimize (\"Os\")\n+    bool timer1Running = false;\n+\n+    uint32_t nextEventCcy;\n+  } waveform;\n \n-static inline ICACHE_RAM_ATTR uint32_t GetCycleCount() {\n-  uint32_t ccount;\n-  __asm__ __volatile__(\"esync; rsr %0,ccount\":\"=a\"(ccount));\n-  return ccount;\n }\n \n // Interrupt on/off control\n static ICACHE_RAM_ATTR void timer1Interrupt();\n-static bool timerRunning = false;\n+\n+// Non-speed critical bits\n+#pragma GCC optimize (\"Os\")\n \n static void initTimer() {\n   timer1_disable();\n   ETS_FRC_TIMER1_INTR_ATTACH(NULL, NULL);\n   ETS_FRC_TIMER1_NMI_INTR_ATTACH(timer1Interrupt);\n   timer1_enable(TIM_DIV1, TIM_EDGE, TIM_SINGLE);\n-  timerRunning = true;\n+  waveform.timer1Running = true;\n+  timer1_write(IRQLATENCYCCYS); // Cause an interrupt post-haste\n }\n \n static void ICACHE_RAM_ATTR deinitTimer() {\n   ETS_FRC_TIMER1_NMI_INTR_ATTACH(NULL);\n   timer1_disable();\n   timer1_isr_init();\n-  timerRunning = false;\n+  waveform.timer1Running = false;\n }\n \n+extern \"C\" {\n+\n // Set a callback.  Pass in NULL to stop it\n void setTimer1Callback(uint32_t (*fn)()) {\n-  timer1CB = fn;\n-  if (!timerRunning && fn) {\n+  waveform.timer1CB = fn;\n+  std::atomic_thread_fence(std::memory_order_acq_rel);\n+  if (!waveform.timer1Running && fn) {\n     initTimer();\n-    timer1_write(microsecondsToClockCycles(1)); // Cause an interrupt post-haste\n-  } else if (timerRunning && !fn && !waveformEnabled) {\n+  } else if (waveform.timer1Running && !fn && !waveform.enabled) {\n     deinitTimer();\n   }\n }\n \n+int startWaveform(uint8_t pin, uint32_t highUS, uint32_t lowUS,\n+  uint32_t runTimeUS, int8_t alignPhase, uint32_t phaseOffsetUS, bool autoPwm) {\n+  return startWaveformClockCycles(pin,\n+    microsecondsToClockCycles(highUS), microsecondsToClockCycles(lowUS),\n+    microsecondsToClockCycles(runTimeUS), alignPhase, microsecondsToClockCycles(phaseOffsetUS), autoPwm);\n+}\n+\n // Start up a waveform on a pin, or change the current one.  Will change to the new\n // waveform smoothly on next low->high transition.  For immediate change, stopWaveform()\n // first, then it will immediately begin.\n-int startWaveform(uint8_t pin, uint32_t timeHighUS, uint32_t timeLowUS, uint32_t runTimeUS) {\n-  return startWaveformClockCycles(pin, microsecondsToClockCycles(timeHighUS), microsecondsToClockCycles(timeLowUS), microsecondsToClockCycles(runTimeUS));\n-}\n-\n-int startWaveformClockCycles(uint8_t pin, uint32_t timeHighCycles, uint32_t timeLowCycles, uint32_t runTimeCycles) {\n-   if ((pin > 16) || isFlashInterfacePin(pin)) {\n-    return false;\n+int startWaveformClockCycles(uint8_t pin, uint32_t highCcys, uint32_t lowCcys,\n+  uint32_t runTimeCcys, int8_t alignPhase, uint32_t phaseOffsetCcys, bool autoPwm) {\n+  uint32_t periodCcys = highCcys + lowCcys;\n+  if (periodCcys < MAXIRQTICKSCCYS) {\n+    if (!highCcys) {\n+      periodCcys = (MAXIRQTICKSCCYS / periodCcys) * periodCcys;\n+    }\n+    else if (!lowCcys) {\n+      highCcys = periodCcys = (MAXIRQTICKSCCYS / periodCcys) * periodCcys;\n+    }\n   }\n-  Waveform *wave = &waveform[pin];\n-  // Adjust to shave off some of the IRQ time, approximately\n-  wave->nextTimeHighCycles = timeHighCycles;\n-  wave->nextTimeLowCycles = timeLowCycles;\n-  wave->expiryCycle = runTimeCycles ? GetCycleCount() + runTimeCycles : 0;\n-  if (runTimeCycles && !wave->expiryCycle) {\n-    wave->expiryCycle = 1; // expiryCycle==0 means no timeout, so avoid setting it\n+  // sanity checks, including mixed signed/unsigned arithmetic safety\n+  if ((pin > 16) || isFlashInterfacePin(pin) || (alignPhase > 16) ||\n+    static_cast<int32_t>(periodCcys) <= 0 ||\n+    static_cast<int32_t>(highCcys) < 0 || static_cast<int32_t>(lowCcys) < 0) {\n+    return false;\n   }\n-\n-  uint32_t mask = 1<<pin;\n-  if (!(waveformEnabled & mask)) {\n-    // Actually set the pin high or low in the IRQ service to guarantee times\n-    wave->nextServiceCycle = GetCycleCount() + microsecondsToClockCycles(1);\n-    waveformToEnable |= mask;\n-    if (!timerRunning) {\n-      initTimer();\n-      timer1_write(microsecondsToClockCycles(10));\n-    } else {\n-      // Ensure timely service....\n-      if (T1L > microsecondsToClockCycles(10)) {\n-        timer1_write(microsecondsToClockCycles(10));\n+  Waveform& wave = waveform.pins[pin];\n+  wave.dutyCcys = highCcys;\n+  wave.adjDutyCcys = 0;\n+  wave.periodCcys = periodCcys;\n+  wave.autoPwm = autoPwm;\n+\n+  std::atomic_thread_fence(std::memory_order_acquire);\n+  const uint32_t pinBit = 1UL << pin;\n+  if (!(waveform.enabled & pinBit)) {\n+    // wave.nextPeriodCcy and wave.endDutyCcy are initialized by the ISR\n+    wave.nextPeriodCcy = phaseOffsetCcys;\n+    wave.expiryCcy = runTimeCcys; // in WaveformMode::INIT, temporarily hold relative cycle count\n+    wave.mode = WaveformMode::INIT;\n+    wave.alignPhase = (alignPhase < 0) ? -1 : alignPhase;\n+    if (!wave.dutyCcys) {\n+      // If initially at zero duty cycle, force GPIO off\n+      if (pin == 16) {\n+        GP16O = 0;\n       }\n+      else {\n+        GPOC = pinBit;\n+      }\n+    }\n+    std::atomic_thread_fence(std::memory_order_release);\n+    waveform.toSetBits = 1UL << pin;\n+    std::atomic_thread_fence(std::memory_order_release);\n+    if (!waveform.timer1Running) {\n+      initTimer();\n     }\n-    while (waveformToEnable) {\n-      delay(0); // Wait for waveform to update\n+    else if (T1V > IRQLATENCYCCYS) {\n+      // Must not interfere if Timer is due shortly\n+      timer1_write(IRQLATENCYCCYS);\n     }\n   }\n-\n-  return true;\n-}\n-\n-// Speed critical bits\n-#pragma GCC optimize (\"O2\")\n-// Normally would not want two copies like this, but due to different\n-// optimization levels the inline attribute gets lost if we try the\n-// other version.\n-\n-static inline ICACHE_RAM_ATTR uint32_t GetCycleCountIRQ() {\n-  uint32_t ccount;\n-  __asm__ __volatile__(\"rsr %0,ccount\":\"=a\"(ccount));\n-  return ccount;\n-}\n-\n-static inline ICACHE_RAM_ATTR uint32_t min_u32(uint32_t a, uint32_t b) {\n-  if (a < b) {\n-    return a;\n+  else {\n+    wave.mode = WaveformMode::INFINITE; // turn off possible expiry to make update atomic from NMI\n+    std::atomic_thread_fence(std::memory_order_release);\n+    wave.expiryCcy = runTimeCcys; // in WaveformMode::UPDATEEXPIRY, temporarily hold relative cycle count\n+    if (runTimeCcys) {\n+      wave.mode = WaveformMode::UPDATEEXPIRY;\n+      std::atomic_thread_fence(std::memory_order_release);\n+      waveform.toSetBits = 1UL << pin;\n+    }\n   }\n-  return b;\n+  std::atomic_thread_fence(std::memory_order_acq_rel);\n+  while (waveform.toSetBits) {\n+    delay(0); // Wait for waveform to update\n+    std::atomic_thread_fence(std::memory_order_acquire);\n+  }\n+  return true;\n }\n \n // Stops a waveform on a pin\n int ICACHE_RAM_ATTR stopWaveform(uint8_t pin) {\n   // Can't possibly need to stop anything if there is no timer active\n-  if (!timerRunning) {\n+  if (!waveform.timer1Running) {\n     return false;\n   }\n   // If user sends in a pin >16 but <32, this will always point to a 0 bit\n   // If they send >=32, then the shift will result in 0 and it will also return false\n-  if (waveformEnabled & (1UL << pin)) {\n-    waveformToDisable = 1UL << pin;\n+  std::atomic_thread_fence(std::memory_order_acquire);\n+  const uint32_t pinBit = 1UL << pin;\n+  if (waveform.enabled & pinBit) {\n+    waveform.toDisableBits = 1UL << pin;\n+    std::atomic_thread_fence(std::memory_order_release);\n     // Must not interfere if Timer is due shortly\n-    if (T1L > microsecondsToClockCycles(10)) {\n-      timer1_write(microsecondsToClockCycles(10));\n+    if (T1V > IRQLATENCYCCYS) {\n+      timer1_write(IRQLATENCYCCYS);\n     }\n-    while (waveformToDisable) {\n+    while (waveform.toDisableBits) {\n       /* no-op */ // Can't delay() since stopWaveform may be called from an IRQ\n+      std::atomic_thread_fence(std::memory_order_acquire);\n     }\n   }\n-  if (!waveformEnabled && !timer1CB) {\n+  if (!waveform.enabled && !waveform.timer1CB) {\n     deinitTimer();\n   }\n   return true;\n }\n \n-// The SDK and hardware take some time to actually get to our NMI code, so\n-// decrement the next IRQ's timer value by a bit so we can actually catch the\n-// real CPU cycle counter we want for the waveforms.\n-#if F_CPU == 80000000\n-  #define DELTAIRQ (microsecondsToClockCycles(3))\n-#else\n-  #define DELTAIRQ (microsecondsToClockCycles(2))\n-#endif\n-\n+};\n \n-static ICACHE_RAM_ATTR void timer1Interrupt() {\n-  // Optimize the NMI inner loop by keeping track of the min and max GPIO that we\n-  // are generating.  In the common case (1 PWM) these may be the same pin and\n-  // we can avoid looking at the other pins.\n-  static int startPin = 0;\n-  static int endPin = 0;\n+// Speed critical bits\n+#pragma GCC optimize (\"O2\")\n \n-  uint32_t nextEventCycles = microsecondsToClockCycles(MAXIRQUS);\n-  uint32_t timeoutCycle = GetCycleCountIRQ() + microsecondsToClockCycles(14);\n+// For dynamic CPU clock frequency switch in loop the scaling logic would have to be adapted.\n+// Using constexpr makes sure that the CPU clock frequency is compile-time fixed.\n+static inline ICACHE_RAM_ATTR int32_t scaleCcys(const int32_t ccys, const bool isCPU2X) {\n+  if (ISCPUFREQ160MHZ) {\n+    return isCPU2X ? ccys : (ccys >> 1);\n+  }\n+  else {\n+    return isCPU2X ? (ccys << 1) : ccys;\n+  }\n+}\n \n-  if (waveformToEnable || waveformToDisable) {\n+static ICACHE_RAM_ATTR void timer1Interrupt() {\n+  const uint32_t isrStartCcy = ESP.getCycleCount();\n+  int32_t clockDrift = isrStartCcy - waveform.nextEventCcy;\n+  const bool isCPU2X = CPU2X & 1;\n+  if ((waveform.toSetBits && !(waveform.enabled & waveform.toSetBits)) || waveform.toDisableBits) {\n     // Handle enable/disable requests from main app.\n-    waveformEnabled = (waveformEnabled & ~waveformToDisable) | waveformToEnable; // Set the requested waveforms on/off\n-    waveformState &= ~waveformToEnable;  // And clear the state of any just started\n-    waveformToEnable = 0;\n-    waveformToDisable = 0;\n+    waveform.enabled = (waveform.enabled & ~waveform.toDisableBits) | waveform.toSetBits; // Set the requested waveforms on/off\n     // Find the first GPIO being generated by checking GCC's find-first-set (returns 1 + the bit of the first 1 in an int32_t)\n-    startPin = __builtin_ffs(waveformEnabled) - 1;\n-    // Find the last bit by subtracting off GCC's count-leading-zeros (no offset in this one)\n-    endPin = 32 - __builtin_clz(waveformEnabled);\n+    waveform.toDisableBits = 0;\n   }\n \n-  bool done = false;\n-  if (waveformEnabled) {\n-    do {\n-      nextEventCycles = microsecondsToClockCycles(MAXIRQUS);\n-      for (int i = startPin; i <= endPin; i++) {\n-        uint32_t mask = 1<<i;\n-\n-        // If it's not on, ignore!\n-        if (!(waveformEnabled & mask)) {\n-          continue;\n-        }\n+  if (waveform.toSetBits) {\n+    const int toSetPin = __builtin_ffs(waveform.toSetBits) - 1;\n+    Waveform& wave = waveform.pins[toSetPin];\n+    switch (wave.mode) {\n+    case WaveformMode::INIT:\n+      waveform.states &= ~waveform.toSetBits; // Clear the state of any just started\n+      if (wave.alignPhase >= 0 && waveform.enabled & (1UL << wave.alignPhase)) {\n+        wave.nextPeriodCcy = waveform.pins[wave.alignPhase].nextPeriodCcy + wave.nextPeriodCcy;\n+      }\n+      else {\n+        wave.nextPeriodCcy = waveform.nextEventCcy;\n+      }\n+      if (!wave.expiryCcy) {\n+        wave.mode = WaveformMode::INFINITE;\n+        break;\n+      }\n+      // fall through\n+    case WaveformMode::UPDATEEXPIRY:\n+      // in WaveformMode::UPDATEEXPIRY, expiryCcy temporarily holds relative CPU cycle count\n+      wave.expiryCcy = wave.nextPeriodCcy + scaleCcys(wave.expiryCcy, isCPU2X);\n+      wave.mode = WaveformMode::EXPIRES;\n+      break;\n+    default:\n+      break;\n+    }\n+    waveform.toSetBits = 0;\n+  }\n \n-        Waveform *wave = &waveform[i];\n-        uint32_t now = GetCycleCountIRQ();\n+  // Exit the loop if the next event, if any, is sufficiently distant.\n+  const uint32_t isrTimeoutCcy = isrStartCcy + ISRTIMEOUTCCYS;\n+  uint32_t busyPins = waveform.enabled;\n+  waveform.nextEventCcy = isrStartCcy + MAXIRQTICKSCCYS;\n+\n+  uint32_t now = ESP.getCycleCount();\n+  uint32_t isrNextEventCcy = now;\n+  while (busyPins) {\n+    if (static_cast<int32_t>(isrNextEventCcy - now) > IRQLATENCYCCYS) {\n+      waveform.nextEventCcy = isrNextEventCcy;\n+      break;\n+    }\n+    isrNextEventCcy = waveform.nextEventCcy;\n+    uint32_t loopPins = busyPins;\n+    while (loopPins) {\n+      const int pin = __builtin_ffsl(loopPins) - 1;\n+      const uint32_t pinBit = 1UL << pin;\n+      loopPins ^= pinBit;\n+\n+      Waveform& wave = waveform.pins[pin];\n+\n+      if (clockDrift) {\n+        wave.endDutyCcy += clockDrift;\n+        wave.nextPeriodCcy += clockDrift;\n+        wave.expiryCcy += clockDrift;\n+      }\n \n+      uint32_t waveNextEventCcy = (waveform.states & pinBit) ? wave.endDutyCcy : wave.nextPeriodCcy;\n+      if (WaveformMode::EXPIRES == wave.mode &&\n+        static_cast<int32_t>(waveNextEventCcy - wave.expiryCcy) >= 0 &&\n+        static_cast<int32_t>(now - wave.expiryCcy) >= 0) {\n         // Disable any waveforms that are done\n-        if (wave->expiryCycle) {\n-          int32_t expiryToGo = wave->expiryCycle - now;\n-          if (expiryToGo < 0) {\n-              // Done, remove!\n-              waveformEnabled &= ~mask;\n-              if (i == 16) {\n-                GP16O &= ~1;\n-              } else {\n-                ClearGPIO(mask);\n+        waveform.enabled ^= pinBit;\n+        busyPins ^= pinBit;\n+      }\n+      else {\n+        const int32_t overshootCcys = now - waveNextEventCcy;\n+        if (overshootCcys >= 0) {\n+          const int32_t periodCcys = scaleCcys(wave.periodCcys, isCPU2X);\n+          if (waveform.states & pinBit) {\n+            // active configuration and forward are 100% duty\n+            if (wave.periodCcys == wave.dutyCcys) {\n+              wave.nextPeriodCcy += periodCcys;\n+              wave.endDutyCcy = wave.nextPeriodCcy;\n+            }\n+            else {\n+              if (wave.autoPwm) {\n+                wave.adjDutyCcys += overshootCcys;\n+              }\n+              waveform.states ^= pinBit;\n+              if (16 == pin) {\n+                GP16O = 0;\n+              }\n+              else {\n+                GPOC = pinBit;\n               }\n-              continue;\n             }\n-        }\n-\n-        // Check for toggles\n-        int32_t cyclesToGo = wave->nextServiceCycle - now;\n-        if (cyclesToGo < 0) {\n-          waveformState ^= mask;\n-          if (waveformState & mask) {\n-            if (i == 16) {\n-              GP16O |= 1; // GPIO16 write slow as it's RMW\n-            } else {\n-              SetGPIO(mask);\n+            waveNextEventCcy = wave.nextPeriodCcy;\n+          }\n+          else {\n+            wave.nextPeriodCcy += periodCcys;\n+            if (!wave.dutyCcys) {\n+              wave.endDutyCcy = wave.nextPeriodCcy;\n             }\n-            wave->nextServiceCycle = now + wave->nextTimeHighCycles;\n-            nextEventCycles = min_u32(nextEventCycles, wave->nextTimeHighCycles);\n-          } else {\n-            if (i == 16) {\n-              GP16O &= ~1; // GPIO16 write slow as it's RMW\n-            } else {\n-              ClearGPIO(mask);\n+            else {\n+              int32_t dutyCcys = scaleCcys(wave.dutyCcys, isCPU2X);\n+              if (dutyCcys <= wave.adjDutyCcys) {\n+                dutyCcys >>= 1;\n+                wave.adjDutyCcys -= dutyCcys;\n+              }\n+              else if (wave.adjDutyCcys) {\n+                dutyCcys -= wave.adjDutyCcys;\n+                wave.adjDutyCcys = 0;\n+              }\n+              wave.endDutyCcy = now + dutyCcys;\n+              if (static_cast<int32_t>(wave.endDutyCcy - wave.nextPeriodCcy) > 0) {\n+                wave.endDutyCcy = wave.nextPeriodCcy;\n+              }\n+              waveform.states |= pinBit;\n+              if (16 == pin) {\n+                GP16O = 1;\n+              }\n+              else {\n+                GPOS = pinBit;\n+              }\n             }\n-            wave->nextServiceCycle = now + wave->nextTimeLowCycles;\n-            nextEventCycles = min_u32(nextEventCycles, wave->nextTimeLowCycles);\n+            waveNextEventCcy = wave.endDutyCcy;\n+          }\n+\n+          if (WaveformMode::EXPIRES == wave.mode && static_cast<int32_t>(waveNextEventCcy - wave.expiryCcy) > 0) {\n+            waveNextEventCcy = wave.expiryCcy;\n+          }\n+        }\n+\n+        if (static_cast<int32_t>(waveNextEventCcy - isrTimeoutCcy) >= 0) {\n+          busyPins ^= pinBit;\n+          if (static_cast<int32_t>(waveform.nextEventCcy - waveNextEventCcy) > 0) {\n+            waveform.nextEventCcy = waveNextEventCcy;\n           }\n-        } else {\n-          uint32_t deltaCycles = wave->nextServiceCycle - now;\n-          nextEventCycles = min_u32(nextEventCycles, deltaCycles);\n+        }\n+        else if (static_cast<int32_t>(isrNextEventCcy - waveNextEventCcy) > 0) {\n+          isrNextEventCcy = waveNextEventCcy;\n         }\n       }\n+      now = ESP.getCycleCount();\n+    }\n+    clockDrift = 0;\n+  }\n \n-      // Exit the loop if we've hit the fixed runtime limit or the next event is known to be after that timeout would occur\n-      uint32_t now = GetCycleCountIRQ();\n-      int32_t cycleDeltaNextEvent = timeoutCycle - (now + nextEventCycles);\n-      int32_t cyclesLeftTimeout = timeoutCycle - now;\n-      done = (cycleDeltaNextEvent < 0) || (cyclesLeftTimeout < 0);\n-    } while (!done);\n-  } // if (waveformEnabled)\n+  int32_t callbackCcys = 0;\n+  if (waveform.timer1CB) {\n+    callbackCcys = scaleCcys(microsecondsToClockCycles(waveform.timer1CB()), isCPU2X);\n+  }\n+  now = ESP.getCycleCount();\n+  int32_t nextEventCcys = waveform.nextEventCcy - now;\n+  // Account for unknown duration of timer1CB().\n+  if (waveform.timer1CB && nextEventCcys > callbackCcys) {\n+    waveform.nextEventCcy = now + callbackCcys;\n+    nextEventCcys = callbackCcys;\n+  }\n \n-  if (timer1CB) {\n-    nextEventCycles = min_u32(nextEventCycles, timer1CB());\n+  // Timer is 80MHz fixed. 160MHz CPU frequency need scaling.\n+  int32_t deltaIrqCcys = DELTAIRQCCYS;\n+  int32_t irqLatencyCcys = IRQLATENCYCCYS;\n+  if (isCPU2X) {\n+    nextEventCcys >>= 1;\n+    deltaIrqCcys >>= 1;\n+    irqLatencyCcys >>= 1;\n   }\n \n-  if (nextEventCycles < microsecondsToClockCycles(10)) {\n-    nextEventCycles = microsecondsToClockCycles(10);\n+  // Firing timer too soon, the NMI occurs before ISR has returned.\n+  if (nextEventCcys < irqLatencyCcys + deltaIrqCcys) {\n+    waveform.nextEventCcy = now + IRQLATENCYCCYS + DELTAIRQCCYS;\n+    nextEventCcys = irqLatencyCcys;\n+  }\n+  else {\n+    nextEventCcys -= deltaIrqCcys;\n   }\n-  nextEventCycles -= DELTAIRQ;\n-\n-  // Do it here instead of global function to save time and because we know it's edge-IRQ\n-#if F_CPU == 160000000\n-  T1L = nextEventCycles >> 1; // Already know we're in range by MAXIRQUS\n-#else\n-  T1L = nextEventCycles; // Already know we're in range by MAXIRQUS\n-#endif\n-  TEIE |= TEIE1; // Edge int enable\n-}\n \n-};\n+  // Register access is fast and edge IRQ was configured before.\n+  T1L = nextEventCcys;\n+}\ndiff --git a/cores/esp8266/core_esp8266_waveform.h b/cores/esp8266/core_esp8266_waveform.h\nindex e42a17f89f..61cb999664 100644\n--- a/cores/esp8266/core_esp8266_waveform.h\n+++ b/cores/esp8266/core_esp8266_waveform.h\n@@ -3,6 +3,7 @@\n                      supporting outputs on all pins in parallel.\n \n   Copyright (c) 2018 Earle F. Philhower, III.  All rights reserved.\n+  Copyright (c) 2020 Dirk O. Kaar.\n \n   The core idea is to have a programmable waveform generator with a unique\n   high and low period (defined in microseconds or CPU clock cycles).  TIMER1 is\n@@ -19,7 +20,7 @@\n \n   This replaces older tone(), analogWrite(), and the Servo classes.\n \n-  Everywhere in the code where \"cycles\" is used, it means ESP.getCycleCount()\n+  Everywhere in the code where \"ccy\" or \"ccys\" is used, it means ESP.getCycleCount()\n   clock cycle count, or an interval measured in CPU clock cycles, but not TIMER1\n   cycles (which may be 2 CPU clock cycles @ 160MHz).\n \n@@ -48,13 +49,25 @@ extern \"C\" {\n #endif\n \n // Start or change a waveform of the specified high and low times on specific pin.\n-// If runtimeUS > 0 then automatically stop it after that many usecs.\n+// If runtimeUS > 0 then automatically stop it after that many usecs, relative to the next\n+// full period.\n+// If waveform is not yet started on pin, and on pin == alignPhase a waveform is running,\n+// the new waveform is started at phaseOffsetUS phase offset, in microseconds, to that.\n+// Setting autoPwm to true allows the wave generator to maintain PWM duty to idle cycle ratio\n+// under load, for applications where frequency or duty cycle must not change, leave false.\n // Returns true or false on success or failure.\n-int startWaveform(uint8_t pin, uint32_t timeHighUS, uint32_t timeLowUS, uint32_t runTimeUS);\n+int startWaveform(uint8_t pin, uint32_t timeHighUS, uint32_t timeLowUS,\n+  uint32_t runTimeUS = 0, int8_t alignPhase = -1, uint32_t phaseOffsetUS = 0, bool autoPwm = false);\n // Start or change a waveform of the specified high and low CPU clock cycles on specific pin.\n-// If runtimeCycles > 0 then automatically stop it after that many CPU clock cycles.\n+// If runtimeCycles > 0 then automatically stop it after that many CPU clock cycles, relative to the next\n+// full period.\n+// If waveform is not yet started on pin, and on pin == alignPhase a waveform is running,\n+// the new waveform is started at phaseOffsetCcys phase offset, in CPU clock cycles, to that.\n+// Setting autoPwm to true allows the wave generator to maintain PWM duty to idle cycle ratio\n+// under load, for applications where frequency or duty cycle must not change, leave false.\n // Returns true or false on success or failure.\n-int startWaveformClockCycles(uint8_t pin, uint32_t timeHighCycles, uint32_t timeLowCycles, uint32_t runTimeCycles);\n+int startWaveformClockCycles(uint8_t pin, uint32_t timeHighCcys, uint32_t timeLowCcys,\n+  uint32_t runTimeCcys = 0, int8_t alignPhase = -1, uint32_t phaseOffsetCcys = 0, bool autoPwm = false);\n // Stop a waveform, if any, on the specified pin.\n // Returns true or false on success or failure.\n int stopWaveform(uint8_t pin);\ndiff --git a/cores/esp8266/core_esp8266_wiring_pwm.cpp b/cores/esp8266/core_esp8266_wiring_pwm.cpp\nindex b4991310d3..6f655716db 100644\n--- a/cores/esp8266/core_esp8266_wiring_pwm.cpp\n+++ b/cores/esp8266/core_esp8266_wiring_pwm.cpp\n@@ -45,8 +45,8 @@ extern void __analogWriteResolution(int res) {\n extern void __analogWriteFreq(uint32_t freq) {\n   if (freq < 100) {\n     analogFreq = 100;\n-  } else if (freq > 40000) {\n-    analogFreq = 40000;\n+  } else if (freq > 60000) {\n+    analogFreq = 60000;\n   } else {\n     analogFreq = freq;\n   }\n@@ -63,22 +63,22 @@ extern void __analogWrite(uint8_t pin, int val) {\n     val = analogScale;\n   }\n \n+  if (analogMap & 1UL << pin) {\n   // Per the Arduino docs at https://www.arduino.cc/reference/en/language/functions/analog-io/analogwrite/\n   // val: the duty cycle: between 0 (always off) and 255 (always on).\n   // So if val = 0 we have digitalWrite(LOW), if we have val==range we have digitalWrite(HIGH)\n \n-  analogMap &= ~(1 << pin);\n+    analogMap &= ~(1 << pin);\n+  }\n+  else {\n+    pinMode(pin, OUTPUT);\n+  }\n   uint32_t high = (analogPeriod * val) / analogScale;\n   uint32_t low = analogPeriod - high;\n-  pinMode(pin, OUTPUT);\n-  if (low == 0) {\n-    digitalWrite(pin, HIGH);\n-  } else if (high == 0) {\n-    digitalWrite(pin, LOW);\n-  } else {\n-    if (startWaveformClockCycles(pin, high, low, 0)) {\n-      analogMap |= (1 << pin);\n-    }\n+  // Find the first GPIO being generated by checking GCC's find-first-set (returns 1 + the bit of the first 1 in an int32_t)\n+  int phaseReference = __builtin_ffs(analogMap) - 1;\n+  if (startWaveformClockCycles(pin, high, low, 0, phaseReference, 0, true)) {\n+    analogMap |= (1 << pin);\n   }\n }\n \ndiff --git a/libraries/Servo/src/Servo.cpp b/libraries/Servo/src/Servo.cpp\nindex aff9afebbe..cacbbebba4 100644\n--- a/libraries/Servo/src/Servo.cpp\n+++ b/libraries/Servo/src/Servo.cpp\n@@ -69,8 +69,8 @@ uint8_t Servo::attach(int pin, uint16_t minUs, uint16_t maxUs)\n uint8_t Servo::attach(int pin, uint16_t minUs, uint16_t maxUs, int value)\n {\n   if (!_attached) {\n-    digitalWrite(pin, LOW);\n     pinMode(pin, OUTPUT);\n+    digitalWrite(pin, LOW);\n     _pin = pin;\n     _attached = true;\n   }\n@@ -115,7 +115,9 @@ void Servo::writeMicroseconds(int value)\n   _valueUs = value;\n   if (_attached) {\n     _servoMap &= ~(1 << _pin);\n-    if (startWaveform(_pin, _valueUs, REFRESH_INTERVAL - _valueUs, 0)) {\n+    // Find the first GPIO being generated by checking GCC's find-first-set (returns 1 + the bit of the first 1 in an int32_t)\n+    int phaseReference = __builtin_ffs(_servoMap) - 1;\n+    if (startWaveform(_pin, _valueUs, REFRESH_INTERVAL - _valueUs, 0, phaseReference)) {\n       _servoMap |= (1 << _pin);\n     }\n   }\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Current PR introduces timing errors leading to PWM jitter and intermittent missing pulses when transitioning from a 100% duty cycle. This results in visible fluctuations in the output signal. Identify and fix this edge-case as it creates an undesirable user experience.\n\n2. Code performance is suboptimal; further optimize ISR to reduce execution time. Current execution is around 16.667us compared to 2.667 to 3.667us for the master branch.\n\n3. Investigate the issue of unexpected outputs during rapid PWM adjustments. Consider how the timing for updates interacts with other PWM channels to avoid glitches and intermittent signals.\n\n4. Future enhancements: Make PWM frequency user-configurable for analog servos, and support higher resolution steps at varying frequencies.\n\nNext steps: Pull the latest changes and retest across various scenarios to validate improvements."
      }
    ],
    "codediff_length": 31157
  },
  {
    "index": 38,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/cores/esp8266/Arduino.h b/cores/esp8266/Arduino.h\nindex 7711e8fa58..518232ac6a 100644\n--- a/cores/esp8266/Arduino.h\n+++ b/cores/esp8266/Arduino.h\n@@ -142,30 +142,9 @@ void timer0_detachInterrupt(void);\n void ets_intr_lock();\n void ets_intr_unlock();\n \n-#ifndef __STRINGIFY\n-#define __STRINGIFY(a) #a\n-#endif\n-\n-// these low level routines provide a replacement for SREG interrupt save that AVR uses\n-// but are esp8266 specific. A normal use pattern is like\n-//\n-//{\n-//    uint32_t savedPS = xt_rsil(1); // this routine will allow level 2 and above\n-//    // do work here\n-//    xt_wsr_ps(savedPS); // restore the state\n-//}\n-//\n-// level (0-15), interrupts of the given level and above will be active\n-// level 15 will disable ALL interrupts,\n-// level 0 will enable ALL interrupts,\n-//\n-#define xt_rsil(level) (__extension__({uint32_t state; __asm__ __volatile__(\"rsil %0,\" __STRINGIFY(level) : \"=a\" (state) :: \"memory\"); state;}))\n-#define xt_wsr_ps(state)  __asm__ __volatile__(\"wsr %0,ps; isync\" :: \"a\" (state) : \"memory\")\n-\n #define interrupts() xt_rsil(0)\n #define noInterrupts() xt_rsil(15)\n \n-\n #define clockCyclesPerMicrosecond() ( F_CPU / 1000000L )\n #define clockCyclesToMicroseconds(a) ( (a) / clockCyclesPerMicrosecond() )\n #define microsecondsToClockCycles(a) ( (a) * clockCyclesPerMicrosecond() )\ndiff --git a/cores/esp8266/Esp.h b/cores/esp8266/Esp.h\nindex bc241eb392..46af2a8cb1 100644\n--- a/cores/esp8266/Esp.h\n+++ b/cores/esp8266/Esp.h\n@@ -209,9 +209,7 @@ class EspClass {\n #ifndef CORE_MOCK\n uint32_t EspClass::getCycleCount()\n {\n-    uint32_t ccount;\n-    __asm__ __volatile__(\"esync; rsr %0,ccount\":\"=a\" (ccount));\n-    return ccount;\n+    return esp_get_cycle_count();\n }\n \n #endif // !defined(CORE_MOCK)\ndiff --git a/cores/esp8266/core_esp8266_features.h b/cores/esp8266/core_esp8266_features.h\nindex aff8fa4de9..3b4289006a 100644\n--- a/cores/esp8266/core_esp8266_features.h\n+++ b/cores/esp8266/core_esp8266_features.h\n@@ -33,7 +33,32 @@\n #define WIFI_HAS_EVENT_CALLBACK\r\n \r\n \r\n+#ifndef __STRINGIFY\r\n+#define __STRINGIFY(a) #a\r\n+#endif\r\n \r\n+// these low level routines provide a replacement for SREG interrupt save that AVR uses\r\n+// but are esp8266 specific. A normal use pattern is like\r\n+//\r\n+//{\r\n+//    uint32_t savedPS = xt_rsil(1); // this routine will allow level 2 and above\r\n+//    // do work here\r\n+//    xt_wsr_ps(savedPS); // restore the state\r\n+//}\r\n+//\r\n+// level (0-15), interrupts of the given level and above will be active\r\n+// level 15 will disable ALL interrupts,\r\n+// level 0 will enable ALL interrupts,\r\n+//\r\n+#ifndef CORE_MOCK\r\n+#define xt_rsil(level) (__extension__({uint32_t state; __asm__ __volatile__(\"rsil %0,\" __STRINGIFY(level) : \"=a\" (state) :: \"memory\"); state;}))\r\n+#define xt_wsr_ps(state)  __asm__ __volatile__(\"wsr %0,ps; isync\" :: \"a\" (state) : \"memory\")\r\n \r\n-#endif\r\n+inline uint32_t esp_get_cycle_count() {\r\n+  uint32_t ccount;\r\n+  __asm__ __volatile__(\"rsr %0,ccount\":\"=a\"(ccount));\r\n+  return ccount;\r\n+}\r\n+#endif // not CORE_MOCK\r\n \r\n+#endif\r\ndiff --git a/cores/esp8266/umm_malloc/umm_malloc.cpp b/cores/esp8266/umm_malloc/umm_malloc.cpp\nindex 09cfbdda71..13930a828e 100644\n--- a/cores/esp8266/umm_malloc/umm_malloc.cpp\n+++ b/cores/esp8266/umm_malloc/umm_malloc.cpp\n@@ -501,6 +501,13 @@\n \n extern \"C\" {\n \n+#undef memcpy\n+#undef memmove\n+#undef memset\n+#define memcpy ets_memcpy\n+#define memmove ets_memmove\n+#define memset ets_memset\n+\n // From UMM, the last caller of a malloc/realloc/calloc which failed:\n extern void *umm_last_fail_alloc_addr;\n extern int umm_last_fail_alloc_size;\n@@ -519,8 +526,50 @@ extern int umm_last_fail_alloc_size;\n #  define DBG_LOG_LEVEL DBG_LOG_LEVEL\n #endif\n \n-// Macro to place constant strings into PROGMEM and print them properly\n-#define printf(fmt, ...) printf(PSTR(fmt), ## __VA_ARGS__ )\n+/*\n+Changes for July 2019:\n+\n+  Correct critical section with interrupt level preserving and nest support\n+  alternative. Replace ets_intr_lock()/ets_intr_unlock() with uint32_t\n+  oldValue=xt_rsil(3)/xt_wrs(oldValue). Added UMM_CRITICAL_DECL macro to define\n+  storage for current state. Expanded UMM_CRITICAL_... to  use unique\n+  identifiers. This helpt facilitate gather function specific timing\n+  information.\n+\n+  Replace printf with something that is ROM or IRAM based so that a printf\n+  that occurs during an ISR malloc/new does not cause a crash. To avoid any\n+  reentry issue it should also avoid doing malloc lib calls.\n+\n+  Refactor realloc to avoid memcpy/memmove while in critical section. This is\n+  only effective when realloc is called with interrupts enabled. The copy\n+  process alone can take over 10us (when copying more than ~498 bytes with a\n+  80MHz CPU clock). It would be good practice for an ISR to avoid realloc.\n+  Note, while doing this might initially sound scary, this appears to be very\n+  stable. It ran on my troublesome sketch for over 3 weeks until I got back from\n+  vacation and flashed an update. Troublesome sketch - runs ESPAsyncTCP, with\n+  modified fauxmo emulation for 10 devices. It receives lost of Network traffic\n+  related to uPnP scans, which includes lots of TCP connects disconnects RSTs\n+  related to uPnP discovery.\n+\n+  Locking is no longer nested in realloc, due to refactoring for reduced IRQ\n+  off time.\n+\n+  I have clocked umm_info critical lock time taking as much as 180us. A common\n+  use for the umm_info call is to get the free heap result. It is common\n+  to try and closely monitor free heap as a method to detect memory leaks.\n+  This may result in frequent calls to umm_info. There has not been a clear\n+  test case that shows an issue yet; however, I and others think they are or\n+  have had crashes related to this.\n+\n+  I have added code that updates a current free heap value from _umm_malloc,\n+  _umm_realloc, and _umm_free. Removing the need to do a long interrupts\n+  disabled calculation via umm_info.\n+\n+  Build optional, min/max time measurements for locks held while in info,\n+  malloc, realloc, and free. Also, maintains a count of how many times each is\n+  called with INTLEVEL set.\n+\n+ */\n \n /* -- dbglog {{{ */\n \n@@ -562,42 +611,42 @@ extern int umm_last_fail_alloc_size;\n /* ------------------------------------------------------------------------- */\n \n #if DBG_LOG_LEVEL >= 6\n-#  define DBG_LOG_TRACE( format, ... ) printf( format, ## __VA_ARGS__ )\n+#  define DBG_LOG_TRACE( format, ... ) DBGLOG_FUNCTION( format, ## __VA_ARGS__ )\n #else\n #  define DBG_LOG_TRACE( format, ... )\n #endif\n \n #if DBG_LOG_LEVEL >= 5\n-#  define DBG_LOG_DEBUG( format, ... ) printf( format, ## __VA_ARGS__ )\n+#  define DBG_LOG_DEBUG( format, ... ) DBGLOG_FUNCTION( format, ## __VA_ARGS__ )\n #else\n #  define DBG_LOG_DEBUG( format, ... )\n #endif\n \n #if DBG_LOG_LEVEL >= 4\n-#  define DBG_LOG_CRITICAL( format, ... ) printf( format, ## __VA_ARGS__ )\n+#  define DBG_LOG_CRITICAL( format, ... ) DBGLOG_FUNCTION( format, ## __VA_ARGS__ )\n #else\n #  define DBG_LOG_CRITICAL( format, ... )\n #endif\n \n #if DBG_LOG_LEVEL >= 3\n-#  define DBG_LOG_ERROR( format, ... ) printf( format, ## __VA_ARGS__ )\n+#  define DBG_LOG_ERROR( format, ... ) DBGLOG_FUNCTION( format, ## __VA_ARGS__ )\n #else\n #  define DBG_LOG_ERROR( format, ... )\n #endif\n \n #if DBG_LOG_LEVEL >= 2\n-#  define DBG_LOG_WARNING( format, ... ) printf( format, ## __VA_ARGS__ )\n+#  define DBG_LOG_WARNING( format, ... ) DBGLOG_FUNCTION( format, ## __VA_ARGS__ )\n #else\n #  define DBG_LOG_WARNING( format, ... )\n #endif\n \n #if DBG_LOG_LEVEL >= 1\n-#  define DBG_LOG_INFO( format, ... ) printf( format, ## __VA_ARGS__ )\n+#  define DBG_LOG_INFO( format, ... ) DBGLOG_FUNCTION( format, ## __VA_ARGS__ )\n #else\n #  define DBG_LOG_INFO( format, ... )\n #endif\n \n-#define DBG_LOG_FORCE( force, format, ... ) {if(force) {printf( format, ## __VA_ARGS__  );}}\n+#define DBG_LOG_FORCE( force, format, ... ) {if(force) {DBGLOG_FUNCTION( format, ## __VA_ARGS__  );}}\n \n /* }}} */\n \n@@ -646,6 +695,10 @@ unsigned short int umm_numblocks = 0;\n #define UMM_PFREE(b)  (UMM_BLOCK(b).body.free.prev)\n #define UMM_DATA(b)   (UMM_BLOCK(b).body.data)\n \n+/*\n+ * This does not look safe, no access locks. It currently is not being\n+ * built, so not an immediate issue. -  06/10/19\n+ */\n /* integrity check (UMM_INTEGRITY_CHECK) {{{ */\n #if defined(UMM_INTEGRITY_CHECK)\n /*\n@@ -686,7 +739,7 @@ static int integrity_check(void) {\n \n     /* Check that next free block number is valid */\n     if (cur >= UMM_NUMBLOCKS) {\n-      printf(\"heap integrity broken: too large next free num: %d \"\n+      DBGLOG_FUNCTION(\"heap integrity broken: too large next free num: %d \"\n           \"(in block %d, addr 0x%lx)\\n\", cur, prev,\n           (unsigned long)&UMM_NBLOCK(prev));\n       ok = 0;\n@@ -699,7 +752,7 @@ static int integrity_check(void) {\n \n     /* Check if prev free block number matches */\n     if (UMM_PFREE(cur) != prev) {\n-      printf(\"heap integrity broken: free links don't match: \"\n+      DBGLOG_FUNCTION(\"heap integrity broken: free links don't match: \"\n           \"%d -> %d, but %d -> %d\\n\",\n           prev, cur, cur, UMM_PFREE(cur));\n       ok = 0;\n@@ -718,7 +771,7 @@ static int integrity_check(void) {\n \n     /* Check that next block number is valid */\n     if (cur >= UMM_NUMBLOCKS) {\n-      printf(\"heap integrity broken: too large next block num: %d \"\n+      DBGLOG_FUNCTION(\"heap integrity broken: too large next block num: %d \"\n           \"(in block %d, addr 0x%lx)\\n\", cur, prev,\n           (unsigned long)&UMM_NBLOCK(prev));\n       ok = 0;\n@@ -733,7 +786,7 @@ static int integrity_check(void) {\n     if ((UMM_NBLOCK(cur) & UMM_FREELIST_MASK)\n         != (UMM_PBLOCK(cur) & UMM_FREELIST_MASK))\n     {\n-      printf(\"heap integrity broken: mask wrong at addr 0x%lx: n=0x%x, p=0x%x\\n\",\n+      DBGLOG_FUNCTION(\"heap integrity broken: mask wrong at addr 0x%lx: n=0x%x, p=0x%x\\n\",\n           (unsigned long)&UMM_NBLOCK(cur),\n           (UMM_NBLOCK(cur) & UMM_FREELIST_MASK),\n           (UMM_PBLOCK(cur) & UMM_FREELIST_MASK)\n@@ -747,7 +800,7 @@ static int integrity_check(void) {\n \n     /* Check if prev block number matches */\n     if (UMM_PBLOCK(cur) != prev) {\n-      printf(\"heap integrity broken: block links don't match: \"\n+      DBGLOG_FUNCTION(\"heap integrity broken: block links don't match: \"\n           \"%d -> %d, but %d -> %d\\n\",\n           prev, cur, cur, UMM_PBLOCK(cur));\n       ok = 0;\n@@ -793,7 +846,7 @@ static int integrity_check(void) {\n  */\n static void dump_mem ( const unsigned char *ptr, size_t len ) {\n   while (len--) {\n-    printf(\" 0x%.2x\", (unsigned int)(*ptr++));\n+    DBGLOG_FUNCTION(\" 0x%.2x\", (unsigned int)(*ptr++));\n   }\n }\n \n@@ -824,11 +877,11 @@ static int check_poison( const unsigned char *ptr, size_t poison_size,\n   }\n \n   if (!ok) {\n-    printf(\"there is no poison %s the block. \"\n+    DBGLOG_FUNCTION(\"there is no poison %s the block. \"\n         \"Expected poison address: 0x%lx, actual data:\",\n         where, (unsigned long)ptr);\n     dump_mem(ptr, poison_size);\n-    printf(\"\\n\");\n+    DBGLOG_FUNCTION(\"\\n\");\n   }\n \n   return ok;\n@@ -842,7 +895,7 @@ static int check_poison_block( umm_block *pblock ) {\n   int ok = 1;\n \n   if (pblock->header.used.next & UMM_FREELIST_MASK) {\n-    printf(\"check_poison_block is called for free block 0x%lx\\n\",\n+    DBGLOG_FUNCTION(\"check_poison_block is called for free block 0x%lx\\n\",\n         (unsigned long)pblock);\n   } else {\n     /* the block is used; let's check poison */\n@@ -851,7 +904,7 @@ static int check_poison_block( umm_block *pblock ) {\n \n     pc_cur = pc + sizeof(UMM_POISONED_BLOCK_LEN_TYPE);\n     if (!check_poison(pc_cur, UMM_POISON_SIZE_BEFORE, \"before\")) {\n-      printf(\"block start: %08x\\n\", pc + sizeof(UMM_POISONED_BLOCK_LEN_TYPE) + UMM_POISON_SIZE_BEFORE);\n+      DBGLOG_FUNCTION(\"block start: %08x\\n\", pc + sizeof(UMM_POISONED_BLOCK_LEN_TYPE) + UMM_POISON_SIZE_BEFORE);\n       UMM_HEAP_CORRUPTION_CB();\n       ok = 0;\n       goto clean;\n@@ -859,7 +912,7 @@ static int check_poison_block( umm_block *pblock ) {\n \n     pc_cur = pc + *((UMM_POISONED_BLOCK_LEN_TYPE *)pc) - UMM_POISON_SIZE_AFTER;\n     if (!check_poison(pc_cur, UMM_POISON_SIZE_AFTER, \"after\")) {\n-\t  printf(\"block start: %08x\\n\", pc + sizeof(UMM_POISONED_BLOCK_LEN_TYPE) + UMM_POISON_SIZE_BEFORE);\n+      DBGLOG_FUNCTION(\"block start: %08x\\n\", pc + sizeof(UMM_POISONED_BLOCK_LEN_TYPE) + UMM_POISON_SIZE_BEFORE);\n       UMM_HEAP_CORRUPTION_CB();\n       ok = 0;\n       goto clean;\n@@ -982,6 +1035,7 @@ static void *get_unpoisoned( void *vptr ) {\n UMM_HEAP_INFO ummHeapInfo;\n \n void ICACHE_FLASH_ATTR *umm_info( void *ptr, int force ) {\n+  UMM_CRITICAL_DECL(id_info);\n \n   unsigned short int blockNo = 0;\n \n@@ -990,7 +1044,7 @@ void ICACHE_FLASH_ATTR *umm_info( void *ptr, int force ) {\n   }\n \n   /* Protect the critical section... */\n-  UMM_CRITICAL_ENTRY();\n+  UMM_CRITICAL_ENTRY(id_info);\n \n   /*\n    * Clear out all of the entries in the ummHeapInfo structure before doing\n@@ -1051,7 +1105,7 @@ void ICACHE_FLASH_ATTR *umm_info( void *ptr, int force ) {\n       if( ptr == &UMM_BLOCK(blockNo) ) {\n \n         /* Release the critical section... */\n-        UMM_CRITICAL_EXIT();\n+        UMM_CRITICAL_EXIT(id_info);\n \n         return( ptr );\n       }\n@@ -1104,8 +1158,23 @@ void ICACHE_FLASH_ATTR *umm_info( void *ptr, int force ) {\n       ummHeapInfo.usedBlocks,\n       ummHeapInfo.freeBlocks  );\n \n+  if (ummHeapInfo.freeBlocks == ummStats.free_blocks) {\n+      DBG_LOG_FORCE( force, \"\\nheap info Free blocks and heap statistics Free blocks match.\\n\");\n+  } else {\n+      DBG_LOG_FORCE( force, \"\\nheap info Free blocks  %5d != heap statistics Free Blocks  %5d\\n\\n\",\n+          ummHeapInfo.freeBlocks,\n+          ummStats.free_blocks  );\n+  }\n+\n+  DBG_LOG_FORCE( force, \"\\numm heap statistics:\\n\");\n+  DBG_LOG_FORCE( force,   \"  Free Space        %5u\\n\", ummStats.free_blocks * sizeof(umm_block));\n+  DBG_LOG_FORCE( force,   \"  Low Watermark     %5u\\n\", ummStats.free_blocks_min * sizeof(umm_block));\n+  DBG_LOG_FORCE( force,   \"  MAX Alloc Request %5u\\n\", ummStats.alloc_max_size);\n+  DBG_LOG_FORCE( force,   \"  OOM Count         %5u\\n\", ummStats.oom_count);\n+  DBG_LOG_FORCE( force,   \"  Size of umm_block %5u\\n\", sizeof(umm_block));\n+\n   /* Release the critical section... */\n-  UMM_CRITICAL_EXIT();\n+  UMM_CRITICAL_EXIT(id_info);\n \n   return( NULL );\n }\n@@ -1223,6 +1292,9 @@ void ICACHE_FLASH_ATTR umm_init( void ) {\n     /* index of the latest `umm_block` */\n     const unsigned short int block_last = UMM_NUMBLOCKS - 1;\n \n+    /* init ummStats */\n+    ummStats.free_blocks = ummStats.free_blocks_min = block_last;\n+\n     /* setup the 0th `umm_block`, which just points to the 1st */\n     UMM_NBLOCK(block_0th) = block_1th;\n     UMM_NFREE(block_0th)  = block_1th;\n@@ -1266,6 +1338,7 @@ void ICACHE_FLASH_ATTR umm_init( void ) {\n /* ------------------------------------------------------------------------ */\n \n static void _umm_free( void *ptr ) {\n+  UMM_CRITICAL_DECL(id_free);\n \n   unsigned short int c;\n \n@@ -1286,15 +1359,18 @@ static void _umm_free( void *ptr ) {\n    *        on the free list!\n    */\n \n-  /* Protect the critical section... */\n-  UMM_CRITICAL_ENTRY();\n-\n   /* Figure out which block we're in. Note the use of truncated division... */\n \n   c = (((char *)ptr)-(char *)(&(umm_heap[0])))/sizeof(umm_block);\n \n   DBG_LOG_DEBUG( \"Freeing block %6d\\n\", c );\n \n+  /* Protect the critical section... */\n+  UMM_CRITICAL_ENTRY(id_free);\n+\n+  /* Update heap statistics */\n+  ummStats.free_blocks += (UMM_NBLOCK(c) - c);\n+\n   /* Now let's assimilate this block with the next one if possible. */\n \n   umm_assimilate_up( c );\n@@ -1346,12 +1422,14 @@ static void _umm_free( void *ptr ) {\n #endif\n \n   /* Release the critical section... */\n-  UMM_CRITICAL_EXIT();\n+  UMM_CRITICAL_EXIT(id_free);\n }\n \n /* ------------------------------------------------------------------------ */\n \n static void *_umm_malloc( size_t size ) {\n+  UMM_CRITICAL_DECL(id_malloc);\n+\n   unsigned short int blocks;\n   unsigned short int blockSize = 0;\n \n@@ -1377,8 +1455,8 @@ static void *_umm_malloc( size_t size ) {\n     return( (void *)NULL );\n   }\n \n-  /* Protect the critical section... */\n-  UMM_CRITICAL_ENTRY();\n+  if ( size > ummStats.alloc_max_size )\n+    ummStats.alloc_max_size = size;\n \n   blocks = umm_blocks( size );\n \n@@ -1390,6 +1468,9 @@ static void *_umm_malloc( size_t size ) {\n    * algorithm\n    */\n \n+  /* Protect the critical section... */\n+  UMM_CRITICAL_ENTRY(id_malloc);\n+\n   cf = UMM_NFREE(0);\n \n   bestBlock = UMM_NFREE(0);\n@@ -1462,19 +1543,27 @@ static void *_umm_malloc( size_t size ) {\n       UMM_PFREE( UMM_NFREE(cf) ) = cf + blocks;\n       UMM_NFREE( cf + blocks ) = UMM_NFREE(cf);\n     }\n+\n+    /* Update heap statistics */\n+    ummStats.free_blocks -= blocks;\n+    if (ummStats.free_blocks < ummStats.free_blocks_min)\n+      ummStats.free_blocks_min = ummStats.free_blocks;\n+\n   } else {\n+    ummStats.oom_count += 1;\n+\n+    /* Release the critical section... */\n+    UMM_CRITICAL_EXIT(id_malloc);\n+\n     /* Out of memory */\n \n     DBG_LOG_DEBUG(  \"Can't allocate %5d blocks\\n\", blocks );\n \n-    /* Release the critical section... */\n-    UMM_CRITICAL_EXIT();\n-\n     return( (void *)NULL );\n   }\n \n   /* Release the critical section... */\n-  UMM_CRITICAL_EXIT();\n+  UMM_CRITICAL_EXIT(id_malloc);\n \n   return( (void *)&UMM_DATA(cf) );\n }\n@@ -1482,10 +1571,10 @@ static void *_umm_malloc( size_t size ) {\n /* ------------------------------------------------------------------------ */\n \n static void *_umm_realloc( void *ptr, size_t size ) {\n+  UMM_CRITICAL_DECL(id_realloc);\n \n   unsigned short int blocks;\n   unsigned short int blockSize;\n-\n   unsigned short int c;\n \n   size_t curSize;\n@@ -1522,8 +1611,33 @@ static void *_umm_realloc( void *ptr, size_t size ) {\n     return( (void *)NULL );\n   }\n \n-  /* Protect the critical section... */\n-  UMM_CRITICAL_ENTRY();\n+  if ( size > ummStats.alloc_max_size )\n+    ummStats.alloc_max_size = size;\n+\n+  /*\n+   * Defer starting critical section.\n+   *\n+   * Initially we should be safe without a critical section as long as we are\n+   * referencing values that are within our allocation as constants.\n+   * And only reference values that will not change, while the redefintions of\n+   * the allocations around us change.\n+   *\n+   * Example UMM_PBLOCK() could be change by a call to malloc from an ISR.\n+   * On the other hand UMM_NBLOCK() is safe returns an address of the next\n+   * block. The calculation is all based on information within our allocation\n+   * that remains constant, until we change it.\n+   *\n+   * As long as we don't try to modify the next block or walk the chain of\n+   * blocks we are okay.\n+   *\n+   * When called by an \"interrupts enabled\" type caller, it bears the\n+   * responsibility to not call again, with the allocate we are currently\n+   * working on. I think this is a normal expectation. I could be wrong.\n+   * Such a situation would involve a function that is called from foreground\n+   * and ISR context. Such code would already have to be re-entrant. This\n+   * change may expand the corner cases for such a function.\n+   *\n+   */\n \n   /*\n    * Otherwise we need to actually do a reallocation. A naiive approach\n@@ -1559,12 +1673,12 @@ static void *_umm_realloc( void *ptr, size_t size ) {\n \n     DBG_LOG_DEBUG( \"realloc the same size block - %d, do nothing\\n\", blocks );\n \n-    /* Release the critical section... */\n-    UMM_CRITICAL_EXIT();\n-\n     return( ptr );\n   }\n \n+  /* Now we need a critical section... */\n+  UMM_CRITICAL_ENTRY(id_realloc);\n+\n   /*\n    * Now we have a block size that could be bigger or smaller. Either\n    * way, try to assimilate up to the next block before doing anything...\n@@ -1573,7 +1687,13 @@ static void *_umm_realloc( void *ptr, size_t size ) {\n    * assimilation step later in free :-)\n    */\n \n-  umm_assimilate_up( c );\n+   if( UMM_NBLOCK(UMM_NBLOCK(c)) & UMM_FREELIST_MASK ) {\n+       // This will often be most of the free heap. The excess is\n+       // restored when umm_free() is called before returning.\n+       ummStats.free_blocks -=\n+           (UMM_NBLOCK(UMM_NBLOCK(c)) & UMM_BLOCKNO_MASK) - UMM_NBLOCK(c);\n+       umm_assimilate_up( c );\n+   }\n \n   /*\n    * Now check if it might help to assimilate down, but don't actually\n@@ -1589,6 +1709,17 @@ static void *_umm_realloc( void *ptr, size_t size ) {\n \n     DBG_LOG_DEBUG( \"realloc() could assimilate down %d blocks - fits!\\n\\r\", c-UMM_PBLOCK(c) );\n \n+    /*\n+     * Calculate the number of blocks to keep while the information is\n+     * still available.\n+     */\n+\n+    unsigned short int prevBlockSize = c - UMM_PBLOCK(c);\n+    ummStats.free_blocks -= prevBlockSize;\n+    unsigned short int prelimBlockSize = blockSize + prevBlockSize;\n+    if(prelimBlockSize < blocks)\n+        prelimBlockSize = blocks;\n+\n     /* Disconnect the previous block from the FREE list */\n \n     umm_disconnect_from_free_list( UMM_PBLOCK(c) );\n@@ -1600,6 +1731,29 @@ static void *_umm_realloc( void *ptr, size_t size ) {\n \n     c = umm_assimilate_down(c, 0);\n \n+    /*\n+     * Currently all or most of the heap has been grabbed. Do an early split of\n+     * allocation down to the amount needed to do a successful move operation.\n+     * This will allow an alloc/new from a ISR to succeed while a memmove is\n+     * running.\n+     */\n+    if( (UMM_NBLOCK(c) - c) > prelimBlockSize ) {\n+        umm_make_new_block( c, prelimBlockSize, 0, 0 );\n+        _umm_free( (void *)&UMM_DATA(c+prelimBlockSize) );\n+    }\n+\n+    // This is the lowest low that may be seen by an ISR doing an alloc/new\n+    if( ummStats.free_blocks < ummStats.free_blocks_min )\n+        ummStats.free_blocks_min = ummStats.free_blocks;\n+\n+    /*\n+     * For the ESP8266 interrupts should not be off for more than 10us.\n+     * An unprotect/protect around memmove should be safe to do here.\n+     * All variables used are on the stack.\n+     */\n+\n+    UMM_CRITICAL_EXIT(id_realloc);\n+\n     /*\n      * Move the bytes down to the new block we just created, but be sure to move\n      * only the original bytes.\n@@ -1610,6 +1764,9 @@ static void *_umm_realloc( void *ptr, size_t size ) {\n     /* And don't forget to adjust the pointer to the new block location! */\n \n     ptr    = (void *)&UMM_DATA(c);\n+\n+    /* Now resume critical section... */\n+    UMM_CRITICAL_ENTRY(id_realloc);\n   }\n \n   /* Now calculate the block size again...and we'll have three cases */\n@@ -1634,6 +1791,9 @@ static void *_umm_realloc( void *ptr, size_t size ) {\n   } else {\n     /* New block is bigger than the old block... */\n \n+    /* Finish up without critical section */\n+    UMM_CRITICAL_EXIT(id_realloc);\n+\n     void *oldptr = ptr;\n \n     DBG_LOG_DEBUG( \"realloc %d to a bigger block %d, make new, copy, and free the old\\n\", blockSize, blocks );\n@@ -1646,12 +1806,18 @@ static void *_umm_realloc( void *ptr, size_t size ) {\n     if( (ptr = _umm_malloc( size )) ) {\n       memcpy( ptr, oldptr, curSize );\n       _umm_free( oldptr );\n+    } else {\n+      ummStats.oom_count += 1; // Needs atomic\n     }\n+    return( ptr );\n \n   }\n \n+  if (ummStats.free_blocks < ummStats.free_blocks_min)\n+      ummStats.free_blocks_min = ummStats.free_blocks;\n+\n   /* Release the critical section... */\n-  UMM_CRITICAL_EXIT();\n+  UMM_CRITICAL_EXIT(id_realloc);\n \n   return( ptr );\n }\n@@ -1766,8 +1932,16 @@ void umm_free( void *ptr ) {\n /* ------------------------------------------------------------------------ */\n \n size_t ICACHE_FLASH_ATTR umm_free_heap_size( void ) {\n-  umm_info(NULL, 0);\n-  return (size_t)ummHeapInfo.freeBlocks * sizeof(umm_block);\n+  return (size_t)ummStats.free_blocks * sizeof(umm_block);\n+}\n+\n+size_t ICACHE_FLASH_ATTR umm_free_heap_size_min( void ) {\n+  return (size_t)ummStats.free_blocks_min * sizeof(umm_block);\n+}\n+\n+size_t ICACHE_FLASH_ATTR umm_free_heap_size_min_reset( void ) {\n+  ummStats.free_blocks_min = ummStats.free_blocks;\n+  return (size_t)ummStats.free_blocks_min *  sizeof(umm_block);\n }\n \n size_t ICACHE_FLASH_ATTR umm_max_block_size( void ) {\ndiff --git a/cores/esp8266/umm_malloc/umm_malloc_cfg.h b/cores/esp8266/umm_malloc/umm_malloc_cfg.h\nindex 14fb4a8e48..39d5897cc9 100644\n--- a/cores/esp8266/umm_malloc/umm_malloc_cfg.h\n+++ b/cores/esp8266/umm_malloc/umm_malloc_cfg.h\n@@ -10,10 +10,25 @@\n extern \"C\" {\n #endif\n \n+#include <core_esp8266_features.h>\n #include <stdlib.h>\n #include <osapi.h>\n \n #include \"c_types.h\"\n+#include \"umm_performance.h\"\n+#include \"umm_stats.h\"\n+\n+#undef DBGLOG_FUNCTION\n+#if defined(DEBUG_ESP_PORT) || defined(DEBUG_ESP_ISR)\n+int _isr_safe_printf_P(const char *fmt, ...) __attribute__((format(printf, 1, 2)));\n+// Note, _isr_safe_printf_P will not handle additional string arguments in\n+// PROGMEM. Only the 1st parameter, fmt, is supported in PROGMEM.\n+#define DBGLOG_FUNCTION(fmt, ...) _isr_safe_printf_P(PSTR(fmt), ##__VA_ARGS__)\n+#else\n+// Macro to place constant strings into PROGMEM and print them properly\n+#define DBGLOG_FUNCTION(fmt, ...) printf(PSTR(fmt), ## __VA_ARGS__ )\n+#endif\n+\n /*\n  * There are a number of defines you can set at compile time that affect how\n  * the memory allocator will operate.\n@@ -110,8 +125,22 @@ extern char _heap_start[];\n  * called from within umm_malloc()\n  */\n \n-#define UMM_CRITICAL_ENTRY() ets_intr_lock()\n-#define UMM_CRITICAL_EXIT()  ets_intr_unlock()\n+\n+#if defined(UMM_CRITICAL_PERIOD_ANALYZE)\n+\n+#define UMM_CRITICAL_DECL(tag) uint32_t _saved_ps_##tag\n+#define UMM_CRITICAL_ENTRY(tag) _critical_entry(&time_stats.tag, &_saved_ps_##tag)\n+#define UMM_CRITICAL_EXIT(tag) _critical_exit(&time_stats.tag, &_saved_ps_##tag)\n+\n+#else\n+\n+// This method preserves the intlevel on entry and restores the\n+// original intlevel at exit.\n+#define UMM_CRITICAL_DECL(tag) uint32_t _saved_ps_##tag\n+#define UMM_CRITICAL_ENTRY(tag) _saved_ps_##tag = xt_rsil(DEFAULT_CRITICAL_SECTION_INTLEVEL)\n+#define UMM_CRITICAL_EXIT(tag) xt_wsr_ps(_saved_ps_##tag)\n+\n+#endif\n \n /*\n  * -D UMM_INTEGRITY_CHECK :\ndiff --git a/cores/esp8266/umm_malloc/umm_performance.cpp b/cores/esp8266/umm_malloc/umm_performance.cpp\nnew file mode 100644\nindex 0000000000..4b9ec4e6b3\n--- /dev/null\n+++ b/cores/esp8266/umm_malloc/umm_performance.cpp\n@@ -0,0 +1,81 @@\n+/*\n+ * umm_malloc performance measurments and ESP specifics\n+ */\n+\n+#include <stdio.h>\n+#include <string.h>\n+#include <pgmspace.h>\n+#include <core_esp8266_features.h>\n+#include \"umm_performance.h\"\n+#include \"umm_stats.h\"\n+\n+extern \"C\" {\n+\n+UMM_STATS ummStats = {0, 0, 0, 0};\n+\n+#ifdef UMM_CRITICAL_PERIOD_ANALYZE\n+struct _UMM_TIME_STATS time_stats = {\n+  {0xFFFFFFFF, 0U, 0U, 0U},\n+  {0xFFFFFFFF, 0U, 0U, 0U},\n+  {0xFFFFFFFF, 0U, 0U, 0U},\n+  {0xFFFFFFFF, 0U, 0U, 0U} };\n+\n+bool ICACHE_FLASH_ATTR get_umm_get_perf_data(struct _UMM_TIME_STATS *p, size_t size) {\n+    if (p && sizeof(time_stats) == size) {\n+        uint32_t save_ps = xt_rsil(DEFAULT_CRITICAL_SECTION_INTLEVEL);\n+        memcpy(p, &time_stats, size);\n+        xt_wsr_ps(save_ps);\n+        return true;\n+    }\n+    return false;\n+}\n+#endif\n+\n+#if defined(DEBUG_ESP_PORT) || defined(DEBUG_ESP_ISR)\n+/*\n+  Printing from the malloc routines is tricky. Since a lot of library calls\n+  will want to do malloc.\n+\n+  Objective:  To be able to print \"last gasp\" diagnostic messages\n+  when interrupts are disabled and w/o availability of heap resources.\n+*/\n+\n+// ROM _putc1, ignores CRs and sends CR/LF for LF, newline.\n+// Always returns character sent.\n+int constexpr (*_rom_putc1)(int) = (int (*)(int))0x40001dcc;\n+void uart_buff_switch(uint8_t);\n+\n+int _isr_safe_printf_P(const char *fmt, ...) __attribute__((format(printf, 1, 2)));\n+int ICACHE_RAM_ATTR _isr_safe_printf_P(const char *fmt, ...) {\n+#ifdef DEBUG_ESP_PORT\n+#define VALUE(x) __STRINGIFY(x)\n+  // Preprocessor and compiler together will optimize away the if.\n+  if (strcmp(\"Serial1\", VALUE(DEBUG_ESP_PORT)) == 0) {\n+    uart_buff_switch(1U);\n+  } else {\n+    uart_buff_switch(0U);\n+  }\n+#else\n+  uart_buff_switch(0U); // Side effect, clears RX FIFO\n+#endif\n+  /*\n+    To use ets_strlen() and ets_memcpy() safely with PROGMEM, flash storage,\n+    the PROGMEM address must be word (4 bytes) aligned. The destination\n+    address for ets_memcpy must also be word-aligned. We also round the\n+    buf_len up to the nearest word boundary. So that all transfers will be\n+    whole words.\n+  */\n+  size_t str_len = ets_strlen(fmt);\n+  size_t buf_len = (str_len + 1 + 3) & ~0x03U;\n+  char ram_buf[buf_len] __attribute__ ((aligned(4)));\n+  ets_memcpy(ram_buf, fmt, buf_len);\n+  va_list argPtr;\n+  va_start(argPtr, fmt);\n+  int result = ets_vprintf(_rom_putc1, ram_buf, argPtr);\n+  va_end(argPtr);\n+  return result;\n+}\n+\n+#endif\n+\n+};\ndiff --git a/cores/esp8266/umm_malloc/umm_performance.h b/cores/esp8266/umm_malloc/umm_performance.h\nnew file mode 100644\nindex 0000000000..5d6ae24c61\n--- /dev/null\n+++ b/cores/esp8266/umm_malloc/umm_performance.h\n@@ -0,0 +1,85 @@\n+/*\n+ * umm_malloc performance measurments and ESP specifics\n+ */\n+\n+#ifndef _UMM_PERFORMANCE_H\n+#define _UMM_PERFORMANCE_H\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+/*\n+ * -D UMM_CRITICAL_PERIOD_ANALYZE :\n+ *\n+ * Build option to collect timing usage data on critical section usage in\n+ * functions: info, malloc, realloc. Collects MIN, MAX, and number of time\n+ * IRQs were disabled at request time. Note, for realloc MAX disabled time\n+ * will not include the time from calling malloc and/or free.\n+ * Examine code for specifics on what info is available and how to access.\n+*/\n+// #define UMM_CRITICAL_PERIOD_ANALYZE\n+\n+\n+/*\n+  Per Devyte, the core currently doesn't support masking a specific interrupt\n+  level. That doesn't mean it can't be implemented, only that at this time\n+  locking is implemented as all or nothing.\n+  https://github.com/esp8266/Arduino/issues/6246#issuecomment-508612609\n+\n+  So for now we default to all, 15.\n+ */\n+#ifndef DEFAULT_CRITICAL_SECTION_INTLEVEL\n+#define DEFAULT_CRITICAL_SECTION_INTLEVEL 15\n+#endif\n+\n+#if defined(UMM_CRITICAL_PERIOD_ANALYZE)\n+// This option adds support for gathering time locked data\n+typedef struct _TIME_STAT {\n+  uint32_t min;\n+  uint32_t max;\n+  uint32_t start;\n+  uint32_t intlevel;\n+} time_stat_t;\n+\n+struct _UMM_TIME_STATS {\n+  time_stat_t id_malloc;\n+  time_stat_t id_realloc;\n+  time_stat_t id_free;\n+  time_stat_t id_info;\n+};\n+\n+extern struct _UMM_TIME_STATS time_stats;\n+\n+bool get_umm_get_perf_data(struct _UMM_TIME_STATS *p, size_t size);\n+\n+static inline void _critical_entry(time_stat_t *p, uint32_t *saved_ps) {\n+    *saved_ps = xt_rsil(DEFAULT_CRITICAL_SECTION_INTLEVEL);\n+    if (0U != (*saved_ps & 0x0FU)) {\n+        p->intlevel += 1U;\n+    }\n+\n+    p->start = esp_get_cycle_count();\n+}\n+\n+static inline void _critical_exit(time_stat_t *p, uint32_t *saved_ps) {\n+    uint32_t elapse = esp_get_cycle_count() - p->start;\n+    if (elapse < p->min)\n+        p->min = elapse;\n+\n+    if (elapse > p->max)\n+        p->max = elapse;\n+\n+    xt_wsr_ps(*saved_ps);\n+}\n+#endif\n+\n+#if defined(DEBUG_ESP_PORT) || defined(DEBUG_ESP_ISR)\n+int _isr_safe_printf_P(const char *fmt, ...) __attribute__((format(printf, 1, 2)));\n+#endif\n+\n+#ifdef __cplusplus\n+}\n+#endif\n+\n+#endif  /* _UMM_PERFORMANCE_H */\ndiff --git a/cores/esp8266/umm_malloc/umm_stats.h b/cores/esp8266/umm_malloc/umm_stats.h\nnew file mode 100644\nindex 0000000000..f2aae9875f\n--- /dev/null\n+++ b/cores/esp8266/umm_malloc/umm_stats.h\n@@ -0,0 +1,36 @@\n+/*\n+ * umm_malloc heap statistics\n+ */\n+\n+#ifndef _UMM_STATS_H\n+#define _UMM_STATS_H\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+typedef struct UMM_STATS_t {\n+  unsigned short int free_blocks;\n+  unsigned short int free_blocks_min;\n+  size_t alloc_max_size;\n+  size_t oom_count;\n+} UMM_STATS;\n+extern UMM_STATS ummStats;\n+\n+size_t ICACHE_FLASH_ATTR umm_free_heap_size_min( void );\n+size_t ICACHE_FLASH_ATTR umm_free_heap_size_min_reset( void );\n+\n+inline size_t umm_get_max_alloc_size( void ) {\n+  return ummStats.alloc_max_size;\n+}\n+\n+inline size_t umm_get_oom_count( void ) {\n+  return ummStats.oom_count;\n+}\n+\n+\n+#ifdef __cplusplus\n+}\n+#endif\n+\n+#endif  /* _UMM_STATS_H */\ndiff --git a/tools/sdk/include/ets_sys.h b/tools/sdk/include/ets_sys.h\nindex 731e562b4f..da1f3897a4 100644\n--- a/tools/sdk/include/ets_sys.h\n+++ b/tools/sdk/include/ets_sys.h\n@@ -190,6 +190,7 @@ void *pvPortMalloc(size_t xWantedSize, const char* file, int line) __attribute__\n void *pvPortRealloc(void* ptr, size_t xWantedSize, const char* file, int line) __attribute__((alloc_size(2)));\n void vPortFree(void *ptr, const char* file, int line);\n void *ets_memcpy(void *dest, const void *src, size_t n);\n+void *ets_memmove(void *dest, const void *src, size_t n);\n void *ets_memset(void *s, int c, size_t n);\n void ets_timer_arm_new(ETSTimer *a, int b, int c, int isMstimer);\n void ets_timer_setfn(ETSTimer *t, ETSTimerFunc *fn, void *parg);\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Add a memory barrier to `xt_rsil()` for proper compiler flagging\u2014it's essential for critical section delineation.\n2. Move `xt_rsil()` and related macros from `Arduino.h` to `cores/esp8266/core_esp8266_features.h` to reduce include dependencies.\n3. Implement a macro like `esp_get_cycle_count()` in the same header and evaluate if it requires a memory fence.\n4. Address UMM integrity check issues: \n   - Ensure integrity checks use critical sections to prevent heap modification during ISR calls.\n   - Reverse the call order of `CHECK_POISON_ALL_BLOCKS()` and `INTEGRITY_CHECK()` for better reliability.\n5. Limit `CHECK_POISON_ALL_BLOCKS()` to be less readily enabled to avoid operational risks.\n6. Investigate Travis CI build failures related to package installations."
      }
    ],
    "codediff_length": 32616
  },
  {
    "index": 39,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/boards.txt b/boards.txt\nindex 8279cd5c53..19a22b5dba 100644\n--- a/boards.txt\n+++ b/boards.txt\n@@ -19,6 +19,7 @@ menu.lvl=Debug Level\n menu.ip=lwIP Variant\n menu.vt=VTables\n menu.exception=Exceptions\n+menu.stacksmash=Stack Protection\n menu.wipe=Erase Flash\n menu.sdk=Espressif FW\n menu.ssl=SSL Support\n@@ -57,6 +58,10 @@ generic.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n generic.menu.exception.enabled=Enabled\n generic.menu.exception.enabled.build.exception_flags=-fexceptions\n generic.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+generic.menu.stacksmash.disabled=Disabled\n+generic.menu.stacksmash.disabled.build.stacksmash_flags=\n+generic.menu.stacksmash.enabled=Enabled\n+generic.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n generic.menu.ssl.all=All SSL ciphers (most compatible)\n generic.menu.ssl.all.build.sslflags=\n generic.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -532,6 +537,10 @@ esp8285.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n esp8285.menu.exception.enabled=Enabled\n esp8285.menu.exception.enabled.build.exception_flags=-fexceptions\n esp8285.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+esp8285.menu.stacksmash.disabled=Disabled\n+esp8285.menu.stacksmash.disabled.build.stacksmash_flags=\n+esp8285.menu.stacksmash.enabled=Enabled\n+esp8285.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n esp8285.menu.ssl.all=All SSL ciphers (most compatible)\n esp8285.menu.ssl.all.build.sslflags=\n esp8285.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -873,6 +882,10 @@ espduino.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n espduino.menu.exception.enabled=Enabled\n espduino.menu.exception.enabled.build.exception_flags=-fexceptions\n espduino.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+espduino.menu.stacksmash.disabled=Disabled\n+espduino.menu.stacksmash.disabled.build.stacksmash_flags=\n+espduino.menu.stacksmash.enabled=Enabled\n+espduino.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n espduino.menu.ssl.all=All SSL ciphers (most compatible)\n espduino.menu.ssl.all.build.sslflags=\n espduino.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -1065,6 +1078,10 @@ huzzah.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n huzzah.menu.exception.enabled=Enabled\n huzzah.menu.exception.enabled.build.exception_flags=-fexceptions\n huzzah.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+huzzah.menu.stacksmash.disabled=Disabled\n+huzzah.menu.stacksmash.disabled.build.stacksmash_flags=\n+huzzah.menu.stacksmash.enabled=Enabled\n+huzzah.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n huzzah.menu.ssl.all=All SSL ciphers (most compatible)\n huzzah.menu.ssl.all.build.sslflags=\n huzzah.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -1258,6 +1275,10 @@ inventone.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n inventone.menu.exception.enabled=Enabled\n inventone.menu.exception.enabled.build.exception_flags=-fexceptions\n inventone.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+inventone.menu.stacksmash.disabled=Disabled\n+inventone.menu.stacksmash.disabled.build.stacksmash_flags=\n+inventone.menu.stacksmash.enabled=Enabled\n+inventone.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n inventone.menu.ssl.all=All SSL ciphers (most compatible)\n inventone.menu.ssl.all.build.sslflags=\n inventone.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -1451,6 +1472,10 @@ cw01.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n cw01.menu.exception.enabled=Enabled\n cw01.menu.exception.enabled.build.exception_flags=-fexceptions\n cw01.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+cw01.menu.stacksmash.disabled=Disabled\n+cw01.menu.stacksmash.disabled.build.stacksmash_flags=\n+cw01.menu.stacksmash.enabled=Enabled\n+cw01.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n cw01.menu.ssl.all=All SSL ciphers (most compatible)\n cw01.menu.ssl.all.build.sslflags=\n cw01.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -1647,6 +1672,10 @@ espresso_lite_v1.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n espresso_lite_v1.menu.exception.enabled=Enabled\n espresso_lite_v1.menu.exception.enabled.build.exception_flags=-fexceptions\n espresso_lite_v1.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+espresso_lite_v1.menu.stacksmash.disabled=Disabled\n+espresso_lite_v1.menu.stacksmash.disabled.build.stacksmash_flags=\n+espresso_lite_v1.menu.stacksmash.enabled=Enabled\n+espresso_lite_v1.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n espresso_lite_v1.menu.ssl.all=All SSL ciphers (most compatible)\n espresso_lite_v1.menu.ssl.all.build.sslflags=\n espresso_lite_v1.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -1843,6 +1872,10 @@ espresso_lite_v2.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n espresso_lite_v2.menu.exception.enabled=Enabled\n espresso_lite_v2.menu.exception.enabled.build.exception_flags=-fexceptions\n espresso_lite_v2.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+espresso_lite_v2.menu.stacksmash.disabled=Disabled\n+espresso_lite_v2.menu.stacksmash.disabled.build.stacksmash_flags=\n+espresso_lite_v2.menu.stacksmash.enabled=Enabled\n+espresso_lite_v2.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n espresso_lite_v2.menu.ssl.all=All SSL ciphers (most compatible)\n espresso_lite_v2.menu.ssl.all.build.sslflags=\n espresso_lite_v2.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -2039,6 +2072,10 @@ phoenix_v1.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n phoenix_v1.menu.exception.enabled=Enabled\n phoenix_v1.menu.exception.enabled.build.exception_flags=-fexceptions\n phoenix_v1.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+phoenix_v1.menu.stacksmash.disabled=Disabled\n+phoenix_v1.menu.stacksmash.disabled.build.stacksmash_flags=\n+phoenix_v1.menu.stacksmash.enabled=Enabled\n+phoenix_v1.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n phoenix_v1.menu.ssl.all=All SSL ciphers (most compatible)\n phoenix_v1.menu.ssl.all.build.sslflags=\n phoenix_v1.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -2235,6 +2272,10 @@ phoenix_v2.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n phoenix_v2.menu.exception.enabled=Enabled\n phoenix_v2.menu.exception.enabled.build.exception_flags=-fexceptions\n phoenix_v2.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+phoenix_v2.menu.stacksmash.disabled=Disabled\n+phoenix_v2.menu.stacksmash.disabled.build.stacksmash_flags=\n+phoenix_v2.menu.stacksmash.enabled=Enabled\n+phoenix_v2.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n phoenix_v2.menu.ssl.all=All SSL ciphers (most compatible)\n phoenix_v2.menu.ssl.all.build.sslflags=\n phoenix_v2.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -2431,6 +2472,10 @@ nodemcu.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n nodemcu.menu.exception.enabled=Enabled\n nodemcu.menu.exception.enabled.build.exception_flags=-fexceptions\n nodemcu.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+nodemcu.menu.stacksmash.disabled=Disabled\n+nodemcu.menu.stacksmash.disabled.build.stacksmash_flags=\n+nodemcu.menu.stacksmash.enabled=Enabled\n+nodemcu.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n nodemcu.menu.ssl.all=All SSL ciphers (most compatible)\n nodemcu.menu.ssl.all.build.sslflags=\n nodemcu.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -2624,6 +2669,10 @@ nodemcuv2.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n nodemcuv2.menu.exception.enabled=Enabled\n nodemcuv2.menu.exception.enabled.build.exception_flags=-fexceptions\n nodemcuv2.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+nodemcuv2.menu.stacksmash.disabled=Disabled\n+nodemcuv2.menu.stacksmash.disabled.build.stacksmash_flags=\n+nodemcuv2.menu.stacksmash.enabled=Enabled\n+nodemcuv2.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n nodemcuv2.menu.ssl.all=All SSL ciphers (most compatible)\n nodemcuv2.menu.ssl.all.build.sslflags=\n nodemcuv2.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -2821,6 +2870,10 @@ modwifi.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n modwifi.menu.exception.enabled=Enabled\n modwifi.menu.exception.enabled.build.exception_flags=-fexceptions\n modwifi.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+modwifi.menu.stacksmash.disabled=Disabled\n+modwifi.menu.stacksmash.disabled.build.stacksmash_flags=\n+modwifi.menu.stacksmash.enabled=Enabled\n+modwifi.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n modwifi.menu.ssl.all=All SSL ciphers (most compatible)\n modwifi.menu.ssl.all.build.sslflags=\n modwifi.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -3034,6 +3087,10 @@ thing.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n thing.menu.exception.enabled=Enabled\n thing.menu.exception.enabled.build.exception_flags=-fexceptions\n thing.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+thing.menu.stacksmash.disabled=Disabled\n+thing.menu.stacksmash.disabled.build.stacksmash_flags=\n+thing.menu.stacksmash.enabled=Enabled\n+thing.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n thing.menu.ssl.all=All SSL ciphers (most compatible)\n thing.menu.ssl.all.build.sslflags=\n thing.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -3227,6 +3284,10 @@ thingdev.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n thingdev.menu.exception.enabled=Enabled\n thingdev.menu.exception.enabled.build.exception_flags=-fexceptions\n thingdev.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+thingdev.menu.stacksmash.disabled=Disabled\n+thingdev.menu.stacksmash.disabled.build.stacksmash_flags=\n+thingdev.menu.stacksmash.enabled=Enabled\n+thingdev.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n thingdev.menu.ssl.all=All SSL ciphers (most compatible)\n thingdev.menu.ssl.all.build.sslflags=\n thingdev.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -3420,6 +3481,10 @@ blynk.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n blynk.menu.exception.enabled=Enabled\n blynk.menu.exception.enabled.build.exception_flags=-fexceptions\n blynk.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+blynk.menu.stacksmash.disabled=Disabled\n+blynk.menu.stacksmash.disabled.build.stacksmash_flags=\n+blynk.menu.stacksmash.enabled=Enabled\n+blynk.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n blynk.menu.ssl.all=All SSL ciphers (most compatible)\n blynk.menu.ssl.all.build.sslflags=\n blynk.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -3613,6 +3678,10 @@ esp210.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n esp210.menu.exception.enabled=Enabled\n esp210.menu.exception.enabled.build.exception_flags=-fexceptions\n esp210.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+esp210.menu.stacksmash.disabled=Disabled\n+esp210.menu.stacksmash.disabled.build.stacksmash_flags=\n+esp210.menu.stacksmash.enabled=Enabled\n+esp210.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n esp210.menu.ssl.all=All SSL ciphers (most compatible)\n esp210.menu.ssl.all.build.sslflags=\n esp210.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -3806,6 +3875,10 @@ d1_mini.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n d1_mini.menu.exception.enabled=Enabled\n d1_mini.menu.exception.enabled.build.exception_flags=-fexceptions\n d1_mini.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+d1_mini.menu.stacksmash.disabled=Disabled\n+d1_mini.menu.stacksmash.disabled.build.stacksmash_flags=\n+d1_mini.menu.stacksmash.enabled=Enabled\n+d1_mini.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n d1_mini.menu.ssl.all=All SSL ciphers (most compatible)\n d1_mini.menu.ssl.all.build.sslflags=\n d1_mini.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -3999,6 +4072,10 @@ d1_mini_pro.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n d1_mini_pro.menu.exception.enabled=Enabled\n d1_mini_pro.menu.exception.enabled.build.exception_flags=-fexceptions\n d1_mini_pro.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+d1_mini_pro.menu.stacksmash.disabled=Disabled\n+d1_mini_pro.menu.stacksmash.disabled.build.stacksmash_flags=\n+d1_mini_pro.menu.stacksmash.enabled=Enabled\n+d1_mini_pro.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n d1_mini_pro.menu.ssl.all=All SSL ciphers (most compatible)\n d1_mini_pro.menu.ssl.all.build.sslflags=\n d1_mini_pro.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -4175,6 +4252,10 @@ d1_mini_lite.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n d1_mini_lite.menu.exception.enabled=Enabled\n d1_mini_lite.menu.exception.enabled.build.exception_flags=-fexceptions\n d1_mini_lite.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+d1_mini_lite.menu.stacksmash.disabled=Disabled\n+d1_mini_lite.menu.stacksmash.disabled.build.stacksmash_flags=\n+d1_mini_lite.menu.stacksmash.enabled=Enabled\n+d1_mini_lite.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n d1_mini_lite.menu.ssl.all=All SSL ciphers (most compatible)\n d1_mini_lite.menu.ssl.all.build.sslflags=\n d1_mini_lite.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -4408,6 +4489,10 @@ d1.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n d1.menu.exception.enabled=Enabled\n d1.menu.exception.enabled.build.exception_flags=-fexceptions\n d1.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+d1.menu.stacksmash.disabled=Disabled\n+d1.menu.stacksmash.disabled.build.stacksmash_flags=\n+d1.menu.stacksmash.enabled=Enabled\n+d1.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n d1.menu.ssl.all=All SSL ciphers (most compatible)\n d1.menu.ssl.all.build.sslflags=\n d1.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -4601,6 +4686,10 @@ espino.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n espino.menu.exception.enabled=Enabled\n espino.menu.exception.enabled.build.exception_flags=-fexceptions\n espino.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+espino.menu.stacksmash.disabled=Disabled\n+espino.menu.stacksmash.disabled.build.stacksmash_flags=\n+espino.menu.stacksmash.enabled=Enabled\n+espino.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n espino.menu.ssl.all=All SSL ciphers (most compatible)\n espino.menu.ssl.all.build.sslflags=\n espino.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -4797,6 +4886,10 @@ espinotee.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n espinotee.menu.exception.enabled=Enabled\n espinotee.menu.exception.enabled.build.exception_flags=-fexceptions\n espinotee.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+espinotee.menu.stacksmash.disabled=Disabled\n+espinotee.menu.stacksmash.disabled.build.stacksmash_flags=\n+espinotee.menu.stacksmash.enabled=Enabled\n+espinotee.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n espinotee.menu.ssl.all=All SSL ciphers (most compatible)\n espinotee.menu.ssl.all.build.sslflags=\n espinotee.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -5007,6 +5100,10 @@ wifinfo.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n wifinfo.menu.exception.enabled=Enabled\n wifinfo.menu.exception.enabled.build.exception_flags=-fexceptions\n wifinfo.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+wifinfo.menu.stacksmash.disabled=Disabled\n+wifinfo.menu.stacksmash.disabled.build.stacksmash_flags=\n+wifinfo.menu.stacksmash.enabled=Enabled\n+wifinfo.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n wifinfo.menu.ssl.all=All SSL ciphers (most compatible)\n wifinfo.menu.ssl.all.build.sslflags=\n wifinfo.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -5259,6 +5356,10 @@ arduino-esp8266.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n arduino-esp8266.menu.exception.enabled=Enabled\n arduino-esp8266.menu.exception.enabled.build.exception_flags=-fexceptions\n arduino-esp8266.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+arduino-esp8266.menu.stacksmash.disabled=Disabled\n+arduino-esp8266.menu.stacksmash.disabled.build.stacksmash_flags=\n+arduino-esp8266.menu.stacksmash.enabled=Enabled\n+arduino-esp8266.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n arduino-esp8266.menu.ssl.all=All SSL ciphers (most compatible)\n arduino-esp8266.menu.ssl.all.build.sslflags=\n arduino-esp8266.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -5453,6 +5554,10 @@ gen4iod.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n gen4iod.menu.exception.enabled=Enabled\n gen4iod.menu.exception.enabled.build.exception_flags=-fexceptions\n gen4iod.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+gen4iod.menu.stacksmash.disabled=Disabled\n+gen4iod.menu.stacksmash.disabled.build.stacksmash_flags=\n+gen4iod.menu.stacksmash.enabled=Enabled\n+gen4iod.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n gen4iod.menu.ssl.all=All SSL ciphers (most compatible)\n gen4iod.menu.ssl.all.build.sslflags=\n gen4iod.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -5714,6 +5819,10 @@ oak.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n oak.menu.exception.enabled=Enabled\n oak.menu.exception.enabled.build.exception_flags=-fexceptions\n oak.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+oak.menu.stacksmash.disabled=Disabled\n+oak.menu.stacksmash.disabled.build.stacksmash_flags=\n+oak.menu.stacksmash.enabled=Enabled\n+oak.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n oak.menu.ssl.all=All SSL ciphers (most compatible)\n oak.menu.ssl.all.build.sslflags=\n oak.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -5907,6 +6016,10 @@ wifiduino.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n wifiduino.menu.exception.enabled=Enabled\n wifiduino.menu.exception.enabled.build.exception_flags=-fexceptions\n wifiduino.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+wifiduino.menu.stacksmash.disabled=Disabled\n+wifiduino.menu.stacksmash.disabled.build.stacksmash_flags=\n+wifiduino.menu.stacksmash.enabled=Enabled\n+wifiduino.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n wifiduino.menu.ssl.all=All SSL ciphers (most compatible)\n wifiduino.menu.ssl.all.build.sslflags=\n wifiduino.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -6100,6 +6213,10 @@ wifi_slot.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n wifi_slot.menu.exception.enabled=Enabled\n wifi_slot.menu.exception.enabled.build.exception_flags=-fexceptions\n wifi_slot.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+wifi_slot.menu.stacksmash.disabled=Disabled\n+wifi_slot.menu.stacksmash.disabled.build.stacksmash_flags=\n+wifi_slot.menu.stacksmash.enabled=Enabled\n+wifi_slot.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n wifi_slot.menu.ssl.all=All SSL ciphers (most compatible)\n wifi_slot.menu.ssl.all.build.sslflags=\n wifi_slot.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -6407,6 +6524,10 @@ wiolink.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n wiolink.menu.exception.enabled=Enabled\n wiolink.menu.exception.enabled.build.exception_flags=-fexceptions\n wiolink.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+wiolink.menu.stacksmash.disabled=Disabled\n+wiolink.menu.stacksmash.disabled.build.stacksmash_flags=\n+wiolink.menu.stacksmash.enabled=Enabled\n+wiolink.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n wiolink.menu.ssl.all=All SSL ciphers (most compatible)\n wiolink.menu.ssl.all.build.sslflags=\n wiolink.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -6600,6 +6721,10 @@ espectro.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n espectro.menu.exception.enabled=Enabled\n espectro.menu.exception.enabled.build.exception_flags=-fexceptions\n espectro.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+espectro.menu.stacksmash.disabled=Disabled\n+espectro.menu.stacksmash.disabled.build.stacksmash_flags=\n+espectro.menu.stacksmash.enabled=Enabled\n+espectro.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n espectro.menu.ssl.all=All SSL ciphers (most compatible)\n espectro.menu.ssl.all.build.sslflags=\n espectro.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -6793,6 +6918,10 @@ eduinowifi.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n eduinowifi.menu.exception.enabled=Enabled\n eduinowifi.menu.exception.enabled.build.exception_flags=-fexceptions\n eduinowifi.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+eduinowifi.menu.stacksmash.disabled=Disabled\n+eduinowifi.menu.stacksmash.disabled.build.stacksmash_flags=\n+eduinowifi.menu.stacksmash.enabled=Enabled\n+eduinowifi.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n eduinowifi.menu.ssl.all=All SSL ciphers (most compatible)\n eduinowifi.menu.ssl.all.build.sslflags=\n eduinowifi.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -6996,6 +7125,10 @@ sonoff.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n sonoff.menu.exception.enabled=Enabled\n sonoff.menu.exception.enabled.build.exception_flags=-fexceptions\n sonoff.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+sonoff.menu.stacksmash.disabled=Disabled\n+sonoff.menu.stacksmash.disabled.build.stacksmash_flags=\n+sonoff.menu.stacksmash.enabled=Enabled\n+sonoff.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n sonoff.menu.ssl.all=All SSL ciphers (most compatible)\n sonoff.menu.ssl.all.build.sslflags=\n sonoff.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n@@ -7230,6 +7363,10 @@ espmxdevkit.menu.exception.disabled.build.stdcpp_lib=-lstdc++\n espmxdevkit.menu.exception.enabled=Enabled\n espmxdevkit.menu.exception.enabled.build.exception_flags=-fexceptions\n espmxdevkit.menu.exception.enabled.build.stdcpp_lib=-lstdc++-exc\n+espmxdevkit.menu.stacksmash.disabled=Disabled\n+espmxdevkit.menu.stacksmash.disabled.build.stacksmash_flags=\n+espmxdevkit.menu.stacksmash.enabled=Enabled\n+espmxdevkit.menu.stacksmash.enabled.build.stacksmash_flags=-fstack-protector\n espmxdevkit.menu.ssl.all=All SSL ciphers (most compatible)\n espmxdevkit.menu.ssl.all.build.sslflags=\n espmxdevkit.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\ndiff --git a/bootloaders/eboot/Makefile b/bootloaders/eboot/Makefile\nindex ff4489e474..17c5351462 100644\n--- a/bootloaders/eboot/Makefile\n+++ b/bootloaders/eboot/Makefile\n@@ -23,7 +23,7 @@ INC += -I../../tools/sdk/include -I../../tools/sdk/uzlib/src\n \n CFLAGS += -std=gnu99\n \n-CFLAGS += -Os -g -Wall -Wpointer-arith -Wno-implicit-function-declaration -Wl,-EL -fno-inline-functions -nostdlib -mlongcalls -mno-text-section-literals -ffunction-sections -fdata-sections\n+CFLAGS += -Os -fcommon -g -Wall -Wpointer-arith -Wno-implicit-function-declaration -Wl,-EL -fno-inline-functions -nostdlib -mlongcalls -mno-text-section-literals -ffunction-sections -fdata-sections\n \n CFLAGS += $(INC)\n \ndiff --git a/bootloaders/eboot/eboot.elf b/bootloaders/eboot/eboot.elf\nindex 60329d847e..1a6e5bc234 100755\nBinary files a/bootloaders/eboot/eboot.elf and b/bootloaders/eboot/eboot.elf differ\ndiff --git a/cores/esp8266/Arduino.h b/cores/esp8266/Arduino.h\nindex edb6bdd5c4..795160bc1b 100644\n--- a/cores/esp8266/Arduino.h\n+++ b/cores/esp8266/Arduino.h\n@@ -127,14 +127,8 @@ void timer0_isr_init(void);\n void timer0_attachInterrupt(timercallback userFunc);\n void timer0_detachInterrupt(void);\n \n-// undefine stdlib's abs if encountered\n-#ifdef abs\n-#undef abs\n-#endif\n-\n-#define abs(x) ((x)>0?(x):-(x))\n+// Use stdlib abs() and round() to avoid issues with the C++ libraries\n #define constrain(amt,low,high) ((amt)<(low)?(low):((amt)>(high)?(high):(amt)))\n-#define round(x)     ((x)>=0?(long)((x)+0.5):(long)((x)-0.5))\n #define radians(deg) ((deg)*DEG_TO_RAD)\n #define degrees(rad) ((rad)*RAD_TO_DEG)\n #define sq(x) ((x)*(x))\n@@ -249,6 +243,7 @@ const int TIM_DIV265 __attribute__((deprecated, weak)) = TIM_DIV256;\n \n using std::min;\n using std::max;\n+using std::round;\n using std::isinf;\n using std::isnan;\n \ndiff --git a/cores/esp8266/StackThunk.h b/cores/esp8266/StackThunk.h\nindex 874081a747..ffaeb32947 100644\n--- a/cores/esp8266/StackThunk.h\n+++ b/cores/esp8266/StackThunk.h\n@@ -51,7 +51,7 @@ extern uint32_t stack_thunk_refcnt;\n \n // Thunking macro\n #define make_stack_thunk(fcnToThunk) \\\n-__asm(\"\\n\\\n+__asm__ (\"\\n\\\n .text\\n\\\n .literal_position\\n\\\n .literal .LC_STACK_VALUE\"#fcnToThunk\", 0xdeadbeef\\n\\\ndiff --git a/cores/esp8266/core_esp8266_features.cpp b/cores/esp8266/core_esp8266_features.cpp\nindex 03396e5008..68f631d05c 100644\n--- a/cores/esp8266/core_esp8266_features.cpp\n+++ b/cores/esp8266/core_esp8266_features.cpp\n@@ -37,8 +37,9 @@ void precache(void *f, uint32_t bytes) {\n   // page (ie 1 word in 8) for this to work.\n   #define CACHE_PAGE_SIZE 32\n \n-  register uint32_t a0 asm(\"a0\");\n-  register uint32_t lines = (bytes/CACHE_PAGE_SIZE)+2;\n+  uint32_t a0;\n+  __asm__(\"mov.n %0, a0\" : \"=r\"(a0));\n+  uint32_t lines = (bytes/CACHE_PAGE_SIZE)+2;\n   volatile uint32_t *p = (uint32_t*)((f ? (uint32_t)f : a0) & ~0x03);\n   uint32_t x;\n   for (uint32_t i=0; i<lines; i++, p+=CACHE_PAGE_SIZE/sizeof(uint32_t)) x=*p;\ndiff --git a/cores/esp8266/core_esp8266_main.cpp b/cores/esp8266/core_esp8266_main.cpp\nindex 2d84362347..337686199d 100644\n--- a/cores/esp8266/core_esp8266_main.cpp\n+++ b/cores/esp8266/core_esp8266_main.cpp\n@@ -172,7 +172,7 @@ extern \"C\" bool ets_post_rom(uint8 prio, ETSSignal sig, ETSParam par);\n \n extern \"C\" bool IRAM_ATTR ets_post(uint8 prio, ETSSignal sig, ETSParam par) {\n   uint32_t saved;\n-  asm volatile (\"rsr %0,ps\":\"=a\" (saved));\n+  __asm__ __volatile__ (\"rsr %0,ps\":\"=a\" (saved));\n   bool rc=ets_post_rom(prio, sig, par);\n   xt_wsr_ps(saved);\n   return rc;\ndiff --git a/cores/esp8266/core_esp8266_postmortem.cpp b/cores/esp8266/core_esp8266_postmortem.cpp\nindex 5f285d6860..db0b95ff22 100644\n--- a/cores/esp8266/core_esp8266_postmortem.cpp\n+++ b/cores/esp8266/core_esp8266_postmortem.cpp\n@@ -45,6 +45,8 @@ static const char* s_panic_what = 0;\n static bool s_abort_called = false;\n static const char* s_unhandled_exception = NULL;\n \n+static uint32_t s_stacksmash_addr = 0;\n+\n void abort() __attribute__((noreturn));\n static void uart_write_char_d(char c);\n static void uart0_write_char_d(char c);\n@@ -54,6 +56,7 @@ static void print_stack(uint32_t start, uint32_t end);\n // using numbers different from \"REASON_\" in user_interface.h (=0..6)\n enum rst_reason_sw\n {\n+    REASON_USER_STACK_SMASH = 253,\n     REASON_USER_SWEXCEPTION_RST = 254\n };\n static int s_user_reset_reason = REASON_DEFAULT_RST;\n@@ -147,6 +150,11 @@ void __wrap_system_restart_local() {\n     else if (rst_info.reason == REASON_SOFT_WDT_RST) {\n         ets_printf_P(PSTR(\"\\nSoft WDT reset\\n\"));\n     }\n+    else if (rst_info.reason == REASON_USER_STACK_SMASH) {\n+        ets_printf_P(PSTR(\"\\nStack overflow detected.\\n\"));\n+        ets_printf_P(PSTR(\"\\nException (%d):\\nepc1=0x%08x epc2=0x%08x epc3=0x%08x excvaddr=0x%08x depc=0x%08x\\n\"),\n+            5 /* Alloca exception, closest thing to stack fault*/, s_stacksmash_addr, 0, 0, 0, 0);\n+   }\n     else {\n         ets_printf_P(PSTR(\"\\nGeneric Reset\\n\"));\n     }\n@@ -290,4 +298,20 @@ void __panic_func(const char* file, int line, const char* func) {\n     raise_exception();\n }\n \n+uintptr_t __stack_chk_guard = 0x08675309 ^ RANDOM_REG32;\n+void __stack_chk_fail(void) {\n+    s_user_reset_reason = REASON_USER_STACK_SMASH;\n+    ets_printf_P(PSTR(\"\\nPANIC: Stack overrun\"));\n+\n+    s_stacksmash_addr = (uint32_t)__builtin_return_address(0);\n+\n+    if (gdb_present())\n+        __asm__ __volatile__ (\"syscall\"); // triggers GDB when enabled\n+\n+    __wrap_system_restart_local();\n+\n+    while (1); // never reached, needed to satisfy \"noreturn\" attribute\n+}\n+\n+\n };\ndiff --git a/cores/esp8266/core_esp8266_si2c.cpp b/cores/esp8266/core_esp8266_si2c.cpp\nindex 3dfc5d1c7f..fa6d164342 100644\n--- a/cores/esp8266/core_esp8266_si2c.cpp\n+++ b/cores/esp8266/core_esp8266_si2c.cpp\n@@ -234,7 +234,7 @@ void ICACHE_RAM_ATTR Twi::busywait(unsigned int v)\n     unsigned int i;\n     for (i = 0; i < v; i++)  // loop time is 5 machine cycles: 31.25ns @ 160MHz, 62.5ns @ 80MHz\n     {\n-        asm(\"nop\"); // minimum element to keep GCC from optimizing this function out.\n+        __asm__ __volatile__(\"nop\"); // minimum element to keep GCC from optimizing this function out.\n     }\n }\n \ndiff --git a/cores/esp8266/core_esp8266_timer.cpp b/cores/esp8266/core_esp8266_timer.cpp\nindex efd528b667..af15de7fa9 100644\n--- a/cores/esp8266/core_esp8266_timer.cpp\n+++ b/cores/esp8266/core_esp8266_timer.cpp\n@@ -31,8 +31,9 @@ extern \"C\" {\n \n static volatile timercallback timer1_user_cb = NULL;\n \n-void ICACHE_RAM_ATTR timer1_isr_handler(void *para){\n+void ICACHE_RAM_ATTR timer1_isr_handler(void *para, void *frame) {\n     (void) para;\n+    (void) frame;\n     if ((T1C & ((1 << TCAR) | (1 << TCIT))) == 0) TEIE &= ~TEIE1;//edge int disable\n     T1I = 0;\n     if (timer1_user_cb) {\n@@ -79,8 +80,9 @@ void ICACHE_RAM_ATTR timer1_disable(){\n \n static volatile timercallback timer0_user_cb = NULL;\n \n-void ICACHE_RAM_ATTR timer0_isr_handler(void* para){\n+void ICACHE_RAM_ATTR timer0_isr_handler(void *para, void *frame) {\n     (void) para;\n+    (void) frame;\n     if (timer0_user_cb) {\n         // to make ISR compatible to Arduino AVR model where interrupts are disabled\n         // we disable them before we call the client ISR\ndiff --git a/cores/esp8266/core_esp8266_wiring_digital.cpp b/cores/esp8266/core_esp8266_wiring_digital.cpp\nindex ab6ed5dee9..9c15703e0a 100644\n--- a/cores/esp8266/core_esp8266_wiring_digital.cpp\n+++ b/cores/esp8266/core_esp8266_wiring_digital.cpp\n@@ -130,8 +130,10 @@ typedef struct {\n static interrupt_handler_t interrupt_handlers[16] = { {0, 0, 0, 0}, };\n static uint32_t interrupt_reg = 0;\n \n-void ICACHE_RAM_ATTR interrupt_handler(void*)\n+void ICACHE_RAM_ATTR interrupt_handler(void *arg, void *frame)\n {\n+  (void) arg;\n+  (void) frame;\n   uint32_t status = GPIE;\n   GPIEC = status;//clear them interrupts\n   uint32_t levels = GPI;\ndiff --git a/cores/esp8266/gdb_hooks.cpp b/cores/esp8266/gdb_hooks.cpp\nindex 3516712c9f..8864f757fb 100644\n--- a/cores/esp8266/gdb_hooks.cpp\n+++ b/cores/esp8266/gdb_hooks.cpp\n@@ -31,6 +31,11 @@ static bool ICACHE_RAM_ATTR __gdb_no_op()\n     return false;\n }\n \n+// To save space, don't create a dummy no-op for each GCC, just point to the no-op\n+// Need to turn off GCC's checking of parameter types or we'll get many warnings\n+#pragma GCC diagnostic push\n+#pragma GCC diagnostic ignored \"-Wattribute-alias\"\n+#pragma GCC diagnostic ignored \"-Wmissing-attributes\"\n void gdb_init(void) __attribute__ ((weak, alias(\"__gdb_no_op\")));\n void gdb_do_break(void) __attribute__ ((weak, alias(\"__gdb_no_op\")));\n bool gdb_present(void) __attribute__ ((weak, alias(\"__gdb_no_op\")));\n@@ -40,5 +45,6 @@ bool gdbstub_has_uart_isr_control(void) __attribute__ ((weak, alias(\"__gdb_no_op\n void gdbstub_set_uart_isr_callback(void (*func)(void*, uint8_t), void* arg) __attribute__ ((weak, alias(\"__gdb_no_op\")));\n void gdbstub_write_char(char c) __attribute__ ((weak, alias(\"__gdb_no_op\")));\n void gdbstub_write(const char* buf, size_t size) __attribute__ ((weak, alias(\"__gdb_no_op\")));\n+#pragma GCC diagnostic pop\n \n };\ndiff --git a/cores/esp8266/uart.cpp b/cores/esp8266/uart.cpp\nindex fd8170b586..a21300e51d 100644\n--- a/cores/esp8266/uart.cpp\n+++ b/cores/esp8266/uart.cpp\n@@ -371,8 +371,9 @@ uart_get_rx_buffer_size(uart_t* uart)\n \n // The default ISR handler called when GDB is not enabled\n void ICACHE_RAM_ATTR\n-uart_isr(void * arg)\n+uart_isr(void * arg, void * frame)\n {\n+    (void) frame;\n     uart_t* uart = (uart_t*)arg;\n     uint32_t usis = USIS(uart->uart_nr);\n \ndiff --git a/libraries/GDBStub/examples/gdbstub_example.ino b/libraries/GDBStub/examples/gdbstub_example/gdbstub_example.ino\nsimilarity index 100%\nrename from libraries/GDBStub/examples/gdbstub_example.ino\nrename to libraries/GDBStub/examples/gdbstub_example/gdbstub_example.ino\ndiff --git a/libraries/GDBStub/src/internal/gdbstub.c b/libraries/GDBStub/src/internal/gdbstub.c\nindex 97b0b13861..e5895a3a0b 100644\n--- a/libraries/GDBStub/src/internal/gdbstub.c\n+++ b/libraries/GDBStub/src/internal/gdbstub.c\n@@ -445,7 +445,7 @@ static inline int gdbHandleCommand() {\n \t\t\t\t\twriteByte(i, gdbGetHexVal(&data, 8));\n \t\t\t\t}\n \t\t\t\t//Make sure caches are up-to-date. Procedure according to Xtensa ISA document, ISYNC inst desc.\n-\t\t\t\tasm volatile(\"ISYNC\\nISYNC\\n\");\n+\t\t\t\t__asm__ __volatile__ (\"ISYNC\\nISYNC\\n\");\n \t\t\t\tgdbSendPacketOK();\n \t\t\t} else {\n \t\t\t\t//Trying to do a software breakpoint on a flash proc, perhaps?\ndiff --git a/libraries/SPISlave/src/hspi_slave.c b/libraries/SPISlave/src/hspi_slave.c\nindex c597e7aa88..8462b84146 100644\n--- a/libraries/SPISlave/src/hspi_slave.c\n+++ b/libraries/SPISlave/src/hspi_slave.c\n@@ -28,8 +28,9 @@ static void (*_hspi_slave_rx_status_cb)(void * arg, uint32_t data) = NULL;\n static void (*_hspi_slave_tx_status_cb)(void * arg) = NULL;\n static uint8_t _hspi_slave_buffer[33];\n \n-void ICACHE_RAM_ATTR _hspi_slave_isr_handler(void *arg)\n+void ICACHE_RAM_ATTR _hspi_slave_isr_handler(void *arg, void *frame)\n {\n+    (void) frame;\n     uint32_t status;\n     uint32_t istatus;\n \ndiff --git a/libraries/Ticker/src/Ticker.h b/libraries/Ticker/src/Ticker.h\nindex 07ce33c623..791ff94567 100644\n--- a/libraries/Ticker/src/Ticker.h\n+++ b/libraries/Ticker/src/Ticker.h\n@@ -74,16 +74,22 @@ class Ticker\n     template<typename TArg>\n     void attach(float seconds, void (*callback)(TArg), TArg arg)\n     {\n+#pragma GCC diagnostic push\n+#pragma GCC diagnostic ignored \"-Wcast-function-type\"\n         static_assert(sizeof(TArg) <= sizeof(void*), \"attach() callback argument size must be <= sizeof(void*)\");\n         _attach_ms(1000UL * seconds, true, reinterpret_cast<callback_with_arg_t>(callback), reinterpret_cast<void*>(arg));\n+#pragma GCC diagnostic pop\n     }\n \n     // callback will be called in SYS ctx when ticker fires\n     template<typename TArg>\n     void attach_ms(uint32_t milliseconds, void (*callback)(TArg), TArg arg)\n     {\n+#pragma GCC diagnostic push\n+#pragma GCC diagnostic ignored \"-Wcast-function-type\"\n         static_assert(sizeof(TArg) <= sizeof(void*), \"attach() callback argument size must be <= sizeof(void*)\");\n         _attach_ms(milliseconds, true, reinterpret_cast<callback_with_arg_t>(callback), reinterpret_cast<void*>(arg));\n+#pragma GCC diagnostic pop\n     }\n \n     // callback will be called at following loop() after ticker fires\ndiff --git a/package/package_esp8266com_index.template.json b/package/package_esp8266com_index.template.json\nindex 33b5b919a5..fdf6dcc43d 100644\n--- a/package/package_esp8266com_index.template.json\n+++ b/package/package_esp8266com_index.template.json\n@@ -123,19 +123,14 @@\n                \"toolsDependencies\": [\n                   {\n                      \"packager\": \"esp8266\",\n-                     \"version\": \"2.5.0-4-b40a506\",\n+                     \"version\": \"3.0.0-gnu12-dc7f933\",\n                      \"name\": \"xtensa-lx106-elf-gcc\"\n                   },\n                   {\n                      \"packager\": \"esp8266\",\n-                     \"version\": \"2.5.0-4-b40a506\",\n+                     \"version\": \"3.0.0-gnu12-dc7f933\",\n                      \"name\": \"mkspiffs\"\n                   },\n-                  {\n-                     \"packager\": \"esp8266\",\n-                     \"version\": \"2.5.0-4-fe5bb56\",\n-                     \"name\": \"mklittlefs\"\n-                  },\n                   {\n                      \"packager\": \"esp8266\",\n                      \"version\": \"3.7.2-post1\",\n@@ -204,174 +199,167 @@\n                ]\n             },\n             {\n-               \"version\": \"2.5.0-4-b40a506\",\n+               \"version\": \"3.0.0-gnu12-dc7f933\",\n                \"name\": \"xtensa-lx106-elf-gcc\",\n                \"systems\": [\n                   {\n                      \"host\": \"aarch64-linux-gnu\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/aarch64-linux-gnu.xtensa-lx106-elf-b40a506.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"aarch64-linux-gnu.xtensa-lx106-elf-b40a506.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:88c5e9a813bd01c97fe2a07a7280e0685cf18a937ad3ea756d33f8bfbbcbfec3\",\n-                     \"size\": \"40983153\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/aarch64-linux-gnu.xtensa-lx106-elf-0474ae9.200706.tar.gz\",\n+                     \"archiveFileName\": \"aarch64-linux-gnu.xtensa-lx106-elf-0474ae9.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:942bb00a70a82f3a91a278da8d9e9064e82d2cb5e4663c61887ee26c3aba5890\",\n+                     \"size\": \"70854850\"\n                   },\n                   {\n                      \"host\": \"arm-linux-gnueabihf\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/arm-linux-gnueabihf.xtensa-lx106-elf-b40a506.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"arm-linux-gnueabihf.xtensa-lx106-elf-b40a506.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:244d958e2532e5e1195aa6c8bb38e6fcf1601d88b67631a371d93c818a5a5b65\",\n-                     \"size\": \"37027468\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/arm-linux-gnueabihf.xtensa-lx106-elf-0474ae9.200706.tar.gz\",\n+                     \"archiveFileName\": \"arm-linux-gnueabihf.xtensa-lx106-elf-0474ae9.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:440c17e590ae3b2ec756c746a925e7d5f375f371e424513f05c2925695e9b3d9\",\n+                     \"size\": \"66929315\"\n                   },\n                   {\n                      \"host\": \"i686-pc-linux-gnu\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/i686-linux-gnu.xtensa-lx106-elf-b40a506.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"i686-linux-gnu.xtensa-lx106-elf-b40a506.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:7c84fa929231d2467060b82ba51599cfb227dea1ac58964c74d46800ac33ba47\",\n-                     \"size\": \"42926131\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/i686-linux-gnu.xtensa-lx106-elf-0474ae9.200706.tar.gz\",\n+                     \"archiveFileName\": \"i686-linux-gnu.xtensa-lx106-elf-0474ae9.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:fa8fad65bc0d986ced6143efd31d00a50f1ef2a0bbb41c5ee8ea2e01055da627\",\n+                     \"size\": \"74021024\"\n                   },\n                   {\n                      \"host\": \"i686-mingw32\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/i686-w64-mingw32.xtensa-lx106-elf-b40a506.1563313032.zip\",\n-                     \"archiveFileName\": \"i686-w64-mingw32.xtensa-lx106-elf-b40a506.1563313032.zip\",\n-                     \"checksum\": \"SHA-256:694680c2215a65364748ca876c701479580c017757cd8ed6c3df0d48c2f7bd79\",\n-                     \"size\": \"44955630\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/i686-w64-mingw32.xtensa-lx106-elf-0474ae9.200706.zip\",\n+                     \"archiveFileName\": \"i686-w64-mingw32.xtensa-lx106-elf-0474ae9.200706.zip\",\n+                     \"checksum\": \"SHA-256:e2473efcf864bbce641094e9adb2ea58f2076f815dfc092b882733201a3dabdf\",\n+                     \"size\": \"71049719\"\n                   },\n                   {\n                      \"host\": \"x86_64-apple-darwin\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/x86_64-apple-darwin14.xtensa-lx106-elf-b40a506.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"x86_64-apple-darwin14.xtensa-lx106-elf-b40a506.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:ddf7a7ea4d53469918671ea662cf529dae5b255f06054db17621b34c71710641\",\n-                     \"size\": \"44393288\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/x86_64-apple-darwin14.xtensa-lx106-elf-0474ae9.200706.tar.gz\",\n+                     \"archiveFileName\": \"x86_64-apple-darwin14.xtensa-lx106-elf-0474ae9.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:2a10610dbcfd27ffe865a6283d363cbb95be2f0980b6518231aebb42bc662235\",\n+                     \"size\": \"75441014\"\n                   },\n                   {\n                      \"host\": \"x86_64-pc-linux-gnu\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/x86_64-linux-gnu.xtensa-lx106-elf-b40a506.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"x86_64-linux-gnu.xtensa-lx106-elf-b40a506.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:90e04da49be288f36097d231e2f46ac46204a7640507011358f8f72c04700080\",\n-                     \"size\": \"43790957\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/x86_64-linux-gnu.xtensa-lx106-elf-0474ae9.200706.tar.gz\",\n+                     \"archiveFileName\": \"x86_64-linux-gnu.xtensa-lx106-elf-0474ae9.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:3feba2c3e9b5a604c397d6631cb75e914eecc2e1de278d2be7ea1ebca19358e8\",\n+                     \"size\": \"74546227\"\n                   },\n                   {\n                      \"host\": \"x86_64-mingw32\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/x86_64-w64-mingw32.xtensa-lx106-elf-b40a506.1563313032.zip\",\n-                     \"archiveFileName\": \"x86_64-w64-mingw32.xtensa-lx106-elf-b40a506.1563313032.zip\",\n-                     \"checksum\": \"SHA-256:01c31cd521b058e0805b9d1f3728798a42b1a217a7a34debcda3fcba23414b0e\",\n-                     \"size\": \"48656678\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/x86_64-w64-mingw32.xtensa-lx106-elf-0474ae9.200706.zip\",\n+                     \"archiveFileName\": \"x86_64-w64-mingw32.xtensa-lx106-elf-0474ae9.200706.zip\",\n+                     \"checksum\": \"SHA-256:cc1cbaa836969362ad5c6fa799306407d62caa3c1e0e9a493c3be87265201348\",\n+                     \"size\": \"75023572\"\n                   }\n                ]\n             },\n             {\n-               \"version\": \"2.5.0-4-b40a506\",\n+               \"version\": \"3.0.0-gnu12-dc7f933\",\n                \"name\": \"mkspiffs\",\n                \"systems\": [\n                   {\n                      \"host\": \"aarch64-linux-gnu\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/aarch64-linux-gnu.mkspiffs-7fefeac.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"aarch64-linux-gnu.mkspiffs-7fefeac.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:49cc1938d5df2bec3eec0b3bf2c84ab887c379b04973a67705c80cf1dec523b3\",\n-                     \"size\": \"51017\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/aarch64-linux-gnu.mkspiffs-7fefeac.200706.tar.gz\",\n+                     \"archiveFileName\": \"aarch64-linux-gnu.mkspiffs-7fefeac.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:a214959ea28f25cf1c1421d06cc1cc62b595f9814eb8fbd243ac75e51a902c51\",\n+                     \"size\": \"51253\"\n                   },\n                   {\n                      \"host\": \"arm-linux-gnueabihf\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/arm-linux-gnueabihf.mkspiffs-7fefeac.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"arm-linux-gnueabihf.mkspiffs-7fefeac.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:084518fe5452bc2a33c346e3f0825a7c42e36bdb41ee3320f767a248452813be\",\n-                     \"size\": \"44050\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/arm-linux-gnueabihf.mkspiffs-7fefeac.200706.tar.gz\",\n+                     \"archiveFileName\": \"arm-linux-gnueabihf.mkspiffs-7fefeac.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:937b5165ee390068d9d37b448104fa4c86ebfb733daca9a04319d43a782476f3\",\n+                     \"size\": \"44265\"\n                   },\n                   {\n                      \"host\": \"i686-pc-linux-gnu\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/i686-linux-gnu.mkspiffs-7fefeac.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"i686-linux-gnu.mkspiffs-7fefeac.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:d121a44416db8c9772372978f5accd13fe5a926fd17faf55a8dce23744dfc88c\",\n-                     \"size\": \"54278\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/i686-linux-gnu.mkspiffs-7fefeac.200706.tar.gz\",\n+                     \"archiveFileName\": \"i686-linux-gnu.mkspiffs-7fefeac.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:79b89d134da9f786e7dba3b984280d679a47d4605c46bfa72c5d65addbf889c1\",\n+                     \"size\": \"54512\"\n                   },\n                   {\n                      \"host\": \"i686-mingw32\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/i686-w64-mingw32.mkspiffs-7fefeac.1563313032.zip\",\n-                     \"archiveFileName\": \"i686-w64-mingw32.mkspiffs-7fefeac.1563313032.zip\",\n-                     \"checksum\": \"SHA-256:3e0fd9212027cba06e362ae6921f48d252834996d81e1ade41d5b5c54735837a\",\n-                     \"size\": \"337874\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/i686-w64-mingw32.mkspiffs-7fefeac.200706.zip\",\n+                     \"archiveFileName\": \"i686-w64-mingw32.mkspiffs-7fefeac.200706.zip\",\n+                     \"checksum\": \"SHA-256:2969a7e9b4c83f75938494c75945c767ab2e31206c0196d0a0eb9bb165697a94\",\n+                     \"size\": \"338191\"\n                   },\n                   {\n                      \"host\": \"x86_64-apple-darwin\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/x86_64-apple-darwin14.mkspiffs-7fefeac.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"x86_64-apple-darwin14.mkspiffs-7fefeac.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:efa480b351be563d35bd6a9bee809cd860f49efd26df711500df02b61460e19c\",\n-                     \"size\": \"368555\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/x86_64-apple-darwin14.mkspiffs-7fefeac.200706.tar.gz\",\n+                     \"archiveFileName\": \"x86_64-apple-darwin14.mkspiffs-7fefeac.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:02de9f7783c7425973a940e25752de908e20c49bfcf40ea1ae85d486f0f8061a\",\n+                     \"size\": \"368766\"\n                   },\n                   {\n                      \"host\": \"x86_64-pc-linux-gnu\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/x86_64-linux-gnu.mkspiffs-7fefeac.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"x86_64-linux-gnu.mkspiffs-7fefeac.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:238f9936f5b39f747602becfe90fae0ed6b31e63ea1fa6f5da062fcb33e0aae9\",\n-                     \"size\": \"52429\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/x86_64-linux-gnu.mkspiffs-7fefeac.200706.tar.gz\",\n+                     \"archiveFileName\": \"x86_64-linux-gnu.mkspiffs-7fefeac.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:761da6e3b5c5bbd9a7ed04a64ca13da7e87148e9646a1a1a9153c31c93b11ab9\",\n+                     \"size\": \"52645\"\n                   },\n                   {\n                      \"host\": \"x86_64-mingw32\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/x86_64-w64-mingw32.mkspiffs-7fefeac.1563313032.zip\",\n-                     \"archiveFileName\": \"x86_64-w64-mingw32.mkspiffs-7fefeac.1563313032.zip\",\n-                     \"checksum\": \"SHA-256:1c71a7ce71bd39fb83bfab138388adca8c1f9b798e09efd9932aa99d26c04c9b\",\n-                     \"size\": \"350035\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/x86_64-w64-mingw32.mkspiffs-7fefeac.200706.zip\",\n+                     \"archiveFileName\": \"x86_64-w64-mingw32.mkspiffs-7fefeac.200706.zip\",\n+                     \"checksum\": \"SHA-256:9017ebfdd74b0784d95ccc7b9647135fecf99008a99784c0dfd656fe22ddcd38\",\n+                     \"size\": \"350353\"\n                   }\n                ]\n             },\n             {\n-               \"version\": \"2.5.0-4-fe5bb56\",\n+               \"version\": \"3.0.0-gnu12-dc7f933\",\n                \"name\": \"mklittlefs\",\n                \"systems\": [\n                   {\n                      \"host\": \"aarch64-linux-gnu\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/aarch64-linux-gnu.mklittlefs-fe5bb56.1578453304.tar.gz\",\n-                     \"archiveFileName\": \"aarch64-linux-gnu.mklittlefs-fe5bb56.1578453304.tar.gz\",\n-                     \"checksum\": \"SHA-256:ac50bae3b580053ba98a181ae3700fafd2b2f8a37ed9c16bc22a5d7c1659388e\",\n-                     \"size\": \"44433\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/aarch64-linux-gnu.mklittlefs-c41e51a.200706.tar.gz\",\n+                     \"archiveFileName\": \"aarch64-linux-gnu.mklittlefs-c41e51a.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:fc56e389383749e4cf4fab0fcf75cc0ebc41e59383caf6c2eff1c3d9794af200\",\n+                     \"size\": \"44651\"\n                   },\n                   {\n                      \"host\": \"arm-linux-gnueabihf\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/arm-linux-gnueabihf.mklittlefs-fe5bb56.1578453304.tar.gz\",\n-                     \"archiveFileName\": \"arm-linux-gnueabihf.mklittlefs-fe5bb56.1578453304.tar.gz\",\n-                     \"checksum\": \"SHA-256:092555612e7e229fbe622df75db70560896c3aea8d0ac2e5fa16d92dc16857cf\",\n-                     \"size\": \"36917\"\n-                  },\n-                  {\n-                     \"host\": \"i686-pc-linux-gnu\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/i686-linux-gnu.mklittlefs-fe5bb56.1578453304.tar.gz\",\n-                     \"archiveFileName\": \"i686-linux-gnu.mklittlefs-fe5bb56.1578453304.tar.gz\",\n-                     \"checksum\": \"SHA-256:060e2525223269d2a5d01055542ff36837f0b19598d78cb02d58563aeda441cd\",\n-                     \"size\": \"47833\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/arm-linux-gnueabihf.mklittlefs-c41e51a.200706.tar.gz\",\n+                     \"archiveFileName\": \"arm-linux-gnueabihf.mklittlefs-c41e51a.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:52b642dd0545eb3bd8dfb75dde6601df21700e4867763fd2696274be279294c5\",\n+                     \"size\": \"37211\"\n                   },\n                   {\n                      \"host\": \"i686-pc-linux-gnu\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/i686-linux-gnu.mklittlefs-7f77f2b.1563313032.tar.gz\",\n-                     \"archiveFileName\": \"i686-linux-gnu.mklittlefs-7f77f2b.1563313032.tar.gz\",\n-                     \"checksum\": \"SHA-256:022c96df4d110f957d43f6d23e9c5e8b699a66d8ab041056dd5da7411a8ade42\",\n-                     \"size\": \"47544\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/i686-linux-gnu.mklittlefs-c41e51a.200706.tar.gz\",\n+                     \"archiveFileName\": \"i686-linux-gnu.mklittlefs-c41e51a.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:7886051d8ccc54aed0af2e7cdf6ff992bb51638df86f3b545955697720b6d062\",\n+                     \"size\": \"48033\"\n                   },\n                   {\n                      \"host\": \"i686-mingw32\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/i686-w64-mingw32.mklittlefs-fe5bb56.1578453304.zip\",\n-                     \"archiveFileName\": \"i686-w64-mingw32.mklittlefs-fe5bb56.1578453304.zip\",\n-                     \"checksum\": \"SHA-256:2e570bed4ec59a9ecc73290e16c31ed53ee15e3abd8c82cb038b2148596d112e\",\n-                     \"size\": \"332329\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/i686-w64-mingw32.mklittlefs-c41e51a.200706.zip\",\n+                     \"archiveFileName\": \"i686-w64-mingw32.mklittlefs-c41e51a.200706.zip\",\n+                     \"checksum\": \"SHA-256:43740db30ce451454f2337331f10ab4ed41bd83dbf0fa0cb4387107388b59f42\",\n+                     \"size\": \"332655\"\n                   },\n                   {\n                      \"host\": \"x86_64-apple-darwin\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/x86_64-apple-darwin14.mklittlefs-fe5bb56.1578453304.tar.gz\",\n-                     \"archiveFileName\": \"x86_64-apple-darwin14.mklittlefs-fe5bb56.1578453304.tar.gz\",\n-                     \"checksum\": \"SHA-256:fcb57ff58eceac79e988cc26a9e009a11ebda68d4ae97e44fed8e7c6d98a35b5\",\n-                     \"size\": \"362389\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/x86_64-apple-darwin14.mklittlefs-c41e51a.200706.tar.gz\",\n+                     \"archiveFileName\": \"x86_64-apple-darwin14.mklittlefs-c41e51a.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:e3edd5e05b70db3c7df6b9d626558348ad04804022fe955c799aeb51808c7dc3\",\n+                     \"size\": \"362608\"\n                   },\n                   {\n                      \"host\": \"x86_64-pc-linux-gnu\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/x86_64-linux-gnu.mklittlefs-fe5bb56.1578453304.tar.gz\",\n-                     \"archiveFileName\": \"x86_64-linux-gnu.mklittlefs-fe5bb56.1578453304.tar.gz\",\n-                     \"checksum\": \"SHA-256:5ef79d76e8e76f8287dc70d10c33f020d4cf5320354571adf666665eeef2e2de\",\n-                     \"size\": \"46580\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/x86_64-linux-gnu.mklittlefs-c41e51a.200706.tar.gz\",\n+                     \"archiveFileName\": \"x86_64-linux-gnu.mklittlefs-c41e51a.200706.tar.gz\",\n+                     \"checksum\": \"SHA-256:66e84dda0aad747517da3785125e05738a540948aab2b7eaa02855167a1eea53\",\n+                     \"size\": \"46778\"\n                   },\n                   {\n                      \"host\": \"x86_64-mingw32\",\n-                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/2.5.0-4/x86_64-w64-mingw32.mklittlefs-fe5bb56.1578453304.zip\",\n-                     \"archiveFileName\": \"x86_64-w64-mingw32.mklittlefs-fe5bb56.1578453304.zip\",\n-                     \"checksum\": \"SHA-256:a460f410a22a59e23d7f862b8d08d6b7dfbc93aa558f8161a3d640d4df2ab86f\",\n-                     \"size\": \"344792\"\n+                     \"url\": \"https://github.com/earlephilhower/esp-quick-toolchain/releases/download/3.0.0-gnu12/x86_64-w64-mingw32.mklittlefs-c41e51a.200706.zip\",\n+                     \"archiveFileName\": \"x86_64-w64-mingw32.mklittlefs-c41e51a.200706.zip\",\n+                     \"checksum\": \"SHA-256:2e319077491f8e832e96eb4f2f7a70dd919333cee4b388c394e0e848d031d542\",\n+                     \"size\": \"345132\"\n                   }\n                ]\n             }\ndiff --git a/platform.txt b/platform.txt\nindex 751d9c9b52..1b1354eb8e 100644\n--- a/platform.txt\n+++ b/platform.txt\n@@ -35,7 +35,9 @@ build.sslflags=\n \n build.exception_flags=-fno-exceptions\n build.stdcpp_lib=-lstdc++\n-build.stdcpp_level=-std=gnu++11\n+build.stdcpp_level=-std=gnu++17\n+\n+build.stacksmash=\n \n build.float=-u _printf_float -u _scanf_float\n build.led=\n@@ -53,7 +55,7 @@ compiler.libc.path={runtime.platform.path}/tools/sdk/libc/xtensa-lx106-elf\n compiler.cpreprocessor.flags=-D__ets__ -DICACHE_FLASH -U__STRICT_ANSI__ \"-I{compiler.sdk.path}/include\" \"-I{compiler.sdk.path}/{build.lwip_include}\" \"-I{compiler.libc.path}/include\" \"-I{build.path}/core\"\n \n compiler.c.cmd=xtensa-lx106-elf-gcc\n-compiler.c.flags=-c {compiler.warning_flags} -Os -g -Wpointer-arith -Wno-implicit-function-declaration -Wl,-EL -fno-inline-functions -nostdlib -mlongcalls -mtext-section-literals -falign-functions=4 -MMD -std=gnu99 -ffunction-sections -fdata-sections {build.exception_flags} {build.sslflags}\n+compiler.c.flags=-c {compiler.warning_flags} -std=c17 {build.stacksmash_flags} -Os -g -Wpointer-arith -Wno-implicit-function-declaration -Wl,-EL -fno-inline-functions -nostdlib -mlongcalls -mtext-section-literals -falign-functions=4 -MMD -ffunction-sections -fdata-sections {build.exception_flags} {build.sslflags}\n \n compiler.S.cmd=xtensa-lx106-elf-gcc\n compiler.S.flags=-c -g -x assembler-with-cpp -MMD -mlongcalls\n@@ -64,7 +66,7 @@ compiler.c.elf.cmd=xtensa-lx106-elf-gcc\n compiler.c.elf.libs=-lhal -lphy -lpp -lnet80211 {build.lwip_lib} -lwpa -lcrypto -lmain -lwps -lbearssl -laxtls -lespnow -lsmartconfig -lairkiss -lwpa2 {build.stdcpp_lib} -lm -lc -lgcc\n \n compiler.cpp.cmd=xtensa-lx106-elf-g++\n-compiler.cpp.flags=-c {compiler.warning_flags} -Os -g -mlongcalls -mtext-section-literals -fno-rtti -falign-functions=4 {build.stdcpp_level} -MMD -ffunction-sections -fdata-sections {build.exception_flags} {build.sslflags}\n+compiler.cpp.flags=-c {compiler.warning_flags} {build.stacksmash_flags} -Os -g -mlongcalls -mtext-section-literals -fno-rtti -falign-functions=4 {build.stdcpp_level} -MMD -ffunction-sections -fdata-sections {build.exception_flags} {build.sslflags}\n \n compiler.as.cmd=xtensa-lx106-elf-as\n \ndiff --git a/tests/platformio.sh b/tests/platformio.sh\nindex e2d24859d7..7e834fb6de 100755\n--- a/tests/platformio.sh\n+++ b/tests/platformio.sh\n@@ -8,6 +8,12 @@ function install_platformio()\n {\n     pip3 install --user -U https://github.com/platformio/platformio/archive/develop.zip\n     platformio platform install \"https://github.com/platformio/platform-espressif8266.git\"\n+    # Overwrite toolchain with this PR's toolset.  Probably better way to do this\n+    ( cd $TRAVIS_BUILD_DIR/tools && python3 get.py )\n+    mv ~/.platformio/packages/toolchain-xtensa/package.json .save\n+    rm -rf ~/.platformio/packages/toolchain-xtensa\n+    mv $TRAVIS_BUILD_DIR/tools/xtensa-lx106-elf ~/.platformio/packages/toolchain-xtensa\n+    mv .save ~/.platformio/packages/toolchain-xtensa/package.json\n     python -c \"import json; import os; fp=open(os.path.expanduser('~/.platformio/platforms/espressif8266/platform.json'), 'r+'); data=json.load(fp); data['packages']['framework-arduinoespressif8266']['version'] = '*'; fp.seek(0); fp.truncate(); json.dump(data, fp); fp.close()\"\n     ln -sf $TRAVIS_BUILD_DIR ~/.platformio/packages/framework-arduinoespressif8266\n     # Install dependencies:\ndiff --git a/tools/boards.txt.py b/tools/boards.txt.py\nindex 30f2a9bbe5..69793489af 100755\n--- a/tools/boards.txt.py\n+++ b/tools/boards.txt.py\n@@ -1006,6 +1006,13 @@\n         ( '.menu.exception.enabled.build.stdcpp_lib', '-lstdc++-exc' ),\n         ]),\n \n+    'stacksmash_menu': collections.OrderedDict([\n+        ( '.menu.stacksmash.disabled', 'Disabled' ),\n+        ( '.menu.stacksmash.disabled.build.stacksmash_flags', '' ),\n+        ( '.menu.stacksmash.enabled', 'Enabled' ),\n+        ( '.menu.stacksmash.enabled.build.stacksmash_flags', '-fstack-protector' ),\n+        ]),\n+\n     'crystalfreq_menu': collections.OrderedDict([\n         ( '.menu.CrystalFreq.26', '26 MHz' ),\n         ( '.menu.CrystalFreq.40', '40 MHz' ),\n@@ -1566,6 +1573,7 @@ def all_boards ():\n     print('menu.ip=lwIP Variant')\n     print('menu.vt=VTables')\n     print('menu.exception=Exceptions')\n+    print('menu.stacksmash=Stack Protection')\n     print('menu.wipe=Erase Flash')\n     print('menu.sdk=Espressif FW')\n     print('menu.ssl=SSL Support')\n@@ -1587,7 +1595,7 @@ def all_boards ():\n                 print(id + optname + '=' + board['opts'][optname])\n \n         # macros\n-        macrolist = [ 'defaults', 'cpufreq_menu', 'vtable_menu', 'exception_menu', 'ssl_cipher_menu' ]\n+        macrolist = [ 'defaults', 'cpufreq_menu', 'vtable_menu', 'exception_menu', 'stacksmash_menu', 'ssl_cipher_menu' ]\n         if 'macro' in board:\n             macrolist += board['macro']\n         if lwip == 2:\ndiff --git a/tools/platformio-build.py b/tools/platformio-build.py\nindex 33ba5380fc..6f315cd69a 100644\n--- a/tools/platformio-build.py\n+++ b/tools/platformio-build.py\n@@ -54,7 +54,7 @@ def scons_patched_match_splitext(path, suffixes=None):\n     ASFLAGS=[\"-x\", \"assembler-with-cpp\"],\n \n     CFLAGS=[\n-        \"-std=gnu99\",\n+        \"-std=c17\",\n         \"-Wpointer-arith\",\n         \"-Wno-implicit-function-declaration\",\n         \"-Wl,-EL\",\n@@ -76,7 +76,7 @@ def scons_patched_match_splitext(path, suffixes=None):\n \n     CXXFLAGS=[\n         \"-fno-rtti\",\n-        \"-std=c++11\"\n+        \"-std=gnu++17\"\n     ],\n \n     LINKFLAGS=[\ndiff --git a/tools/sdk/include/ets_sys.h b/tools/sdk/include/ets_sys.h\nindex e30607eed7..7908f127c3 100644\n--- a/tools/sdk/include/ets_sys.h\n+++ b/tools/sdk/include/ets_sys.h\n@@ -70,7 +70,9 @@ typedef struct _ETSTIMER_ {\n \n /* interrupt related */\n \n-typedef void (*int_handler_t)(void*);\n+// The xtos_1int handler calls with param1 as the arg, param2 as a pointer\n+// to an exception frame in memory.\n+typedef void (*int_handler_t)(void*, void*);\n \n #define ETS_SLC_INUM        1\n #define ETS_SDIO_INUM       1\n@@ -83,11 +85,11 @@ typedef void (*int_handler_t)(void*);\n #define ETS_WDT_INUM        8\n #define ETS_FRC_TIMER1_INUM 9  /* use edge*/\n \n-typedef void (* ets_isr_t)(void *);\n+// The xtos_1int handler calls with param1 as the arg, param2 as a pointer\n+// to an exception frame in memory.\n \n void ets_intr_lock(void);\n void ets_intr_unlock(void);\n-void ets_isr_attach(int i, ets_isr_t func, void *arg);\n \n void NmiTimSetFunc(void (*func)(void));\n \ndiff --git a/tools/sdk/ld/eagle.app.v6.common.ld.h b/tools/sdk/ld/eagle.app.v6.common.ld.h\nindex b7ba38e128..9e233b1ccf 100644\n--- a/tools/sdk/ld/eagle.app.v6.common.ld.h\n+++ b/tools/sdk/ld/eagle.app.v6.common.ld.h\n@@ -161,6 +161,10 @@ SECTIONS\n #endif\n     *libgcc.a:_umoddi3.o(.literal .text)\n     *libgcc.a:_udivdi3.o(.literal .text)\n+    *libgcc.a:_divsf3.o(.literal .text)\n+    *libgcc.a:_fixsfsi.o(.literal .text)\n+    *libgcc.a:_cmpdf2.o(.literal .text)\n+    *libgcc.a:_cmpsf2.o(.literal .text)\n     *libstdc++.a:( .literal .text .literal.* .text.*)\n     *libstdc++-exc.a:( .literal .text .literal.* .text.*)\n     *libsmartconfig.a:(.literal .text .literal.* .text.*)\n@@ -192,13 +196,17 @@ SECTIONS\n     /* Constant strings in flash (PSTRs) */\n     *(.irom0.pstr.*)\n \n+    /* Inline flash strings PSTR() within templated code */\n+    *(.rodata._ZZ*__pstr__*)\n+\n     /* __FUNCTION__ locals */\n     *(.rodata._ZZ*__FUNCTION__)\n     *(.rodata._ZZ*__PRETTY_FUNCTION__)\n     *(.rodata._ZZ*__func__)\n \n     /* std::* exception strings, in their own section to allow string coalescing */\n-    *(.irom.exceptiontext)\n+    *(.irom.exceptiontext, .rodata.exceptiontext)\n+    *(.rodata.*__exception_what__*) /* G++ seems to throw out templatized section attributes */\n \n     /* c++ typeof IDs, etc. */\n     *(.rodata._ZTIN* .rodata._ZTSN10* .rodata._ZTISt* .rodata._ZTSSt*)\ndiff --git a/tools/sdk/lib/libbearssl.a b/tools/sdk/lib/libbearssl.a\nindex 9fa5f9cb4e..ae8623201d 100644\nBinary files a/tools/sdk/lib/libbearssl.a and b/tools/sdk/lib/libbearssl.a differ\ndiff --git a/tools/sdk/lib/libgcc.a b/tools/sdk/lib/libgcc.a\nindex def0397657..9cd309f559 100644\nBinary files a/tools/sdk/lib/libgcc.a and b/tools/sdk/lib/libgcc.a differ\ndiff --git a/tools/sdk/lib/libhal.a b/tools/sdk/lib/libhal.a\nindex c2193e140b..0316a11bbb 100644\nBinary files a/tools/sdk/lib/libhal.a and b/tools/sdk/lib/libhal.a differ\ndiff --git a/tools/sdk/lib/liblwip2-1460-feat.a b/tools/sdk/lib/liblwip2-1460-feat.a\nindex 6c231417b2..227e62a655 100644\nBinary files a/tools/sdk/lib/liblwip2-1460-feat.a and b/tools/sdk/lib/liblwip2-1460-feat.a differ\ndiff --git a/tools/sdk/lib/liblwip2-1460.a b/tools/sdk/lib/liblwip2-1460.a\nindex 1e56d93913..55a451df1d 100644\nBinary files a/tools/sdk/lib/liblwip2-1460.a and b/tools/sdk/lib/liblwip2-1460.a differ\ndiff --git a/tools/sdk/lib/liblwip2-536-feat.a b/tools/sdk/lib/liblwip2-536-feat.a\nindex fe3218fa72..3976d501f8 100644\nBinary files a/tools/sdk/lib/liblwip2-536-feat.a and b/tools/sdk/lib/liblwip2-536-feat.a differ\ndiff --git a/tools/sdk/lib/liblwip2-536.a b/tools/sdk/lib/liblwip2-536.a\nindex 85c3db3bd3..c6b65c0078 100644\nBinary files a/tools/sdk/lib/liblwip2-536.a and b/tools/sdk/lib/liblwip2-536.a differ\ndiff --git a/tools/sdk/lib/liblwip6-1460-feat.a b/tools/sdk/lib/liblwip6-1460-feat.a\nindex 995020bde5..ba43447db8 100644\nBinary files a/tools/sdk/lib/liblwip6-1460-feat.a and b/tools/sdk/lib/liblwip6-1460-feat.a differ\ndiff --git a/tools/sdk/lib/liblwip6-536-feat.a b/tools/sdk/lib/liblwip6-536-feat.a\nindex 5e901a6879..f251aee321 100644\nBinary files a/tools/sdk/lib/liblwip6-536-feat.a and b/tools/sdk/lib/liblwip6-536-feat.a differ\ndiff --git a/tools/sdk/lib/libstdc++-exc.a b/tools/sdk/lib/libstdc++-exc.a\nindex dfb4b190bf..0a4929f0fb 100644\nBinary files a/tools/sdk/lib/libstdc++-exc.a and b/tools/sdk/lib/libstdc++-exc.a differ\ndiff --git a/tools/sdk/lib/libstdc++.a b/tools/sdk/lib/libstdc++.a\nindex 49d30d4791..21492fe4d9 100644\nBinary files a/tools/sdk/lib/libstdc++.a and b/tools/sdk/lib/libstdc++.a differ\ndiff --git a/tools/sdk/libc/xtensa-lx106-elf/include/sys/pgmspace.h b/tools/sdk/libc/xtensa-lx106-elf/include/sys/pgmspace.h\nindex 6d798ce7ca..c8c337aac9 100644\n--- a/tools/sdk/libc/xtensa-lx106-elf/include/sys/pgmspace.h\n+++ b/tools/sdk/libc/xtensa-lx106-elf/include/sys/pgmspace.h\n@@ -41,7 +41,7 @@ extern \"C\" {\n     // Multi-alignment variant of PSTR, n controls the alignment and should typically be 1 or 4\n     // Adapted from AVR-specific code at https://forum.arduino.cc/index.php?topic=194603.0\n     // Uses C attribute section instead of ASM block to allow for C language string concatenation (\"x\" \"y\" === \"xy\")\n-    #define PSTRN(s,n) (__extension__({static const char __c[] __attribute__((__aligned__(n))) __attribute__((section( \"\\\".irom0.pstr.\" __FILE__ \".\" __STRINGIZE(__LINE__) \".\"  __STRINGIZE(__COUNTER__) \"\\\", \\\"aSM\\\", @progbits, 1 #\"))) = (s); &__c[0];}))\n+    #define PSTRN(s,n) (__extension__({static const char __pstr__[] __attribute__((__aligned__(n))) __attribute__((section( \"\\\".irom0.pstr.\" __FILE__ \".\" __STRINGIZE(__LINE__) \".\"  __STRINGIZE(__COUNTER__) \"\\\", \\\"aSM\\\", @progbits, 1 #\"))) = (s); &__pstr__[0];}))\n #endif\n #ifndef PSTR\n   // PSTR() uses the default alignment defined by PSTR_ALIGN\n@@ -61,7 +61,7 @@ extern \"C\" {\n //     w1,     w0\n \n #define pgm_read_with_offset(addr, res) \\\n-  asm(\"extui    %0, %1, 0, 2\\n\"     /* Extract offset within word (in bytes) */ \\\n+  __asm__(\"extui    %0, %1, 0, 2\\n\"     /* Extract offset within word (in bytes) */ \\\n       \"sub      %1, %1, %0\\n\"       /* Subtract offset from addr, yielding an aligned address */ \\\n       \"l32i.n   %1, %1, 0x0\\n\"      /* Load word from aligned address */ \\\n       \"ssa8l    %0\\n\"               /* Prepare to shift by offset (in bits) */ \\\n@@ -71,25 +71,25 @@ extern \"C\" {\n       :);\n \n #define pgm_read_dword_with_offset(addr, res) \\\n-  asm(\"extui    %0, %1, 0, 2\\n\"     /* Extract offset within word (in bytes) */ \\\n+  __asm__(\"extui    %0, %1, 0, 2\\n\"     /* Extract offset within word (in bytes) */ \\\n       \"sub      %1, %1, %0\\n\"       /* Subtract offset from addr, yielding an aligned address */ \\\n-      \"l32i     a15, %1, 0\\n\" \\\n+      \"l32i     a14, %1, 0\\n\" \\\n       \"l32i     %1, %1, 4\\n\" \\\n       \"ssa8l    %0\\n\" \\\n-      \"src      %0, %1, a15\\n\" \\\n+      \"src      %0, %1, a14\\n\" \\\n       :\"=r\"(res), \"=r\"(addr) \\\n       :\"1\"(addr) \\\n-      :\"a15\");\n+      :\"a14\");\n \n static inline uint8_t pgm_read_byte_inlined(const void* addr) {\n-  register uint32_t res;\n+  uint32_t res;\n   pgm_read_with_offset(addr, res);\n   return (uint8_t) res;     /* This masks the lower byte from the returned word */\n }\n \n /* Although this says \"word\", it's actually 16 bit, i.e. half word on Xtensa */\n static inline uint16_t pgm_read_word_inlined(const void* addr) {\n-  register uint32_t res;\n+  uint32_t res;\n   pgm_read_with_offset(addr, res);\n   return (uint16_t) res;    /* This masks the lower half-word from the returned word */\n }\n@@ -97,7 +97,7 @@ static inline uint16_t pgm_read_word_inlined(const void* addr) {\n /* Can't legally cast bits of uint32_t to a float w/o conversion or std::memcpy, which is inefficient. */\n /* The ASM block doesn't care the type, so just pass in what C thinks is a float and return in custom fcn. */\n static inline float pgm_read_float_unaligned(const void *addr) {\n-  register float res;\n+  float res;\n   pgm_read_with_offset(addr, res);\n   return res;\n }\ndiff --git a/tools/sdk/libc/xtensa-lx106-elf/lib/crt0.o b/tools/sdk/libc/xtensa-lx106-elf/lib/crt0.o\nindex 8a790872c8..6e04087a58 100644\nBinary files a/tools/sdk/libc/xtensa-lx106-elf/lib/crt0.o and b/tools/sdk/libc/xtensa-lx106-elf/lib/crt0.o differ\ndiff --git a/tools/sdk/libc/xtensa-lx106-elf/lib/libc.a b/tools/sdk/libc/xtensa-lx106-elf/lib/libc.a\nindex 1562ca8095..6a8a50424a 100644\nBinary files a/tools/sdk/libc/xtensa-lx106-elf/lib/libc.a and b/tools/sdk/libc/xtensa-lx106-elf/lib/libc.a differ\ndiff --git a/tools/sdk/libc/xtensa-lx106-elf/lib/libg.a b/tools/sdk/libc/xtensa-lx106-elf/lib/libg.a\nindex 2a1a82d909..6a8a50424a 100644\nBinary files a/tools/sdk/libc/xtensa-lx106-elf/lib/libg.a and b/tools/sdk/libc/xtensa-lx106-elf/lib/libg.a differ\ndiff --git a/tools/sdk/libc/xtensa-lx106-elf/lib/libm.a b/tools/sdk/libc/xtensa-lx106-elf/lib/libm.a\nindex 0d2f0a4936..794ee229a9 100644\nBinary files a/tools/sdk/libc/xtensa-lx106-elf/lib/libm.a and b/tools/sdk/libc/xtensa-lx106-elf/lib/libm.a differ\ndiff --git a/tools/sdk/lwip2/builder b/tools/sdk/lwip2/builder\nindex 92add5010f..3798bf015b 160000\n--- a/tools/sdk/lwip2/builder\n+++ b/tools/sdk/lwip2/builder\n@@ -1 +1 @@\n-Subproject commit 92add5010fc329cbfbbcb1ce713108451cf9fc8c\n+Subproject commit 3798bf015b5a66e9b1a420ee0d3caa9ffe5d399e\ndiff --git a/tools/sdk/lwip2/include/gluedebug.h b/tools/sdk/lwip2/include/gluedebug.h\nindex a53099744d..f7a1917799 100644\n--- a/tools/sdk/lwip2/include/gluedebug.h\n+++ b/tools/sdk/lwip2/include/gluedebug.h\n@@ -38,9 +38,13 @@\n \n #define HAS_PHY_CAPTURE 1\n #ifdef __cplusplus\n-extern \"C\"\n+extern \"C\" {\n #endif\n-void (*phy_capture) (int netif_idx, const char* data, size_t len, int out, int success);\n+extern void (*phy_capture) (int netif_idx, const char* data, size_t len, int out, int success);\n+#ifdef __cplusplus\n+}\n+#endif\n+\n \n /////////////////////////////////////////////////////////////////////////////\n #if ARDUINO\ndiff --git a/tools/sdk/lwip2/include/lwip-git-hash.h b/tools/sdk/lwip2/include/lwip-git-hash.h\nindex 8a40c5e20e..88a4bb706c 100644\n--- a/tools/sdk/lwip2/include/lwip-git-hash.h\n+++ b/tools/sdk/lwip2/include/lwip-git-hash.h\n@@ -1,5 +1,5 @@\n // generated by makefiles/make-lwip2-hash\n #ifndef LWIP_HASH_H\n #define LWIP_HASH_H\n-#define LWIP_HASH_STR \"STABLE-2_1_2_RELEASE/glue:1.2-30-g92add50\"\n+#define LWIP_HASH_STR \"STABLE-2_1_2_RELEASE/glue:1.2-31-g3798bf0\"\n #endif // LWIP_HASH_H\ndiff --git a/tools/sdk/lwip2/include/lwip/priv/tcp_priv.h b/tools/sdk/lwip2/include/lwip/priv/tcp_priv.h\nindex 394d9633af..72f9126d46 100644\n--- a/tools/sdk/lwip2/include/lwip/priv/tcp_priv.h\n+++ b/tools/sdk/lwip2/include/lwip/priv/tcp_priv.h\n@@ -357,7 +357,7 @@ extern struct tcp_pcb ** const tcp_pcb_lists[NUM_TCP_PCB_LISTS];\n #if TCP_DEBUG_PCB_LISTS\n #define TCP_REG(pcbs, npcb) do {\\\n                             struct tcp_pcb *tcp_tmp_pcb; \\\n-                            LWIP_DEBUGF(TCP_DEBUG, (\"TCP_REG %p local port %\" U16_F \"\\n\", (void *)(npcb), (npcb)->local_port)); \\\n+                            LWIP_DEBUGF(TCP_DEBUG, (\"TCP_REG %p local port %\"U16_F\"\\n\", (void *)(npcb), (npcb)->local_port)); \\\n                             for (tcp_tmp_pcb = *(pcbs); \\\n           tcp_tmp_pcb != NULL; \\\n         tcp_tmp_pcb = tcp_tmp_pcb->next) { \\\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Compiler Compatibility Issue**: The `make_shared` functionality fails with GCC 9.2.0 due to missing references. Transition to the `gcc-9.1` branch resolves this. Recommend testing with GCC version specified in the toolchain for compatibility.\n\n2. **Optimization Settings**: Recompilation with `-O2` or `-O3` reduces IRAM usage but increases flash usage. Directly manipulate inline attributes to manage memory more effectively instead of only adjusting optimization flags.\n\n3. **Linker Script Improvement**: Consider adding output section filters to optimize .irom0.text for `__FUNCTION__` and `PSTR()` usage in templates. \n\n4. **PSTR Naming Convention**: Update `PSTR()` static variable naming in `pgmspace.h` from `__c` to something more descriptive, like `__pstr`.\n\n5. **Future Considerations**: Evaluate moving to C++17 for future PRs, as some deprecation issues exist with C++14 (e.g., `register`). \n\n6. **Next Steps**: Implement the linker script changes and test against updated optimization settings and compiler versions."
      }
    ],
    "codediff_length": 72293
  },
  {
    "index": 40,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/cores/esp8266/Esp.h b/cores/esp8266/Esp.h\nindex f717c15881..bc241eb392 100644\n--- a/cores/esp8266/Esp.h\n+++ b/cores/esp8266/Esp.h\n@@ -213,7 +213,8 @@ uint32_t EspClass::getCycleCount()\n     __asm__ __volatile__(\"esync; rsr %0,ccount\":\"=a\" (ccount));\n     return ccount;\n }\n-#endif\n+\n+#endif // !defined(CORE_MOCK)\n \n extern EspClass ESP;\n \ndiff --git a/cores/esp8266/FunctionalInterrupt.cpp b/cores/esp8266/FunctionalInterrupt.cpp\nindex 2633c63182..fa57e217e5 100644\n--- a/cores/esp8266/FunctionalInterrupt.cpp\n+++ b/cores/esp8266/FunctionalInterrupt.cpp\n@@ -1,7 +1,6 @@\n #include <FunctionalInterrupt.h>\n #include <Schedule.h>\n #include \"Arduino.h\"\n-#include <ScheduledFunctions.h>\n \n // Duplicate typedefs from core_esp8266_wiring_digital_c\n typedef void (*voidFuncPtr)(void);\n@@ -17,7 +16,6 @@ void ICACHE_RAM_ATTR interruptFunctional(void* arg)\n \tif (localArg->functionInfo->reqScheduledFunction)\n \t{\n \t\tschedule_function(std::bind(localArg->functionInfo->reqScheduledFunction,InterruptInfo(*(localArg->interruptInfo))));\n-//      scheduledInterrupts->scheduleFunctionReg(std::bind(localArg->functionInfo->reqScheduledFunction,InterruptInfo(*(localArg->interruptInfo))), false, true);\n \t}\n \tif (localArg->functionInfo->reqFunction)\n \t{\n@@ -54,10 +52,6 @@ void attachInterrupt(uint8_t pin, std::function<void(void)> intRoutine, int mode\n \n void attachScheduledInterrupt(uint8_t pin, std::function<void(InterruptInfo)> scheduledIntRoutine, int mode)\n {\n-\tif (!scheduledInterrupts)\n-\t{\n-\t\tscheduledInterrupts = new ScheduledFunctions(32);\n-\t}\n \tInterruptInfo* ii = new InterruptInfo;\n \n \tFunctionInfo* fi = new FunctionInfo;\ndiff --git a/cores/esp8266/FunctionalInterrupt.h b/cores/esp8266/FunctionalInterrupt.h\nindex a6d53188ae..968793e499 100644\n--- a/cores/esp8266/FunctionalInterrupt.h\n+++ b/cores/esp8266/FunctionalInterrupt.h\n@@ -4,7 +4,6 @@\n #include <stddef.h>\n #include <stdint.h>\n #include <functional>\n-#include <ScheduledFunctions.h>\n \n extern \"C\" {\n #include \"c_types.h\"\n@@ -29,7 +28,6 @@ struct ArgStructure {\n \tFunctionInfo* functionInfo = nullptr;\n };\n \n-static ScheduledFunctions* scheduledInterrupts;\n void attachInterrupt(uint8_t pin, std::function<void(void)> intRoutine, int mode);\n void attachScheduledInterrupt(uint8_t pin, std::function<void(InterruptInfo)> scheduledIntRoutine, int mode);\n \ndiff --git a/cores/esp8266/PolledTimeout.h b/cores/esp8266/PolledTimeout.h\nindex 95157d3772..fe9c9ca4bc 100644\n--- a/cores/esp8266/PolledTimeout.h\n+++ b/cores/esp8266/PolledTimeout.h\n@@ -153,7 +153,7 @@ class timeoutTemplate\n     reset(userTimeout);\n   }\n \n-  ICACHE_RAM_ATTR\n+  IRAM_ATTR // fast\n   bool expired()\n   {\n     YieldPolicyT::execute(); //in case of DoNothing: gets optimized away\n@@ -162,7 +162,7 @@ class timeoutTemplate\n     return expiredOneShot();\n   }\n   \n-  ICACHE_RAM_ATTR\n+  IRAM_ATTR // fast\n   operator bool()\n   {\n     return expired(); \n@@ -178,6 +178,7 @@ class timeoutTemplate\n     return _timeout != alwaysExpired;\n   }\n \n+  IRAM_ATTR // called from ISR\n   void reset(const timeType newUserTimeout)\n   {\n     reset();\n@@ -185,6 +186,7 @@ class timeoutTemplate\n     _neverExpires = (newUserTimeout < 0) || (newUserTimeout > timeMax());\n   }\n \n+  IRAM_ATTR // called from ISR\n   void reset()\n   {\n     _start = TimePolicyT::time();\n@@ -208,7 +210,7 @@ class timeoutTemplate\n \n private:\n \n-  ICACHE_RAM_ATTR\n+  IRAM_ATTR // fast\n   bool checkExpired(const timeType internalUnit) const\n   {\n     // canWait() is not checked here\n@@ -218,7 +220,7 @@ class timeoutTemplate\n \n protected:\n \n-  ICACHE_RAM_ATTR\n+  IRAM_ATTR // fast\n   bool expiredRetrigger()\n   {\n     if (!canWait())\n@@ -234,7 +236,7 @@ class timeoutTemplate\n     return false;\n   }\n   \n-  ICACHE_RAM_ATTR\n+  IRAM_ATTR // fast\n   bool expiredOneShot() const\n   {\n     // returns \"always expired\" or \"has expired\"\ndiff --git a/cores/esp8266/Schedule.cpp b/cores/esp8266/Schedule.cpp\nindex 27b9731954..bf968743e2 100644\n--- a/cores/esp8266/Schedule.cpp\n+++ b/cores/esp8266/Schedule.cpp\n@@ -1,78 +1,131 @@\n+\n+#include <assert.h>\n+\n #include \"Schedule.h\"\n+#include \"PolledTimeout.h\"\n+#include \"interrupts.h\"\n+\n+typedef std::function<bool(void)> mFuncT;\n \n struct scheduled_fn_t\n {\n-    scheduled_fn_t* mNext;\n-    std::function<void(void)> mFunc;\n+    scheduled_fn_t* mNext = nullptr;\n+    mFuncT mFunc;\n+    esp8266::polledTimeout::periodicFastUs callNow;\n+\n+    scheduled_fn_t() : callNow(esp8266::polledTimeout::periodicFastUs::alwaysExpired) { }\n };\n \n-static scheduled_fn_t* sFirst = 0;\n-static scheduled_fn_t* sLast = 0;\n+static scheduled_fn_t* sFirst = nullptr;\n+static scheduled_fn_t* sLast = nullptr;\n \n-static scheduled_fn_t* sFirstUnused = 0;\n-static scheduled_fn_t* sLastUnused = 0;\n+static scheduled_fn_t* sUnused = nullptr;\n \n static int sCount = 0;\n \n-static scheduled_fn_t* get_fn() {\n-    scheduled_fn_t* result = NULL;\n+IRAM_ATTR // called from ISR\n+static scheduled_fn_t* get_fn_unsafe()\n+{\n+    scheduled_fn_t* result = nullptr;\n     // try to get an item from unused items list\n-    if (sFirstUnused) {\n-        result = sFirstUnused;\n-        sFirstUnused = result->mNext;\n-        if (sFirstUnused == NULL) {\n-            sLastUnused = NULL;\n-        }\n+    if (sUnused)\n+    {\n+        result = sUnused;\n+        sUnused = sUnused->mNext;\n+        result->mNext = nullptr;\n     }\n     // if no unused items, and count not too high, allocate a new one\n-    else if (sCount != SCHEDULED_FN_MAX_COUNT) {\n+    else if (sCount < SCHEDULED_FN_MAX_COUNT)\n+    {\n         result = new scheduled_fn_t;\n-        result->mNext = NULL;\n         ++sCount;\n     }\n     return result;\n }\n \n-static void recycle_fn(scheduled_fn_t* fn)\n+static void recycle_fn_unsafe(scheduled_fn_t* fn)\n {\n-    if (!sLastUnused) {\n-        sFirstUnused = fn;\n-    }\n-    else {\n-        sLastUnused->mNext = fn;\n-    }\n-    fn->mNext = NULL;\n-    sLastUnused = fn;\n+    fn->mFunc = nullptr; // special overload in c++ std lib\n+    fn->mNext = sUnused;\n+    sUnused = fn;\n }\n \n-bool schedule_function(std::function<void(void)> fn)\n+IRAM_ATTR // (not only) called from ISR\n+bool schedule_function_us(std::function<bool(void)>&& fn, uint32_t repeat_us)\n {\n-    scheduled_fn_t* item = get_fn();\n-    if (!item) {\n+    assert(repeat_us < decltype(scheduled_fn_t::callNow)::neverExpires); //~26800000us (26.8s)\n+\n+    InterruptLock lockAllInterruptsInThisScope;\n+\n+    scheduled_fn_t* item = get_fn_unsafe();\n+    if (!item)\n         return false;\n-    }\n+\n+    if (repeat_us)\n+        item->callNow.reset(repeat_us);\n+\n     item->mFunc = fn;\n-    item->mNext = NULL;\n-    if (!sFirst) {\n-        sFirst = item;\n-    }\n-    else {\n+    if (sFirst)\n         sLast->mNext = item;\n-    }\n+    else\n+        sFirst = item;\n     sLast = item;\n+\n     return true;\n }\n \n+IRAM_ATTR // (not only) called from ISR\n+bool schedule_function_us(const std::function<bool(void)>& fn, uint32_t repeat_us)\n+{\n+    return schedule_function_us(std::function<bool(void)>(fn), repeat_us);\n+}\n+\n+IRAM_ATTR // called from ISR\n+bool schedule_function(std::function<void(void)>&& fn)\n+{\n+    return schedule_function_us([fn]() { fn(); return false; }, 0);\n+}\n+\n+IRAM_ATTR // called from ISR\n+bool schedule_function(const std::function<void(void)>& fn)\n+{\n+    return schedule_function(std::function<void(void)>(fn));\n+}\n+\n void run_scheduled_functions()\n {\n-\tscheduled_fn_t* rFirst = sFirst;\n-\tsFirst = NULL;\n-\tsLast  = NULL;\n-    while (rFirst) {\n-        scheduled_fn_t* item = rFirst;\n-        rFirst = item->mNext;\n-        item->mFunc();\n-        item->mFunc = std::function<void(void)>();\n-        recycle_fn(item);\n+    // Note to the reader:\n+    // There is no exposed API to remove a scheduled function:\n+    // Scheduled functions are removed only from this function, and\n+    // its purpose is that it is never called from an interrupt\n+    // (always on cont stack).\n+\n+    scheduled_fn_t* lastRecurring = nullptr;\n+    scheduled_fn_t* toCall = sFirst;\n+    while (toCall)\n+    {\n+        scheduled_fn_t* item = toCall;\n+        toCall = toCall->mNext;\n+        if (item->callNow)\n+        {\n+            if (item->mFunc())\n+            {\n+                lastRecurring = item;\n+            }\n+            else\n+            {\n+                InterruptLock lockAllInterruptsInThisScope;\n+\n+                if (sFirst == item)\n+                    sFirst = sFirst->mNext;\n+                else if (lastRecurring)\n+                    lastRecurring->mNext = item->mNext;\n+\n+                if (sLast == item)\n+                    sLast = lastRecurring;\n+\n+                recycle_fn_unsafe(item);\n+            }\n+        }\n     }\n }\ndiff --git a/cores/esp8266/Schedule.h b/cores/esp8266/Schedule.h\nindex 3399972945..bda3ebf48e 100644\n--- a/cores/esp8266/Schedule.h\n+++ b/cores/esp8266/Schedule.h\n@@ -4,22 +4,28 @@\n #include <functional>\n \n #define SCHEDULED_FN_MAX_COUNT 32\n-#define SCHEDULED_FN_INITIAL_COUNT 4\n \n-// Warning \n-// This API is not considered stable. \n-// Function signatures will change.\n+// This API was not considered stable but is now stabilizing.\n+// Function signatures may change, queue must stay FIFO.\n // You have been warned.\n \n-// Run given function next time `loop` function returns, \n+// Run given function ONCE next time `loop` function returns,\n+// or `yield` is called,\n // or `run_scheduled_functions` is called.\n // Use std::bind to pass arguments to a function, or call a class member function.\n // Note: there is no mechanism for cancelling scheduled functions.\n // Keep that in mind when binding functions to objects which may have short lifetime.\n // Returns false if the number of scheduled functions exceeds SCHEDULED_FN_MAX_COUNT.\n-bool schedule_function(std::function<void(void)> fn);\n+//bool schedule_function(std::function<void(void)>&& fn);\n+bool schedule_function(const std::function<void(void)>& fn);\n \n-// Run all scheduled functions. \n+// Run given function periodically about every <repeat_us> microseconds until it returns false.\n+// Note that it may be more than <repeat_us> microseconds between calls if `yield` is not called\n+// frequently, and therefore should not be used for timing critical operations.\n+//bool schedule_function_us(std::function<bool(void)>&& fn, uint32_t repeat_us);\n+bool schedule_function_us(const std::function<bool(void)>& fn, uint32_t repeat_us);\n+\n+// Run all scheduled functions.\n // Use this function if your are not using `loop`, or `loop` does not return\n // on a regular basis.\n void run_scheduled_functions();\ndiff --git a/cores/esp8266/ScheduledFunctions.cpp b/cores/esp8266/ScheduledFunctions.cpp\ndeleted file mode 100644\nindex 25bc58db61..0000000000\n--- a/cores/esp8266/ScheduledFunctions.cpp\n+++ /dev/null\n@@ -1,117 +0,0 @@\n-/*\n- * ScheduledFunctions.cpp\n- *\n- *  Created on: 27 apr. 2018\n- *      Author: Herman\n- */\n-#include \"ScheduledFunctions.h\"\n-\n-std::list<ScheduledFunctions::ScheduledElement> ScheduledFunctions::scheduledFunctions;\n-\n-ScheduledFunctions::ScheduledFunctions()\n-:ScheduledFunctions(UINT_MAX)\n-{\n-}\n-\n-ScheduledFunctions::ScheduledFunctions(unsigned int reqMax)\n-{\n-\tmaxElements = reqMax;\n-}\n-\n-ScheduledFunctions::~ScheduledFunctions() {\n-}\n-\n-ScheduledRegistration ScheduledFunctions::insertElement(ScheduledElement se, bool front)\n-{\n-\tif (countElements >= maxElements)\n-\t{\n-\t\treturn nullptr;\n-\t}\n-\telse\n-\t{\n-\t\tcountElements++;\n-\t\tif (front)\n-\t\t {\n-\t\t\tscheduledFunctions.push_front(se);\n-\t\t\treturn scheduledFunctions.begin()->registration;\n-\t\t }\n-\t\t else\n-\t\t {\n-\t\t\t scheduledFunctions.push_back(se);\n-\t\t\t return scheduledFunctions.rbegin()->registration;\n-\t\t }\n-\t}\n-}\n-\n-std::list<ScheduledFunctions::ScheduledElement>::iterator ScheduledFunctions::eraseElement(std::list<ScheduledFunctions::ScheduledElement>::iterator it)\n-{\n-\tcountElements--;\n-\treturn scheduledFunctions.erase(it);\n-}\n-\n-bool ScheduledFunctions::scheduleFunction(ScheduledFunction sf, bool continuous, bool front)\n-{\n-\treturn (insertElement({this,continuous,nullptr,sf}, front) == nullptr);\n-}\n-\n-bool ScheduledFunctions::scheduleFunction(ScheduledFunction sf)\n-{\n-\treturn scheduleFunction(sf, false, false);\n-}\n-\n-ScheduledRegistration ScheduledFunctions::scheduleFunctionReg (ScheduledFunction sf, bool continuous, bool front)\n-{\n-\treturn insertElement({this,continuous,std::make_shared<int>(1),sf},front);\n-}\n-\n-void ScheduledFunctions::runScheduledFunctions()\n-{\n-\tauto lastElement = scheduledFunctions.end(); // do not execute elements added during runScheduledFunctions\n-\tauto it = scheduledFunctions.begin();\n-\twhile (it != lastElement)\n-\t{\n-\t\tbool erase = false;\n-\t\tif (it->registration == nullptr)\n-\t\t{\n-\t\t\tit->function();\n-\t\t}\n-\t\telse\n-\t\t{\n-\t\t\tif (it->registration.use_count() > 1)\n-\t\t\t{\n-\t\t\t\tit->function();\n-\t\t\t}\n-\t\t\telse\n-\t\t\t{\n-\t\t\t\terase = true;\n-\t\t\t}\n-\t\t}\n-\t\tif ((!it->continuous) || (erase))\n-\t\t{\n-\t\t\tit = it->_this->eraseElement(it);\n-\t\t}\n-\t\telse\n-\t\t{\n-\t\t\tit++;\n-\t\t}\n-\t}\n-}\n-\n-void ScheduledFunctions::removeFunction(ScheduledRegistration sr)\n-{\n-\tauto it = scheduledFunctions.begin();\n-\tbool removed = false;\n-\twhile ((!removed) && (it != scheduledFunctions.end()))\n-\t{\n-\t\tif (it->registration == sr)\n-\t\t{\n-\t\t\tit = eraseElement(it);\n-\t\t\tremoved = true;\n-\t\t}\n-\t\telse\n-\t\t{\n-\t\t\tit++;\n-\t\t}\n-\t}\n-}\n-\ndiff --git a/cores/esp8266/ScheduledFunctions.h b/cores/esp8266/ScheduledFunctions.h\ndeleted file mode 100644\nindex 0129635364..0000000000\n--- a/cores/esp8266/ScheduledFunctions.h\n+++ /dev/null\n@@ -1,51 +0,0 @@\n-/*\n- * ScheduledFunctions.h\n- *\n- *  Created on: 27 apr. 2018\n- *      Author: Herman\n- */\n-#include \"Arduino.h\"\n-#include \"Schedule.h\"\n-\n-#include <functional>\n-#include <memory>\n-#include <list>\n-#include <climits>\n-\n-#ifndef SCHEDULEDFUNCTIONS_H_\n-#define SCHEDULEDFUNCTIONS_H_\n-\n-typedef std::function<void(void)> ScheduledFunction;\n-typedef std::shared_ptr<void> ScheduledRegistration;\n-\n-class ScheduledFunctions {\n-\n-public:\n-\tScheduledFunctions();\n-\tScheduledFunctions(unsigned int reqMax);\n-\tvirtual ~ScheduledFunctions();\n-\n-\tstruct ScheduledElement\n-\t{\n-\t\tScheduledFunctions* _this;\n-\t\tbool continuous;\n-\t\tScheduledRegistration registration;\n-\t\tScheduledFunction function;\n-\t};\n-\n-\tScheduledRegistration insertElement(ScheduledElement se, bool front);\n-\tstd::list<ScheduledElement>::iterator eraseElement(std::list<ScheduledElement>::iterator);\n-\tbool scheduleFunction(ScheduledFunction sf, bool continuous, bool front);\n-\tbool scheduleFunction(ScheduledFunction sf);\n-\tScheduledRegistration scheduleFunctionReg (ScheduledFunction sf, bool continuous, bool front);\n-\tstatic void runScheduledFunctions();\n-\tvoid removeFunction(ScheduledRegistration sr);\n-\n-\n-\tstatic std::list<ScheduledElement> scheduledFunctions;\n-\tunsigned int maxElements;\n-\tunsigned int countElements = 0;\n-\n-};\n-\n-#endif /* SCHEDULEDFUNCTIONS_H_ */\ndiff --git a/cores/esp8266/core_esp8266_main.cpp b/cores/esp8266/core_esp8266_main.cpp\nindex 5d0fb54e65..7ab1e56bf7 100644\n--- a/cores/esp8266/core_esp8266_main.cpp\n+++ b/cores/esp8266/core_esp8266_main.cpp\n@@ -91,13 +91,15 @@ extern \"C\" void esp_yield() {\n }\n \n extern \"C\" void esp_schedule() {\n+    // always on CONT stack here\n+    run_scheduled_functions();\n     ets_post(LOOP_TASK_PRIORITY, 0, 0);\n }\n \n extern \"C\" void __yield() {\n     if (cont_can_yield(g_pcont)) {\n         esp_schedule();\n-        esp_yield();\n+        cont_yield(g_pcont); //esp_yield();\n     }\n     else {\n         panic();\n@@ -122,7 +124,6 @@ static void loop_wrapper() {\n         setup_done = true;\n     }\n     loop();\n-    run_scheduled_functions();\n     esp_schedule();\n }\n \ndiff --git a/tests/host/common/Arduino.h b/tests/host/common/Arduino.h\nindex 9b75fc114c..02f0d9695f 100644\n--- a/tests/host/common/Arduino.h\n+++ b/tests/host/common/Arduino.h\n@@ -143,26 +143,12 @@ extern \"C\" {\n #define __STRINGIFY(a) #a\n #endif\n     \n-    // these low level routines provide a replacement for SREG interrupt save that AVR uses\n-    // but are esp8266 specific. A normal use pattern is like\n-    //\n-    //{\n-    //    uint32_t savedPS = xt_rsil(1); // this routine will allow level 2 and above\n-    //    // do work here\n-    //    xt_wsr_ps(savedPS); // restore the state\n-    //}\n-    //\n-    // level (0-15), interrupts of the given level and above will be active\n-    // level 15 will disable ALL interrupts,\n-    // level 0 will enable ALL interrupts,\n-    //\n-#define xt_rsil(level) (__extension__({uint32_t state; __asm__ __volatile__(\"rsil %0,\" __STRINGIFY(level) : \"=a\" (state)); state;}))\n-#define xt_wsr_ps(state)  __asm__ __volatile__(\"wsr %0,ps; isync\" :: \"a\" (state) : \"memory\")\n-    \n+#define xt_rsil(level) (level)\n+#define xt_wsr_ps(state) do { (void)(state); } while (0)\n+\n #define interrupts() xt_rsil(0)\n #define noInterrupts() xt_rsil(15)\n-    \n-    \n+\n #define clockCyclesPerMicrosecond() ( F_CPU / 1000000L )\n #define clockCyclesToMicroseconds(a) ( (a) / clockCyclesPerMicrosecond() )\n #define microsecondsToClockCycles(a) ( (a) * clockCyclesPerMicrosecond() )\ndiff --git a/tests/host/common/c_types.h b/tests/host/common/c_types.h\nindex 897c2cbc6e..867f2f7726 100644\n--- a/tests/host/common/c_types.h\n+++ b/tests/host/common/c_types.h\n@@ -102,6 +102,9 @@ typedef enum {\n #define ICACHE_RODATA_ATTR\n #endif /* ICACHE_FLASH */\n \n+// counterpart https://github.com/espressif/arduino-esp32/blob/master/cores/esp32/esp8266-compat.h\n+#define IRAM_ATTR ICACHE_RAM_ATTR\n+\n #define STORE_ATTR __attribute__((aligned(4)))\n \n #ifndef __cplusplus\ndiff --git a/tests/host/common/mock.h b/tests/host/common/mock.h\nindex 067411139f..e681d64975 100644\n--- a/tests/host/common/mock.h\n+++ b/tests/host/common/mock.h\n@@ -131,8 +131,6 @@ void mockUDPSwallow (size_t copied, char* ccinbuf, size_t& ccinbufsize);\n class UdpContext;\n void register_udp (int sock, UdpContext* udp = nullptr);\n \n-class InterruptLock { };\n-\n //\n \n void mock_start_spiffs (const String& fname, size_t size_kb, size_t block_kb = 8, size_t page_b = 512);\ndiff --git a/tools/sdk/include/c_types.h b/tools/sdk/include/c_types.h\nindex 40eb5bedf9..88dc147213 100644\n--- a/tools/sdk/include/c_types.h\n+++ b/tools/sdk/include/c_types.h\n@@ -93,6 +93,9 @@ typedef enum {\n #define ICACHE_RAM_ATTR\n #endif /* ICACHE_FLASH */\n \n+// counterpart https://github.com/espressif/arduino-esp32/blob/master/cores/esp32/esp8266-compat.h\n+#define IRAM_ATTR ICACHE_RAM_ATTR\n+\n #define STORE_ATTR __attribute__((aligned(4)))\n \n #ifndef __cplusplus\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Ensure interrupt safety around `get_fn` to prevent race conditions from IRQs calling `schedule_fcn()` during linked list operations. \n\n2. Revert the implementation of the linked list from LIFO back to FIFO to avoid issues with deep queue items not being reached, particularly in use cases involving I2C transactions.\n\n3. Avoid using `yield()` in scheduled functions, as they should act like interrupt handlers. Consider adding a boolean flag to prevent nested calls during `yield()` execution.\n\n4. Update `lastRecurring` logic: it should only be updated if `!item->callNow`. Incorporate a scope lock to handle interrupt safety when modifying linked list state during function calls.\n\n5. Evaluate if `loop()` should be transformed into a scheduled function in future RTOS transitions."
      }
    ],
    "codediff_length": 18303
  },
  {
    "index": 41,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/cores/esp8266/core_esp8266_si2c.cpp b/cores/esp8266/core_esp8266_si2c.cpp\nindex 6f6cd58971..7200f63154 100644\n--- a/cores/esp8266/core_esp8266_si2c.cpp\n+++ b/cores/esp8266/core_esp8266_si2c.cpp\n@@ -1,114 +1,152 @@\n /*\n-  si2c.c - Software I2C library for esp8266\n+    si2c.c - Software I2C library for esp8266\n \n-  Copyright (c) 2015 Hristo Gochkov. All rights reserved.\n-  This file is part of the esp8266 core for Arduino environment.\n+    Copyright (c) 2015 Hristo Gochkov. All rights reserved.\n+    This file is part of the esp8266 core for Arduino environment.\n \n-  This library is free software; you can redistribute it and/or\n-  modify it under the terms of the GNU Lesser General Public\n-  License as published by the Free Software Foundation; either\n-  version 2.1 of the License, or (at your option) any later version.\n+    This library is free software; you can redistribute it and/or\n+    modify it under the terms of the GNU Lesser General Public\n+    License as published by the Free Software Foundation; either\n+    version 2.1 of the License, or (at your option) any later version.\n \n-  This library is distributed in the hope that it will be useful,\n-  but WITHOUT ANY WARRANTY; without even the implied warranty of\n-  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n-  Lesser General Public License for more details.\n+    This library is distributed in the hope that it will be useful,\n+    but WITHOUT ANY WARRANTY; without even the implied warranty of\n+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+    Lesser General Public License for more details.\n \n-  You should have received a copy of the GNU Lesser General Public\n-  License along with this library; if not, write to the Free Software\n-  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n-  Modified January 2017 by Bjorn Hammarberg (bjoham@esp8266.com) - i2c slave support\n+    You should have received a copy of the GNU Lesser General Public\n+    License along with this library; if not, write to the Free Software\n+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n+    Modified January 2017 by Bjorn Hammarberg (bjoham@esp8266.com) - i2c slave support\n */\n #include \"twi.h\"\n #include \"pins_arduino.h\"\n #include \"wiring_private.h\"\n \n-extern \"C\" {\n \n-unsigned int preferred_si2c_clock = 100000;\n-#include \"twi_util.h\"\n \n+extern \"C\" {\n+#include \"twi_util.h\"\n #include \"ets_sys.h\"\n+};\n \n-unsigned char twi_dcount = 18;\n-static unsigned char twi_sda, twi_scl;\n-static uint32_t twi_clockStretchLimit;\n-static unsigned char twi_addr = 0;\n-\n-// modes (private)\n-#define TWIPM_UNKNOWN \t0\n-#define TWIPM_IDLE \t\t1\n-#define TWIPM_ADDRESSED\t2\n-#define TWIPM_WAIT\t\t3\n-\n-// states (private)\n-#define TWIP_UNKNOWN \t0\n-#define TWIP_IDLE \t\t1\n-#define TWIP_START \t\t2\n-#define TWIP_SEND_ACK\t3\n-#define TWIP_WAIT_ACK\t4\n-#define TWIP_WAIT_STOP\t5\n-#define TWIP_SLA_W\t\t6\n-#define TWIP_SLA_R\t\t7\n-#define TWIP_REP_START\t8\n-#define TWIP_READ\t\t9\n-#define TWIP_STOP \t\t10\n-#define TWIP_REC_ACK\t11\n-#define TWIP_READ_ACK\t12\n-#define TWIP_RWAIT_ACK\t13\n-#define TWIP_WRITE\t\t14\n-#define TWIP_BUS_ERR \t15\n-\n-static volatile uint8_t twip_mode = TWIPM_IDLE;\n-static volatile uint8_t twip_state = TWIP_IDLE;\n-static volatile uint8_t twip_status = TW_NO_INFO;\n-static volatile uint8_t bitCount = 0;\n-\n-#define TWDR twi_data\n-static volatile uint8_t twi_data = 0x00;\n-static volatile uint8_t twi_ack = 0;\n-static volatile uint8_t twi_ack_rec = 0;\n-static volatile int twi_timeout_ms = 10;\n-\n-#define TWI_READY 0\n-#define TWI_MRX   1\n-#define TWI_MTX   2\n-#define TWI_SRX   3\n-#define TWI_STX   4\n-static volatile uint8_t twi_state = TWI_READY;\n-static volatile uint8_t twi_error = 0xFF;\n-\n-static uint8_t twi_txBuffer[TWI_BUFFER_LENGTH];\n-static volatile uint8_t twi_txBufferIndex;\n-static volatile uint8_t twi_txBufferLength;\n-\n-static uint8_t twi_rxBuffer[TWI_BUFFER_LENGTH];\n-static volatile uint8_t twi_rxBufferIndex;\n-\n-static void (*twi_onSlaveTransmit)(void);\n-static void (*twi_onSlaveReceive)(uint8_t*, size_t);\n-\n-static void onSclChange(void);\n-static void onSdaChange(void);\n-\n-#define EVENTTASK_QUEUE_SIZE 1\n-#define EVENTTASK_QUEUE_PRIO 2\n-\n-#define TWI_SIG_RANGE\t0x00000100\n-#define TWI_SIG_RX \t\t(TWI_SIG_RANGE + 0x01)\n-#define TWI_SIG_TX \t\t(TWI_SIG_RANGE + 0x02)\n-\n-static ETSEvent eventTaskQueue[EVENTTASK_QUEUE_SIZE];\n-static void eventTask(ETSEvent *e);\n-static ETSTimer timer;\n-static void onTimer(void *unused);\n-\n-#define SDA_LOW()   (GPES = (1 << twi_sda)) //Enable SDA (becomes output and since GPO is 0 for the pin, it will pull the line low)\n-#define SDA_HIGH()  (GPEC = (1 << twi_sda)) //Disable SDA (becomes input and since it has pullup it will go high)\n-#define SDA_READ()  ((GPI & (1 << twi_sda)) != 0)\n-#define SCL_LOW()   (GPES = (1 << twi_scl))\n-#define SCL_HIGH()  (GPEC = (1 << twi_scl))\n-#define SCL_READ()  ((GPI & (1 << twi_scl)) != 0)\n+\n+// Implement as a class to reduce code size by allowing access to many global variables with a single base pointer\n+class Twi\n+{\n+private:\n+    unsigned int preferred_si2c_clock = 100000;\n+    unsigned char twi_dcount = 18;\n+    unsigned char twi_sda = 0;\n+    unsigned char twi_scl = 0;\n+    unsigned char twi_addr = 0;\n+    uint32_t twi_clockStretchLimit = 0;\n+\n+    // These are int-wide, even though they could all fit in a byte, to reduce code size and avoid any potential\n+    // issues about RmW on packed bytes.  The int-wide variations of asm instructions are smaller than the equivalent\n+    // byte-wide ones, and since these emums are used everywhere, the difference adds up fast.  There is only a single\n+    // instance of the class, though, so the extra 12 bytes of RAM used here saves a lot more IRAM.\n+    volatile enum { TWIPM_UNKNOWN = 0, TWIPM_IDLE, TWIPM_ADDRESSED, TWIPM_WAIT} twip_mode = TWIPM_IDLE;\n+    volatile enum { TWIP_UNKNOWN = 0, TWIP_IDLE, TWIP_START, TWIP_SEND_ACK, TWIP_WAIT_ACK, TWIP_WAIT_STOP, TWIP_SLA_W, TWIP_SLA_R, TWIP_REP_START, TWIP_READ, TWIP_STOP, TWIP_REC_ACK, TWIP_READ_ACK, TWIP_RWAIT_ACK, TWIP_WRITE, TWIP_BUS_ERR } twip_state = TWIP_IDLE;\n+    volatile int twip_status = TW_NO_INFO;\n+    volatile int bitCount = 0;\n+\n+    volatile uint8_t twi_data = 0x00;\n+    volatile int twi_ack = 0;\n+    volatile int twi_ack_rec = 0;\n+    volatile int twi_timeout_ms = 10;\n+\n+    volatile enum { TWI_READY = 0, TWI_MRX, TWI_MTX, TWI_SRX, TWI_STX } twi_state = TWI_READY;\n+    volatile uint8_t twi_error = 0xFF;\n+\n+    uint8_t twi_txBuffer[TWI_BUFFER_LENGTH];\n+    volatile int twi_txBufferIndex = 0;\n+    volatile int twi_txBufferLength = 0;\n+\n+    uint8_t twi_rxBuffer[TWI_BUFFER_LENGTH];\n+    volatile int twi_rxBufferIndex = 0;\n+\n+    void (*twi_onSlaveTransmit)(void);\n+    void (*twi_onSlaveReceive)(uint8_t*, size_t);\n+\n+    // ETS queue/timer interfaces\n+    enum { EVENTTASK_QUEUE_SIZE = 1, EVENTTASK_QUEUE_PRIO = 2 };\n+    enum { TWI_SIG_RANGE = 0x00000100, TWI_SIG_RX = 0x00000101, TWI_SIG_TX = 0x00000102 };\n+    ETSEvent eventTaskQueue[EVENTTASK_QUEUE_SIZE];\n+    ETSTimer timer;\n+\n+    // Event/IRQ callbacks, so they can't use \"this\" and need to be static\n+    static void ICACHE_RAM_ATTR onSclChange(void);\n+    static void ICACHE_RAM_ATTR onSdaChange(void);\n+    static void eventTask(ETSEvent *e);\n+    static void ICACHE_RAM_ATTR onTimer(void *unused);\n+\n+    // Allow not linking in the slave code if there is no call to setAddress\n+    bool _slaveEnabled = false;\n+\n+    // Internal use functions\n+    void ICACHE_RAM_ATTR busywait(unsigned char v);\n+    bool write_start(void);\n+    bool write_stop(void);\n+    bool write_bit(bool bit);\n+    bool read_bit(void);\n+    bool write_byte(unsigned char byte);\n+    unsigned char read_byte(bool nack);\n+    void ICACHE_RAM_ATTR onTwipEvent(uint8_t status);\n+\n+    // Inline helpers\n+    inline void SDA_LOW()\n+    {\n+        GPES = (1 << twi_sda);\n+    }\n+    inline void SDA_HIGH()\n+    {\n+        GPEC = (1 << twi_sda);\n+    }\n+    inline bool SDA_READ()\n+    {\n+        return (GPI & (1 << twi_sda)) != 0;\n+    }\n+    inline void SCL_LOW()\n+    {\n+        GPES = (1 << twi_scl);\n+    }\n+    inline void SCL_HIGH()\n+    {\n+        GPEC = (1 << twi_scl);\n+    }\n+    inline bool SCL_READ()\n+    {\n+        return (GPI & (1 << twi_scl)) != 0;\n+    }\n+    // Handle the case where a slave needs to stretch the clock with a time-limited busy wait\n+    inline void WAIT_CLOCK_STRETCH()\n+    {\n+        for (unsigned int t = 0; !SCL_READ() && (t < twi_clockStretchLimit); t++)\n+        {\n+            /* noop */\n+        }\n+    }\n+\n+\n+public:\n+    void setClock(unsigned int freq);\n+    void setClockStretchLimit(uint32_t limit);\n+    void init(unsigned char sda, unsigned char scl);\n+    void setAddress(uint8_t address);\n+    unsigned char writeTo(unsigned char address, unsigned char * buf, unsigned int len, unsigned char sendStop);\n+    unsigned char readFrom(unsigned char address, unsigned char* buf, unsigned int len, unsigned char sendStop);\n+    uint8_t status();\n+    uint8_t transmit(const uint8_t* data, uint8_t length);\n+    void attachSlaveRxEvent(void (*function)(uint8_t*, size_t));\n+    void attachSlaveTxEvent(void (*function)(void));\n+    inline void ICACHE_RAM_ATTR reply(uint8_t ack);\n+    inline void ICACHE_RAM_ATTR stop(void);\n+    inline void ICACHE_RAM_ATTR releaseBus(void);\n+    void enableSlave();\n+};\n+\n+static Twi twi;\n \n #ifndef FCPU80\n #define FCPU80 80000000L\n@@ -120,670 +158,910 @@ static void onTimer(void *unused);\n #define TWI_CLOCK_STRETCH_MULTIPLIER 6\n #endif\n \n-void twi_setClock(unsigned int freq){\n-  preferred_si2c_clock = freq;\n+\n+void Twi::setClock(unsigned int freq)\n+{\n+    preferred_si2c_clock = freq;\n #if F_CPU == FCPU80\n-  if(freq <= 50000) twi_dcount = 38;//about 50KHz\n-  else if(freq <= 100000) twi_dcount = 19;//about 100KHz\n-  else if(freq <= 200000) twi_dcount = 8;//about 200KHz\n-  else if(freq <= 300000) twi_dcount = 3;//about 300KHz\n-  else if(freq <= 400000) twi_dcount = 1;//about 400KHz\n-  else twi_dcount = 1;//about 400KHz\n+    if (freq <= 50000)\n+    {\n+        twi_dcount = 38;  //about 50KHz\n+    }\n+    else if (freq <= 100000)\n+    {\n+        twi_dcount = 19;  //about 100KHz\n+    }\n+    else if (freq <= 200000)\n+    {\n+        twi_dcount = 8;  //about 200KHz\n+    }\n+    else if (freq <= 300000)\n+    {\n+        twi_dcount = 3;  //about 300KHz\n+    }\n+    else if (freq <= 400000)\n+    {\n+        twi_dcount = 1;  //about 400KHz\n+    }\n+    else\n+    {\n+        twi_dcount = 1;  //about 400KHz\n+    }\n #else\n-  if(freq <= 50000) twi_dcount = 64;//about 50KHz\n-  else if(freq <= 100000) twi_dcount = 32;//about 100KHz\n-  else if(freq <= 200000) twi_dcount = 14;//about 200KHz\n-  else if(freq <= 300000) twi_dcount = 8;//about 300KHz\n-  else if(freq <= 400000) twi_dcount = 5;//about 400KHz\n-  else if(freq <= 500000) twi_dcount = 3;//about 500KHz\n-  else if(freq <= 600000) twi_dcount = 2;//about 600KHz\n-  else twi_dcount = 1;//about 700KHz\n+    if (freq <= 50000)\n+    {\n+        twi_dcount = 64;  //about 50KHz\n+    }\n+    else if (freq <= 100000)\n+    {\n+        twi_dcount = 32;  //about 100KHz\n+    }\n+    else if (freq <= 200000)\n+    {\n+        twi_dcount = 14;  //about 200KHz\n+    }\n+    else if (freq <= 300000)\n+    {\n+        twi_dcount = 8;  //about 300KHz\n+    }\n+    else if (freq <= 400000)\n+    {\n+        twi_dcount = 5;  //about 400KHz\n+    }\n+    else if (freq <= 500000)\n+    {\n+        twi_dcount = 3;  //about 500KHz\n+    }\n+    else if (freq <= 600000)\n+    {\n+        twi_dcount = 2;  //about 600KHz\n+    }\n+    else\n+    {\n+        twi_dcount = 1;  //about 700KHz\n+    }\n #endif\n }\n \n-void twi_setClockStretchLimit(uint32_t limit){\n-  twi_clockStretchLimit = limit * TWI_CLOCK_STRETCH_MULTIPLIER;\n+void Twi::setClockStretchLimit(uint32_t limit)\n+{\n+    twi_clockStretchLimit = limit * TWI_CLOCK_STRETCH_MULTIPLIER;\n+}\n+\n+\n+\n+void Twi::init(unsigned char sda, unsigned char scl)\n+{\n+    // set timer function\n+    ets_timer_setfn(&timer, onTimer, NULL);\n+\n+    // create event task\n+    ets_task(eventTask, EVENTTASK_QUEUE_PRIO, eventTaskQueue, EVENTTASK_QUEUE_SIZE);\n+\n+    twi_sda = sda;\n+    twi_scl = scl;\n+    pinMode(twi_sda, INPUT_PULLUP);\n+    pinMode(twi_scl, INPUT_PULLUP);\n+    twi_setClock(preferred_si2c_clock);\n+    twi_setClockStretchLimit(230); // default value is 230 uS\n }\n \n-void twi_init(unsigned char sda, unsigned char scl)\n+void Twi::setAddress(uint8_t address)\n {\n-  // set timer function\n-  ets_timer_setfn(&timer, onTimer, NULL);\n-\n-  // create event task\n-  ets_task(eventTask, EVENTTASK_QUEUE_PRIO, eventTaskQueue, EVENTTASK_QUEUE_SIZE);\n-\n-  twi_sda = sda;\n-  twi_scl = scl;\n-  pinMode(twi_sda, INPUT_PULLUP);\n-  pinMode(twi_scl, INPUT_PULLUP);\n-  twi_setClock(preferred_si2c_clock);\n-  twi_setClockStretchLimit(230); // default value is 230 uS\n-\n-  if (twi_addr != 0)\n-  {\n-\tattachInterrupt(scl, onSclChange, CHANGE);\n-\tattachInterrupt(sda, onSdaChange, CHANGE);\n-  }\n+    // set twi slave address (skip over R/W bit)\n+    twi_addr = address << 1;\n }\n \n-void twi_setAddress(uint8_t address)\n+void Twi::enableSlave()\n {\n-  // set twi slave address (skip over R/W bit)\n-  twi_addr = address << 1;\n+    if (!_slaveEnabled)\n+    {\n+        attachInterrupt(twi_scl, onSclChange, CHANGE);\n+        attachInterrupt(twi_sda, onSdaChange, CHANGE);\n+        _slaveEnabled = true;\n+    }\n }\n \n-static void ICACHE_RAM_ATTR twi_delay(unsigned char v){\n-  unsigned int i;\n+void ICACHE_RAM_ATTR Twi::busywait(unsigned char v)\n+{\n+    unsigned int i;\n #pragma GCC diagnostic push\n #pragma GCC diagnostic ignored \"-Wunused-but-set-variable\"\n-  unsigned int reg;\n-  for (i = 0; i < v; i++) {\n-    reg = GPI;\n-  }\n-  (void)reg;\n+    unsigned int reg;\n+    for (i = 0; i < v; i++)\n+    {\n+        reg = GPI;\n+    }\n+    (void)reg;\n #pragma GCC diagnostic pop\n }\n \n-static bool twi_write_start(void) {\n-  SCL_HIGH();\n-  SDA_HIGH();\n-  if (SDA_READ() == 0) {\n-    return false;\n-  }\n-  twi_delay(twi_dcount);\n-  SDA_LOW();\n-  twi_delay(twi_dcount);\n-  return true;\n+bool Twi::write_start(void)\n+{\n+    SCL_HIGH();\n+    SDA_HIGH();\n+    if (!SDA_READ())\n+    {\n+        return false;\n+    }\n+    busywait(twi_dcount);\n+    SDA_LOW();\n+    busywait(twi_dcount);\n+    return true;\n }\n \n-static bool twi_write_stop(void){\n-  uint32_t i = 0;\n-  SCL_LOW();\n-  SDA_LOW();\n-  twi_delay(twi_dcount);\n-  SCL_HIGH();\n-  while (SCL_READ() == 0 && (i++) < twi_clockStretchLimit); // Clock stretching\n-  twi_delay(twi_dcount);\n-  SDA_HIGH();\n-  twi_delay(twi_dcount);\n-  return true;\n+bool Twi::write_stop(void)\n+{\n+    SCL_LOW();\n+    SDA_LOW();\n+    busywait(twi_dcount);\n+    SCL_HIGH();\n+    WAIT_CLOCK_STRETCH();\n+    busywait(twi_dcount);\n+    SDA_HIGH();\n+    busywait(twi_dcount);\n+    return true;\n }\n \n-static bool twi_write_bit(bool bit) {\n-  uint32_t i = 0;\n-  SCL_LOW();\n-  if (bit) SDA_HIGH();\n-  else SDA_LOW();\n-  twi_delay(twi_dcount+1);\n-  SCL_HIGH();\n-  while (SCL_READ() == 0 && (i++) < twi_clockStretchLimit);// Clock stretching\n-  twi_delay(twi_dcount);\n-  return true;\n+bool Twi::write_bit(bool bit)\n+{\n+    SCL_LOW();\n+    if (bit)\n+    {\n+        SDA_HIGH();\n+    }\n+    else\n+    {\n+        SDA_LOW();\n+    }\n+    busywait(twi_dcount + 1);\n+    SCL_HIGH();\n+    WAIT_CLOCK_STRETCH();\n+    busywait(twi_dcount);\n+    return true;\n }\n \n-static bool twi_read_bit(void) {\n-  uint32_t i = 0;\n-  SCL_LOW();\n-  SDA_HIGH();\n-  twi_delay(twi_dcount+2);\n-  SCL_HIGH();\n-  while (SCL_READ() == 0 && (i++) < twi_clockStretchLimit);// Clock stretching\n-  bool bit = SDA_READ();\n-  twi_delay(twi_dcount);\n-  return bit;\n+bool Twi::read_bit(void)\n+{\n+    SCL_LOW();\n+    SDA_HIGH();\n+    busywait(twi_dcount + 2);\n+    SCL_HIGH();\n+    WAIT_CLOCK_STRETCH();\n+    bool bit = SDA_READ();\n+    busywait(twi_dcount);\n+    return bit;\n }\n \n-static bool twi_write_byte(unsigned char byte) {\n-  unsigned char bit;\n-  for (bit = 0; bit < 8; bit++) {\n-    twi_write_bit(byte & 0x80);\n-    byte <<= 1;\n-  }\n-  return !twi_read_bit();//NACK/ACK\n+bool Twi::write_byte(unsigned char byte)\n+{\n+    unsigned char bit;\n+    for (bit = 0; bit < 8; bit++)\n+    {\n+        write_bit(byte & 0x80);\n+        byte <<= 1;\n+    }\n+    return !read_bit();//NACK/ACK\n }\n \n-static unsigned char twi_read_byte(bool nack) {\n-  unsigned char byte = 0;\n-  unsigned char bit;\n-  for (bit = 0; bit < 8; bit++) byte = (byte << 1) | twi_read_bit();\n-  twi_write_bit(nack);\n-  return byte;\n+unsigned char Twi::read_byte(bool nack)\n+{\n+    unsigned char byte = 0;\n+    unsigned char bit;\n+    for (bit = 0; bit < 8; bit++)\n+    {\n+        byte = (byte << 1) | read_bit();\n+    }\n+    write_bit(nack);\n+    return byte;\n }\n \n-unsigned char twi_writeTo(unsigned char address, unsigned char * buf, unsigned int len, unsigned char sendStop){\n-  unsigned int i;\n-  if(!twi_write_start()) return 4;//line busy\n-  if(!twi_write_byte(((address << 1) | 0) & 0xFF)) {\n-    if (sendStop) twi_write_stop();\n-    return 2; //received NACK on transmit of address\n-  }\n-  for(i=0; i<len; i++) {\n-    if(!twi_write_byte(buf[i])) {\n-      if (sendStop) twi_write_stop();\n-      return 3;//received NACK on transmit of data\n-    }\n-  }\n-  if(sendStop) twi_write_stop();\n-  i = 0;\n-  while(SDA_READ() == 0 && (i++) < 10){\n-    SCL_LOW();\n-    twi_delay(twi_dcount);\n-    SCL_HIGH();\n-    unsigned int t=0; while(SCL_READ()==0 && (t++)<twi_clockStretchLimit); // twi_clockStretchLimit\n-    twi_delay(twi_dcount);\n-  }\n-  return 0;\n+unsigned char Twi::writeTo(unsigned char address, unsigned char * buf, unsigned int len, unsigned char sendStop)\n+{\n+    unsigned int i;\n+    if (!write_start())\n+    {\n+        return 4;  //line busy\n+    }\n+    if (!write_byte(((address << 1) | 0) & 0xFF))\n+    {\n+        if (sendStop)\n+        {\n+            write_stop();\n+        }\n+        return 2; //received NACK on transmit of address\n+    }\n+    for (i = 0; i < len; i++)\n+    {\n+        if (!write_byte(buf[i]))\n+        {\n+            if (sendStop)\n+            {\n+                write_stop();\n+            }\n+            return 3;//received NACK on transmit of data\n+        }\n+    }\n+    if (sendStop)\n+    {\n+        write_stop();\n+    }\n+    i = 0;\n+    while (!SDA_READ() && (i++) < 10)\n+    {\n+        SCL_LOW();\n+        busywait(twi_dcount);\n+        SCL_HIGH();\n+        WAIT_CLOCK_STRETCH();\n+        busywait(twi_dcount);\n+    }\n+    return 0;\n }\n \n-unsigned char twi_readFrom(unsigned char address, unsigned char* buf, unsigned int len, unsigned char sendStop){\n-  unsigned int i;\n-  if(!twi_write_start()) return 4;//line busy\n-  if(!twi_write_byte(((address << 1) | 1) & 0xFF)) {\n-    if (sendStop) twi_write_stop();\n-    return 2;//received NACK on transmit of address\n-  }\n-  for(i=0; i<(len-1); i++) buf[i] = twi_read_byte(false);\n-  buf[len-1] = twi_read_byte(true);\n-  if(sendStop) twi_write_stop();\n-  i = 0;\n-  while(SDA_READ() == 0 && (i++) < 10){\n-    SCL_LOW();\n-    twi_delay(twi_dcount);\n-    SCL_HIGH();\n-    unsigned int t=0; while(SCL_READ()==0 && (t++)<twi_clockStretchLimit); // twi_clockStretchLimit\n-    twi_delay(twi_dcount);\n-  }\n-  return 0;\n+unsigned char Twi::readFrom(unsigned char address, unsigned char* buf, unsigned int len, unsigned char sendStop)\n+{\n+    unsigned int i;\n+    if (!write_start())\n+    {\n+        return 4;  //line busy\n+    }\n+    if (!write_byte(((address << 1) | 1) & 0xFF))\n+    {\n+        if (sendStop)\n+        {\n+            write_stop();\n+        }\n+        return 2;//received NACK on transmit of address\n+    }\n+    for (i = 0; i < (len - 1); i++)\n+    {\n+        buf[i] = read_byte(false);\n+    }\n+    buf[len - 1] = read_byte(true);\n+    if (sendStop)\n+    {\n+        write_stop();\n+    }\n+    i = 0;\n+    while (!SDA_READ() && (i++) < 10)\n+    {\n+        SCL_LOW();\n+        busywait(twi_dcount);\n+        SCL_HIGH();\n+        WAIT_CLOCK_STRETCH();\n+        busywait(twi_dcount);\n+    }\n+    return 0;\n }\n \n-uint8_t twi_status() {\n-    if (SCL_READ() == 0)\n-      return I2C_SCL_HELD_LOW; // SCL held low by another device, no procedure available to recover\n+uint8_t Twi::status()\n+{\n+    if (!SCL_READ())\n+    {\n+        return I2C_SCL_HELD_LOW;  // SCL held low by another device, no procedure available to recover\n+    }\n \n     int clockCount = 20;\n-    while (SDA_READ() == 0 && clockCount-- > 0) { // if SDA low, read the bits slaves have to sent to a max\n-        twi_read_bit();\n-        if (SCL_READ() == 0) {\n-          return I2C_SCL_HELD_LOW_AFTER_READ; // I2C bus error. SCL held low beyond slave clock stretch time\n+    while (!SDA_READ() && clockCount-- > 0)   // if SDA low, read the bits slaves have to sent to a max\n+    {\n+        read_bit();\n+        if (!SCL_READ())\n+        {\n+            return I2C_SCL_HELD_LOW_AFTER_READ; // I2C bus error. SCL held low beyond slave clock stretch time\n         }\n     }\n-    if (SDA_READ() == 0)\n-      return I2C_SDA_HELD_LOW; // I2C bus error. SDA line held low by slave/another_master after n bits.\n-    \n-    if (!twi_write_start())\n-      return I2C_SDA_HELD_LOW_AFTER_INIT;  // line busy. SDA again held low by another device. 2nd master?\n+    if (!SDA_READ())\n+    {\n+        return I2C_SDA_HELD_LOW;  // I2C bus error. SDA line held low by slave/another_master after n bits.\n+    }\n+\n+    if (!write_start())\n+    {\n+        return I2C_SDA_HELD_LOW_AFTER_INIT;  // line busy. SDA again held low by another device. 2nd master?\n+    }\n \n     return I2C_OK;\n }\n \n-uint8_t twi_transmit(const uint8_t* data, uint8_t length)\n+uint8_t Twi::transmit(const uint8_t* data, uint8_t length)\n {\n-  uint8_t i;\n+    uint8_t i;\n \n-  // ensure data will fit into buffer\n-  if (length > TWI_BUFFER_LENGTH) {\n-    return 1;\n-  }\n+    // ensure data will fit into buffer\n+    if (length > TWI_BUFFER_LENGTH)\n+    {\n+        return 1;\n+    }\n \n-  // ensure we are currently a slave transmitter\n-  if (twi_state != TWI_STX) {\n-    return 2;\n-  }\n+    // ensure we are currently a slave transmitter\n+    if (twi_state != TWI_STX)\n+    {\n+        return 2;\n+    }\n \n-  // set length and copy data into tx buffer\n-  twi_txBufferLength = length;\n-  for (i = 0; i < length; ++i) {\n-    twi_txBuffer[i] = data[i];\n-  }\n+    // set length and copy data into tx buffer\n+    twi_txBufferLength = length;\n+    for (i = 0; i < length; ++i)\n+    {\n+        twi_txBuffer[i] = data[i];\n+    }\n \n-  return 0;\n+    return 0;\n }\n \n-void twi_attachSlaveRxEvent( void (*function)(uint8_t*, size_t) )\n+void Twi::attachSlaveRxEvent(void (*function)(uint8_t*, size_t))\n {\n-  twi_onSlaveReceive = function;\n+    twi_onSlaveReceive = function;\n }\n \n-void twi_attachSlaveTxEvent( void (*function)(void) )\n+void Twi::attachSlaveTxEvent(void (*function)(void))\n {\n-  twi_onSlaveTransmit = function;\n+    twi_onSlaveTransmit = function;\n }\n \n-void ICACHE_RAM_ATTR twi_reply(uint8_t ack)\n+inline void ICACHE_RAM_ATTR Twi::reply(uint8_t ack)\n {\n-  // transmit master read ready signal, with or without ack\n-  if (ack) {\n-    //TWCR = _BV(TWEN) | _BV(TWIE) | _BV(TWINT) | _BV(TWEA);\n-\tSCL_HIGH();\t\t// _BV(TWINT)\n-\ttwi_ack = 1; \t// _BV(TWEA)\n-  } else {\n-\t//TWCR = _BV(TWEN) | _BV(TWIE) | _BV(TWINT);\n-\tSCL_HIGH();\t\t// _BV(TWINT)\n-\ttwi_ack = 0;\t// ~_BV(TWEA)\n-  }\n+    // transmit master read ready signal, with or without ack\n+    if (ack)\n+    {\n+        //TWCR = _BV(TWEN) | _BV(TWIE) | _BV(TWINT) | _BV(TWEA);\n+        SCL_HIGH();\t\t// _BV(TWINT)\n+        twi_ack = 1; \t// _BV(TWEA)\n+    }\n+    else\n+    {\n+        //TWCR = _BV(TWEN) | _BV(TWIE) | _BV(TWINT);\n+        SCL_HIGH();\t\t// _BV(TWINT)\n+        twi_ack = 0;\t// ~_BV(TWEA)\n+    }\n }\n \n-void ICACHE_RAM_ATTR twi_stop(void)\n+inline void ICACHE_RAM_ATTR Twi::stop(void)\n {\n-\t// send stop condition\n-\t//TWCR = _BV(TWEN) | _BV(TWIE) | _BV(TWEA) | _BV(TWINT) | _BV(TWSTO);\n-\tSCL_HIGH();\t\t// _BV(TWINT)\n-\ttwi_ack = 1;\t// _BV(TWEA)\n-\ttwi_delay(5);\t// Maybe this should be here\n-\tSDA_HIGH();\t\t// _BV(TWSTO)\n-\t// update twi state\n-\ttwi_state = TWI_READY;\n+    // send stop condition\n+    //TWCR = _BV(TWEN) | _BV(TWIE) | _BV(TWEA) | _BV(TWINT) | _BV(TWSTO);\n+    SCL_HIGH();\t\t// _BV(TWINT)\n+    twi_ack = 1;\t// _BV(TWEA)\n+    busywait(5);\t// Maybe this should be here\n+    SDA_HIGH();\t\t// _BV(TWSTO)\n+    // update twi state\n+    twi_state = TWI_READY;\n }\n \n-void ICACHE_RAM_ATTR twi_releaseBus(void)\n+inline void ICACHE_RAM_ATTR Twi::releaseBus(void)\n {\n-\t// release bus\n-\t//TWCR = _BV(TWEN) | _BV(TWIE) | _BV(TWEA) | _BV(TWINT);\n-\tSCL_HIGH();\t\t// _BV(TWINT)\n-\ttwi_ack = 1; \t// _BV(TWEA)\n-\tSDA_HIGH();\n-\n-\t// update twi state\n-\ttwi_state = TWI_READY;\n+    // release bus\n+    //TWCR = _BV(TWEN) | _BV(TWIE) | _BV(TWEA) | _BV(TWINT);\n+    SCL_HIGH();\t\t// _BV(TWINT)\n+    twi_ack = 1; \t// _BV(TWEA)\n+    SDA_HIGH();\n+\n+    // update twi state\n+    twi_state = TWI_READY;\n }\n \n \n-void ICACHE_RAM_ATTR twi_onTwipEvent(uint8_t status)\n+void ICACHE_RAM_ATTR Twi::onTwipEvent(uint8_t status)\n {\n-  switch(status) {\n+    twip_status = status;\n+    switch (status)\n+    {\n     // Slave Receiver\n     case TW_SR_SLA_ACK:   // addressed, returned ack\n     case TW_SR_GCALL_ACK: // addressed generally, returned ack\n     case TW_SR_ARB_LOST_SLA_ACK:   // lost arbitration, returned ack\n     case TW_SR_ARB_LOST_GCALL_ACK: // lost arbitration, returned ack\n-      // enter slave receiver mode\n-      twi_state = TWI_SRX;\n-      // indicate that rx buffer can be overwritten and ack\n-      twi_rxBufferIndex = 0;\n-      twi_reply(1);\n-      break;\n+        // enter slave receiver mode\n+        twi_state = TWI_SRX;\n+        // indicate that rx buffer can be overwritten and ack\n+        twi_rxBufferIndex = 0;\n+        reply(1);\n+        break;\n     case TW_SR_DATA_ACK:       // data received, returned ack\n     case TW_SR_GCALL_DATA_ACK: // data received generally, returned ack\n-      // if there is still room in the rx buffer\n-      if(twi_rxBufferIndex < TWI_BUFFER_LENGTH){\n-        // put byte in buffer and ack\n-        twi_rxBuffer[twi_rxBufferIndex++] = TWDR;\n-        twi_reply(1);\n-      }else{\n-        // otherwise nack\n-        twi_reply(0);\n-      }\n-      break;\n+        // if there is still room in the rx buffer\n+        if (twi_rxBufferIndex < TWI_BUFFER_LENGTH)\n+        {\n+            // put byte in buffer and ack\n+            twi_rxBuffer[twi_rxBufferIndex++] = twi_data;\n+            reply(1);\n+        }\n+        else\n+        {\n+            // otherwise nack\n+            reply(0);\n+        }\n+        break;\n     case TW_SR_STOP: // stop or repeated start condition received\n-      // put a null char after data if there's room\n-      if(twi_rxBufferIndex < TWI_BUFFER_LENGTH){\n-        twi_rxBuffer[twi_rxBufferIndex] = '\\0';\n-      }\n-      // callback to user-defined callback over event task to allow for non-RAM-residing code\n-\t  //twi_rxBufferLock = true; // This may be necessary\n-\t  ets_post(EVENTTASK_QUEUE_PRIO, TWI_SIG_RX, twi_rxBufferIndex);\n-\n-      // since we submit rx buffer to \"wire\" library, we can reset it\n-      twi_rxBufferIndex = 0;\n-      break;\n+        // put a null char after data if there's room\n+        if (twi_rxBufferIndex < TWI_BUFFER_LENGTH)\n+        {\n+            twi_rxBuffer[twi_rxBufferIndex] = '\\0';\n+        }\n+        // callback to user-defined callback over event task to allow for non-RAM-residing code\n+        //twi_rxBufferLock = true; // This may be necessary\n+        ets_post(EVENTTASK_QUEUE_PRIO, TWI_SIG_RX, twi_rxBufferIndex);\n+\n+        // since we submit rx buffer to \"wire\" library, we can reset it\n+        twi_rxBufferIndex = 0;\n+        break;\n \n     case TW_SR_DATA_NACK:       // data received, returned nack\n     case TW_SR_GCALL_DATA_NACK: // data received generally, returned nack\n-      // nack back at master\n-      twi_reply(0);\n-      break;\n+        // nack back at master\n+        reply(0);\n+        break;\n \n     // Slave Transmitter\n     case TW_ST_SLA_ACK:          // addressed, returned ack\n     case TW_ST_ARB_LOST_SLA_ACK: // arbitration lost, returned ack\n-      // enter slave transmitter mode\n-      twi_state = TWI_STX;\n-      // ready the tx buffer index for iteration\n-      twi_txBufferIndex = 0;\n-      // set tx buffer length to be zero, to verify if user changes it\n-      twi_txBufferLength = 0;\n-      // callback to user-defined callback over event task to allow for non-RAM-residing code\n-      // request for txBuffer to be filled and length to be set\n-      // note: user must call twi_transmit(bytes, length) to do this\n-\t  ets_post(EVENTTASK_QUEUE_PRIO, TWI_SIG_TX, 0);\n-\t  break;\n-\n-\tcase TW_ST_DATA_ACK: // byte sent, ack returned\n-      // copy data to output register\n-      TWDR = twi_txBuffer[twi_txBufferIndex++];\n-\n-\t  bitCount = 8;\n-\t  bitCount--;\n-\t  (twi_data & 0x80) ? SDA_HIGH() : SDA_LOW();\n-\t  twi_data <<= 1;\n-\n-      // if there is more to send, ack, otherwise nack\n-      if(twi_txBufferIndex < twi_txBufferLength){\n-        twi_reply(1);\n-      }else{\n-        twi_reply(0);\n-      }\n-      break;\n+        // enter slave transmitter mode\n+        twi_state = TWI_STX;\n+        // ready the tx buffer index for iteration\n+        twi_txBufferIndex = 0;\n+        // set tx buffer length to be zero, to verify if user changes it\n+        twi_txBufferLength = 0;\n+        // callback to user-defined callback over event task to allow for non-RAM-residing code\n+        // request for txBuffer to be filled and length to be set\n+        // note: user must call twi_transmit(bytes, length) to do this\n+        ets_post(EVENTTASK_QUEUE_PRIO, TWI_SIG_TX, 0);\n+        break;\n+\n+    case TW_ST_DATA_ACK: // byte sent, ack returned\n+        // copy data to output register\n+        twi_data = twi_txBuffer[twi_txBufferIndex++];\n+\n+        bitCount = 8;\n+        bitCount--;\n+        if (twi_data & 0x80)\n+        {\n+            SDA_HIGH();\n+        }\n+        else\n+        {\n+            SDA_LOW();\n+        }\n+        twi_data <<= 1;\n+\n+        // if there is more to send, ack, otherwise nack\n+        if (twi_txBufferIndex < twi_txBufferLength)\n+        {\n+            reply(1);\n+        }\n+        else\n+        {\n+            reply(0);\n+        }\n+        break;\n     case TW_ST_DATA_NACK: // received nack, we are done\n     case TW_ST_LAST_DATA: // received ack, but we are done already!\n-      // leave slave receiver state\n-      twi_releaseBus();\n-      break;\n+        // leave slave receiver state\n+        releaseBus();\n+        break;\n \n     // All\n     case TW_NO_INFO:   // no state information\n-      break;\n+        break;\n     case TW_BUS_ERROR: // bus error, illegal stop/start\n-      twi_error = TW_BUS_ERROR;\n-      twi_stop();\n-      break;\n-  }\n+        twi_error = TW_BUS_ERROR;\n+        stop();\n+        break;\n+    }\n }\n \n-void ICACHE_RAM_ATTR onTimer(void *unused)\n+void ICACHE_RAM_ATTR Twi::onTimer(void *unused)\n {\n-\t(void)unused;\n-\ttwi_releaseBus();\n-\ttwip_status = TW_BUS_ERROR;\n-\ttwi_onTwipEvent(twip_status);\n-\ttwip_mode = TWIPM_WAIT;\n-\ttwip_state = TWIP_BUS_ERR;\n+    (void)unused;\n+    twi.releaseBus();\n+    twi.onTwipEvent(TW_BUS_ERROR);\n+    twi.twip_mode = TWIPM_WAIT;\n+    twi.twip_state = TWIP_BUS_ERR;\n }\n \n-static void eventTask(ETSEvent *e)\n+void Twi::eventTask(ETSEvent *e)\n {\n \n-\tif (e == NULL) {\n-\t\treturn;\n-\t}\n+    if (e == NULL)\n+    {\n+        return;\n+    }\n \n-\tswitch (e->sig)\n-\t{\n-\t\tcase TWI_SIG_TX:\n-\t\t\ttwi_onSlaveTransmit();\n+    switch (e->sig)\n+    {\n+    case TWI_SIG_TX:\n+        twi.twi_onSlaveTransmit();\n \n-\t\t\t// if they didn't change buffer & length, initialize it\n-\t\t\tif (twi_txBufferLength == 0) {\n-\t\t\t\ttwi_txBufferLength = 1;\n-\t\t\t\ttwi_txBuffer[0] = 0x00;\n-\t\t\t}\n+        // if they didn't change buffer & length, initialize it\n+        if (twi.twi_txBufferLength == 0)\n+        {\n+            twi.twi_txBufferLength = 1;\n+            twi.twi_txBuffer[0] = 0x00;\n+        }\n \n-\t\t\t// Initiate transmission\n-\t\t\ttwi_onTwipEvent(TW_ST_DATA_ACK);\n+        // Initiate transmission\n+        twi.onTwipEvent(TW_ST_DATA_ACK);\n \n-\t\t\tbreak;\n+        break;\n \n-\t\tcase TWI_SIG_RX:\n-\t\t\t// ack future responses and leave slave receiver state\n-\t\t\ttwi_releaseBus();\n-\t\t\ttwi_onSlaveReceive(twi_rxBuffer, e->par);\n-\t\t\tbreak;\n-\t}\n+    case TWI_SIG_RX:\n+        // ack future responses and leave slave receiver state\n+        twi.releaseBus();\n+        twi.twi_onSlaveReceive(twi.twi_rxBuffer, e->par);\n+        break;\n+    }\n }\n \n-void ICACHE_RAM_ATTR onSclChange(void)\n+// The state machine is converted from a 0...15 state to a 1-hot encoded state, and then\n+// compared to the logical-or of all states with the same branch.  This removes the need\n+// for a large series of straight-line compares.  The biggest win is when multiple states\n+// all have the same branch (onSdaChange), but for others there is some benefit, still.\n+#define S2M(x) (1<<(x))\n+// Shorthand for if the state is any of the or'd bitmask x\n+#define IFSTATE(x) if (twip_state_mask & (x))\n+\n+void ICACHE_RAM_ATTR Twi::onSclChange(void)\n {\n-\tstatic uint8_t sda;\n-\tstatic uint8_t scl;\n-\n-\tsda\t= SDA_READ();\n-\tscl = SCL_READ();\n-\n-\ttwip_status = 0xF8;\t\t// reset TWI status\n-\n-\tswitch (twip_state)\n-\t{\n-\t\tcase TWIP_IDLE:\n-\t\tcase TWIP_WAIT_STOP:\n-\t\tcase TWIP_BUS_ERR:\n-\t\t\t// ignore\n-\t\t\tbreak;\n-\n-\t\tcase TWIP_START:\n-\t\tcase TWIP_REP_START:\n-\t\tcase TWIP_SLA_W:\n-\t\tcase TWIP_READ:\n-\t\t\tif (!scl) {\n-\t\t\t\t// ignore\n-\t\t\t} else {\n-\t\t\t\tbitCount--;\n-\t\t\t\ttwi_data <<= 1;\n-\t\t\t\ttwi_data |= sda;\n-\n-\t\t\t\tif (bitCount != 0) {\n-\t\t\t\t\t// continue\n-\t\t\t\t} else {\n-\t\t\t\t\ttwip_state = TWIP_SEND_ACK;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tcase TWIP_SEND_ACK:\n-\t\t\tif (scl) {\n-\t\t\t\t// ignore\n-\t\t\t} else {\n-\t\t\t\tif (twip_mode == TWIPM_IDLE) {\n-\t\t\t\t\tif ((twi_data & 0xFE) != twi_addr) {\n-\t\t\t\t\t\t// ignore\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tSDA_LOW();\n-\t\t\t\t\t}\n-\t\t\t\t} else {\n-\t\t\t\t\tif (!twi_ack) {\n-\t\t\t\t\t\t// ignore\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tSDA_LOW();\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t\ttwip_state = TWIP_WAIT_ACK;\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tcase TWIP_WAIT_ACK:\n-\t\t\tif (scl) {\n-\t\t\t\t// ignore\n-\t\t\t} else {\n-\t\t\t\tif (twip_mode == TWIPM_IDLE) {\n-\t\t\t\t\tif ((twi_data & 0xFE) != twi_addr) {\n-\t\t\t\t\t\tSDA_HIGH();\n-\t\t\t\t\t\ttwip_state = TWIP_WAIT_STOP;\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tSCL_LOW();\t// clock stretching\n-\t\t\t\t\t\tSDA_HIGH();\n-\t\t\t\t\t\ttwip_mode = TWIPM_ADDRESSED;\n-\t\t\t\t\t\tif (!(twi_data & 0x01)) {\n-\t\t\t\t\t\t\ttwip_status = TW_SR_SLA_ACK;\n-\t\t\t\t\t\t\ttwi_onTwipEvent(twip_status);\n-\t\t\t\t\t\t\tbitCount = 8;\n-\t\t\t\t\t\t\ttwip_state = TWIP_SLA_W;\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\ttwip_status = TW_ST_SLA_ACK;\n-\t\t\t\t\t\t\ttwi_onTwipEvent(twip_status);\n-\t\t\t\t\t\t\ttwip_state = TWIP_SLA_R;\n-\t\t\t\t\t\t}\n-\t\t\t\t\t}\n-\t\t\t\t} else {\n-\t\t\t\t\tSCL_LOW();\t// clock stretching\n-\t\t\t\t\tSDA_HIGH();\n-\t\t\t\t\tif (!twi_ack) {\n-\t\t\t\t\t\ttwip_status = TW_SR_DATA_NACK;\n-\t\t\t\t\t\ttwi_onTwipEvent(twip_status);\n-\t\t\t\t\t\ttwip_mode = TWIPM_WAIT;\n-\t\t\t\t\t\ttwip_state = TWIP_WAIT_STOP;\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\ttwip_status = TW_SR_DATA_ACK;\n-\t\t\t\t\t\ttwi_onTwipEvent(twip_status);\n-\t\t\t\t\t\tbitCount = 8;\n-\t\t\t\t\t\ttwip_state = TWIP_READ;\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tcase TWIP_SLA_R:\n-\t\tcase TWIP_WRITE:\n-\t\t\tif (scl) {\n-\t\t\t\t// ignore\n-\t\t\t} else {\n-\t\t\t\tbitCount--;\n-\t\t\t\t(twi_data & 0x80) ? SDA_HIGH() : SDA_LOW();\n-\t\t\t\ttwi_data <<= 1;\n-\n-\t\t\t\tif (bitCount != 0) {\n-\t\t\t\t\t// continue\n-\t\t\t\t} else {\n-\t\t\t\t\ttwip_state = TWIP_REC_ACK;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tcase TWIP_REC_ACK:\n-\t\t\tif (scl) {\n-\t\t\t\t// ignore\n-\t\t\t} else {\n-\t\t\t\tSDA_HIGH();\n-\t\t\t\ttwip_state = TWIP_READ_ACK;\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tcase TWIP_READ_ACK:\n-\t\t\tif (!scl) {\n-\t\t\t\t// ignore\n-\t\t\t} else {\n-\t\t\t\ttwi_ack_rec = !sda;\n-\t\t\t\ttwip_state = TWIP_RWAIT_ACK;\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tcase TWIP_RWAIT_ACK:\n-\t\t\tif (scl) {\n-\t\t\t\t// ignore\n-\t\t\t} else {\n-\t\t\t\tSCL_LOW();\t// clock stretching\n-\t\t\t\tif (twi_ack && twi_ack_rec) {\n-\t\t\t\t\ttwip_status = TW_ST_DATA_ACK;\n-\t\t\t\t\ttwi_onTwipEvent(twip_status);\n-\t\t\t\t\ttwip_state = TWIP_WRITE;\n-\t\t\t\t} else {\n-\t\t\t\t\t// we have no more data to send and/or the master doesn't want anymore\n-\t\t\t\t\ttwip_status = twi_ack_rec ? TW_ST_LAST_DATA : TW_ST_DATA_NACK;\n-\t\t\t\t\ttwi_onTwipEvent(twip_status);\n-\t\t\t\t\ttwip_mode = TWIPM_WAIT;\n-\t\t\t\t\ttwip_state = TWIP_WAIT_STOP;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tdefault:\n-\t\t\tbreak;\n-\t}\n+    unsigned int sda;\n+    unsigned int scl;\n+\n+    // Store bool return in int to reduce final code size.\n+    sda = twi.SDA_READ();\n+    scl = twi.SCL_READ();\n+\n+    twi.twip_status = 0xF8;\t\t// reset TWI status\n+\n+    int twip_state_mask = S2M(twi.twip_state);\n+    IFSTATE(S2M(TWIP_START) | S2M(TWIP_REP_START) | S2M(TWIP_SLA_W) | S2M(TWIP_READ))\n+    {\n+        if (!scl)\n+        {\n+            // ignore\n+        }\n+        else\n+        {\n+            twi.bitCount--;\n+            twi.twi_data <<= 1;\n+            twi.twi_data |= sda;\n+\n+            if (twi.bitCount != 0)\n+            {\n+                // continue\n+            }\n+            else\n+            {\n+                twi.twip_state = TWIP_SEND_ACK;\n+            }\n+        }\n+    }\n+    else IFSTATE(S2M(TWIP_SEND_ACK))\n+    {\n+        if (scl)\n+        {\n+            // ignore\n+        }\n+        else\n+        {\n+            if (twi.twip_mode == TWIPM_IDLE)\n+            {\n+                if ((twi.twi_data & 0xFE) != twi.twi_addr)\n+                {\n+                    // ignore\n+                }\n+                else\n+                {\n+                    twi.SDA_LOW();\n+                }\n+            }\n+            else\n+            {\n+                if (!twi.twi_ack)\n+                {\n+                    // ignore\n+                }\n+                else\n+                {\n+                    twi.SDA_LOW();\n+                }\n+            }\n+            twi.twip_state = TWIP_WAIT_ACK;\n+        }\n+    }\n+    else IFSTATE(S2M(TWIP_WAIT_ACK))\n+    {\n+        if (scl)\n+        {\n+            // ignore\n+        }\n+        else\n+        {\n+            if (twi.twip_mode == TWIPM_IDLE)\n+            {\n+                if ((twi.twi_data & 0xFE) != twi.twi_addr)\n+                {\n+                    twi.SDA_HIGH();\n+                    twi.twip_state = TWIP_WAIT_STOP;\n+                }\n+                else\n+                {\n+                    twi.SCL_LOW();\t// clock stretching\n+                    twi.SDA_HIGH();\n+                    twi.twip_mode = TWIPM_ADDRESSED;\n+                    if (!(twi.twi_data & 0x01))\n+                    {\n+                        twi.onTwipEvent(TW_SR_SLA_ACK);\n+                        twi.bitCount = 8;\n+                        twi.twip_state = TWIP_SLA_W;\n+                    }\n+                    else\n+                    {\n+                        twi.onTwipEvent(TW_ST_SLA_ACK);\n+                        twi.twip_state = TWIP_SLA_R;\n+                    }\n+                }\n+            }\n+            else\n+            {\n+                twi.SCL_LOW();\t// clock stretching\n+                twi.SDA_HIGH();\n+                if (!twi.twi_ack)\n+                {\n+                    twi.onTwipEvent(TW_SR_DATA_NACK);\n+                    twi.twip_mode = TWIPM_WAIT;\n+                    twi.twip_state = TWIP_WAIT_STOP;\n+                }\n+                else\n+                {\n+                    twi.onTwipEvent(TW_SR_DATA_ACK);\n+                    twi.bitCount = 8;\n+                    twi.twip_state = TWIP_READ;\n+                }\n+            }\n+        }\n+    }\n+    else IFSTATE(S2M(TWIP_SLA_R) | S2M(TWIP_WRITE))\n+    {\n+        if (scl)\n+        {\n+            // ignore\n+        }\n+        else\n+        {\n+            twi.bitCount--;\n+            if (twi.twi_data & 0x80)\n+            {\n+                twi.SDA_HIGH();\n+            }\n+            else\n+            {\n+                twi.SDA_LOW();\n+            }\n+            twi.twi_data <<= 1;\n+\n+            if (twi.bitCount != 0)\n+            {\n+                // continue\n+            }\n+            else\n+            {\n+                twi.twip_state = TWIP_REC_ACK;\n+            }\n+        }\n+    }\n+    else IFSTATE(S2M(TWIP_REC_ACK))\n+    {\n+        if (scl)\n+        {\n+            // ignore\n+        }\n+        else\n+        {\n+            twi.SDA_HIGH();\n+            twi.twip_state = TWIP_READ_ACK;\n+        }\n+    }\n+    else IFSTATE(S2M(TWIP_READ_ACK))\n+    {\n+        if (!scl)\n+        {\n+            // ignore\n+        }\n+        else\n+        {\n+            twi.twi_ack_rec = !sda;\n+            twi.twip_state = TWIP_RWAIT_ACK;\n+        }\n+    }\n+    else IFSTATE(S2M(TWIP_RWAIT_ACK))\n+    {\n+        if (scl)\n+        {\n+            // ignore\n+        }\n+        else\n+        {\n+            twi.SCL_LOW();\t// clock stretching\n+            if (twi.twi_ack && twi.twi_ack_rec)\n+            {\n+                twi.onTwipEvent(TW_ST_DATA_ACK);\n+                twi.twip_state = TWIP_WRITE;\n+            }\n+            else\n+            {\n+                // we have no more data to send and/or the master doesn't want anymore\n+                twi.onTwipEvent(twi.twi_ack_rec ? TW_ST_LAST_DATA : TW_ST_DATA_NACK);\n+                twi.twip_mode = TWIPM_WAIT;\n+                twi.twip_state = TWIP_WAIT_STOP;\n+            }\n+        }\n+    }\n }\n \n-void ICACHE_RAM_ATTR onSdaChange(void)\n+void ICACHE_RAM_ATTR Twi::onSdaChange(void)\n {\n-\tstatic uint8_t sda;\n-\tstatic uint8_t scl;\n-\tsda\t= SDA_READ();\n-\tscl = SCL_READ();\n-\n-\tswitch (twip_state)\n-\t{\n-\t\tcase TWIP_IDLE:\n-\t\t\tif (!scl) {\n-\t\t\t\t// DATA - ignore\n-\t\t\t} else if (sda) {\n-\t\t\t\t// STOP - ignore\n-\t\t\t} else {\n-\t\t\t\t// START\n-\t\t\t\tbitCount = 8;\n-\t\t\t\ttwip_state = TWIP_START;\n-\t\t\t\tets_timer_arm_new(&timer, twi_timeout_ms, false, true); // Once, ms\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tcase TWIP_START:\n-\t\tcase TWIP_REP_START:\n-\t\tcase TWIP_SEND_ACK:\n-\t\tcase TWIP_WAIT_ACK:\n-\t\tcase TWIP_SLA_R:\n-\t\tcase TWIP_REC_ACK:\n-\t\tcase TWIP_READ_ACK:\n-\t\tcase TWIP_RWAIT_ACK:\n-\t\tcase TWIP_WRITE:\n-\t\t\tif (!scl) {\n-\t\t\t\t// DATA - ignore\n-\t\t\t} else {\n-\t\t\t\t// START or STOP\n-\t\t\t\tSDA_HIGH();\t // Should not be necessary\n-\t\t\t\ttwip_status = TW_BUS_ERROR;\n-\t\t\t\ttwi_onTwipEvent(twip_status);\n-\t\t\t\ttwip_mode = TWIPM_WAIT;\n-\t\t\t\ttwip_state = TWIP_BUS_ERR;\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tcase TWIP_WAIT_STOP:\n-\t\tcase TWIP_BUS_ERR:\n-\t\t\tif (!scl) {\n-\t\t\t\t// DATA - ignore\n-\t\t\t} else {\n-\t\t\t\tif (sda) {\n-\t\t\t\t\t// STOP\n-\t\t\t\t\tSCL_LOW();\t// clock stretching\n-\t\t\t\t\tets_timer_disarm(&timer);\n-\t\t\t\t\ttwip_state = TWIP_IDLE;\n-\t\t\t\t\ttwip_mode = TWIPM_IDLE;\n-\t\t\t\t\tSCL_HIGH();\n-\t\t\t\t} else {\n-\t\t\t\t\t// START\n-\t\t\t\t\tif (twip_state == TWIP_BUS_ERR) {\n-\t\t\t\t\t\t// ignore\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tbitCount = 8;\n-\t\t\t\t\t\ttwip_state = TWIP_REP_START;\n-\t\t\t\t\t\tets_timer_arm_new(&timer, twi_timeout_ms, false, true); // Once, ms\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tcase TWIP_SLA_W:\n-\t\tcase TWIP_READ:\n-\t\t\tif (!scl) {\n-\t\t\t\t// DATA - ignore\n-\t\t\t} else {\n-\t\t\t\t// START or STOP\n-\t\t\t\tif (bitCount != 7) {\n-\t\t\t\t\t// inside byte transfer - error\n-\t\t\t\t\ttwip_status = TW_BUS_ERROR;\n-\t\t\t\t\ttwi_onTwipEvent(twip_status);\n-\t\t\t\t\ttwip_mode = TWIPM_WAIT;\n-\t\t\t\t\ttwip_state = TWIP_BUS_ERR;\n-\t\t\t\t} else {\n-\t\t\t\t\t// during first bit in byte transfer - ok\n-\t\t\t\t\tSCL_LOW();\t// clock stretching\n-\t\t\t\t\ttwip_status = TW_SR_STOP;\n-\t\t\t\t\ttwi_onTwipEvent(twip_status);\n-\t\t\t\t\tif (sda) {\n-\t\t\t\t\t\t// STOP\n-\t\t\t\t\t\tets_timer_disarm(&timer);\n-\t\t\t\t\t\ttwip_state = TWIP_IDLE;\n-\t\t\t\t\t\ttwip_mode = TWIPM_IDLE;\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\t// START\n-\t\t\t\t\t\tbitCount = 8;\n-\t\t\t\t\t\tets_timer_arm_new(&timer, twi_timeout_ms, false, true); // Once, ms\n-\t\t\t\t\t\ttwip_state = TWIP_REP_START;\n-\t\t\t\t\t\ttwip_mode = TWIPM_IDLE;\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tbreak;\n-\n-\t\tdefault:\n-\t\t\tbreak;\n-\t}\n+    unsigned int sda;\n+    unsigned int scl;\n+\n+    // Store bool return in int to reduce final code size.\n+    sda = twi.SDA_READ();\n+    scl = twi.SCL_READ();\n+\n+    int twip_state_mask = S2M(twi.twip_state);\n+    if (scl)   /* !DATA */\n+    {\n+        IFSTATE(S2M(TWIP_IDLE))\n+        {\n+            if (sda)\n+            {\n+                // STOP - ignore\n+            }\n+            else\n+            {\n+                // START\n+                twi.bitCount = 8;\n+                twi.twip_state = TWIP_START;\n+                ets_timer_arm_new(&twi.timer, twi.twi_timeout_ms, false, true); // Once, ms\n+            }\n+        }\n+        else IFSTATE(S2M(TWIP_START) | S2M(TWIP_REP_START) | S2M(TWIP_SEND_ACK) | S2M(TWIP_WAIT_ACK) | S2M(TWIP_SLA_R) | S2M(TWIP_REC_ACK) | S2M(TWIP_READ_ACK) | S2M(TWIP_RWAIT_ACK) | S2M(TWIP_WRITE))\n+        {\n+            // START or STOP\n+            twi.SDA_HIGH();\t // Should not be necessary\n+            twi.onTwipEvent(TW_BUS_ERROR);\n+            twi.twip_mode = TWIPM_WAIT;\n+            twi.twip_state = TWIP_BUS_ERR;\n+        }\n+        else IFSTATE(S2M(TWIP_WAIT_STOP) | S2M(TWIP_BUS_ERR))\n+        {\n+            if (sda)\n+            {\n+                // STOP\n+                twi.SCL_LOW();\t// clock stretching\n+                ets_timer_disarm(&twi.timer);\n+                twi.twip_state = TWIP_IDLE;\n+                twi.twip_mode = TWIPM_IDLE;\n+                twi.SCL_HIGH();\n+            }\n+            else\n+            {\n+                // START\n+                if (twi.twip_state == TWIP_BUS_ERR)\n+                {\n+                    // ignore\n+                }\n+                else\n+                {\n+                    twi.bitCount = 8;\n+                    twi.twip_state = TWIP_REP_START;\n+                    ets_timer_arm_new(&twi.timer, twi.twi_timeout_ms, false, true); // Once, ms\n+                }\n+            }\n+        }\n+        else IFSTATE(S2M(TWIP_SLA_W) | S2M(TWIP_READ))\n+        {\n+            // START or STOP\n+            if (twi.bitCount != 7)\n+            {\n+                // inside byte transfer - error\n+                twi.onTwipEvent(TW_BUS_ERROR);\n+                twi.twip_mode = TWIPM_WAIT;\n+                twi.twip_state = TWIP_BUS_ERR;\n+            }\n+            else\n+            {\n+                // during first bit in byte transfer - ok\n+                twi.SCL_LOW();\t// clock stretching\n+                twi.onTwipEvent(TW_SR_STOP);\n+                if (sda)\n+                {\n+                    // STOP\n+                    ets_timer_disarm(&twi.timer);\n+                    twi.twip_state = TWIP_IDLE;\n+                    twi.twip_mode = TWIPM_IDLE;\n+                }\n+                else\n+                {\n+                    // START\n+                    twi.bitCount = 8;\n+                    ets_timer_arm_new(&twi.timer, twi.twi_timeout_ms, false, true); // Once, ms\n+                    twi.twip_state = TWIP_REP_START;\n+                    twi.twip_mode = TWIPM_IDLE;\n+                }\n+            }\n+        }\n+    }\n }\n \n+// C wrappers for the object, since API is exposed only as C\n+extern \"C\" {\n+\n+    void twi_init(unsigned char sda, unsigned char scl)\n+    {\n+        return twi.init(sda, scl);\n+    }\n+\n+    void twi_setAddress(uint8_t a)\n+    {\n+        return twi.setAddress(a);\n+    }\n+\n+    void twi_stop(void)\n+    {\n+        twi.stop();\n+    }\n+\n+    void twi_setClock(unsigned int freq)\n+    {\n+        twi.setClock(freq);\n+    }\n+\n+    void twi_setClockStretchLimit(uint32_t limit)\n+    {\n+        twi.setClockStretchLimit(limit);\n+    }\n+\n+    uint8_t twi_writeTo(unsigned char address, unsigned char * buf, unsigned int len, unsigned char sendStop)\n+    {\n+        return twi.writeTo(address, buf, len, sendStop);\n+    }\n+\n+    uint8_t twi_readFrom(unsigned char address, unsigned char * buf, unsigned int len, unsigned char sendStop)\n+    {\n+        return twi.readFrom(address, buf, len, sendStop);\n+    }\n+\n+    uint8_t twi_status()\n+    {\n+        return twi.status();\n+    }\n+\n+    uint8_t twi_transmit(const uint8_t * buf, uint8_t len)\n+    {\n+        return twi.transmit(buf, len);\n+    }\n+\n+    void twi_attachSlaveRxEvent(void (*cb)(uint8_t*, size_t))\n+    {\n+        twi.attachSlaveRxEvent(cb);\n+    }\n+\n+    void twi_attachSlaveTxEvent(void (*cb)(void))\n+    {\n+        twi.attachSlaveTxEvent(cb);\n+    }\n+\n+    void twi_reply(uint8_t r)\n+    {\n+        twi.reply(r);\n+    }\n+\n+    void twi_releaseBus(void)\n+    {\n+        twi.releaseBus();\n+    }\n+\n+    void twi_enableSlaveMode(void)\n+    {\n+        twi.enableSlave();\n+    }\n+\n };\ndiff --git a/cores/esp8266/twi.h b/cores/esp8266/twi.h\nindex 685221820b..27aaaff640 100644\n--- a/cores/esp8266/twi.h\n+++ b/cores/esp8266/twi.h\n@@ -1,23 +1,23 @@\n /*\n-  twi.h - Software I2C library for esp8266\n+    twi.h - Software I2C library for esp8266\n \n-  Copyright (c) 2015 Hristo Gochkov. All rights reserved.\n-  This file is part of the esp8266 core for Arduino environment.\n+    Copyright (c) 2015 Hristo Gochkov. All rights reserved.\n+    This file is part of the esp8266 core for Arduino environment.\n \n-  This library is free software; you can redistribute it and/or\n-  modify it under the terms of the GNU Lesser General Public\n-  License as published by the Free Software Foundation; either\n-  version 2.1 of the License, or (at your option) any later version.\n+    This library is free software; you can redistribute it and/or\n+    modify it under the terms of the GNU Lesser General Public\n+    License as published by the Free Software Foundation; either\n+    version 2.1 of the License, or (at your option) any later version.\n \n-  This library is distributed in the hope that it will be useful,\n-  but WITHOUT ANY WARRANTY; without even the implied warranty of\n-  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n-  Lesser General Public License for more details.\n+    This library is distributed in the hope that it will be useful,\n+    but WITHOUT ANY WARRANTY; without even the implied warranty of\n+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+    Lesser General Public License for more details.\n \n-  You should have received a copy of the GNU Lesser General Public\n-  License along with this library; if not, write to the Free Software\n-  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n-  Modified January 2017 by Bjorn Hammarberg (bjoham@esp8266.com) - i2c slave support\n+    You should have received a copy of the GNU Lesser General Public\n+    License along with this library; if not, write to the Free Software\n+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n+    Modified January 2017 by Bjorn Hammarberg (bjoham@esp8266.com) - i2c slave support\n */\n #ifndef SI2C_h\n #define SI2C_h\n@@ -48,12 +48,13 @@ uint8_t twi_status();\n \n uint8_t twi_transmit(const uint8_t*, uint8_t);\n \n-void twi_attachSlaveRxEvent( void (*)(uint8_t*, size_t) );\n-void twi_attachSlaveTxEvent( void (*)(void) );\n+void twi_attachSlaveRxEvent(void (*)(uint8_t*, size_t));\n+void twi_attachSlaveTxEvent(void (*)(void));\n void twi_reply(uint8_t);\n //void twi_stop(void);\n void twi_releaseBus(void);\n \n+void twi_enableSlaveMode(void);\n \n #ifdef __cplusplus\n }\ndiff --git a/libraries/Wire/Wire.cpp b/libraries/Wire/Wire.cpp\nindex 88103650d1..3aa3604ab0 100644\n--- a/libraries/Wire/Wire.cpp\n+++ b/libraries/Wire/Wire.cpp\n@@ -1,31 +1,31 @@\n /*\n-  TwoWire.cpp - TWI/I2C library for Arduino & Wiring\n-  Copyright (c) 2006 Nicholas Zambetti.  All right reserved.\n-\n-  This library is free software; you can redistribute it and/or\n-  modify it under the terms of the GNU Lesser General Public\n-  License as published by the Free Software Foundation; either\n-  version 2.1 of the License, or (at your option) any later version.\n-\n-  This library is distributed in the hope that it will be useful,\n-  but WITHOUT ANY WARRANTY; without even the implied warranty of\n-  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n-  Lesser General Public License for more details.\n-\n-  You should have received a copy of the GNU Lesser General Public\n-  License along with this library; if not, write to the Free Software\n-  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n-\n-  Modified 2012 by Todd Krein (todd@krein.org) to implement repeated starts\n-  Modified December 2014 by Ivan Grokhotkov (ivan@esp8266.com) - esp8266 support\n-  Modified April 2015 by Hrsto Gochkov (ficeto@ficeto.com) - alternative esp8266 support\n-  Modified January 2017 by Bjorn Hammarberg (bjoham@esp8266.com) - i2c slave support\n+    TwoWire.cpp - TWI/I2C library for Arduino & Wiring\n+    Copyright (c) 2006 Nicholas Zambetti.  All right reserved.\n+\n+    This library is free software; you can redistribute it and/or\n+    modify it under the terms of the GNU Lesser General Public\n+    License as published by the Free Software Foundation; either\n+    version 2.1 of the License, or (at your option) any later version.\n+\n+    This library is distributed in the hope that it will be useful,\n+    but WITHOUT ANY WARRANTY; without even the implied warranty of\n+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+    Lesser General Public License for more details.\n+\n+    You should have received a copy of the GNU Lesser General Public\n+    License along with this library; if not, write to the Free Software\n+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n+\n+    Modified 2012 by Todd Krein (todd@krein.org) to implement repeated starts\n+    Modified December 2014 by Ivan Grokhotkov (ivan@esp8266.com) - esp8266 support\n+    Modified April 2015 by Hrsto Gochkov (ficeto@ficeto.com) - alternative esp8266 support\n+    Modified January 2017 by Bjorn Hammarberg (bjoham@esp8266.com) - i2c slave support\n */\n \n extern \"C\" {\n-  #include <stdlib.h>\n-  #include <string.h>\n-  #include <inttypes.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <inttypes.h>\n }\n \n #include \"twi.h\"\n@@ -58,226 +58,273 @@ static int default_scl_pin = SCL;\n \n // Constructors ////////////////////////////////////////////////////////////////\n \n-TwoWire::TwoWire(){}\n+TwoWire::TwoWire() {}\n \n // Public Methods //////////////////////////////////////////////////////////////\n \n-void TwoWire::begin(int sda, int scl){\n-  default_sda_pin = sda;\n-  default_scl_pin = scl;\n-  twi_init(sda, scl);\n-  flush();\n+void TwoWire::begin(int sda, int scl)\n+{\n+    default_sda_pin = sda;\n+    default_scl_pin = scl;\n+    twi_init(sda, scl);\n+    flush();\n }\n \n-void TwoWire::begin(int sda, int scl, uint8_t address){\n-  default_sda_pin = sda;\n-  default_scl_pin = scl;\n-  twi_setAddress(address);\n-  twi_init(sda, scl);\n-  twi_attachSlaveTxEvent(onRequestService);\n-  twi_attachSlaveRxEvent(onReceiveService);\n-  flush();\n+void TwoWire::begin(int sda, int scl, uint8_t address)\n+{\n+    default_sda_pin = sda;\n+    default_scl_pin = scl;\n+    twi_setAddress(address);\n+    twi_init(sda, scl);\n+    twi_attachSlaveTxEvent(onRequestService);\n+    twi_attachSlaveRxEvent(onReceiveService);\n+    flush();\n }\n \n-void TwoWire::pins(int sda, int scl){\n-  default_sda_pin = sda;\n-  default_scl_pin = scl;\n+void TwoWire::pins(int sda, int scl)\n+{\n+    default_sda_pin = sda;\n+    default_scl_pin = scl;\n }\n \n-void TwoWire::begin(void){\n-  begin(default_sda_pin, default_scl_pin);\n+void TwoWire::begin(void)\n+{\n+    begin(default_sda_pin, default_scl_pin);\n }\n \n-void TwoWire::begin(uint8_t address){\n-  twi_setAddress(address);\n-  twi_attachSlaveTxEvent(onRequestService);\n-  twi_attachSlaveRxEvent(onReceiveService);\n-  begin();\n+void TwoWire::begin(uint8_t address)\n+{\n+    twi_setAddress(address);\n+    twi_attachSlaveTxEvent(onRequestService);\n+    twi_attachSlaveRxEvent(onReceiveService);\n+    begin();\n }\n \n-uint8_t TwoWire::status(){\n-\treturn twi_status();\n+uint8_t TwoWire::status()\n+{\n+    return twi_status();\n }\n \n-void TwoWire::begin(int address){\n-  begin((uint8_t)address);\n+void TwoWire::begin(int address)\n+{\n+    begin((uint8_t)address);\n }\n \n-void TwoWire::setClock(uint32_t frequency){\n-  twi_setClock(frequency);\n+void TwoWire::setClock(uint32_t frequency)\n+{\n+    twi_setClock(frequency);\n }\n \n-void TwoWire::setClockStretchLimit(uint32_t limit){\n-  twi_setClockStretchLimit(limit);\n+void TwoWire::setClockStretchLimit(uint32_t limit)\n+{\n+    twi_setClockStretchLimit(limit);\n }\n \n-size_t TwoWire::requestFrom(uint8_t address, size_t size, bool sendStop){\n-  if(size > BUFFER_LENGTH){\n-    size = BUFFER_LENGTH;\n-  }\n-  size_t read = (twi_readFrom(address, rxBuffer, size, sendStop) == 0)?size:0;\n-  rxBufferIndex = 0;\n-  rxBufferLength = read;\n-  return read;\n+size_t TwoWire::requestFrom(uint8_t address, size_t size, bool sendStop)\n+{\n+    if (size > BUFFER_LENGTH)\n+    {\n+        size = BUFFER_LENGTH;\n+    }\n+    size_t read = (twi_readFrom(address, rxBuffer, size, sendStop) == 0) ? size : 0;\n+    rxBufferIndex = 0;\n+    rxBufferLength = read;\n+    return read;\n }\n \n-uint8_t TwoWire::requestFrom(uint8_t address, uint8_t quantity, uint8_t sendStop){\n-  return requestFrom(address, static_cast<size_t>(quantity), static_cast<bool>(sendStop));\n+uint8_t TwoWire::requestFrom(uint8_t address, uint8_t quantity, uint8_t sendStop)\n+{\n+    return requestFrom(address, static_cast<size_t>(quantity), static_cast<bool>(sendStop));\n }\n \n-uint8_t TwoWire::requestFrom(uint8_t address, uint8_t quantity){\n-  return requestFrom(address, static_cast<size_t>(quantity), true);\n+uint8_t TwoWire::requestFrom(uint8_t address, uint8_t quantity)\n+{\n+    return requestFrom(address, static_cast<size_t>(quantity), true);\n }\n \n-uint8_t TwoWire::requestFrom(int address, int quantity){\n-  return requestFrom(static_cast<uint8_t>(address), static_cast<size_t>(quantity), true);\n+uint8_t TwoWire::requestFrom(int address, int quantity)\n+{\n+    return requestFrom(static_cast<uint8_t>(address), static_cast<size_t>(quantity), true);\n }\n \n-uint8_t TwoWire::requestFrom(int address, int quantity, int sendStop){\n-  return requestFrom(static_cast<uint8_t>(address), static_cast<size_t>(quantity), static_cast<bool>(sendStop));\n+uint8_t TwoWire::requestFrom(int address, int quantity, int sendStop)\n+{\n+    return requestFrom(static_cast<uint8_t>(address), static_cast<size_t>(quantity), static_cast<bool>(sendStop));\n }\n \n-void TwoWire::beginTransmission(uint8_t address){\n-  transmitting = 1;\n-  txAddress = address;\n-  txBufferIndex = 0;\n-  txBufferLength = 0;\n+void TwoWire::beginTransmission(uint8_t address)\n+{\n+    transmitting = 1;\n+    txAddress = address;\n+    txBufferIndex = 0;\n+    txBufferLength = 0;\n }\n \n-void TwoWire::beginTransmission(int address){\n-  beginTransmission((uint8_t)address);\n+void TwoWire::beginTransmission(int address)\n+{\n+    beginTransmission((uint8_t)address);\n }\n \n-uint8_t TwoWire::endTransmission(uint8_t sendStop){\n-  int8_t ret = twi_writeTo(txAddress, txBuffer, txBufferLength, sendStop);\n-  txBufferIndex = 0;\n-  txBufferLength = 0;\n-  transmitting = 0;\n-  return ret;\n+uint8_t TwoWire::endTransmission(uint8_t sendStop)\n+{\n+    int8_t ret = twi_writeTo(txAddress, txBuffer, txBufferLength, sendStop);\n+    txBufferIndex = 0;\n+    txBufferLength = 0;\n+    transmitting = 0;\n+    return ret;\n }\n \n-uint8_t TwoWire::endTransmission(void){\n-  return endTransmission(true);\n+uint8_t TwoWire::endTransmission(void)\n+{\n+    return endTransmission(true);\n }\n \n-size_t TwoWire::write(uint8_t data){\n-  if(transmitting){\n-    if(txBufferLength >= BUFFER_LENGTH){\n-      setWriteError();\n-      return 0;\n+size_t TwoWire::write(uint8_t data)\n+{\n+    if (transmitting)\n+    {\n+        if (txBufferLength >= BUFFER_LENGTH)\n+        {\n+            setWriteError();\n+            return 0;\n+        }\n+        txBuffer[txBufferIndex] = data;\n+        ++txBufferIndex;\n+        txBufferLength = txBufferIndex;\n     }\n-    txBuffer[txBufferIndex] = data;\n-    ++txBufferIndex;\n-    txBufferLength = txBufferIndex;\n-  } else {\n-    twi_transmit(&data, 1);\n-  }\n-  return 1;\n+    else\n+    {\n+        twi_transmit(&data, 1);\n+    }\n+    return 1;\n }\n \n-size_t TwoWire::write(const uint8_t *data, size_t quantity){\n-  if(transmitting){\n-    for(size_t i = 0; i < quantity; ++i){\n-      if(!write(data[i])) return i;\n+size_t TwoWire::write(const uint8_t *data, size_t quantity)\n+{\n+    if (transmitting)\n+    {\n+        for (size_t i = 0; i < quantity; ++i)\n+        {\n+            if (!write(data[i]))\n+            {\n+                return i;\n+            }\n+        }\n+    }\n+    else\n+    {\n+        twi_transmit(data, quantity);\n     }\n-  }else{\n-    twi_transmit(data, quantity);\n-  }\n-  return quantity;\n+    return quantity;\n }\n \n-int TwoWire::available(void){\n-  int result = rxBufferLength - rxBufferIndex;\n+int TwoWire::available(void)\n+{\n+    int result = rxBufferLength - rxBufferIndex;\n \n-  if (!result) {\n-    // yielding here will not make more data \"available\",\n-    // but it will prevent the system from going into WDT reset\n-    optimistic_yield(1000);\n-  }\n+    if (!result)\n+    {\n+        // yielding here will not make more data \"available\",\n+        // but it will prevent the system from going into WDT reset\n+        optimistic_yield(1000);\n+    }\n \n-  return result;\n+    return result;\n }\n \n-int TwoWire::read(void){\n-  int value = -1;\n-  if(rxBufferIndex < rxBufferLength){\n-    value = rxBuffer[rxBufferIndex];\n-    ++rxBufferIndex;\n-  }\n-  return value;\n+int TwoWire::read(void)\n+{\n+    int value = -1;\n+    if (rxBufferIndex < rxBufferLength)\n+    {\n+        value = rxBuffer[rxBufferIndex];\n+        ++rxBufferIndex;\n+    }\n+    return value;\n }\n \n-int TwoWire::peek(void){\n-  int value = -1;\n-  if(rxBufferIndex < rxBufferLength){\n-    value = rxBuffer[rxBufferIndex];\n-  }\n-  return value;\n+int TwoWire::peek(void)\n+{\n+    int value = -1;\n+    if (rxBufferIndex < rxBufferLength)\n+    {\n+        value = rxBuffer[rxBufferIndex];\n+    }\n+    return value;\n }\n \n-void TwoWire::flush(void){\n-  rxBufferIndex = 0;\n-  rxBufferLength = 0;\n-  txBufferIndex = 0;\n-  txBufferLength = 0;\n+void TwoWire::flush(void)\n+{\n+    rxBufferIndex = 0;\n+    rxBufferLength = 0;\n+    txBufferIndex = 0;\n+    txBufferLength = 0;\n }\n \n void TwoWire::onReceiveService(uint8_t* inBytes, size_t numBytes)\n {\n-  // don't bother if user hasn't registered a callback\n-  if (!user_onReceive) {\n-\treturn;\n-  }\n-  // // don't bother if rx buffer is in use by a master requestFrom() op\n-  // // i know this drops data, but it allows for slight stupidity\n-  // // meaning, they may not have read all the master requestFrom() data yet\n-  // if(rxBufferIndex < rxBufferLength){\n-  //   return;\n-  // }\n-  \n-  // copy twi rx buffer into local read buffer\n-  // this enables new reads to happen in parallel\n-  for (uint8_t i = 0; i < numBytes; ++i) {\n-\trxBuffer[i] = inBytes[i];\n-  }\n-  \n-  // set rx iterator vars\n-  rxBufferIndex = 0;\n-  rxBufferLength = numBytes;\n-  \n-  // alert user program\n-  user_onReceive(numBytes);\n+    // don't bother if user hasn't registered a callback\n+    if (!user_onReceive)\n+    {\n+        return;\n+    }\n+    // // don't bother if rx buffer is in use by a master requestFrom() op\n+    // // i know this drops data, but it allows for slight stupidity\n+    // // meaning, they may not have read all the master requestFrom() data yet\n+    // if(rxBufferIndex < rxBufferLength){\n+    //   return;\n+    // }\n+\n+    // copy twi rx buffer into local read buffer\n+    // this enables new reads to happen in parallel\n+    for (uint8_t i = 0; i < numBytes; ++i)\n+    {\n+        rxBuffer[i] = inBytes[i];\n+    }\n+\n+    // set rx iterator vars\n+    rxBufferIndex = 0;\n+    rxBufferLength = numBytes;\n+\n+    // alert user program\n+    user_onReceive(numBytes);\n }\n \n void TwoWire::onRequestService(void)\n {\n-\t// don't bother if user hasn't registered a callback\n-\tif (!user_onRequest) {\n-\t\treturn;\n-\t}\n-\t\n-\t// reset tx buffer iterator vars\n-\t// !!! this will kill any pending pre-master sendTo() activity\n-\ttxBufferIndex = 0;\n-\ttxBufferLength = 0;\n-\t\n-\t// alert user program\n-\tuser_onRequest();\n+    // don't bother if user hasn't registered a callback\n+    if (!user_onRequest)\n+    {\n+        return;\n+    }\n+\n+    // reset tx buffer iterator vars\n+    // !!! this will kill any pending pre-master sendTo() activity\n+    txBufferIndex = 0;\n+    txBufferLength = 0;\n+\n+    // alert user program\n+    user_onRequest();\n }\n \n-void TwoWire::onReceive( void (*function)(int) ) {\n-  // arduino api compatibility fixer:\n-  // really hope size parameter will not exceed 2^31 :)\n-  static_assert(sizeof(int) == sizeof(size_t), \"something is wrong in Arduino kingdom\");\n-  user_onReceive = reinterpret_cast<void(*)(size_t)>(function);\n+void TwoWire::onReceive(void (*function)(int))\n+{\n+    // arduino api compatibility fixer:\n+    // really hope size parameter will not exceed 2^31 :)\n+    static_assert(sizeof(int) == sizeof(size_t), \"something is wrong in Arduino kingdom\");\n+    user_onReceive = reinterpret_cast<void(*)(size_t)>(function);\n }\n \n-void TwoWire::onReceive( void (*function)(size_t) ) {\n-  user_onReceive = function;\n+void TwoWire::onReceive(void (*function)(size_t))\n+{\n+    user_onReceive = function;\n+    twi_enableSlaveMode();\n }\n \n-void TwoWire::onRequest( void (*function)(void) ){\n-  user_onRequest = function;\n+void TwoWire::onRequest(void (*function)(void))\n+{\n+    user_onRequest = function;\n+    twi_enableSlaveMode();\n }\n \n // Preinstantiate Objects //////////////////////////////////////////////////////\ndiff --git a/libraries/Wire/Wire.h b/libraries/Wire/Wire.h\nindex d396f4a843..5d6b36457e 100644\n--- a/libraries/Wire/Wire.h\n+++ b/libraries/Wire/Wire.h\n@@ -1,24 +1,24 @@\n /*\n-  TwoWire.h - TWI/I2C library for Arduino & Wiring\n-  Copyright (c) 2006 Nicholas Zambetti.  All right reserved.\n-\n-  This library is free software; you can redistribute it and/or\n-  modify it under the terms of the GNU Lesser General Public\n-  License as published by the Free Software Foundation; either\n-  version 2.1 of the License, or (at your option) any later version.\n-\n-  This library is distributed in the hope that it will be useful,\n-  but WITHOUT ANY WARRANTY; without even the implied warranty of\n-  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n-  Lesser General Public License for more details.\n-\n-  You should have received a copy of the GNU Lesser General Public\n-  License along with this library; if not, write to the Free Software\n-  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n-\n-  Modified 2012 by Todd Krein (todd@krein.org) to implement repeated starts\n-  Modified December 2014 by Ivan Grokhotkov (ivan@esp8266.com) - esp8266 support\n-  Modified April 2015 by Hrsto Gochkov (ficeto@ficeto.com) - alternative esp8266 support\n+    TwoWire.h - TWI/I2C library for Arduino & Wiring\n+    Copyright (c) 2006 Nicholas Zambetti.  All right reserved.\n+\n+    This library is free software; you can redistribute it and/or\n+    modify it under the terms of the GNU Lesser General Public\n+    License as published by the Free Software Foundation; either\n+    version 2.1 of the License, or (at your option) any later version.\n+\n+    This library is distributed in the hope that it will be useful,\n+    but WITHOUT ANY WARRANTY; without even the implied warranty of\n+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+    Lesser General Public License for more details.\n+\n+    You should have received a copy of the GNU Lesser General Public\n+    License along with this library; if not, write to the Free Software\n+    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n+\n+    Modified 2012 by Todd Krein (todd@krein.org) to implement repeated starts\n+    Modified December 2014 by Ivan Grokhotkov (ivan@esp8266.com) - esp8266 support\n+    Modified April 2015 by Hrsto Gochkov (ficeto@ficeto.com) - alternative esp8266 support\n */\n \n #ifndef TwoWire_h\n@@ -33,7 +33,7 @@\n \n class TwoWire : public Stream\n {\n-  private:\n+private:\n     static uint8_t rxBuffer[];\n     static uint8_t rxBufferIndex;\n     static uint8_t rxBufferLength;\n@@ -48,10 +48,10 @@ class TwoWire : public Stream\n     static void (*user_onReceive)(size_t);\n     static void onRequestService(void);\n     static void onReceiveService(uint8_t*, size_t);\n-  public:\n+public:\n     TwoWire();\n     void begin(int sda, int scl);\n-    void begin(int sda, int scl, uint8_t address);    \n+    void begin(int sda, int scl, uint8_t address);\n     void pins(int sda, int scl) __attribute__((deprecated)); // use begin(sda, scl) in new code\n     void begin();\n     void begin(uint8_t);\n@@ -63,22 +63,22 @@ class TwoWire : public Stream\n     uint8_t endTransmission(void);\n     uint8_t endTransmission(uint8_t);\n     size_t requestFrom(uint8_t address, size_t size, bool sendStop);\n-\tuint8_t status();\n+    uint8_t status();\n \n     uint8_t requestFrom(uint8_t, uint8_t);\n     uint8_t requestFrom(uint8_t, uint8_t, uint8_t);\n     uint8_t requestFrom(int, int);\n     uint8_t requestFrom(int, int, int);\n-    \n+\n     virtual size_t write(uint8_t);\n     virtual size_t write(const uint8_t *, size_t);\n     virtual int available(void);\n     virtual int read(void);\n     virtual int peek(void);\n     virtual void flush(void);\n-    void onReceive( void (*)(int) );    // arduino api\n-    void onReceive( void (*)(size_t) ); // legacy esp8266 backward compatibility\n-    void onRequest( void (*)(void) );\n+    void onReceive(void (*)(int));      // arduino api\n+    void onReceive(void (*)(size_t));   // legacy esp8266 backward compatibility\n+    void onRequest(void (*)(void));\n \n     using Print::write;\n };\ndiff --git a/tests/restyle.sh b/tests/restyle.sh\nindex 32a18c1078..b085d33dc7 100755\n--- a/tests/restyle.sh\n+++ b/tests/restyle.sh\n@@ -9,7 +9,11 @@ test -d cores/esp8266\n test -d libraries\n \n #all=\"cores/esp8266 libraries\"\n-all=\"libraries/ESP8266mDNS\"\n+all=\"\n+libraries/ESP8266mDNS\n+libraries/Wire\n+cores/esp8266/core_esp8266_si2c.cpp\n+\"\n \n for d in $all; do\n     for e in c cpp h; do\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Memory Usage**: A slight IRAM reduction but a small heap increase suggests additional optimizations are needed for memory management.\n\n2. **Struct Optimization**: Pooling loose variables into a structure significantly reduces instruction count and memory access overhead. Consider refactoring global variables into structs.\n\n3. **I2C Issues**: The I2C implementation shows unreliable ACK responses from the slave. Increase interrupt priority for GPIO (used by I2C) to improve latency and functionality. This might enhance compatibility with standard I2C devices.\n\n4. **Code Structure**: Refactor complex if-else structures back to meaningful functions to improve readability. Use inline functions where appropriate to minimize size.\n\n5. **Remove/Document Slave Mode**: If performance issues persist, consider removing the I2C slave mode from the standard library or moving it to a separate library, clearly documenting limitations."
      }
    ],
    "codediff_length": 69060
  },
  {
    "index": 42,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/cores/esp8266/Arduino.h b/cores/esp8266/Arduino.h\nindex 60737e0195..bcaa3ebfd2 100644\n--- a/cores/esp8266/Arduino.h\n+++ b/cores/esp8266/Arduino.h\n@@ -275,6 +275,8 @@ void setTZ(const char* tz);\n void configTime(const char* tz, const char* server1,\n     const char* server2 = nullptr, const char* server3 = nullptr);\n \n+void attachInterrupt(uint8_t pin, std::function<void()> userFunc, int mode);\n+\n // configures with approximated TZ value. part of the old api, prefer configTime with TZ variable\n void configTime(int timezone, int daylightOffset_sec, const char* server1,\n     const char* server2 = nullptr, const char* server3 = nullptr);\ndiff --git a/cores/esp8266/FunctionalInterrupt.cpp b/cores/esp8266/FunctionalInterrupt.cpp\ndeleted file mode 100644\nindex f468595787..0000000000\n--- a/cores/esp8266/FunctionalInterrupt.cpp\n+++ /dev/null\n@@ -1,65 +0,0 @@\n-#include <FunctionalInterrupt.h>\n-#include <Schedule.h>\n-#include \"Arduino.h\"\n-\n-// Duplicate typedefs from core_esp8266_wiring_digital_c\n-typedef void (*voidFuncPtr)(void);\n-typedef void (*voidFuncPtrArg)(void*);\n-\n-// Helper functions for Functional interrupt routines\n-extern \"C\" void __attachInterruptFunctionalArg(uint8_t pin, voidFuncPtr userFunc, void*fp, int mode, bool functional);\n-\n-\n-void IRAM_ATTR interruptFunctional(void* arg)\n-{\n-    ArgStructure* localArg = (ArgStructure*)arg;\n-\tif (localArg->functionInfo->reqScheduledFunction)\n-\t{\n-\t\tschedule_function(std::bind(localArg->functionInfo->reqScheduledFunction,InterruptInfo(*(localArg->interruptInfo))));\n-\t}\n-\tif (localArg->functionInfo->reqFunction)\n-\t{\n-\t  localArg->functionInfo->reqFunction();\n-\t}\n-}\n-\n-extern \"C\"\n-{\n-   void cleanupFunctional(void* arg)\n-   {\n-\t ArgStructure* localArg = (ArgStructure*)arg;\n-\t delete (FunctionInfo*)localArg->functionInfo;\n-     delete (InterruptInfo*)localArg->interruptInfo;\n-\t delete localArg;\n-   }\n-}\n-\n-void attachInterrupt(uint8_t pin, std::function<void(void)> intRoutine, int mode)\n-{\n-\t// use the local interrupt routine which takes the ArgStructure as argument\n-\n-\tInterruptInfo* ii = nullptr;\n-\n-\tFunctionInfo* fi = new FunctionInfo;\n-\tfi->reqFunction = intRoutine;\n-\n-\tArgStructure* as = new ArgStructure;\n-\tas->interruptInfo = ii;\n-\tas->functionInfo = fi;\n-\n-\t__attachInterruptFunctionalArg(pin, (voidFuncPtr)interruptFunctional, as, mode, true);\n-}\n-\n-void attachScheduledInterrupt(uint8_t pin, std::function<void(InterruptInfo)> scheduledIntRoutine, int mode)\n-{\n-\tInterruptInfo* ii = new InterruptInfo;\n-\n-\tFunctionInfo* fi = new FunctionInfo;\n-\tfi->reqScheduledFunction = scheduledIntRoutine;\n-\n-\tArgStructure* as = new ArgStructure;\n-\tas->interruptInfo = ii;\n-\tas->functionInfo = fi;\n-\n-\t__attachInterruptFunctionalArg(pin, (voidFuncPtr)interruptFunctional, as, mode, true);\n-}\ndiff --git a/cores/esp8266/FunctionalInterrupt.h b/cores/esp8266/FunctionalInterrupt.h\ndeleted file mode 100644\nindex 968793e499..0000000000\n--- a/cores/esp8266/FunctionalInterrupt.h\n+++ /dev/null\n@@ -1,35 +0,0 @@\n-#ifndef FUNCTIONALINTERRUPT_H\n-#define FUNCTIONALINTERRUPT_H\n-\n-#include <stddef.h>\n-#include <stdint.h>\n-#include <functional>\n-\n-extern \"C\" {\n-#include \"c_types.h\"\n-#include \"ets_sys.h\"\n-}\n-\n-// Structures for communication\n-\n-struct InterruptInfo {\n-\tuint8_t pin = 0;\n-\tuint8_t value = 0;\n-\tuint32_t micro = 0;\n-};\n-\n-struct FunctionInfo {\n-    std::function<void(void)> reqFunction = nullptr;\n-\tstd::function<void(InterruptInfo)> reqScheduledFunction = nullptr;\n-};\n-\n-struct ArgStructure {\n-\tInterruptInfo* interruptInfo = nullptr;\n-\tFunctionInfo* functionInfo = nullptr;\n-};\n-\n-void attachInterrupt(uint8_t pin, std::function<void(void)> intRoutine, int mode);\n-void attachScheduledInterrupt(uint8_t pin, std::function<void(InterruptInfo)> scheduledIntRoutine, int mode);\n-\n-\n-#endif //INTERRUPTS_H\ndiff --git a/cores/esp8266/core_esp8266_wiring_digital.cpp b/cores/esp8266/core_esp8266_wiring_digital.cpp\nindex 6b42c3ee36..613fc2e027 100644\n--- a/cores/esp8266/core_esp8266_wiring_digital.cpp\n+++ b/cores/esp8266/core_esp8266_wiring_digital.cpp\n@@ -30,236 +30,244 @@\n \n extern \"C\" {\n \n-volatile uint32_t* const esp8266_gpioToFn[16] PROGMEM = { &GPF0, &GPF1, &GPF2, &GPF3, &GPF4, &GPF5, &GPF6, &GPF7, &GPF8, &GPF9, &GPF10, &GPF11, &GPF12, &GPF13, &GPF14, &GPF15 };\n+    volatile uint32_t* const esp8266_gpioToFn[16] PROGMEM = { &GPF0, &GPF1, &GPF2, &GPF3, &GPF4, &GPF5, &GPF6, &GPF7, &GPF8, &GPF9, &GPF10, &GPF11, &GPF12, &GPF13, &GPF14, &GPF15 };\n \n-extern void __pinMode(uint8_t pin, uint8_t mode) {\n-  if(pin < 16){\n-    if(mode == SPECIAL){\n-      GPC(pin) = (GPC(pin) & (0xF << GPCI)); //SOURCE(GPIO) | DRIVER(NORMAL) | INT_TYPE(UNCHANGED) | WAKEUP_ENABLE(DISABLED)\n-      GPEC = (1 << pin); //Disable\n-      GPF(pin) = GPFFS(GPFFS_BUS(pin));//Set mode to BUS (RX0, TX0, TX1, SPI, HSPI or CLK depending in the pin)\n-      if(pin == 3) GPF(pin) |= (1 << GPFPU);//enable pullup on RX\n-    } else if(mode & FUNCTION_0){\n-      GPC(pin) = (GPC(pin) & (0xF << GPCI)); //SOURCE(GPIO) | DRIVER(NORMAL) | INT_TYPE(UNCHANGED) | WAKEUP_ENABLE(DISABLED)\n-      GPEC = (1 << pin); //Disable\n-      GPF(pin) = GPFFS((mode >> 4) & 0x07);\n-      if(pin == 13 && mode == FUNCTION_4) GPF(pin) |= (1 << GPFPU);//enable pullup on RX\n-    }  else if(mode == OUTPUT || mode == OUTPUT_OPEN_DRAIN){\n-      GPF(pin) = GPFFS(GPFFS_GPIO(pin));//Set mode to GPIO\n-      GPC(pin) = (GPC(pin) & (0xF << GPCI)); //SOURCE(GPIO) | DRIVER(NORMAL) | INT_TYPE(UNCHANGED) | WAKEUP_ENABLE(DISABLED)\n-      if(mode == OUTPUT_OPEN_DRAIN) GPC(pin) |= (1 << GPCD);\n-      GPES = (1 << pin); //Enable\n-    } else if(mode == INPUT || mode == INPUT_PULLUP){\n-      GPF(pin) = GPFFS(GPFFS_GPIO(pin));//Set mode to GPIO\n-      GPEC = (1 << pin); //Disable\n-      GPC(pin) = (GPC(pin) & (0xF << GPCI)) | (1 << GPCD); //SOURCE(GPIO) | DRIVER(OPEN_DRAIN) | INT_TYPE(UNCHANGED) | WAKEUP_ENABLE(DISABLED)\n-      if(mode == INPUT_PULLUP) {\n-          GPF(pin) |= (1 << GPFPU);  // Enable  Pullup\n-      }\n-    } else if(mode == WAKEUP_PULLUP || mode == WAKEUP_PULLDOWN){\n-      GPF(pin) = GPFFS(GPFFS_GPIO(pin));//Set mode to GPIO\n-      GPEC = (1 << pin); //Disable\n-      if(mode == WAKEUP_PULLUP) {\n-          GPF(pin) |= (1 << GPFPU);  // Enable  Pullup\n-          GPC(pin) = (1 << GPCD) | (4 << GPCI) | (1 << GPCWE); //SOURCE(GPIO) | DRIVER(OPEN_DRAIN) | INT_TYPE(LOW) | WAKEUP_ENABLE(ENABLED)\n-      } else {\n-          GPF(pin) |= (1 << GPFPD);  // Enable  Pulldown\n-          GPC(pin) = (1 << GPCD) | (5 << GPCI) | (1 << GPCWE); //SOURCE(GPIO) | DRIVER(OPEN_DRAIN) | INT_TYPE(HIGH) | WAKEUP_ENABLE(ENABLED)\n-      }\n+    extern void __pinMode(uint8_t pin, uint8_t mode) {\n+        if (pin < 16) {\n+            if (mode == SPECIAL) {\n+                GPC(pin) = (GPC(pin) & (0xF << GPCI)); //SOURCE(GPIO) | DRIVER(NORMAL) | INT_TYPE(UNCHANGED) | WAKEUP_ENABLE(DISABLED)\n+                GPEC = (1 << pin); //Disable\n+                GPF(pin) = GPFFS(GPFFS_BUS(pin));//Set mode to BUS (RX0, TX0, TX1, SPI, HSPI or CLK depending in the pin)\n+                if (pin == 3) GPF(pin) |= (1 << GPFPU);//enable pullup on RX\n+            }\n+            else if (mode & FUNCTION_0) {\n+                GPC(pin) = (GPC(pin) & (0xF << GPCI)); //SOURCE(GPIO) | DRIVER(NORMAL) | INT_TYPE(UNCHANGED) | WAKEUP_ENABLE(DISABLED)\n+                GPEC = (1 << pin); //Disable\n+                GPF(pin) = GPFFS((mode >> 4) & 0x07);\n+                if (pin == 13 && mode == FUNCTION_4) GPF(pin) |= (1 << GPFPU);//enable pullup on RX\n+            }\n+            else if (mode == OUTPUT || mode == OUTPUT_OPEN_DRAIN) {\n+                GPF(pin) = GPFFS(GPFFS_GPIO(pin));//Set mode to GPIO\n+                GPC(pin) = (GPC(pin) & (0xF << GPCI)); //SOURCE(GPIO) | DRIVER(NORMAL) | INT_TYPE(UNCHANGED) | WAKEUP_ENABLE(DISABLED)\n+                if (mode == OUTPUT_OPEN_DRAIN) GPC(pin) |= (1 << GPCD);\n+                GPES = (1 << pin); //Enable\n+            }\n+            else if (mode == INPUT || mode == INPUT_PULLUP) {\n+                GPF(pin) = GPFFS(GPFFS_GPIO(pin));//Set mode to GPIO\n+                GPEC = (1 << pin); //Disable\n+                GPC(pin) = (GPC(pin) & (0xF << GPCI)) | (1 << GPCD); //SOURCE(GPIO) | DRIVER(OPEN_DRAIN) | INT_TYPE(UNCHANGED) | WAKEUP_ENABLE(DISABLED)\n+                if (mode == INPUT_PULLUP) {\n+                    GPF(pin) |= (1 << GPFPU);  // Enable  Pullup\n+                }\n+            }\n+            else if (mode == WAKEUP_PULLUP || mode == WAKEUP_PULLDOWN) {\n+                GPF(pin) = GPFFS(GPFFS_GPIO(pin));//Set mode to GPIO\n+                GPEC = (1 << pin); //Disable\n+                if (mode == WAKEUP_PULLUP) {\n+                    GPF(pin) |= (1 << GPFPU);  // Enable  Pullup\n+                    GPC(pin) = (1 << GPCD) | (4 << GPCI) | (1 << GPCWE); //SOURCE(GPIO) | DRIVER(OPEN_DRAIN) | INT_TYPE(LOW) | WAKEUP_ENABLE(ENABLED)\n+                }\n+                else {\n+                    GPF(pin) |= (1 << GPFPD);  // Enable  Pulldown\n+                    GPC(pin) = (1 << GPCD) | (5 << GPCI) | (1 << GPCWE); //SOURCE(GPIO) | DRIVER(OPEN_DRAIN) | INT_TYPE(HIGH) | WAKEUP_ENABLE(ENABLED)\n+                }\n+            }\n+        }\n+        else if (pin == 16) {\n+            GPF16 = GP16FFS(GPFFS_GPIO(pin));//Set mode to GPIO\n+            GPC16 = 0;\n+            if (mode == INPUT || mode == INPUT_PULLDOWN_16) {\n+                if (mode == INPUT_PULLDOWN_16) {\n+                    GPF16 |= (1 << GP16FPD);//Enable Pulldown\n+                }\n+                GP16E &= ~1;\n+            }\n+            else if (mode == OUTPUT) {\n+                GP16E |= 1;\n+            }\n+        }\n     }\n-  } else if(pin == 16){\n-    GPF16 = GP16FFS(GPFFS_GPIO(pin));//Set mode to GPIO\n-    GPC16 = 0;\n-    if(mode == INPUT || mode == INPUT_PULLDOWN_16){\n-      if(mode == INPUT_PULLDOWN_16){\n-        GPF16 |= (1 << GP16FPD);//Enable Pulldown\n-      }\n-      GP16E &= ~1;\n-    } else if(mode == OUTPUT){\n-      GP16E |= 1;\n+\n+    extern void IRAM_ATTR __digitalWrite(uint8_t pin, uint8_t val) {\n+        stopWaveform(pin); // Disable any Tone or startWaveform on this pin\n+        _stopPWM(pin);     // and any analogWrites (PWM)\n+        if (pin < 16) {\n+            if (val) GPOS = (1 << pin);\n+            else GPOC = (1 << pin);\n+        }\n+        else if (pin == 16) {\n+            if (val) GP16O |= 1;\n+            else GP16O &= ~1;\n+        }\n     }\n-  }\n-}\n \n-extern void IRAM_ATTR __digitalWrite(uint8_t pin, uint8_t val) {\n-  stopWaveform(pin); // Disable any Tone or startWaveform on this pin\n-  _stopPWM(pin);     // and any analogWrites (PWM)\n-  if(pin < 16){\n-    if(val) GPOS = (1 << pin);\n-    else GPOC = (1 << pin);\n-  } else if(pin == 16){\n-    if(val) GP16O |= 1;\n-    else GP16O &= ~1;\n-  }\n-}\n+    extern int IRAM_ATTR __digitalRead(uint8_t pin) {\n+        if (pin < 16) {\n+            return GPIP(pin);\n+        }\n+        else if (pin == 16) {\n+            return GP16I & 0x01;\n+        }\n+        return 0;\n+    }\n \n-extern int IRAM_ATTR __digitalRead(uint8_t pin) {\n-  if(pin < 16){\n-    return GPIP(pin);\n-  } else if(pin == 16){\n-    return GP16I & 0x01;\n-  }\n-  return 0;\n-}\n+    /*\n+      GPIO INTERRUPTS\n+    */\n \n-/*\n-  GPIO INTERRUPTS\n-*/\n+    typedef void (*voidFuncPtr)(void);\n+    typedef void (*voidFuncPtrArg)(void*);\n \n-typedef void (*voidFuncPtr)(void);\n-typedef void (*voidFuncPtrArg)(void*);\n+    namespace\n+    {\n+        struct interrupt_handler_t {\n+            interrupt_handler_t()\n+            {\n+                mode = 0;\n+            }\n+            ~interrupt_handler_t()\n+            {\n+            }\n+            uint8_t mode;\n+            std::function<void()> userFunc;\n+        };\n \n-typedef struct {\n-  uint8_t mode;\n-  voidFuncPtr fn;\n-  void * arg;\n-  bool functional;\n-} interrupt_handler_t;\n+        static interrupt_handler_t interrupt_handlers[16];\n+        static uint32_t interrupt_reg = 0;\n \n-//duplicate from functionalInterrupt.h keep in sync\n-typedef struct InterruptInfo {\n-\tuint8_t pin;\n-\tuint8_t value;\n-\tuint32_t micro;\n-} InterruptInfo;\n+        inline void isr_iram_assertion(voidFuncPtrArg userFunc)\n+        {\n+            // #5780\n+            // https://github.com/esp8266/esp8266-wiki/wiki/Memory-Map\n+            if ((uint32_t)userFunc >= 0x40200000)\n+            {\n+                // ISR not in IRAM\n+                ::printf((PGM_P)F(\"ISR not in IRAM!\\r\\n\"));\n+                abort();\n+            }\n+        }\n \n-typedef struct {\n-\tInterruptInfo* interruptInfo;\n-\tvoid* functionInfo;\n-} ArgStructure;\n+        void set_interrupt_handlers(uint8_t pin, std::function<void()>&& userFunc, uint8_t mode)\n+        {\n+            interrupt_handler_t& handler = interrupt_handlers[pin];\n+            handler.userFunc = std::move(userFunc);\n+            handler.mode = handler.userFunc ?  mode : 0;\n+        }\n \n-static interrupt_handler_t interrupt_handlers[16] = { {0, 0, 0, 0}, };\n-static uint32_t interrupt_reg = 0;\n+        void IRAM_ATTR interrupt_handler(void *arg, void *frame);\n \n-void IRAM_ATTR interrupt_handler(void *arg, void *frame)\n-{\n-  (void) arg;\n-  (void) frame;\n-  uint32_t status = GPIE;\n-  GPIEC = status;//clear them interrupts\n-  uint32_t levels = GPI;\n-  if(status == 0 || interrupt_reg == 0) return;\n-  ETS_GPIO_INTR_DISABLE();\n-  int i = 0;\n-  uint32_t changedbits = status & interrupt_reg;\n-  while(changedbits){\n-    while(!(changedbits & (1 << i))) i++;\n-    changedbits &= ~(1 << i);\n-    interrupt_handler_t *handler = &interrupt_handlers[i];\n-    if (handler->fn && \n-        (handler->mode == CHANGE || \n-         (handler->mode & 1) == !!(levels & (1 << i)))) {\n-          // to make ISR compatible to Arduino AVR model where interrupts are disabled\n-          // we disable them before we call the client ISR\n-          esp8266::InterruptLock irqLock; // stop other interrupts\n-          if (handler->functional)\n-          {\n-              ArgStructure* localArg = (ArgStructure*)handler->arg;\n-              if (localArg && localArg->interruptInfo)\n-              {\n-                  localArg->interruptInfo->pin = i;\n-                  localArg->interruptInfo->value = __digitalRead(i);\n-                  localArg->interruptInfo->micro = micros();\n-              }\n-          }\n-          if (handler->arg)\n-          {\n-              ((voidFuncPtrArg)handler->fn)(handler->arg);\n-          }\n-          else\n-          {\n-              handler->fn();\n-          }\n-      }\n-  }\n-  ETS_GPIO_INTR_ENABLE();\n-}\n+        void set_interrupt_reg(uint8_t pin, int mode)\n+        {\n+            interrupt_reg |= (1 << pin);\n+            GPC(pin) &= ~(0xF << GPCI);//INT mode disabled\n+            GPIEC = (1 << pin); //Clear Interrupt for this pin\n+            GPC(pin) |= ((mode & 0xF) << GPCI);//INT mode \"mode\"\n+            ETS_GPIO_INTR_ATTACH(interrupt_handler, &interrupt_reg);\n+        }\n \n-extern void cleanupFunctional(void* arg);\n+    }\n \n-static void set_interrupt_handlers(uint8_t pin, voidFuncPtr userFunc, void* arg, uint8_t mode, bool functional)\n-{\n-  interrupt_handler_t* handler = &interrupt_handlers[pin];\n-  handler->mode = mode;\n-  handler->fn = userFunc;\n-  if (handler->functional && handler->arg)  // Clean when new attach without detach\n-  {\n-    cleanupFunctional(handler->arg);\n-  }\n-  handler->arg = arg;\n-  handler->functional = functional;\n-}\n+    extern void __attachInterruptArg(uint8_t pin, voidFuncPtrArg const userFunc, void* const arg, int mode)\n+    {\n+        isr_iram_assertion(userFunc);\n+        attachInterrupt(pin, std::bind(userFunc, arg), mode);\n+    }\n \n-extern void __attachInterruptFunctionalArg(uint8_t pin, voidFuncPtrArg userFunc, void* arg, int mode, bool functional)\n-{\n-  // #5780\n-  // https://github.com/esp8266/esp8266-wiki/wiki/Memory-Map\n-  if ((uint32_t)userFunc >= 0x40200000)\n-  {\n-    // ISR not in IRAM\n-    ::printf((PGM_P)F(\"ISR not in IRAM!\\r\\n\"));\n-    abort();\n-  }\n+    extern void __attachInterrupt(uint8_t pin, voidFuncPtr userFunc, int mode)\n+    {\n+        attachInterruptArg(pin, reinterpret_cast<voidFuncPtrArg>(userFunc), nullptr, mode);\n+    }\n \n-  if(pin < 16) {\n-    ETS_GPIO_INTR_DISABLE();\n-    set_interrupt_handlers(pin, (voidFuncPtr)userFunc, arg, mode, functional);\n-    interrupt_reg |= (1 << pin);\n-    GPC(pin) &= ~(0xF << GPCI);//INT mode disabled\n-    GPIEC = (1 << pin); //Clear Interrupt for this pin\n-    GPC(pin) |= ((mode & 0xF) << GPCI);//INT mode \"mode\"\n-    ETS_GPIO_INTR_ATTACH(interrupt_handler, &interrupt_reg);\n-    ETS_GPIO_INTR_ENABLE();\n-  }\n-}\n+    extern void IRAM_ATTR __detachInterrupt(uint8_t pin)\n+    {\n+        if (pin < 16)\n+        {\n+            ETS_GPIO_INTR_DISABLE();\n+            GPC(pin) &= ~(0xF << GPCI);//INT mode disabled\n+            GPIEC = (1 << pin); //Clear Interrupt for this pin\n+            interrupt_reg &= ~(1 << pin);\n+            interrupt_handler_t& handler = interrupt_handlers[pin];\n+            handler.userFunc = nullptr;\n+            handler.mode = 0;\n+            if (interrupt_reg)\n+            {\n+                ETS_GPIO_INTR_ENABLE();\n+            }\n+        }\n+    }\n \n-extern void __attachInterruptArg(uint8_t pin, voidFuncPtrArg userFunc, void* arg, int mode)\n-{\n-    __attachInterruptFunctionalArg(pin, userFunc, arg, mode, false);\n-}\n+    extern void __resetPins() {\n+        for (int i = 0; i <= 16; ++i) {\n+            if (!isFlashInterfacePin(i)) {\n+                pinMode(i, INPUT);\n+            }\n+        }\n+    }\n+\n+    extern void initPins() {\n+        //Disable UART interrupts\n+        system_set_os_print(0);\n+        U0IE = 0;\n+        U1IE = 0;\n+\n+        resetPins();\n+    }\n+\n+    extern void resetPins() __attribute__ ((weak, alias(\"__resetPins\")));\n+    extern void pinMode(uint8_t pin, uint8_t mode) __attribute__((weak, alias(\"__pinMode\")));\n+    extern void digitalWrite(uint8_t pin, uint8_t val) __attribute__((weak, alias(\"__digitalWrite\")));\n+    extern int digitalRead(uint8_t pin) __attribute__((weak, alias(\"__digitalRead\"), nothrow));\n+    extern void attachInterrupt(uint8_t pin, voidFuncPtr handler, int mode) __attribute__((weak, alias(\"__attachInterrupt\")));\n+    extern void attachInterruptArg(uint8_t pin, voidFuncPtrArg handler, void* arg, int mode) __attribute__((weak, alias(\"__attachInterruptArg\")));\n+    extern void detachInterrupt(uint8_t pin) __attribute__((weak, alias(\"__detachInterrupt\")));\n+\n+};\n \n-extern void IRAM_ATTR __detachInterrupt(uint8_t pin) {\n+extern void attachInterrupt(uint8_t pin, std::function<void()> userFunc, int mode)\n+{\n+    // isr_iram_assertion cannot inspect std::function objects\n     if (pin < 16)\n     {\n         ETS_GPIO_INTR_DISABLE();\n-        GPC(pin) &= ~(0xF << GPCI);//INT mode disabled\n-        GPIEC = (1 << pin); //Clear Interrupt for this pin\n-        interrupt_reg &= ~(1 << pin);\n-\t\tset_interrupt_handlers(pin, nullptr, nullptr, 0, false);\n-        if (interrupt_reg)\n-        {\n-            ETS_GPIO_INTR_ENABLE();\n-        }\n+        set_interrupt_handlers(pin, std::move(userFunc), mode);\n+        set_interrupt_reg(pin, mode);\n+        ETS_GPIO_INTR_ENABLE();\n     }\n }\n \n-extern void __attachInterrupt(uint8_t pin, voidFuncPtr userFunc, int mode)\n-{\n-    __attachInterruptFunctionalArg(pin, (voidFuncPtrArg)userFunc, 0, mode, false);\n-}\n+// Speed critical bits\n+#pragma GCC optimize (\"O2\")\n \n-extern void __resetPins() {\n-  for (int i = 0; i <= 16; ++i) {\n-    if (!isFlashInterfacePin(i))\n-        pinMode(i, INPUT);\n-  }\n-}\n+namespace\n+{\n \n-extern void initPins() {\n-  //Disable UART interrupts\n-  system_set_os_print(0);\n-  U0IE = 0;\n-  U1IE = 0;\n+    void IRAM_ATTR interrupt_handler(void *arg, void *frame)\n+    {\n+        (void) arg;\n+        (void) frame;\n+        uint32_t status = GPIE;\n+        GPIEC = status;//clear them interrupts\n+        uint32_t levels = GPI;\n+        if (status == 0 || interrupt_reg == 0) return;\n+        ETS_GPIO_INTR_DISABLE();\n+        uint32_t i = 0;\n+        uint32_t changedbits = status & interrupt_reg;\n+        while (changedbits >= (1UL << i)) {\n+            while (!(changedbits & (1UL << i)))\n+            {\n+                ++i;\n+            }\n+            const interrupt_handler_t& handler = interrupt_handlers[i];\n+            if (handler.mode == CHANGE ||\n+                (handler.mode & 1) == static_cast<bool>(levels & (1UL << i))) {\n+                // to make ISR compatible to Arduino AVR model where interrupts are disabled\n+                // we disable them before we call the client ISR\n+                esp8266::InterruptLock irqLock; // stop other interrupts\n+                handler.userFunc();\n+            }\n+            ++i;\n+        }\n+        ETS_GPIO_INTR_ENABLE();\n+    }\n \n-  resetPins();\n }\n-\n-extern void resetPins() __attribute__ ((weak, alias(\"__resetPins\")));\n-extern void pinMode(uint8_t pin, uint8_t mode) __attribute__ ((weak, alias(\"__pinMode\")));\n-extern void digitalWrite(uint8_t pin, uint8_t val) __attribute__ ((weak, alias(\"__digitalWrite\")));\n-extern int digitalRead(uint8_t pin) __attribute__ ((weak, alias(\"__digitalRead\"), nothrow));\n-extern void attachInterrupt(uint8_t pin, voidFuncPtr handler, int mode) __attribute__ ((weak, alias(\"__attachInterrupt\")));\n-extern void attachInterruptArg(uint8_t pin, voidFuncPtrArg handler, void* arg, int mode) __attribute__((weak, alias(\"__attachInterruptArg\")));\n-extern void detachInterrupt(uint8_t pin) __attribute__ ((weak, alias(\"__detachInterrupt\")));\n-\n-};\ndiff --git a/libraries/FunctionalInterrupt/examples/Functional/Functional.ino b/libraries/FunctionalInterrupt/examples/Functional/Functional.ino\nnew file mode 100644\nindex 0000000000..e5eff172e9\n--- /dev/null\n+++ b/libraries/FunctionalInterrupt/examples/Functional/Functional.ino\n@@ -0,0 +1,71 @@\n+// Hint: On ESP8266, this no longer depends on FunctionalInterrupt, but is rather a feature of\n+// the standard API in Arduino.h\n+\n+//#include <FunctionalInterrupt.h>\n+\n+#if defined(ESP32)\n+#define BUTTON1 16\n+#define BUTTON2 17\n+#elif defined(ARDUINO_ESP8266_WEMOS_D1MINI)\n+#define BUTTON1 D4\n+#define BUTTON2 D3\n+#else\n+#define BUTTON1 2\n+#define BUTTON2 0\n+#endif\n+\n+class Button {\n+public:\n+  Button(uint8_t reqPin)\n+    : PIN(reqPin) {\n+    pinMode(PIN, INPUT_PULLUP);\n+    attachInterrupt(PIN, std::bind(buttonIsr_static, this), FALLING);\n+  };\n+  ~Button() {\n+    detachInterrupt(PIN);\n+  }\n+\n+  void IRAM_ATTR buttonIsr() {\n+    numberKeyPresses += 1;\n+    pressed = true;\n+  }\n+\n+  static void IRAM_ATTR buttonIsr_static(void* const self) {\n+    static_cast<Button*>(self)->buttonIsr();\n+  }\n+\n+  uint32_t checkPressed() {\n+    if (pressed) {\n+      Serial.printf(\"Button on pin %u has been pressed %u times\\n\", PIN, numberKeyPresses);\n+      pressed = false;\n+    }\n+    return numberKeyPresses;\n+  }\n+\n+private:\n+  const uint8_t PIN;\n+  volatile uint32_t numberKeyPresses = 0;\n+  volatile bool pressed = false;\n+};\n+\n+Button* button1;\n+Button* button2;\n+\n+\n+void setup() {\n+  Serial.begin(115200);\n+  Serial.println(\"FunctionalInterrupt test/example\");\n+\n+  button1 = new Button(BUTTON1);\n+  button2 = new Button(BUTTON2);\n+\n+  Serial.println(\"setup() complete\");\n+}\n+\n+void loop() {\n+  button1->checkPressed();\n+  if (nullptr != button2 && 10 < button2->checkPressed()) {\n+    delete button2;\n+    button2 = nullptr;\n+  }\n+}\ndiff --git a/libraries/FunctionalInterrupt/examples/ScheduledFunctional/ScheduledFunctional.ino b/libraries/FunctionalInterrupt/examples/ScheduledFunctional/ScheduledFunctional.ino\nnew file mode 100644\nindex 0000000000..fc769b2027\n--- /dev/null\n+++ b/libraries/FunctionalInterrupt/examples/ScheduledFunctional/ScheduledFunctional.ino\n@@ -0,0 +1,68 @@\n+#include <FunctionalInterrupt.h>\n+\n+#if defined(ESP32)\n+#define BUTTON1 16\n+#define BUTTON2 17\n+#elif defined(ARDUINO_ESP8266_WEMOS_D1MINI)\n+#define BUTTON1 D4\n+#define BUTTON2 D3\n+#else\n+#define BUTTON1 2\n+#define BUTTON2 0\n+#endif\n+\n+class Button {\n+public:\n+  Button(uint8_t reqPin)\n+    : PIN(reqPin) {\n+    pinMode(PIN, INPUT_PULLUP);\n+    attachScheduledInterrupt(\n+      PIN, [this](const InterruptInfo& ii) {\n+        Serial.print(\"Pin \");\n+        Serial.println(ii.pin);\n+        numberKeyPresses += 1;\n+        pressed = true;\n+      },\n+      FALLING);  // works on ESP8266\n+  };\n+  ~Button() {\n+    detachInterrupt(PIN);\n+  }\n+\n+  uint32_t checkPressed() {\n+    if (pressed) {\n+      Serial.printf(\"Button on pin %u has been pressed %u times\\n\", PIN, numberKeyPresses);\n+      pressed = false;\n+    }\n+    return numberKeyPresses;\n+  }\n+\n+private:\n+  const uint8_t PIN;\n+  volatile uint32_t numberKeyPresses = 0;\n+  volatile bool pressed = false;\n+};\n+\n+Button* button1;\n+Button* button2;\n+\n+\n+void setup() {\n+  Serial.begin(115200);\n+  while (!Serial) {}\n+  delay(500);\n+  Serial.println(\"FunctionalInterrupt test/example\");\n+\n+  button1 = new Button(BUTTON1);\n+  button2 = new Button(BUTTON2);\n+\n+  Serial.println(\"setup() complete\");\n+}\n+\n+void loop() {\n+  button1->checkPressed();\n+  if (nullptr != button2 && 10 < button2->checkPressed()) {\n+    delete button2;\n+    button2 = nullptr;\n+  }\n+}\ndiff --git a/libraries/FunctionalInterrupt/keywords.txt b/libraries/FunctionalInterrupt/keywords.txt\nnew file mode 100644\nindex 0000000000..babcb63442\n--- /dev/null\n+++ b/libraries/FunctionalInterrupt/keywords.txt\n@@ -0,0 +1,11 @@\n+#######################################\n+# Datatypes (KEYWORD1)\n+#######################################\n+\n+InterruptInfo\tKEYWORD1\n+\n+#######################################\n+# Methods and Functions (KEYWORD2)\n+#######################################\n+\n+attachScheduledInterrupt\tKEYWORD2\ndiff --git a/libraries/FunctionalInterrupt/library.properties b/libraries/FunctionalInterrupt/library.properties\nnew file mode 100644\nindex 0000000000..9738f1e971\n--- /dev/null\n+++ b/libraries/FunctionalInterrupt/library.properties\n@@ -0,0 +1,10 @@\n+name=FunctionalInterrupt\n+version=1.0\n+author=hreintke <hreintke@tauri.nl>\n+maintainer=hreintke <hreintke@tauri.nl>\n+sentence=C++ functional and scheduled interrupt handling\n+paragraph=\n+category=Other\n+url=https://github.com/esp8266/Arduino\n+architectures=esp8266\n+dot_a_linkage=true\ndiff --git a/libraries/FunctionalInterrupt/src/FunctionalInterrupt.cpp b/libraries/FunctionalInterrupt/src/FunctionalInterrupt.cpp\nnew file mode 100644\nindex 0000000000..030c5b171f\n--- /dev/null\n+++ b/libraries/FunctionalInterrupt/src/FunctionalInterrupt.cpp\n@@ -0,0 +1,36 @@\n+#include \"FunctionalInterrupt.h\"\n+#include <Schedule.h>\n+#include <Arduino.h>\n+\n+namespace\n+{\n+\n+    struct InterruptScheduleFunctionalArg\n+    {\n+        uint8_t pin;\n+        std::function<void(const InterruptInfo&)> scheduledIntRoutine;\n+    };\n+    struct ScheduleLambdaArg\n+    {\n+        std::function<void(const InterruptInfo&)> scheduledIntRoutine;\n+        InterruptInfo interruptInfo;\n+    };\n+\n+    void IRAM_ATTR interruptScheduleFunctional(const InterruptScheduleFunctionalArg& arg)\n+    {\n+        ScheduleLambdaArg lambdaArg{ arg.scheduledIntRoutine, { arg.pin } };\n+        lambdaArg.interruptInfo.value = digitalRead(arg.pin);\n+        lambdaArg.interruptInfo.micro = micros();\n+        schedule_function(std::bind(lambdaArg.scheduledIntRoutine, lambdaArg.interruptInfo));\n+    }\n+\n+}\n+\n+void attachScheduledInterrupt(uint8_t pin, const std::function<void(const InterruptInfo&)>& scheduledIntRoutine, int mode)\n+{\n+    if (scheduledIntRoutine)\n+    {\n+        InterruptScheduleFunctionalArg arg{ pin, scheduledIntRoutine };\n+        attachInterrupt(pin, std::bind(interruptScheduleFunctional, arg), mode);\n+    }\n+}\ndiff --git a/libraries/FunctionalInterrupt/src/FunctionalInterrupt.h b/libraries/FunctionalInterrupt/src/FunctionalInterrupt.h\nnew file mode 100644\nindex 0000000000..ca1d0e8b0c\n--- /dev/null\n+++ b/libraries/FunctionalInterrupt/src/FunctionalInterrupt.h\n@@ -0,0 +1,18 @@\n+#ifndef FUNCTIONALINTERRUPT_H\n+#define FUNCTIONALINTERRUPT_H\n+\n+#include <functional>\n+\n+// Structures for communication\n+\n+struct InterruptInfo\n+{\n+    InterruptInfo(uint8_t _pin) : pin(_pin) {}\n+    const uint8_t pin;\n+    uint8_t value = 0;\n+    uint32_t micro = 0;\n+};\n+\n+void attachScheduledInterrupt(uint8_t pin, const std::function<void(const InterruptInfo&)>& scheduledIntRoutine, int mode);\n+\n+#endif //FUNCTIONALINTERRUPT_H\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "- **Identified issues**: The interaction between IRAM and std::function features incomplete code and is unclear, particularly regarding ISR management. Ensure std::function and lambdas are explicitly marked as IRAM, especially for ISRs.\n\n- **Implementation suggestions**: For better API clarity, confirm that std::function<void(void)> is inlined or linker-optimized in IRAM as per issue #5922. Review performance changes in `core_esp8266_wiring_digital.cpp`, specifically `interrupt_handler(void*)`.\n\n- **Proposed next steps**: Verify the functionality of #6047 concerning handling ISRs and check the implementation of lambda captures. Address potential bugs from the performance patch. Test for \"missed cache interrupt\" interception for debugging purposes. \n\n- **Performance note**: Improvement observed in IRQ handling\u2014141,242 IRQs/s with the PR versus 136,239 IRQs/s in master."
      }
    ],
    "codediff_length": 28115
  },
  {
    "index": 43,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/boards.txt b/boards.txt\nindex 9c4af2f529..d32a47e85d 100644\n--- a/boards.txt\n+++ b/boards.txt\n@@ -64,10 +64,10 @@ generic.menu.ssl.all=All SSL ciphers (most compatible)\n generic.menu.ssl.all.build.sslflags=\n generic.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n generic.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+generic.menu.waveform.pwm=Locked PWM\n+generic.menu.waveform.pwm.build.waveform=\n generic.menu.waveform.phase=Locked Phase\n generic.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-generic.menu.waveform.pwm=Locked PWM\n-generic.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n generic.menu.ResetMethod.nodemcu=dtr (aka nodemcu)\n generic.menu.ResetMethod.nodemcu.upload.resetmethod=--before default_reset --after hard_reset\n generic.menu.ResetMethod.ck=no dtr (aka ck)\n@@ -537,10 +537,10 @@ esp8285.menu.ssl.all=All SSL ciphers (most compatible)\n esp8285.menu.ssl.all.build.sslflags=\n esp8285.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n esp8285.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+esp8285.menu.waveform.pwm=Locked PWM\n+esp8285.menu.waveform.pwm.build.waveform=\n esp8285.menu.waveform.phase=Locked Phase\n esp8285.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-esp8285.menu.waveform.pwm=Locked PWM\n-esp8285.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n esp8285.menu.ResetMethod.nodemcu=dtr (aka nodemcu)\n esp8285.menu.ResetMethod.nodemcu.upload.resetmethod=--before default_reset --after hard_reset\n esp8285.menu.ResetMethod.ck=no dtr (aka ck)\n@@ -880,10 +880,10 @@ gen4iod.menu.ssl.all=All SSL ciphers (most compatible)\n gen4iod.menu.ssl.all.build.sslflags=\n gen4iod.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n gen4iod.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+gen4iod.menu.waveform.pwm=Locked PWM\n+gen4iod.menu.waveform.pwm.build.waveform=\n gen4iod.menu.waveform.phase=Locked Phase\n gen4iod.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-gen4iod.menu.waveform.pwm=Locked PWM\n-gen4iod.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n gen4iod.upload.resetmethod=--before default_reset --after hard_reset\n gen4iod.menu.FlashMode.dout=DOUT (compatible)\n gen4iod.menu.FlashMode.dout.build.flash_mode=dout\n@@ -1138,10 +1138,10 @@ huzzah.menu.ssl.all=All SSL ciphers (most compatible)\n huzzah.menu.ssl.all.build.sslflags=\n huzzah.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n huzzah.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+huzzah.menu.waveform.pwm=Locked PWM\n+huzzah.menu.waveform.pwm.build.waveform=\n huzzah.menu.waveform.phase=Locked Phase\n huzzah.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-huzzah.menu.waveform.pwm=Locked PWM\n-huzzah.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n huzzah.upload.resetmethod=--before default_reset --after hard_reset\n huzzah.build.flash_mode=qio\n huzzah.build.flash_flags=-DFLASHMODE_QIO\n@@ -1329,10 +1329,10 @@ wifi_slot.menu.ssl.all=All SSL ciphers (most compatible)\n wifi_slot.menu.ssl.all.build.sslflags=\n wifi_slot.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n wifi_slot.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+wifi_slot.menu.waveform.pwm=Locked PWM\n+wifi_slot.menu.waveform.pwm.build.waveform=\n wifi_slot.menu.waveform.phase=Locked Phase\n wifi_slot.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-wifi_slot.menu.waveform.pwm=Locked PWM\n-wifi_slot.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n wifi_slot.upload.resetmethod=--before default_reset --after hard_reset\n wifi_slot.menu.FlashFreq.40=40MHz\n wifi_slot.menu.FlashFreq.40.build.flash_freq=40\n@@ -1646,10 +1646,10 @@ arduino-esp8266.menu.ssl.all=All SSL ciphers (most compatible)\n arduino-esp8266.menu.ssl.all.build.sslflags=\n arduino-esp8266.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n arduino-esp8266.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+arduino-esp8266.menu.waveform.pwm=Locked PWM\n+arduino-esp8266.menu.waveform.pwm.build.waveform=\n arduino-esp8266.menu.waveform.phase=Locked Phase\n arduino-esp8266.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-arduino-esp8266.menu.waveform.pwm=Locked PWM\n-arduino-esp8266.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n arduino-esp8266.upload.resetmethod=--before no_reset --after soft_reset\n arduino-esp8266.build.flash_mode=qio\n arduino-esp8266.build.flash_flags=-DFLASHMODE_QIO\n@@ -1838,10 +1838,10 @@ espmxdevkit.menu.ssl.all=All SSL ciphers (most compatible)\n espmxdevkit.menu.ssl.all.build.sslflags=\n espmxdevkit.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n espmxdevkit.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+espmxdevkit.menu.waveform.pwm=Locked PWM\n+espmxdevkit.menu.waveform.pwm.build.waveform=\n espmxdevkit.menu.waveform.phase=Locked Phase\n espmxdevkit.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-espmxdevkit.menu.waveform.pwm=Locked PWM\n-espmxdevkit.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n espmxdevkit.upload.resetmethod=--before default_reset --after hard_reset\n espmxdevkit.build.flash_mode=dout\n espmxdevkit.build.flash_flags=-DFLASHMODE_DOUT\n@@ -2070,10 +2070,10 @@ oak.menu.ssl.all=All SSL ciphers (most compatible)\n oak.menu.ssl.all.build.sslflags=\n oak.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n oak.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+oak.menu.waveform.pwm=Locked PWM\n+oak.menu.waveform.pwm.build.waveform=\n oak.menu.waveform.phase=Locked Phase\n oak.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-oak.menu.waveform.pwm=Locked PWM\n-oak.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n oak.upload.resetmethod=--before no_reset --after soft_reset\n oak.build.flash_mode=dio\n oak.build.flash_flags=-DFLASHMODE_DIO\n@@ -2270,10 +2270,10 @@ espduino.menu.ssl.all=All SSL ciphers (most compatible)\n espduino.menu.ssl.all.build.sslflags=\n espduino.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n espduino.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+espduino.menu.waveform.pwm=Locked PWM\n+espduino.menu.waveform.pwm.build.waveform=\n espduino.menu.waveform.phase=Locked Phase\n espduino.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-espduino.menu.waveform.pwm=Locked PWM\n-espduino.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n espduino.build.flash_mode=dio\n espduino.build.flash_flags=-DFLASHMODE_DIO\n espduino.build.flash_freq=40\n@@ -2460,10 +2460,10 @@ espectro.menu.ssl.all=All SSL ciphers (most compatible)\n espectro.menu.ssl.all.build.sslflags=\n espectro.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n espectro.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+espectro.menu.waveform.pwm=Locked PWM\n+espectro.menu.waveform.pwm.build.waveform=\n espectro.menu.waveform.phase=Locked Phase\n espectro.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-espectro.menu.waveform.pwm=Locked PWM\n-espectro.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n espectro.upload.resetmethod=--before default_reset --after hard_reset\n espectro.build.flash_mode=dio\n espectro.build.flash_flags=-DFLASHMODE_DIO\n@@ -2651,10 +2651,10 @@ espino.menu.ssl.all=All SSL ciphers (most compatible)\n espino.menu.ssl.all.build.sslflags=\n espino.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n espino.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+espino.menu.waveform.pwm=Locked PWM\n+espino.menu.waveform.pwm.build.waveform=\n espino.menu.waveform.phase=Locked Phase\n espino.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-espino.menu.waveform.pwm=Locked PWM\n-espino.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n espino.menu.ResetMethod.nodemcu=dtr (aka nodemcu)\n espino.menu.ResetMethod.nodemcu.upload.resetmethod=--before default_reset --after hard_reset\n espino.menu.ResetMethod.ck=no dtr (aka ck)\n@@ -2845,10 +2845,10 @@ espresso_lite_v1.menu.ssl.all=All SSL ciphers (most compatible)\n espresso_lite_v1.menu.ssl.all.build.sslflags=\n espresso_lite_v1.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n espresso_lite_v1.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+espresso_lite_v1.menu.waveform.pwm=Locked PWM\n+espresso_lite_v1.menu.waveform.pwm.build.waveform=\n espresso_lite_v1.menu.waveform.phase=Locked Phase\n espresso_lite_v1.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-espresso_lite_v1.menu.waveform.pwm=Locked PWM\n-espresso_lite_v1.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n espresso_lite_v1.build.flash_mode=dio\n espresso_lite_v1.build.flash_flags=-DFLASHMODE_DIO\n espresso_lite_v1.build.flash_freq=40\n@@ -3039,10 +3039,10 @@ espresso_lite_v2.menu.ssl.all=All SSL ciphers (most compatible)\n espresso_lite_v2.menu.ssl.all.build.sslflags=\n espresso_lite_v2.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n espresso_lite_v2.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+espresso_lite_v2.menu.waveform.pwm=Locked PWM\n+espresso_lite_v2.menu.waveform.pwm.build.waveform=\n espresso_lite_v2.menu.waveform.phase=Locked Phase\n espresso_lite_v2.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-espresso_lite_v2.menu.waveform.pwm=Locked PWM\n-espresso_lite_v2.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n espresso_lite_v2.build.flash_mode=dio\n espresso_lite_v2.build.flash_flags=-DFLASHMODE_DIO\n espresso_lite_v2.build.flash_freq=40\n@@ -3243,10 +3243,10 @@ sonoff.menu.ssl.all=All SSL ciphers (most compatible)\n sonoff.menu.ssl.all.build.sslflags=\n sonoff.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n sonoff.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+sonoff.menu.waveform.pwm=Locked PWM\n+sonoff.menu.waveform.pwm.build.waveform=\n sonoff.menu.waveform.phase=Locked Phase\n sonoff.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-sonoff.menu.waveform.pwm=Locked PWM\n-sonoff.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n sonoff.upload.resetmethod=--before no_reset --after soft_reset\n sonoff.build.flash_mode=dout\n sonoff.build.flash_flags=-DFLASHMODE_DOUT\n@@ -3474,10 +3474,10 @@ inventone.menu.ssl.all=All SSL ciphers (most compatible)\n inventone.menu.ssl.all.build.sslflags=\n inventone.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n inventone.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+inventone.menu.waveform.pwm=Locked PWM\n+inventone.menu.waveform.pwm.build.waveform=\n inventone.menu.waveform.phase=Locked Phase\n inventone.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-inventone.menu.waveform.pwm=Locked PWM\n-inventone.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n inventone.upload.resetmethod=--before default_reset --after hard_reset\n inventone.build.flash_mode=dio\n inventone.build.flash_flags=-DFLASHMODE_DIO\n@@ -3665,10 +3665,10 @@ d1_mini.menu.ssl.all=All SSL ciphers (most compatible)\n d1_mini.menu.ssl.all.build.sslflags=\n d1_mini.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n d1_mini.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+d1_mini.menu.waveform.pwm=Locked PWM\n+d1_mini.menu.waveform.pwm.build.waveform=\n d1_mini.menu.waveform.phase=Locked Phase\n d1_mini.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-d1_mini.menu.waveform.pwm=Locked PWM\n-d1_mini.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n d1_mini.upload.resetmethod=--before default_reset --after hard_reset\n d1_mini.build.flash_mode=dio\n d1_mini.build.flash_flags=-DFLASHMODE_DIO\n@@ -3856,10 +3856,10 @@ d1_mini_lite.menu.ssl.all=All SSL ciphers (most compatible)\n d1_mini_lite.menu.ssl.all.build.sslflags=\n d1_mini_lite.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n d1_mini_lite.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+d1_mini_lite.menu.waveform.pwm=Locked PWM\n+d1_mini_lite.menu.waveform.pwm.build.waveform=\n d1_mini_lite.menu.waveform.phase=Locked Phase\n d1_mini_lite.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-d1_mini_lite.menu.waveform.pwm=Locked PWM\n-d1_mini_lite.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n d1_mini_lite.upload.resetmethod=--before default_reset --after hard_reset\n d1_mini_lite.build.flash_mode=dout\n d1_mini_lite.build.flash_flags=-DFLASHMODE_DOUT\n@@ -4087,10 +4087,10 @@ d1_mini_pro.menu.ssl.all=All SSL ciphers (most compatible)\n d1_mini_pro.menu.ssl.all.build.sslflags=\n d1_mini_pro.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n d1_mini_pro.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+d1_mini_pro.menu.waveform.pwm=Locked PWM\n+d1_mini_pro.menu.waveform.pwm.build.waveform=\n d1_mini_pro.menu.waveform.phase=Locked Phase\n d1_mini_pro.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-d1_mini_pro.menu.waveform.pwm=Locked PWM\n-d1_mini_pro.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n d1_mini_pro.upload.resetmethod=--before default_reset --after hard_reset\n d1_mini_pro.build.flash_mode=dio\n d1_mini_pro.build.flash_flags=-DFLASHMODE_DIO\n@@ -4261,10 +4261,10 @@ d1.menu.ssl.all=All SSL ciphers (most compatible)\n d1.menu.ssl.all.build.sslflags=\n d1.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n d1.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+d1.menu.waveform.pwm=Locked PWM\n+d1.menu.waveform.pwm.build.waveform=\n d1.menu.waveform.phase=Locked Phase\n d1.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-d1.menu.waveform.pwm=Locked PWM\n-d1.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n d1.upload.resetmethod=--before default_reset --after hard_reset\n d1.build.flash_mode=dio\n d1.build.flash_flags=-DFLASHMODE_DIO\n@@ -4452,10 +4452,10 @@ nodemcu.menu.ssl.all=All SSL ciphers (most compatible)\n nodemcu.menu.ssl.all.build.sslflags=\n nodemcu.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n nodemcu.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+nodemcu.menu.waveform.pwm=Locked PWM\n+nodemcu.menu.waveform.pwm.build.waveform=\n nodemcu.menu.waveform.phase=Locked Phase\n nodemcu.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-nodemcu.menu.waveform.pwm=Locked PWM\n-nodemcu.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n nodemcu.upload.resetmethod=--before default_reset --after hard_reset\n nodemcu.build.flash_mode=qio\n nodemcu.build.flash_flags=-DFLASHMODE_QIO\n@@ -4643,10 +4643,10 @@ nodemcuv2.menu.ssl.all=All SSL ciphers (most compatible)\n nodemcuv2.menu.ssl.all.build.sslflags=\n nodemcuv2.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n nodemcuv2.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+nodemcuv2.menu.waveform.pwm=Locked PWM\n+nodemcuv2.menu.waveform.pwm.build.waveform=\n nodemcuv2.menu.waveform.phase=Locked Phase\n nodemcuv2.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-nodemcuv2.menu.waveform.pwm=Locked PWM\n-nodemcuv2.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n nodemcuv2.upload.resetmethod=--before default_reset --after hard_reset\n nodemcuv2.build.flash_mode=dio\n nodemcuv2.build.flash_flags=-DFLASHMODE_DIO\n@@ -4838,10 +4838,10 @@ modwifi.menu.ssl.all=All SSL ciphers (most compatible)\n modwifi.menu.ssl.all.build.sslflags=\n modwifi.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n modwifi.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+modwifi.menu.waveform.pwm=Locked PWM\n+modwifi.menu.waveform.pwm.build.waveform=\n modwifi.menu.waveform.phase=Locked Phase\n modwifi.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-modwifi.menu.waveform.pwm=Locked PWM\n-modwifi.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n modwifi.upload.resetmethod=--before no_reset --after soft_reset\n modwifi.build.flash_mode=qio\n modwifi.build.flash_flags=-DFLASHMODE_QIO\n@@ -5049,10 +5049,10 @@ phoenix_v1.menu.ssl.all=All SSL ciphers (most compatible)\n phoenix_v1.menu.ssl.all.build.sslflags=\n phoenix_v1.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n phoenix_v1.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+phoenix_v1.menu.waveform.pwm=Locked PWM\n+phoenix_v1.menu.waveform.pwm.build.waveform=\n phoenix_v1.menu.waveform.phase=Locked Phase\n phoenix_v1.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-phoenix_v1.menu.waveform.pwm=Locked PWM\n-phoenix_v1.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n phoenix_v1.build.flash_mode=dio\n phoenix_v1.build.flash_flags=-DFLASHMODE_DIO\n phoenix_v1.build.flash_freq=40\n@@ -5243,10 +5243,10 @@ phoenix_v2.menu.ssl.all=All SSL ciphers (most compatible)\n phoenix_v2.menu.ssl.all.build.sslflags=\n phoenix_v2.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n phoenix_v2.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+phoenix_v2.menu.waveform.pwm=Locked PWM\n+phoenix_v2.menu.waveform.pwm.build.waveform=\n phoenix_v2.menu.waveform.phase=Locked Phase\n phoenix_v2.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-phoenix_v2.menu.waveform.pwm=Locked PWM\n-phoenix_v2.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n phoenix_v2.build.flash_mode=dio\n phoenix_v2.build.flash_flags=-DFLASHMODE_DIO\n phoenix_v2.build.flash_freq=40\n@@ -5437,10 +5437,10 @@ eduinowifi.menu.ssl.all=All SSL ciphers (most compatible)\n eduinowifi.menu.ssl.all.build.sslflags=\n eduinowifi.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n eduinowifi.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+eduinowifi.menu.waveform.pwm=Locked PWM\n+eduinowifi.menu.waveform.pwm.build.waveform=\n eduinowifi.menu.waveform.phase=Locked Phase\n eduinowifi.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-eduinowifi.menu.waveform.pwm=Locked PWM\n-eduinowifi.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n eduinowifi.upload.resetmethod=--before default_reset --after hard_reset\n eduinowifi.build.flash_mode=dio\n eduinowifi.build.flash_flags=-DFLASHMODE_DIO\n@@ -5628,10 +5628,10 @@ wiolink.menu.ssl.all=All SSL ciphers (most compatible)\n wiolink.menu.ssl.all.build.sslflags=\n wiolink.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n wiolink.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+wiolink.menu.waveform.pwm=Locked PWM\n+wiolink.menu.waveform.pwm.build.waveform=\n wiolink.menu.waveform.phase=Locked Phase\n wiolink.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-wiolink.menu.waveform.pwm=Locked PWM\n-wiolink.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n wiolink.upload.resetmethod=--before default_reset --after hard_reset\n wiolink.build.flash_mode=qio\n wiolink.build.flash_flags=-DFLASHMODE_QIO\n@@ -5819,10 +5819,10 @@ blynk.menu.ssl.all=All SSL ciphers (most compatible)\n blynk.menu.ssl.all.build.sslflags=\n blynk.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n blynk.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+blynk.menu.waveform.pwm=Locked PWM\n+blynk.menu.waveform.pwm.build.waveform=\n blynk.menu.waveform.phase=Locked Phase\n blynk.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-blynk.menu.waveform.pwm=Locked PWM\n-blynk.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n blynk.upload.resetmethod=--before default_reset --after hard_reset\n blynk.build.flash_mode=qio\n blynk.build.flash_flags=-DFLASHMODE_QIO\n@@ -6010,10 +6010,10 @@ thing.menu.ssl.all=All SSL ciphers (most compatible)\n thing.menu.ssl.all.build.sslflags=\n thing.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n thing.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+thing.menu.waveform.pwm=Locked PWM\n+thing.menu.waveform.pwm.build.waveform=\n thing.menu.waveform.phase=Locked Phase\n thing.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-thing.menu.waveform.pwm=Locked PWM\n-thing.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n thing.upload.resetmethod=--before no_reset --after soft_reset\n thing.build.flash_mode=qio\n thing.build.flash_flags=-DFLASHMODE_QIO\n@@ -6201,10 +6201,10 @@ thingdev.menu.ssl.all=All SSL ciphers (most compatible)\n thingdev.menu.ssl.all.build.sslflags=\n thingdev.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n thingdev.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+thingdev.menu.waveform.pwm=Locked PWM\n+thingdev.menu.waveform.pwm.build.waveform=\n thingdev.menu.waveform.phase=Locked Phase\n thingdev.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-thingdev.menu.waveform.pwm=Locked PWM\n-thingdev.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n thingdev.upload.resetmethod=--before default_reset --after hard_reset\n thingdev.build.flash_mode=dio\n thingdev.build.flash_flags=-DFLASHMODE_DIO\n@@ -6392,10 +6392,10 @@ esp210.menu.ssl.all=All SSL ciphers (most compatible)\n esp210.menu.ssl.all.build.sslflags=\n esp210.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n esp210.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+esp210.menu.waveform.pwm=Locked PWM\n+esp210.menu.waveform.pwm.build.waveform=\n esp210.menu.waveform.phase=Locked Phase\n esp210.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-esp210.menu.waveform.pwm=Locked PWM\n-esp210.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n esp210.upload.resetmethod=--before no_reset --after soft_reset\n esp210.build.flash_mode=qio\n esp210.build.flash_flags=-DFLASHMODE_QIO\n@@ -6583,10 +6583,10 @@ espinotee.menu.ssl.all=All SSL ciphers (most compatible)\n espinotee.menu.ssl.all.build.sslflags=\n espinotee.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n espinotee.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+espinotee.menu.waveform.pwm=Locked PWM\n+espinotee.menu.waveform.pwm.build.waveform=\n espinotee.menu.waveform.phase=Locked Phase\n espinotee.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-espinotee.menu.waveform.pwm=Locked PWM\n-espinotee.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n espinotee.upload.resetmethod=--before default_reset --after hard_reset\n espinotee.build.flash_mode=qio\n espinotee.build.flash_flags=-DFLASHMODE_QIO\n@@ -6774,10 +6774,10 @@ wifiduino.menu.ssl.all=All SSL ciphers (most compatible)\n wifiduino.menu.ssl.all.build.sslflags=\n wifiduino.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n wifiduino.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+wifiduino.menu.waveform.pwm=Locked PWM\n+wifiduino.menu.waveform.pwm.build.waveform=\n wifiduino.menu.waveform.phase=Locked Phase\n wifiduino.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-wifiduino.menu.waveform.pwm=Locked PWM\n-wifiduino.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n wifiduino.upload.resetmethod=--before default_reset --after hard_reset\n wifiduino.build.flash_mode=dio\n wifiduino.build.flash_flags=-DFLASHMODE_DIO\n@@ -6982,10 +6982,10 @@ wifinfo.menu.ssl.all=All SSL ciphers (most compatible)\n wifinfo.menu.ssl.all.build.sslflags=\n wifinfo.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n wifinfo.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+wifinfo.menu.waveform.pwm=Locked PWM\n+wifinfo.menu.waveform.pwm.build.waveform=\n wifinfo.menu.waveform.phase=Locked Phase\n wifinfo.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-wifinfo.menu.waveform.pwm=Locked PWM\n-wifinfo.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n wifinfo.upload.resetmethod=--before default_reset --after hard_reset\n wifinfo.build.flash_mode=qio\n wifinfo.build.flash_flags=-DFLASHMODE_QIO\n@@ -7220,10 +7220,10 @@ cw01.menu.ssl.all=All SSL ciphers (most compatible)\n cw01.menu.ssl.all.build.sslflags=\n cw01.menu.ssl.basic=Basic SSL ciphers (lower ROM use)\n cw01.menu.ssl.basic.build.sslflags=-DBEARSSL_SSL_BASIC\n+cw01.menu.waveform.pwm=Locked PWM\n+cw01.menu.waveform.pwm.build.waveform=\n cw01.menu.waveform.phase=Locked Phase\n cw01.menu.waveform.phase.build.waveform=-DWAVEFORM_LOCKED_PHASE\n-cw01.menu.waveform.pwm=Locked PWM\n-cw01.menu.waveform.pwm.build.waveform=-DWAVEFORM_LOCKED_PWM\n cw01.upload.resetmethod=--before default_reset --after hard_reset\n cw01.menu.CrystalFreq.26=26 MHz\n cw01.menu.CrystalFreq.40=40 MHz\ndiff --git a/cores/esp8266/Tone.cpp b/cores/esp8266/Tone.cpp\nindex 601b1df51d..8deeb63d09 100644\n--- a/cores/esp8266/Tone.cpp\n+++ b/cores/esp8266/Tone.cpp\n@@ -30,6 +30,13 @@ static void _startTone(uint8_t _pin, uint32_t high, uint32_t low, uint32_t durat\n     return;\n   }\n \n+#ifndef WAVEFORM_LOCKED_PHASE\n+  // Stop any analogWrites (PWM) because they are a different generator\n+  _stopPWM(_pin);\n+#endif\n+  // If there's another Tone or startWaveform on this pin\n+  // it will be changed on-the-fly (no need to stop it)\n+\n   pinMode(_pin, OUTPUT);\n \n   high = std::max(high, (uint32_t)microsecondsToClockCycles(25));  // new 20KHz maximum tone frequency,\ndiff --git a/cores/esp8266/core_esp8266_waveform.h b/cores/esp8266/core_esp8266_waveform.h\nindex e24819a65d..4c5ce4fedb 100644\n--- a/cores/esp8266/core_esp8266_waveform.h\n+++ b/cores/esp8266/core_esp8266_waveform.h\n@@ -1,93 +1,7 @@\n-/*\n-  esp8266_waveform - General purpose waveform generation and control,\n-                     supporting outputs on all pins in parallel.\n-\n-  Copyright (c) 2018 Earle F. Philhower, III.  All rights reserved.\n-  Copyright (c) 2020 Dirk O. Kaar.\n-\n-  The core idea is to have a programmable waveform generator with a unique\n-  high and low period (defined in microseconds or CPU clock cycles).  TIMER1 is\n-  set to 1-shot mode and is always loaded with the time until the next edge\n-  of any live waveforms.\n-\n-  Up to one waveform generator per pin supported.\n-\n-  Each waveform generator is synchronized to the ESP clock cycle counter, not the\n-  timer.  This allows for removing interrupt jitter and delay as the counter\n-  always increments once per 80MHz clock.  Changes to a waveform are\n-  contiguous and only take effect on the next waveform transition,\n-  allowing for smooth transitions.\n-\n-  This replaces older tone(), analogWrite(), and the Servo classes.\n-\n-  Everywhere in the code where \"ccy\" or \"ccys\" is used, it means ESP.getCycleCount()\n-  clock cycle count, or an interval measured in CPU clock cycles, but not TIMER1\n-  cycles (which may be 2 CPU clock cycles @ 160MHz).\n-\n-  This library is free software; you can redistribute it and/or\n-  modify it under the terms of the GNU Lesser General Public\n-  License as published by the Free Software Foundation; either\n-  version 2.1 of the License, or (at your option) any later version.\n-\n-  This library is distributed in the hope that it will be useful,\n-  but WITHOUT ANY WARRANTY; without even the implied warranty of\n-  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n-  Lesser General Public License for more details.\n-\n-  You should have received a copy of the GNU Lesser General Public\n-  License along with this library; if not, write to the Free Software\n-  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n-*/\n+// Wrapper to include both versions of the waveform generator\n \n #ifdef WAVEFORM_LOCKED_PHASE\n-\n-#include <Arduino.h>\n-\n-#ifndef __ESP8266_WAVEFORM_H\n-#define __ESP8266_WAVEFORM_H\n-\n-#ifdef __cplusplus\n-extern \"C\" {\n+    #include \"core_esp8266_waveform_phase.h\"\n+#else\n+    #include \"core_esp8266_waveform_pwm.h\"\n #endif\n-\n-// Start or change a waveform of the specified high and low times on specific pin.\n-// If runtimeUS > 0 then automatically stop it after that many usecs, relative to the next\n-// full period.\n-// If waveform is not yet started on pin, and on pin == alignPhase a waveform is running,\n-// the new waveform is started at phaseOffsetUS phase offset, in microseconds, to that.\n-// Setting autoPwm to true allows the wave generator to maintain PWM duty to idle cycle ratio\n-// under load, for applications where frequency or duty cycle must not change, leave false.\n-// Returns true or false on success or failure.\n-int startWaveform(uint8_t pin, uint32_t timeHighUS, uint32_t timeLowUS,\n-  uint32_t runTimeUS = 0, int8_t alignPhase = -1, uint32_t phaseOffsetUS = 0, bool autoPwm = false);\n-// Start or change a waveform of the specified high and low CPU clock cycles on specific pin.\n-// If runtimeCycles > 0 then automatically stop it after that many CPU clock cycles, relative to the next\n-// full period.\n-// If waveform is not yet started on pin, and on pin == alignPhase a waveform is running,\n-// the new waveform is started at phaseOffsetCcys phase offset, in CPU clock cycles, to that.\n-// Setting autoPwm to true allows the wave generator to maintain PWM duty to idle cycle ratio\n-// under load, for applications where frequency or duty cycle must not change, leave false.\n-// Returns true or false on success or failure.\n-int startWaveformClockCycles(uint8_t pin, uint32_t timeHighCcys, uint32_t timeLowCcys,\n-  uint32_t runTimeCcys = 0, int8_t alignPhase = -1, uint32_t phaseOffsetCcys = 0, bool autoPwm = false);\n-// Stop a waveform, if any, on the specified pin.\n-// Returns true or false on success or failure.\n-int stopWaveform(uint8_t pin);\n-\n-// Add a callback function to be called on *EVERY* timer1 trigger.  The\n-// callback returns the number of microseconds until the next desired call.\n-// However, since it is called every timer1 interrupt, it may be called\n-// again before this period.  It should therefore use the ESP Cycle Counter\n-// to determine whether or not to perform an operation.\n-// Pass in NULL to disable the callback and, if no other waveforms being\n-// generated, stop the timer as well.\n-// Make sure the CB function has the ICACHE_RAM_ATTR decorator.\n-void setTimer1Callback(uint32_t (*fn)());\n-\n-#ifdef __cplusplus\n-}\n-#endif\n-\n-#endif // __ESP8266_WAVEFORM_H\n-\n-#endif // WAVEFORM_LOCKED_PHASE\ndiff --git a/cores/esp8266/core_esp8266_waveform.cpp b/cores/esp8266/core_esp8266_waveform_phase.cpp\nsimilarity index 99%\nrename from cores/esp8266/core_esp8266_waveform.cpp\nrename to cores/esp8266/core_esp8266_waveform_phase.cpp\nindex 4bd0f1c013..62e3ad3dd5 100644\n--- a/cores/esp8266/core_esp8266_waveform.cpp\n+++ b/cores/esp8266/core_esp8266_waveform_phase.cpp\n@@ -41,7 +41,7 @@\n \n #ifdef WAVEFORM_LOCKED_PHASE\n \n-#include \"core_esp8266_waveform.h\"\n+#include \"core_esp8266_waveform_phase.h\"\n #include <Arduino.h>\n #include \"ets_sys.h\"\n #include <atomic>\ndiff --git a/cores/esp8266/core_esp8266_waveform_phase.h b/cores/esp8266/core_esp8266_waveform_phase.h\nnew file mode 100644\nindex 0000000000..e24819a65d\n--- /dev/null\n+++ b/cores/esp8266/core_esp8266_waveform_phase.h\n@@ -0,0 +1,93 @@\n+/*\n+  esp8266_waveform - General purpose waveform generation and control,\n+                     supporting outputs on all pins in parallel.\n+\n+  Copyright (c) 2018 Earle F. Philhower, III.  All rights reserved.\n+  Copyright (c) 2020 Dirk O. Kaar.\n+\n+  The core idea is to have a programmable waveform generator with a unique\n+  high and low period (defined in microseconds or CPU clock cycles).  TIMER1 is\n+  set to 1-shot mode and is always loaded with the time until the next edge\n+  of any live waveforms.\n+\n+  Up to one waveform generator per pin supported.\n+\n+  Each waveform generator is synchronized to the ESP clock cycle counter, not the\n+  timer.  This allows for removing interrupt jitter and delay as the counter\n+  always increments once per 80MHz clock.  Changes to a waveform are\n+  contiguous and only take effect on the next waveform transition,\n+  allowing for smooth transitions.\n+\n+  This replaces older tone(), analogWrite(), and the Servo classes.\n+\n+  Everywhere in the code where \"ccy\" or \"ccys\" is used, it means ESP.getCycleCount()\n+  clock cycle count, or an interval measured in CPU clock cycles, but not TIMER1\n+  cycles (which may be 2 CPU clock cycles @ 160MHz).\n+\n+  This library is free software; you can redistribute it and/or\n+  modify it under the terms of the GNU Lesser General Public\n+  License as published by the Free Software Foundation; either\n+  version 2.1 of the License, or (at your option) any later version.\n+\n+  This library is distributed in the hope that it will be useful,\n+  but WITHOUT ANY WARRANTY; without even the implied warranty of\n+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+  Lesser General Public License for more details.\n+\n+  You should have received a copy of the GNU Lesser General Public\n+  License along with this library; if not, write to the Free Software\n+  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n+*/\n+\n+#ifdef WAVEFORM_LOCKED_PHASE\n+\n+#include <Arduino.h>\n+\n+#ifndef __ESP8266_WAVEFORM_H\n+#define __ESP8266_WAVEFORM_H\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+// Start or change a waveform of the specified high and low times on specific pin.\n+// If runtimeUS > 0 then automatically stop it after that many usecs, relative to the next\n+// full period.\n+// If waveform is not yet started on pin, and on pin == alignPhase a waveform is running,\n+// the new waveform is started at phaseOffsetUS phase offset, in microseconds, to that.\n+// Setting autoPwm to true allows the wave generator to maintain PWM duty to idle cycle ratio\n+// under load, for applications where frequency or duty cycle must not change, leave false.\n+// Returns true or false on success or failure.\n+int startWaveform(uint8_t pin, uint32_t timeHighUS, uint32_t timeLowUS,\n+  uint32_t runTimeUS = 0, int8_t alignPhase = -1, uint32_t phaseOffsetUS = 0, bool autoPwm = false);\n+// Start or change a waveform of the specified high and low CPU clock cycles on specific pin.\n+// If runtimeCycles > 0 then automatically stop it after that many CPU clock cycles, relative to the next\n+// full period.\n+// If waveform is not yet started on pin, and on pin == alignPhase a waveform is running,\n+// the new waveform is started at phaseOffsetCcys phase offset, in CPU clock cycles, to that.\n+// Setting autoPwm to true allows the wave generator to maintain PWM duty to idle cycle ratio\n+// under load, for applications where frequency or duty cycle must not change, leave false.\n+// Returns true or false on success or failure.\n+int startWaveformClockCycles(uint8_t pin, uint32_t timeHighCcys, uint32_t timeLowCcys,\n+  uint32_t runTimeCcys = 0, int8_t alignPhase = -1, uint32_t phaseOffsetCcys = 0, bool autoPwm = false);\n+// Stop a waveform, if any, on the specified pin.\n+// Returns true or false on success or failure.\n+int stopWaveform(uint8_t pin);\n+\n+// Add a callback function to be called on *EVERY* timer1 trigger.  The\n+// callback returns the number of microseconds until the next desired call.\n+// However, since it is called every timer1 interrupt, it may be called\n+// again before this period.  It should therefore use the ESP Cycle Counter\n+// to determine whether or not to perform an operation.\n+// Pass in NULL to disable the callback and, if no other waveforms being\n+// generated, stop the timer as well.\n+// Make sure the CB function has the ICACHE_RAM_ATTR decorator.\n+void setTimer1Callback(uint32_t (*fn)());\n+\n+#ifdef __cplusplus\n+}\n+#endif\n+\n+#endif // __ESP8266_WAVEFORM_H\n+\n+#endif // WAVEFORM_LOCKED_PHASE\ndiff --git a/cores/esp8266/core_esp8266_waveform_pwm.cpp b/cores/esp8266/core_esp8266_waveform_pwm.cpp\nnew file mode 100644\nindex 0000000000..aea88e15b9\n--- /dev/null\n+++ b/cores/esp8266/core_esp8266_waveform_pwm.cpp\n@@ -0,0 +1,626 @@\n+/*\n+  esp8266_waveform - General purpose waveform generation and control,\n+                     supporting outputs on all pins in parallel.\n+\n+  Copyright (c) 2018 Earle F. Philhower, III.  All rights reserved.\n+\n+  The core idea is to have a programmable waveform generator with a unique\n+  high and low period (defined in microseconds or CPU clock cycles).  TIMER1\n+  is set to 1-shot mode and is always loaded with the time until the next\n+  edge of any live waveforms.\n+\n+  Up to one waveform generator per pin supported.\n+\n+  Each waveform generator is synchronized to the ESP clock cycle counter, not\n+  the timer.  This allows for removing interrupt jitter and delay as the\n+  counter always increments once per 80MHz clock.  Changes to a waveform are\n+  contiguous and only take effect on the next waveform transition,\n+  allowing for smooth transitions.\n+\n+  This replaces older tone(), analogWrite(), and the Servo classes.\n+\n+  Everywhere in the code where \"cycles\" is used, it means ESP.getCycleCount()\n+  clock cycle count, or an interval measured in CPU clock cycles, but not\n+  TIMER1 cycles (which may be 2 CPU clock cycles @ 160MHz).\n+\n+  This library is free software; you can redistribute it and/or\n+  modify it under the terms of the GNU Lesser General Public\n+  License as published by the Free Software Foundation; either\n+  version 2.1 of the License, or (at your option) any later version.\n+\n+  This library is distributed in the hope that it will be useful,\n+  but WITHOUT ANY WARRANTY; without even the implied warranty of\n+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+  Lesser General Public License for more details.\n+\n+  You should have received a copy of the GNU Lesser General Public\n+  License along with this library; if not, write to the Free Software\n+  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n+*/\n+\n+#ifndef WAVEFORM_LOCKED_PHASE\n+\n+#include <Arduino.h>\n+#include \"ets_sys.h\"\n+#include \"core_esp8266_waveform_pwm.h\"\n+#include \"user_interface.h\"\n+extern \"C\" {\n+\n+// Maximum delay between IRQs\n+#define MAXIRQUS (10000)\n+\n+// Waveform generator can create tones, PWM, and servos\n+typedef struct {\n+  uint32_t nextServiceCycle;   // ESP cycle timer when a transition required\n+  uint32_t expiryCycle;        // For time-limited waveform, the cycle when this waveform must stop\n+  uint32_t timeHighCycles;     // Actual running waveform period (adjusted using desiredCycles)\n+  uint32_t timeLowCycles;      //\n+  uint32_t desiredHighCycles;  // Ideal waveform period to drive the error signal\n+  uint32_t desiredLowCycles;   //\n+  uint32_t lastEdge;           // Cycle when this generator last changed\n+} Waveform;\n+\n+class WVFState {\n+public:\n+  Waveform waveform[17];        // State of all possible pins\n+  uint32_t waveformState = 0;   // Is the pin high or low, updated in NMI so no access outside the NMI code\n+  uint32_t waveformEnabled = 0; // Is it actively running, updated in NMI so no access outside the NMI code\n+\n+  // Enable lock-free by only allowing updates to waveformState and waveformEnabled from IRQ service routine\n+  uint32_t waveformToEnable = 0;  // Message to the NMI handler to start a waveform on a inactive pin\n+  uint32_t waveformToDisable = 0; // Message to the NMI handler to disable a pin from waveform generation\n+\n+  uint32_t waveformToChange = 0; // Mask of pin to change. One bit set in main app, cleared when effected in the NMI\n+  uint32_t waveformNewHigh = 0;\n+  uint32_t waveformNewLow = 0;\n+\n+  uint32_t (*timer1CB)() = NULL;\n+\n+  // Optimize the NMI inner loop by keeping track of the min and max GPIO that we\n+  // are generating.  In the common case (1 PWM) these may be the same pin and\n+  // we can avoid looking at the other pins.\n+  uint16_t startPin = 0;\n+  uint16_t endPin = 0;\n+};\n+static WVFState wvfState;\n+\n+\n+// Ensure everything is read/written to RAM\n+#define MEMBARRIER() { __asm__ volatile(\"\" ::: \"memory\"); }\n+\n+// Non-speed critical bits\n+#pragma GCC optimize (\"Os\")\n+\n+// Interrupt on/off control\n+static ICACHE_RAM_ATTR void timer1Interrupt();\n+static bool timerRunning = false;\n+\n+static __attribute__((noinline)) void initTimer() {\n+  if (!timerRunning) {\n+    timer1_disable();\n+    ETS_FRC_TIMER1_INTR_ATTACH(NULL, NULL);\n+    ETS_FRC_TIMER1_NMI_INTR_ATTACH(timer1Interrupt);\n+    timer1_enable(TIM_DIV1, TIM_EDGE, TIM_SINGLE);\n+    timerRunning = true;\n+    timer1_write(microsecondsToClockCycles(10));\n+  }\n+}\n+\n+static ICACHE_RAM_ATTR void forceTimerInterrupt() {\n+  if (T1L > microsecondsToClockCycles(10)) {\n+    T1L = microsecondsToClockCycles(10);\n+  }\n+}\n+\n+// PWM implementation using special purpose state machine\n+//\n+// Keep an ordered list of pins with the delta in cycles between each\n+// element, with a terminal entry making up the remainder of the PWM\n+// period.  With this method sum(all deltas) == PWM period clock cycles.\n+//\n+// At t=0 set all pins high and set the timeout for the 1st edge.\n+// On interrupt, if we're at the last element reset to t=0 state\n+// Otherwise, clear that pin down and set delay for next element\n+// and so forth.\n+\n+constexpr int maxPWMs = 8;\n+\n+// PWM machine state\n+typedef struct PWMState {\n+  uint32_t mask; // Bitmask of active pins\n+  uint32_t cnt;  // How many entries\n+  uint32_t idx;  // Where the state machine is along the list\n+  uint8_t  pin[maxPWMs + 1];\n+  uint32_t delta[maxPWMs + 1];\n+  uint32_t nextServiceCycle;  // Clock cycle for next step\n+  struct PWMState *pwmUpdate; // Set by main code, cleared by ISR\n+} PWMState;\n+\n+static PWMState pwmState;\n+static uint32_t _pwmFreq = 1000;\n+static uint32_t _pwmPeriod = microsecondsToClockCycles(1000000UL) / _pwmFreq;\n+\n+\n+// If there are no more scheduled activities, shut down Timer 1.\n+// Otherwise, do nothing.\n+static ICACHE_RAM_ATTR void disableIdleTimer() {\n+ if (timerRunning && !wvfState.waveformEnabled && !pwmState.cnt && !wvfState.timer1CB) {\n+    ETS_FRC_TIMER1_NMI_INTR_ATTACH(NULL);\n+    timer1_disable();\n+    timer1_isr_init();\n+    timerRunning = false;\n+  }\n+}\n+\n+// Notify the NMI that a new PWM state is available through the mailbox.\n+// Wait for mailbox to be emptied (either busy or delay() as needed)\n+static ICACHE_RAM_ATTR void _notifyPWM(PWMState *p, bool idle) {\n+  p->pwmUpdate = nullptr;\n+  pwmState.pwmUpdate = p;\n+  MEMBARRIER();\n+  forceTimerInterrupt();\n+  while (pwmState.pwmUpdate) {\n+    if (idle) {\n+      delay(0);\n+    }\n+    MEMBARRIER();\n+  }\n+}\n+\n+static void _addPWMtoList(PWMState &p, int pin, uint32_t val, uint32_t range);\n+\n+// Called when analogWriteFreq() changed to update the PWM total period\n+void _setPWMFreq(uint32_t freq) {\n+  _pwmFreq = freq;\n+\n+  // Convert frequency into clock cycles\n+  uint32_t cc = microsecondsToClockCycles(1000000UL) / freq;\n+\n+  // Simple static adjustment to bring period closer to requested due to overhead\n+  // Empirically determined as a constant PWM delay and a function of the number of PWMs\n+#if F_CPU == 80000000\n+  cc -= ((microsecondsToClockCycles(pwmState.cnt) * 13) >> 4) + 110;\n+#else\n+  cc -= ((microsecondsToClockCycles(pwmState.cnt) * 10) >> 4) + 75;\n+#endif\n+\n+  if (cc == _pwmPeriod) {\n+    return; // No change\n+  }\n+\n+  _pwmPeriod = cc;\n+\n+  if (pwmState.cnt) {\n+    PWMState p;  // The working copy since we can't edit the one in use\n+    p.mask = 0;\n+    p.cnt = 0;\n+    for (uint32_t i = 0; i < pwmState.cnt; i++) {\n+      auto pin = pwmState.pin[i];\n+      _addPWMtoList(p, pin, wvfState.waveform[pin].desiredHighCycles, wvfState.waveform[pin].desiredLowCycles);\n+    }\n+    // Update and wait for mailbox to be emptied\n+    initTimer();\n+    _notifyPWM(&p, true);\n+    disableIdleTimer();\n+  }\n+}\n+\n+// Helper routine to remove an entry from the state machine\n+// and clean up any marked-off entries\n+static void _cleanAndRemovePWM(PWMState *p, int pin) {\n+  uint32_t leftover = 0;\n+  uint32_t in, out;\n+  for (in = 0, out = 0; in < p->cnt; in++) {\n+    if ((p->pin[in] != pin) && (p->mask & (1<<p->pin[in]))) {\n+        p->pin[out] = p->pin[in];\n+        p->delta[out] = p->delta[in] + leftover;\n+        leftover = 0;\n+        out++;\n+    } else {\n+        leftover += p->delta[in];\n+        p->mask &= ~(1<<p->pin[in]);\n+    }\n+  }\n+  p->cnt = out;\n+  // Final pin is never used: p->pin[out] = 0xff;\n+  p->delta[out] = p->delta[in] + leftover;\n+}\n+\n+\n+// Disable PWM on a specific pin (i.e. when a digitalWrite or analogWrite(0%/100%))\n+ICACHE_RAM_ATTR bool _stopPWM(int pin) {\n+  if (!((1<<pin) & pwmState.mask)) {\n+    return false; // Pin not actually active\n+  }\n+\n+  PWMState p;  // The working copy since we can't edit the one in use\n+  p = pwmState;\n+\n+  // In _stopPWM we just clear the mask but keep everything else\n+  // untouched to save IRAM.  The main startPWM will handle cleanup.\n+  p.mask &= ~(1<<pin);\n+  if (!p.mask) {\n+    // If all have been stopped, then turn PWM off completely\n+    p.cnt = 0;\n+  }\n+\n+  // Update and wait for mailbox to be emptied, no delay (could be in ISR)\n+  _notifyPWM(&p, false);\n+  // Possibly shut down the timer completely if we're done\n+  disableIdleTimer();\n+  return true;\n+}\n+\n+static void _addPWMtoList(PWMState &p, int pin, uint32_t val, uint32_t range) {\n+  // Stash the val and range so we can re-evaluate the fraction\n+  // should the user change PWM frequency.  This allows us to\n+  // give as great a precision as possible.  We know by construction\n+  // that the waveform for this pin will be inactive so we can borrow\n+  // memory from that structure.\n+  wvfState.waveform[pin].desiredHighCycles = val;  // Numerator == high\n+  wvfState.waveform[pin].desiredLowCycles = range; // Denominator == low\n+\n+  uint32_t cc = (_pwmPeriod * val) / range;\n+\n+  // Clip to sane values in the case we go from OK to not-OK when adjusting frequencies\n+  if (cc == 0) {\n+    cc = 1;\n+  } else if (cc >= _pwmPeriod) {\n+    cc = _pwmPeriod - 1;\n+  }\n+\n+  if (p.cnt == 0) {\n+    // Starting up from scratch, special case 1st element and PWM period\n+    p.pin[0] = pin;\n+    p.delta[0] = cc;\n+   // Final pin is never used: p.pin[1] = 0xff;\n+    p.delta[1] = _pwmPeriod - cc;\n+  } else {\n+    uint32_t ttl = 0;\n+    uint32_t i;\n+    // Skip along until we're at the spot to insert\n+    for (i=0; (i <= p.cnt) && (ttl + p.delta[i] < cc); i++) {\n+      ttl += p.delta[i];\n+    }\n+    // Shift everything out by one to make space for new edge\n+    for (int32_t j = p.cnt; j >= (int)i; j--) {\n+      p.pin[j + 1] = p.pin[j];\n+      p.delta[j + 1] = p.delta[j];\n+    }\n+    int off = cc - ttl; // The delta from the last edge to the one we're inserting\n+    p.pin[i] = pin;\n+    p.delta[i] = off; // Add the delta to this new pin\n+    p.delta[i + 1] -= off; // And subtract it from the follower to keep sum(deltas) constant\n+  }\n+  p.cnt++;\n+  p.mask |= 1<<pin;\n+}\n+\n+// Called by analogWrite(1...99%) to set the PWM duty in clock cycles\n+bool _setPWM(int pin, uint32_t val, uint32_t range) {\n+  stopWaveform(pin);\n+  PWMState p;  // Working copy\n+  p = pwmState;\n+  // Get rid of any entries for this pin\n+  _cleanAndRemovePWM(&p, pin);\n+  // And add it to the list, in order\n+  if (p.cnt >= maxPWMs) {\n+    return false; // No space left\n+  }\n+\n+  // Sanity check for all-on/off\n+  uint32_t cc = (_pwmPeriod * val) / range;\n+  if ((cc == 0) || (cc >= _pwmPeriod)) {\n+    digitalWrite(pin, cc ? HIGH : LOW);\n+    return true;\n+  }\n+\n+  _addPWMtoList(p, pin, val, range);\n+\n+  // Set mailbox and wait for ISR to copy it over\n+  initTimer();\n+  _notifyPWM(&p, true);\n+  disableIdleTimer();\n+\n+  // Potentially recalculate the PWM period if we've added another pin\n+  _setPWMFreq(_pwmFreq);\n+\n+  return true;\n+}\n+\n+// Start up a waveform on a pin, or change the current one.  Will change to the new\n+// waveform smoothly on next low->high transition.  For immediate change, stopWaveform()\n+// first, then it will immediately begin.\n+int startWaveform(uint8_t pin, uint32_t timeHighUS, uint32_t timeLowUS, uint32_t runTimeUS) {\n+  return startWaveformClockCycles(pin, microsecondsToClockCycles(timeHighUS), microsecondsToClockCycles(timeLowUS), microsecondsToClockCycles(runTimeUS));\n+}\n+\n+int startWaveformClockCycles(uint8_t pin, uint32_t timeHighCycles, uint32_t timeLowCycles, uint32_t runTimeCycles) {\n+   if ((pin > 16) || isFlashInterfacePin(pin)) {\n+    return false;\n+  }\n+  Waveform *wave = &wvfState.waveform[pin];\n+  wave->expiryCycle = runTimeCycles ? ESP.getCycleCount() + runTimeCycles : 0;\n+  if (runTimeCycles && !wave->expiryCycle) {\n+    wave->expiryCycle = 1; // expiryCycle==0 means no timeout, so avoid setting it\n+  }\n+\n+  _stopPWM(pin); // Make sure there's no PWM live here\n+\n+  uint32_t mask = 1<<pin;\n+  MEMBARRIER();\n+  if (wvfState.waveformEnabled & mask) {\n+    // Make sure no waveform changes are waiting to be applied\n+    while (wvfState.waveformToChange) {\n+      delay(0); // Wait for waveform to update\n+      // No mem barrier here, the call to a global function implies global state updated\n+    }\n+    wvfState.waveformNewHigh = timeHighCycles;\n+    wvfState.waveformNewLow = timeLowCycles;\n+    MEMBARRIER();\n+    wvfState.waveformToChange = mask;\n+    // The waveform will be updated some time in the future on the next period for the signal\n+  } else { //  if (!(wvfState.waveformEnabled & mask)) {\n+    wave->timeHighCycles = timeHighCycles;\n+    wave->desiredHighCycles = timeHighCycles;\n+    wave->timeLowCycles = timeLowCycles;\n+    wave->desiredLowCycles = timeLowCycles;\n+    wave->lastEdge = 0;\n+    wave->nextServiceCycle = ESP.getCycleCount() + microsecondsToClockCycles(1);\n+    wvfState.waveformToEnable |= mask;\n+    MEMBARRIER();\n+    initTimer();\n+    forceTimerInterrupt();\n+    while (wvfState.waveformToEnable) {\n+      delay(0); // Wait for waveform to update\n+      // No mem barrier here, the call to a global function implies global state updated\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+\n+// Set a callback.  Pass in NULL to stop it\n+void setTimer1Callback(uint32_t (*fn)()) {\n+  wvfState.timer1CB = fn;\n+  if (fn) {\n+    initTimer();\n+    forceTimerInterrupt();\n+  }\n+  disableIdleTimer();\n+}\n+\n+// Stops a waveform on a pin\n+int ICACHE_RAM_ATTR stopWaveform(uint8_t pin) {\n+  // Can't possibly need to stop anything if there is no timer active\n+  if (!timerRunning) {\n+    return false;\n+  }\n+  // If user sends in a pin >16 but <32, this will always point to a 0 bit\n+  // If they send >=32, then the shift will result in 0 and it will also return false\n+  uint32_t mask = 1<<pin;\n+  if (wvfState.waveformEnabled & mask) {\n+    wvfState.waveformToDisable = mask;\n+    // Cancel any pending updates for this waveform, too.\n+    if (wvfState.waveformToChange & mask) {\n+        wvfState.waveformToChange = 0;\n+    }\n+    forceTimerInterrupt();\n+    while (wvfState.waveformToDisable) {\n+      MEMBARRIER(); // If it wasn't written yet, it has to be by now\n+      /* no-op */ // Can't delay() since stopWaveform may be called from an IRQ\n+    }\n+  }\n+  disableIdleTimer();\n+  return true;\n+}\n+\n+// Speed critical bits\n+#pragma GCC optimize (\"O2\")\n+\n+// Normally would not want two copies like this, but due to different\n+// optimization levels the inline attribute gets lost if we try the\n+// other version.\n+static inline ICACHE_RAM_ATTR uint32_t GetCycleCountIRQ() {\n+  uint32_t ccount;\n+  __asm__ __volatile__(\"rsr %0,ccount\":\"=a\"(ccount));\n+  return ccount;\n+}\n+\n+// Find the earliest cycle as compared to right now\n+static inline ICACHE_RAM_ATTR uint32_t earliest(uint32_t a, uint32_t b) {\n+    uint32_t now = GetCycleCountIRQ();\n+    int32_t da = a - now;\n+    int32_t db = b - now;\n+    return (da < db) ? a : b;\n+}\n+\n+// The SDK and hardware take some time to actually get to our NMI code, so\n+// decrement the next IRQ's timer value by a bit so we can actually catch the\n+// real CPU cycle counter we want for the waveforms.\n+\n+// The SDK also sometimes is running at a different speed the the Arduino core\n+// so the ESP cycle counter is actually running at a variable speed.\n+// adjust(x) takes care of adjusting a delta clock cycle amount accordingly.\n+#if F_CPU == 80000000\n+  #define DELTAIRQ (microsecondsToClockCycles(9)/4)\n+  #define adjust(x) ((x) << (turbo ? 1 : 0))\n+#else\n+  #define DELTAIRQ (microsecondsToClockCycles(9)/8)\n+  #define adjust(x) ((x) >> 0)\n+#endif\n+\n+// When the time to the next edge is greater than this, RTI and set another IRQ to minimize CPU usage\n+#define MINIRQTIME microsecondsToClockCycles(4)\n+\n+static ICACHE_RAM_ATTR void timer1Interrupt() {\n+  // Flag if the core is at 160 MHz, for use by adjust()\n+  bool turbo = (*(uint32_t*)0x3FF00014) & 1 ? true : false;\n+\n+  uint32_t nextEventCycle = GetCycleCountIRQ() + microsecondsToClockCycles(MAXIRQUS);\n+  uint32_t timeoutCycle = GetCycleCountIRQ() + microsecondsToClockCycles(14);\n+\n+  if (wvfState.waveformToEnable || wvfState.waveformToDisable) {\n+    // Handle enable/disable requests from main app\n+    wvfState.waveformEnabled = (wvfState.waveformEnabled & ~wvfState.waveformToDisable) | wvfState.waveformToEnable; // Set the requested waveforms on/off\n+    wvfState.waveformState &= ~wvfState.waveformToEnable;  // And clear the state of any just started\n+    wvfState.waveformToEnable = 0;\n+    wvfState.waveformToDisable = 0;\n+    // No mem barrier.  Globals must be written to RAM on ISR exit.\n+    // Find the first GPIO being generated by checking GCC's find-first-set (returns 1 + the bit of the first 1 in an int32_t)\n+    wvfState.startPin = __builtin_ffs(wvfState.waveformEnabled) - 1;\n+    // Find the last bit by subtracting off GCC's count-leading-zeros (no offset in this one)\n+    wvfState.endPin = 32 - __builtin_clz(wvfState.waveformEnabled);\n+  } else if (!pwmState.cnt && pwmState.pwmUpdate) {\n+    // Start up the PWM generator by copying from the mailbox\n+    pwmState.cnt = 1;\n+    pwmState.idx = 1; // Ensure copy this cycle, cause it to start at t=0\n+    pwmState.nextServiceCycle = GetCycleCountIRQ(); // Do it this loop!\n+    // No need for mem barrier here.  Global must be written by IRQ exit\n+  }\n+\n+  bool done = false;\n+  if (wvfState.waveformEnabled || pwmState.cnt) {\n+    do {\n+      nextEventCycle = GetCycleCountIRQ() + microsecondsToClockCycles(MAXIRQUS);\n+\n+      // PWM state machine implementation\n+      if (pwmState.cnt) {\n+        int32_t cyclesToGo;\n+        do {\n+            cyclesToGo = pwmState.nextServiceCycle - GetCycleCountIRQ();\n+            if (cyclesToGo < 0) {\n+                if (pwmState.idx == pwmState.cnt) { // Start of pulses, possibly copy new\n+                  if (pwmState.pwmUpdate) {\n+                    // Do the memory copy from temp to global and clear mailbox\n+                    pwmState = *(PWMState*)pwmState.pwmUpdate;\n+                  }\n+                  GPOS = pwmState.mask; // Set all active pins high\n+                  if (pwmState.mask & (1<<16)) {\n+                    GP16O = 1;\n+                  }\n+                  pwmState.idx = 0;\n+                } else {\n+                  do {\n+                    // Drop the pin at this edge\n+                    if (pwmState.mask & (1<<pwmState.pin[pwmState.idx])) {\n+                      GPOC = 1<<pwmState.pin[pwmState.idx];\n+                      if (pwmState.pin[pwmState.idx] == 16) {\n+                        GP16O = 0;\n+                      }\n+                    }\n+                    pwmState.idx++;\n+                    // Any other pins at this same PWM value will have delta==0, drop them too.\n+                  } while (pwmState.delta[pwmState.idx] == 0);\n+                }\n+                // Preserve duty cycle over PWM period by using now+xxx instead of += delta\n+                cyclesToGo = adjust(pwmState.delta[pwmState.idx]);\n+                pwmState.nextServiceCycle = GetCycleCountIRQ() + cyclesToGo;\n+            }\n+            nextEventCycle = earliest(nextEventCycle, pwmState.nextServiceCycle);\n+        } while (pwmState.cnt && (cyclesToGo < 100));\n+      }\n+\n+      for (auto i = wvfState.startPin; i <= wvfState.endPin; i++) {\n+        uint32_t mask = 1<<i;\n+\n+        // If it's not on, ignore!\n+        if (!(wvfState.waveformEnabled & mask)) {\n+          continue;\n+        }\n+\n+        Waveform *wave = &wvfState.waveform[i];\n+        uint32_t now = GetCycleCountIRQ();\n+\n+        // Disable any waveforms that are done\n+        if (wave->expiryCycle) {\n+          int32_t expiryToGo = wave->expiryCycle - now;\n+          if (expiryToGo < 0) {\n+              // Done, remove!\n+              if (i == 16) {\n+                GP16O = 0;\n+              } \n+              GPOC = mask;\n+              wvfState.waveformEnabled &= ~mask;\n+              continue;\n+            }\n+        }\n+\n+        // Check for toggles\n+        int32_t cyclesToGo = wave->nextServiceCycle - now;\n+        if (cyclesToGo < 0) {\n+          uint32_t nextEdgeCycles;\n+          uint32_t desired = 0;\n+          uint32_t *timeToUpdate;\n+          wvfState.waveformState ^= mask;\n+          if (wvfState.waveformState & mask) {\n+            if (i == 16) {\n+              GP16O = 1;\n+            }\n+            GPOS = mask;\n+\n+            if (wvfState.waveformToChange & mask) {\n+              // Copy over next full-cycle timings\n+              wave->timeHighCycles = wvfState.waveformNewHigh;\n+              wave->desiredHighCycles = wvfState.waveformNewHigh;\n+              wave->timeLowCycles = wvfState.waveformNewLow;\n+              wave->desiredLowCycles = wvfState.waveformNewLow;\n+              wave->lastEdge = 0;\n+              wvfState.waveformToChange = 0;\n+            }\n+            if (wave->lastEdge) {\n+              desired = wave->desiredLowCycles;\n+              timeToUpdate = &wave->timeLowCycles;\n+            }\n+            nextEdgeCycles = wave->timeHighCycles;\n+          } else {\n+            if (i == 16) {\n+              GP16O = 0;\n+            }\n+            GPOC = mask;\n+            desired = wave->desiredHighCycles;\n+            timeToUpdate = &wave->timeHighCycles;\n+            nextEdgeCycles = wave->timeLowCycles;\n+          }\n+          if (desired) {\n+            desired = adjust(desired);\n+            int32_t err = desired - (now - wave->lastEdge);\n+            if (abs(err) < desired) { // If we've lost > the entire phase, ignore this error signal\n+                err /= 2;\n+                *timeToUpdate += err;\n+            }\n+          }\n+          nextEdgeCycles = adjust(nextEdgeCycles);\n+          wave->nextServiceCycle = now + nextEdgeCycles;\n+          wave->lastEdge = now;\n+        }\n+        nextEventCycle = earliest(nextEventCycle, wave->nextServiceCycle);\n+      }\n+\n+      // Exit the loop if we've hit the fixed runtime limit or the next event is known to be after that timeout would occur\n+      uint32_t now = GetCycleCountIRQ();\n+      int32_t cycleDeltaNextEvent = nextEventCycle - now;\n+      int32_t cyclesLeftTimeout = timeoutCycle - now;\n+      done = (cycleDeltaNextEvent > MINIRQTIME) || (cyclesLeftTimeout < 0);\n+    } while (!done);\n+  } // if (wvfState.waveformEnabled)\n+\n+  if (wvfState.timer1CB) {\n+    nextEventCycle = earliest(nextEventCycle, GetCycleCountIRQ() + wvfState.timer1CB());\n+  }\n+\n+  int32_t nextEventCycles = nextEventCycle - GetCycleCountIRQ();\n+\n+  if (nextEventCycles < MINIRQTIME) {\n+    nextEventCycles = MINIRQTIME;\n+  }\n+  nextEventCycles -= DELTAIRQ;\n+\n+  // Do it here instead of global function to save time and because we know it's edge-IRQ\n+  T1L = nextEventCycles >> (turbo ? 1 : 0);\n+}\n+\n+};\n+\n+#endif\ndiff --git a/cores/esp8266/core_esp8266_waveform_pwm.h b/cores/esp8266/core_esp8266_waveform_pwm.h\nnew file mode 100644\nindex 0000000000..8d60e4e7cf\n--- /dev/null\n+++ b/cores/esp8266/core_esp8266_waveform_pwm.h\n@@ -0,0 +1,87 @@\n+/*\n+  esp8266_waveform - General purpose waveform generation and control,\n+                     supporting outputs on all pins in parallel.\n+\n+  Copyright (c) 2018 Earle F. Philhower, III.  All rights reserved.\n+\n+  The core idea is to have a programmable waveform generator with a unique\n+  high and low period (defined in microseconds or CPU clock cycles).  TIMER1 is\n+  set to 1-shot mode and is always loaded with the time until the next edge\n+  of any live waveforms.\n+\n+  Up to one waveform generator per pin supported.\n+\n+  Each waveform generator is synchronized to the ESP clock cycle counter, not the\n+  timer.  This allows for removing interrupt jitter and delay as the counter\n+  always increments once per 80MHz clock.  Changes to a waveform are\n+  contiguous and only take effect on the next waveform transition,\n+  allowing for smooth transitions.\n+\n+  This replaces older tone(), analogWrite(), and the Servo classes.\n+\n+  Everywhere in the code where \"cycles\" is used, it means ESP.getCycleCount()\n+  clock cycle count, or an interval measured in CPU clock cycles, but not TIMER1\n+  cycles (which may be 2 CPU clock cycles @ 160MHz).\n+\n+  This library is free software; you can redistribute it and/or\n+  modify it under the terms of the GNU Lesser General Public\n+  License as published by the Free Software Foundation; either\n+  version 2.1 of the License, or (at your option) any later version.\n+\n+  This library is distributed in the hope that it will be useful,\n+  but WITHOUT ANY WARRANTY; without even the implied warranty of\n+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+  Lesser General Public License for more details.\n+\n+  You should have received a copy of the GNU Lesser General Public\n+  License along with this library; if not, write to the Free Software\n+  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n+*/\n+\n+#ifndef WAVEFORM_LOCKED_PHASE\n+\n+#include <Arduino.h>\n+\n+#ifndef __ESP8266_WAVEFORM_H\n+#define __ESP8266_WAVEFORM_H\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+// Start or change a waveform of the specified high and low times on specific pin.\n+// If runtimeUS > 0 then automatically stop it after that many usecs.\n+// Returns true or false on success or failure.\n+int startWaveform(uint8_t pin, uint32_t timeHighUS, uint32_t timeLowUS, uint32_t runTimeUS);\n+// Start or change a waveform of the specified high and low CPU clock cycles on specific pin.\n+// If runtimeCycles > 0 then automatically stop it after that many CPU clock cycles.\n+// Returns true or false on success or failure.\n+int startWaveformClockCycles(uint8_t pin, uint32_t timeHighCycles, uint32_t timeLowCycles, uint32_t runTimeCycles);\n+// Stop a waveform, if any, on the specified pin.\n+// Returns true or false on success or failure.\n+int stopWaveform(uint8_t pin);\n+\n+// Add a callback function to be called on *EVERY* timer1 trigger.  The\n+// callback returns the number of microseconds until the next desired call.\n+// However, since it is called every timer1 interrupt, it may be called\n+// again before this period.  It should therefore use the ESP Cycle Counter\n+// to determine whether or not to perform an operation.\n+// Pass in NULL to disable the callback and, if no other waveforms being\n+// generated, stop the timer as well.\n+// Make sure the CB function has the ICACHE_RAM_ATTR decorator.\n+void setTimer1Callback(uint32_t (*fn)());\n+\n+\n+\n+// Internal-only calls, not for applications\n+extern void _setPWMFreq(uint32_t freq);\n+extern bool _stopPWM(int pin);\n+extern bool _setPWM(int pin, uint32_t val, uint32_t range);\n+\n+#ifdef __cplusplus\n+}\n+#endif\n+\n+#endif\n+\n+#endif\ndiff --git a/cores/esp8266/core_esp8266_wiring_digital.cpp b/cores/esp8266/core_esp8266_wiring_digital.cpp\nindex 9c15703e0a..539f5448b7 100644\n--- a/cores/esp8266/core_esp8266_wiring_digital.cpp\n+++ b/cores/esp8266/core_esp8266_wiring_digital.cpp\n@@ -82,7 +82,10 @@ extern void __pinMode(uint8_t pin, uint8_t mode) {\n }\n \n extern void ICACHE_RAM_ATTR __digitalWrite(uint8_t pin, uint8_t val) {\n-  stopWaveform(pin);\n+  stopWaveform(pin); // Disable any tone\n+#ifndef WAVEFORM_LOCKED_PHASE\n+  _stopPWM(pin);     // ...and any analogWrite\n+#endif\n   if(pin < 16){\n     if(val) GPOS = (1 << pin);\n     else GPOC = (1 << pin);\ndiff --git a/cores/esp8266/core_esp8266_wiring_pwm.cpp b/cores/esp8266/core_esp8266_wiring_pwm.cpp\nindex 565cac7d87..a456c965c8 100644\n--- a/cores/esp8266/core_esp8266_wiring_pwm.cpp\n+++ b/cores/esp8266/core_esp8266_wiring_pwm.cpp\n@@ -73,11 +73,39 @@ extern void __analogWrite(uint8_t pin, int val) {\n   }\n }\n \n-#endif // WAVEFORM_LOCKED_PHASE\n+#else // !WAVEFORM_LOCKED_PHASE\n+\n+extern void __analogWriteFreq(uint32_t freq) {\n+  if (freq < 100) {\n+    freq = 100;\n+  } else if (freq > 60000) {\n+    freq = 60000;\n+  } else {\n+    freq = freq;\n+  }\n+  _setPWMFreq(freq);\n+}\n+\n+extern void __analogWrite(uint8_t pin, int val) {\n+  if (pin > 16) {\n+    return;\n+  }\n \n-#ifdef WAVEFORM_LOCKED_PWM\n+  if (val < 0) {\n+    val = 0;\n+  } else if (val > analogScale) {\n+    val = analogScale;\n+  }\n+\n+  // Per the Arduino docs at https://www.arduino.cc/reference/en/language/functions/analog-io/analogwrite/\n+  // val: the duty cycle: between 0 (always off) and 255 (always on).\n+  // So if val = 0 we have digitalWrite(LOW), if we have val==range we have digitalWrite(HIGH)\n+  pinMode(pin, OUTPUT);\n+  _setPWM(pin, val, analogScale);\n+}\n+\n+#endif // WAVEFORM_LOCKED_PHASE\n \n-#endif // WAVEFORM_LOCKED_PWM\n \n extern void __analogWriteRange(uint32_t range) {\n   if ((range >= 15) && (range <= 65535)) {\ndiff --git a/libraries/Servo/src/Servo.cpp b/libraries/Servo/src/Servo.cpp\nindex 09d87c0f47..d24ea33799 100644\n--- a/libraries/Servo/src/Servo.cpp\n+++ b/libraries/Servo/src/Servo.cpp\n@@ -95,7 +95,11 @@ void Servo::detach()\n {\n   if (_attached) {\n     _servoMap &= ~(1 << _pin);\n+#ifdef WAVEFORM_LOCKED_PHASE\n     startWaveform(_pin, 0, REFRESH_INTERVAL, 1);\n+#else\n+    // TODO - timeHigh == 0 is illegal in _PWM code branch.  Do nothing for now.\n+#endif\n     delay(REFRESH_INTERVAL / 1000); // long enough to complete active period under all circumstances.\n     stopWaveform(_pin);\n     _attached = false;\ndiff --git a/libraries/SoftwareSerial b/libraries/SoftwareSerial\nindex 6d520c259c..4c08ee8d2c 160000\n--- a/libraries/SoftwareSerial\n+++ b/libraries/SoftwareSerial\n@@ -1 +1 @@\n-Subproject commit 6d520c259cad4457ccdbee362c16f7fa3b504b06\n+Subproject commit 4c08ee8d2cb7b5b27eb4f86797694cbac94aa5c9\ndiff --git a/tools/boards.txt.py b/tools/boards.txt.py\nindex 816c9c00a6..d0fcc45854 100755\n--- a/tools/boards.txt.py\n+++ b/tools/boards.txt.py\n@@ -1471,10 +1471,10 @@ def led (name, default, ledList):\n \n def waveform ():\n     return { 'waveform': collections.OrderedDict([\n+                        ('.menu.waveform.pwm', 'Locked PWM'),\n+                        ('.menu.waveform.pwm.build.waveform', ''),\n                         ('.menu.waveform.phase', 'Locked Phase'),\n                         ('.menu.waveform.phase.build.waveform', '-DWAVEFORM_LOCKED_PHASE'),\n-                        ('.menu.waveform.pwm', 'Locked PWM'),\n-                        ('.menu.waveform.pwm.build.waveform', '-DWAVEFORM_LOCKED_PWM'),\n                     ])\n            }\n \ndiff --git a/tools/platformio-build.py b/tools/platformio-build.py\nindex c735247f3a..6620b37401 100644\n--- a/tools/platformio-build.py\n+++ b/tools/platformio-build.py\n@@ -242,9 +242,7 @@ def scons_patched_match_splitext(path, suffixes=None):\n #\n if \"PIO_FRAMEWORK_ARDUINO_WAVEFORM_LOCKED_PWM\" in flatten_cppdefines:\n     env.Append(CPPDEFINES=[(\"WAVEFORM_LOCKED_PWM\", 1)])\n-# PIO_FRAMEWORK_ARDUINO_WAVEFORM_LOCKED_PHASE (defaults)\n-else:\n-    env.Append(CPPDEFINES=[(\"WAVEFORM_LOCKED_PHASE\", 1)])\n+# PIO_FRAMEWORK_ARDUINO_WAVEFORM_LOCKED_PHASE will be used by default\n \n #\n # VTables\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Reproduce and analyze the \"hump\" issue in the PWM output, likely caused by the interaction between busy-wait and IRQ handling. Review your test sketches against the provided links.\n\n2. Confirm the performance impact of aggregating GPIO changes\u2014the current implementation is suboptimal. Revert to the previous method for better performance.\n\n3. Establish performance metrics and memory usage for your changes. Specifically address how to achieve well-defined 0V and Vmax output bands across all duty cycle settings.\n\n4. Acknowledge the potential for performance degradation during WiFi operations due to interrupt priorities affecting PWM stability.\n\n5. Investigate the instability of the BUILTIN_LED GPIO when set to 1022; this behavior should align with typical outputs.\n\n6. Engage with #7022 for better phase synchronization if applicable."
      }
    ],
    "codediff_length": 65981
  },
  {
    "index": 44,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/doc/faq/readme.rst b/doc/faq/readme.rst\nindex 4fb065a38f..5bea6ce0da 100644\n--- a/doc/faq/readme.rst\n+++ b/doc/faq/readme.rst\n@@ -72,7 +72,7 @@ version).  WPS is always available, and not using it will give an extra\n ~4.5KB compared to releases until 2.4.1 included.\n \n This Arduino library doesn't work on ESP. How do I make it work?\n-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n \n You would like to use this Arduino library with ESP8266 and it does not\n perform. It is not listed among libraries verified to work with ESP8266.\n@@ -80,7 +80,7 @@ perform. It is not listed among libraries verified to work with ESP8266.\n `Read more <a03-library-does-not-work.rst>`__.\n \n In the IDE, for ESP-12E that has 4M flash, I can choose 4M (1M FS) or 4M (3M FS). No matter what I select, the IDE tells me the maximum code space is about 1M. Where does my flash go?\n-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n \n The reason we cannot have more than 1MB of code in flash has to do with\n a hardware limitation. Flash cache hardware on the ESP8266 only allows\n@@ -152,6 +152,44 @@ Artificially clearing them is a workaround to help saving precious heap.\n \n Ref.  `#1923 <https://github.com/esp8266/Arduino/issues/1923>`__\n \n+Use custom defines from build options file\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+A file named ``build_opt.h`` next to the ``sketch.ino`` file enables the user\n+to specify custom definitons in a central and organized location.\n+\n+The following code is a slightly modified Blink example sketch. It opens the\n+possibility to define the ``WAIT_TIME`` between the LED state changes. If no\n+``build_opt.h`` file is placed next to the sketch file, the default value will\n+be set as 1000ms in this example.\n+\n+.. code:: cpp\n+\n+    #ifndef WAIT_TIME\n+    #define WAIT_TIME   1000             // use 1000ms if not defined different\n+    #endif\n+\n+    void setup() {\n+      // initialize digital pin LED_BUILTIN as an output.\n+      pinMode(LED_BUILTIN, OUTPUT);\n+    }\n+\n+    void loop() {\n+      digitalWrite(LED_BUILTIN, HIGH);\n+      delay(WAIT_TIME);\n+      digitalWrite(LED_BUILTIN, LOW);\n+      delay(WAIT_TIME);\n+    }\n+\n+Place the following content in a file named ``build_opt.h`` at the same\n+location as the ``sketch.ino`` file to define the ``WAIT_TIME`` to 500ms.\n+\n+.. code:: cpp\n+\n+    -DWAIT_TIME=500\n+\n+``core.s`` files are not automatically rebuilt when changes are made to the\n+``build_opt.h`` file.\n \n Why is there a board generator and what about it ?\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ndiff --git a/platform.txt b/platform.txt\nindex 7541466196..555171d473 100644\n--- a/platform.txt\n+++ b/platform.txt\n@@ -12,6 +12,7 @@ version=3.0.1-dev\n runtime.tools.xtensa-lx106-elf-gcc.path={runtime.platform.path}/tools/xtensa-lx106-elf\n runtime.tools.python3.path={runtime.platform.path}/tools/python3\n \n+runtime.tools.prebuild={runtime.platform.path}/tools/prebuild.py\n runtime.tools.esptool.path={runtime.platform.path}/tools/esptool\n runtime.tools.signing={runtime.platform.path}/tools/signing.py\n runtime.tools.elf2bin={runtime.platform.path}/tools/elf2bin.py\n@@ -85,6 +86,13 @@ compiler.size.cmd=xtensa-lx106-elf-size\n # This can be overridden in boards.txt\n build.extra_flags=-DESP8266\n \n+# Pre and post build hooks\n+build.opt.name=build_opt.h\n+build.opt.path={build.path}/sketch/{build.opt.name}\n+\n+# Create empty {build.opt} if it does not exist in the output sketch dir\n+recipe.hooks.prebuild.1.pattern=\"{runtime.tools.python3.path}/python3\" \"{runtime.tools.prebuild}\" \"{build.path}\" \"{build.source.path}\"\n+\n # These can be overridden in platform.local.txt\n compiler.c.extra_flags=\n compiler.c.elf.extra_flags=\n@@ -107,13 +115,13 @@ recipe.hooks.linking.prelink.3.pattern=\"{compiler.path}{compiler.c.cmd}\" -CC -E\n recipe.hooks.linking.prelink.4.pattern=\"{compiler.path}{compiler.c.cmd}\" -CC -E -P {build.vtable_flags} {build.mmuflags} \"{runtime.platform.path}/tools/sdk/ld/eagle.app.v6.common.ld.h\" -o \"{build.path}/local.eagle.app.v6.common.ld\"\n \n ## Compile c files\n-recipe.c.o.pattern=\"{compiler.path}{compiler.c.cmd}\" {compiler.cpreprocessor.flags} {compiler.c.flags} -D{build.sdk}=1 -DF_CPU={build.f_cpu} {build.lwip_flags} {build.debug_port} {build.debug_level} -DARDUINO={runtime.ide.version} -DARDUINO_{build.board} -DARDUINO_ARCH_{build.arch} -DARDUINO_BOARD=\"{build.board}\" {build.led} {build.flash_flags} {compiler.c.extra_flags} {build.extra_flags} {includes} \"{source_file}\" -o \"{object_file}\"\n+recipe.c.o.pattern=\"{compiler.path}{compiler.c.cmd}\" {compiler.cpreprocessor.flags} {compiler.c.flags} -D{build.sdk}=1 -DF_CPU={build.f_cpu} {build.lwip_flags} {build.debug_port} {build.debug_level} -DARDUINO={runtime.ide.version} -DARDUINO_{build.board} -DARDUINO_ARCH_{build.arch} -DARDUINO_BOARD=\"{build.board}\" {build.led} {build.flash_flags} {compiler.c.extra_flags} {build.extra_flags} \"@{build.opt.path}\" {includes} \"{source_file}\" -o \"{object_file}\"\n \n ## Compile c++ files\n-recipe.cpp.o.pattern=\"{compiler.path}{compiler.cpp.cmd}\" {compiler.cpreprocessor.flags} {compiler.cpp.flags} -D{build.sdk}=1 -DF_CPU={build.f_cpu} {build.lwip_flags} {build.debug_port} {build.debug_level} -DARDUINO={runtime.ide.version} -DARDUINO_{build.board} -DARDUINO_ARCH_{build.arch} -DARDUINO_BOARD=\"{build.board}\" {build.led} {build.flash_flags} {compiler.cpp.extra_flags} {build.extra_flags} {includes} \"{source_file}\" -o \"{object_file}\"\n+recipe.cpp.o.pattern=\"{compiler.path}{compiler.cpp.cmd}\" {compiler.cpreprocessor.flags} {compiler.cpp.flags} -D{build.sdk}=1 -DF_CPU={build.f_cpu} {build.lwip_flags} {build.debug_port} {build.debug_level} -DARDUINO={runtime.ide.version} -DARDUINO_{build.board} -DARDUINO_ARCH_{build.arch} -DARDUINO_BOARD=\"{build.board}\" {build.led} {build.flash_flags} {compiler.cpp.extra_flags} {build.extra_flags} \"@{build.opt.path}\" {includes} \"{source_file}\" -o \"{object_file}\"\n \n ## Compile S files\n-recipe.S.o.pattern=\"{compiler.path}{compiler.c.cmd}\" {compiler.cpreprocessor.flags} {compiler.S.flags} -D{build.sdk}=1 -DF_CPU={build.f_cpu} {build.lwip_flags} {build.debug_port} {build.debug_level} -DARDUINO={runtime.ide.version} -DARDUINO_{build.board} -DARDUINO_ARCH_{build.arch} -DARDUINO_BOARD=\"{build.board}\" {build.led} {build.flash_flags} {compiler.S.extra_flags} {build.extra_flags} {includes} \"{source_file}\" -o \"{object_file}\"\n+recipe.S.o.pattern=\"{compiler.path}{compiler.c.cmd}\" {compiler.cpreprocessor.flags} {compiler.S.flags} -D{build.sdk}=1 -DF_CPU={build.f_cpu} {build.lwip_flags} {build.debug_port} {build.debug_level} -DARDUINO={runtime.ide.version} -DARDUINO_{build.board} -DARDUINO_ARCH_{build.arch} -DARDUINO_BOARD=\"{build.board}\" {build.led} {build.flash_flags} {compiler.S.extra_flags} {build.extra_flags} \"@{build.opt.path}\" {includes} \"{source_file}\" -o \"{object_file}\"\n \n ## Create archives\n recipe.ar.pattern=\"{compiler.path}{compiler.ar.cmd}\" {compiler.ar.flags} {compiler.ar.extra_flags} \"{archive_file_path}\" \"{object_file}\"\ndiff --git a/tools/prebuild.py b/tools/prebuild.py\nnew file mode 100644\nindex 0000000000..3b074ca65e\n--- /dev/null\n+++ b/tools/prebuild.py\n@@ -0,0 +1,130 @@\n+#!/usr/bin/env python3\n+# -*- coding: utf-8 -*-\n+#\n+# prebuild.py \u2014 create build_opt.h file in build directory if it does not exist\n+#\n+# This script will create a folder called \"sketch\" in the build path if it does\n+# not yet exist and create an empty build options file inside if this does also\n+# not exist yet\n+#\n+# Written by brainelectronics, 2021.\n+#\n+\n+import os\n+import sys\n+\n+\n+def create_sketch_dir(build_path):\n+    \"\"\"\n+    Create the sketch directory\n+    :param      build_path:  The path to the build directory\n+    :type       build_path:  str\n+    \"\"\"\n+    sketch_build_path = os.path.join(build_path, \"sketch\")\n+\n+    if not os.path.exists(sketch_build_path):\n+        os.makedirs(sketch_build_path)\n+\n+\n+def create_build_options_file(source_path, build_path, build_opt_name=\"build_opt.h\"):\n+    \"\"\"\n+    Create the build options file in the build directory.\n+    The modification time of the build options file is set to the sketch\n+    modification time in case the file did not exist or the users build options\n+    modification time to reflect changes which require a recompilation\n+    :param      source_path:     The path to the source directory\n+    :type       source_path:     str\n+    :param      build_path:      The path to the build directory\n+    :type       build_path:      str\n+    :param      build_opt_name:  The build option file name\n+    :type       build_opt_name:  str, optional\n+    \"\"\"\n+    build_opt_source_path = os.path.join(source_path, build_opt_name)\n+    build_opt_build_path = os.path.join(build_path, \"sketch\", build_opt_name)\n+\n+    # check for an existing build options file in the source directory\n+    if os.path.exists(build_opt_source_path):\n+        # user does have/use an build options file in it's sketch directory\n+\n+        if os.path.exists(build_opt_build_path):\n+            # set build options file modification time to the same time as the\n+            # sketch modification time to avoid rebuilding libraries\n+            set_file_time_to_sketch_time(source_path, build_opt_build_path)\n+        else:\n+            # the build options file does not yet exist in the build directory\n+            # just continue as it will be copied by the IDE automatically on\n+            # time. This section is only entered on the very first run\n+            pass\n+    else:\n+        # user does not have a build options file, create empty one to avoid\n+        # compilation error due to missing file for compilation\n+        open(build_opt_build_path, 'a').close()\n+\n+        # set build options file modification time to the same time as the\n+        # sketch modification time to avoid rebuilding libraries\n+        set_file_time_to_sketch_time(source_path, build_opt_build_path)\n+\n+\n+def set_file_time_to_sketch_time(source_path, destination_path):\n+    \"\"\"\n+    Set the file ctime and mtime to the ctime and mtime of the sketch.\n+    :param      source_path:       The source path to the sketch\n+    :type       source_path:       str\n+    :param      destination_path:  The destination path to the file to modify\n+    :type       destination_path:  str\n+    \"\"\"\n+    sketch_path = get_full_sketch_path(source_path)\n+    sketch_mtime = get_modification_time(sketch_path)\n+    destination_ctime = get_creation_time(destination_path)\n+\n+    os.utime(destination_path, (destination_ctime, sketch_mtime))\n+\n+\n+def get_full_sketch_path(source_path):\n+    \"\"\"\n+    Get the full sketch path.\n+    :param      source_path:  The source path\n+    :type       source_path:  str\n+    :returns:   The full sketch path including the '.ino' extension.\n+    :rtype:     str\n+    \"\"\"\n+    base_name = os.path.basename(source_path)\n+\n+    sketch_path = os.path.join(source_path, base_name + '.ino')\n+\n+    return sketch_path\n+\n+\n+def get_modification_time(file_path):\n+    \"\"\"\n+    Get the modification time of a file.\n+    :param      file_path:  The file path\n+    :type       file_path:  str\n+    :returns:   The modification time.\n+    :rtype:     float\n+    \"\"\"\n+    return os.path.getmtime(file_path)\n+\n+\n+def get_creation_time(file_path):\n+    \"\"\"\n+    Gets the creation time if a file.\n+    :param      file_path:  The file path\n+    :type       file_path:  str\n+    :returns:   The creation time.\n+    :rtype:     float\n+    \"\"\"\n+    return os.path.getctime(file_path)\n+\n+\n+def main():\n+    if len(sys.argv) == 3:\n+        build_path = sys.argv[1]\n+        source_path = sys.argv[2]\n+\n+        create_sketch_dir(build_path)\n+        create_build_options_file(source_path, build_path)\n+\n+\n+if __name__ == '__main__':\n+    sys.exit(main())\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **File Handling Issue**: Ensure `build_opt.h` is backdated upon creation to avoid unnecessary rebuilds of libraries. Adjust the creation process to match the timestamp of other source files if it does not exist.\n\n2. **Build Errors**: Address `FileNotFoundError` for `build_opt.h` during the build process. Confirm that `build_opt.h` is copied correctly to the temp build directory.\n\n3. **Build Options Format**: Change the naming convention from `build_opt.h` to `build.opt`. This improves clarity and avoids confusion since it doesn't contain actual header code.\n\n4. **Script Modifications**: Update prebuild.py to copy `build_opt.h` to `build.opt`, creating a proxy file for tracking changes. Maintain timestamps for triggering recompilation.\n\n5. **Compatibility Concerns**: Note the incompatibility with STM32 platform stemming from how build options are currently managed. Engage the STM32 community for alignment on changes.\n\n6. **IDE Behavior**: Disable \"Aggressively cache compiled core\" in user preferences to avoid conflicts with caching behavior when `build.opt` is altered. \n\n7. **Next Steps**: Implement the proposed changes and test thoroughly to confirm behavior across different environments (Linux, Windows) and ensure consistent error handling."
      }
    ],
    "codediff_length": 12118
  },
  {
    "index": 45,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/cores/esp8266/Arduino.h b/cores/esp8266/Arduino.h\nindex 5424d3baf3..b274f17121 100644\n--- a/cores/esp8266/Arduino.h\n+++ b/cores/esp8266/Arduino.h\n@@ -279,6 +279,7 @@ unsigned long pulseIn(uint8_t pin, uint8_t state, unsigned long timeout = 100000\n unsigned long pulseInLong(uint8_t pin, uint8_t state, unsigned long timeout = 1000000L);\n \n void tone(uint8_t _pin, unsigned int frequency, unsigned long duration = 0);\n+void tone(uint8_t _pin, double frequency, unsigned long duration = 0);\n void noTone(uint8_t _pin);\n \n // WMath prototypes\ndiff --git a/cores/esp8266/Tone.cpp b/cores/esp8266/Tone.cpp\nindex fb7837ee46..a3345bb612 100644\n--- a/cores/esp8266/Tone.cpp\n+++ b/cores/esp8266/Tone.cpp\n@@ -3,7 +3,7 @@\n \n   A Tone Generator Library for the ESP8266\n \n-  Copyright (c) 2016 Ben Pirt. All rights reserved.\n+  Original Copyright (c) 2016 Ben Pirt. All rights reserved.\n   This file is part of the esp8266 core for Arduino environment.\n \n   This library is free software; you can redistribute it and/or\n@@ -22,115 +22,59 @@\n */\n \n #include \"Arduino.h\"\n-#include \"pins_arduino.h\"\n+#include \"core_esp8266_waveform.h\"\n \n-#define AVAILABLE_TONE_PINS 1\n-const uint8_t tone_timers[] = { 1 };\n-static uint8_t tone_pins[AVAILABLE_TONE_PINS] = { 255, };\n-static long toggle_counts[AVAILABLE_TONE_PINS] = { 0, };\n-#define T1INDEX 0\n+// Which pins have a tone running on them?\n+static uint32_t _toneMap = 0;\n \n-void t1IntHandler();\n \n-static int8_t toneBegin(uint8_t _pin) {\n-  int8_t _index = -1;\n-\n-  // if we're already using the pin, reuse it.\n-  for (int i = 0; i < AVAILABLE_TONE_PINS; i++) {\n-    if (tone_pins[i] == _pin) {\n-      return i;\n-    }\n+static void _startTone(uint8_t _pin, uint32_t high, uint32_t low, unsigned long duration) {\n+  if (_pin > 16) {\n+    return;\n   }\n \n-  // search for an unused timer.\n-  for (int i = 0; i < AVAILABLE_TONE_PINS; i++) {\n-    if (tone_pins[i] == 255) {\n-      tone_pins[i] = _pin;\n-      _index = i;\n-      break;\n-    }\n-  }\n+  pinMode(_pin, OUTPUT);\n \n-  return _index;\n-}\n+  high = std::max(high, (uint32_t)100);\n+  low = std::max(low, (uint32_t)100);\n \n-// frequency (in hertz) and duration (in milliseconds).\n-void tone(uint8_t _pin, unsigned int frequency, unsigned long duration) {\n-  int8_t _index;\n-\n-  _index = toneBegin(_pin);\n-\n-  if (_index >= 0) {\n-    // Set the pinMode as OUTPUT\n-    pinMode(_pin, OUTPUT);\n-\n-    // Alternate handling of zero freqency to avoid divide by zero errors\n-    if (frequency == 0)\n-    {\n-        noTone(_pin);\n-        return;\n-    }\n-\n-    // Calculate the toggle count\n-    if (duration > 0) {\n-      toggle_counts[_index] = 2 * frequency * duration / 1000;\n-    } else {\n-      toggle_counts[_index] = -1;\n-    }\n-\n-    // set up the interrupt frequency\n-    switch (tone_timers[_index]) {\n-      case 0:\n-        // Not currently supported\n-        break;\n-\n-      case 1:\n-        timer1_disable();\n-        timer1_isr_init();\n-        timer1_attachInterrupt(t1IntHandler);\n-        timer1_enable(TIM_DIV1, TIM_EDGE, TIM_LOOP);\n-        timer1_write((clockCyclesPerMicrosecond() * 500000) / frequency);\n-        break;\n-    }\n+  if (startWaveform(_pin, high, low, (uint32_t) duration * 1000)) {\n+    _toneMap |= 1 << _pin;\n   }\n }\n \n-void disableTimer(uint8_t _index) {\n-  tone_pins[_index] = 255;\n-\n-  switch (tone_timers[_index]) {\n-    case 0:\n-      // Not currently supported\n-      break;\n \n-    case 1:\n-      timer1_disable();\n-      break;\n+void tone(uint8_t _pin, unsigned int frequency, unsigned long duration) {\n+  if (frequency == 0) {\n+    noTone(_pin);\n+  } else {\n+    uint32_t period = 1000000L / frequency;\n+    uint32_t high = period / 2;\n+    uint32_t low = period - high;\n+    _startTone(_pin, high, low, duration);\n   }\n }\n \n-void noTone(uint8_t _pin) {\n-  for (int i = 0; i < AVAILABLE_TONE_PINS; i++) {\n-    if (tone_pins[i] == _pin) {\n-      tone_pins[i] = 255;\n-      disableTimer(i);\n-      break;\n-    }\n+\n+// Separate tone(float) to hopefully not pull in floating point libs unless\n+// it's called with a float.\n+void tone(uint8_t _pin, double frequency, unsigned long duration) {\n+  if (frequency < 1.0) { // FP means no exact comparisons\n+    noTone(_pin);\n+  } else {\n+    double period = 1000000.0 / frequency;\n+    uint32_t high = (uint32_t)((period / 2.0) + 0.5);\n+    uint32_t low = (uint32_t)(period + 0.5) - high;\n+    _startTone(_pin, high, low, duration);\n   }\n-  digitalWrite(_pin, LOW);\n }\n \n-ICACHE_RAM_ATTR void t1IntHandler() {\n-  if (toggle_counts[T1INDEX] != 0){\n-    // toggle the pin\n-    digitalWrite(tone_pins[T1INDEX], toggle_counts[T1INDEX] % 2);\n-    toggle_counts[T1INDEX]--;\n-    // handle the case of indefinite duration\n-    if (toggle_counts[T1INDEX] < -2){\n-      toggle_counts[T1INDEX] = -1;\n-    }\n-  }else{\n-    disableTimer(T1INDEX);\n-    digitalWrite(tone_pins[T1INDEX], LOW);\n+\n+void noTone(uint8_t _pin) {\n+  if (_pin > 16) {\n+    return;\n   }\n+  stopWaveform(_pin);\n+  _toneMap &= ~(1 << _pin);\n+  digitalWrite(_pin, 0);\n }\ndiff --git a/cores/esp8266/base64.cpp b/cores/esp8266/base64.cpp\nold mode 100755\nnew mode 100644\ndiff --git a/cores/esp8266/base64.h b/cores/esp8266/base64.h\nold mode 100755\nnew mode 100644\ndiff --git a/cores/esp8266/core_esp8266_waveform.c b/cores/esp8266/core_esp8266_waveform.c\nnew file mode 100644\nindex 0000000000..0454c768b2\n--- /dev/null\n+++ b/cores/esp8266/core_esp8266_waveform.c\n@@ -0,0 +1,304 @@\n+/*\n+  esp8266_waveform - General purpose waveform generation and control,\n+                     supporting outputs on all pins in parallel.\n+\n+  Copyright (c) 2018 Earle F. Philhower, III.  All rights reserved.\n+\n+  The core idea is to have a programmable waveform generator with a unique\n+  high and low period (defined in microseconds).  TIMER1 is set to 1-shot\n+  mode and is always loaded with the time until the next edge of any live\n+  waveforms.\n+\n+  Up to one waveform generator per pin supported.\n+\n+  Each waveform generator is synchronized to the ESP cycle counter, not the\n+  timer.  This allows for removing interrupt jitter and delay as the counter\n+  always increments once per 80MHz clock.  Changes to a waveform are\n+  contiguous and only take effect on the next waveform transition,\n+  allowing for smooth transitions.\n+\n+  This replaces older tone(), analogWrite(), and the Servo classes.\n+\n+  Everywhere in the code where \"cycles\" is used, it means ESP.getCycleTime()\n+  cycles, not TIMER1 cycles (which may be 2 CPU clocks @ 160MHz).\n+\n+  This library is free software; you can redistribute it and/or\n+  modify it under the terms of the GNU Lesser General Public\n+  License as published by the Free Software Foundation; either\n+  version 2.1 of the License, or (at your option) any later version.\n+\n+  This library is distributed in the hope that it will be useful,\n+  but WITHOUT ANY WARRANTY; without even the implied warranty of\n+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+  Lesser General Public License for more details.\n+\n+  You should have received a copy of the GNU Lesser General Public\n+  License along with this library; if not, write to the Free Software\n+  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n+*/\n+\n+#include <Arduino.h>\n+#include \"core_esp8266_waveform.h\"\n+\n+// Need speed, not size, here\n+#pragma GCC optimize (\"O3\")\n+\n+// Map the IRQ stuff to standard terminology\n+#define cli() ets_intr_lock()\n+#define sei() ets_intr_unlock()\n+\n+// Maximum delay between IRQs\n+#define MAXIRQUS (10000)\n+\n+// If the cycles from now to an event are below this value, perform it anyway since IRQs take longer than this\n+#define CYCLES_FLUFF (100)\n+\n+// Macro to get count of predefined array elements\n+#define countof(a) ((size_t)(sizeof(a)/sizeof(a[0])))\n+\n+// Set/clear *any* GPIO\n+#define SetGPIOPin(a) do { if (a < 16) { GPOS |= (1<<a); } else { GP16O |= 1; } } while (0)\n+#define ClearGPIOPin(a) do { if (a < 16) { GPOC |= (1<<a); } else { GP16O &= ~1; } } while (0)\n+// Set/clear GPIO 0-15\n+#define SetGPIO(a) do { GPOS = a; } while (0)\n+#define ClearGPIO(a) do { GPOC = a; } while (0)\n+\n+// Waveform generator can create tones, PWM, and servos\n+typedef struct {\n+  uint32_t nextServiceCycle;        // ESP cycle timer when a transition required\n+  uint32_t timeLeftCycles;          // For time-limited waveform, how many ESP cycles left\n+  uint16_t gpioMask;                // Mask instead of value to speed IRQ loop\n+  uint16_t gpio16Mask;              // Mask instead of value to speed IRQ loop\n+  unsigned state              : 1;  // Current state of this pin\n+  unsigned nextTimeHighCycles : 31; // Copy over low->high to keep smooth waveform\n+  unsigned enabled            : 1;  // Is this GPIO generating a waveform?\n+  unsigned nextTimeLowCycles  : 31; // Copy over high->low to keep smooth waveform\n+} Waveform;\n+\n+// These can be accessed in interrupts, so ensure to bracket access with SEI/CLI\n+static Waveform waveform[] = {\n+  {0, 0, 1<<0, 0, 0, 0, 0, 0}, // GPIO0\n+  {0, 0, 1<<1, 0, 0, 0, 0, 0}, // GPIO1\n+  {0, 0, 1<<2, 0, 0, 0, 0, 0},\n+  {0, 0, 1<<3, 0, 0, 0, 0, 0},\n+  {0, 0, 1<<4, 0, 0, 0, 0, 0},\n+  {0, 0, 1<<5, 0, 0, 0, 0, 0},\n+  // GPIOS 6-11 not allowed, used for flash\n+  {0, 0, 1<<12, 0, 0, 0, 0, 0},\n+  {0, 0, 1<<13, 0, 0, 0, 0, 0},\n+  {0, 0, 1<<14, 0, 0, 0, 0, 0},\n+  {0, 0, 1<<15, 0, 0, 0, 0, 0},\n+  {0, 0, 0, 1, 0, 0, 0, 0}  // GPIO16\n+};\n+\n+static uint32_t (*timer1CB)() = NULL;;\n+\n+\n+// Helper functions\n+static inline ICACHE_RAM_ATTR uint32_t MicrosecondsToCycles(uint32_t microseconds) {\n+  return clockCyclesPerMicrosecond() * microseconds;\n+}\n+\n+static inline ICACHE_RAM_ATTR uint32_t min_u32(uint32_t a, uint32_t b) {\n+  if (a < b) {\n+    return a;\n+  }\n+  return b;\n+}\n+\n+static inline ICACHE_RAM_ATTR uint32_t min_s32(int32_t a, int32_t b) {\n+  if (a < b) {\n+    return a;\n+  }\n+  return b;\n+}\n+\n+static inline ICACHE_RAM_ATTR void ReloadTimer(uint32_t a) {\n+  // Below a threshold you actually miss the edge IRQ, so ensure enough time\n+  if (a > 32) {\n+    timer1_write(a);\n+  } else {\n+    timer1_write(32);\n+  }\n+}\n+\n+static inline ICACHE_RAM_ATTR uint32_t GetCycleCount() {\n+  uint32_t ccount;\n+  __asm__ __volatile__(\"esync; rsr %0,ccount\":\"=a\"(ccount));\n+  return ccount;\n+}\n+\n+// Interrupt on/off control\n+static ICACHE_RAM_ATTR void timer1Interrupt();\n+static uint8_t timerRunning = false;\n+static uint32_t lastCycleCount = 0; // Last ESP cycle counter on running the interrupt routine\n+\n+static void initTimer() {\n+  timer1_disable();\n+  timer1_isr_init();\n+  timer1_attachInterrupt(timer1Interrupt);\n+  lastCycleCount = GetCycleCount();\n+  timer1_enable(TIM_DIV1, TIM_EDGE, TIM_SINGLE);\n+  timerRunning = true;\n+}\n+\n+static void deinitTimer() {\n+  timer1_attachInterrupt(NULL);\n+  timer1_disable();\n+  timer1_isr_init();\n+  timerRunning = false;\n+}\n+\n+// Set a callback.  Pass in NULL to stop it\n+void setTimer1Callback(uint32_t (*fn)()) {\n+  timer1CB = fn;\n+  if (!timerRunning && fn) {\n+    initTimer();\n+  } else if (timerRunning && !fn) {\n+    int cnt = 0;\n+    for (size_t i = 0; i < countof(waveform); i++) {\n+      cnt += waveform[i].enabled ? 1 : 0;\n+    }\n+    if (!cnt) {\n+      deinitTimer();\n+    }\n+  }\n+  ReloadTimer(MicrosecondsToCycles(1)); // Cause an interrupt post-haste\n+}\n+\n+// Start up a waveform on a pin, or change the current one.  Will change to the new\n+// waveform smoothly on next low->high transition.  For immediate change, stopWaveform()\n+// first, then it will immediately begin.\n+int startWaveform(uint8_t pin, uint32_t timeHighUS, uint32_t timeLowUS, uint32_t runTimeUS) {\n+  Waveform *wave = NULL;\n+  for (size_t i = 0; i < countof(waveform); i++) {\n+    if (((pin == 16) && waveform[i].gpio16Mask==1) || ((pin != 16) && (waveform[i].gpioMask == 1<<pin))) {\n+      wave = (Waveform*) & (waveform[i]);\n+      break;\n+    }\n+  }\n+  if (!wave) {\n+    return false;\n+  }\n+  wave->nextTimeHighCycles = MicrosecondsToCycles(timeHighUS) - 70;  // Take out some time for IRQ codepath\n+  wave->nextTimeLowCycles = MicrosecondsToCycles(timeLowUS) - 70;  // Take out some time for IRQ codepath\n+  wave->timeLeftCycles = MicrosecondsToCycles(runTimeUS);\n+  if (!wave->enabled) {\n+    wave->state = 0;\n+    // Actually set the pin high or low in the IRQ service to guarantee times\n+    wave->nextServiceCycle = GetCycleCount() + MicrosecondsToCycles(1);\n+    wave->enabled = 1;\n+    if (!timerRunning) {\n+      initTimer();\n+    }\n+    ReloadTimer(MicrosecondsToCycles(1)); // Cause an interrupt post-haste\n+  }\n+  return true;\n+}\n+\n+// Stops a waveform on a pin\n+int stopWaveform(uint8_t pin) {\n+  for (size_t i = 0; i < countof(waveform); i++) {\n+    if (((pin == 16) && waveform[i].gpio16Mask) || ((pin != 16) && (waveform[i].gpioMask == 1<<pin))) {\n+      waveform[i].enabled = 0;\n+      int cnt = timer1CB?1:0;\n+      for (size_t i = 0; i < countof(waveform); i++) {\n+        cnt += waveform[i].enabled ? 1 : 0;\n+      }\n+      if (!cnt) {\n+        deinitTimer();\n+      }\n+      return true;\n+    }\n+  }\n+  cli();\n+  return false;\n+}\n+\n+static ICACHE_RAM_ATTR void timer1Interrupt() {\n+  uint32_t nextEventCycles;\n+  #if F_CPU == 160000000\n+  uint8_t cnt = 20;\n+  #else\n+  uint8_t cnt = 10;\n+  #endif\n+\n+  do {\n+    nextEventCycles = MicrosecondsToCycles(MAXIRQUS);\n+    for (size_t i = 0; i < countof(waveform); i++) {\n+      Waveform *wave = &waveform[i];\n+      uint32_t now;\n+\n+      // If it's not on, ignore!\n+      if (!wave->enabled) {\n+        continue;\n+      }\n+\n+      // Check for toggles\n+      now = GetCycleCount();\n+      if (now >= wave->nextServiceCycle) {\n+        wave->state = !wave->state;\n+        if (wave->state) {\n+          SetGPIO(wave->gpioMask);\n+          if (wave->gpio16Mask) {\n+            GP16O |= wave->gpio16Mask; // GPIO16 write slow as it's RMW\n+          }\n+          wave->nextServiceCycle = now + wave->nextTimeHighCycles;\n+          nextEventCycles = min_u32(nextEventCycles, wave->nextTimeHighCycles);\n+        } else {\n+          ClearGPIO(wave->gpioMask);\n+          if (wave->gpio16Mask) {\n+            GP16O &= ~wave->gpio16Mask;\n+          }\n+          wave->nextServiceCycle = now + wave->nextTimeLowCycles;\n+          nextEventCycles = min_u32(nextEventCycles, wave->nextTimeLowCycles);\n+        }\n+      } else {\n+        uint32_t deltaCycles = wave->nextServiceCycle - now;\n+        nextEventCycles = min_u32(nextEventCycles, deltaCycles);\n+      }\n+    }\n+  } while (--cnt && (nextEventCycles < MicrosecondsToCycles(4)));\n+\n+  uint32_t curCycleCount = GetCycleCount();\n+  uint32_t deltaCycles = curCycleCount - lastCycleCount;\n+  lastCycleCount = curCycleCount;\n+\n+  // Check for timed-out waveforms out of the high-frequency toggle loop\n+  for (size_t i = 0; i < countof(waveform); i++) {\n+    Waveform *wave = &waveform[i];\n+    if (wave->timeLeftCycles) {\n+      // Check for unsigned underflow with new > old\n+      if (deltaCycles >= wave->timeLeftCycles) {\n+        // Done, remove!\n+        wave->enabled = false;\n+        ClearGPIO(wave->gpioMask);\n+        GP16O &= ~wave->gpio16Mask;\n+      } else {\n+        uint32_t newTimeLeftCycles = wave->timeLeftCycles - deltaCycles;\n+        wave->timeLeftCycles = newTimeLeftCycles;\n+      }\n+    }\n+  }\n+\n+  if (timer1CB) {\n+    nextEventCycles = min_u32(nextEventCycles, timer1CB());\n+  }\n+\n+  #if F_CPU == 160000000\n+  if (nextEventCycles <= 5 * MicrosecondsToCycles(1)) {\n+    nextEventCycles = MicrosecondsToCycles(1) / 2;\n+  } else {\n+    nextEventCycles -= 5 * MicrosecondsToCycles(1);\n+  }\n+  nextEventCycles = nextEventCycles >> 1;\n+  #else\n+  if (nextEventCycles <= 6 * MicrosecondsToCycles(1)) {\n+    nextEventCycles = MicrosecondsToCycles(1) / 2;\n+  } else {\n+    nextEventCycles -= 6 * MicrosecondsToCycles(1);\n+  }\n+  #endif\n+\n+  ReloadTimer(nextEventCycles);\n+}\ndiff --git a/cores/esp8266/core_esp8266_waveform.h b/cores/esp8266/core_esp8266_waveform.h\nnew file mode 100644\nindex 0000000000..24ce91fb36\n--- /dev/null\n+++ b/cores/esp8266/core_esp8266_waveform.h\n@@ -0,0 +1,71 @@\n+/*\n+  esp8266_waveform - General purpose waveform generation and control,\n+                     supporting outputs on all pins in parallel.\n+\n+  Copyright (c) 2018 Earle F. Philhower, III.  All rights reserved.\n+\n+  The core idea is to have a programmable waveform generator with a unique\n+  high and low period (defined in microseconds).  TIMER1 is set to 1-shot\n+  mode and is always loaded with the time until the next edge of any live\n+  waveforms.\n+\n+  Up to one waveform generator per pin supported.\n+\n+  Each waveform generator is synchronized to the ESP cycle counter, not the\n+  timer.  This allows for removing interrupt jitter and delay as the counter\n+  always increments once per 80MHz clock.  Changes to a waveform are\n+  contiguous and only take effect on the next waveform transition,\n+  allowing for smooth transitions.\n+\n+  This replaces older tone(), analogWrite(), and the Servo classes.\n+\n+  Everywhere in the code where \"cycles\" is used, it means ESP.getCycleTime()\n+  cycles, not TIMER1 cycles (which may be 2 CPU clocks @ 160MHz).\n+\n+  This library is free software; you can redistribute it and/or\n+  modify it under the terms of the GNU Lesser General Public\n+  License as published by the Free Software Foundation; either\n+  version 2.1 of the License, or (at your option) any later version.\n+\n+  This library is distributed in the hope that it will be useful,\n+  but WITHOUT ANY WARRANTY; without even the implied warranty of\n+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+  Lesser General Public License for more details.\n+\n+  You should have received a copy of the GNU Lesser General Public\n+  License along with this library; if not, write to the Free Software\n+  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n+*/\n+\n+#include <Arduino.h>\n+\n+#ifndef __ESP8266_WAVEFORM_H\n+#define __ESP8266_WAVEFORM_H\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+// Start or change a waveform of the specified high and low times on specific pin.\n+// If runtimeUS > 0 then automatically stop it after that many usecs.\n+// Returns true or false on success or failure.\n+int startWaveform(uint8_t pin, uint32_t timeHighUS, uint32_t timeLowUS, uint32_t runTimeUS);\n+// Stop a waveform, if any, on the specified pin.\n+// Returns true or false on success or failure.\n+int stopWaveform(uint8_t pin);\n+\n+// Add a callback function to be called on *EVERY* timer1 trigger.  The\n+// callback returns the number of microseconds until the next desired call.\n+// However, since it is called every timer1 interrupt, it may be called\n+// again before this period.  It should therefore use the ESP Cycle Counter\n+// to determine whether or not to perform an operation.\n+// Pass in NULL to disable the callback and, if no other waveforms being\n+// generated, stop the timer as well.\n+// Make sure the CB function has the ICACHE_RAM_ATTR decorator.\n+void setTimer1Callback(uint32_t (*fn)());\n+\n+#ifdef __cplusplus\n+}\n+#endif\n+\n+#endif\ndiff --git a/cores/esp8266/core_esp8266_wiring_digital.c b/cores/esp8266/core_esp8266_wiring_digital.c\nindex 6b9b129cac..4ee398d615 100644\n--- a/cores/esp8266/core_esp8266_wiring_digital.c\n+++ b/cores/esp8266/core_esp8266_wiring_digital.c\n@@ -24,13 +24,12 @@\n #include \"c_types.h\"\n #include \"eagle_soc.h\"\n #include \"ets_sys.h\"\n-\n-extern void pwm_stop_pin(uint8_t pin);\n+#include \"core_esp8266_waveform.h\"\n \n uint8_t esp8266_gpioToFn[16] = {0x34, 0x18, 0x38, 0x14, 0x3C, 0x40, 0x1C, 0x20, 0x24, 0x28, 0x2C, 0x30, 0x04, 0x08, 0x0C, 0x10};\n \n extern void __pinMode(uint8_t pin, uint8_t mode) {\n-  pwm_stop_pin(pin);\n+  stopWaveform(pin);\n   if(pin < 16){\n     if(mode == SPECIAL){\n       GPC(pin) = (GPC(pin) & (0xF << GPCI)); //SOURCE(GPIO) | DRIVER(NORMAL) | INT_TYPE(UNCHANGED) | WAKEUP_ENABLE(DISABLED)\n@@ -80,7 +79,7 @@ extern void __pinMode(uint8_t pin, uint8_t mode) {\n }\n \n extern void ICACHE_RAM_ATTR __digitalWrite(uint8_t pin, uint8_t val) {\n-  pwm_stop_pin(pin);\n+  stopWaveform(pin);\n   if(pin < 16){\n     if(val) GPOS = (1 << pin);\n     else GPOC = (1 << pin);\n@@ -91,7 +90,7 @@ extern void ICACHE_RAM_ATTR __digitalWrite(uint8_t pin, uint8_t val) {\n }\n \n extern int ICACHE_RAM_ATTR __digitalRead(uint8_t pin) {\n-  pwm_stop_pin(pin);\n+  stopWaveform(pin);\n   if(pin < 16){\n     return GPIP(pin);\n   } else if(pin == 16){\ndiff --git a/cores/esp8266/core_esp8266_wiring_pwm.c b/cores/esp8266/core_esp8266_wiring_pwm.c\nindex 671eaa4145..153f30ee37 100644\n--- a/cores/esp8266/core_esp8266_wiring_pwm.c\n+++ b/cores/esp8266/core_esp8266_wiring_pwm.c\n@@ -1,7 +1,9 @@\n /*\n   pwm.c - analogWrite implementation for esp8266\n \n-  Copyright (c) 2015 Hristo Gochkov. All rights reserved.\n+  Use the shared TIMER1 utilities to generate PWM signals\n+\n+  Original Copyright (c) 2015 Hristo Gochkov. All rights reserved.\n   This file is part of the esp8266 core for Arduino environment.\n \n   This library is free software; you can redistribute it and/or\n@@ -18,204 +20,58 @@\n   License along with this library; if not, write to the Free Software\n   Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n */\n-#include \"wiring_private.h\"\n-#include \"pins_arduino.h\"\n-#include \"c_types.h\"\n-#include \"eagle_soc.h\"\n-#include \"ets_sys.h\"\n-\n-#ifndef F_CPU\n-#define F_CPU 800000000L\n-#endif\n-\n-struct pwm_isr_table {\n-    uint8_t len;\n-    uint16_t steps[17];\n-    uint32_t masks[17];\n-};\n \n-struct pwm_isr_data {\n-    struct pwm_isr_table tables[2];\n-    uint8_t active;//0 or 1, which table is active in ISR\n-};\n+#include <Arduino.h>\n+#include \"core_esp8266_waveform.h\"\n \n-static struct pwm_isr_data _pwm_isr_data;\n \n-uint32_t pwm_mask = 0;\n-uint16_t pwm_values[17] = {0,};\n-uint32_t pwm_freq = 1000;\n-uint32_t pwm_range = PWMRANGE;\n+static uint32_t analogMap = 0;\n+static int32_t analogScale = 255;\n+static uint16_t analogFreq = 1000;\n \n-uint8_t pwm_steps_changed = 0;\n-uint32_t pwm_multiplier = 0;\n-\n-int pwm_sort_array(uint16_t a[], uint16_t al)\n-{\n-    uint16_t i, j;\n-    for (i = 1; i < al; i++) {\n-        uint16_t tmp = a[i];\n-        for (j = i; j >= 1 && tmp < a[j-1]; j--) {\n-            a[j] = a[j-1];\n-        }\n-        a[j] = tmp;\n-    }\n-    int bl = 1;\n-    for(i = 1; i < al; i++) {\n-        if(a[i] != a[i-1]) {\n-            a[bl++] = a[i];\n-        }\n-    }\n-    return bl;\n+extern void __analogWriteRange(uint32_t range) {\n+  if (range > 0) {\n+    analogScale = range;\n+  }\n }\n \n-uint32_t pwm_get_mask(uint16_t value)\n-{\n-    uint32_t mask = 0;\n-    int i;\n-    for(i=0; i<17; i++) {\n-        if((pwm_mask & (1 << i)) != 0 && pwm_values[i] == value) {\n-            mask |= (1 << i);\n-        }\n-    }\n-    return mask;\n+extern void __analogWriteFreq(uint32_t freq) {\n+  if (freq < 100) {\n+    analogFreq = 100;\n+  } else if (freq > 40000) {\n+    analogFreq = 40000;\n+  } else {\n+    analogFreq = freq;\n+  }\n }\n \n-void prep_pwm_steps()\n-{\n-    if(pwm_mask == 0) {\n-        return;\n+extern void __analogWrite(uint8_t pin, int val) {\n+  if (pin >= 16) {\n+    return;\n+  }\n+  uint32_t analogPeriod = 1000000L / analogFreq;\n+  if (val < 0) {\n+    val = 0;\n+  } else if (val > analogScale) {\n+    val = analogScale;\n+  }\n+\n+  analogMap &= ~(1 << pin);\n+  uint32_t high = (analogPeriod * val) / analogScale;\n+  uint32_t low = analogPeriod - high;\n+  if (low == 0) {\n+    stopWaveform(pin);\n+    digitalWrite(pin, HIGH);\n+  } else if (high == 0) {\n+    stopWaveform(pin);\n+    digitalWrite(pin, LOW);\n+  } else {\n+    if (startWaveform(pin, high, low, 0)) {\n+      analogMap |= (1 << pin);\n     }\n-\n-    int pwm_temp_steps_len = 0;\n-    uint16_t pwm_temp_steps[17];\n-    uint32_t pwm_temp_masks[17];\n-    uint32_t range = pwm_range;\n-\n-    if((F_CPU / ESP8266_CLOCK) == 1) {\n-        range /= 2;\n-    }\n-\n-    int i;\n-    for(i=0; i<17; i++) {\n-        if((pwm_mask & (1 << i)) != 0 && pwm_values[i] != 0) {\n-            pwm_temp_steps[pwm_temp_steps_len++] = pwm_values[i];\n-        }\n-    }\n-    pwm_temp_steps[pwm_temp_steps_len++] = range;\n-    pwm_temp_steps_len = pwm_sort_array(pwm_temp_steps, pwm_temp_steps_len) - 1;\n-    for(i=0; i<pwm_temp_steps_len; i++) {\n-        pwm_temp_masks[i] = pwm_get_mask(pwm_temp_steps[i]);\n-    }\n-    for(i=pwm_temp_steps_len; i>0; i--) {\n-        pwm_temp_steps[i] = pwm_temp_steps[i] - pwm_temp_steps[i-1];\n-    }\n-\n-    pwm_steps_changed = 0;\n-    struct pwm_isr_table *table = &(_pwm_isr_data.tables[!_pwm_isr_data.active]);\n-    table->len = pwm_temp_steps_len;\n-    ets_memcpy(table->steps, pwm_temp_steps, (pwm_temp_steps_len + 1) * 2);\n-    ets_memcpy(table->masks, pwm_temp_masks, pwm_temp_steps_len * 4);\n-    pwm_multiplier = ESP8266_CLOCK/(range * pwm_freq);\n-    pwm_steps_changed = 1;\n-}\n-\n-void ICACHE_RAM_ATTR pwm_timer_isr() //103-138\n-{\n-    struct pwm_isr_table *table = &(_pwm_isr_data.tables[_pwm_isr_data.active]);\n-    static uint8_t current_step = 0;\n-    TEIE &= ~TEIE1;//14\n-    T1I = 0;//9\n-    if(current_step < table->len) { //20/21\n-        uint32_t mask = table->masks[current_step] & pwm_mask;\n-        if(mask & 0xFFFF) {\n-            GPOC = mask & 0xFFFF;    //15/21\n-        }\n-        if(mask & 0x10000) {\n-            GP16O = 0;    //6/13\n-        }\n-        current_step++;//1\n-    } else {\n-        current_step = 0;//1\n-        if(pwm_mask == 0) { //12\n-            table->len = 0;\n-            return;\n-        }\n-        if(pwm_mask & 0xFFFF) {\n-            GPOS = pwm_mask & 0xFFFF;    //11\n-        }\n-        if(pwm_mask & 0x10000) {\n-            GP16O = 1;    //5/13\n-        }\n-        if(pwm_steps_changed) { //12/21\n-            _pwm_isr_data.active = !_pwm_isr_data.active;\n-            table = &(_pwm_isr_data.tables[_pwm_isr_data.active]);\n-            pwm_steps_changed = 0;\n-        }\n-    }\n-    T1L = (table->steps[current_step] * pwm_multiplier);//23\n-    TEIE |= TEIE1;//13\n-}\n-\n-void pwm_start_timer()\n-{\n-    timer1_disable();\n-    ETS_FRC_TIMER1_INTR_ATTACH(NULL, NULL);\n-    ETS_FRC_TIMER1_NMI_INTR_ATTACH(pwm_timer_isr);\n-    timer1_enable(TIM_DIV1, TIM_EDGE, TIM_SINGLE);\n-    timer1_write(1);\n-}\n-\n-void ICACHE_RAM_ATTR pwm_stop_pin(uint8_t pin)\n-{\n-    if(pwm_mask){\n-        pwm_mask &= ~(1 << pin);\n-        if(pwm_mask == 0) {\n-            ETS_FRC_TIMER1_NMI_INTR_ATTACH(NULL);\n-            timer1_disable();\n-            timer1_isr_init();\n-        }\n-    }\n-}\n-\n-extern void __analogWrite(uint8_t pin, int value)\n-{\n-    bool start_timer = false;\n-    if(value == 0) {\n-        digitalWrite(pin, LOW);\n-        prep_pwm_steps();\n-        return;\n-    }\n-    if((pwm_mask & (1 << pin)) == 0) {\n-        if(pwm_mask == 0) {\n-            memset(&_pwm_isr_data, 0, sizeof(_pwm_isr_data));\n-            start_timer = true;\n-        }\n-        pinMode(pin, OUTPUT);\n-        digitalWrite(pin, LOW);\n-        pwm_mask |= (1 << pin);\n-    }\n-    if((F_CPU / ESP8266_CLOCK) == 1) {\n-        value = (value+1) / 2;\n-    }\n-    pwm_values[pin] = value % (pwm_range + 1);\n-    prep_pwm_steps();\n-    if(start_timer) {\n-        pwm_start_timer();\n-    }\n-}\n-\n-extern void __analogWriteFreq(uint32_t freq)\n-{\n-    pwm_freq = freq;\n-    prep_pwm_steps();\n-}\n-\n-extern void __analogWriteRange(uint32_t range)\n-{\n-    pwm_range = range;\n-    prep_pwm_steps();\n+  }\n }\n \n-extern void analogWrite(uint8_t pin, int val) __attribute__ ((weak, alias(\"__analogWrite\")));\n-extern void analogWriteFreq(uint32_t freq) __attribute__ ((weak, alias(\"__analogWriteFreq\")));\n-extern void analogWriteRange(uint32_t range) __attribute__ ((weak, alias(\"__analogWriteRange\")));\n+extern void analogWrite(uint8_t pin, int val) __attribute__((weak, alias(\"__analogWrite\")));\n+extern void analogWriteFreq(uint32_t freq) __attribute__((weak, alias(\"__analogWriteFreq\")));\n+extern void analogWriteRange(uint32_t range) __attribute__((weak, alias(\"__analogWriteRange\")));\ndiff --git a/libraries/Servo/src/Servo.cpp b/libraries/Servo/src/Servo.cpp\nnew file mode 100644\nindex 0000000000..305d2c82a5\n--- /dev/null\n+++ b/libraries/Servo/src/Servo.cpp\n@@ -0,0 +1,129 @@\n+/*\n+Servo library using shared TIMER1 infrastructure\n+\n+Original Copyright (c) 2015 Michael C. Miller. All right reserved.\n+\n+This library is free software; you can redistribute it and/or\n+modify it under the terms of the GNU Lesser General Public\n+License as published by the Free Software Foundation; either\n+version 2.1 of the License, or (at your option) any later version.\n+\n+This library is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n+Lesser General Public License for more details.\n+\n+You should have received a copy of the GNU Lesser General Public\n+License along with this library; if not, write to the Free Software\n+Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n+*/\n+\n+#if defined(ESP8266)\n+\n+#include <Arduino.h>\n+#include <Servo.h>\n+#include \"core_esp8266_waveform.h\"\n+\n+// similiar to map but will have increased accuracy that provides a more\n+// symetric api (call it and use result to reverse will provide the original value)\n+int improved_map(int value, int minIn, int maxIn, int minOut, int maxOut)\n+{\n+    const int rangeIn = maxIn - minIn;\n+    const int rangeOut = maxOut - minOut;\n+    const int deltaIn = value - minIn;\n+    // fixed point math constants to improve accurancy of divide and rounding\n+    const int fixedHalfDecimal = 1;\n+    const int fixedDecimal = fixedHalfDecimal * 2;\n+\n+    return ((deltaIn * rangeOut * fixedDecimal) / (rangeIn) + fixedHalfDecimal) / fixedDecimal + minOut;\n+}\n+\n+//-------------------------------------------------------------------\n+// Servo class methods\n+\n+Servo::Servo()\n+{\n+  _attached = false;\n+  _valueUs = DEFAULT_PULSE_WIDTH;\n+  _minUs = MIN_PULSE_WIDTH;\n+  _maxUs = MAX_PULSE_WIDTH;\n+}\n+\n+Servo::~Servo() {\n+  detach();\n+}\n+\n+\n+uint8_t Servo::attach(int pin)\n+{\n+  return attach(pin, MIN_PULSE_WIDTH, MAX_PULSE_WIDTH);\n+}\n+\n+uint8_t Servo::attach(int pin, uint16_t minUs, uint16_t maxUs)\n+{\n+  if (!_attached) {\n+    digitalWrite(pin, LOW);\n+    pinMode(pin, OUTPUT);\n+    _pin = pin;\n+    _attached = true;\n+  }\n+\n+  // keep the min and max within 200-3000 us, these are extreme\n+  // ranges and should support extreme servos while maintaining\n+  // reasonable ranges\n+  _maxUs = max((uint16_t)250, min((uint16_t)3000, maxUs));\n+  _minUs = max((uint16_t)200, min(_maxUs, minUs));\n+\n+  write(_valueUs);\n+\n+  return pin;\n+}\n+\n+void Servo::detach()\n+{\n+  if (_attached) {\n+    stopWaveform(_pin);\n+    _attached = false;\n+    digitalWrite(_pin, LOW);\n+  }\n+}\n+\n+void Servo::write(int value)\n+{\n+  // treat values less than 544 as angles in degrees (valid values in microseconds are handled as microseconds)\n+  if (value < MIN_PULSE_WIDTH) {\n+    // assumed to be 0-180 degrees servo\n+    value = constrain(value, 0, 180);\n+    // writeMicroseconds will contrain the calculated value for us\n+    // for any user defined min and max, but we must use default min max\n+    value = improved_map(value, 0, 180, MIN_PULSE_WIDTH, MAX_PULSE_WIDTH);\n+  }\n+  writeMicroseconds(value);\n+}\n+\n+void Servo::writeMicroseconds(int value)\n+{\n+  _valueUs = value;\n+  if (_attached) {\n+    startWaveform(_pin, _valueUs, REFRESH_INTERVAL - _valueUs, 0);\n+  }\n+}\n+\n+int Servo::read() // return the value as degrees\n+{\n+  // read returns the angle for an assumed 0-180, so we calculate using \n+  // the normal min/max constants and not user defined ones\n+  return improved_map(readMicroseconds(), MIN_PULSE_WIDTH, MAX_PULSE_WIDTH, 0, 180);\n+}\n+\n+int Servo::readMicroseconds()\n+{\n+  return _valueUs;\n+}\n+\n+bool Servo::attached()\n+{\n+  return _attached;\n+}\n+\n+#endif\ndiff --git a/libraries/Servo/src/Servo.h b/libraries/Servo/src/Servo.h\nindex d4bf861baf..6b19a477bd 100644\n--- a/libraries/Servo/src/Servo.h\n+++ b/libraries/Servo/src/Servo.h\n@@ -1,6 +1,6 @@\n /*\n   Servo.h - Interrupt driven Servo library for Esp8266 using timers\n-  Copyright (c) 2015 Michael C. Miller. All right reserved.\n+  Original Copyright (c) 2015 Michael C. Miller. All right reserved.\n \n   This library is free software; you can redistribute it and/or\n   modify it under the terms of the GNU Lesser General Public\n@@ -23,13 +23,6 @@\n //   The servos are pulsed in the background using the value most recently\n //   written using the write() method.\n //\n-//   This library uses timer0 and timer1.\n-//   Note that timer0 may be repurposed when the first servo is attached.\n-//\n-//   Timers are seized as needed in groups of 12 servos - 24 servos use two\n-//   timers, there are only two timers for the esp8266 so the support stops here\n-//   The sequence used to sieze timers is defined in timers.h\n-//\n //   The methods are:\n //\n //   Servo - Class for manipulating servo motors connected to Arduino pins.\n@@ -58,15 +51,7 @@\n #define DEFAULT_PULSE_WIDTH  1500     // default pulse width when servo is attached\n #define REFRESH_INTERVAL    20000     // minumim time to refresh servos in microseconds \n \n-// NOTE: to maintain a strict refresh interval the user needs to not exceede 8 servos \n-#define SERVOS_PER_TIMER       12     // the maximum number of servos controlled by one timer \n-#define MAX_SERVOS   (ServoTimerSequence_COUNT  * SERVOS_PER_TIMER)\n-\n-#if defined(ESP8266)\n-\n-#include \"esp8266/ServoTimers.h\"\n-\n-#else\n+#if !defined(ESP8266)\n \n #error \"This library only supports esp8266 boards.\"\n \n@@ -76,6 +61,7 @@ class Servo\n {\n public:\n     Servo();\n+    ~Servo();\n     uint8_t attach(int pin);           // attach the given pin to the next free channel, sets pinMode, returns channel number or 0 if failure\n     uint8_t attach(int pin, uint16_t min, uint16_t max); // as above but also sets min and max values for writes. \n     void detach();\n@@ -85,9 +71,11 @@ class Servo\n     int readMicroseconds();            // returns current pulse width in microseconds for this servo (was read_us() in first release)\n     bool attached();                   // return true if this servo is attached, otherwise false \n private:\n-    uint8_t _servoIndex;               // index into the channel data for this servo\n+    bool     _attached;\n+    uint8_t  _pin;\n     uint16_t _minUs;                   \n     uint16_t _maxUs;                   \n+    uint16_t _valueUs;\n };\n \n #endif\ndiff --git a/libraries/Servo/src/esp8266/Servo.cpp b/libraries/Servo/src/esp8266/Servo.cpp\ndeleted file mode 100644\nindex 676aab2cc6..0000000000\n--- a/libraries/Servo/src/esp8266/Servo.cpp\n+++ /dev/null\n@@ -1,308 +0,0 @@\n-/*\n-Copyright (c) 2015 Michael C. Miller. All right reserved.\n-\n-This library is free software; you can redistribute it and/or\n-modify it under the terms of the GNU Lesser General Public\n-License as published by the Free Software Foundation; either\n-version 2.1 of the License, or (at your option) any later version.\n-\n-This library is distributed in the hope that it will be useful,\n-but WITHOUT ANY WARRANTY; without even the implied warranty of\n-MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n-Lesser General Public License for more details.\n-\n-You should have received a copy of the GNU Lesser General Public\n-License along with this library; if not, write to the Free Software\n-Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n-*/\n-\n-#if defined(ESP8266)\n-\n-#include <Arduino.h>\n-#include <Servo.h>\n-\n-\n-#define INVALID_SERVO         255     // flag indicating an invalid servo index\n-\n-const uint32_t c_CycleCompensation = 4;  // compensation us to trim adjust for digitalWrite delays\n-\n-#define INVALID_PIN           63    // flag indicating never attached servo\n-\n-struct ServoInfo  {\n-    uint8_t pin : 6;             // a pin number from 0 to 62, 63 reserved\n-    uint8_t isActive : 1;        // true if this channel is enabled, pin not pulsed if false\n-    uint8_t isDetaching : 1;     // true if this channel is being detached, maintains pulse integrity\n-};\n-\n-struct ServoState {\n-    ServoInfo info;\n-    volatile uint16_t usPulse;\n-};\n-\n-#if !defined (SERVO_EXCLUDE_TIMER0)\n-ServoTimer0 s_servoTimer0;\n-#endif\n-\n-#if !defined (SERVO_EXCLUDE_TIMER1)\n-ServoTimer1 s_servoTimer1;\n-#endif\n-\n-static ServoState s_servos[MAX_SERVOS];     // static array of servo structures\n-\n-static uint8_t s_servoCount = 0;            // the total number of attached s_servos\n-\n-\n-// inconvenience macros\n-#define SERVO_INDEX_TO_TIMER(servoIndex) ((ServoTimerSequence)(servoIndex / SERVOS_PER_TIMER)) // returns the timer controlling this servo\n-#define SERVO_INDEX(timerId, channel)  ((timerId * SERVOS_PER_TIMER) + channel)     // macro to access servo index by timer and channel\n-\n-// similiar to map but will have increased accuracy that provides a more\n-// symetric api (call it and use result to reverse will provide the original value)\n-// \n-int improved_map(int value, int minIn, int maxIn, int minOut, int maxOut)\n-{\n-    const int rangeIn = maxIn - minIn;\n-    const int rangeOut = maxOut - minOut;\n-    const int deltaIn = value - minIn;\n-    // fixed point math constants to improve accurancy of divide and rounding\n-    const int fixedHalfDecimal = 1;\n-    const int fixedDecimal = fixedHalfDecimal * 2;\n-\n-    return ((deltaIn * rangeOut * fixedDecimal) / (rangeIn) + fixedHalfDecimal) / fixedDecimal + minOut;\n-}\n-\n-//------------------------------------------------------------------------------\n-// Interrupt handler template method that takes a class that implements\n-// a standard set of methods for the timer abstraction\n-//------------------------------------------------------------------------------\n-template <class T>\n-static void Servo_Handler(T* timer) ICACHE_RAM_ATTR;\n-\n-template <class T>\n-static void Servo_Handler(T* timer)\n-{\n-    uint8_t servoIndex;\n-\n-    // clear interrupt\n-    timer->ResetInterrupt();\n-\n-    if (timer->isEndOfCycle()) {\n-        timer->StartCycle();\n-    }\n-    else {\n-        servoIndex = SERVO_INDEX(timer->timerId(), timer->getCurrentChannel());\n-        if (servoIndex < s_servoCount && s_servos[servoIndex].info.isActive) {\n-            // pulse this channel low if activated\n-            digitalWrite(s_servos[servoIndex].info.pin, LOW);\n-\n-            if (s_servos[servoIndex].info.isDetaching) {\n-                s_servos[servoIndex].info.isActive = false;\n-                s_servos[servoIndex].info.isDetaching = false;\n-            }\n-        }\n-        timer->nextChannel();\n-    }\n-\n-    servoIndex = SERVO_INDEX(timer->timerId(), timer->getCurrentChannel());\n-\n-    if (servoIndex < s_servoCount &&\n-        timer->getCurrentChannel() < SERVOS_PER_TIMER) {\n-        timer->SetPulseCompare(timer->usToTicks(s_servos[servoIndex].usPulse) - c_CycleCompensation);\n-\n-        if (s_servos[servoIndex].info.isActive) {\n-            if (s_servos[servoIndex].info.isDetaching) {\n-                // it was active, reset state and leave low\n-                s_servos[servoIndex].info.isActive = false;\n-                s_servos[servoIndex].info.isDetaching = false;\n-            }\n-            else {\n-                // its an active channel so pulse it high\n-                digitalWrite(s_servos[servoIndex].info.pin, HIGH);\n-            }\n-        }\n-    }\n-    else {\n-        if (!isTimerActive(timer->timerId())) {\n-            // no active running channels on this timer, stop the ISR\n-            finISR(timer->timerId());\n-        }\n-        else {\n-            // finished all channels so wait for the refresh period to expire before starting over\n-            // allow a few ticks to ensure the next match is not missed\n-            uint32_t refreshCompare = timer->usToTicks(REFRESH_INTERVAL);\n-            if ((timer->GetCycleCount() + c_CycleCompensation * 2) < refreshCompare) {\n-                timer->SetCycleCompare(refreshCompare - c_CycleCompensation);\n-            }\n-            else {\n-                // at least REFRESH_INTERVAL has elapsed\n-                timer->SetCycleCompare(timer->GetCycleCount() + c_CycleCompensation * 2);\n-            }\n-        }\n-\n-        timer->setEndOfCycle();\n-    }\n-}\n-\n-static void handler0() ICACHE_RAM_ATTR;\n-static void handler0()\n-{\n-    Servo_Handler<ServoTimer0>(&s_servoTimer0);\n-}\n-\n-static void handler1() ICACHE_RAM_ATTR;\n-static void handler1()\n-{\n-    Servo_Handler<ServoTimer1>(&s_servoTimer1);\n-}\n-\n-static void initISR(ServoTimerSequence timerId)\n-{\n-#if !defined (SERVO_EXCLUDE_TIMER0)\n-    if (timerId == ServoTimerSequence_Timer0)\n-        s_servoTimer0.InitInterrupt(&handler0);\n-#endif\n-#if !defined (SERVO_EXCLUDE_TIMER1)\n-    if (timerId == ServoTimerSequence_Timer1)\n-        s_servoTimer1.InitInterrupt(&handler1);\n-#endif\n-}\n-\n-static void finISR(ServoTimerSequence timerId) ICACHE_RAM_ATTR;\n-static void finISR(ServoTimerSequence timerId)\n-{\n-#if !defined (SERVO_EXCLUDE_TIMER0)\n-    if (timerId == ServoTimerSequence_Timer0)\n-        s_servoTimer0.StopInterrupt();\n-#endif\n-#if !defined (SERVO_EXCLUDE_TIMER1)\n-    if (timerId == ServoTimerSequence_Timer1)\n-        s_servoTimer1.StopInterrupt();\n-#endif\n-}\n-\n-// returns true if any servo is active on this timer\n-static boolean isTimerActive(ServoTimerSequence timerId) ICACHE_RAM_ATTR;\n-static boolean isTimerActive(ServoTimerSequence timerId)\n-{\n-    for (uint8_t channel = 0; channel < SERVOS_PER_TIMER; channel++) {\n-        if (s_servos[SERVO_INDEX(timerId, channel)].info.isActive) {\n-            return true;\n-        }\n-    }\n-    return false;\n-}\n-\n-//-------------------------------------------------------------------\n-// Servo class methods\n-\n-Servo::Servo()\n-{\n-    if (s_servoCount < MAX_SERVOS) {\n-        // assign a servo index to this instance\n-        _servoIndex = s_servoCount++;\n-        // store default values\n-        s_servos[_servoIndex].usPulse = DEFAULT_PULSE_WIDTH;\n-\n-        // set default _minUs and _maxUs incase write() is called before attach()\n-        _minUs = MIN_PULSE_WIDTH;\n-        _maxUs = MAX_PULSE_WIDTH;\n-\n-        s_servos[_servoIndex].info.isActive = false;\n-        s_servos[_servoIndex].info.isDetaching = false;\n-        s_servos[_servoIndex].info.pin = INVALID_PIN;\n-    }\n-    else {\n-        _servoIndex = INVALID_SERVO;  // too many servos\n-    }\n-}\n-\n-uint8_t Servo::attach(int pin)\n-{\n-    return attach(pin, MIN_PULSE_WIDTH, MAX_PULSE_WIDTH);\n-}\n-\n-uint8_t Servo::attach(int pin, uint16_t minUs, uint16_t maxUs)\n-{\n-    ServoTimerSequence timerId;\n-\n-    if (_servoIndex < MAX_SERVOS) {\n-        if (s_servos[_servoIndex].info.pin == INVALID_PIN) {\n-            pinMode(pin, OUTPUT);       // set servo pin to output\n-            digitalWrite(pin, LOW);\n-            s_servos[_servoIndex].info.pin = pin;\n-        }\n-\n-        // keep the min and max within 200-3000 us, these are extreme\n-        // ranges and should support extreme servos while maintaining\n-        // reasonable ranges\n-        _maxUs = max((uint16_t)250, min((uint16_t)3000, maxUs));\n-        _minUs = max((uint16_t)200, min(_maxUs, minUs));\n-\n-        // initialize the timerId if it has not already been initialized\n-        timerId = SERVO_INDEX_TO_TIMER(_servoIndex);\n-        if (!isTimerActive(timerId)) {\n-            initISR(timerId);\n-        }\n-        s_servos[_servoIndex].info.isDetaching = false;\n-        s_servos[_servoIndex].info.isActive = true;  // this must be set after the check for isTimerActive\n-    }\n-    return _servoIndex;\n-}\n-\n-void Servo::detach()\n-{\n-    if (s_servos[_servoIndex].info.isActive) {\n-        s_servos[_servoIndex].info.isDetaching = true;\n-    }\n-}\n-\n-void Servo::write(int value)\n-{\n-    // treat values less than 544 as angles in degrees (valid values in microseconds are handled as microseconds)\n-    if (value < MIN_PULSE_WIDTH) {\n-        // assumed to be 0-180 degrees servo\n-        value = constrain(value, 0, 180);\n-        // writeMicroseconds will contrain the calculated value for us\n-        // for any user defined min and max, but we must use default min max\n-        value = improved_map(value, 0, 180, MIN_PULSE_WIDTH, MAX_PULSE_WIDTH);\n-    }\n-    writeMicroseconds(value);\n-}\n-\n-void Servo::writeMicroseconds(int value)\n-{\n-    // ensure channel is valid\n-    if ((_servoIndex < MAX_SERVOS)) {\n-        // ensure pulse width is valid\n-        value = constrain(value, _minUs, _maxUs);\n-\n-        s_servos[_servoIndex].usPulse = value;\n-    }\n-}\n-\n-int Servo::read() // return the value as degrees\n-{\n-    // read returns the angle for an assumed 0-180, so we calculate using \n-    // the normal min/max constants and not user defined ones\n-    return improved_map(readMicroseconds(), MIN_PULSE_WIDTH, MAX_PULSE_WIDTH, 0, 180);\n-}\n-\n-int Servo::readMicroseconds()\n-{\n-    unsigned int pulsewidth;\n-    if (_servoIndex != INVALID_SERVO) {\n-        pulsewidth = s_servos[_servoIndex].usPulse;\n-    }\n-    else {\n-        pulsewidth = 0;\n-    }\n-\n-    return pulsewidth;\n-}\n-\n-bool Servo::attached()\n-{\n-    return s_servos[_servoIndex].info.isActive;\n-}\n-\n-#endif\ndiff --git a/libraries/Servo/src/esp8266/ServoTimers.h b/libraries/Servo/src/esp8266/ServoTimers.h\ndeleted file mode 100644\nindex 90a19e1651..0000000000\n--- a/libraries/Servo/src/esp8266/ServoTimers.h\n+++ /dev/null\n@@ -1,225 +0,0 @@\n-/*\n-  Copyright (c) 2015 Michael C. Miller. All right reserved.\n-\n-  This library is free software; you can redistribute it and/or\n-  modify it under the terms of the GNU Lesser General Public\n-  License as published by the Free Software Foundation; either\n-  version 2.1 of the License, or (at your option) any later version.\n-\n-  This library is distributed in the hope that it will be useful,\n-  but WITHOUT ANY WARRANTY; without even the implied warranty of\n-  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n-  Lesser General Public License for more details.\n-\n-  You should have received a copy of the GNU Lesser General Public\n-  License along with this library; if not, write to the Free Software\n-  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n-  */\n-\n-//\n-// Defines for timer abstractions used with  Servo library\n-//\n-// ServoTimerSequence enumerates the sequence that the timers should be allocated\n-// ServoTimerSequence_COUNT indicates how many timers are available.\n-//\n-enum ServoTimerSequence {\n-\n-#if !defined (SERVO_EXCLUDE_TIMER0)\n-    ServoTimerSequence_Timer0,\n-#endif\n-\n-#if !defined (SERVO_EXCLUDE_TIMER1)\n-    ServoTimerSequence_Timer1,\n-#endif\n-\n-    ServoTimerSequence_COUNT\n-};\n-\n-\n-#if !defined (SERVO_EXCLUDE_TIMER0)\n-\n-struct ServoTimer0\n-{\n-public:\n-    ServoTimer0()\n-    {\n-        setEndOfCycle();\n-    }\n-\n-\n-    uint32_t usToTicks(uint32_t us) const\n-    {\n-        return (clockCyclesPerMicrosecond() * us);     // converts microseconds to tick\n-    }\n-    uint32_t ticksToUs(uint32_t ticks) const\n-    {\n-        return (ticks / clockCyclesPerMicrosecond()); // converts from ticks back to microseconds\n-    }\n-\n-    void InitInterrupt(timercallback handler)\n-    {\n-        timer0_isr_init();\n-        timer0_attachInterrupt(handler);\n-    }\n-\n-    void ResetInterrupt() {}; // timer0 doesn't have a clear interrupt\n-\n-    void StopInterrupt()\n-    {\n-        timer0_detachInterrupt();\n-    }\n-\n-    void SetPulseCompare(uint32_t value)\n-    {\n-        timer0_write(ESP.getCycleCount() + value);\n-    }\n-\n-    void SetCycleCompare(uint32_t value)\n-    {\n-        timer0_write(_cycleStart + value);\n-    }\n-\n-    uint32_t GetCycleCount() const\n-    {\n-        return ESP.getCycleCount() - _cycleStart;\n-    }\n-\n-\n-    void StartCycle()\n-    {\n-        _cycleStart = ESP.getCycleCount();\n-        _currentChannel = 0;\n-    }\n-\n-    int8_t getCurrentChannel() const\n-    {\n-        return _currentChannel;\n-    }\n-\n-    void nextChannel()\n-    {\n-        _currentChannel++;\n-    }\n-\n-    void setEndOfCycle()\n-    {\n-        _currentChannel = -1;\n-    }\n-\n-    bool isEndOfCycle() const\n-    {\n-        return (_currentChannel == -1);\n-    }\n-\n-    ServoTimerSequence timerId() const\n-    {\n-        return ServoTimerSequence_Timer0;\n-    }\n-\n-private:\n-    volatile uint32_t _cycleStart;\n-    volatile int8_t _currentChannel;\n-};\n-\n-#endif\n-\n-\n-#if !defined (SERVO_EXCLUDE_TIMER1)\n-\n-#define TIMER1_TICKS_PER_US (APB_CLK_FREQ / 1000000L)\n-\n-struct ServoTimer1\n-{\n-public:\n-    ServoTimer1()\n-    {\n-        setEndOfCycle();\n-    }\n-\n-\n-    uint32_t usToTicks(uint32_t us) const\n-    {\n-        return (TIMER1_TICKS_PER_US / 16 * us);     // converts microseconds to tick\n-    }\n-    uint32_t ticksToUs(uint32_t ticks) const\n-    {\n-        return (ticks / TIMER1_TICKS_PER_US * 16); // converts from ticks back to microseconds\n-    }\n-\n-    void InitInterrupt(timercallback handler)\n-    {\n-        timer1_isr_init();\n-        timer1_attachInterrupt(handler);\n-        timer1_enable(TIM_DIV16, TIM_EDGE, TIM_SINGLE);\n-        timer1_write(usToTicks(REFRESH_INTERVAL));\n-    }\n-\n-    void ResetInterrupt() {}; // timer1 doesn't have a clear interrupt\n-\n-    void StopInterrupt()\n-    {\n-        timer1_detachInterrupt();\n-    }\n-\n-    void SetPulseCompare(uint32_t value)\n-    {\n-        _cycleTicks += value;\n-        timer1_write(value);\n-    }\n-\n-    void SetCycleCompare(uint32_t value)\n-    {\n-        if (value <= _cycleTicks)\n-        {\n-            value = 1;\n-        }\n-        else\n-        {\n-            value -= _cycleTicks;\n-        }\n-        timer1_write(value);\n-    }\n-\n-    uint32_t GetCycleCount() const\n-    {\n-        return _cycleTicks;\n-    }\n-\n-\n-    void StartCycle()\n-    {\n-        _cycleTicks = 0;\n-        _currentChannel = 0;\n-    }\n-\n-    int8_t getCurrentChannel() const\n-    {\n-        return _currentChannel;\n-    }\n-\n-    void nextChannel()\n-    {\n-        _currentChannel++;\n-    }\n-\n-    void setEndOfCycle()\n-    {\n-        _currentChannel = -1;\n-    }\n-\n-    bool isEndOfCycle() const\n-    {\n-        return (_currentChannel == -1);\n-    }\n-\n-    ServoTimerSequence timerId() const\n-    {\n-        return ServoTimerSequence_Timer1;\n-    }\n-\n-private:\n-    volatile uint32_t _cycleTicks;\n-    volatile int8_t _currentChannel;\n-};\n-\n-#endif\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "### Feedback Summary:\n\n1. **Pulse Width Limitation**: The current implementation restricts the minimum pulse width to ~2-3 \u00b5s for `analogWrite`, requiring changes to allow shorter, high-accuracy pulses especially for values <1%.\n\n2. **Timer Structure**: Consolidate TIMER1 usage into a shared waveform generation interrupt to enhance resource efficiency. Tone, `analogWrite`, and Servo should call this shared resource.\n\n3. **ISR Design**: Transition ISR callback to return `uint32_t` for better timer management. Return specific ticks for jitter adjustments, and ensure a function exists for enabling/disabling timers.\n\n4. **CPU Cycle Management**: Acknowledge that certain operations, like pin mode setting, may introduce delays, suggesting need for smarter timer management to reduce overhead.\n\n5. **Shared Timers**: Assess possibilities for creating multiple virtual timers from a primary timer without affecting tone or PWM performance.\n\n6. **Jitter Issues**: Identify and mitigate jitter issues with overlapping timers, utilizing a high-accuracy timer for more consistent output.\n\n7. **Testing Stability**: Emphasize the need for rigorous stability testing with the new architecture, particularly regarding the use of ticker callbacks during music playback to avoid latency issues.\n\n8. **Project Optimization**: Consider moving critical PWM and tone operations to a more robust timer management system to address ongoing reset and jitter issues for better performance in applications like adaptive backlighting.\n\nEnsure to validate performance across various testing scenarios while aligning waveform generation requirements with user needs."
      }
    ],
    "codediff_length": 49890
  },
  {
    "index": 46,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/libraries/Servo/src/Servo.cpp b/libraries/Servo/src/Servo.cpp\nindex 3dc2c7753e..aff9afebbe 100644\n--- a/libraries/Servo/src/Servo.cpp\n+++ b/libraries/Servo/src/Servo.cpp\n@@ -27,15 +27,15 @@ Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n uint32_t Servo::_servoMap = 0;\n \n // similiar to map but will have increased accuracy that provides a more\n-// symetric api (call it and use result to reverse will provide the original value)\n+// symmetrical api (call it and use result to reverse will provide the original value)\n int improved_map(int value, int minIn, int maxIn, int minOut, int maxOut)\n {\n     const int rangeIn = maxIn - minIn;\n     const int rangeOut = maxOut - minOut;\n     const int deltaIn = value - minIn;\n     // fixed point math constants to improve accurancy of divide and rounding\n-    const int fixedHalfDecimal = 1;\n-    const int fixedDecimal = fixedHalfDecimal * 2;\n+    constexpr int fixedHalfDecimal = 1;\n+    constexpr int fixedDecimal = fixedHalfDecimal * 2;\n \n     return ((deltaIn * rangeOut * fixedDecimal) / (rangeIn) + fixedHalfDecimal) / fixedDecimal + minOut;\n }\n@@ -46,9 +46,9 @@ int improved_map(int value, int minIn, int maxIn, int minOut, int maxOut)\n Servo::Servo()\n {\n   _attached = false;\n-  _valueUs = DEFAULT_PULSE_WIDTH;\n-  _minUs = MIN_PULSE_WIDTH;\n-  _maxUs = MAX_PULSE_WIDTH;\n+  _valueUs = DEFAULT_NEUTRAL_PULSE_WIDTH;\n+  _minUs = DEFAULT_MIN_PULSE_WIDTH;\n+  _maxUs = DEFAULT_MAX_PULSE_WIDTH;\n }\n \n Servo::~Servo() {\n@@ -58,10 +58,15 @@ Servo::~Servo() {\n \n uint8_t Servo::attach(int pin)\n {\n-  return attach(pin, MIN_PULSE_WIDTH, MAX_PULSE_WIDTH);\n+  return attach(pin, DEFAULT_MIN_PULSE_WIDTH, DEFAULT_MAX_PULSE_WIDTH);\n }\n \n uint8_t Servo::attach(int pin, uint16_t minUs, uint16_t maxUs)\n+{\n+  return attach(pin, minUs, maxUs, _valueUs);\n+}\n+\n+uint8_t Servo::attach(int pin, uint16_t minUs, uint16_t maxUs, int value)\n {\n   if (!_attached) {\n     digitalWrite(pin, LOW);\n@@ -76,7 +81,7 @@ uint8_t Servo::attach(int pin, uint16_t minUs, uint16_t maxUs)\n   _maxUs = max((uint16_t)250, min((uint16_t)3000, maxUs));\n   _minUs = max((uint16_t)200, min(_maxUs, minUs));\n \n-  write(_valueUs);\n+  write(value);\n \n   return pin;\n }\n@@ -85,20 +90,20 @@ void Servo::detach()\n {\n   if (_attached) {\n     _servoMap &= ~(1 << _pin);\n+    startWaveform(_pin, 0, REFRESH_INTERVAL, 1);\n+    delay(REFRESH_INTERVAL / 1000); // long enough to complete active period under all circumstances.\n     stopWaveform(_pin);\n     _attached = false;\n-    digitalWrite(_pin, LOW);\n+    _valueUs = DEFAULT_NEUTRAL_PULSE_WIDTH;\n   }\n }\n \n void Servo::write(int value)\n {\n-  // treat values less than 544 as angles in degrees (valid values in microseconds are handled as microseconds)\n-  if (value < _minUs) {\n+  // treat any value less than 200 as angle in degrees (values equal or larger are handled as microseconds)\n+  if (value < 200) {\n     // assumed to be 0-180 degrees servo\n     value = constrain(value, 0, 180);\n-    // writeMicroseconds will contrain the calculated value for us\n-    // for any user defined min and max, but we must use default min max\n     value = improved_map(value, 0, 180, _minUs, _maxUs);\n   }\n   writeMicroseconds(value);\n@@ -106,6 +111,7 @@ void Servo::write(int value)\n \n void Servo::writeMicroseconds(int value)\n {\n+  value = constrain(value, _minUs, _maxUs);\n   _valueUs = value;\n   if (_attached) {\n     _servoMap &= ~(1 << _pin);\n@@ -117,8 +123,7 @@ void Servo::writeMicroseconds(int value)\n \n int Servo::read() // return the value as degrees\n {\n-  // read returns the angle for an assumed 0-180, so we calculate using \n-  // the normal min/max constants and not user defined ones\n+  // read returns the angle for an assumed 0-180\n   return improved_map(readMicroseconds(), _minUs, _maxUs, 0, 180);\n }\n \ndiff --git a/libraries/Servo/src/Servo.h b/libraries/Servo/src/Servo.h\nindex 45f593c0d8..38d78709a4 100644\n--- a/libraries/Servo/src/Servo.h\n+++ b/libraries/Servo/src/Servo.h\n@@ -27,9 +27,9 @@\n //\n //   Servo - Class for manipulating servo motors connected to Arduino pins.\n //\n-//   attach(pin )  - Attaches a servo motor to an i/o pin.\n-//   attach(pin, min, max  ) - Attaches to a pin setting min and max values in microseconds\n-//   default min is 544, max is 2400\n+//   attach(pin)  - Attaches a servo motor to an i/o pin.\n+//   attach(pin, min, max) - Attaches to a pin setting min and max values in microseconds\n+//   default min is 1000, max is 2000\n //\n //   write()     - Sets the servo angle in degrees.  (invalid angle that is valid as pulse in microseconds is treated as microseconds)\n //   writeMicroseconds() - Sets the servo pulse width in microseconds\n@@ -44,13 +44,17 @@\n \n #include <Arduino.h>\n \n-// the following are in us (microseconds)\n-//\n-#define MIN_PULSE_WIDTH       544     // the shortest pulse sent to a servo  \n-#define MAX_PULSE_WIDTH      2400     // the longest pulse sent to a servo \n-#define DEFAULT_PULSE_WIDTH  1500     // default pulse width when servo is attached\n-#define REFRESH_INTERVAL    20000     // minumim time to refresh servos in microseconds \n-#define MAX_SERVOS             12\n+// The following values are in us (microseconds).\n+// Since the defaults can be overwritten in the new attach() member function,\n+// they were modified from the Arduino AVR defaults to be in the safe range\n+// of publically available specifications. While this implies that many 180\u00b0\n+// servos do not operate the full 0\u00b0 to 180\u00b0 sweep using these, it also prevents\n+// unsuspecting damage. For Arduino AVR, the same change is being discussed.\n+#define DEFAULT_MIN_PULSE_WIDTH      1000 // uncalibrated default, the shortest duty cycle sent to a servo\n+#define DEFAULT_MAX_PULSE_WIDTH      2000 // uncalibrated default, the longest duty cycle sent to a servo \n+#define DEFAULT_NEUTRAL_PULSE_WIDTH  1500 // default duty cycle when servo is attached\n+#define REFRESH_INTERVAL            20000 // classic default period to refresh servos in microseconds \n+#define MAX_SERVOS                      9 // D0-D8\n \n #if !defined(ESP8266)\n \n@@ -63,8 +67,16 @@ class Servo\n public:\n     Servo();\n     ~Servo();\n-    uint8_t attach(int pin);           // attach the given pin to the next free channel, sets pinMode, returns channel number or 0 if failure\n-    uint8_t attach(int pin, uint16_t min, uint16_t max); // as above but also sets min and max values for writes. \n+    // attach the given pin to the next free channel, sets pinMode, returns channel number or 0 if failure.\n+    // returns channel number or 0 if failure.\n+    uint8_t attach(int pin);\n+    // attach the given pin to the next free channel, sets pinMode, min, and max values for write().\n+    // returns channel number or 0 if failure.\n+    uint8_t attach(int pin, uint16_t min, uint16_t max);\n+    // attach the given pin to the next free channel, sets pinMode, min, and max values for write(),\n+    // and sets the initial value, the same as write().\n+    // returns channel number or 0 if failure.\n+    uint8_t attach(int pin, uint16_t min, uint16_t max, int value);\n     void detach();\n     void write(int value);             // if value is < 200 its treated as an angle, otherwise as pulse width in microseconds \n     void writeMicroseconds(int value); // Write pulse width in microseconds \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "- The trim pots should not exceed a 20% deviation from standard timing without justification. Adjust the default values to stay within this range. Users can recompile if specific brands require wider timings.\n- Introduce exposed variables for min/max pulse width settings in the user's code, e.g., `#define MIN_PULSE_WIDTH 550; #define MAX_PULSE_WIDTH 2330`, with defaults reverting to 1000us/2000us if not overridden.\n- The `detach` function currently uses a 20 ms delay, which is suboptimal. Revise the stopWaveform interrupt implementation to ensure the last pulse is sent correctly without delays. \n- Consider adding a deprecation warning for the `attach(int pin)` method to encourage users to switch to a more robust API.\n- Update the PR to include documentation on the rationale behind default values and deprecation notices."
      }
    ],
    "codediff_length": 7283
  },
  {
    "index": 47,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/CMake/AbseilHelpers.cmake b/CMake/AbseilHelpers.cmake\nnew file mode 100644\nindex 00000000000..9e1772bb5f0\n--- /dev/null\n+++ b/CMake/AbseilHelpers.cmake\n@@ -0,0 +1,156 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+include(CMakeParseArguments)\n+\n+\n+#\n+# create a library in the absl namespace\n+#\n+# parameters\n+# SOURCES : sources files for the library\n+# PUBLIC_LIBRARIES: targets and flags for linking phase\n+# PRIVATE_COMPILE_FLAGS: compile flags for the library. Will not be exported.\n+# EXPORT_NAME: export name for the absl:: target export\n+# TARGET: target name\n+#\n+# create a target associated to <NAME>\n+# libraries are installed under CMAKE_INSTALL_FULL_LIBDIR by default\n+#\n+function(absl_library)\n+  cmake_parse_arguments(ABSL_LIB\n+    \"DISABLE_INSTALL\" # keep that in case we want to support installation one day\n+    \"TARGET;EXPORT_NAME\"\n+    \"SOURCES;PUBLIC_LIBRARIES;PRIVATE_COMPILE_FLAGS;PUBLIC_INCLUDE_DIRS;PRIVATE_INCLUDE_DIRS\"\n+    ${ARGN}\n+  )\n+\n+  set(_NAME ${ABSL_LIB_TARGET})\n+  string(TOUPPER ${_NAME} _UPPER_NAME)\n+\n+  add_library(${_NAME} STATIC ${ABSL_LIB_SOURCES})\n+\n+  target_compile_options(${_NAME} PRIVATE ${ABSL_COMPILE_CXXFLAGS} ${ABSL_LIB_PRIVATE_COMPILE_FLAGS})\n+  target_link_libraries(${_NAME} PUBLIC ${ABSL_LIB_PUBLIC_LIBRARIES})\n+  target_include_directories(${_NAME}\n+    PUBLIC ${ABSL_COMMON_INCLUDE_DIRS} ${ABSL_LIB_PUBLIC_INCLUDE_DIRS}\n+    PRIVATE ${ABSL_LIB_PRIVATE_INCLUDE_DIRS}\n+  )\n+\n+  if(ABSL_LIB_EXPORT_NAME)\n+    add_library(absl::${ABSL_LIB_EXPORT_NAME} ALIAS ${_NAME})\n+  endif()\n+endfunction()\n+\n+\n+\n+#\n+# header only virtual target creation\n+#\n+function(absl_header_library)\n+  cmake_parse_arguments(ABSL_HO_LIB\n+    \"DISABLE_INSTALL\"\n+    \"EXPORT_NAME;TARGET\"\n+    \"PUBLIC_LIBRARIES;PRIVATE_COMPILE_FLAGS;PUBLIC_INCLUDE_DIRS;PRIVATE_INCLUDE_DIRS\"\n+    ${ARGN}\n+  )\n+\n+  set(_NAME ${ABSL_HO_LIB_TARGET})\n+\n+  set(__dummy_header_only_lib_file \"${CMAKE_CURRENT_BINARY_DIR}/${_NAME}_header_only_dummy.cc\")\n+\n+  if(NOT EXISTS ${__dummy_header_only_lib_file})\n+    file(WRITE ${__dummy_header_only_lib_file}\n+      \"\\\n+       /* generated file for header-only cmake target */ \\\n+       \\\n+       // single meaningless symbol \\\n+       void __${_NAME}__header_fakesym() {} \\\n+       \\\n+      \"\n+    )\n+  endif()\n+\n+\n+  add_library(${_NAME} ${__dummy_header_only_lib_file})\n+  target_link_libraries(${_NAME} PUBLIC ${ABSL_HO_LIB_PUBLIC_LIBRARIES})\n+  target_include_directories(${_NAME}\n+    PUBLIC ${ABSL_COMMON_INCLUDE_DIRS} ${ABSL_HO_LIB_PUBLIC_INCLUDE_DIRS}\n+    PRIVATE ${ABSL_HO_LIB_PRIVATE_INCLUDE_DIRS}\n+  )\n+\n+  if(ABSL_HO_LIB_EXPORT_NAME)\n+    add_library(absl::${ABSL_HO_LIB_EXPORT_NAME} ALIAS ${_NAME})\n+  endif()\n+\n+endfunction()\n+\n+\n+#\n+# create an abseil unit_test and add it to the executed test list\n+#\n+# parameters\n+# TARGET: target name prefix\n+# SOURCES: sources files for the tests\n+# PUBLIC_LIBRARIES: targets and flags for linking phase.\n+# PRIVATE_COMPILE_FLAGS: compile flags for the test. Will not be exported.\n+#\n+# create a target associated to <NAME>_bin\n+#\n+# all tests will be register for execution with add_test()\n+#\n+# test compilation and execution is disable when BUILD_TESTING=OFF\n+#\n+function(absl_test)\n+\n+  cmake_parse_arguments(ABSL_TEST\n+    \"\"\n+    \"TARGET\"\n+    \"SOURCES;PUBLIC_LIBRARIES;PRIVATE_COMPILE_FLAGS;PUBLIC_INCLUDE_DIRS\"\n+    ${ARGN}\n+  )\n+\n+\n+  if(BUILD_TESTING)\n+\n+    set(_NAME ${ABSL_TEST_TARGET})\n+    string(TOUPPER ${_NAME} _UPPER_NAME)\n+\n+    add_executable(${_NAME}_bin ${ABSL_TEST_SOURCES})\n+\n+    target_compile_options(${_NAME}_bin PRIVATE ${ABSL_COMPILE_CXXFLAGS} ${ABSL_TEST_PRIVATE_COMPILE_FLAGS})\n+    target_link_libraries(${_NAME}_bin PUBLIC ${ABSL_TEST_PUBLIC_LIBRARIES} ${ABSL_TEST_COMMON_LIBRARIES})\n+    target_include_directories(${_NAME}_bin\n+      PUBLIC ${ABSL_COMMON_INCLUDE_DIRS} ${ABSL_TEST_PUBLIC_INCLUDE_DIRS}\n+      PRIVATE ${GMOCK_INCLUDE_DIRS} ${GTEST_INCLUDE_DIRS}\n+    )\n+\n+    add_test(${_NAME}_test ${_NAME}_bin)\n+  endif(BUILD_TESTING)\n+\n+endfunction()\n+\n+\n+\n+\n+function(check_target my_target)\n+\n+  if(NOT TARGET ${my_target})\n+    message(FATAL_ERROR \" ABSL: compiling absl requires a ${my_target} CMake target in your project,\n+                   see CMake/README.md for more details\")\n+  endif(NOT TARGET ${my_target})\n+\n+endfunction()\ndiff --git a/CMake/README.md b/CMake/README.md\nnew file mode 100644\nindex 00000000000..21633f14d51\n--- /dev/null\n+++ b/CMake/README.md\n@@ -0,0 +1,73 @@\n+\n+## Abseil CMake build instructions\n+\n+\n+### Recommended usage : incorporate Abseil into an  CMake project\n+\n+  For API / ABI compatibility reasons, it is recommended to build\n+  and use abseil in a subdirectory of your project or as an embedded\n+  dependency\n+\n+  This is similar to the recommended usage of the googletest framework\n+  ( https://github.com/google/googletest/blob/master/googletest/README.md )\n+\n+  Build and use step-by-step\n+\n+\n+  1- Download abseil and copy it in a sub-directory in your project.\n+      or add abseil as a git-submodule in your project\n+\n+  2- If not done yet, download and copy in your project the two dependencies of\n+      abseil `cctz` and `googletest`\n+\n+    * cctz  https://github.com/google/cctz\n+    * googletest https://github.com/google/googletest\n+\n+  3- You can then use the cmake command `add_subdirectory()` to include\n+  abseil directly and use the abseil targets in your project.\n+\n+    Note: Abseil requires CCTZ and the googletest framework. Consequently,\n+    the targets  `gtest`, `gtest_main`, `gmock` and `cctz` need\n+    to be declared in your project before including abseil with `add_subdirectory`.\n+\n+\n+  4- Add the absl:: target you wish to use to the `target_link_libraries()`\n+    section of your executable or of your library\n+\n+\n+      Here is a short CMakeLists.txt example of a possible project file\n+      using abseil\n+\n+      cmake_minimum_required(VERSION 2.8.12)\n+      project(my_project)\n+\n+      set(CMAKE_CXX_FLAGS \"-std=c++11 -stdlib=libc++ ${CMAKE_CXX_FLAGS}\")\n+\n+      add_subdirectory(googletest)\n+      add_subdirectory(cctz)\n+      add_subdirectory(abseil-cpp)\n+\n+      add_executable(my_exe source.cpp)\n+      target_link_libraries(my_exe absl::base absl::synchronization absl::strings)\n+\n+\n+You will need to create your own CMake files for cctz until https://github.com/google/cctz/pull/54 lands.  As of this writing, that pull request requires -DBUILD_TESTING=OFF as it doesn't correctly export cctz's dependency on Google Benchmark.\n+    \n+    You will find here a non exhaustive list of absl public targets\n+\n+      absl::base\n+      absl::algorithm\n+      absl::container\n+      absl::debugging\n+      absl::memory\n+      absl::meta\n+      absl::numeric\n+      absl::strings\n+      absl::synchronization\n+      absl::time\n+      absl::utility\n+\n+\n+\n+\n+\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..ddd60502d46\n--- /dev/null\n+++ b/CMakeLists.txt\n@@ -0,0 +1,79 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+cmake_minimum_required(VERSION 2.8.12)\n+project(absl)\n+\n+# enable ctest\n+include(CTest)\n+\n+list(APPEND CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/CMake)\n+\n+include(GNUInstallDirs)\n+include(AbseilHelpers)\n+\n+\n+# config options\n+set(ABSL_STD_CXX_FLAG \"-std=c++11\" CACHE STRING \"c++ std flag (default: c++11)\")\n+\n+\n+\n+##\n+## Using absl targets\n+##\n+## all public absl targets are\n+## exported with the absl:: prefix\n+##\n+## e.g absl::base absl::synchronization absl::strings ....\n+##\n+## DO NOT rely on the internal targets outside of the prefix\n+\n+\n+# include current path\n+list(APPEND ABSL_COMMON_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR})\n+\n+# -std=X\n+set(CMAKE_CXX_FLAGS \"${ABSL_STD_CXX_FLAG} ${CMAKE_CXX_FLAGS}\")\n+set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_WARNING_VLA} ${CMAKE_CXX_FLAGS} \")\n+\n+\n+# find dependencies\n+## pthread\n+find_package(Threads REQUIRED)\n+\n+# commented: used only for standalone test\n+#add_subdirectory(cctz)\n+#add_subdirectory(googletest)\n+\n+## check targets\n+check_target(cctz)\n+check_target(gtest)\n+check_target(gtest_main)\n+check_target(gmock)\n+\n+# -fexceptions\n+set(ABSL_EXCEPTIONS_FLAG \"${CMAKE_CXX_EXCEPTIONS}\")\n+\n+# fix stuff\n+set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FIX_MSVC} ${CMAKE_CXX_FLAGS}\") \n+\n+list(APPEND ABSL_TEST_COMMON_LIBRARIES\n+  gtest_main\n+  gtest\n+  gmock\n+  ${CMAKE_THREAD_LIBS_INIT}\n+)\n+\n+add_subdirectory(absl)\ndiff --git a/README.md b/README.md\nindex 9d75b67d443..dcd01ac6926 100644\n--- a/README.md\n+++ b/README.md\n@@ -10,6 +10,7 @@ standard library.\n - [Codemap](#codemap)\n - [License](#license)\n - [Links](#links)\n+- [Build with cmake](#cmake)\n \n <a name=\"about\"></a>\n ## About Abseil\n@@ -84,3 +85,8 @@ For more information about Abseil:\n * Peruse our\n   [Abseil Compatibility Guarantees](http://abseil.io/about/compatibility) to\n   understand both what we promise to you, and what we expect of you in return.\n+\n+<a name=\"cmake\"></a>\n+## Build with CMake\n+\n+Please check the [CMake build instructions](CMake/README.md)\ndiff --git a/absl/CMakeLists.txt b/absl/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..689f64e258b\n--- /dev/null\n+++ b/absl/CMakeLists.txt\n@@ -0,0 +1,30 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\n+\n+add_subdirectory(base)\n+add_subdirectory(algorithm)\n+add_subdirectory(container)\n+add_subdirectory(debugging)\n+add_subdirectory(memory)\n+add_subdirectory(meta)\n+add_subdirectory(numeric)\n+add_subdirectory(strings)\n+add_subdirectory(synchronization)\n+add_subdirectory(time)\n+add_subdirectory(types)\n+add_subdirectory(utility)\ndiff --git a/absl/algorithm/CMakeLists.txt b/absl/algorithm/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..fdf45c55ed6\n--- /dev/null\n+++ b/absl/algorithm/CMakeLists.txt\n@@ -0,0 +1,63 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+list(APPEND ALGORITHM_PUBLIC_HEADERS\n+  \"algorithm.h\"\n+  \"container.h\"\n+)\n+\n+\n+#\n+## TESTS\n+#\n+\n+# test algorithm_test\n+list(APPEND ALGORITHM_TEST_SRC\n+  \"algorithm_test.cc\"\n+  ${ALGORITHM_PUBLIC_HEADERS}\n+  ${ALGORITHM_INTERNAL_HEADERS}\n+)\n+\n+absl_header_library(\n+  TARGET\n+    absl_algorithm\n+  EXPORT_NAME\n+    algorithm\n+)\n+\n+absl_test(\n+  TARGET\n+    algorithm_test\n+  SOURCES\n+    ${ALGORITHM_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    absl::algorithm\n+)\n+\n+\n+\n+\n+# test container_test\n+set(CONTAINER_TEST_SRC \"container_test.cc\")\n+\n+absl_test(\n+  TARGET\n+    container_test\n+  SOURCES\n+    ${CONTAINER_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    absl::algorithm\n+)\ndiff --git a/absl/base/CMakeLists.txt b/absl/base/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..3e94d51fef8\n--- /dev/null\n+++ b/absl/base/CMakeLists.txt\n@@ -0,0 +1,341 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+list(APPEND BASE_PUBLIC_HEADERS\n+  \"attributes.h\"\n+  \"call_once.h\"\n+  \"casts.h\"\n+  \"config.h\"\n+  \"dynamic_annotations.h\"\n+  \"macros.h\"\n+  \"optimization.h\"\n+  \"policy_checks.h\"\n+  \"port.h\"\n+  \"thread_annotations.h\"\n+)\n+\n+\n+list(APPEND BASE_INTERNAL_HEADERS\n+  \"internal/atomic_hook.h\"\n+  \"internal/cycleclock.h\"\n+  \"internal/endian.h\"\n+  \"internal/exception_testing.h\"\n+  \"internal/identity.h\"\n+  \"internal/invoke.h\"\n+  \"internal/log_severity.h\"\n+  \"internal/low_level_alloc.h\"\n+  \"internal/low_level_scheduling.h\"\n+  \"internal/malloc_extension_c.h\"\n+  \"internal/malloc_extension.h\"\n+  \"internal/malloc_hook_c.h\"\n+  \"internal/malloc_hook.h\"\n+  \"internal/malloc_hook_invoke.h\"\n+  \"internal/per_thread_tls.h\"\n+  \"internal/raw_logging.h\"\n+  \"internal/scheduling_mode.h\"\n+  \"internal/spinlock.h\"\n+  \"internal/spinlock_wait.h\"\n+  \"internal/sysinfo.h\"\n+  \"internal/thread_identity.h\"\n+  \"internal/throw_delegate.h\"\n+  \"internal/tsan_mutex_interface.h\"\n+  \"internal/unaligned_access.h\"\n+  \"internal/unscaledcycleclock.h\"\n+)\n+\n+\n+# absl_base main library\n+list(APPEND BASE_SRC \n+  \"internal/cycleclock.cc\"\n+  \"internal/raw_logging.cc\"\n+  \"internal/spinlock.cc\"\n+  \"internal/sysinfo.cc\"\n+  \"internal/thread_identity.cc\"\n+  \"internal/unscaledcycleclock.cc\"\n+  \"internal/low_level_alloc.cc\"\n+  \"internal/malloc_hook.cc\"\n+  ${BASE_PUBLIC_HEADERS}\n+  ${BASE_INTERNAL_HEADERS}\n+)\n+\n+absl_library(\n+  TARGET\n+    absl_base\n+  SOURCES\n+    ${BASE_SRC}\n+  PUBLIC_LIBRARIES\n+    absl_dynamic_annotations\n+    absl_spinlock_wait\n+  EXPORT_NAME\n+    base\n+)\n+\n+# malloc extension library\n+set(MALLOC_EXTENSION_SRC \"internal/malloc_extension.cc\")\n+set(MALLOC_EXTENSION_PUBLIC_LIBRARIES absl::base)\n+\n+absl_library(\n+  TARGET\n+    absl_malloc_extension\n+  SOURCES\n+    ${MALLOC_EXTENSION_SRC}\n+  PUBLIC_LIBRARIES\n+    ${MALLOC_EXTENSION_PUBLIC_LIBRARIES}\n+  EXPORT_NAME\n+    malloc_extension\n+)\n+\n+# throw delegate library\n+set(THROW_DELEGATE_SRC \"internal/throw_delegate.cc\")\n+\n+absl_library(\n+  TARGET\n+    absl_throw_delegate\n+  SOURCES\n+    ${THROW_DELEGATE_SRC}\n+  PUBLIC_LIBRARIES\n+    ${THROW_DELEGATE_PUBLIC_LIBRARIES}\n+  PRIVATE_COMPILE_FLAGS\n+    ${ABSL_EXCEPTIONS_FLAG}\n+  EXPORT_NAME\n+    throw_delegate\n+)\n+\n+\n+# dynamic_annotations library\n+set(DYNAMIC_ANNOTATIONS_SRC \"dynamic_annotations.cc\")\n+\n+absl_library(\n+  TARGET\n+    absl_dynamic_annotations\n+  SOURCES\n+    ${DYNAMIC_ANNOTATIONS_SRC}\n+)\n+\n+\n+# spinlock_wait library\n+set(SPINLOCK_WAIT_SRC \"internal/spinlock_wait.cc\")\n+\n+absl_library(\n+  TARGET\n+    absl_spinlock_wait\n+  SOURCES\n+    ${SPINLOCK_WAIT_SRC}\n+)\n+\n+\n+# malloc_internal library\n+list(APPEND MALLOC_INTERNAL_SRC\n+  \"internal/low_level_alloc.cc\"\n+  \"internal/malloc_hook.cc\"\n+  \"internal/malloc_hook_mmap_linux.inc\"\n+)\n+\n+absl_library(\n+  TARGET\n+    absl_malloc_internal\n+  SOURCES\n+    ${MALLOC_INTERNAL_SRC}\n+  PUBLIC_LIBRARIES\n+    absl_dynamic_annotations\n+)\n+\n+\n+\n+#\n+## TESTS\n+#\n+\n+# call once test\n+set(CALL_ONCE_TEST_SRC \"call_once_test.cc\")\n+set(CALL_ONCE_TEST_PUBLIC_LIBRARIES absl::base absl::synchronization)\n+\n+absl_test(\n+  TARGET\n+    call_once_test\n+  SOURCES\n+    ${CALL_ONCE_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${CALL_ONCE_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test bit_cast_test\n+set(BIT_CAST_TEST_SRC \"bit_cast_test.cc\")\n+\n+absl_test(\n+  TARGET\n+    bit_cast_test\n+  SOURCES\n+    ${BIT_CAST_TEST_SRC}\n+)\n+\n+\n+# test absl_throw_delegate_test\n+set(THROW_DELEGATE_TEST_SRC \"throw_delegate_test.cc\")\n+set(THROW_DELEGATE_TEST_PUBLIC_LIBRARIES absl::base absl_throw_delegate)\n+\n+absl_test(\n+  TARGET\n+    throw_delegate_test\n+  SOURCES\n+    ${THROW_DELEGATE_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${THROW_DELEGATE_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test invoke_test\n+set(INVOKE_TEST_SRC \"invoke_test.cc\")\n+set(INVOKE_TEST_PUBLIC_LIBRARIES absl::strings)\n+\n+absl_test(\n+  TARGET\n+    invoke_test\n+  SOURCES\n+    ${INVOKE_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${INVOKE_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test spinlock_test_common\n+set(SPINLOCK_TEST_COMMON_SRC \"spinlock_test_common.cc\")\n+set(SPINLOCK_TEST_COMMON_PUBLIC_LIBRARIES absl::base absl::synchronization)\n+\n+absl_test(\n+  TARGET\n+    spinlock_test_common\n+  SOURCES\n+    ${SPINLOCK_TEST_COMMON_SRC}\n+  PUBLIC_LIBRARIES\n+    ${SPINLOCK_TEST_COMMON_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test spinlock_test\n+set(SPINLOCK_TEST_SRC \"spinlock_test_common.cc\")\n+set(SPINLOCK_TEST_PUBLIC_LIBRARIES absl::base absl::synchronization)\n+\n+absl_test(\n+  TARGET\n+    spinlock_test\n+  SOURCES\n+    ${SPINLOCK_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${SPINLOCK_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test endian_test\n+set(ENDIAN_TEST_SRC \"internal/endian_test.cc\")\n+\n+absl_test(\n+  TARGET\n+    endian_test\n+  SOURCES\n+    ${ENDIAN_TEST_SRC}\n+)\n+\n+\n+# test config_test\n+set(CONFIG_TEST_SRC \"config_test.cc\")\n+set(CONFIG_TEST_PUBLIC_LIBRARIES absl::base absl::synchronization)\n+absl_test(\n+  TARGET\n+    config_test\n+  SOURCES\n+    ${CONFIG_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${CONFIG_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test raw_logging_test\n+set(RAW_LOGGING_TEST_SRC \"raw_logging_test.cc\")\n+set(RAW_LOGGING_TEST_PUBLIC_LIBRARIES absl::base)\n+\n+absl_test(\n+  TARGET\n+    raw_logging_test\n+  SOURCES\n+    ${RAW_LOGGING_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${RAW_LOGGING_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test sysinfo_test\n+set(SYSINFO_TEST_SRC \"internal/sysinfo_test.cc\")\n+set(SYSINFO_TEST_PUBLIC_LIBRARIES absl::base absl::synchronization)\n+\n+absl_test(\n+  TARGET\n+    sysinfo_test\n+  SOURCES\n+    ${SYSINFO_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${SYSINFO_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test low_level_alloc_test\n+set(LOW_LEVEL_ALLOC_TEST_SRC \"internal/low_level_alloc_test.cc\")\n+set(LOW_LEVEL_ALLOC_TEST_PUBLIC_LIBRARIES absl::base)\n+\n+absl_test(\n+  TARGET\n+    low_level_alloc_test\n+  SOURCES\n+    ${LOW_LEVEL_ALLOC_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${LOW_LEVEL_ALLOC_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test thread_identity_test\n+set(THREAD_IDENTITY_TEST_SRC \"internal/thread_identity_test.cc\")\n+set(THREAD_IDENTITY_TEST_PUBLIC_LIBRARIES absl::base absl::synchronization)\n+\n+absl_test(\n+  TARGET\n+    thread_identity_test\n+  SOURCES\n+    ${THREAD_IDENTITY_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${THREAD_IDENTITY_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test absl_malloc_extension_system_malloc_test\n+set(MALLOC_EXTENSION_SYSTEM_MALLOC_TEST_SRC \"internal/malloc_extension_test.cc\")\n+set(MALLOC_EXTENSION_SYSTEM_MALLOC_TEST_PUBLIC_LIBRARIES absl::base absl_malloc_extension)\n+set(MALLOC_EXTENSION_SYSTEM_MALLOC_TEST_PRIVATE_COMPILE_FLAGS \"-DABSL_MALLOC_EXTENSION_TEST_ALLOW_MISSING_EXTENSION=1\")\n+\n+absl_test(\n+  TARGET\n+    absl_malloc_extension_system_malloc_test\n+  SOURCES\n+    ${MALLOC_EXTENSION_SYSTEM_MALLOC_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${MALLOC_EXTENSION_SYSTEM_MALLOC_TEST_PUBLIC_LIBRARIES}\n+  PRIVATE_COMPILE_FLAGS\n+    ${MALLOC_EXTENSION_SYSTEM_MALLOC_TEST_PRIVATE_COMPILE_FLAGS}\n+)\n+\n+\n+\n+\ndiff --git a/absl/container/CMakeLists.txt b/absl/container/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..f56ce92d81b\n--- /dev/null\n+++ b/absl/container/CMakeLists.txt\n@@ -0,0 +1,126 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\n+list(APPEND CONTAINER_PUBLIC_HEADERS\n+  \"fixed_array.h\"\n+  \"inlined_vector.h\"\n+)\n+\n+\n+list(APPEND CONTAINER_INTERNAL_HEADERS\n+  \"internal/test_instance_tracker.h\"\n+)\n+\n+\n+absl_header_library(\n+  TARGET\n+    absl_container\n+  EXPORT_NAME\n+    container\n+)\n+\n+\n+#\n+## TESTS\n+#\n+\n+list(APPEND TEST_INSTANCE_TRACKER_LIB_SRC\n+  \"internal/test_instance_tracker.cc\"\n+  ${CONTAINER_PUBLIC_HEADERS}\n+  ${CONTAINER_INTERNAL_HEADERS}\n+)\n+\n+\n+absl_library(\n+  TARGET\n+    test_instance_tracker_lib\n+  SOURCES\n+    ${TEST_INSTANCE_TRACKER_LIB_SRC}\n+  PUBLIC_LIBRARIES\n+    absl::container\n+  DISABLE_INSTALL\n+)\n+\n+\n+\n+# test fixed_array_test\n+set(FIXED_ARRAY_TEST_SRC \"fixed_array_test.cc\")\n+set(FIXED_ARRAY_TEST_PUBLIC_LIBRARIES absl::base absl_throw_delegate test_instance_tracker_lib)\n+\n+absl_test(\n+  TARGET\n+    fixed_array_test\n+  SOURCES\n+    ${FIXED_ARRAY_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${FIXED_ARRAY_TEST_PUBLIC_LIBRARIES}\n+  PRIVATE_COMPILE_FLAGS\n+    ${ABSL_EXCEPTIONS_FLAG}\n+)\n+\n+\n+\n+absl_test(\n+  TARGET\n+    fixed_array_test_noexceptions\n+  SOURCES\n+    ${FIXED_ARRAY_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${FIXED_ARRAY_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test inlined_vector_test\n+set(INLINED_VECTOR_TEST_SRC \"inlined_vector_test.cc\")\n+set(INLINED_VECTOR_TEST_PUBLIC_LIBRARIES absl::base absl_throw_delegate test_instance_tracker_lib)\n+\n+absl_test(\n+  TARGET\n+    inlined_vector_test\n+  SOURCES\n+    ${INLINED_VECTOR_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${INLINED_VECTOR_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+absl_test(\n+  TARGET\n+    inlined_vector_test_noexceptions\n+  SOURCES\n+    ${INLINED_VECTOR_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${INLINED_VECTOR_TEST_PUBLIC_LIBRARIES}\n+  PRIVATE_COMPILE_FLAGS\n+    ${ABSL_NOEXCEPTION_CXXFLAGS}\n+)\n+\n+\n+# test test_instance_tracker_test\n+set(TEST_INSTANCE_TRACKER_TEST_SRC \"internal/test_instance_tracker_test.cc\")\n+set(TEST_INSTANCE_TRACKER_TEST_PUBLIC_LIBRARIES absl::base absl_throw_delegate test_instance_tracker_lib)\n+\n+\n+absl_test(\n+  TARGET\n+    test_instance_tracker_test\n+  SOURCES\n+    ${TEST_INSTANCE_TRACKER_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${TEST_INSTANCE_TRACKER_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\ndiff --git a/absl/debugging/CMakeLists.txt b/absl/debugging/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..57efe80fd05\n--- /dev/null\n+++ b/absl/debugging/CMakeLists.txt\n@@ -0,0 +1,93 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+list(APPEND DEBUGGING_PUBLIC_HEADERS\n+  \"leak_check.h\"\n+  \"stacktrace.h\"\n+)\n+\n+\n+list(APPEND DEBUGGING_INTERNAL_HEADERS\n+  \"internal/address_is_readable.h\"\n+  \"internal/elf_mem_image.h\"\n+  \"internal/stacktrace_config.h\"\n+  \"internal/vdso_support.h\"\n+)\n+\n+\n+list(APPEND STACKTRACE_SRC\n+  \"stacktrace.cc\"\n+  \"internal/address_is_readable.cc\"\n+  \"internal/elf_mem_image.cc\"\n+  \"internal/vdso_support.cc\"\n+  ${DEBUGGING_PUBLIC_HEADERS}\n+  ${DEBUGGING_INTERNAL_HEADERS}\n+)\n+\n+absl_library(\n+  TARGET\n+    absl_stacktrace\n+  SOURCES\n+    ${STACKTRACE_SRC}\n+  EXPORT_NAME\n+    stacktrace\n+)\n+\n+\n+list(APPEND LEAK_CHECK_SRC\n+  \"leak_check.cc\"\n+)\n+\n+\n+# leak_check library\n+absl_library(\n+  TARGET\n+    absl_leak_check\n+  SOURCES\n+    ${LEAK_CHECK_SRC}\n+  PUBLIC_LIBRARIES\n+    absl_base\n+  EXPORT_NAME\n+    leak_check\n+)\n+\n+\n+# component target\n+absl_header_library(\n+  TARGET\n+    absl_debugging\n+  PUBLIC_LIBRARIES\n+    absl_stacktrace absl_leak_check\n+  EXPORT_NAME\n+    debugging\n+)\n+\n+#\n+## TESTS\n+#\n+\n+# test leak_check_test\n+list(APPEND LEAK_CHECK_TEST_SRC \"leak_check_test.cc\")\n+\n+absl_test(\n+  TARGET\n+    leak_check_test\n+  SOURCES\n+    ${LEAK_CHECK_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    absl_leak_check\n+)\n+\ndiff --git a/absl/memory/CMakeLists.txt b/absl/memory/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..21bfc87ed6e\n--- /dev/null\n+++ b/absl/memory/CMakeLists.txt\n@@ -0,0 +1,52 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+list(APPEND MEMORY_PUBLIC_HEADERS\n+  \"memory.h\"\n+)\n+\n+\n+absl_header_library(\n+  TARGET\n+    absl_memory\n+  EXPORT_NAME\n+    memory\n+)\n+\n+#\n+## TESTS\n+#\n+\n+# test memory_test\n+list(APPEND MEMORY_TEST_SRC\n+  \"memory_test.cc\"\n+  ${MEMORY_PUBLIC_HEADERS}\n+)\n+set(MEMORY_TEST_PUBLIC_LIBRARIES absl::base absl::memory)\n+\n+\n+\n+absl_test(\n+  TARGET\n+    memory_test\n+  SOURCES\n+    ${MEMORY_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${MEMORY_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+\ndiff --git a/absl/meta/CMakeLists.txt b/absl/meta/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..d56fced8aa0\n--- /dev/null\n+++ b/absl/meta/CMakeLists.txt\n@@ -0,0 +1,49 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+list(APPEND META_PUBLIC_HEADERS\n+  \"type_traits.h\"\n+)\n+\n+\n+#\n+## TESTS\n+#\n+\n+# test type_traits_test\n+list(APPEND TYPE_TRAITS_TEST_SRC\n+  \"type_traits_test.cc\"\n+  ${META_PUBLIC_HEADERS}\n+)\n+\n+absl_header_library(\n+  TARGET\n+    absl_meta\n+  EXPORT_NAME\n+    meta\n+ )\n+\n+absl_test(\n+  TARGET\n+    type_traits_test\n+  SOURCES\n+    ${TYPE_TRAITS_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${TYPE_TRAITS_TEST_PUBLIC_LIBRARIES} absl::meta\n+)\n+\n+\n+\ndiff --git a/absl/numeric/CMakeLists.txt b/absl/numeric/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..3360b2ee726\n--- /dev/null\n+++ b/absl/numeric/CMakeLists.txt\n@@ -0,0 +1,62 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+list(APPEND NUMERIC_PUBLIC_HEADERS\n+  \"int128.h\"\n+)\n+\n+\n+# library 128\n+list(APPEND INT128_SRC\n+  \"int128.cc\"\n+  ${NUMERIC_PUBLIC_HEADERS}\n+)\n+absl_library(\n+  TARGET\n+    absl_int128\n+  SOURCES\n+    ${INT128_SRC}\n+  PUBLIC_LIBRARIES\n+    ${INT128_PUBLIC_LIBRARIES}\n+  EXPORT_NAME\n+    int128\n+)\n+\n+\n+absl_header_library(\n+  TARGET\n+    absl_numeric\n+  PUBLIC_LIBRARIES\n+    absl::int128\n+  EXPORT_NAME\n+    numeric\n+)\n+\n+# test int128_test\n+set(INT128_TEST_SRC \"int128_test.cc\")\n+set(INT128_TEST_PUBLIC_LIBRARIES absl::numeric absl::base)\n+\n+absl_test(\n+  TARGET\n+    int128_test\n+  SOURCES\n+    ${INT128_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${INT128_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+\ndiff --git a/absl/strings/CMakeLists.txt b/absl/strings/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..dcd4974bc61\n--- /dev/null\n+++ b/absl/strings/CMakeLists.txt\n@@ -0,0 +1,299 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\n+list(APPEND STRINGS_PUBLIC_HEADERS\n+  \"ascii.h\"\n+  \"escaping.h\"\n+  \"match.h\"\n+  \"numbers.h\"\n+  \"str_cat.h\"\n+  \"string_view.h\"\n+  \"strip.h\"\n+  \"str_join.h\"\n+  \"str_replace.h\"\n+  \"str_split.h\"\n+  \"substitute.h\"\n+)\n+\n+\n+list(APPEND STRINGS_INTERNAL_HEADERS\n+  \"internal/char_map.h\"\n+  \"internal/memutil.h\"\n+  \"internal/ostringstream.h\"\n+  \"internal/resize_uninitialized.h\"\n+  \"internal/str_join_internal.h\"\n+  \"internal/str_split_internal.h\"\n+  \"internal/utf8.h\"\n+)\n+\n+\n+\n+# add string library\n+list(APPEND STRINGS_SRC\n+  \"ascii.cc\"\n+  \"escaping.cc\"\n+  \"internal/memutil.cc\"\n+  \"internal/memutil.h\"\n+  \"internal/utf8.cc\"\n+  \"match.cc\"\n+  \"numbers.cc\"\n+  \"str_cat.cc\"\n+  \"str_replace.cc\"\n+  \"str_split.cc\"\n+  \"string_view.cc\"\n+  \"substitute.cc\"\n+  ${STRINGS_PUBLIC_HEADERS}\n+  ${STRINGS_INTERNAL_HEADERS}\n+)\n+set(STRINGS_PUBLIC_LIBRARIES absl::base absl_throw_delegate)\n+\n+absl_library(\n+  TARGET\n+    absl_strings\n+  SOURCES\n+    ${STRINGS_SRC}\n+  PUBLIC_LIBRARIES\n+    ${STRINGS_PUBLIC_LIBRARIES}\n+  EXPORT_NAME\n+    strings\n+)\n+\n+\n+#\n+## TESTS\n+#\n+\n+# test match_test\n+set(MATCH_TEST_SRC \"match_test.cc\")\n+set(MATCH_TEST_PUBLIC_LIBRARIES absl::strings)\n+\n+absl_test(\n+  TARGET\n+    match_test\n+  SOURCES\n+    ${MATCH_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${MATCH_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test escaping_test\n+set(ESCAPING_TEST_SRC \"escaping_test.cc\")\n+set(ESCAPING_TEST_PUBLIC_LIBRARIES absl::strings absl::base)\n+\n+absl_test(\n+  TARGET\n+    escaping_test\n+  SOURCES\n+    ${ESCAPING_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${ESCAPING_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test ascii_test\n+set(ASCII_TEST_SRC \"ascii_test.cc\")\n+set(ASCII_TEST_PUBLIC_LIBRARIES absl::strings)\n+\n+absl_test(\n+  TARGET\n+    ascii_test\n+  SOURCES\n+    ${ASCII_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${ASCII_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test memutil_test\n+set(MEMUTIL_TEST_SRC \"internal/memutil_test.cc\")\n+set(MEMUTIL_TEST_PUBLIC_LIBRARIES absl::strings)\n+\n+absl_test(\n+  TARGET\n+    memutil_test\n+  SOURCES\n+    ${MEMUTIL_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${MEMUTIL_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test utf8_test\n+set(UTF8_TEST_SRC \"internal/utf8_test.cc\")\n+set(UTF8_TEST_PUBLIC_LIBRARIES absl::strings absl::base)\n+\n+absl_test(\n+  TARGET\n+    utf8_test\n+  SOURCES\n+    ${UTF8_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${UTF8_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test string_view_test\n+set(STRING_VIEW_TEST_SRC \"string_view_test.cc\")\n+set(STRING_VIEW_TEST_PUBLIC_LIBRARIES absl::strings absl_throw_delegate absl::base)\n+\n+absl_test(\n+  TARGET\n+    string_view_test\n+  SOURCES\n+    ${STRING_VIEW_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${STRING_VIEW_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test substitute_test\n+set(SUBSTITUTE_TEST_SRC \"substitute_test.cc\")\n+set(SUBSTITUTE_TEST_PUBLIC_LIBRARIES absl::strings absl::base)\n+\n+absl_test(\n+  TARGET\n+    substitute_test\n+  SOURCES\n+    ${SUBSTITUTE_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${SUBSTITUTE_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test str_replace_test\n+set(STR_REPLACE_TEST_SRC \"str_replace_test.cc\")\n+set(STR_REPLACE_TEST_PUBLIC_LIBRARIES absl::strings absl::base absl_throw_delegate)\n+\n+absl_test(\n+  TARGET\n+    str_replace_test\n+  SOURCES\n+    ${STR_REPLACE_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${STR_REPLACE_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test str_split_test\n+set(STR_SPLIT_TEST_SRC \"str_split_test.cc\")\n+set(STR_SPLIT_TEST_PUBLIC_LIBRARIES absl::strings absl::base absl_throw_delegate)\n+\n+absl_test(\n+  TARGET\n+    str_split_test\n+  SOURCES\n+    ${STR_SPLIT_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${STR_SPLIT_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test ostringstream_test\n+set(OSTRINGSTREAM_TEST_SRC \"internal/ostringstream_test.cc\")\n+\n+absl_test(\n+  TARGET\n+    ostringstream_test\n+  SOURCES\n+    ${OSTRINGSTREAM_TEST_SRC}\n+)\n+\n+\n+# test resize_uninitialized_test\n+set(RESIZE_UNINITIALIZED_TEST_SRC \"internal/resize_uninitialized_test.cc\")\n+\n+absl_test(\n+  TARGET\n+    resize_uninitialized_test\n+  SOURCES\n+    ${RESIZE_UNINITIALIZED_TEST_SRC}\n+)\n+\n+\n+# test str_join_test\n+set(STR_JOIN_TEST_SRC \"str_join_test.cc\")\n+set(STR_JOIN_TEST_PUBLIC_LIBRARIES absl::strings)\n+\n+absl_test(\n+  TARGET\n+    str_join_test\n+  SOURCES\n+    ${STR_JOIN_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${STR_JOIN_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test str_cat_test\n+set(STR_CAT_TEST_SRC \"str_cat_test.cc\")\n+set(STR_CAT_TEST_PUBLIC_LIBRARIES absl::strings)\n+\n+absl_test(\n+  TARGET\n+    str_cat_test\n+  SOURCES\n+    ${STR_CAT_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${STR_CAT_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test numbers_test\n+set(NUMBERS_TEST_SRC \"numbers_test.cc\")\n+set(NUMBERS_TEST_PUBLIC_LIBRARIES absl::strings)\n+\n+absl_test(\n+  TARGET\n+    numbers_test\n+  SOURCES\n+    ${NUMBERS_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${NUMBERS_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test strip_test\n+set(STRIP_TEST_SRC \"strip_test.cc\")\n+set(STRIP_TEST_PUBLIC_LIBRARIES absl::strings)\n+\n+absl_test(\n+  TARGET\n+    strip_test\n+  SOURCES\n+    ${STRIP_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${STRIP_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test char_map_test\n+set(CHAR_MAP_TEST_SRC \"internal/char_map_test.cc\")\n+set(CHAR_MAP_TEST_PUBLIC_LIBRARIES absl::strings)\n+\n+absl_test(\n+  TARGET\n+    char_map_test\n+  SOURCES\n+    ${CHAR_MAP_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${CHAR_MAP_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+\n+\ndiff --git a/absl/synchronization/CMakeLists.txt b/absl/synchronization/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..c5c4c626861\n--- /dev/null\n+++ b/absl/synchronization/CMakeLists.txt\n@@ -0,0 +1,154 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+list(APPEND SYNCHRONIZATION_PUBLIC_HEADERS\n+  \"barrier.h\"\n+  \"blocking_counter.h\"\n+  \"mutex.h\"\n+  \"notification.h\"\n+)\n+\n+\n+list(APPEND SYNCHRONIZATION_INTERNAL_HEADERS\n+  \"internal/create_thread_identity.h\"\n+  \"internal/graphcycles.h\"\n+  \"internal/kernel_timeout.h\"\n+  \"internal/per_thread_sem.h\"\n+  \"internal/thread_pool.h\"\n+  \"internal/waiter.h\"\n+)\n+\n+\n+\n+# syncrhonisation library\n+list(APPEND SYNCHRONIZATION_SRC \n+  \"barrier.cc\"\n+  \"blocking_counter.cc\"\n+  \"internal/create_thread_identity.cc\"\n+  \"internal/per_thread_sem.cc\"\n+  \"internal/waiter.cc\"\n+  \"internal/graphcycles.cc\"\n+  \"notification.cc\"\n+  \"mutex.cc\"\n+)\n+set(SYNCHRONIZATION_PUBLIC_LIBRARIES absl::base absl_malloc_extension absl::time)\n+\n+absl_library(\n+  TARGET\n+    absl_synchronization\n+  SOURCES\n+    ${SYNCHRONIZATION_SRC}\n+  PUBLIC_LIBRARIES\n+    ${SYNCHRONIZATION_PUBLIC_LIBRARIES}\n+  EXPORT_NAME\n+    synchronization\n+)\n+\n+\n+#\n+## TESTS\n+#\n+\n+\n+# test barrier_test\n+set(BARRIER_TEST_SRC \"barrier_test.cc\")\n+set(BARRIER_TEST_PUBLIC_LIBRARIES absl::synchronization)\n+\n+absl_test(\n+  TARGET\n+    barrier_test\n+  SOURCES\n+    ${BARRIER_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${BARRIER_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test blocking_counter_test\n+set(BLOCKING_COUNTER_TEST_SRC \"blocking_counter_test.cc\")\n+set(BLOCKING_COUNTER_TEST_PUBLIC_LIBRARIES absl::synchronization)\n+\n+absl_test(\n+  TARGET\n+    blocking_counter_test\n+  SOURCES\n+    ${BLOCKING_COUNTER_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${BLOCKING_COUNTER_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test graphcycles_test\n+set(GRAPHCYCLES_TEST_SRC \"internal/graphcycles_test.cc\")\n+set(GRAPHCYCLES_TEST_PUBLIC_LIBRARIES absl::synchronization)\n+\n+absl_test(\n+  TARGET\n+    graphcycles_test\n+  SOURCES\n+    ${GRAPHCYCLES_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${GRAPHCYCLES_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test mutex_test\n+set(MUTEX_TEST_SRC \"mutex_test.cc\")\n+set(MUTEX_TEST_PUBLIC_LIBRARIES absl::synchronization)\n+\n+absl_test(\n+  TARGET\n+    mutex_test\n+  SOURCES\n+    ${MUTEX_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${MUTEX_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test notification_test\n+set(NOTIFICATION_TEST_SRC \"notification_test.cc\")\n+set(NOTIFICATION_TEST_PUBLIC_LIBRARIES absl::synchronization)\n+\n+absl_test(\n+  TARGET\n+    notification_test\n+  SOURCES\n+    ${NOTIFICATION_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${NOTIFICATION_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test per_thread_sem_test_common\n+set(PER_THREAD_SEM_TEST_COMMON_SRC \"internal/per_thread_sem_test.cc\")\n+set(PER_THREAD_SEM_TEST_COMMON_PUBLIC_LIBRARIES absl::synchronization absl::strings)\n+\n+absl_test(\n+  TARGET\n+    per_thread_sem_test_common\n+  SOURCES\n+    ${PER_THREAD_SEM_TEST_COMMON_SRC}\n+  PUBLIC_LIBRARIES\n+    ${PER_THREAD_SEM_TEST_COMMON_PUBLIC_LIBRARIES}\n+)\n+\n+\n+\n+\n+\n+\n+\ndiff --git a/absl/time/CMakeLists.txt b/absl/time/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..60f61483e9a\n--- /dev/null\n+++ b/absl/time/CMakeLists.txt\n@@ -0,0 +1,78 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+list(APPEND TIME_PUBLIC_HEADERS\n+  \"clock.h\"\n+  \"time.h\"\n+)\n+\n+\n+list(APPEND TIME_INTERNAL_HEADERS\n+  \"internal/test_util.h\"\n+)\n+\n+list(APPEND TIME_SRC\n+  \"time.cc\"\n+  \"clock.cc\"\n+  \"duration.cc\"\n+  \"format.cc\"\n+  ${TIME_PUBLIC_HEADERS}\n+  ${TIME_INTERNAL_HEADERS}\n+)\n+set(TIME_PUBLIC_LIBRARIES absl::base absl::stacktrace absl::int128 cctz)\n+\n+absl_library(\n+  TARGET\n+    absl_time\n+  SOURCES\n+    ${TIME_SRC}\n+  PUBLIC_LIBRARIES\n+    ${TIME_PUBLIC_LIBRARIES}\n+  PUBLIC_INCLUDE_DIRS\n+    ${CCTZ_INCLUDE_DIRS}\n+  EXPORT_NAME\n+    time\n+)\n+\n+\n+\n+#\n+## TESTS\n+#\n+\n+# test time_test\n+list(APPEND TIME_TEST_SRC\n+  \"time_test.cc\"\n+  \"clock_test.cc\"\n+  \"duration_test.cc\"\n+  \"format_test.cc\"\n+  \"time_norm_test.cc\"\n+  \"time_test.cc\"\n+  \"time_zone_test.cc\"\n+  \"internal/test_util.cc\"\n+)\n+set(TIME_TEST_PUBLIC_LIBRARIES absl::time)\n+\n+absl_test(\n+  TARGET\n+    time_test\n+  SOURCES\n+    ${TIME_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${TIME_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\ndiff --git a/absl/types/CMakeLists.txt b/absl/types/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..3e464497492\n--- /dev/null\n+++ b/absl/types/CMakeLists.txt\n@@ -0,0 +1,171 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+list(APPEND TYPES_PUBLIC_HEADERS\n+  \"any.h\"\n+  \"bad_any_cast.h\"\n+  \"bad_optional_access.h\"\n+  \"optional.h\"\n+  \"span.h\"\n+)\n+\n+\n+# any library\n+absl_header_library(\n+  TARGET\n+    absl_any\n+  PUBLIC_LIBRARIES\n+    absl::utility\n+  EXPORT_NAME\n+    any\n+)\n+\n+# span library\n+absl_header_library(\n+  TARGET\n+    absl_span\n+  PUBLIC_LIBRARIES\n+    absl::utility\n+  EXPORT_NAME\n+    span\n+)\n+\n+\n+# bad_any_cast library\n+list(APPEND BAD_ANY_CAST_SRC\n+  \"bad_any_cast.cc\"\n+  ${TYPES_PUBLIC_HEADERS}\n+)\n+\n+absl_library(\n+  TARGET\n+    absl_bad_any_cast\n+  SOURCES\n+    ${BAD_ANY_CAST_SRC}\n+  PUBLIC_LIBRARIES\n+    absl::base absl::any\n+  EXPORT_NAME\n+    bad_any_cast\n+)\n+\n+\n+# optional library\n+list(APPEND OPTIONAL_SRC\n+  \"optional.cc\"\n+)\n+\n+absl_library(\n+  TARGET\n+    absl_optional\n+  SOURCES\n+    ${OPTIONAL_SRC}\n+  PUBLIC_LIBRARIES\n+    absl::base\n+  EXPORT_NAME\n+    optional\n+)\n+\n+\n+set(BAD_OPTIONAL_ACCESS_SRC \"bad_optional_access.cc\")\n+set(BAD_OPTIONAL_ACCESS_LIBRARIES absl::base)\n+\n+absl_library(\n+  TARGET\n+    absl_bad_optional_access\n+  SOURCES\n+    ${BAD_OPTIONAL_ACCESS_SRC}\n+  PUBLIC_LIBRARIES\n+    ${BAD_OPTIONAL_ACCESS_PUBLIC_LIBRARIES}\n+  EXPORT_NAME\n+    bad_optional_access\n+)\n+\n+\n+\n+#\n+## TESTS\n+#\n+\n+\n+# test any_test\n+set(ANY_TEST_SRC \"any_test.cc\")\n+set(ANY_TEST_PUBLIC_LIBRARIES absl::base absl::throw_delegate absl::any absl::bad_any_cast test_instance_tracker_lib)\n+\n+absl_test(\n+  TARGET\n+    any_test\n+  SOURCES\n+    ${ANY_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${ANY_TEST_PUBLIC_LIBRARIES}\n+  PRIVATE_COMPILE_FLAGS\n+    ${ABSL_EXCEPTIONS_FLAG}\n+)\n+\n+\n+# test any_test_noexceptions\n+absl_test(\n+  TARGET\n+    any_test_noexceptions\n+  SOURCES\n+    ${ANY_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${ANY_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+# test span_test\n+set(SPAN_TEST_SRC \"span_test.cc\")\n+set(SPAN_TEST_PUBLIC_LIBRARIES absl::base absl::strings absl::throw_delegate absl::span test_instance_tracker_lib)\n+\n+absl_test(\n+  TARGET\n+    span_test\n+  SOURCES\n+    ${SPAN_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${SPAN_TEST_PUBLIC_LIBRARIES}\n+  PRIVATE_COMPILE_FLAGS\n+    ${ABSL_EXCEPTIONS_FLAG}\n+)\n+\n+\n+# test span_test_noexceptions\n+absl_test(\n+  TARGET\n+    span_test_noexceptions\n+  SOURCES\n+    ${SPAN_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${SPAN_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+\n+# test optional_test\n+set(OPTIONAL_TEST_SRC \"optional_test.cc\")\n+set(OPTIONAL_TEST_PUBLIC_LIBRARIES absl::base absl::throw_delegate absl::optional absl_bad_optional_access)\n+\n+absl_test(\n+  TARGET\n+    optional_test\n+  SOURCES\n+    ${OPTIONAL_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${OPTIONAL_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\ndiff --git a/absl/utility/CMakeLists.txt b/absl/utility/CMakeLists.txt\nnew file mode 100644\nindex 00000000000..daf3417859b\n--- /dev/null\n+++ b/absl/utility/CMakeLists.txt\n@@ -0,0 +1,60 @@\n+#\n+# Copyright 2017 The Abseil Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\n+list(APPEND UTILITY_PUBLIC_HEADERS\n+  \"utility.h\"\n+)\n+\n+\n+\n+list(APPEND UTILITY_SRC\n+  \"utility.cc\"\n+  ${UTILITY_PUBLIC_HEADERS}\n+)\n+\n+absl_library(\n+  TARGET\n+    absl_utility\n+  SOURCES\n+    ${UTILITY_SRC}\n+  PUBLIC_LIBRARIES\n+    ${UTILITY_PUBLIC_LIBRARIES}\n+  EXPORT_NAME\n+    utility\n+)\n+\n+\n+\n+#\n+## TESTS\n+#\n+\n+# test utility_test\n+set(UTILITY_TEST_SRC \"utility_test.cc\")\n+set(UTILITY_TEST_PUBLIC_LIBRARIES absl::utility)\n+\n+absl_test(\n+  TARGET\n+    utility_test\n+  SOURCES\n+    ${UTILITY_TEST_SRC}\n+  PUBLIC_LIBRARIES\n+    ${UTILITY_TEST_PUBLIC_LIBRARIES}\n+)\n+\n+\n+\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **CMake Configuration**: Export imported targets from Find modules to maintain compatibility with CMake 2.8 and ensure proper integration and usage of flags across compilers, as specified in `absl/copts.bzl`.\n\n2. **CCTZ Dependency Management**: Support building CCTZ as a git submodule or via CMake\u2019s `ExternalProject_Add`, with a flag to disable bundling. Maintain external build/install options to accommodate package managers.\n\n3. **Tests Configuration Issue**: Address the build issue with Ninja and `ExternalProject` when `BUILD_TESTING` is enabled.\n\n4. **Install Targets**: Ensure easy usage of Abseil within CMake projects by providing appropriate install targets and package support.\n\n5. **Avoid Unix-only Constructs**: Minimize dependency on Unix-specific tools to improve Windows compatibility."
      }
    ],
    "codediff_length": 45206
  },
  {
    "index": 48,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/absl/debugging/BUILD.bazel b/absl/debugging/BUILD.bazel\nindex b87c55a54f6..beec279ff8e 100644\n--- a/absl/debugging/BUILD.bazel\n+++ b/absl/debugging/BUILD.bazel\n@@ -70,8 +70,14 @@ cc_library(\n cc_test(\n     name = \"symbolize_test\",\n     srcs = [\"symbolize_test.cc\"],\n-    copts = ABSL_TEST_COPTS,\n-    linkopts = ABSL_DEFAULT_LINKOPTS,\n+    copts = ABSL_TEST_COPTS + select({\n+        \"//absl:windows\": [\"/Z7\"],\n+        \"//conditions:default\": [],\n+    }),\n+    linkopts = ABSL_DEFAULT_LINKOPTS + select({\n+        \"//absl:windows\": [\"/DEBUG\"],\n+        \"//conditions:default\": [],\n+    }),\n     deps = [\n         \":stack_consumption\",\n         \":symbolize\",\ndiff --git a/absl/debugging/CMakeLists.txt b/absl/debugging/CMakeLists.txt\nindex c409e33e39c..1e7a450e81c 100644\n--- a/absl/debugging/CMakeLists.txt\n+++ b/absl/debugging/CMakeLists.txt\n@@ -62,6 +62,9 @@ absl_cc_test(\n     \"symbolize_test.cc\"\n   COPTS\n     ${ABSL_TEST_COPTS}\n+    $<$<BOOL:${MSVC}>:-Z7>\n+  LINKOPTS\n+    $<$<BOOL:${MSVC}>:-DEBUG>\n   DEPS\n     absl::stack_consumption\n     absl::symbolize\ndiff --git a/absl/debugging/symbolize.cc b/absl/debugging/symbolize.cc\nindex 24e3a7f0a0e..54ed97002a1 100644\n--- a/absl/debugging/symbolize.cc\n+++ b/absl/debugging/symbolize.cc\n@@ -16,12 +16,9 @@\n \n #if defined(ABSL_INTERNAL_HAVE_ELF_SYMBOLIZE)\n #include \"absl/debugging/symbolize_elf.inc\"\n-#elif defined(_WIN32) && defined(_DEBUG)\n-// The Windows Symbolizer only works in debug mode. Note that _DEBUG\n-// is the macro that defines whether or not MS C-Runtime debug info is\n-// available. Note that the PDB files containing the debug info must\n-// also be available to the program at runtime for the symbolizer to\n-// work.\n+#elif defined(_WIN32)\n+// The Windows Symbolizer only works if PDB files containing the debug info\n+// are available to the program at runtime.\n #include \"absl/debugging/symbolize_win32.inc\"\n #else\n #include \"absl/debugging/symbolize_unimplemented.inc\"\ndiff --git a/absl/debugging/symbolize_test.cc b/absl/debugging/symbolize_test.cc\nindex 533799a6ebc..0bac60b9ea2 100644\n--- a/absl/debugging/symbolize_test.cc\n+++ b/absl/debugging/symbolize_test.cc\n@@ -35,10 +35,29 @@\n \n using testing::Contains;\n \n+#ifdef _WIN32\n+#define ABSL_SYMBOLIZE_TEST_NOINLINE __declspec(noinline)\n+#else\n+#define ABSL_SYMBOLIZE_TEST_NOINLINE ABSL_ATTRIBUTE_NOINLINE\n+#endif\n+\n // Functions to symbolize. Use C linkage to avoid mangled names.\n extern \"C\" {\n-void nonstatic_func() { ABSL_BLOCK_TAIL_CALL_OPTIMIZATION(); }\n-static void static_func() { ABSL_BLOCK_TAIL_CALL_OPTIMIZATION(); }\n+ABSL_SYMBOLIZE_TEST_NOINLINE void nonstatic_func() {\n+  // The next line makes this a unique function to prevent the compiler from\n+  // folding identical functions together.\n+  volatile int x = __LINE__;\n+  static_cast<void>(x);\n+  ABSL_BLOCK_TAIL_CALL_OPTIMIZATION();\n+}\n+\n+ABSL_SYMBOLIZE_TEST_NOINLINE static void static_func() {\n+  // The next line makes this a unique function to prevent the compiler from\n+  // folding identical functions together.\n+  volatile int x = __LINE__;\n+  static_cast<void>(x);\n+  ABSL_BLOCK_TAIL_CALL_OPTIMIZATION();\n+}\n }  // extern \"C\"\n \n struct Foo {\n@@ -46,7 +65,11 @@ struct Foo {\n };\n \n // A C++ method that should have a mangled name.\n-void ABSL_ATTRIBUTE_NOINLINE Foo::func(int) {\n+ABSL_SYMBOLIZE_TEST_NOINLINE void Foo::func(int) {\n+  // The next line makes this a unique function to prevent the compiler from\n+  // folding identical functions together.\n+  volatile int x = __LINE__;\n+  static_cast<void>(x);\n   ABSL_BLOCK_TAIL_CALL_OPTIMIZATION();\n }\n \n@@ -449,14 +472,14 @@ void ABSL_ATTRIBUTE_NOINLINE TestWithReturnAddress() {\n #endif\n }\n \n-#elif defined(_WIN32) && defined(_DEBUG)\n+#elif defined(_WIN32)\n \n TEST(Symbolize, Basics) {\n   EXPECT_STREQ(\"nonstatic_func\", TrySymbolize((void *)(&nonstatic_func)));\n \n   // The name of an internal linkage symbol is not specified; allow either a\n   // mangled or an unmangled name here.\n-  const char* static_func_symbol = TrySymbolize((void *)(&static_func));\n+  const char *static_func_symbol = TrySymbolize((void *)(&static_func));\n   ASSERT_TRUE(static_func_symbol != nullptr);\n   EXPECT_TRUE(strstr(static_func_symbol, \"static_func\") != nullptr);\n \n@@ -483,7 +506,7 @@ TEST(Symbolize, Truncation) {\n }\n \n TEST(Symbolize, SymbolizeWithDemangling) {\n-  const char* result = TrySymbolize((void *)(&Foo::func));\n+  const char *result = TrySymbolize((void *)(&Foo::func));\n   ASSERT_TRUE(result != nullptr);\n   EXPECT_TRUE(strstr(result, \"Foo::func\") != nullptr) << result;\n }\ndiff --git a/absl/debugging/symbolize_win32.inc b/absl/debugging/symbolize_win32.inc\nindex 5a55f29d296..0fb4b803769 100644\n--- a/absl/debugging/symbolize_win32.inc\n+++ b/absl/debugging/symbolize_win32.inc\n@@ -57,9 +57,8 @@ bool Symbolize(const void *pc, char *out, int out_size) {\n   if (out_size <= 0) {\n     return false;\n   }\n-  std::aligned_storage<sizeof(SYMBOL_INFO) + MAX_SYM_NAME,\n-                       alignof(SYMBOL_INFO)>::type buf;\n-  SYMBOL_INFO *symbol = reinterpret_cast<SYMBOL_INFO *>(&buf);\n+  alignas(SYMBOL_INFO) char buf[sizeof(SYMBOL_INFO) + MAX_SYM_NAME];\n+  SYMBOL_INFO *symbol = reinterpret_cast<SYMBOL_INFO *>(buf);\n   symbol->SizeOfStruct = sizeof(SYMBOL_INFO);\n   symbol->MaxNameLen = MAX_SYM_NAME;\n   if (!SymFromAddr(process, reinterpret_cast<DWORD64>(pc), nullptr, symbol)) {\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. The test fails in non-debug mode due to reliance on the `_DEBUG` macro; consider removing this dependency for greater flexibility.\n2. The MSVC ICF is incorrectly merging functions, despite using `__declspec(noinline)` - implement a `volatile int` workaround.\n3. Compile flags `/Z7` and `/DEBUG` must be correctly applied to the entire binary; confirm link step settings across all files.\n4. Ensure you are using the latest Bazel version; investigate discrepancies in test results across different setups.\n5. To debug, modify `symbolize_test.cc` and capture the output from `bazel build -c opt -s //absl/debugging/symbolize_test` for analysis.\n6. Run `bazel clean --expunge` before retesting to avoid caching issues.\n7. If failures persist, document the failures and share detailed logs for further investigation."
      }
    ],
    "codediff_length": 5342
  },
  {
    "index": 49,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/absl/container/flat_hash_map.h b/absl/container/flat_hash_map.h\nindex 00cc4dcff9f..68fa508e96b 100644\n--- a/absl/container/flat_hash_map.h\n+++ b/absl/container/flat_hash_map.h\n@@ -150,7 +150,7 @@ class flat_hash_map : public absl::container_internal::raw_hash_map<\n   //\n   //   std::vector<std::pair<int, std::string>> v = {{1, \"a\"}, {2, \"b\"}};\n   //   absl::flat_hash_map<int, std::string> map7(v.begin(), v.end());\n-  flat_hash_map() {}\n+  flat_hash_map() = default;\n   using Base::Base;\n \n   // flat_hash_map::begin()\ndiff --git a/absl/container/flat_hash_set.h b/absl/container/flat_hash_set.h\nindex 6bf51833fca..03edb5fc93c 100644\n--- a/absl/container/flat_hash_set.h\n+++ b/absl/container/flat_hash_set.h\n@@ -143,7 +143,7 @@ class flat_hash_set\n   //\n   //   std::vector<std::string> v = {\"a\", \"b\"};\n   //   absl::flat_hash_set<std::string> set7(v.begin(), v.end());\n-  flat_hash_set() {}\n+  flat_hash_set() = default;\n   using Base::Base;\n \n   // flat_hash_set::begin()\ndiff --git a/absl/container/internal/common.h b/absl/container/internal/common.h\nindex b06e7113180..99f289fc275 100644\n--- a/absl/container/internal/common.h\n+++ b/absl/container/internal/common.h\n@@ -55,7 +55,7 @@ class node_handle_base {\n  public:\n   using allocator_type = Alloc;\n \n-  constexpr node_handle_base() {}\n+  constexpr node_handle_base() = default;\n   node_handle_base(node_handle_base&& other) noexcept {\n     *this = std::move(other);\n   }\n@@ -114,7 +114,7 @@ class node_handle : public node_handle_base<PolicyTraits, Alloc> {\n  public:\n   using value_type = typename PolicyTraits::value_type;\n \n-  constexpr node_handle() {}\n+  constexpr node_handle() = default;\n \n   value_type& value() const { return PolicyTraits::element(this->slot()); }\n \n@@ -135,7 +135,7 @@ class node_handle<Policy, PolicyTraits, Alloc,\n   using key_type = typename Policy::key_type;\n   using mapped_type = typename Policy::mapped_type;\n \n-  constexpr node_handle() {}\n+  constexpr node_handle() = default;\n \n   auto key() const -> decltype(PolicyTraits::key(this->slot())) {\n     return PolicyTraits::key(this->slot());\ndiff --git a/absl/container/internal/raw_hash_map.h b/absl/container/internal/raw_hash_map.h\nindex 0014cf80805..04252d2d1d0 100644\n--- a/absl/container/internal/raw_hash_map.h\n+++ b/absl/container/internal/raw_hash_map.h\n@@ -56,7 +56,7 @@ class raw_hash_map : public raw_hash_set<Policy, Hash, Eq, Alloc> {\n   using iterator = typename raw_hash_map::raw_hash_set::iterator;\n   using const_iterator = typename raw_hash_map::raw_hash_set::const_iterator;\n \n-  raw_hash_map() {}\n+  raw_hash_map() = default;\n   using raw_hash_map::raw_hash_set::raw_hash_set;\n \n   // The last two template parameters ensure that both arguments are rvalues\ndiff --git a/absl/container/internal/raw_hash_set.h b/absl/container/internal/raw_hash_set.h\nindex 02030bd1a32..2f2c4141a85 100644\n--- a/absl/container/internal/raw_hash_set.h\n+++ b/absl/container/internal/raw_hash_set.h\n@@ -611,7 +611,7 @@ class raw_hash_set {\n     using pointer = absl::remove_reference_t<reference>*;\n     using difference_type = typename raw_hash_set::difference_type;\n \n-    iterator() {}\n+    iterator() = default;\n \n     // PRECONDITION: not an end() iterator.\n     reference operator*() const { return PolicyTraits::element(slot_); }\n@@ -674,7 +674,7 @@ class raw_hash_set {\n     using pointer = typename raw_hash_set::const_pointer;\n     using difference_type = typename raw_hash_set::difference_type;\n \n-    const_iterator() {}\n+    const_iterator() = default;\n     // Implicit construction from iterator.\n     const_iterator(iterator i) : inner_(std::move(i)) {}\n \n@@ -704,10 +704,7 @@ class raw_hash_set {\n   using node_type = node_handle<Policy, hash_policy_traits<Policy>, Alloc>;\n   using insert_return_type = InsertReturnType<iterator, node_type>;\n \n-  raw_hash_set() noexcept(\n-      std::is_nothrow_default_constructible<hasher>::value&&\n-          std::is_nothrow_default_constructible<key_equal>::value&&\n-              std::is_nothrow_default_constructible<allocator_type>::value) {}\n+  raw_hash_set() = default;\n \n   explicit raw_hash_set(size_t bucket_count, const hasher& hash = hasher(),\n                         const key_equal& eq = key_equal(),\ndiff --git a/absl/container/node_hash_map.h b/absl/container/node_hash_map.h\nindex a841f5abd00..a17e4fba78a 100644\n--- a/absl/container/node_hash_map.h\n+++ b/absl/container/node_hash_map.h\n@@ -145,7 +145,7 @@ class node_hash_map\n   //\n   //   std::vector<std::pair<int, std::string>> v = {{1, \"a\"}, {2, \"b\"}};\n   //   absl::node_hash_map<int, std::string> map7(v.begin(), v.end());\n-  node_hash_map() {}\n+  node_hash_map() = default;\n   using Base::Base;\n \n   // node_hash_map::begin()\ndiff --git a/absl/container/node_hash_set.h b/absl/container/node_hash_set.h\nindex 0cd1fe57f96..8e2c57ed73f 100644\n--- a/absl/container/node_hash_set.h\n+++ b/absl/container/node_hash_set.h\n@@ -137,7 +137,7 @@ class node_hash_set\n   //\n   //   std::vector<std::string> v = {\"a\", \"b\"};\n   //   absl::node_hash_set<std::string> set7(v.begin(), v.end());\n-  node_hash_set() {}\n+  node_hash_set() = default;\n   using Base::Base;\n \n   // node_hash_set::begin()\ndiff --git a/absl/strings/internal/char_map.h b/absl/strings/internal/char_map.h\nindex b9108b8cddd..8d44d745818 100644\n--- a/absl/strings/internal/char_map.h\n+++ b/absl/strings/internal/char_map.h\n@@ -32,17 +32,17 @@ namespace strings_internal {\n \n class Charmap {\n  public:\n-  constexpr Charmap() : m_() {}\n+  constexpr Charmap() = default;\n \n   // Initializes with a given char*.  Note that NUL is not treated as\n   // a terminator, but rather a char to be flicked.\n-  Charmap(const char* str, int len) : m_() {\n+  Charmap(const char* str, int len) {\n     while (len--) SetChar(*str++);\n   }\n \n   // Initializes with a given char*.  NUL is treated as a terminator\n   // and will not be in the charmap.\n-  explicit Charmap(const char* str) : m_() {\n+  explicit Charmap(const char* str) {\n     while (*str) SetChar(*str++);\n   }\n \n@@ -127,7 +127,7 @@ class Charmap {\n     m_[c / 64] |= static_cast<uint64_t>(1) << (c % 64);\n   }\n \n-  uint64_t m_[4];\n+  uint64_t m_[4] = {};\n };\n \n // Mirror the char-classifying predicates in <cctype>\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. If `constexpr` is removed, add a test to ensure constexpr construction is still supported.\n2. Prefer explicit constructors (`T() {}`) for clarity regarding default constructibility, exception safety, and `constexpr` status, especially in templates.\n3. Use `constexpr T() noexcept {}` for constructors that should guarantee non-throwing and `constexpr` capabilities.\n4. Evaluate types impacted by losing trivial default constructibility; ensure `T() = default;` for trivial types to preserve their properties.\n5. Consider potential ambiguities with `T() = default;` regarding exception specifications and compiler optimizations; maintain consistency in your design decisions across class hierarchies."
      }
    ],
    "codediff_length": 6204
  },
  {
    "index": 50,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/absl/meta/type_traits.h b/absl/meta/type_traits.h\nindex a456ae4f299..92ad1e559c2 100644\n--- a/absl/meta/type_traits.h\n+++ b/absl/meta/type_traits.h\n@@ -471,12 +471,17 @@ using swap_internal::StdSwapIsUnconstrained;\n // absl::is_trivially_relocatable<T>\n //\n // Detects whether a type is known to be \"trivially relocatable\" -- meaning it\n-// can be relocated without invoking the constructor/destructor, using a form of\n-// move elision.\n-//\n-// This trait is conservative, for backwards compatibility. If it's true then\n-// the type is definitely trivially relocatable, but if it's false then the type\n-// may or may not be.\n+// can be relocated from one place to another as if by memcpy/memmove.\n+// This implies that its object representation doesn't depend on its address,\n+// and also none of its special member functions do anything strange.\n+//\n+// This trait is conservative. If it's true then the type is definitely\n+// trivially relocatable, but there are many types which are \"Platonically\"\n+// trivially relocatable but for which the type trait returns false because\n+// it can't introspect into the special members and see that they're not\n+// doing anything strange. (For example, std::vector<int> is trivially\n+// relocatable on every known STL implementation, but\n+// absl::is_trivially_relocatable<std::vector<int>> remains false.)\n //\n // Example:\n //\n@@ -509,22 +514,27 @@ using swap_internal::StdSwapIsUnconstrained;\n // TODO(b/324278148): If all versions we use have the bug fixed, then\n // remove the condition.\n //\n+// Clang on all platforms fails to detect that a type with a user-provided\n+// move-assignment operator is not trivially relocatable. So in fact we\n+// opt out of Clang altogether, for now.\n+//\n+// TODO: remove the opt-out once Clang's behavior is fixed.\n+//\n // According to https://github.com/abseil/abseil-cpp/issues/1479, this does not\n // work with NVCC either.\n-#if ABSL_HAVE_BUILTIN(__is_trivially_relocatable) &&                 \\\n-    !(defined(__clang__) && (defined(_WIN32) || defined(_WIN64))) && \\\n-    !(defined(__APPLE__)) && !defined(__NVCC__)\n+#if ABSL_HAVE_BUILTIN(__is_trivially_relocatable) && \\\n+    (defined(__cpp_impl_trivially_relocatable) ||    \\\n+     (!defined(__clang__) && !defined(__APPLE__) && !defined(__NVCC__)))\n template <class T>\n struct is_trivially_relocatable\n     : std::integral_constant<bool, __is_trivially_relocatable(T)> {};\n #else\n // Otherwise we use a fallback that detects only those types we can feasibly\n-// detect. Any time that has trivial move-construction and destruction\n-// operations is by definition trivially relocatable.\n+// detect. Any type that is trivially copyable is by definition trivially\n+// relocatable.\n template <class T>\n struct is_trivially_relocatable\n-    : absl::conjunction<absl::is_trivially_move_constructible<T>,\n-                        absl::is_trivially_destructible<T>> {};\n+    : std::is_trivially_copyable<T> {};\n #endif\n \n // absl::is_constant_evaluated()\ndiff --git a/absl/meta/type_traits_test.cc b/absl/meta/type_traits_test.cc\nindex 8f926901244..13a27985e93 100644\n--- a/absl/meta/type_traits_test.cc\n+++ b/absl/meta/type_traits_test.cc\n@@ -751,7 +751,7 @@ TEST(TriviallyRelocatable, PrimitiveTypes) {\n \n // User-defined types can be trivially relocatable as long as they don't have a\n // user-provided move constructor or destructor.\n-TEST(TriviallyRelocatable, UserDefinedTriviallyReconstructible) {\n+TEST(TriviallyRelocatable, UserDefinedTriviallyRelocatable) {\n   struct S {\n     int x;\n     int y;\n@@ -780,6 +780,28 @@ TEST(TriviallyRelocatable, UserProvidedCopyConstructor) {\n   static_assert(!absl::is_trivially_relocatable<S>::value, \"\");\n }\n \n+// A user-provided copy assignment operator disqualifies a type from\n+// being trivially relocatable.\n+TEST(TriviallyRelocatable, UserProvidedCopyAssignment) {\n+  struct S {\n+    S(const S&) = default;\n+    S& operator=(const S&) { return *this; }  // NOLINT(modernize-use-equals-default)\n+  };\n+\n+  static_assert(!absl::is_trivially_relocatable<S>::value, \"\");\n+}\n+\n+// A user-provided move assignment operator disqualifies a type from\n+// being trivially relocatable.\n+TEST(TriviallyRelocatable, UserProvidedMoveAssignment) {\n+  struct S {\n+    S(S&&) = default;\n+    S& operator=(S&&) { return *this; }  // NOLINT(modernize-use-equals-default)\n+  };\n+\n+  static_assert(!absl::is_trivially_relocatable<S>::value, \"\");\n+}\n+\n // A user-provided destructor disqualifies a type from being trivially\n // relocatable.\n TEST(TriviallyRelocatable, UserProvidedDestructor) {\n@@ -796,15 +818,16 @@ TEST(TriviallyRelocatable, UserProvidedDestructor) {\n // __is_trivially_relocatable is fixed there.\n #if defined(ABSL_HAVE_ATTRIBUTE_TRIVIAL_ABI) &&                      \\\n     ABSL_HAVE_BUILTIN(__is_trivially_relocatable) &&                 \\\n-    !(defined(__clang__) && (defined(_WIN32) || defined(_WIN64))) && \\\n-    !defined(__APPLE__)\n+    (defined(__cpp_impl_trivially_relocatable) ||                    \\\n+     (!defined(__clang__) && !defined(__APPLE__) && !defined(__NVCC__)))\n // A type marked with the \"trivial ABI\" attribute is trivially relocatable even\n-// if it has user-provided move/copy constructors and a user-provided\n-// destructor.\n-TEST(TrivallyRelocatable, TrivialAbi) {\n+// if it has user-provided special members.\n+TEST(TriviallyRelocatable, TrivialAbi) {\n   struct ABSL_ATTRIBUTE_TRIVIAL_ABI S {\n     S(S&&) {}       // NOLINT(modernize-use-equals-default)\n     S(const S&) {}  // NOLINT(modernize-use-equals-default)\n+    void operator=(S&&) {}\n+    void operator=(const S&) {}\n     ~S() {}         // NOLINT(modernize-use-equals-default)\n   };\n \n@@ -824,7 +847,7 @@ constexpr int64_t NegateIfConstantEvaluated(int64_t i) {\n \n #endif  // ABSL_HAVE_CONSTANT_EVALUATED\n \n-TEST(TrivallyRelocatable, is_constant_evaluated) {\n+TEST(IsConstantEvaluated, is_constant_evaluated) {\n #ifdef ABSL_HAVE_CONSTANT_EVALUATED\n   constexpr int64_t constant = NegateIfConstantEvaluated(42);\n   EXPECT_EQ(constant, -42);\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. File an upstream bug with Clang for issues with the Windows calling convention that affects `[[trivial_abi]]`. \n2. Review PR #84621 for Clang and verify its compatibility with Abseil's usage of 'trivially relocatable.' \n3. Note that `__is_trivially_relocatable` was disabled for AppleClang 15+ (commit df2c771e) and confirm the need for addressing both Windows and Apple errors.\n4. Encourage contributions to the upstream bug fixes to ensure alignment with P1144, allowing safe replacement of `operator=` with `memcpy` in `inlined_vector::erase` and `inlined_vector::swap`.\n5. Follow up on possible workarounds for tests relying on `absl::is_trivially_relocatable`."
      }
    ],
    "codediff_length": 6017
  },
  {
    "index": 51,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/bgfx.cpp b/src/bgfx.cpp\nindex e34a71020d..00e90c17bc 100644\n--- a/src/bgfx.cpp\n+++ b/src/bgfx.cpp\n@@ -2537,6 +2537,7 @@ namespace bgfx\n \n \tvoid Context::flushTextureUpdateBatch(CommandBuffer& _cmdbuf)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"flushTextureUpdateBatch\", 0xff2040ff);\n \t\tif (m_textureUpdateBatch.sort() )\n \t\t{\n \t\t\tconst uint32_t pos = _cmdbuf.m_pos;\ndiff --git a/src/bgfx_p.h b/src/bgfx_p.h\nindex 7639dafdd8..ec9e26c9b3 100644\n--- a/src/bgfx_p.h\n+++ b/src/bgfx_p.h\n@@ -1700,6 +1700,9 @@ namespace bgfx\n \t\t\t\t\tbind.m_idx = kInvalidHandle;\n \t\t\t\t\tbind.m_type = 0;\n \t\t\t\t\tbind.m_samplerFlags = 0;\n+\t\t\t\t\tbind.m_format = 0;\n+\t\t\t\t\tbind.m_access = 0;\n+\t\t\t\t\tbind.m_mip = 0;\n \t\t\t\t}\n \t\t\t}\n \t\t};\n@@ -2168,6 +2171,8 @@ namespace bgfx\n \t\t\tbx::memSet(m_occlusion, 0xff, sizeof(m_occlusion) );\n \n \t\t\tm_perfStats.viewStats = m_viewStats;\n+\n+\t\t\tbx::memSet(&m_renderItemBind[0], 0, sizeof(m_renderItemBind));\n \t\t}\n \n \t\t~Frame()\n@@ -2445,6 +2450,13 @@ namespace bgfx\n \t{\n \t\tEncoderImpl()\n \t\t{\n+\t\t\t// Although it will be cleared by the discard(), the fact that the\n+\t\t\t// struct is padded to have a size equal to the cache line size,\n+\t\t\t// will leaves bytes uninitialized. This will influence the hashing\n+\t\t\t// as it reads those bytes too. To make this deterministic, we will\n+\t\t\t// clear all bytes (inclusively the padding) before we start.\n+\t\t\tbx::memSet(&m_bind, 0, sizeof(m_bind));\n+\n \t\t\tdiscard(BGFX_DISCARD_ALL);\n \t\t}\n \n@@ -2725,6 +2737,9 @@ namespace bgfx\n \t\t\t\t? BGFX_SAMPLER_INTERNAL_DEFAULT\n \t\t\t\t: _flags\n \t\t\t\t;\n+\t\t\tbind.m_format = 0;\n+\t\t\tbind.m_access = 0;\n+\t\t\tbind.m_mip    = 0;\n \n \t\t\tif (isValid(_sampler) )\n \t\t\t{\ndiff --git a/src/config.h b/src/config.h\nindex b1f5803133..f7b6a5cc04 100644\n--- a/src/config.h\n+++ b/src/config.h\n@@ -324,6 +324,22 @@ BX_STATIC_ASSERT(bx::isPowerOf2(BGFX_CONFIG_MAX_VIEWS), \"BGFX_CONFIG_MAX_VIEWS m\n #\tdefine BGFX_CONFIG_TRANSIENT_INDEX_BUFFER_SIZE (2<<20)\n #endif // BGFX_CONFIG_TRANSIENT_INDEX_BUFFER_SIZE\n \n+#ifndef BGFX_CONFIG_PER_FRAME_SCRATCH_STAGING_BUFFER_SIZE\n+/// Amount of scratch buffer size (per in-flight frame) that will be reserved\n+/// for staging data for copying to the device (such as vertex buffer data,\n+/// texture data, etc). This buffer will be used instead of allocating memory\n+/// on device separately for every data copy.\n+/// Note: Currently only used by the Vulkan backend.\n+#   define BGFX_CONFIG_PER_FRAME_SCRATCH_STAGING_BUFFER_SIZE (32<<20)\n+#endif\n+\n+#ifndef BGFX_CONFIG_MAX_STAGING_SIZE_FOR_SCRACH_BUFFER\n+/// The threshold of data size above which the staging scratch buffer will\n+/// not be used, but instead a separate device memory allocation will take\n+/// place to stage the data for copying to device.\n+#   define BGFX_CONFIG_MAX_STAGING_SIZE_FOR_SCRACH_BUFFER (16 << 20)\n+#endif\n+\n #ifndef BGFX_CONFIG_MAX_INSTANCE_DATA_COUNT\n #\tdefine BGFX_CONFIG_MAX_INSTANCE_DATA_COUNT 5\n #endif // BGFX_CONFIG_MAX_INSTANCE_DATA_COUNT\ndiff --git a/src/renderer_vk.cpp b/src/renderer_vk.cpp\nindex 7b783871c3..a6bdf19a00 100644\n--- a/src/renderer_vk.cpp\n+++ b/src/renderer_vk.cpp\n@@ -1983,7 +1983,12 @@ VK_IMPORT_DEVICE\n \t\t\t\tfor (uint32_t ii = 0; ii < m_numFramesInFlight; ++ii)\n \t\t\t\t{\n \t\t\t\t\tBX_TRACE(\"Create scratch buffer %d\", ii);\n-\t\t\t\t\tm_scratchBuffer[ii].create(size, count);\n+\t\t\t\t\tm_scratchBuffer[ii].createUniform(size, count);\n+\t\t\t\t}\n+\t\t\t\tfor (uint32_t ii = 0; ii < m_numFramesInFlight; ++ii)\n+\t\t\t\t{\n+\t\t\t\t\tBX_TRACE(\"Create scratch staging buffer %d\", ii);\n+\t\t\t\t\tm_scratchStagingBuffer[ii].createStaging(BGFX_CONFIG_PER_FRAME_SCRATCH_STAGING_BUFFER_SIZE);\n \t\t\t\t}\n \t\t\t}\n \n@@ -2051,6 +2056,7 @@ VK_IMPORT_DEVICE\n \t\t\t\tfor (uint32_t ii = 0; ii < m_numFramesInFlight; ++ii)\n \t\t\t\t{\n \t\t\t\t\tm_scratchBuffer[ii].destroy();\n+\t\t\t\t\tm_scratchStagingBuffer[ii].destroy();\n \t\t\t\t}\n \t\t\t\tvkDestroy(m_pipelineCache);\n \t\t\t\tvkDestroy(m_descriptorPool);\n@@ -2115,6 +2121,11 @@ VK_IMPORT_DEVICE\n \t\t\t\tm_scratchBuffer[ii].destroy();\n \t\t\t}\n \n+\t\t\tfor (uint32_t ii = 0; ii < m_numFramesInFlight; ++ii)\n+\t\t\t{\n+\t\t\t\tm_scratchStagingBuffer[ii].destroy();\n+\t\t\t}\n+\n \t\t\tfor (uint32_t ii = 0; ii < BX_COUNTOF(m_frameBuffers); ++ii)\n \t\t\t{\n \t\t\t\tm_frameBuffers[ii].destroy();\n@@ -4276,6 +4287,10 @@ VK_IMPORT_DEVICE\n \n \t\t\tif (0 != depthAspectMask)\n \t\t\t{\n+\t\t\t\tattachments[mrt].colorAttachment = VK_ATTACHMENT_UNUSED;\n+\t\t\t\t// The above is meaningless and not required by the spec, but Khronos\n+\t\t\t\t// Validation Layer has a conditional jump depending on this, even\n+\t\t\t\t// without VK_IMAGE_ASPECT_COLOR_BIT set. Valgrind found this.\n \t\t\t\tattachments[mrt].aspectMask = depthAspectMask;\n \t\t\t\tattachments[mrt].clearValue.depthStencil.stencil = _clear.m_stencil;\n \t\t\t\tattachments[mrt].clearValue.depthStencil.depth   = _clear.m_depth;\n@@ -4313,6 +4328,7 @@ VK_IMPORT_DEVICE\n \n \t\tVkResult allocateMemory(const VkMemoryRequirements* requirements, VkMemoryPropertyFlags propertyFlags, ::VkDeviceMemory* memory) const\n \t\t{\n+\t\t\tBGFX_PROFILER_SCOPE(\"RendererContextVK::allocateMemory\", kColorResource);\n \t\t\tVkMemoryAllocateInfo ma;\n \t\t\tma.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;\n \t\t\tma.pNext = NULL;\n@@ -4339,6 +4355,7 @@ VK_IMPORT_DEVICE\n \n \t\tVkResult createHostBuffer(uint32_t _size, VkMemoryPropertyFlags _flags, ::VkBuffer* _buffer, ::VkDeviceMemory* _memory, const void* _data = NULL)\n \t\t{\n+\t\t\tBGFX_PROFILER_SCOPE(\"createHostBuffer\", kColorResource);\n \t\t\tVkResult result = VK_SUCCESS;\n \n \t\t\tVkBufferCreateInfo bci;\n@@ -4384,6 +4401,7 @@ VK_IMPORT_DEVICE\n \n \t\t\tif (_data != NULL)\n \t\t\t{\n+\t\t\t\tBGFX_PROFILER_SCOPE(\"map and copy data\", kColorResource);\n \t\t\t\tvoid* dst;\n \t\t\t\tresult = vkMapMemory(m_device, *_memory, 0, _size, 0, &dst);\n \t\t\t\tif (VK_SUCCESS != result)\n@@ -4408,6 +4426,40 @@ VK_IMPORT_DEVICE\n \t\t\treturn createHostBuffer(_size, flags, _buffer, _memory, _data);\n \t\t}\n \n+\t\tStagingBufferVK allocFromScratchStagingBuffer(uint32_t _size, uint32_t _align, const void *_data = NULL)\n+\t\t{\n+\t\t\tBGFX_PROFILER_SCOPE(\"allocFromScratchStagingBuffer\", kColorResource);\n+\t\t\tStagingBufferVK result;\n+\t\t\tScratchBufferVK &scratch = m_scratchStagingBuffer[m_cmd.m_currentFrameInFlight];\n+\t\t\tif (_size <= BGFX_CONFIG_MAX_STAGING_SIZE_FOR_SCRACH_BUFFER)\n+\t\t\t{\n+\t\t\t\tuint32_t scratchOffset = scratch.alloc(_size, _align);\n+\t\t\t\tif (scratchOffset != UINT32_MAX)\n+\t\t\t\t{\n+\t\t\t\t\tresult.m_isFromScratch = true;\n+\t\t\t\t\tresult.m_size = _size;\n+\t\t\t\t\tresult.m_offset = scratchOffset;\n+\t\t\t\t\tresult.m_buffer = scratch.m_buffer;\n+\t\t\t\t\tresult.m_deviceMem = scratch.m_deviceMem;\n+\t\t\t\t\tresult.m_data = scratch.m_data + result.m_offset;\n+\t\t\t\t\tif (_data != NULL)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tBGFX_PROFILER_SCOPE(\"copy to scratch\", kColorResource);\n+\t\t\t\t\t\tbx::memCopy(result.m_data, _data, _size);\n+\t\t\t\t\t}\n+\t\t\t\t\treturn result;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\t// Not enough space or too big, we will create a new staging buffer on the spot.\n+\t\t\tresult.m_isFromScratch = false;\n+\t\t\tVK_CHECK(createStagingBuffer(_size, &result.m_buffer, &result.m_deviceMem, _data));\n+\t\t\tresult.m_size = _size;\n+\t\t\tresult.m_offset = 0;\n+\t\t\tresult.m_data = NULL;\n+\t\t\treturn result;\n+\t\t}\n+\n \t\tVkResult createReadbackBuffer(uint32_t _size, ::VkBuffer* _buffer, ::VkDeviceMemory* _memory)\n \t\t{\n \t\t\tconst VkMemoryPropertyFlags flags = 0\n@@ -4440,6 +4492,7 @@ VK_IMPORT_DEVICE\n \t\tint64_t m_presentElapsed;\n \n \t\tScratchBufferVK m_scratchBuffer[BGFX_CONFIG_MAX_FRAME_LATENCY];\n+\t\tScratchBufferVK m_scratchStagingBuffer[BGFX_CONFIG_MAX_FRAME_LATENCY];\n \n \t\tuint32_t        m_numFramesInFlight;\n \t\tCommandQueueVK  m_cmd;\n@@ -4518,6 +4571,7 @@ VK_IMPORT_DEVICE\n \t{                                                                                   \\\n \t\tif (VK_NULL_HANDLE != _obj)                                                     \\\n \t\t{                                                                               \\\n+\t\t\tBGFX_PROFILER_SCOPE(\"vkDestroy\" #_name, kColorResource);                    \\\n \t\t\tvkDestroy##_name(s_renderVK->m_device, _obj.vk, s_renderVK->m_allocatorCb); \\\n \t\t\t_obj = VK_NULL_HANDLE;                                                      \\\n \t\t}                                                                               \\\n@@ -4533,6 +4587,7 @@ VK_DESTROY\n \t{\n \t\tif (VK_NULL_HANDLE != _obj)\n \t\t{\n+\t\t\tBGFX_PROFILER_SCOPE(\"vkFreeMemory\", kColorResource);\n \t\t\tvkFreeMemory(s_renderVK->m_device, _obj.vk, s_renderVK->m_allocatorCb);\n \t\t\t_obj = VK_NULL_HANDLE;\n \t\t}\n@@ -4542,6 +4597,7 @@ VK_DESTROY\n \t{\n \t\tif (VK_NULL_HANDLE != _obj)\n \t\t{\n+\t\t\tBGFX_PROFILER_SCOPE(\"vkDestroySurfaceKHR\", kColorResource);\n \t\t\tvkDestroySurfaceKHR(s_renderVK->m_instance, _obj.vk, s_renderVK->m_allocatorCb);\n \t\t\t_obj = VK_NULL_HANDLE;\n \t\t}\n@@ -4551,6 +4607,7 @@ VK_DESTROY\n \t{\n \t\tif (VK_NULL_HANDLE != _obj)\n \t\t{\n+\t\t\tBGFX_PROFILER_SCOPE(\"vkFreeDescriptorSets\", kColorResource);\n \t\t\tvkFreeDescriptorSets(s_renderVK->m_device, s_renderVK->m_descriptorPool, 1, &_obj);\n \t\t\t_obj = VK_NULL_HANDLE;\n \t\t}\n@@ -4571,14 +4628,12 @@ VK_DESTROY\n \t\ts_renderVK->release(_obj);\n \t}\n \n-\tvoid ScratchBufferVK::create(uint32_t _size, uint32_t _count)\n+\tvoid ScratchBufferVK::create(uint32_t _size, uint32_t _count, VkBufferUsageFlags usage, uint32_t _align)\n \t{\n \t\tconst VkAllocationCallbacks* allocatorCb = s_renderVK->m_allocatorCb;\n \t\tconst VkDevice device = s_renderVK->m_device;\n-\t\tconst VkPhysicalDeviceLimits& deviceLimits = s_renderVK->m_deviceProperties.limits;\n \n-\t\tconst uint32_t align = uint32_t(deviceLimits.minUniformBufferOffsetAlignment);\n-\t\tconst uint32_t entrySize = bx::strideAlign(_size, align);\n+\t\tconst uint32_t entrySize = bx::strideAlign(_size, _align);\n \t\tconst uint32_t totalSize = entrySize * _count;\n \n \t\tVkBufferCreateInfo bci;\n@@ -4586,7 +4641,7 @@ VK_DESTROY\n \t\tbci.pNext = NULL;\n \t\tbci.flags = 0;\n \t\tbci.size  = totalSize;\n-\t\tbci.usage = VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT;\n+\t\tbci.usage = usage;\n \t\tbci.sharingMode           = VK_SHARING_MODE_EXCLUSIVE;\n \t\tbci.queueFamilyIndexCount = 0;\n \t\tbci.pQueueFamilyIndices   = NULL;\n@@ -4616,12 +4671,27 @@ VK_DESTROY\n \n \t\tm_size = (uint32_t)mr.size;\n \t\tm_pos  = 0;\n+\t\tm_align = _align;\n \n \t\tVK_CHECK(vkBindBufferMemory(device, m_buffer, m_deviceMem, 0) );\n \n \t\tVK_CHECK(vkMapMemory(device, m_deviceMem, 0, m_size, 0, (void**)&m_data) );\n \t}\n \n+\tvoid ScratchBufferVK::createUniform(uint32_t _size, uint32_t _count)\n+\t{\n+\t\tconst VkPhysicalDeviceLimits& deviceLimits = s_renderVK->m_deviceProperties.limits;\n+\t\tconst uint32_t align = uint32_t(deviceLimits.minUniformBufferOffsetAlignment);\n+\t\tcreate(_size, _count, VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT, align);\n+\t}\n+\n+\tvoid ScratchBufferVK::createStaging(uint32_t _size)\n+\t{\n+\t\tconst VkPhysicalDeviceLimits& deviceLimits = s_renderVK->m_deviceProperties.limits;\n+\t\tconst uint32_t align = uint32_t(deviceLimits.optimalBufferCopyOffsetAlignment);\n+\t\tcreate(_size, 1, VK_BUFFER_USAGE_TRANSFER_SRC_BIT | VK_BUFFER_USAGE_TRANSFER_DST_BIT, align);\n+\t}\n+\n \tvoid ScratchBufferVK::destroy()\n \t{\n \t\treset();\n@@ -4637,26 +4707,34 @@ VK_DESTROY\n \t\tm_pos = 0;\n \t}\n \n-\tuint32_t ScratchBufferVK::write(const void* _data, uint32_t _size)\n+\tuint32_t ScratchBufferVK::alloc(uint32_t _size, uint32_t _minAlign)\n \t{\n-\t\tBX_ASSERT(m_pos < m_size, \"Out of scratch buffer memory\");\n+\t\tconst uint32_t align = bx::uint32_lcm(m_align, _minAlign);\n+\t\tconst uint32_t dstOffset = bx::strideAlign(m_pos, align);\n+\t\tif (dstOffset + _size <= m_size)\n+\t\t{\n+\t\t\tm_pos = dstOffset + _size;\n+\t\t\treturn dstOffset;\n+\t\t} else\n+\t\t{\n+\t\t\treturn UINT32_MAX;\n+\t\t}\n+\t}\n \n-\t\tconst uint32_t offset = m_pos;\n+\tuint32_t ScratchBufferVK::write(const void* _data, uint32_t _size, uint32_t _minAlign)\n+\t{\n+\t\tuint32_t dstOffset = alloc(_size, _minAlign);\n+\t\tBX_ASSERT(dstOffset != UINT32_MAX, \"Not enough space on ScratchBuffer left to allocate %u bytes with alignment %u.\", _size, _minAlign);\n \n \t\tif (_size > 0)\n \t\t{\n-\t\t\tbx::memCopy(&m_data[m_pos], _data, _size);\n-\n-\t\t\tconst VkPhysicalDeviceLimits& deviceLimits = s_renderVK->m_deviceProperties.limits;\n-\t\t\tconst uint32_t align = uint32_t(deviceLimits.minUniformBufferOffsetAlignment);\n-\t\t\tconst uint32_t alignedSize = bx::strideAlign(_size, align);\n-\n-\t\t\tm_pos += alignedSize;\n+\t\t\tbx::memCopy(&m_data[dstOffset], _data, _size);\n \t\t}\n \n-\t\treturn offset;\n+\t\treturn dstOffset;\n \t}\n \n+\n \tvoid ScratchBufferVK::flush()\n \t{\n \t\tconst VkPhysicalDeviceLimits& deviceLimits = s_renderVK->m_deviceProperties.limits;\n@@ -4722,15 +4800,13 @@ VK_DESTROY\n \t\tBGFX_PROFILER_SCOPE(\"BufferVK::update\", kColorFrame);\n \t\tBX_UNUSED(_discard);\n \n-\t\tVkBuffer stagingBuffer;\n-\t\tVkDeviceMemory stagingMem;\n-\t\tVK_CHECK(s_renderVK->createStagingBuffer(_size, &stagingBuffer, &stagingMem, _data) );\n+\t\tStagingBufferVK stagingBuffer = s_renderVK->allocFromScratchStagingBuffer(_size, 8, _data);\n \n \t\tVkBufferCopy region;\n-\t\tregion.srcOffset = 0;\n+\t\tregion.srcOffset = stagingBuffer.m_offset;\n \t\tregion.dstOffset = _offset;\n \t\tregion.size      = _size;\n-\t\tvkCmdCopyBuffer(_commandBuffer, stagingBuffer, m_buffer, 1, &region);\n+\t\tvkCmdCopyBuffer(_commandBuffer, stagingBuffer.m_buffer, m_buffer, 1, &region);\n \n \t\tsetMemoryBarrier(\n \t\t\t  _commandBuffer\n@@ -4738,8 +4814,11 @@ VK_DESTROY\n \t\t\t, VK_PIPELINE_STAGE_TRANSFER_BIT\n \t\t\t);\n \n-\t\ts_renderVK->release(stagingBuffer);\n-\t\ts_renderVK->release(stagingMem);\n+\t\tif (!stagingBuffer.m_isFromScratch)\n+\t\t{\n+\t\t\ts_renderVK->release(stagingBuffer.m_buffer);\n+\t\t\ts_renderVK->release(stagingBuffer.m_deviceMem);\n+\t\t}\n \t}\n \n \tvoid BufferVK::destroy()\n@@ -5683,6 +5762,7 @@ VK_DESTROY\n \n \tvoid ReadbackVK::readback(VkDeviceMemory _memory, VkDeviceSize _offset, void* _data, uint8_t _mip) const\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"ReadbackVK::readback\", kColorResource);\n \t\tif (m_image == VK_NULL_HANDLE)\n \t\t{\n \t\t\treturn;\n@@ -5708,6 +5788,7 @@ VK_DESTROY\n \n \tVkResult TextureVK::create(VkCommandBuffer _commandBuffer, uint32_t _width, uint32_t _height, uint64_t _flags, VkFormat _format)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"TextureVK::create\", kColorResource);\n \t\tBX_ASSERT(0 != (_flags & BGFX_TEXTURE_RT_MASK), \"\");\n \t\t_flags |= BGFX_TEXTURE_RT_WRITE_ONLY;\n \n@@ -5742,6 +5823,7 @@ VK_DESTROY\n \n \tVkResult TextureVK::createImages(VkCommandBuffer _commandBuffer)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"TextureVK::createImages\", kColorResource);\n \t\tVkResult result = VK_SUCCESS;\n \n \t\tconst VkAllocationCallbacks* allocatorCb = s_renderVK->m_allocatorCb;\n@@ -5871,6 +5953,7 @@ VK_DESTROY\n \n \tvoid* TextureVK::create(VkCommandBuffer _commandBuffer, const Memory* _mem, uint64_t _flags, uint8_t _skip)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"TextureVK::create\", kColorResource);\n \t\tbimg::ImageContainer imageContainer;\n \n \t\tif (bimg::imageParse(imageContainer, _mem->data, _mem->size) )\n@@ -6097,34 +6180,50 @@ VK_DESTROY\n \t\t\tif (totalMemSize > 0)\n \t\t\t{\n \t\t\t\tconst VkDevice device = s_renderVK->m_device;\n-\n-\t\t\t\tVkBuffer stagingBuffer;\n-\t\t\t\tVkDeviceMemory stagingDeviceMem;\n-\t\t\t\tVK_CHECK(s_renderVK->createStagingBuffer(totalMemSize, &stagingBuffer, &stagingDeviceMem) );\n-\n+\t\t\t\tconst bimg::ImageBlockInfo &dstBlockInfo = bimg::getBlockInfo(bimg::TextureFormat::Enum(m_textureFormat));\n+\t\t\t\tStagingBufferVK stagingBuffer = s_renderVK->allocFromScratchStagingBuffer(totalMemSize, dstBlockInfo.blockSize);\n \t\t\t\tuint8_t* mappedMemory;\n-\t\t\t\tVK_CHECK(vkMapMemory(\n-\t\t\t\t\t  device\n-\t\t\t\t\t, stagingDeviceMem\n-\t\t\t\t\t, 0\n-\t\t\t\t\t, totalMemSize\n-\t\t\t\t\t, 0\n-\t\t\t\t\t, (void**)&mappedMemory\n-\t\t\t\t\t) );\n+\n+\t\t\t\tif (!stagingBuffer.m_isFromScratch)\n+\t\t\t\t{\n+\t\t\t\t\tVK_CHECK(vkMapMemory(\n+\t\t\t\t\t\t  device\n+\t\t\t\t\t\t, stagingBuffer.m_deviceMem\n+\t\t\t\t\t\t, 0\n+\t\t\t\t\t\t, totalMemSize\n+\t\t\t\t\t\t, 0\n+\t\t\t\t\t\t, (void**)&mappedMemory\n+\t\t\t\t\t\t) );\n+\t\t\t\t} else\n+\t\t\t\t{\n+\t\t\t\t\tmappedMemory = stagingBuffer.m_data;\n+\t\t\t\t}\n \n \t\t\t\t// copy image to staging buffer\n \t\t\t\tfor (uint32_t ii = 0; ii < numSrd; ++ii)\n \t\t\t\t{\n \t\t\t\t\tbx::memCopy(mappedMemory, imageInfos[ii].data, imageInfos[ii].size);\n \t\t\t\t\tmappedMemory += imageInfos[ii].size;\n+\t\t\t\t\tbufferCopyInfo[ii].bufferOffset += stagingBuffer.m_offset;\n+\t\t\t\t\tBX_ASSERT(\n+\t\t\t\t\t\t  bx::uint32_mod(bufferCopyInfo[ii].bufferOffset, dstBlockInfo.blockSize) == 0\n+\t\t\t\t\t\t, \"Alignment for subimage %u is not aligned correctly (%u).\"\n+\t\t\t\t\t\t, ii, bufferCopyInfo[ii].bufferOffset, dstBlockInfo.blockSize\n+\t\t\t\t\t\t);\n \t\t\t\t}\n \n-\t\t\t\tvkUnmapMemory(device, stagingDeviceMem);\n+\t\t\t\tif (!stagingBuffer.m_isFromScratch)\n+\t\t\t\t{\n+\t\t\t\t\tvkUnmapMemory(device, stagingBuffer.m_deviceMem);\n+\t\t\t\t}\n \n-\t\t\t\tcopyBufferToTexture(_commandBuffer, stagingBuffer, numSrd, bufferCopyInfo);\n+\t\t\t\tcopyBufferToTexture(_commandBuffer, stagingBuffer.m_buffer, numSrd, bufferCopyInfo);\n \n-\t\t\t\ts_renderVK->release(stagingBuffer);\n-\t\t\t\ts_renderVK->release(stagingDeviceMem);\n+\t\t\t\tif (!stagingBuffer.m_isFromScratch)\n+\t\t\t\t{\n+\t\t\t\t\ts_renderVK->release(stagingBuffer.m_buffer);\n+\t\t\t\t\ts_renderVK->release(stagingBuffer.m_deviceMem);\n+\t\t\t\t}\n \t\t\t}\n \t\t\telse\n \t\t\t{\n@@ -6148,6 +6247,7 @@ VK_DESTROY\n \n \tvoid TextureVK::destroy()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"TextureVK::destroy\", kColorResource);\n \t\tm_readback.destroy();\n \n \t\tif (VK_NULL_HANDLE != m_textureImage)\n@@ -6168,12 +6268,14 @@ VK_DESTROY\n \n \tvoid TextureVK::update(VkCommandBuffer _commandBuffer, uint8_t _side, uint8_t _mip, const Rect& _rect, uint16_t _z, uint16_t _depth, uint16_t _pitch, const Memory* _mem)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"TextureVK::update\", kColorResource);\n \t\tconst uint32_t bpp = bimg::getBitsPerPixel(bimg::TextureFormat::Enum(m_textureFormat) );\n+\t\tconst bimg::ImageBlockInfo& blockInfo = bimg::getBlockInfo(bimg::TextureFormat::Enum(m_textureFormat) );\n \t\tuint32_t rectpitch = _rect.m_width * bpp / 8;\n \t\tuint32_t slicepitch = rectpitch * _rect.m_height;\n+\t\tuint32_t align = blockInfo.blockSize;\n \t\tif (bimg::isCompressed(bimg::TextureFormat::Enum(m_textureFormat) ) )\n \t\t{\n-\t\t\tconst bimg::ImageBlockInfo& blockInfo = bimg::getBlockInfo(bimg::TextureFormat::Enum(m_textureFormat) );\n \t\t\trectpitch  = (_rect.m_width  / blockInfo.blockWidth ) * blockInfo.blockSize;\n \t\t\tslicepitch = (_rect.m_height / blockInfo.blockHeight) * rectpitch;\n \t\t}\n@@ -6209,9 +6311,11 @@ VK_DESTROY\n \t\t\t};\n \t\t}\n \n-\t\tVkBuffer stagingBuffer = VK_NULL_HANDLE;\n-\t\tVkDeviceMemory stagingDeviceMem = VK_NULL_HANDLE;\n-\t\tVK_CHECK(s_renderVK->createStagingBuffer(size, &stagingBuffer, &stagingDeviceMem, data) );\n+\t\tStagingBufferVK stagingBuffer = s_renderVK->allocFromScratchStagingBuffer(size, align, data);\n+\t\tregion.bufferOffset += stagingBuffer.m_offset;\n+\t\tBX_ASSERT(region.bufferOffset % align == 0,\n+\t\t\t\t\"Alignment for image (mip %u, z %s) is not aligned correctly (%u).\",\n+\t\t\t\t_mip, _z, region.bufferOffset, align);\n \n \t\tif (VK_IMAGE_VIEW_TYPE_3D == m_type)\n \t\t{\n@@ -6227,10 +6331,13 @@ VK_DESTROY\n \t\t\tregion.imageSubresource.baseArrayLayer = _z;\n \t\t}\n \n-\t\tcopyBufferToTexture(_commandBuffer, stagingBuffer, 1, &region);\n+\t\tcopyBufferToTexture(_commandBuffer, stagingBuffer.m_buffer, 1, &region);\n \n-\t\ts_renderVK->release(stagingBuffer);\n-\t\ts_renderVK->release(stagingDeviceMem);\n+\t\tif (!stagingBuffer.m_isFromScratch)\n+\t\t{\n+\t\t\ts_renderVK->release(stagingBuffer.m_buffer);\n+\t\t\ts_renderVK->release(stagingBuffer.m_deviceMem);\n+\t\t}\n \n \t\tif (NULL != temp)\n \t\t{\n@@ -6298,6 +6405,7 @@ VK_DESTROY\n \n \t\tif (needMipGen)\n \t\t{\n+\t\t\tBGFX_PROFILER_SCOPE(\"TextureVK::resolve genMipmaps\", kColorResource);\n \t\t\tsetImageMemoryBarrier(_commandBuffer, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL);\n \n \t\t\tint32_t mipWidth  = bx::max<int32_t>(int32_t(m_width)  >> _mip, 1);\n@@ -6385,6 +6493,16 @@ VK_DESTROY\n \n \t\tsetImageMemoryBarrier(_commandBuffer, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL);\n \n+\n+\t\tbimg::TextureFormat::Enum tf = bimg::TextureFormat::Enum(m_textureFormat);\n+\t\tconst bimg::ImageBlockInfo &blockInfo = bimg::getBlockInfo(tf);\n+\t\tfor (uint32_t i = 0; i < _bufferImageCopyCount; ++i) {\n+\t\t\tBX_ASSERT(\n+\t\t\t\t  bx::uint32_mod(_bufferImageCopy[i].bufferOffset, blockInfo.blockSize) == 0\n+\t\t\t\t, \"Misaligned texture of type %s to offset %u, which is not a multiple of %u.\"\n+\t\t\t\t, bimg::getName(tf), _bufferImageCopy[i].bufferOffset, blockInfo.blockSize\n+\t\t\t\t);\n+\t\t}\n \t\tvkCmdCopyBufferToImage(\n \t\t\t  _commandBuffer\n \t\t\t, _stagingBuffer\n@@ -6664,6 +6782,7 @@ VK_DESTROY\n \n \tvoid SwapChainVK::update(VkCommandBuffer _commandBuffer, void* _nwh, const Resolution& _resolution)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"SwapChainVK::update\", kColorFrame);\n \t\tconst VkPhysicalDevice physicalDevice = s_renderVK->m_physicalDevice;\n \n \t\tm_lastImageRenderedSemaphore = VK_NULL_HANDLE;\n@@ -6753,6 +6872,7 @@ VK_DESTROY\n \n \tVkResult SwapChainVK::createSurface()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"SwapChainVK::createSurface\", kColorFrame);\n \t\tVkResult result = VK_ERROR_INITIALIZATION_FAILED;\n \n \t\tconst VkInstance instance = s_renderVK->m_instance;\n@@ -6910,6 +7030,7 @@ VK_DESTROY\n \n \tVkResult SwapChainVK::createSwapChain()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"SwapChainVK::createSwapchain\", kColorFrame);\n \t\tVkResult result = VK_SUCCESS;\n \n \t\tconst VkPhysicalDevice physicalDevice = s_renderVK->m_physicalDevice;\n@@ -7124,6 +7245,7 @@ VK_DESTROY\n \n \tvoid SwapChainVK::releaseSwapChain()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"SwapChainVK::releaseSwapChain\", kColorFrame);\n \t\tfor (uint32_t ii = 0; ii < BX_COUNTOF(m_backBufferColorImageView); ++ii)\n \t\t{\n \t\t\trelease(m_backBufferColorImageView[ii]);\n@@ -7142,6 +7264,7 @@ VK_DESTROY\n \n \tVkResult SwapChainVK::createAttachments(VkCommandBuffer _commandBuffer)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"SwapChainVK::createAttachments\", kColorFrame);\n \t\tVkResult result = VK_SUCCESS;\n \n \t\tconst uint32_t samplerIndex = (m_resolution.reset & BGFX_RESET_MSAA_MASK) >> BGFX_RESET_MSAA_SHIFT;\n@@ -7217,6 +7340,7 @@ VK_DESTROY\n \n \tvoid SwapChainVK::releaseAttachments()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"SwapChainVK::releaseAttachments\", kColorFrame);\n \t\trelease(m_backBufferDepthStencilImageView);\n \t\trelease(m_backBufferColorMsaaImageView);\n \n@@ -7226,6 +7350,7 @@ VK_DESTROY\n \n \tVkResult SwapChainVK::createFrameBuffer()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"SwapChainVK::createFrameBuffer\", kColorFrame);\n \t\tVkResult result = VK_SUCCESS;\n \n \t\tconst VkDevice device = s_renderVK->m_device;\n@@ -7287,6 +7412,7 @@ VK_DESTROY\n \n \tuint32_t SwapChainVK::findPresentMode(bool _vsync)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"SwapChainVK::findPresentMode\", kColorFrame);\n \t\tVkResult result = VK_SUCCESS;\n \n \t\tconst VkPhysicalDevice physicalDevice = s_renderVK->m_physicalDevice;\n@@ -7348,6 +7474,7 @@ VK_DESTROY\n \n \tTextureFormat::Enum SwapChainVK::findSurfaceFormat(TextureFormat::Enum _format, VkColorSpaceKHR _colorSpace, bool _srgb)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"SwapChainVK::findSurfaceFormat\", kColorFrame);\n \t\tVkResult result = VK_SUCCESS;\n \n \t\tTextureFormat::Enum selectedFormat = TextureFormat::Count;\n@@ -7421,6 +7548,7 @@ VK_DESTROY\n \n \tbool SwapChainVK::acquire(VkCommandBuffer _commandBuffer)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"SwapChainVK::acquire\", kColorFrame);\n \t\tif (VK_NULL_HANDLE == m_swapChain\n \t\t||  m_needToRefreshSwapchain)\n \t\t{\n@@ -7555,6 +7683,7 @@ VK_DESTROY\n \n \tvoid FrameBufferVK::create(uint8_t _num, const Attachment* _attachment)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"FrameBufferVK::create\", kColorFrame);\n \t\tm_numTh = _num;\n \t\tbx::memCopy(m_attachment, _attachment, sizeof(Attachment) * _num);\n \n@@ -7563,6 +7692,7 @@ VK_DESTROY\n \n \tVkResult FrameBufferVK::create(uint16_t _denseIdx, void* _nwh, uint32_t _width, uint32_t _height, TextureFormat::Enum _format, TextureFormat::Enum _depthFormat)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"FrameBufferVK::create\", kColorFrame);\n \t\tVkResult result = VK_SUCCESS;\n \n \t\tResolution resolution = s_renderVK->m_resolution;\n@@ -7599,6 +7729,7 @@ VK_DESTROY\n \n \tvoid FrameBufferVK::preReset()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"FrameBufferVK::preReset\", kColorFrame);\n \t\tif (VK_NULL_HANDLE != m_framebuffer)\n \t\t{\n \t\t\ts_renderVK->release(m_framebuffer);\n@@ -7612,6 +7743,7 @@ VK_DESTROY\n \n \tvoid FrameBufferVK::postReset()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"FrameBufferVK::postReset\", kColorFrame);\n \t\tif (m_numTh > 0)\n \t\t{\n \t\t\tconst VkDevice device = s_renderVK->m_device;\n@@ -7672,6 +7804,7 @@ VK_DESTROY\n \n \tvoid FrameBufferVK::update(VkCommandBuffer _commandBuffer, const Resolution& _resolution)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"FrameBufferVK::update\", kColorResource);\n \t\tm_swapChain.update(_commandBuffer, m_nwh, _resolution);\n \t\tVK_CHECK(s_renderVK->getRenderPass(m_swapChain, &m_renderPass) );\n \t\tm_width   = _resolution.width;\n@@ -7686,6 +7819,7 @@ VK_DESTROY\n \t\t\treturn;\n \t\t}\n \n+\t\tBGFX_PROFILER_SCOPE(\"FrameBufferVK::resolve\", kColorFrame);\n \t\tif (NULL == m_nwh)\n \t\t{\n \t\t\tfor (uint32_t ii = 0; ii < m_numTh; ++ii)\n@@ -7717,6 +7851,7 @@ VK_DESTROY\n \n \tuint16_t FrameBufferVK::destroy()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"FrameBufferVK::destroy\", kColorFrame);\n \t\tpreReset();\n \n \t\tif (NULL != m_nwh)\n@@ -7739,6 +7874,7 @@ VK_DESTROY\n \n \tbool FrameBufferVK::acquire(VkCommandBuffer _commandBuffer)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"FrameBufferVK::acquire\", kColorFrame);\n \t\tbool acquired = true;\n \n \t\tif (NULL != m_nwh)\n@@ -7755,6 +7891,7 @@ VK_DESTROY\n \n \tvoid FrameBufferVK::present()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"FrameBufferVK::present\", kColorFrame);\n \t\tm_swapChain.present();\n \t\tm_needPresent = false;\n \t}\n@@ -7773,6 +7910,7 @@ VK_DESTROY\n \t\tm_queue = _queue;\n \t\tm_numFramesInFlight = bx::clamp<uint32_t>(_numFramesInFlight, 1, BGFX_CONFIG_MAX_FRAME_LATENCY);\n \t\tm_activeCommandBuffer = VK_NULL_HANDLE;\n+\t\tm_consumeIndex = 0;\n \n \t\treturn reset();\n \t}\n@@ -7873,6 +8011,7 @@ VK_DESTROY\n \n \tVkResult CommandQueueVK::alloc(VkCommandBuffer* _commandBuffer)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"CommandQueueVK::alloc\", kColorResource);\n \t\tVkResult result = VK_SUCCESS;\n \n \t\tif (m_activeCommandBuffer == VK_NULL_HANDLE)\n@@ -7944,6 +8083,7 @@ VK_DESTROY\n \n \tvoid CommandQueueVK::kick(bool _wait)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"CommandQueueVK::kick\", kColorDraw);\n \t\tif (VK_NULL_HANDLE != m_activeCommandBuffer)\n \t\t{\n \t\t\tconst VkDevice device = s_renderVK->m_device;\n@@ -7975,11 +8115,14 @@ VK_DESTROY\n \t\t\tm_numWaitSemaphores   = 0;\n \t\t\tm_numSignalSemaphores = 0;\n \n-\t\t\tVK_CHECK(vkQueueSubmit(m_queue, 1, &si, m_completedFence) );\n+\t\t\t{\n+\t\t\t\tBGFX_PROFILER_SCOPE(\"CommandQueueVK::kick vkQueueSubmit\", kColorDraw);\n+\t\t\t\tVK_CHECK(vkQueueSubmit(m_queue, 1, &si, m_completedFence) );\n+\t\t\t}\n \n \t\t\tif (_wait)\n \t\t\t{\n-\t\t\t\tBGFX_PROFILER_SCOPE(\"vkWaitForFences\", kColorFrame);\n+\t\t\t\tBGFX_PROFILER_SCOPE(\"CommandQueue::kick vkWaitForFences\", kColorDraw);\n \t\t\t\tVK_CHECK(vkWaitForFences(device, 1, &m_completedFence, VK_TRUE, UINT64_MAX) );\n \t\t\t}\n \n@@ -7992,6 +8135,7 @@ VK_DESTROY\n \n \tvoid CommandQueueVK::finish(bool _finishAll)\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"CommandQueueVK::finish\", kColorDraw);\n \t\tif (_finishAll)\n \t\t{\n \t\t\tfor (uint32_t ii = 0; ii < m_numFramesInFlight; ++ii)\n@@ -8017,6 +8161,7 @@ VK_DESTROY\n \n \tvoid CommandQueueVK::consume()\n \t{\n+\t\tBGFX_PROFILER_SCOPE(\"CommandQueueVK::consume\", kColorResource);\n \t\tm_consumeIndex = (m_consumeIndex + 1) % m_numFramesInFlight;\n \n \t\tfor (const Resource& resource : m_release[m_consumeIndex])\n@@ -8256,6 +8401,9 @@ VK_DESTROY\n \t\tScratchBufferVK& scratchBuffer = m_scratchBuffer[m_cmd.m_currentFrameInFlight];\n \t\tscratchBuffer.reset();\n \n+\t\tScratchBufferVK& scratchStagingBuffer = m_scratchStagingBuffer[m_cmd.m_currentFrameInFlight];\n+\t\tscratchStagingBuffer.reset();\n+\n \t\tsetMemoryBarrier(\n \t\t\t  m_commandBuffer\n \t\t\t, VK_PIPELINE_STAGE_TRANSFER_BIT\n@@ -9212,7 +9360,14 @@ VK_DESTROY\n \n \t\tm_presentElapsed = 0;\n \n-\t\tscratchBuffer.flush();\n+\t\t{\n+\t\t\tBGFX_PROFILER_SCOPE(\"scratchBuffer::flush\", kColorResource);\n+\t\t\tscratchBuffer.flush();\n+\t\t}\n+\t\t{\n+\t\t\tBGFX_PROFILER_SCOPE(\"scratchStagingBuffer::flush\", kColorResource);\n+\t\t\tscratchStagingBuffer.flush();\n+\t\t}\n \n \t\tfor (uint16_t ii = 0; ii < m_numWindows; ++ii)\n \t\t{\ndiff --git a/src/renderer_vk.h b/src/renderer_vk.h\nindex 0d1aebfb1d..7f496baa25 100644\n--- a/src/renderer_vk.h\n+++ b/src/renderer_vk.h\n@@ -389,6 +389,15 @@ VK_DESTROY_FUNC(DescriptorSet);\n \t\tHashMap m_hashMap;\n \t};\n \n+\tstruct StagingBufferVK {\n+\t\tVkBuffer m_buffer;\n+\t\tVkDeviceMemory m_deviceMem;\n+\t\tuint8_t *m_data;\n+\t\tuint32_t m_size;\n+\t\tuint32_t m_offset;\n+\t\tbool m_isFromScratch;\n+\t};\n+\n \tclass ScratchBufferVK\n \t{\n \tpublic:\n@@ -400,10 +409,13 @@ VK_DESTROY_FUNC(DescriptorSet);\n \t\t{\n \t\t}\n \n-\t\tvoid create(uint32_t _size, uint32_t _count);\n+\t\tvoid create(uint32_t _size, uint32_t _count, VkBufferUsageFlags _usage, uint32_t align);\n+\t\tvoid createUniform(uint32_t _size, uint32_t _count);\n+\t\tvoid createStaging(uint32_t _size);\n \t\tvoid destroy();\n \t\tvoid reset();\n-\t\tuint32_t write(const void* _data, uint32_t _size);\n+\t\tuint32_t alloc(uint32_t _size, uint32_t _minAlign = 1);\n+\t\tuint32_t write(const void* _data, uint32_t _size, uint32_t _minAlign = 1);\n \t\tvoid flush();\n \n \t\tVkBuffer m_buffer;\n@@ -411,6 +423,7 @@ VK_DESTROY_FUNC(DescriptorSet);\n \t\tuint8_t* m_data;\n \t\tuint32_t m_size;\n \t\tuint32_t m_pos;\n+\t\tuint32_t m_align;\n \t};\n \n \tstruct BufferVK\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Crash Issue**: Examples crash with `VK_ERROR_DEVICE_LOST`. Test the branch further by running `example-01-cubesDebug` in Debug mode.\n\n2. **Semaphore Error**: The `vkAcquireNextImageKHR` semaphore bug is also present in `master`. Address this before further testing.\n\n3. **Alignment Error**: Encountered validation error `VK_FORMAT_B8G8R8A8_UNORM` states `bufferOffset` in `vkCmdCopyBufferToImage` must be aligned. Check `bx::strideAlign` usage to ensure correctness.\n\n4. **Invalid Image Offsets**: Validation errors for `imageOffset` and `imageExtent` imply buffer offsets must match image dimensions. Review and correct bounds for image regions.\n\n5. **Debug Assistance**: Add logging and assertions to identify crash cause. Capture full error output during crash for further analysis.\n\n6. **Next Steps**: Confirm compilation matches execution, reproduce issues accurately, and share crash outputs."
      }
    ],
    "codediff_length": 28322
  },
  {
    "index": 52,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/node/Node.cpp b/node/Node.cpp\nindex 9f195a1069..1dbb6d19d7 100644\n--- a/node/Node.cpp\n+++ b/node/Node.cpp\n@@ -236,13 +236,14 @@ ZT1_ResultCode Node::processBackgroundTasks(uint64_t now,volatile uint64_t *next\n \t\t\tstd::vector< SharedPtr<Network> > needConfig;\n \t\t\t{\n \t\t\t\tMutex::Lock _l(_networks_m);\n-\t\t\t\tfor(std::map< uint64_t,SharedPtr<Network> >::const_iterator n(_networks.begin());n!=_networks.end();++n) {\n-\t\t\t\t\tSharedPtr<NetworkConfig> nc(n->second->config2());\n-\t\t\t\t\tif (((now - n->second->lastConfigUpdate()) >= ZT_NETWORK_AUTOCONF_DELAY)||(!nc))\n-\t\t\t\t\t\tneedConfig.push_back(n->second);\n+\t\t\t\tfor(std::vector< SharedPtr<Network> >::const_iterator n(_networks.begin());n!=_networks.end();++n) {\n+\t\t\t\t\tSharedPtr<NetworkConfig> nc((*n)->config2());\n+\t\t\t\t\tif (((now - (*n)->lastConfigUpdate()) >= ZT_NETWORK_AUTOCONF_DELAY)||(!nc))\n+\t\t\t\t\t\tneedConfig.push_back(*n);\n \t\t\t\t\tif (nc)\n \t\t\t\t\t\tnetworkRelays.insert(networkRelays.end(),nc->relays().begin(),nc->relays().end());\n \t\t\t\t}\n+\t\t\t\tstd::sort(_networks.begin(),_networks.end());\n \t\t\t}\n \n \t\t\t// Request updated configuration for networks that need it\n@@ -310,19 +311,24 @@ ZT1_ResultCode Node::processBackgroundTasks(uint64_t now,volatile uint64_t *next\n ZT1_ResultCode Node::join(uint64_t nwid)\n {\n \tMutex::Lock _l(_networks_m);\n-\tSharedPtr<Network> &nwe = _networks[nwid];\n-\tif (!nwe)\n-\t\tnwe = SharedPtr<Network>(new Network(RR,nwid));\n+\tSharedPtr<Network> nw = _network(nwid);\n+\tif(!nw) {\n+\t\t_networks.push_back(SharedPtr<Network>(new Network(RR,nwid)));\n+\t\tstd::sort(_networks.begin(),_networks.end());\n+\t}\n \treturn ZT1_RESULT_OK;\n }\n \n ZT1_ResultCode Node::leave(uint64_t nwid)\n {\n \tMutex::Lock _l(_networks_m);\n-\tstd::map< uint64_t,SharedPtr<Network> >::iterator nw(_networks.find(nwid));\n-\tif (nw != _networks.end()) {\n-\t\tnw->second->destroy();\n-\t\t_networks.erase(nw);\n+\tstd::vector< SharedPtr<Network> >::iterator nwi = std::lower_bound(_networks.begin(), _networks.end(), nwid, NetworkComparator());\n+\tif(nwi != _networks.end() && (*nwi)->id() == nwid) {\n+\t\t(*nwi)->destroy();\n+\t\t// erase element (replace by last)\n+\t\t*nwi = _networks.back();\n+\t\t_networks.pop_back();\n+\t\tstd::sort(_networks.begin(),_networks.end());\n \t}\n \treturn ZT1_RESULT_OK;\n }\n@@ -406,10 +412,10 @@ ZT1_PeerList *Node::peers() const\n ZT1_VirtualNetworkConfig *Node::networkConfig(uint64_t nwid) const\n {\n \tMutex::Lock _l(_networks_m);\n-\tstd::map< uint64_t,SharedPtr<Network> >::const_iterator nw(_networks.find(nwid));\n-\tif (nw != _networks.end()) {\n+\tSharedPtr<Network> nw = _network(nwid);\n+\tif(nw) {\n \t\tZT1_VirtualNetworkConfig *nc = (ZT1_VirtualNetworkConfig *)::malloc(sizeof(ZT1_VirtualNetworkConfig));\n-\t\tnw->second->externalConfig(nc);\n+\t\tnw->externalConfig(nc);\n \t\treturn nc;\n \t}\n \treturn (ZT1_VirtualNetworkConfig *)0;\n@@ -426,8 +432,8 @@ ZT1_VirtualNetworkList *Node::networks() const\n \tnl->networks = (ZT1_VirtualNetworkConfig *)(buf + sizeof(ZT1_VirtualNetworkList));\n \n \tnl->networkCount = 0;\n-\tfor(std::map< uint64_t,SharedPtr<Network> >::const_iterator n(_networks.begin());n!=_networks.end();++n)\n-\t\tn->second->externalConfig(&(nl->networks[nl->networkCount++]));\n+\tfor(std::vector< SharedPtr<Network> >::const_iterator n(_networks.begin());n!=_networks.end();++n)\n+\t\t(*n)->externalConfig(&(nl->networks[nl->networkCount++]));\n \n \treturn nl;\n }\ndiff --git a/node/Node.hpp b/node/Node.hpp\nindex 1d9372e469..b0f4ab2221 100644\n--- a/node/Node.hpp\n+++ b/node/Node.hpp\n@@ -155,19 +155,16 @@ class Node\n \t\t\tlen);\n \t}\n \n-\tinline SharedPtr<Network> network(uint64_t nwid)\n+\tinline SharedPtr<Network> network(uint64_t nwid) const\n \t{\n \t\tMutex::Lock _l(_networks_m);\n-\t\tstd::map< uint64_t,SharedPtr<Network> >::iterator nw(_networks.find(nwid));\n-\t\treturn ((nw == _networks.end()) ? SharedPtr<Network>() : nw->second);\n+\t\treturn _network(nwid);\n \t}\n \n \tinline std::vector< SharedPtr<Network> > allNetworks() const\n \t{\n \t\tMutex::Lock _l(_networks_m);\n-\t\tstd::vector< SharedPtr<Network> > nw;\n-\t\tfor(std::map< uint64_t,SharedPtr<Network> >::const_iterator n(_networks.begin());n!=_networks.end();++n)\n-\t\t\tnw.push_back(n->second);\n+\t\tstd::vector< SharedPtr<Network> > nw(_networks);\n \t\treturn nw;\n \t}\n \n@@ -208,6 +205,23 @@ class Node\n #endif\n \n private:\n+\t// for binary search on _networks\n+\tstruct NetworkComparator {\n+\t\tbool operator()(const SharedPtr<Network> &n,uint64_t nwid) const {\n+\t\t\treturn n->id() < nwid;\n+\t\t}\n+\t};\n+\n+\tinline SharedPtr<Network> _network(uint64_t nwid) const\n+\t{\n+\t\tstd::vector< SharedPtr<Network> >::const_iterator iter = std::lower_bound(_networks.begin(), _networks.end(), nwid, NetworkComparator());\n+\t\tif(iter != _networks.end() && (*iter)->id() == nwid) {\n+\t\t\treturn *iter;\n+\t\t} else {\n+\t\t\treturn SharedPtr<Network>();\n+\t\t}\n+\t}\n+\n \tRuntimeEnvironment _RR;\n \tRuntimeEnvironment *RR;\n \n@@ -223,7 +237,7 @@ class Node\n \t//Dictionary _localConfig; // persisted as local.conf\n \t//Mutex _localConfig_m;\n \n-\tstd::map< uint64_t,SharedPtr<Network> > _networks;\n+\tstd::vector< SharedPtr<Network> > _networks;\n \tMutex _networks_m;\n \n \tMutex _backgroundTasksLock;\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Bugs/Errors**: Ensure collision scenarios are adequately tested in the hash array implementation.\n\n2. **Implementation Suggestions**:\n   - Consider using a closed hash table for better performance with larger datasets. For small sizes (<10), a binary tree may be efficient.\n   - Investigate the feasibility of using a plain C array for hash-based storage to optimize performance.\n\n3. **Performance Concerns**: Results show that using a vector or array yields superior performance over `std::map` and `std::unordered_map` for small sizes.\n\n4. **Next Steps**: \n   - Implement collision handling in the hash array tests.\n   - Analyze dependencies on ordering when swapping out `std::map` for unordered structures to avoid breaking functionality. \n   - Create a new Hash class to maintain performance and manage collisions effectively."
      }
    ],
    "codediff_length": 5033
  },
  {
    "index": 53,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/CMakeLists.txt b/CMakeLists.txt\nnew file mode 100644\nindex 0000000000..8e6285b38a\n--- /dev/null\n+++ b/CMakeLists.txt\n@@ -0,0 +1,198 @@\n+cmake_minimum_required(VERSION 3.14)\n+project(mold VERSION 1.3.0)\n+\n+include(CMakeDependentOption)\n+\n+# FIXME: this is for parity with the makefiles that install directly to <prefix>/lib\n+# NOTE: defining this before including GNUInstallDirs makes its platform detection a noop\n+set(CMAKE_INSTALL_LIBDIR lib CACHE PATH \"\")\n+include(GNUInstallDirs)\n+\n+# Mold build options\n+cmake_dependent_option(MOLD_USE_MIMALLOC \"Use mimalloc\" ON\n+    \"NOT APPLE;NOT ANDROID\" OFF)\n+cmake_dependent_option(MOLD_USE_SYSTEM_MIMALLOC \"Use system or vendored mimalloc\" ON\n+    MOLD_USE_MIMALLOC OFF)\n+option(MOLD_USE_SYSTEM_TBB \"Use system or vendored TBB\" ON)\n+\n+# Setup mimalloc\n+if(MOLD_USE_MIMALLOC)\n+    if(MOLD_USE_SYSTEM_MIMALLOC)\n+        find_package(mimalloc REQUIRED)\n+        target_compile_definitions(mimalloc INTERFACE USE_SYSTEM_MIMALLOC)\n+    else()\n+        function(mold_add_mimalloc)\n+            option(MI_BUILD_TESTS \"Build test executables\" OFF)\n+            add_subdirectory(third-party/mimalloc EXCLUDE_FROM_ALL)\n+            target_compile_definitions(mimalloc PRIVATE MI_USE_ENVIRON=0)\n+        endfunction()\n+\n+        mold_add_mimalloc()\n+    endif()\n+endif()\n+\n+# Setup TBB\n+if(MOLD_USE_SYSTEM_TBB)\n+    find_package(TBB REQUIRED)\n+else()\n+    function(mold_add_tbb)\n+        set(BUILD_SHARED_LIBS OFF)\n+        set(TBB_TEST OFF CACHE INTERNAL \"\")\n+        set(TBB_STRICT OFF CACHE INTERNAL \"\")\n+        add_subdirectory(third-party/tbb EXCLUDE_FROM_ALL)\n+        target_compile_definitions(tbb PRIVATE __TBB_DYNAMIC_LOAD_ENABLED=0)\n+    endfunction()\n+\n+    mold_add_tbb()\n+endif()\n+\n+add_library(mold-wrapper SHARED)\n+\n+# Remove the default `lib` prefix\n+set_target_properties(mold-wrapper PROPERTIES PREFIX \"\")\n+target_link_libraries(mold-wrapper PRIVATE ${CMAKE_DL_LIBS})\n+target_sources(mold-wrapper PRIVATE elf/mold-wrapper.c)\n+\n+add_executable(mold)\n+target_compile_features(mold PRIVATE cxx_std_20)\n+target_include_directories(mold SYSTEM PRIVATE third-party)\n+\n+if(NOT MSVC)\n+    include(CheckLibraryExists)\n+    check_library_exists(m pow \"\" LIBM_FOUND)\n+\n+    if(LIBM_FOUND)\n+        target_link_libraries(mold PRIVATE m)\n+    endif()\n+endif()\n+\n+find_package(ZLIB REQUIRED)\n+target_link_libraries(mold PRIVATE ZLIB::ZLIB TBB::tbb ${CMAKE_DL_LIBS})\n+\n+if(MOLD_USE_MIMALLOC)\n+    target_link_libraries(mold PRIVATE mimalloc)\n+endif()\n+\n+if(NOT APPLE)\n+    find_package(OpenSSL REQUIRED COMPONENTS Crypto)\n+    target_link_libraries(mold PRIVATE OpenSSL::Crypto)\n+endif()\n+\n+if(CMAKE_SYSTEM_PROCESSOR MATCHES riscv64\n+    OR CMAKE_SYSTEM_PROCESSOR MATCHES armv6)\n+    target_link_libraries(mold PRIVATE atomic)\n+endif()\n+\n+set_property(SOURCE main.cc elf/lto.cc macho/output-chunks.cc APPEND PROPERTY\n+    COMPILE_DEFINITIONS \"MOLD_VERSION=\\\"${CMAKE_PROJECT_VERSION}\\\"\")\n+\n+if(EXISTS .git/HEAD)\n+    file(STRINGS .git/HEAD GIT_HASH)\n+\n+    if(GIT_HASH MATCHES \"ref: \")\n+        string(REPLACE \"ref: \" \"\" GIT_HASH \"${GIT_HASH}\")\n+        file(STRINGS .git/${GIT_HASH} GIT_HASH)\n+    endif()\n+\n+    set_property(SOURCE main.cc APPEND PROPERTY\n+        COMPILE_DEFINITIONS \"GIT_HASH=\\\"${GIT_HASH}\\\"\")\n+endif()\n+\n+target_sources(mold PRIVATE\n+    compress.cc\n+    demangle.cc\n+    filepath.cc\n+    glob.cc\n+    hyperloglog.cc\n+    main.cc\n+    multi-glob.cc\n+    perf.cc\n+    strerror.cc\n+    tar.cc\n+    uuid.cc\n+    elf/arch-arm32.cc\n+    elf/arch-arm64.cc\n+    elf/arch-i386.cc\n+    elf/arch-riscv64.cc\n+    elf/arch-x86-64.cc\n+    elf/cmdline.cc\n+    elf/dwarf.cc\n+    elf/gc-sections.cc\n+    elf/icf.cc\n+    elf/input-files.cc\n+    elf/input-sections.cc\n+    elf/linker-script.cc\n+    elf/lto.cc\n+    elf/main.cc\n+    elf/mapfile.cc\n+    elf/output-chunks.cc\n+    elf/passes.cc\n+    elf/relocatable.cc\n+    elf/subprocess.cc\n+    macho/arch-arm64.cc\n+    macho/arch-x86-64.cc\n+    macho/cmdline.cc\n+    macho/dead-strip.cc\n+    macho/input-files.cc\n+    macho/input-sections.cc\n+    macho/lto.cc\n+    macho/main.cc\n+    macho/mapfile.cc\n+    macho/output-chunks.cc\n+    macho/tapi.cc\n+    macho/yaml.cc\n+    third-party/rust-demangle/rust-demangle.c)\n+\n+include(CTest)\n+\n+if(BUILD_TESTING)\n+    # Create the ld and ld64 symlinks required for testing\n+    add_custom_command(\n+        TARGET mold POST_BUILD\n+        COMMAND ${CMAKE_COMMAND} -E create_symlink mold ld\n+        WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}\n+        COMMENT \"Creating ld symlink\"\n+        VERBATIM)\n+    add_custom_command(\n+        TARGET mold POST_BUILD\n+        COMMAND ${CMAKE_COMMAND} -E create_symlink mold ld64\n+        WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}\n+        COMMENT \"Creating ld64 symlink\"\n+        VERBATIM)\n+    add_subdirectory(test)\n+\n+    include(ProcessorCount)\n+    ProcessorCount(MOLD_NPROC)\n+    add_custom_target(\n+        check\n+        COMMAND \"${CMAKE_COMMAND}\" --build \"${mold_BINARY_DIR}\" --config \"\\$<CONFIG>\" -j \"${MOLD_NPROC}\"\n+        COMMAND \"${CMAKE_CTEST_COMMAND}\" -C \"\\$<CONFIG>\" -j \"${MOLD_NPROC}\"\n+        VERBATIM\n+        USES_TERMINAL)\n+endif()\n+\n+if(NOT CMAKE_SKIP_INSTALL_RULES)\n+    install(TARGETS mold)\n+    install(TARGETS mold-wrapper DESTINATION ${CMAKE_INSTALL_LIBDIR}/mold)\n+    install(CODE \"\\\n+        file(REAL_PATH \\${CMAKE_INSTALL_PREFIX} INSTALL_PREFIX)\n+        file(RELATIVE_PATH\\\n+            REL_SYMLINK\\\n+            \\${INSTALL_PREFIX}/${CMAKE_INSTALL_BINDIR}/mold\\\n+            \\${INSTALL_PREFIX}/${CMAKE_INSTALL_LIBEXECDIR}/mold)\\n\\\n+        execute_process(\\\n+            COMMAND ${CMAKE_COMMAND} -E make_directory\\\n+            \\${INSTALL_PREFIX}/${CMAKE_INSTALL_LIBEXECDIR}/mold)\\n\\\n+        execute_process(\\\n+            COMMAND ${CMAKE_COMMAND} -E create_symlink\\\n+            \\${REL_SYMLINK}\\\n+            \\${INSTALL_PREFIX}/${CMAKE_INSTALL_LIBEXECDIR}/mold/ld)\\n\\\n+        execute_process(\\\n+            COMMAND ${CMAKE_COMMAND} -E create_symlink\\\n+            mold\\\n+            \\${INSTALL_PREFIX}/${CMAKE_INSTALL_BINDIR}/ld.mold)\\n\\\n+        execute_process(\\\n+            COMMAND ${CMAKE_COMMAND} -E create_symlink\\\n+            mold\\\n+            \\${INSTALL_PREFIX}/${CMAKE_INSTALL_BINDIR}/ld64.mold)\")\n+endif()\n\\ No newline at end of file\ndiff --git a/test/CMakeLists.txt b/test/CMakeLists.txt\nnew file mode 100644\nindex 0000000000..9a3629c1d4\n--- /dev/null\n+++ b/test/CMakeLists.txt\n@@ -0,0 +1,30 @@\n+function(mold_add_arch_test NAME DIR TRIPLE MACHINE)\n+    set(TEST_NAME \"${NAME}_arch_${MACHINE}\")\n+    add_test(NAME ${TEST_NAME}\n+        COMMAND ${DIR}/${NAME}.sh\n+        WORKING_DIRECTORY ${mold_BINARY_DIR})\n+\n+    set(TEST_ENV\n+        TEST_CC=${TRIPLE}-gcc\n+        TEST_CXX=${TRIPLE}-g++\n+        TEST_GCC=${TRIPLE}-gcc\n+        TEST_GXX=${TRIPLE}-g++\n+        OBJDUMP=${TRIPLE}-objdump\n+        MACHINE=${MACHINE}\n+        \"QEMU=qemu-${MACHINE} -L /usr/${TRIPLE}\")\n+    set_tests_properties(${TEST_NAME} PROPERTIES ENVIRONMENT \"${TEST_ENV}\")\n+endfunction()\n+\n+function(mold_add_arch_tests NAME DIR)\n+    mold_add_arch_test(${NAME} ${DIR} x86_64-linux-gnu x86_64)\n+    mold_add_arch_test(${NAME} ${DIR} i686-linux-gnu i386)\n+    mold_add_arch_test(${NAME} ${DIR} aarch64-linux-gnu aarch64)\n+    mold_add_arch_test(${NAME} ${DIR} arm-linux-gnueabihf arm)\n+    mold_add_arch_test(${NAME} ${DIR} riscv64-linux-gnu riscv64)\n+endfunction()\n+\n+if(CMAKE_SYSTEM_NAME MATCHES Linux)\n+    add_subdirectory(elf)\n+elseif(CMAKE_SYSTEM_NAME MATCHES Darwin)\n+    add_subdirectory(macho)\n+endif()\n\\ No newline at end of file\ndiff --git a/test/elf/CMakeLists.txt b/test/elf/CMakeLists.txt\nnew file mode 100644\nindex 0000000000..250f2607e4\n--- /dev/null\n+++ b/test/elf/CMakeLists.txt\n@@ -0,0 +1,258 @@\n+set(MOLD_ELF_TESTS\n+    absolute-symbols\n+    allow-multiple-definition\n+    ar-alignment\n+    as-needed2\n+    as-needed\n+    as-needed-weak\n+    auxiliary\n+    basic\n+    bno-symbolic\n+    bsymbolic-functions\n+    bsymbolic\n+    bug178\n+    build-id\n+    canonical-plt\n+    cmdline\n+    color-diagnostics\n+    comment\n+    common-archive\n+    common-ref\n+    common\n+    compress-debug-sections\n+    compressed-debug-info-gnu\n+    compressed-debug-info\n+    copyrel-protected\n+    copyrel-relro\n+    copyrel\n+    dead-debug-sections\n+    debug-macro-section\n+    default-symver\n+    defsym\n+    demangle-rust\n+    demangle\n+    dependency-file\n+    disable-new-dtags\n+    discard\n+    dso-undef\n+    dt-init\n+    dt-needed\n+    duplicate-error\n+    dynamic-dt-debug\n+    dynamic-linker\n+    dynamic-list2\n+    dynamic-list\n+    dynamic\n+    emit-relocs\n+    empty-file\n+    empty-input\n+    empty-version\n+    emulation-deduction\n+    entry\n+    exception-mcmodel-large\n+    exception\n+    exclude-libs2\n+    exclude-libs3\n+    exclude-libs\n+    execstack-if-needed\n+    execstack\n+    export-dynamic\n+    export-from-exe\n+    fatal-warnings\n+    filler\n+    filter\n+    func-addr\n+    gc-sections\n+    gdb-index-compress-output\n+    gdb-index-dwarf2\n+    gdb-index-dwarf3\n+    gdb-index-dwarf4\n+    gdb-index-dwarf5\n+    gdb-index-empty\n+    glibc-2.22-bug\n+    gnu-hash\n+    gnu-linkonce\n+    gnu-retain\n+    gnu-unique\n+    gnu-warning\n+    hello-dynamic\n+    hello-static\n+    help\n+    hidden-undef\n+    icf\n+    icf-small\n+    ifunc-dso\n+    ifunc-dynamic\n+    ifunc-export\n+    ifunc-static-pie\n+    ifunc-static\n+    image-base\n+    incompatible-libs2\n+    incompatible-libs\n+    incompatible-obj\n+    init-array-priorities\n+    init-array-readonly\n+    init-array\n+    initfirst\n+    init-in-dso\n+    init\n+    interpose\n+    invalid-version-script\n+    large-alignment-dso\n+    large-alignment\n+    linker-script2\n+    linker-script3\n+    linker-script4\n+    linker-script\n+    link-order\n+    lto-archive\n+    lto-dso\n+    lto-gcc\n+    lto-llvm\n+    lto-version-script\n+    many-sections\n+    mergeable-records\n+    mergeable-strings\n+    missing-but-ok\n+    missing-error\n+    mold-wrapper2\n+    mold-wrapper\n+    nocopyreloc\n+    noinhibit-exec\n+    non-canonical-plt\n+    no-quick-exit\n+    nostdlib\n+    note2\n+    note-property\n+    note\n+    now\n+    oformat-binary\n+    omagic\n+    package-metadata\n+    pack-dyn-relocs-relr\n+    pie\n+    plt-dso\n+    pltgot\n+    plt\n+    preinit-array\n+    print-dependencies\n+    protected-dynsym\n+    protected\n+    push-pop-state\n+    relax\n+    relocatable-archive\n+    relocatable\n+    reloc-overflow\n+    reloc-rodata\n+    reloc\n+    reloc-zero\n+    relro\n+    repro\n+    require-defined\n+    response-file\n+    retain-symbols-file\n+    reverse-sections\n+    rodata-name\n+    rosegment\n+    rpath\n+    run-clang\n+    run\n+    section-alignment\n+    section-name\n+    section-start\n+    shared\n+    shuffle-sections-seed\n+    shuffle-sections\n+    soname\n+    start-lib\n+    start-stop-symbol\n+    static-archive\n+    static-pie\n+    stdout\n+    strip\n+    symbol-rank\n+    symbol-version2\n+    symbol-version3\n+    symbol-version\n+    symtab-dso\n+    symtab-section-symbols\n+    symtab\n+    synthetic-symbols\n+    sysroot2\n+    sysroot-linker-script\n+    sysroot\n+    thin-archive\n+    thread-count\n+    tls-common\n+    tlsdesc-import\n+    tlsdesc\n+    tlsdesc-static\n+    tls-dso\n+    tls-gd2\n+    tls-gd-mcmodel-large\n+    tls-gd-noplt\n+    tls-gd\n+    tls-ie\n+    tls-large-tbss\n+    tls-ld-mcmodel-large\n+    tls-ld-noplt\n+    tls-ld\n+    tls-le\n+    tls-module-base\n+    tls-nopic\n+    tls-pic\n+    trace\n+    trace-symbol\n+    undefined\n+    unique\n+    unresolved-symbols\n+    verbose\n+    versioned-undef\n+    version-script10\n+    version-script11\n+    version-script12\n+    version-script13\n+    version-script14\n+    version-script15\n+    version-script2\n+    version-script3\n+    version-script4\n+    version-script5\n+    version-script6\n+    version-script7\n+    version-script8\n+    version-script9\n+    version-script\n+    version\n+    visibility\n+    warn-common\n+    warn-execstack\n+    warn-once\n+    warn-shared-textrel\n+    warn-textrel\n+    warn-unresolved-symbols\n+    weak-export-dso\n+    weak-export-exe\n+    weak-undef\n+    whole-archive\n+    wrap\n+    z-cet-report\n+    z-defs\n+    z-ibtplt\n+    z-ibt\n+    z-max-page-size\n+    z-nodefaultlib\n+    z-nodump\n+    z-now\n+    z-origin\n+    z-separate-code\n+    z-shstk\n+    z-text\n+    z-unknown)\n+\n+foreach(MOLD_ELF_TEST IN LISTS MOLD_ELF_TESTS)\n+    add_test(NAME \"${MOLD_ELF_TEST}_host\"\n+        COMMAND \"${CMAKE_CURRENT_LIST_DIR}/${MOLD_ELF_TEST}.sh\"\n+        WORKING_DIRECTORY ${mold_BINARY_DIR})\n+    mold_add_arch_tests(${MOLD_ELF_TEST} ${CMAKE_CURRENT_LIST_DIR})\n+endforeach()\n\\ No newline at end of file\ndiff --git a/test/macho/CMakeLists.txt b/test/macho/CMakeLists.txt\nnew file mode 100644\nindex 0000000000..f641abadc2\n--- /dev/null\n+++ b/test/macho/CMakeLists.txt\n@@ -0,0 +1,96 @@\n+set(MOLD_ELF_TESTS\n+    add-ast-path\n+    add-empty-section\n+    adhoc-codesign\n+    all-load\n+    application-extension\n+    archive\n+    baserel\n+    basic\n+    bss\n+    bundle\n+    comdat\n+    common-alignment\n+    common\n+    cstring\n+    data-reloc\n+    dead-strip-dylibs2\n+    dead-strip-dylibs\n+    dead-strip\n+    dependency-info\n+    dlinfo\n+    duplicate-error\n+    dylib\n+    entry\n+    exception\n+    export-dynamic\n+    exported-symbols-list\n+    filepath2\n+    filepath\n+    force-load\n+    framework\n+    headerpad-max-install-names\n+    headerpad\n+    hello2\n+    hello3\n+    hello4\n+    hello5\n+    hello\n+    hidden-l\n+    install-name\n+    lc-build-version\n+    lc-linker-option\n+    lib1\n+    libunwind\n+    lto\n+    macos-version-min\n+    map\n+    merge-scope\n+    missing-error\n+    needed-framework\n+    needed-l\n+    objc\n+    object-path-lto\n+    order-file\n+    pagezero-size2\n+    pagezero-size3\n+    pagezero-size\n+    platform-version\n+    private-extern\n+    reexport-l\n+    reproducibility\n+    response-file\n+    rpath\n+    search-dylibs-first\n+    search-paths-first\n+    sectcreate\n+    stack-size\n+    subsections-via-symbols\n+    syslibroot\n+    tbd-add\n+    tbd-hide\n+    tbd-install-name\n+    tbd-previous\n+    tbd-reexport\n+    tbd\n+    tls2\n+    tls\n+    undef\n+    unexported-symbols-list\n+    universal\n+    unkown-tbd-target\n+    U\n+    uuid2\n+    uuid\n+    weak-def-dylib\n+    weak-def-ref\n+    weak-def\n+    weak-l\n+    weak-undef\n+    Z)\n+\n+foreach(MOLD_MACHO_TEST IN LISTS MOLD_MACHO_TESTS)\n+    add_test(NAME ${MOLD_MACHO_TEST}\n+        COMMAND ${CMAKE_CURRENT_LIST_DIR}/${MOLD_MACHO_TEST}.sh)\n+    mold_add_arch_tests(${MOLD_MACHO_TEST} ${CMAKE_CURRENT_LIST_DIR})\n+endforeach()\n\\ No newline at end of file\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **CMake Migration**: Delay full integration of CMake until mold 2.0. Current Makefile stability means no immediate need to switch.\n\n2. **Test Failures**: Address failing arch tests; specifically, 'REG_RIP' is undeclared. Investigate architecture-specific includes to resolve.\n\n3. **Windows Support**: Errors related to Windows support cannot be overlooked. Ensure relevant changes don't hinder cross-platform compatibility.\n\n4. **CMake Configuration Errors**: \n   - Adjust line `#file(STRINGS .git/HEAD GIT_HASH)` for compatibility.\n   - Resolve missing `rust-demangle.c` by commenting it out.\n\n5. **Dependencies**: Ensure TBB and mimalloc are installed or adjust flags to use system versions.\n\n6. **Testing Differences**: Clarify usage of `ninja test` vs. `ninja check` for accurate behavior and execution. \n\nNext steps: Fix identified bugs, rectify CMake configuration issues, and confirm dependency installations."
      }
    ],
    "codediff_length": 14515
  },
  {
    "index": 54,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/d3d9/d3d9_common_texture.cpp b/src/d3d9/d3d9_common_texture.cpp\nindex 8ce017fec90..a04d285761b 100644\n--- a/src/d3d9/d3d9_common_texture.cpp\n+++ b/src/d3d9/d3d9_common_texture.cpp\n@@ -201,8 +201,7 @@ namespace dxvk {\n     const uint32_t planeCount = m_mapping.ConversionFormatInfo.PlaneCount;\n \n     return std::min(planeCount, 2u)\n-         * formatInfo.elementSize\n-         * blockCount.width\n+         * align(formatInfo.elementSize * blockCount.width, 4)\n          * blockCount.height\n          * blockCount.depth;\n   }\ndiff --git a/src/d3d9/d3d9_device.cpp b/src/d3d9/d3d9_device.cpp\nindex d5d28854cd4..e2b35ca6908 100644\n--- a/src/d3d9/d3d9_device.cpp\n+++ b/src/d3d9/d3d9_device.cpp\n@@ -51,7 +51,7 @@ namespace dxvk {\n     , m_d3d9Options    ( dxvkDevice, pParent->GetInstance()->config() )\n     , m_isSWVP         ( (BehaviorFlags & D3DCREATE_SOFTWARE_VERTEXPROCESSING) ? TRUE : FALSE ) {\n     // If we can SWVP, then we use an extended constant set\n-    // as SWVP has many more slots available than HWVP. \n+    // as SWVP has many more slots available than HWVP.\n     bool canSWVP = CanSWVP();\n     DetermineConstantLayouts(canSWVP);\n \n@@ -656,8 +656,10 @@ namespace dxvk {\n \n     VkOffset3D srcBlockOffset = { 0u, 0u, 0u };\n     VkOffset3D dstOffset = { 0u, 0u, 0u };\n+    VkExtent3D texLevelExtent = srcTextureInfo->GetExtentMip(src->GetSubresource());\n+    VkExtent3D texLevelBlockCount = util::computeBlockCount(texLevelExtent, formatInfo->blockSize);\n \n-    VkExtent3D copyExtent = srcTextureInfo->GetExtentMip(src->GetSubresource());\n+    VkExtent3D copyExtent = texLevelExtent;\n \n     if (pSourceRect != nullptr) {\n       srcBlockOffset = { pSourceRect->left / int32_t(formatInfo->blockSize.width),\n@@ -675,34 +677,41 @@ namespace dxvk {\n                     0u };\n     }\n \n+    VkExtent3D copyBlockCount = util::computeBlockCount(copyExtent, formatInfo->blockSize);\n+\n     const auto dstSubresource = vk::makeSubresourceLayers(\n       dstTextureInfo->GetSubresourceFromIndex(VK_IMAGE_ASPECT_COLOR_BIT, dst->GetSubresource()));\n \n-    Rc<DxvkBuffer> srcBuffer = srcTextureInfo->GetBuffer(src->GetSubresource());\n-    Rc<DxvkImage>  dstImage  = dstTextureInfo->GetImage();\n+    DxvkBufferSliceHandle srcSlice = srcTextureInfo->GetMappedSlice(src->GetSubresource());\n+    VkDeviceSize dirtySize = copyBlockCount.width * copyBlockCount.height * formatInfo->elementSize;\n+    D3D9BufferSlice slice = AllocTempBuffer<false>(dirtySize);\n+    VkDeviceSize copySrcOffset = (srcBlockOffset.z * texLevelBlockCount.height * texLevelBlockCount.width\n+        + srcBlockOffset.y * texLevelBlockCount.width\n+        + srcBlockOffset.x)\n+        * formatInfo->elementSize;\n \n-    VkExtent3D levelExtent = srcTextureInfo->GetExtentMip(src->GetSubresource());\n-    VkExtent3D blockCount  = util::computeBlockCount(levelExtent, formatInfo->blockSize);\n+    VkDeviceSize pitch = align(texLevelBlockCount.width * formatInfo->elementSize, 4);\n+    void* srcData = reinterpret_cast<uint8_t*>(srcSlice.mapPtr) + copySrcOffset;\n+    util::packImageData(\n+      slice.mapPtr, srcData, copyBlockCount, formatInfo->elementSize,\n+      pitch, pitch * texLevelBlockCount.height);\n \n-    VkDeviceSize srcByteOffset = srcBlockOffset.y * formatInfo->elementSize * blockCount.width\n+    Rc<DxvkImage>  dstImage  = dstTextureInfo->GetImage();\n+    VkDeviceSize srcByteOffset = srcBlockOffset.y * formatInfo->elementSize * texLevelBlockCount.width\n                                + srcBlockOffset.x * formatInfo->elementSize;\n \n-    VkExtent2D fullSrcExtent = VkExtent2D{ blockCount.width  * formatInfo->blockSize.width,\n-                                           blockCount.height * formatInfo->blockSize.height };\n-\n     EmitCs([\n       cDstImage   = std::move(dstImage),\n-      cSrcBuffer  = std::move(srcBuffer),\n+      cSrcSlice   = slice.slice,\n       cDstLayers  = dstSubresource,\n       cDstOffset  = dstOffset,\n-      cSrcOffset  = srcByteOffset,\n-      cCopyExtent = copyExtent,\n-      cSrcExtent  = fullSrcExtent\n+      cSrcOffset  = srcByteOffset + slice.slice.offset(),\n+      cCopyExtent = copyExtent\n     ] (DxvkContext* ctx) {\n       ctx->copyBufferToImage(\n         cDstImage, cDstLayers, cDstOffset, cCopyExtent,\n-        cSrcBuffer, cSrcOffset,\n-        cSrcExtent);\n+        cSrcSlice.buffer(), cSrcSlice.offset() + cSrcOffset,\n+        VkExtent2D { 0, 0 });\n     });\n \n     dstTextureInfo->SetWrittenByGPU(dst->GetSubresource(), true);\n@@ -745,7 +754,6 @@ namespace dxvk {\n         continue;\n \n       for (uint32_t m = 0; m < mipLevels; m++) {\n-        Rc<DxvkBuffer> srcBuffer = srcTexInfo->GetBuffer(srcTexInfo->CalcSubresource(a, m));\n         VkImageSubresourceLayers dstLayers = { VK_IMAGE_ASPECT_COLOR_BIT, m, a, 1 };\n \n         VkOffset3D scaledBoxOffset = {\n@@ -754,36 +762,50 @@ namespace dxvk {\n           int32_t(alignDown(box.Front >> m, formatInfo->blockSize.depth))\n         };\n         VkExtent3D scaledBoxExtent = util::computeMipLevelExtent({\n-          uint32_t(box.Right - box.Left),\n-          uint32_t(box.Bottom - box.Top),\n-          uint32_t(box.Back - box.Front)\n+          uint32_t(box.Right - scaledBoxOffset.x),\n+          uint32_t(box.Bottom - scaledBoxOffset.y),\n+          uint32_t(box.Back - scaledBoxOffset.z)\n         }, m);\n         VkExtent3D scaledBoxExtentBlockCount = util::computeBlockCount(scaledBoxExtent, formatInfo->blockSize);\n         VkExtent3D scaledAlignedBoxExtent = util::computeBlockExtent(scaledBoxExtentBlockCount, formatInfo->blockSize);\n \n         VkExtent3D texLevelExtent = dstImage->mipLevelExtent(m);\n         VkExtent3D texLevelExtentBlockCount = util::computeBlockCount(texLevelExtent, formatInfo->blockSize);\n+\n+        scaledAlignedBoxExtent.width = std::min<uint32_t>(texLevelExtent.width, scaledAlignedBoxExtent.width);\n+        scaledAlignedBoxExtent.height = std::min<uint32_t>(texLevelExtent.height, scaledAlignedBoxExtent.height);\n+        scaledAlignedBoxExtent.depth = std::min<uint32_t>(texLevelExtent.depth, scaledAlignedBoxExtent.depth);\n+\n+        VkDeviceSize dirtySize = scaledBoxExtentBlockCount.width * scaledBoxExtentBlockCount.height * scaledBoxExtentBlockCount.depth * formatInfo->elementSize;\n+        D3D9BufferSlice slice = AllocTempBuffer<false>(dirtySize);\n         VkOffset3D boxOffsetBlockCount = util::computeBlockOffset(scaledBoxOffset, formatInfo->blockSize);\n-        VkDeviceSize srcOffset = boxOffsetBlockCount.z * formatInfo->elementSize * texLevelExtentBlockCount.depth\n-                                  + boxOffsetBlockCount.y * formatInfo->elementSize * texLevelExtentBlockCount.width\n-                                  + boxOffsetBlockCount.x * formatInfo->elementSize;\n-        VkExtent2D srcExtent = VkExtent2D{ texLevelExtentBlockCount.width  * formatInfo->blockSize.width,\n-                                           texLevelExtentBlockCount.height * formatInfo->blockSize.height };\n+        VkDeviceSize copySrcOffset = (boxOffsetBlockCount.z * texLevelExtentBlockCount.height * texLevelExtentBlockCount.width\n+            + boxOffsetBlockCount.y * texLevelExtentBlockCount.width\n+            + boxOffsetBlockCount.x)\n+            * formatInfo->elementSize;\n+\n+        VkDeviceSize pitch = align(texLevelExtentBlockCount.width * formatInfo->elementSize, 4);\n+        void* srcData = reinterpret_cast<uint8_t*>(srcTexInfo->GetMappedSlice(srcTexInfo->CalcSubresource(a, m)).mapPtr) + copySrcOffset;\n+        util::packImageData(\n+          slice.mapPtr, srcData, scaledBoxExtentBlockCount, formatInfo->elementSize,\n+          pitch, pitch * texLevelExtentBlockCount.height);\n+\n+        scaledAlignedBoxExtent.width  = std::min<uint32_t>(texLevelExtent.width, scaledAlignedBoxExtent.width);\n+        scaledAlignedBoxExtent.height = std::min<uint32_t>(texLevelExtent.height, scaledAlignedBoxExtent.height);\n+        scaledAlignedBoxExtent.depth  = std::min<uint32_t>(texLevelExtent.depth, scaledAlignedBoxExtent.depth);\n \n         EmitCs([\n           cDstImage  = dstImage,\n-          cSrcBuffer = srcBuffer,\n+          cSrcSlice  = slice.slice,\n           cDstLayers = dstLayers,\n           cExtent    = scaledAlignedBoxExtent,\n-          cOffset    = scaledBoxOffset,\n-          cSrcOffset = srcOffset,\n-          cSrcExtent = srcExtent\n+          cOffset    = scaledBoxOffset\n         ] (DxvkContext* ctx) {\n           ctx->copyBufferToImage(\n             cDstImage,  cDstLayers,\n             cOffset, cExtent,\n-            cSrcBuffer, cSrcOffset,\n-            cSrcExtent);\n+            cSrcSlice.buffer(), cSrcSlice.offset(),\n+            VkExtent2D { 0, 0 });\n         });\n \n         dstTexInfo->SetWrittenByGPU(dstTexInfo->CalcSubresource(a, m), true);\n@@ -836,14 +858,21 @@ namespace dxvk {\n \n     VkExtent3D srcExtent = srcTexInfo->GetExtentMip(src->GetMipLevel());\n \n+    VkExtent3D texLevelExtentBlockCount = util::computeBlockCount(srcExtent, srcFormatInfo->blockSize);\n+    VkDeviceSize pitch = align(texLevelExtentBlockCount.width * uint32_t(srcFormatInfo->elementSize), 4);\n+    uint32_t pitchBlocks = uint32_t(pitch / srcFormatInfo->elementSize);\n+    VkExtent2D dstExtent = VkExtent2D{ pitchBlocks,\n+                                       texLevelExtentBlockCount.height * pitchBlocks };\n+\n     EmitCs([\n       cBuffer       = dstBuffer,\n       cImage        = srcImage,\n       cSubresources = srcSubresourceLayers,\n-      cLevelExtent  = srcExtent\n+      cLevelExtent  = srcExtent,\n+      cDstExtent    = dstExtent\n     ] (DxvkContext* ctx) {\n       ctx->copyImageToBuffer(\n-        cBuffer, 0, VkExtent2D { 0u, 0u },\n+        cBuffer, 0, cDstExtent,\n         cImage, cSubresources, VkOffset3D { 0, 0, 0 },\n         cLevelExtent);\n     });\n@@ -964,7 +993,7 @@ namespace dxvk {\n \n     if (unlikely(IsBlitRegionInvalid(blitInfo.dstOffsets, dstExtent)))\n       return D3DERR_INVALIDCALL;\n-    \n+\n     VkExtent3D srcCopyExtent =\n     { uint32_t(blitInfo.srcOffsets[1].x - blitInfo.srcOffsets[0].x),\n       uint32_t(blitInfo.srcOffsets[1].y - blitInfo.srcOffsets[0].y),\n@@ -1676,9 +1705,9 @@ namespace dxvk {\n \n     if (unlikely(ShouldRecord()))\n       return m_recorder->SetClipPlane(Index, pPlane);\n-    \n+\n     bool dirty = false;\n-    \n+\n     for (uint32_t i = 0; i < 4; i++) {\n       dirty |= m_state.clipPlanes[Index].coeff[i] != pPlane[i];\n       m_state.clipPlanes[Index].coeff[i] = pPlane[i];\n@@ -1686,10 +1715,10 @@ namespace dxvk {\n \n     bool enabled = m_state.renderStates[D3DRS_CLIPPLANEENABLE] & (1u << Index);\n     dirty &= enabled;\n-    \n+\n     if (dirty)\n       m_flags.set(D3D9DeviceFlag::DirtyClipPlanes);\n-    \n+\n     return D3D_OK;\n   }\n \n@@ -1699,10 +1728,10 @@ namespace dxvk {\n \n     if (unlikely(Index >= caps::MaxClipPlanes || !pPlane))\n       return D3DERR_INVALIDCALL;\n-    \n+\n     for (uint32_t i = 0; i < 4; i++)\n       pPlane[i] = m_state.clipPlanes[Index].coeff[i];\n-    \n+\n     return D3D_OK;\n   }\n \n@@ -1819,7 +1848,7 @@ namespace dxvk {\n           UpdateActiveRTs(3);\n           m_flags.set(D3D9DeviceFlag::DirtyBlendState);\n           break;\n-        \n+\n         case D3DRS_ALPHATESTENABLE: {\n           bool newATOC = IsAlphaToCoverageEnabled();\n           bool newAlphaTest = IsAlphaTestEnabled();\n@@ -2375,7 +2404,7 @@ namespace dxvk {\n \n     const uint32_t upSize = drawInfo.vertexCount * VertexStreamZeroStride;\n \n-    auto upSlice = AllocUpBuffer(upSize);\n+    auto upSlice = AllocTempBuffer<true>(upSize);\n     std::memcpy(upSlice.mapPtr, pVertexStreamZeroData, upSize);\n \n     EmitCs([this,\n@@ -2426,7 +2455,7 @@ namespace dxvk {\n \n     const uint32_t upSize = vertexSize + indicesSize;\n \n-    auto upSlice = AllocUpBuffer(upSize);\n+    auto upSlice = AllocTempBuffer<true>(upSize);\n     uint8_t* data = reinterpret_cast<uint8_t*>(upSlice.mapPtr);\n \n     std::memcpy(data, pVertexStreamZeroData, vertexSize);\n@@ -2546,7 +2575,7 @@ namespace dxvk {\n     // We unbound the pixel shader before,\n     // let's make sure that gets rebound.\n     m_flags.set(D3D9DeviceFlag::DirtyFFPixelShader);\n-    \n+\n     if (m_state.pixelShader != nullptr) {\n       BindShader<DxsoProgramTypes::PixelShader>(\n         GetCommonShader(m_state.pixelShader),\n@@ -2911,7 +2940,7 @@ namespace dxvk {\n \n     if (likely(pStride != nullptr))\n       *pStride = 0;\n-    \n+\n     if (unlikely(ppStreamData == nullptr || pOffsetInBytes == nullptr || pStride == nullptr))\n       return D3DERR_INVALIDCALL;\n \n@@ -3619,7 +3648,7 @@ namespace dxvk {\n     DWORD newUsage = newTexture != nullptr ? newTexture->Desc()->Usage : 0;\n \n     DWORD combinedUsage = oldUsage | newUsage;\n-    \n+\n     TextureChangePrivate(m_state.textures[StateSampler], pTexture);\n \n     BindTexture(StateSampler);\n@@ -3800,65 +3829,82 @@ namespace dxvk {\n   }\n \n \n-  D3D9UPBufferSlice D3D9DeviceEx::AllocUpBuffer(VkDeviceSize size) {\n+  template<bool UpBuffer>\n+  D3D9BufferSlice D3D9DeviceEx::AllocTempBuffer(VkDeviceSize size) {\n     constexpr VkDeviceSize DefaultSize = 1 << 20;\n \n-    constexpr VkMemoryPropertyFlags memoryFlags\n-      = VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT\n-      | VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT\n-      | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT;\n+    VkMemoryPropertyFlags memoryFlags\n+      = VK_MEMORY_PROPERTY_HOST_COHERENT_BIT\n+      | VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT;\n+\n+    if constexpr (UpBuffer) {\n+      memoryFlags |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;\n+    }\n+\n+    D3D9BufferSlice& currentSlice = UpBuffer ? m_upBuffer : m_managedUploadBuffer;\n \n     if (size <= DefaultSize) {\n-      if (unlikely(!m_upBuffer.slice.defined())) {\n+      if (unlikely(!currentSlice.slice.defined())) {\n         DxvkBufferCreateInfo info;\n         info.size   = DefaultSize;\n-        info.usage  = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT\n-                    | VK_BUFFER_USAGE_INDEX_BUFFER_BIT;\n-        info.access = VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT\n-                    | VK_ACCESS_INDEX_READ_BIT;\n-        info.stages = VK_PIPELINE_STAGE_VERTEX_INPUT_BIT;\n+        if constexpr (UpBuffer) {\n+          info.usage  = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT\n+                      | VK_BUFFER_USAGE_INDEX_BUFFER_BIT;\n+          info.access = VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT\n+                      | VK_ACCESS_INDEX_READ_BIT;\n+          info.stages = VK_PIPELINE_STAGE_VERTEX_INPUT_BIT;\n+        } else {\n+          info.usage  = VK_BUFFER_USAGE_TRANSFER_SRC_BIT;\n+          info.stages = VK_PIPELINE_STAGE_TRANSFER_BIT;\n+          info.access = VK_ACCESS_TRANSFER_READ_BIT;\n+        }\n \n-        m_upBuffer.slice  = DxvkBufferSlice(m_dxvkDevice->createBuffer(info, memoryFlags));\n-        m_upBuffer.mapPtr = m_upBuffer.slice.mapPtr(0);\n-      } else if (unlikely(m_upBuffer.slice.length() < size)) {\n-        auto physSlice = m_upBuffer.slice.buffer()->allocSlice();\n+        currentSlice.slice  = DxvkBufferSlice(m_dxvkDevice->createBuffer(info, memoryFlags));\n+        currentSlice.mapPtr = currentSlice.slice.mapPtr(0);\n+      } else if (unlikely(currentSlice.slice.length() < size)) {\n+        auto physSlice = currentSlice.slice.buffer()->allocSlice();\n \n-        m_upBuffer.slice  = DxvkBufferSlice(m_upBuffer.slice.buffer());\n-        m_upBuffer.mapPtr = physSlice.mapPtr;\n+        currentSlice.slice  = DxvkBufferSlice(currentSlice.slice.buffer());\n+        currentSlice.mapPtr = physSlice.mapPtr;\n \n         EmitCs([\n-          cBuffer = m_upBuffer.slice.buffer(),\n+          cBuffer = currentSlice.slice.buffer(),\n           cSlice  = physSlice\n         ] (DxvkContext* ctx) {\n           ctx->invalidateBuffer(cBuffer, cSlice);\n         });\n       }\n \n-      D3D9UPBufferSlice result;\n-      result.slice  = m_upBuffer.slice.subSlice(0, size);\n-      result.mapPtr = reinterpret_cast<char*>(m_upBuffer.mapPtr) + m_upBuffer.slice.offset();\n+      D3D9BufferSlice result;\n+      result.slice  = currentSlice.slice.subSlice(0, size);\n+      result.mapPtr = reinterpret_cast<char*>(currentSlice.mapPtr) + currentSlice.slice.offset();\n \n       VkDeviceSize adjust = align(size, CACHE_LINE_SIZE);\n-      m_upBuffer.slice = m_upBuffer.slice.subSlice(adjust, m_upBuffer.slice.length() - adjust);\n+      currentSlice.slice = currentSlice.slice.subSlice(adjust, currentSlice.slice.length() - adjust);\n       return result;\n     } else {\n       // Create a temporary buffer for very large allocations\n       DxvkBufferCreateInfo info;\n       info.size   = size;\n-      info.usage  = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT\n-                  | VK_BUFFER_USAGE_INDEX_BUFFER_BIT;\n-      info.access = VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT\n-                  | VK_ACCESS_INDEX_READ_BIT;\n-      info.stages = VK_PIPELINE_STAGE_VERTEX_INPUT_BIT;\n+      if constexpr (UpBuffer) {\n+        info.usage  = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT\n+                    | VK_BUFFER_USAGE_INDEX_BUFFER_BIT;\n+        info.access = VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT\n+                    | VK_ACCESS_INDEX_READ_BIT;\n+        info.stages = VK_PIPELINE_STAGE_VERTEX_INPUT_BIT;\n+      } else {\n+        info.usage  = VK_BUFFER_USAGE_TRANSFER_SRC_BIT;\n+        info.stages = VK_PIPELINE_STAGE_TRANSFER_BIT;\n+        info.access = VK_ACCESS_TRANSFER_READ_BIT;\n+      }\n \n-      D3D9UPBufferSlice result;\n+      D3D9BufferSlice result;\n       result.slice  = DxvkBufferSlice(m_dxvkDevice->createBuffer(info, memoryFlags));\n       result.mapPtr = result.slice.mapPtr(0);\n       return result;\n     }\n   }\n \n-\n   bool D3D9DeviceEx::ShouldRecord() {\n     return m_recorder != nullptr && !m_recorder->IsApplying();\n   }\n@@ -3973,11 +4019,10 @@ namespace dxvk {\n \n     VkExtent3D levelExtent = pResource->GetExtentMip(MipLevel);\n     VkExtent3D blockCount  = util::computeBlockCount(levelExtent, formatInfo->blockSize);\n-    \n+\n     const bool systemmem = desc.Pool == D3DPOOL_SYSTEMMEM;\n     const bool managed   = IsPoolManaged(desc.Pool);\n     const bool scratch   = desc.Pool == D3DPOOL_SCRATCH;\n-    const bool doNotWait = Flags & D3DLOCK_DONOTWAIT;\n \n     bool fullResource = pBox == nullptr;\n     if (unlikely(!fullResource)) {\n@@ -4043,34 +4088,14 @@ namespace dxvk {\n       // calling app promises not to overwrite data that is in use\n       // or is reading. Remember! This will only trigger for MANAGED resources\n       // that cannot get affected by GPU, therefore readonly is A-OK for NOT waiting.\n-      const bool skipWait = (readOnly && managed) || scratch || (readOnly && systemmem && !wasWrittenByGPU);\n-\n-      bool doImplicitDiscard = (managed || (systemmem && !wasWrittenByGPU)) && !doNotWait;\n-\n-      doImplicitDiscard = doImplicitDiscard && m_d3d9Options.allowImplicitDiscard;\n+      const bool skipWait = scratch || managed || (systemmem && !wasWrittenByGPU);\n \n       if (alloced) {\n         std::memset(physSlice.mapPtr, 0, physSlice.length);\n       }\n       else if (!skipWait) {\n-        if (doImplicitDiscard) {\n-          if (!WaitForResource(mappedBuffer, D3DLOCK_DONOTWAIT)) {\n-            // if the mapped buffer is currently being copied to image\n-            // we can just avoid a stall by allocating a new slice and copying the existing contents\n-            DxvkBufferSliceHandle oldSlice = physSlice;\n-            physSlice = pResource->DiscardMapSlice(Subresource);\n-            std::memcpy(physSlice.mapPtr, oldSlice.mapPtr, oldSlice.length);\n-            EmitCs([\n-              cImageBuffer = std::move(mappedBuffer),\n-              cBufferSlice = physSlice\n-            ] (DxvkContext* ctx) {\n-              ctx->invalidateBuffer(cImageBuffer, cBufferSlice);\n-            });\n-          }\n-        } else {\n-          if (!WaitForResource(mappedBuffer, Flags))\n-            return D3DERR_WASSTILLDRAWING;\n-        }\n+        if (!WaitForResource(mappedBuffer, Flags))\n+          return D3DERR_WASSTILLDRAWING;\n       }\n     }\n     else {\n@@ -4158,13 +4183,13 @@ namespace dxvk {\n     if (atiHack) {\n       // We need to lie here. The game is expected to use this info and do a workaround.\n       // It's stupid. I know.\n-      pLockedBox->RowPitch   = std::max(desc.Width >> MipLevel, 1u);\n+      pLockedBox->RowPitch   = align(std::max(desc.Width >> MipLevel, 1u), 4);\n       pLockedBox->SlicePitch = pLockedBox->RowPitch * std::max(desc.Height >> MipLevel, 1u);\n     }\n     else {\n       // Data is tightly packed within the mapped buffer.\n-      pLockedBox->RowPitch   = formatInfo->elementSize * blockCount.width;\n-      pLockedBox->SlicePitch = formatInfo->elementSize * blockCount.width * blockCount.height;\n+      pLockedBox->RowPitch   = align(formatInfo->elementSize * blockCount.width, 4);\n+      pLockedBox->SlicePitch = pLockedBox->RowPitch * blockCount.height;\n     }\n \n     pResource->SetLocked(Subresource, true);\n@@ -4258,19 +4283,16 @@ namespace dxvk {\n   HRESULT D3D9DeviceEx::FlushImage(\n         D3D9CommonTexture*      pResource,\n         UINT                    Subresource) {\n-    const Rc<DxvkImage>  image = pResource->GetImage();\n+    const Rc<DxvkImage> image = pResource->GetImage();\n \n     // Now that data has been written into the buffer,\n     // we need to copy its contents into the image\n-    const Rc<DxvkBuffer> copyBuffer = pResource->GetBuffer(Subresource);\n+    const DxvkBufferSliceHandle srcSlice = pResource->GetMappedSlice(Subresource);\n \n     auto formatInfo  = imageFormatInfo(image->info().format);\n     auto subresource = pResource->GetSubresourceFromIndex(\n       formatInfo->aspectMask, Subresource);\n \n-    VkExtent3D levelExtent = image\n-      ->mipLevelExtent(subresource.mipLevel);\n-\n     VkImageSubresourceLayers subresourceLayers = {\n       subresource.aspectMask,\n       subresource.mipLevel,\n@@ -4279,25 +4301,76 @@ namespace dxvk {\n     auto convertFormat = pResource->GetFormatMapping().ConversionFormatInfo;\n \n     if (likely(convertFormat.FormatType == D3D9ConversionFormat_None)) {\n+      const DxvkFormatInfo* formatInfo = imageFormatInfo(pResource->GetFormatMapping().FormatColor);\n+      VkImageSubresourceLayers dstLayers = { VK_IMAGE_ASPECT_COLOR_BIT, subresource.mipLevel, subresource.arrayLayer, 1 };\n+\n+      const D3DBOX& box = pResource->GetDirtyBox(subresource.arrayLayer);\n+      VkOffset3D scaledBoxOffset = {\n+        int32_t(alignDown(box.Left  >> subresource.mipLevel, formatInfo->blockSize.width)),\n+        int32_t(alignDown(box.Top   >> subresource.mipLevel, formatInfo->blockSize.height)),\n+        int32_t(alignDown(box.Front >> subresource.mipLevel, formatInfo->blockSize.depth))\n+      };\n+      VkExtent3D scaledBoxExtent = util::computeMipLevelExtent({\n+        uint32_t(box.Right - scaledBoxOffset.x),\n+        uint32_t(box.Bottom - scaledBoxOffset.y),\n+        uint32_t(box.Back - scaledBoxOffset.z)\n+      }, subresource.mipLevel);\n+      VkExtent3D scaledBoxExtentBlockCount = util::computeBlockCount(scaledBoxExtent, formatInfo->blockSize);\n+      VkExtent3D scaledAlignedBoxExtent = util::computeBlockExtent(scaledBoxExtentBlockCount, formatInfo->blockSize);\n+\n+      VkExtent3D texLevelExtent = image->mipLevelExtent(subresource.mipLevel);\n+      VkExtent3D texLevelExtentBlockCount = util::computeBlockCount(texLevelExtent, formatInfo->blockSize);\n+\n+      scaledAlignedBoxExtent.width = std::min<uint32_t>(texLevelExtent.width, scaledAlignedBoxExtent.width);\n+      scaledAlignedBoxExtent.height = std::min<uint32_t>(texLevelExtent.height, scaledAlignedBoxExtent.height);\n+      scaledAlignedBoxExtent.depth = std::min<uint32_t>(texLevelExtent.depth, scaledAlignedBoxExtent.depth);\n+\n+      VkDeviceSize dirtySize = scaledBoxExtentBlockCount.width * scaledBoxExtentBlockCount.height * scaledBoxExtentBlockCount.depth * formatInfo->elementSize;\n+      D3D9BufferSlice slice = AllocTempBuffer<false>(dirtySize);\n+      VkOffset3D boxOffsetBlockCount = util::computeBlockOffset(scaledBoxOffset, formatInfo->blockSize);\n+      VkDeviceSize copySrcOffset = (boxOffsetBlockCount.z * texLevelExtentBlockCount.height * texLevelExtentBlockCount.width\n+          + boxOffsetBlockCount.y * texLevelExtentBlockCount.width\n+          + boxOffsetBlockCount.x)\n+          * formatInfo->elementSize;\n+\n+      VkDeviceSize pitch = align(texLevelExtentBlockCount.width * formatInfo->elementSize, 4);\n+      void* srcData = reinterpret_cast<uint8_t*>(srcSlice.mapPtr) + copySrcOffset;\n+      util::packImageData(\n+        slice.mapPtr, srcData, scaledBoxExtentBlockCount, formatInfo->elementSize,\n+        pitch, pitch * texLevelExtentBlockCount.height);\n+\n       EmitCs([\n-        cSrcBuffer      = copyBuffer,\n+        cSrcSlice       = slice.slice,\n         cDstImage       = image,\n-        cDstLayers      = subresourceLayers,\n-        cDstLevelExtent = levelExtent\n+        cDstLayers      = dstLayers,\n+        cDstLevelExtent = scaledAlignedBoxExtent,\n+        cOffset         = scaledBoxOffset\n       ] (DxvkContext* ctx) {\n-        ctx->copyBufferToImage(cDstImage, cDstLayers,\n-          VkOffset3D{ 0, 0, 0 }, cDstLevelExtent,\n-          cSrcBuffer, 0, { 0u, 0u });\n+        ctx->copyBufferToImage(\n+          cDstImage,  cDstLayers,\n+          cOffset, cDstLevelExtent,\n+          cSrcSlice.buffer(), cSrcSlice.offset(),\n+          VkExtent2D { 0, 0 });\n       });\n-    } \n+    }\n     else {\n+      VkExtent3D texLevelExtent = image->mipLevelExtent(Subresource);\n+      VkExtent3D texLevelExtentBlockCount = util::computeBlockCount(texLevelExtent, formatInfo->blockSize);\n+\n+      D3D9BufferSlice slice = AllocTempBuffer<false>(srcSlice.length);\n+      VkDeviceSize pitch = align(texLevelExtentBlockCount.width * formatInfo->elementSize, 4);\n+      util::packImageData(\n+        slice.mapPtr, srcSlice.mapPtr, texLevelExtent, formatInfo->elementSize,\n+        pitch, pitch * texLevelExtentBlockCount.height);\n+\n       Flush();\n       SynchronizeCsThread();\n \n       m_converter->ConvertFormat(\n         convertFormat,\n         image, subresourceLayers,\n-        copyBuffer);\n+        slice.slice.buffer(),\n+        slice.slice.offset());\n     }\n \n     if (pResource->IsAutomaticMip())\n@@ -4365,19 +4438,17 @@ namespace dxvk {\n     const bool quickRead   = ((Flags & D3DLOCK_READONLY) && !pResource->WasWrittenByGPU());\n     const bool boundsCheck = desc.Pool != D3DPOOL_DEFAULT && !quickRead;\n \n-    if (boundsCheck) {\n-      // We can only respect this for these cases -- otherwise R/W OOB still get copied on native\n-      // and some stupid games depend on that.\n-      const bool respectUserBounds = !(Flags & D3DLOCK_DISCARD) &&\n-                                     SizeToLock != 0;\n+    // We can only respect this for these cases -- otherwise R/W OOB still get copied on native\n+    // and some stupid games depend on that.\n+    const bool respectUserBounds = !(Flags & D3DLOCK_DISCARD) &&\n+                                    SizeToLock != 0;\n \n-      // If we don't respect the bounds, encompass it all in our tests/checks\n-      // These values may be out of range and don't get clamped.\n-      uint32_t offset = respectUserBounds ? OffsetToLock : 0;\n-      uint32_t size   = respectUserBounds ? SizeToLock   : desc.Size;\n+    // If we don't respect the bounds, encompass it all in our tests/checks\n+    // These values may be out of range and don't get clamped.\n+    uint32_t offset = respectUserBounds ? OffsetToLock : 0;\n+    uint32_t size   = respectUserBounds ? std::min(SizeToLock, desc.Size - offset) : (desc.Size - offset);\n \n-      pResource->DirtyRange().Conjoin(D3D9Range(offset, offset + size));\n-    }\n+    pResource->DirtyRange().Conjoin(D3D9Range(offset, offset + size));\n \n     Rc<DxvkBuffer> mappingBuffer = pResource->GetBuffer<D3D9_COMMON_BUFFER_TYPE_MAPPING>();\n \n@@ -4415,31 +4486,8 @@ namespace dxvk {\n                             quickRead                     ||\n                             (boundsCheck && !pResource->GPUReadingRange().Overlaps(pResource->DirtyRange()));\n       if (!skipWait) {\n-        const bool backed    = pResource->GetMapMode() == D3D9_COMMON_BUFFER_MAP_MODE_BUFFER;\n-        const bool doNotWait = Flags & D3DLOCK_DONOTWAIT;\n-\n-        bool doImplicitDiscard = backed && !doNotWait && pResource->GetLockCount() == 0 && !pResource->WasWrittenByGPU();\n-\n-        doImplicitDiscard = doImplicitDiscard && m_d3d9Options.allowImplicitDiscard;\n-\n-        if (doImplicitDiscard) {\n-          if (!WaitForResource(mappingBuffer, D3DLOCK_DONOTWAIT)) {\n-            // if the mapped buffer is currently being copied to the primary buffer\n-            // we can just avoid a stall by allocating a new slice and copying the existing contents\n-            DxvkBufferSliceHandle oldSlice = physSlice;\n-            physSlice = pResource->DiscardMapSlice();\n-            std::memcpy(physSlice.mapPtr, oldSlice.mapPtr, oldSlice.length);\n-            EmitCs([\n-              cBuffer = std::move(mappingBuffer),\n-              cBufferSlice = physSlice\n-            ] (DxvkContext* ctx) {\n-              ctx->invalidateBuffer(cBuffer, cBufferSlice);\n-            });\n-          }\n-        } else {\n-          if (!WaitForResource(mappingBuffer, Flags))\n-            return D3DERR_WASSTILLDRAWING;\n-        }\n+        if (!WaitForResource(mappingBuffer, Flags))\n+          return D3DERR_WASSTILLDRAWING;\n \n         pResource->SetWrittenByGPU(false);\n         pResource->GPUReadingRange().Clear();\n@@ -4471,16 +4519,22 @@ namespace dxvk {\n     auto dstBuffer = pResource->GetBufferSlice<D3D9_COMMON_BUFFER_TYPE_REAL>();\n     auto srcBuffer = pResource->GetBufferSlice<D3D9_COMMON_BUFFER_TYPE_STAGING>();\n \n+    D3D9Range& range = pResource->DirtyRange();\n+\n+    D3D9BufferSlice slice = AllocTempBuffer<false>(range.max - range.min);\n+    memcpy(slice.mapPtr, srcBuffer.mapPtr(range.min), range.max - range.min);\n+\n     EmitCs([\n-      cDstSlice = dstBuffer,\n-      cSrcSlice = srcBuffer\n+      cDstSlice  = dstBuffer,\n+      cSrcSlice = slice.slice,\n+      cLength    = range.max - range.min\n     ] (DxvkContext* ctx) {\n       ctx->copyBuffer(\n         cDstSlice.buffer(),\n         cDstSlice.offset(),\n         cSrcSlice.buffer(),\n         cSrcSlice.offset(),\n-        cSrcSlice.length());\n+        cLength);\n     });\n \n     pResource->GPUReadingRange().Conjoin(pResource->DirtyRange());\n@@ -4665,7 +4719,7 @@ namespace dxvk {\n                            DxsoProgramType::PixelShader,\n                            DxsoConstantBuffers::PSConstantBuffer);\n \n-    m_vsClipPlanes = \n+    m_vsClipPlanes =\n       CreateConstantBuffer(false,\n                            caps::MaxClipPlanes * sizeof(D3D9ClipPlane),\n                            DxsoProgramType::VertexShader,\n@@ -4774,16 +4828,16 @@ namespace dxvk {\n \n   void D3D9DeviceEx::UpdateClipPlanes() {\n     m_flags.clr(D3D9DeviceFlag::DirtyClipPlanes);\n-    \n+\n     auto slice = m_vsClipPlanes->allocSlice();\n     auto dst = reinterpret_cast<D3D9ClipPlane*>(slice.mapPtr);\n-    \n+\n     for (uint32_t i = 0; i < caps::MaxClipPlanes; i++) {\n       dst[i] = (m_state.renderStates[D3DRS_CLIPPLANEENABLE] & (1 << i))\n         ? m_state.clipPlanes[i]\n         : D3D9ClipPlane();\n     }\n-    \n+\n     EmitCs([\n       cBuffer = m_vsClipPlanes,\n       cSlice  = slice\n@@ -4865,7 +4919,7 @@ namespace dxvk {\n     else\n       Logger::warn(\"D3D9: Invalid push constant set to update.\");\n   }\n-  \n+\n \n \n   void D3D9DeviceEx::Flush() {\n@@ -5034,7 +5088,7 @@ namespace dxvk {\n     m_activeTexturesToGen &= ~mask;\n   }\n \n-  \n+\n   void D3D9DeviceEx::MarkTextureMipsDirty(D3D9CommonTexture* pResource) {\n     pResource->SetNeedsMipGen(true);\n     pResource->MarkAllWrittenByGPU();\n@@ -5510,13 +5564,13 @@ namespace dxvk {\n \n   void D3D9DeviceEx::BindAlphaTestState() {\n     m_flags.clr(D3D9DeviceFlag::DirtyAlphaTestState);\n-    \n+\n     auto& rs = m_state.renderStates;\n-    \n+\n     VkCompareOp alphaOp = IsAlphaTestEnabled()\n       ? DecodeCompareOp(D3DCMPFUNC(rs[D3DRS_ALPHAFUNC]))\n       : VK_COMPARE_OP_ALWAYS;\n-    \n+\n     EmitCs([cAlphaOp = alphaOp] (DxvkContext* ctx) {\n       ctx->setSpecConstant(VK_PIPELINE_BIND_POINT_GRAPHICS, D3D9SpecConstantId::AlphaTestEnable, cAlphaOp != VK_COMPARE_OP_ALWAYS);\n       ctx->setSpecConstant(VK_PIPELINE_BIND_POINT_GRAPHICS, D3D9SpecConstantId::AlphaCompareOp,  cAlphaOp);\n@@ -5699,7 +5753,7 @@ namespace dxvk {\n   void D3D9DeviceEx::UndirtySamplers() {\n     for (uint32_t dirty = m_dirtySamplerStates; dirty; dirty &= dirty - 1)\n       BindSampler(bit::tzcnt(dirty));\n-    \n+\n     m_dirtySamplerStates = 0;\n   }\n \n@@ -5777,7 +5831,7 @@ namespace dxvk {\n \n     if (m_flags.test(D3D9DeviceFlag::DirtyBlendState))\n       BindBlendState();\n-    \n+\n     if (m_flags.test(D3D9DeviceFlag::DirtyDepthStencilState))\n       BindDepthStencilState();\n \n@@ -5786,13 +5840,13 @@ namespace dxvk {\n \n     if (m_flags.test(D3D9DeviceFlag::DirtyDepthBias))\n       BindDepthBias();\n-    \n+\n     if (m_flags.test(D3D9DeviceFlag::DirtyMultiSampleState))\n       BindMultiSampleState();\n \n     if (m_flags.test(D3D9DeviceFlag::DirtyAlphaTestState))\n       BindAlphaTestState();\n-    \n+\n     if (m_flags.test(D3D9DeviceFlag::DirtyClipPlanes))\n       UpdateClipPlanes();\n \n@@ -6023,7 +6077,7 @@ namespace dxvk {\n         // out attributes and bindings not used by the shader\n         uint32_t attrCount = CompactSparseList(attrList.data(), attrMask);\n         uint32_t bindCount = CompactSparseList(bindList.data(), bindMask);\n-      \n+\n         ctx->setInputLayout(\n           attrCount, attrList.data(),\n           bindCount, bindList.data());\n@@ -6039,8 +6093,8 @@ namespace dxvk {\n         UINT                              Stride) {\n     EmitCs([\n       cSlotId       = Slot,\n-      cBufferSlice  = pBuffer != nullptr ? \n-          pBuffer->GetCommonBuffer()->GetBufferSlice<D3D9_COMMON_BUFFER_TYPE_REAL>(Offset) \n+      cBufferSlice  = pBuffer != nullptr ?\n+          pBuffer->GetCommonBuffer()->GetBufferSlice<D3D9_COMMON_BUFFER_TYPE_REAL>(Offset)\n         : DxvkBufferSlice(),\n       cStride       = pBuffer != nullptr ? Stride : 0\n     ] (DxvkContext* ctx) {\n@@ -6342,7 +6396,7 @@ namespace dxvk {\n         data->TexcoordMatrices[i] = m_state.transforms[GetTransformIndex(D3DTS_TEXTURE0) + i];\n \n       data->ViewportInfo = m_viewportInfo;\n-      \n+\n       DecodeD3DCOLOR(m_state.renderStates[D3DRS_AMBIENT], data->GlobalAmbient.data);\n \n       uint32_t lightIdx = 0;\n@@ -6399,7 +6453,7 @@ namespace dxvk {\n             return 0b100u; // Arg 2\n           case D3DTOP_MULTIPLYADD:\n           case D3DTOP_LERP:\n-            return 0b111u; // Arg 0, 1, 2 \n+            return 0b111u; // Arg 0, 1, 2\n           default:\n             return 0b110u; // Arg 1, 2\n         }\n@@ -6593,23 +6647,23 @@ namespace dxvk {\n \n     const D3D9_VK_FORMAT_MAPPING srcFormatInfo = LookupFormat(srcDesc->Format);\n     const D3D9_VK_FORMAT_MAPPING dstFormatInfo = LookupFormat(dstDesc->Format);\n-    \n+\n     auto srcVulkanFormatInfo = imageFormatInfo(srcFormatInfo.FormatColor);\n     auto dstVulkanFormatInfo = imageFormatInfo(dstFormatInfo.FormatColor);\n-    \n+\n     const VkImageSubresource dstSubresource =\n       dstTextureInfo->GetSubresourceFromIndex(\n         dstVulkanFormatInfo->aspectMask, 0);\n-    \n+\n     const VkImageSubresource srcSubresource =\n       srcTextureInfo->GetSubresourceFromIndex(\n         srcVulkanFormatInfo->aspectMask, src->GetSubresource());\n-    \n+\n     const VkImageSubresourceLayers dstSubresourceLayers = {\n       dstSubresource.aspectMask,\n       dstSubresource.mipLevel,\n       dstSubresource.arrayLayer, 1 };\n-    \n+\n     const VkImageSubresourceLayers srcSubresourceLayers = {\n       srcSubresource.aspectMask,\n       srcSubresource.mipLevel,\n@@ -6630,7 +6684,7 @@ namespace dxvk {\n           cSrcImage, cSrcLayers, VkOffset3D { 0, 0, 0 },\n           cDstImage->mipLevelExtent(cDstLayers.mipLevel));\n       });\n-    } else {      \n+    } else {\n       EmitCs([\n         cDstImage  = dstTextureInfo->GetImage(),\n         cSrcImage  = srcTextureInfo->GetImage(),\n@@ -6685,7 +6739,7 @@ namespace dxvk {\n     });\n   }\n \n-  \n+\n   HRESULT D3D9DeviceEx::ResetState(D3DPRESENT_PARAMETERS* pPresentationParameters) {\n     if (!pPresentationParameters->EnableAutoDepthStencil)\n       SetDepthStencilSurface(nullptr);\n@@ -6754,7 +6808,7 @@ namespace dxvk {\n \n     rs[D3DRS_TEXTUREFACTOR]       = 0xffffffff;\n     m_flags.set(D3D9DeviceFlag::DirtyFFPixelData);\n-    \n+\n     rs[D3DRS_DIFFUSEMATERIALSOURCE]  = D3DMCS_COLOR1;\n     rs[D3DRS_SPECULARMATERIALSOURCE] = D3DMCS_COLOR2;\n     rs[D3DRS_AMBIENTMATERIALSOURCE]  = D3DMCS_MATERIAL;\n@@ -7003,5 +7057,4 @@ namespace dxvk {\n     return D3D_OK;\n   }\n \n-\n }\ndiff --git a/src/d3d9/d3d9_device.h b/src/d3d9/d3d9_device.h\nindex ccc7e494461..1b450639aa4 100644\n--- a/src/d3d9/d3d9_device.h\n+++ b/src/d3d9/d3d9_device.h\n@@ -85,7 +85,7 @@ namespace dxvk {\n     Rc<DxvkSampler> depth;\n   };\n \n-  struct D3D9UPBufferSlice {\n+  struct D3D9BufferSlice {\n     DxvkBufferSlice slice = {};\n     void*           mapPtr = nullptr;\n   };\n@@ -999,7 +999,8 @@ namespace dxvk {\n     Rc<DxvkBuffer>                  m_psFixedFunction;\n     Rc<DxvkBuffer>                  m_psShared;\n \n-    D3D9UPBufferSlice               m_upBuffer;\n+    D3D9BufferSlice                 m_upBuffer;\n+    D3D9BufferSlice                 m_managedUploadBuffer;\n \n     const D3D9Options               m_d3d9Options;\n     DxsoOptions                     m_dxsoOptions;\n@@ -1073,7 +1074,8 @@ namespace dxvk {\n \n     void DetermineConstantLayouts(bool canSWVP);\n \n-    D3D9UPBufferSlice AllocUpBuffer(VkDeviceSize size);\n+    template<bool UpBuffer>\n+    D3D9BufferSlice AllocTempBuffer(VkDeviceSize size);\n \n     bool ShouldRecord();\n \ndiff --git a/src/d3d9/d3d9_format_helpers.cpp b/src/d3d9/d3d9_format_helpers.cpp\nindex 77a1eecb571..9c581e236c0 100644\n--- a/src/d3d9/d3d9_format_helpers.cpp\n+++ b/src/d3d9/d3d9_format_helpers.cpp\n@@ -28,33 +28,34 @@ namespace dxvk {\n           D3D9_CONVERSION_FORMAT_INFO   conversionFormat,\n     const Rc<DxvkImage>&                dstImage,\n           VkImageSubresourceLayers      dstSubresource,\n-    const Rc<DxvkBuffer>&               srcBuffer) {\n+    const Rc<DxvkBuffer>&               srcBuffer,\n+          uint32_t                      srcBufferOffset) {\n     switch (conversionFormat.FormatType) {\n       case D3D9ConversionFormat_YUY2:\n       case D3D9ConversionFormat_UYVY: {\n         uint32_t specConstant = conversionFormat.FormatType == D3D9ConversionFormat_UYVY ? 1 : 0;\n-        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, VK_FORMAT_R32_UINT, specConstant, { 2u, 1u });\n+        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, srcBufferOffset, VK_FORMAT_R32_UINT, specConstant, { 2u, 1u });\n         break;\n       }\n \n       case D3D9ConversionFormat_NV12:\n-        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, VK_FORMAT_R16_UINT, 0, { 2u, 1u });\n+        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, srcBufferOffset, VK_FORMAT_R16_UINT, 0, { 2u, 1u });\n         break;\n \n       case D3D9ConversionFormat_YV12:\n-        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, VK_FORMAT_R8_UINT, 0, { 1u, 1u });\n+        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, srcBufferOffset, VK_FORMAT_R8_UINT, 0, { 1u, 1u });\n         break;\n \n       case D3D9ConversionFormat_L6V5U5:\n-        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, VK_FORMAT_R16_UINT, 0, { 1u, 1u });\n+        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, srcBufferOffset, VK_FORMAT_R16_UINT, 0, { 1u, 1u });\n         break;\n \n       case D3D9ConversionFormat_X8L8V8U8:\n-        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, VK_FORMAT_R32_UINT, 0, { 1u, 1u });\n+        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, srcBufferOffset, VK_FORMAT_R32_UINT, 0, { 1u, 1u });\n         break;\n \n       case D3D9ConversionFormat_A2W10V10U10:\n-        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, VK_FORMAT_R32_UINT, 0, { 1u, 1u });\n+        ConvertGenericFormat(conversionFormat, dstImage, dstSubresource, srcBuffer, srcBufferOffset, VK_FORMAT_R32_UINT, 0, { 1u, 1u });\n         break;\n \n       default:\n@@ -68,6 +69,7 @@ namespace dxvk {\n     const Rc<DxvkImage>&                dstImage,\n           VkImageSubresourceLayers      dstSubresource,\n     const Rc<DxvkBuffer>&               srcBuffer,\n+          uint32_t                      srcBufferOffset,\n           VkFormat                      bufferFormat,\n           uint32_t                      specConstantValue,\n           VkExtent2D                    macroPixelRun) {\n@@ -89,7 +91,7 @@ namespace dxvk {\n \n     DxvkBufferViewCreateInfo bufferViewInfo;\n     bufferViewInfo.format      = bufferFormat;\n-    bufferViewInfo.rangeOffset = 0;\n+    bufferViewInfo.rangeOffset = srcBufferOffset;\n     bufferViewInfo.rangeLength = srcBuffer->info().size;\n     auto tmpBufferView = m_device->createBufferView(srcBuffer, bufferViewInfo);\n \ndiff --git a/src/d3d9/d3d9_format_helpers.h b/src/d3d9/d3d9_format_helpers.h\nindex 08019842d62..3563e9fdbf6 100644\n--- a/src/d3d9/d3d9_format_helpers.h\n+++ b/src/d3d9/d3d9_format_helpers.h\n@@ -19,7 +19,8 @@ namespace dxvk {\n             D3D9_CONVERSION_FORMAT_INFO   conversionFormat,\n       const Rc<DxvkImage>&                dstImage,\n             VkImageSubresourceLayers      dstSubresource,\n-      const Rc<DxvkBuffer>&               srcBuffer);\n+      const Rc<DxvkBuffer>&               srcBuffer,\n+            uint32_t                      srcBufferOffset);\n \n   private:\n \n@@ -28,6 +29,7 @@ namespace dxvk {\n       const Rc<DxvkImage>&                dstImage,\n             VkImageSubresourceLayers      dstSubresource,\n       const Rc<DxvkBuffer>&               srcBuffer,\n+            uint32_t                      srcBufferOffset,\n             VkFormat                      bufferFormat,\n             uint32_t                      specConstantValue,\n             VkExtent2D                    macroPixelRun);\ndiff --git a/src/d3d9/d3d9_options.cpp b/src/d3d9/d3d9_options.cpp\nindex 2af05717436..fa2564c2595 100644\n--- a/src/d3d9/d3d9_options.cpp\n+++ b/src/d3d9/d3d9_options.cpp\n@@ -74,7 +74,6 @@ namespace dxvk {\n     this->alphaTestWiggleRoom           = config.getOption<bool>        (\"d3d9.alphaTestWiggleRoom\",           false);\n     this->apitraceMode                  = config.getOption<bool>        (\"d3d9.apitraceMode\",                  false);\n     this->deviceLocalConstantBuffers    = config.getOption<bool>        (\"d3d9.deviceLocalConstantBuffers\",    false);\n-    this->allowImplicitDiscard          = config.getOption<bool>        (\"d3d9.allowImplicitDiscard\",          true);\n \n     // If we are not Nvidia, enable general hazards.\n     this->generalHazards = adapter != nullptr\ndiff --git a/src/d3d9/d3d9_options.h b/src/d3d9/d3d9_options.h\nindex df271a1160b..87e1e0ec9f2 100644\n--- a/src/d3d9/d3d9_options.h\n+++ b/src/d3d9/d3d9_options.h\n@@ -152,10 +152,6 @@ namespace dxvk {\n \n     /// Use device local memory for constant buffers.\n     bool deviceLocalConstantBuffers;\n-\n-    /// Allow implicit discard of resources in contested situations.\n-    /// Some naughty apps write to pointers outside of lock boundaries.\n-    bool allowImplicitDiscard;\n   };\n \n }\n\\ No newline at end of file\ndiff --git a/src/util/config/config.cpp b/src/util/config/config.cpp\nindex c73fae9377c..c336a4962fd 100644\n--- a/src/util/config/config.cpp\n+++ b/src/util/config/config.cpp\n@@ -383,7 +383,6 @@ namespace dxvk {\n     }} },\n     /* Warhammer: Online                         */\n     { R\"(\\\\WAR(-64)?\\.exe$)\", {{\n-      { \"d3d9.allowImplicitDiscard\",        \"False\" },\n       { \"d3d9.customVendorId\",              \"1002\" },\n     }} },\n     /* Dragon Nest                               */\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "- **Bug Identified**: Using Apitrace with DXVK leads to graphical issues when tracing. Ensure that the correct DXVK d3d9.dll is used; the Apitrace wrapper shouldn't overwrite it. \n\n- **Implementation Suggestion**: Avoid copying DXVK d3d9.dll to `syswow64`; this could disrupt the system. Instead, continue using the original method if it works.\n\n- **Compatibility Concern**: There may be specific issues with NVIDIA drivers based on the reproduction of the problem with DXVK versions back to 1.5.5. Test with different drivers if issues persist.\n\n- **Next Steps**: Confirm consistency of the trace results with different configurations, and report findings with additional graphics cards to identify hardware-specific bugs."
      }
    ],
    "codediff_length": 43577
  },
  {
    "index": 55,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/include/meson.build b/include/meson.build\nnew file mode 100644\nindex 00000000000..8063ab5010b\n--- /dev/null\n+++ b/include/meson.build\n@@ -0,0 +1,22 @@\n+idl_files = files([\n+    'native/unknwn.idl',\n+    'native/dxgiformat.idl',\n+    'native/dxgicommon.idl',\n+    'native/dxgitype.idl',\n+    'native/dxgi.idl',\n+    'native/dxgi1_2.idl',\n+    'native/dxgi1_3.idl',\n+    'native/dxgi1_4.idl',\n+    'native/d3dcommon.idl',\n+    'native/d3d10.idl',\n+    'native/d3d10_1.idl',\n+    'native/d3d11.idl',\n+    'native/d3d11_1.idl',\n+    'native/d3d11sdklayers.idl'\n+])\n+\n+if dxvk_native\n+  com_headers = com_header_generator.process(idl_files)\n+else\n+  com_headers = []\n+endif\ndiff --git a/meson.build b/meson.build\nindex 784ea58f6e3..6e36f2a4f68 100644\n--- a/meson.build\n+++ b/meson.build\n@@ -1,4 +1,4 @@\n-project('dxvk', ['c', 'cpp'], version : 'v1.0', meson_version : '>= 0.43')\n+project('dxvk', ['c', 'cpp'], version : 'v1.0', meson_version : '>= 0.46')\n \n cpu_family = target_machine.cpu_family()\n \n@@ -17,19 +17,27 @@ if dxvk_compiler.get_id() == 'msvc'\n   add_project_arguments('/std:' + dxvk_cpp_std, language : 'cpp')\n endif\n \n-dxvk_include_path = include_directories('./include')\n-\n if (cpu_family == 'x86_64')\n   dxvk_library_path = meson.source_root() + '/lib'\n else\n   dxvk_library_path = meson.source_root() + '/lib32'\n endif\n \n-code = '''#ifndef __WINE__\n+winelib_check_code = '''#ifndef __WINE__\n #error 1\n #endif'''\n \n-dxvk_winelib = dxvk_compiler.compiles(code, name: 'winelib check')\n+mingw_check_code = '''#ifndef __MINGW32__\n+#error 1\n+#endif'''\n+\n+dxvk_winelib = dxvk_compiler.compiles(winelib_check_code, name: 'winelib check')\n+dxvk_mingw   = dxvk_compiler.compiles(mingw_check_code, name: 'mingw check')\n+\n+dxvk_native = not dxvk_mingw and not dxvk_winelib and dxvk_compiler.get_id() != 'msvc'\n+\n+dxvk_include_path = include_directories(['./include', dxvk_native ? './include/native' : ''])\n+\n dxvk_extradep = [ ]\n \n if dxvk_winelib\n@@ -42,6 +50,25 @@ if dxvk_winelib\n   exe_ext = '.exe.so'\n   dll_ext = '.dll'\n   def_spec_ext = '.spec'\n+elif dxvk_native\n+  lib_vulkan = dxvk_compiler.find_library('vulkan', dirs : dxvk_library_path)\n+  lib_dxgi   = dependency('', required : false)\n+  lib_d3dcompiler_43 = dependency('', required : false)\n+  lib_d3dcompiler_47 = dependency('', required : false)\n+  dxvk_extradep += [ declare_dependency(link_args: [ '-ldl' ]) ]\n+  dxvk_extradep += [ declare_dependency(link_args: [ '-pthread' ]) ]\n+\n+  idl_compiler = find_program('widl')\n+\n+  com_header_generator = generator(idl_compiler,\n+    output    : [ '@BASENAME@.h' ],\n+    arguments : [ '-h', '-o', '@OUTPUT@', '@INPUT@' ])\n+\n+  exe_ext = ''\n+  dll_ext = ''\n+  def_spec_ext = '.def'\n+  \n+  add_project_arguments(['-DDXVK_NATIVE=1'], language : 'cpp')\n else\n   lib_vulkan  = dxvk_compiler.find_library('vulkan-1', dirs : dxvk_library_path)\n   lib_d3d11   = dxvk_compiler.find_library('d3d11')\n@@ -68,6 +95,8 @@ dxvk_version = vcs_tag(\n   input:  'version.h.in',\n   output: 'version.h')\n \n+subdir('include')\n+\n subdir('src')\n \n enable_tests = get_option('enable_tests')\n@@ -75,3 +104,11 @@ enable_tests = get_option('enable_tests')\n if enable_tests\n   subdir('tests')\n endif\n+\n+if dxvk_native\n+  pkg = import('pkgconfig')\n+  pkg.generate(\n+    d3d11_dll,\n+    description : 'D3D10-11 Layer On Vulkan',\n+    subdirs : 'dxvk')\n+endif\ndiff --git a/src/d3d10/d3d10_main.cpp b/src/d3d10/d3d10_main.cpp\nindex 6bab89a2a8a..ee3fd951c12 100644\n--- a/src/d3d10/d3d10_main.cpp\n+++ b/src/d3d10/d3d10_main.cpp\n@@ -1,13 +1,20 @@\n+#ifndef DXVK_NATIVE\n #include <d3dcompiler.h>\n+#include \"d3d10_reflection.h\"\n+#endif\n+\n \n #include \"d3d10_include.h\"\n-#include \"d3d10_reflection.h\"\n \n #include \"../dxgi/dxgi_adapter.h\"\n \n+#include \"../vulkan/vulkan_presenter.h\"\n+\n+#ifndef DXVK_NATIVE\n namespace dxvk {\n   Logger Logger::s_instance(\"d3d10.log\");\n }\n+#endif\n \n extern \"C\" {\n   using namespace dxvk;\n@@ -54,6 +61,7 @@ extern \"C\" {\n     return S_OK;\n   }\n \n+#ifndef DXVK_NATIVE\n \n   DLLEXPORT HRESULT __stdcall D3D10CreateDevice1(\n           IDXGIAdapter*           pAdapter,\n@@ -377,6 +385,8 @@ extern \"C\" {\n       ppErrorMsgs);\n   }\n \n+#endif\n+\n }\n \n \ndiff --git a/src/d3d10/d3d10_multithread.cpp b/src/d3d10/d3d10_multithread.cpp\nindex bc93e92e77e..66033643512 100644\n--- a/src/d3d10/d3d10_multithread.cpp\n+++ b/src/d3d10/d3d10_multithread.cpp\n@@ -1,5 +1,7 @@\n #include \"d3d10_device.h\"\n \n+#include \"../util/thread.h\"\n+\n namespace dxvk {\n \n   void D3D10DeviceMutex::lock() {\n@@ -17,7 +19,7 @@ namespace dxvk {\n \n \n   bool D3D10DeviceMutex::try_lock() {\n-    uint32_t threadId = GetCurrentThreadId();\n+    uint32_t threadId = this_thread::get_id();\n     uint32_t expected = 0;\n \n     bool status = m_owner.compare_exchange_weak(\ndiff --git a/src/d3d10/meson.build b/src/d3d10/meson.build\nindex 899de196e39..a9b5da4040b 100644\n--- a/src/d3d10/meson.build\n+++ b/src/d3d10/meson.build\n@@ -1,35 +1,38 @@\n d3d10_main_src = [\n   'd3d10_main.cpp',\n-  'd3d10_reflection.cpp',\n ]\n \n+if not dxvk_native\n+  d3d10_main_src += 'd3d10_reflection.cpp'\n+endif\n+\n d3d10_deps = [ lib_d3dcompiler_43, lib_dxgi ]\n d3d10_deps += dxvk_winelib ? lib_d3d11 : d3d11_dep\n \n-d3d10_core_dll = shared_library('d3d10core'+dll_ext, d3d10_main_src,\n+d3d10_core_dll = shared_library('d3d10core'+dll_ext, d3d10_main_src, com_headers,\n   name_prefix         : '',\n   dependencies        : [ d3d10_deps, dxbc_dep, dxvk_dep ],\n   include_directories : dxvk_include_path,\n   install             : true,\n-  objects             : not dxvk_msvc ? 'd3d10core'+def_spec_ext : [],\n+  objects             : not dxvk_msvc and not dxvk_native ? 'd3d10core'+def_spec_ext : [],\n   vs_module_defs      : 'd3d10core'+def_spec_ext,\n   override_options    : ['cpp_std='+dxvk_cpp_std])\n \n-d3d10_dll = shared_library('d3d10'+dll_ext, d3d10_main_src,\n+d3d10_dll = shared_library('d3d10'+dll_ext, d3d10_main_src, com_headers,\n   name_prefix         : '',\n   dependencies        : [ d3d10_deps, dxbc_dep, dxvk_dep ],\n   include_directories : dxvk_include_path,\n   install             : true,\n-  objects             : not dxvk_msvc ? 'd3d10'+def_spec_ext : [],\n+  objects             : not dxvk_msvc and not dxvk_native ? 'd3d10'+def_spec_ext : [],\n   vs_module_defs      : 'd3d10'+def_spec_ext,\n   override_options    : ['cpp_std='+dxvk_cpp_std])\n \n-d3d10_1_dll = shared_library('d3d10_1'+dll_ext, d3d10_main_src,\n+d3d10_1_dll = shared_library('d3d10_1'+dll_ext, d3d10_main_src, com_headers,\n   name_prefix         : '',\n   dependencies        : [ d3d10_deps, dxbc_dep, dxvk_dep ],\n   include_directories : dxvk_include_path,\n   install             : true,\n-  objects             : not dxvk_msvc ? 'd3d10_1'+def_spec_ext : [],\n+  objects             : not dxvk_msvc and not dxvk_native ? 'd3d10_1'+def_spec_ext : [],\n   vs_module_defs      : 'd3d10_1'+def_spec_ext,\n   override_options    : ['cpp_std='+dxvk_cpp_std])\n \ndiff --git a/src/d3d11/d3d11_device.cpp b/src/d3d11/d3d11_device.cpp\nindex 1405cfab3a3..c283592e75d 100644\n--- a/src/d3d11/d3d11_device.cpp\n+++ b/src/d3d11/d3d11_device.cpp\n@@ -1734,10 +1734,6 @@ namespace dxvk {\n     // Make sure the back buffer size is not zero\n     DXGI_SWAP_CHAIN_DESC1 desc = *pDesc;\n     \n-    GetWindowClientSize(hWnd,\n-      desc.Width  ? nullptr : &desc.Width,\n-      desc.Height ? nullptr : &desc.Height);\n-    \n     // If necessary, set up a default set of\n     // fullscreen parameters for the swap chain\n     DXGI_SWAP_CHAIN_FULLSCREEN_DESC fsDesc;\n@@ -1985,13 +1981,21 @@ namespace dxvk {\n \n \n   Rc<DxvkDevice> D3D11DXGIDevice::CreateDevice(D3D_FEATURE_LEVEL FeatureLevel) {\n+    IWineDXGISwapChainHelper* helper;\n+    m_dxgiAdapter->QueryInterface(__uuidof(IWineDXGISwapChainHelper), (void**)&helper);\n+\n+    PFN_vkGetInstanceProcAddr getInstanceProcAddr;\n+    helper->GetVulkanFuncFinder(&getInstanceProcAddr);\n+\n+    helper->Release();\n+\n     DxvkDeviceFeatures deviceFeatures = D3D11Device::GetDeviceFeatures(m_dxvkAdapter, FeatureLevel);\n \n     uint32_t flHi = (uint32_t(FeatureLevel) >> 12);\n     uint32_t flLo = (uint32_t(FeatureLevel) >> 8) & 0x7;\n \n     std::string apiName = str::format(\"D3D11 FL \", flHi, \"_\", flLo);\n-    return m_dxvkAdapter->createDevice(apiName, deviceFeatures);\n+    return m_dxvkAdapter->createDevice(apiName, deviceFeatures, getInstanceProcAddr);\n   }\n \n-}\n+}\n\\ No newline at end of file\ndiff --git a/src/d3d11/d3d11_include.h b/src/d3d11/d3d11_include.h\nindex d2d869b7ec3..ab140312e67 100644\n--- a/src/d3d11/d3d11_include.h\n+++ b/src/d3d11/d3d11_include.h\n@@ -39,7 +39,7 @@ typedef enum D3D11_FORMAT_SUPPORT2 {\n   D3D11_FORMAT_SUPPORT2_SHAREABLE                                     = 0x400,\n   D3D11_FORMAT_SUPPORT2_MULTIPLANE_OVERLAY                            = 0x4000\n } D3D11_FORMAT_SUPPORT2;\n-#ifndef __WINE__\n+#if !defined(__WINE__) && !defined(DXVK_NATIVE)\n \n //MinGW-Headers supports these typedefs since 6.0.0\n #if !defined(__MINGW64_VERSION_MAJOR) || __MINGW64_VERSION_MAJOR < 6\ndiff --git a/src/d3d11/d3d11_main.cpp b/src/d3d11/d3d11_main.cpp\nindex 4ab16cacf20..27ea6d7b0d5 100644\n--- a/src/d3d11/d3d11_main.cpp\n+++ b/src/d3d11/d3d11_main.cpp\n@@ -8,8 +8,15 @@\n #include \"d3d11_enums.h\"\n #include \"d3d11_interop.h\"\n \n+#include \"../dxvk/dxvk_util.h\"\n+\n+\n namespace dxvk {\n+#ifndef DXVK_NATIVE\n   Logger Logger::s_instance(\"d3d11.log\");\n+#else\n+  Logger Logger::s_instance(\"dxvk.log\");\n+#endif\n }\n   \n extern \"C\" {\n@@ -38,7 +45,19 @@ extern \"C\" {\n       DXGI_ADAPTER_DESC desc;\n       pAdapter->GetDesc(&desc);\n \n-      dxvkInstance = new DxvkInstance();\n+      IWineDXGISwapChainHelper* helper;\n+      pAdapter->QueryInterface(__uuidof(IWineDXGISwapChainHelper), (void**)&helper);\n+\n+      PFN_vkGetInstanceProcAddr getInstanceProcAddr;\n+      if (FAILED(helper->GetVulkanFuncFinder(&getInstanceProcAddr))) {\n+        Logger::err(\"D3D11CoreCreateDevice: Failed to create D3D11 device\");\n+        helper->Release();\n+        return E_FAIL;\n+      }\n+      helper->Release();\n+\n+      dxvkInstance = new DxvkInstance(getInstanceProcAddr);\n+\n       dxvkAdapter  = dxvkInstance->findAdapterByLuid(&desc.AdapterLuid);\n \n       if (dxvkAdapter == nullptr)\n@@ -97,6 +116,7 @@ extern \"C\" {\n     }\n   }\n   \n+#ifndef DXVK_NATIVE\n   \n   DLLEXPORT HRESULT __stdcall D3D11CreateDevice(\n           IDXGIAdapter*         pAdapter,\n@@ -247,5 +267,7 @@ extern \"C\" {\n     \n     return S_OK;\n   }\n-  \n+\n+#endif\n+\n }\n\\ No newline at end of file\ndiff --git a/src/d3d11/d3d11_swapchain.cpp b/src/d3d11/d3d11_swapchain.cpp\nindex a0320d1e4b7..60ffc784cc3 100644\n--- a/src/d3d11/d3d11_swapchain.cpp\n+++ b/src/d3d11/d3d11_swapchain.cpp\n@@ -339,7 +339,16 @@ namespace dxvk {\n     presenterDesc.numFormats      = PickFormats(m_desc.Format, presenterDesc.formats);\n     presenterDesc.numPresentModes = PickPresentModes(false, presenterDesc.presentModes);\n \n-    m_presenter = new vk::Presenter(m_window,\n+    IWineDXGISwapChainHelper* helper;\n+    this->GetAdapter(__uuidof(IWineDXGISwapChainHelper), (void**)&helper);\n+\n+    VkSurfaceKHR surface;\n+    if (helper->CreateSurface(m_window, m_device->adapter()->vki()->instance(), &surface) != VK_SUCCESS)\n+      throw DxvkError(\"Failed to create surface\");\n+\n+    helper->Release();\n+\n+    m_presenter = new vk::Presenter(surface,\n       m_device->adapter()->vki(),\n       m_device->vkd(),\n       presenterDevice,\ndiff --git a/src/d3d11/meson.build b/src/d3d11/meson.build\nindex 15ae3d0eaef..5e273d33e89 100644\n--- a/src/d3d11/meson.build\n+++ b/src/d3d11/meson.build\n@@ -21,6 +21,10 @@ d3d10_src = [\n   '../d3d10/d3d10_view_srv.cpp',\n ]\n \n+if dxvk_native\n+  d3d10_src += '../d3d10/d3d10_main.cpp'\n+endif\n+\n d3d11_src = [\n   'd3d11_annotation.cpp',\n   'd3d11_blend.cpp',\n@@ -54,12 +58,18 @@ d3d11_src = [\n   'd3d11_view_uav.cpp',\n ]\n \n-d3d11_dll = shared_library('d3d11'+dll_ext, dxgi_common_src + d3d11_src + d3d10_src, glsl_generator.process(dxgi_shaders),\n+if dxvk_native\n+  name = 'libdxvk'\n+else\n+  name = 'd3d11'+dll_ext\n+endif\n+\n+d3d11_dll = shared_library(name, dxgi_common_src + d3d11_src + d3d10_src, glsl_generator.process(dxgi_shaders), com_headers,\n   name_prefix         : '',\n   dependencies        : [ lib_dxgi, dxbc_dep, dxvk_dep ],\n   include_directories : dxvk_include_path,\n   install             : true,\n-  objects             : not dxvk_msvc ? 'd3d11'+def_spec_ext : [],\n+  objects             : not dxvk_msvc and not dxvk_native ? 'd3d11'+def_spec_ext : [],\n   vs_module_defs      : 'd3d11'+def_spec_ext,\n   override_options    : ['cpp_std='+dxvk_cpp_std])\n \ndiff --git a/src/dxbc/meson.build b/src/dxbc/meson.build\nindex 3aa5c70b6e5..737224e43b3 100644\n--- a/src/dxbc/meson.build\n+++ b/src/dxbc/meson.build\n@@ -14,7 +14,7 @@ dxbc_src = files([\n   'dxbc_util.cpp',\n ])\n \n-dxbc_lib = static_library('dxbc', dxbc_src,\n+dxbc_lib = static_library('dxbc', dxbc_src, com_headers,\n   include_directories : [ dxvk_include_path ],\n   override_options    : ['cpp_std='+dxvk_cpp_std])\n \ndiff --git a/src/dxgi/dxgi_adapter.cpp b/src/dxgi/dxgi_adapter.cpp\nindex 5b90f65e0e9..a847acb9f52 100644\n--- a/src/dxgi/dxgi_adapter.cpp\n+++ b/src/dxgi/dxgi_adapter.cpp\n@@ -12,11 +12,223 @@\n \n namespace dxvk {\n \n+  WineDXGISwapChainHelper::WineDXGISwapChainHelper(\n+    DxgiAdapter* pAdapter)\n+  : m_adapter(pAdapter) {\n+\n+  }\n+\n+  ULONG STDMETHODCALLTYPE WineDXGISwapChainHelper::AddRef() {\n+    return m_adapter->AddRef();\n+  }\n+\n+  ULONG STDMETHODCALLTYPE WineDXGISwapChainHelper::Release() {\n+    return m_adapter->Release();\n+  }\n+\n+  HRESULT STDMETHODCALLTYPE WineDXGISwapChainHelper::QueryInterface(\n+          REFIID                  riid,\n+          void**                  ppvObject) {\n+    return m_adapter->QueryInterface(riid, ppvObject);\n+  }\n+\n+  HRESULT STDMETHODCALLTYPE WineDXGISwapChainHelper::GetMonitor(\n+          HWND                    hWnd, \n+          HMONITOR*               pMonitor) {\n+    if (!IsWindow(hWnd))\n+      return DXGI_ERROR_INVALID_CALL;\n+    \n+    RECT windowRect = { 0, 0, 0, 0 };\n+    ::GetWindowRect(hWnd, &windowRect);\n+    \n+    *pMonitor = ::MonitorFromPoint(\n+      { (windowRect.left + windowRect.right) / 2,\n+        (windowRect.top + windowRect.bottom) / 2 },\n+      MONITOR_DEFAULTTOPRIMARY);\n+\n+    return S_OK;\n+  }\n+\n+  HRESULT STDMETHODCALLTYPE WineDXGISwapChainHelper::GetWindowInfo(\n+          HWND                    hWnd,\n+          RECT*                   pRect,\n+          RECT*                   pClientRect,\n+          LONG*                   pStyle,\n+          LONG*                   pExstyle) {\n+    if (!IsWindow(hWnd))\n+      return DXGI_ERROR_INVALID_CALL;\n+\n+    if (pRect)\n+      ::GetWindowRect(hWnd, pRect);\n+\n+    if (pClientRect)\n+      ::GetClientRect(hWnd, pClientRect);\n+\n+    if (pStyle)\n+      *pStyle = ::GetWindowLongW(hWnd, GWL_STYLE);\n+\n+    if (pExstyle)\n+      *pExstyle = ::GetWindowLongW(hWnd, GWL_EXSTYLE);\n+\n+    return S_OK;\n+  }\n+\n+  HRESULT STDMETHODCALLTYPE WineDXGISwapChainHelper::SetWindowPos(\n+          HWND                    hWnd,\n+          HWND                    hWndInsertAfter,\n+          RECT                    Position,\n+          UINT                    Flags) {\n+    if (!IsWindow(hWnd))\n+      return DXGI_ERROR_INVALID_CALL;\n+\n+    ::SetWindowPos(hWnd, hWndInsertAfter, Position.left, Position.top, Position.right - Position.left, \n+      Position.bottom - Position.top, Flags);\n+\n+    return S_OK;\n+  }\n+\n+  HRESULT STDMETHODCALLTYPE WineDXGISwapChainHelper::ResizeWindow(\n+          HWND                    hWnd,\n+          UINT                    Width,\n+          UINT                    Height) {\n+    if (!IsWindow(hWnd))\n+      return DXGI_ERROR_INVALID_CALL;\n+\n+    RECT oldRect = {0, 0, 0, 0};\n+    RECT newRect = {0, 0, 0, 0};\n+\n+    ::GetWindowRect(hWnd, &oldRect);\n+    ::SetRect(&newRect, 0, 0, Width, Height);\n+    ::AdjustWindowRectEx(&newRect,\n+      ::GetWindowLongW(hWnd, GWL_STYLE), FALSE,\n+      ::GetWindowLongW(hWnd, GWL_EXSTYLE));\n+    ::SetRect(&newRect, 0, 0, newRect.right - newRect.left, newRect.bottom - newRect.top);\n+    ::OffsetRect(&newRect, oldRect.left, oldRect.top);\n+    ::MoveWindow(hWnd, newRect.left, newRect.top,\n+        newRect.right - newRect.left, newRect.bottom - newRect.top, TRUE);\n+\n+    return S_OK;\n+  }\n+\n+  HRESULT STDMETHODCALLTYPE WineDXGISwapChainHelper::SetWindowStyles(\n+          HWND                    hWnd,\n+    const LONG*                   pStyle,\n+    const LONG*                   pExstyle) {\n+    if (!IsWindow(hWnd))\n+      return DXGI_ERROR_INVALID_CALL;\n+\n+    if (pStyle)\n+      ::SetWindowLongW(hWnd, GWL_STYLE, *pStyle);\n+\n+    if (pExstyle)\n+      ::SetWindowLongW(hWnd, GWL_EXSTYLE, *pExstyle);\n+\n+    return S_OK;\n+  }\n+\n+  HRESULT STDMETHODCALLTYPE WineDXGISwapChainHelper::GetDisplayMode(\n+          HMONITOR                hMonitor,\n+          DWORD                   ModeNum,\n+          DXGI_MODE_DESC*         pMode) {\n+    ::MONITORINFOEXW monInfo;\n+    monInfo.cbSize = sizeof(monInfo);\n+\n+    if (!::GetMonitorInfoW(hMonitor, reinterpret_cast<MONITORINFO*>(&monInfo))) {\n+      Logger::err(\"DXGI: Failed to query monitor info\");\n+      return E_FAIL;\n+    }\n+    \n+    DEVMODEW devMode = { };\n+    devMode.dmSize = sizeof(devMode);\n+    \n+    if (!::EnumDisplaySettingsW(monInfo.szDevice, ModeNum, &devMode))\n+      return DXGI_ERROR_NOT_FOUND;\n+    \n+    pMode->Width            = devMode.dmPelsWidth;\n+    pMode->Height           = devMode.dmPelsHeight;\n+    pMode->RefreshRate      = { devMode.dmDisplayFrequency, 1 };\n+    pMode->Format           = DXGI_FORMAT_R8G8B8A8_UNORM_SRGB; // FIXME\n+    pMode->ScanlineOrdering = DXGI_MODE_SCANLINE_ORDER_PROGRESSIVE;\n+    pMode->Scaling          = DXGI_MODE_SCALING_UNSPECIFIED;\n+    return S_OK;\n+  }\n+\n+  HRESULT STDMETHODCALLTYPE WineDXGISwapChainHelper::SetDisplayMode(\n+          HMONITOR                hMonitor,\n+    const DXGI_MODE_DESC*         pMode) {\n+    ::MONITORINFOEXW monInfo;\n+    monInfo.cbSize = sizeof(monInfo);\n+\n+    if (!::GetMonitorInfoW(hMonitor, reinterpret_cast<MONITORINFO*>(&monInfo))) {\n+      Logger::err(\"DXGI: Failed to query monitor info\");\n+      return E_FAIL;\n+    }\n+    \n+    DEVMODEW devMode = { };\n+    devMode.dmSize       = sizeof(devMode);\n+    devMode.dmFields     = DM_PELSWIDTH | DM_PELSHEIGHT | DM_BITSPERPEL;\n+    devMode.dmPelsWidth  = pMode->Width;\n+    devMode.dmPelsHeight = pMode->Height;\n+    devMode.dmBitsPerPel = GetMonitorFormatBpp(pMode->Format);\n+    \n+    if (pMode->RefreshRate.Numerator != 0)  {\n+      devMode.dmFields |= DM_DISPLAYFREQUENCY;\n+      devMode.dmDisplayFrequency = pMode->RefreshRate.Numerator\n+                                 / pMode->RefreshRate.Denominator;\n+    }\n+    \n+    Logger::info(str::format(\"DXGI: Setting display mode: \",\n+      devMode.dmPelsWidth, \"x\", devMode.dmPelsHeight, \"@\",\n+      devMode.dmDisplayFrequency));\n+    \n+    LONG status = ::ChangeDisplaySettingsExW(\n+      monInfo.szDevice, &devMode, nullptr, CDS_FULLSCREEN, nullptr);\n+    \n+    return status == DISP_CHANGE_SUCCESSFUL ? S_OK : DXGI_ERROR_NOT_CURRENTLY_AVAILABLE;\n+  }\n+\n+#if defined(__WINE__)\n+\n+  extern \"C\"\n+  PFN_vkVoidFunction native_vkGetInstanceProcAddrWINE(VkInstance instance, const char *name);\n+  static const PFN_vkGetInstanceProcAddr GetInstanceProcAddr = native_vkGetInstanceProcAddrWINE;\n+\n+#else\n+\n+  static const PFN_vkGetInstanceProcAddr GetInstanceProcAddr = vkGetInstanceProcAddr;\n+\n+#endif\n+\n+  HRESULT STDMETHODCALLTYPE WineDXGISwapChainHelper::GetVulkanFuncFinder(\n+    pfn_vkGetInstanceProcAddr* pFuncFinder) {\n+    *pFuncFinder = GetInstanceProcAddr;\n+    \n+    return S_OK;\n+  }\n+\n+  VkResult STDMETHODCALLTYPE WineDXGISwapChainHelper::CreateSurface(\n+    HWND window,\n+    VkInstance instance,\n+    VkSurfaceKHR* pSurface) {\n+    HINSTANCE instance = reinterpret_cast<HINSTANCE>(\n+      GetWindowLongPtr(window, GWLP_HINSTANCE));\n+\n+    VkWin32SurfaceCreateInfoKHR info;\n+    info.sType      = VK_STRUCTURE_TYPE_WIN32_SURFACE_CREATE_INFO_KHR;\n+    info.pNext      = nullptr;\n+    info.flags      = 0;\n+    info.hinstance  = instance;\n+    info.hwnd = window;\n+\n+    return m_vki->vkCreateWin32SurfaceKHR(m_vki->instance(), &info, nullptr, pSurface);\n+  }\n+\n   DxgiAdapter::DxgiAdapter(\n           DxgiFactory*      factory,\n     const Rc<DxvkAdapter>&  adapter)\n-  : m_factory (factory),\n-    m_adapter (adapter) {\n+  : m_factory    (factory),\n+    m_wineHelper (this),\n+    m_adapter    (adapter) {\n     \n   }\n   \n@@ -42,6 +254,11 @@ namespace dxvk {\n       *ppvObject = ref(this);\n       return S_OK;\n     }\n+\n+    if (riid == __uuidof(IWineDXGISwapChainHelper)) {\n+      *ppvObject = ref(&m_wineHelper);\n+      return S_OK;\n+    }\n     \n     Logger::warn(\"DxgiAdapter::QueryInterface: Unknown interface query\");\n     Logger::warn(str::format(riid));\ndiff --git a/src/dxgi/dxgi_adapter.h b/src/dxgi/dxgi_adapter.h\nindex d450a1e5f95..56b8d2c23e5 100644\n--- a/src/dxgi/dxgi_adapter.h\n+++ b/src/dxgi/dxgi_adapter.h\n@@ -9,8 +9,73 @@\n \n namespace dxvk {\n   \n+  class DxgiAdapter;\n   class DxgiFactory;\n   class DxgiOutput;\n+\n+  class WineDXGISwapChainHelper : public IWineDXGISwapChainHelper {\n+\n+public:\n+\n+    WineDXGISwapChainHelper(\n+            DxgiAdapter* pAdapter);\n+\n+    ULONG STDMETHODCALLTYPE AddRef();\n+\n+    ULONG STDMETHODCALLTYPE Release();\n+\n+    HRESULT STDMETHODCALLTYPE QueryInterface(\n+            REFIID                  riid,\n+            void**                  ppvObject);\n+\n+    HRESULT STDMETHODCALLTYPE GetMonitor(\n+            HWND      hWnd,\n+            HMONITOR* pMonitor);\n+\n+    HRESULT STDMETHODCALLTYPE GetWindowInfo(\n+            HWND  hWnd,\n+            RECT* pRect,\n+            RECT* pClientRect,\n+            LONG* pStyle,\n+            LONG* pExStyle);\n+    \n+    HRESULT STDMETHODCALLTYPE SetWindowPos(\n+            HWND hWnd,\n+            HWND hWndInsertAfter,\n+            RECT Position,\n+            UINT Flags);\n+    \n+    HRESULT STDMETHODCALLTYPE ResizeWindow(\n+            HWND hWnd,\n+            UINT Width,\n+            UINT Height);\n+\n+    HRESULT STDMETHODCALLTYPE SetWindowStyles(\n+            HWND  hWnd,\n+      const LONG* pStyle,\n+      const LONG* pExstyle);\n+\n+    HRESULT STDMETHODCALLTYPE GetDisplayMode(\n+            HMONITOR        hMonitor,\n+            DWORD           ModeNum,\n+            DXGI_MODE_DESC* pMode);\n+\n+    HRESULT STDMETHODCALLTYPE SetDisplayMode(\n+            HMONITOR        hMonitor,\n+      const DXGI_MODE_DESC* pMode);\n+\n+    HRESULT STDMETHODCALLTYPE GetVulkanFuncFinder(\n+            PFN_vkGetInstanceProcAddr* pFuncFinder);\n+\n+    VkResult STDMETHODCALLTYPE CreateSurface(\n+            HWND window,\n+            VkInstance instance,\n+            VkSurfaceKHR* pSurface);\n+\n+private:\n+\n+    DxgiAdapter* m_adapter;\n+  };\n   \n   class DxgiAdapter : public DxgiObject<IDXGIVkAdapter> {\n     \n@@ -74,8 +139,9 @@ namespace dxvk {\n     \n   private:\n     \n-    Com<DxgiFactory>  m_factory;\n-    Rc<DxvkAdapter>   m_adapter;\n+    Com<DxgiFactory>        m_factory;\n+    WineDXGISwapChainHelper m_wineHelper;\n+    Rc<DxvkAdapter>         m_adapter;\n     \n     UINT64            m_memReservation[2] = { 0, 0 };\n     \ndiff --git a/src/dxgi/dxgi_include.h b/src/dxgi/dxgi_include.h\nindex 92112617e00..45a63f2d899 100644\n--- a/src/dxgi/dxgi_include.h\n+++ b/src/dxgi/dxgi_include.h\n@@ -1,7 +1,7 @@\n #pragma once\n \n //for some reason we need to specify __declspec(dllexport) for MinGW\n-#if defined(_MSC_VER) || defined(__WINE__)\n+#if defined(_MSC_VER) || defined(__WINE__) || defined(DXVK_NATIVE)\n   #define DLLEXPORT\n #else\n   #define DLLEXPORT __declspec(dllexport)\ndiff --git a/src/dxgi/dxgi_interfaces.h b/src/dxgi/dxgi_interfaces.h\nindex eacc6970292..49663a5342b 100644\n--- a/src/dxgi/dxgi_interfaces.h\n+++ b/src/dxgi/dxgi_interfaces.h\n@@ -238,6 +238,61 @@ IWineDXGISwapChainFactory : public IUnknown {\n             IDXGISwapChain1**       ppSwapChain) = 0;\n };\n \n+/**\n+ * \\brief IWineDXGISwapChainHelper adapter interface\n+ * \n+ * Allows our swap chain implementation to rely on the\n+ * adapter for win32 function calls\n+ */\n+MIDL_INTERFACE(\"d922ca90-6152-41f9-8b44-47adaac22b40\")\n+IWineDXGISwapChainHelper : public IUnknown {\n+    static const GUID guid;\n+\n+    virtual HRESULT STDMETHODCALLTYPE GetMonitor(\n+            HWND      hWnd,\n+            HMONITOR* pMonitor) = 0;\n+\n+    virtual HRESULT STDMETHODCALLTYPE GetWindowInfo(\n+            HWND  hWnd,\n+            RECT* pRect,\n+            RECT* pClientRect,\n+            LONG* pStyle,\n+            LONG* pExStyle) = 0;\n+\n+    virtual HRESULT STDMETHODCALLTYPE SetWindowPos(\n+            HWND hWnd,\n+            HWND hWndInsertAfter,\n+            RECT Position,\n+            UINT Flags) = 0;\n+\n+    virtual HRESULT STDMETHODCALLTYPE ResizeWindow(\n+            HWND hWnd,\n+            UINT Width,\n+            UINT Height) = 0;\n+\n+    virtual HRESULT STDMETHODCALLTYPE SetWindowStyles(\n+            HWND  hWnd,\n+      const LONG* pStyle,\n+      const LONG* pExstyle) = 0;\n+\n+    virtual HRESULT STDMETHODCALLTYPE GetDisplayMode(\n+            HMONITOR        hMonitor,\n+            DWORD           ModeNum,\n+            DXGI_MODE_DESC* pMode) = 0;\n+\n+    virtual HRESULT STDMETHODCALLTYPE SetDisplayMode(\n+            HMONITOR        hMonitor,\n+      const DXGI_MODE_DESC* pMode) = 0;\n+\n+    virtual HRESULT STDMETHODCALLTYPE GetVulkanFuncFinder(\n+            PFN_vkGetInstanceProcAddr* pFuncFinder) = 0;\n+\n+    virtual VkResult STDMETHODCALLTYPE CreateSurface(\n+            HWND hWnd,\n+            VkInstance instance,\n+            VkSurfaceKHR* pSurface) = 0;\n+};\n+\n \n #ifdef _MSC_VER\n struct __declspec(uuid(\"907bf281-ea3c-43b4-a8e4-9f231107b4ff\")) IDXGIVkAdapter;\n@@ -245,10 +300,12 @@ struct __declspec(uuid(\"e2ef5fa5-dc21-4af7-90c4-f67ef6a09323\")) IDXGIVkInteropDe\n struct __declspec(uuid(\"5546cf8c-77e7-4341-b05d-8d4d5000e77d\")) IDXGIVkInteropSurface;\n struct __declspec(uuid(\"104001a6-7f36-4957-b932-86ade9567d91\")) IDXGIVkSwapChain;\n struct __declspec(uuid(\"53cb4ff0-c25a-4164-a891-0e83db0a7aac\")) IWineDXGISwapChainFactory;\n+struct __declspec(uuid(\"d922ca90-6152-41f9-8b44-47adaac22b40\")) IWineDXGISwapChainHelper;\n #else\n DXVK_DEFINE_GUID(IDXGIVkAdapter);\n DXVK_DEFINE_GUID(IDXGIVkInteropDevice);\n DXVK_DEFINE_GUID(IDXGIVkInteropSurface);\n DXVK_DEFINE_GUID(IDXGIVkSwapChain);\n DXVK_DEFINE_GUID(IWineDXGISwapChainFactory);\n+DXVK_DEFINE_GUID(IWineDXGISwapChainHelper);\n #endif\n\\ No newline at end of file\ndiff --git a/src/dxgi/dxgi_monitor.cpp b/src/dxgi/dxgi_monitor.cpp\nindex 9227b1a7599..3d28ac987bc 100644\n--- a/src/dxgi/dxgi_monitor.cpp\n+++ b/src/dxgi/dxgi_monitor.cpp\n@@ -66,81 +66,4 @@ namespace dxvk {\n   }\n   \n \n-  HRESULT GetMonitorDisplayMode(\n-          HMONITOR                hMonitor,\n-          DWORD                   ModeNum,\n-          DXGI_MODE_DESC*         pMode) {\n-    ::MONITORINFOEXW monInfo;\n-    monInfo.cbSize = sizeof(monInfo);\n-\n-    if (!::GetMonitorInfoW(hMonitor, reinterpret_cast<MONITORINFO*>(&monInfo))) {\n-      Logger::err(\"DXGI: Failed to query monitor info\");\n-      return E_FAIL;\n-    }\n-    \n-    DEVMODEW devMode = { };\n-    devMode.dmSize = sizeof(devMode);\n-    \n-    if (!::EnumDisplaySettingsW(monInfo.szDevice, ModeNum, &devMode))\n-      return DXGI_ERROR_NOT_FOUND;\n-    \n-    pMode->Width            = devMode.dmPelsWidth;\n-    pMode->Height           = devMode.dmPelsHeight;\n-    pMode->RefreshRate      = { devMode.dmDisplayFrequency, 1 };\n-    pMode->Format           = DXGI_FORMAT_R8G8B8A8_UNORM_SRGB; // FIXME\n-    pMode->ScanlineOrdering = DXGI_MODE_SCANLINE_ORDER_PROGRESSIVE;\n-    pMode->Scaling          = DXGI_MODE_SCALING_UNSPECIFIED;\n-    return S_OK;\n-  }\n-  \n-    \n-  HRESULT SetMonitorDisplayMode(\n-          HMONITOR                hMonitor,\n-    const DXGI_MODE_DESC*         pMode) {\n-    ::MONITORINFOEXW monInfo;\n-    monInfo.cbSize = sizeof(monInfo);\n-\n-    if (!::GetMonitorInfoW(hMonitor, reinterpret_cast<MONITORINFO*>(&monInfo))) {\n-      Logger::err(\"DXGI: Failed to query monitor info\");\n-      return E_FAIL;\n-    }\n-    \n-    DEVMODEW devMode = { };\n-    devMode.dmSize       = sizeof(devMode);\n-    devMode.dmFields     = DM_PELSWIDTH | DM_PELSHEIGHT | DM_BITSPERPEL;\n-    devMode.dmPelsWidth  = pMode->Width;\n-    devMode.dmPelsHeight = pMode->Height;\n-    devMode.dmBitsPerPel = GetMonitorFormatBpp(pMode->Format);\n-    \n-    if (pMode->RefreshRate.Numerator != 0)  {\n-      devMode.dmFields |= DM_DISPLAYFREQUENCY;\n-      devMode.dmDisplayFrequency = pMode->RefreshRate.Numerator\n-                                 / pMode->RefreshRate.Denominator;\n-    }\n-    \n-    Logger::info(str::format(\"DXGI: Setting display mode: \",\n-      devMode.dmPelsWidth, \"x\", devMode.dmPelsHeight, \"@\",\n-      devMode.dmDisplayFrequency));\n-    \n-    LONG status = ::ChangeDisplaySettingsExW(\n-      monInfo.szDevice, &devMode, nullptr, CDS_FULLSCREEN, nullptr);\n-    \n-    return status == DISP_CHANGE_SUCCESSFUL ? S_OK : DXGI_ERROR_NOT_CURRENTLY_AVAILABLE;;\n-  }\n-  \n-  \n-  void GetWindowClientSize(\n-          HWND                    hWnd,\n-          UINT*                   pWidth,\n-          UINT*                   pHeight) {\n-    RECT rect = { };\n-    ::GetClientRect(hWnd, &rect);\n-    \n-    if (pWidth)\n-      *pWidth = rect.right - rect.left;\n-    \n-    if (pHeight)\n-      *pHeight = rect.bottom - rect.top;\n-  }\n-\n }\n\\ No newline at end of file\ndiff --git a/src/dxgi/dxgi_monitor.h b/src/dxgi/dxgi_monitor.h\nindex 9e03155a993..80733468a1c 100644\n--- a/src/dxgi/dxgi_monitor.h\n+++ b/src/dxgi/dxgi_monitor.h\n@@ -61,41 +61,4 @@ namespace dxvk {\n    */\n   void ReleaseMonitorData();\n \n-\n-  /**\n-   * \\brief Retrieves monitor display mode\n-   *\n-   * \\param [in] hMonitor Monitor handle\n-   * \\param [in] ModeNum Mode number\n-   * \\param [out] Display mode properties\n-   * \\returns S_OK on success\n-   */\n-  HRESULT GetMonitorDisplayMode(\n-          HMONITOR                hMonitor,\n-          DWORD                   ModeNum,\n-          DXGI_MODE_DESC*         pMode);\n-\n-  /**\n-   * \\brief Sets monitor display mode\n-   * \n-   * \\param [in] hMonitor Monitor handle\n-   * \\param [in] pMode Display mode properties\n-   * \\returns S_OK on success\n-   */\n-  HRESULT SetMonitorDisplayMode(\n-          HMONITOR                hMonitor,\n-    const DXGI_MODE_DESC*         pMode);\n-  \n-  /**\n-   * \\brief Queries window client size\n-   * \n-   * \\param [in] hWnd Window to query\n-   * \\param [out] pWidth Client width\n-   * \\param [out] pHeight Client height\n-   */\n-  void GetWindowClientSize(\n-          HWND                    hWnd,\n-          UINT*                   pWidth,\n-          UINT*                   pHeight);\n-\n }\n\\ No newline at end of file\ndiff --git a/src/dxgi/dxgi_output.cpp b/src/dxgi/dxgi_output.cpp\nindex 3bcf4bd08cf..c930df2cc52 100644\n--- a/src/dxgi/dxgi_output.cpp\n+++ b/src/dxgi/dxgi_output.cpp\n@@ -32,6 +32,10 @@ namespace dxvk {\n     }\n     \n     InitMonitorData(monitor, &monitorData);    \n+\n+    // Setup a swapchain helper since dxgi_monitor lost some functions\n+    if (FAILED(m_adapter->QueryInterface(__uuidof(IWineDXGISwapChainHelper), reinterpret_cast<void**>(&m_helper))))\n+      throw DxvkError(\"DXGI: Failed to get helper from adapter\");\n   }\n   \n   \n@@ -170,7 +174,7 @@ namespace dxvk {\n \n     if (targetWidth == 0 || targetHeight == 0) {\n       DXGI_MODE_DESC activeMode = { };\n-      GetMonitorDisplayMode(m_monitor,\n+      m_helper->GetDisplayMode(m_monitor,\n         ENUM_CURRENT_SETTINGS, &activeMode);\n \n       targetWidth  = activeMode.Width;\ndiff --git a/src/dxgi/dxgi_output.h b/src/dxgi/dxgi_output.h\nindex 37228214163..8b3086453f0 100644\n--- a/src/dxgi/dxgi_output.h\n+++ b/src/dxgi/dxgi_output.h\n@@ -126,8 +126,9 @@ namespace dxvk {\n     \n   private:\n     \n-    Com<DxgiAdapter> m_adapter = nullptr;\n-    HMONITOR         m_monitor = nullptr;\n+    Com<DxgiAdapter>              m_adapter = nullptr;\n+    Com<IWineDXGISwapChainHelper> m_helper = nullptr;\n+    HMONITOR                      m_monitor = nullptr;\n     \n   };\n \ndiff --git a/src/dxgi/dxgi_swapchain.cpp b/src/dxgi/dxgi_swapchain.cpp\nindex e47a55727a7..cdcdb9a291c 100644\n--- a/src/dxgi/dxgi_swapchain.cpp\n+++ b/src/dxgi/dxgi_swapchain.cpp\n@@ -25,7 +25,14 @@ namespace dxvk {\n     \n     if (FAILED(m_presenter->GetAdapter(__uuidof(IDXGIAdapter), reinterpret_cast<void**>(&m_adapter))))\n       throw DxvkError(\"DXGI: Failed to get adapter for present device\");\n+\n+    if (FAILED(m_adapter->QueryInterface(__uuidof(IWineDXGISwapChainHelper), reinterpret_cast<void**>(&m_helper))))\n+      throw DxvkError(\"DXGI: Failed to get helper from adapter\");\n     \n+    GetWindowClientSize(hWnd,\n+      m_desc.Width  ? nullptr : &m_desc.Width,\n+      m_desc.Height ? nullptr : &m_desc.Height);\n+\n     // Apply initial window mode and fullscreen state\n     if (!m_descFs.Windowed && FAILED(EnterFullscreenMode(nullptr)))\n       throw DxvkError(\"DXGI: Failed to set initial fullscreen state\");\n@@ -93,17 +100,10 @@ namespace dxvk {\n   HRESULT STDMETHODCALLTYPE DxgiSwapChain::GetContainingOutput(IDXGIOutput** ppOutput) {\n     InitReturnPtr(ppOutput);\n     \n-    if (!IsWindow(m_window))\n+    HMONITOR monitor;\n+    if( FAILED(m_helper->GetMonitor(m_window, &monitor)))\n       return DXGI_ERROR_INVALID_CALL;\n-    \n-    RECT windowRect = { 0, 0, 0, 0 };\n-    ::GetWindowRect(m_window, &windowRect);\n-    \n-    HMONITOR monitor = ::MonitorFromPoint(\n-      { (windowRect.left + windowRect.right) / 2,\n-        (windowRect.top + windowRect.bottom) / 2 },\n-      MONITOR_DEFAULTTOPRIMARY);\n-    \n+\n     return GetOutputFromMonitor(monitor, ppOutput);\n   }\n   \n@@ -173,7 +173,7 @@ namespace dxvk {\n   HRESULT STDMETHODCALLTYPE DxgiSwapChain::GetFullscreenState(\n           BOOL*         pFullscreen,\n           IDXGIOutput** ppTarget) {\n-    if (!IsWindow(m_window))\n+    if (FAILED(m_helper->GetWindowInfo(m_window, nullptr, nullptr, nullptr, nullptr)))\n       return DXGI_ERROR_INVALID_CALL;\n     \n     HRESULT hr = S_OK;\n@@ -247,7 +247,7 @@ namespace dxvk {\n           UINT                      SyncInterval,\n           UINT                      PresentFlags,\n     const DXGI_PRESENT_PARAMETERS*  pPresentParameters) {\n-    if (!IsWindow(m_window))\n+    if (FAILED(m_helper->GetWindowInfo(m_window, nullptr, nullptr, nullptr, nullptr)))\n       return DXGI_ERROR_INVALID_CALL;\n     \n     if (PresentFlags & DXGI_PRESENT_TEST)\n@@ -277,7 +277,7 @@ namespace dxvk {\n           UINT        Height,\n           DXGI_FORMAT NewFormat,\n           UINT        SwapChainFlags) {\n-    if (!IsWindow(m_window))\n+    if (FAILED(m_helper->GetWindowInfo(m_window, nullptr, nullptr, nullptr, nullptr)))\n       return DXGI_ERROR_INVALID_CALL;\n     \n     std::lock_guard<std::mutex> lock(m_lockBuffer);\n@@ -322,7 +322,7 @@ namespace dxvk {\n     if (pNewTargetParameters == nullptr)\n       return DXGI_ERROR_INVALID_CALL;\n     \n-    if (!IsWindow(m_window))\n+    if (FAILED(m_helper->GetWindowInfo(m_window, nullptr, nullptr, nullptr, nullptr)))\n       return DXGI_ERROR_INVALID_CALL;\n \n     // Update the swap chain description\n@@ -333,19 +333,8 @@ namespace dxvk {\n     m_descFs.Scaling          = pNewTargetParameters->Scaling;\n     \n     if (m_descFs.Windowed) {\n-      // Adjust window position and size\n-      RECT newRect = { 0, 0, 0, 0 };\n-      RECT oldRect = { 0, 0, 0, 0 };\n-      \n-      ::GetWindowRect(m_window, &oldRect);\n-      ::SetRect(&newRect, 0, 0, pNewTargetParameters->Width, pNewTargetParameters->Height);\n-      ::AdjustWindowRectEx(&newRect,\n-        ::GetWindowLongW(m_window, GWL_STYLE), FALSE,\n-        ::GetWindowLongW(m_window, GWL_EXSTYLE));\n-      ::SetRect(&newRect, 0, 0, newRect.right - newRect.left, newRect.bottom - newRect.top);\n-      ::OffsetRect(&newRect, oldRect.left, oldRect.top);    \n-      ::MoveWindow(m_window, newRect.left, newRect.top,\n-          newRect.right - newRect.left, newRect.bottom - newRect.top, TRUE);\n+      m_helper->ResizeWindow(\n+        m_window, pNewTargetParameters->Width, pNewTargetParameters->Height);\n     } else {\n       Com<IDXGIOutput> output;\n       \n@@ -364,8 +353,7 @@ namespace dxvk {\n       \n       RECT newRect = desc.DesktopCoordinates;\n       \n-      ::MoveWindow(m_window, newRect.left, newRect.top,\n-          newRect.right - newRect.left, newRect.bottom - newRect.top, TRUE);\n+      m_helper->SetWindowPos(m_window, 0, newRect, SWP_NOZORDER | SWP_NOACTIVATE);\n     }\n     \n     return S_OK;\n@@ -489,7 +477,7 @@ namespace dxvk {\n   HRESULT DxgiSwapChain::EnterFullscreenMode(IDXGIOutput* pTarget) {\n     Com<IDXGIOutput> output = static_cast<DxgiOutput*>(pTarget);\n \n-    if (!IsWindow(m_window))\n+    if (FAILED(m_helper->GetWindowInfo(m_window, nullptr, nullptr, nullptr, nullptr)))\n       return DXGI_ERROR_NOT_CURRENTLY_AVAILABLE;\n     \n     if (output == nullptr) {\n@@ -500,7 +488,7 @@ namespace dxvk {\n     }\n     \n     // Find a display mode that matches what we need\n-    ::GetWindowRect(m_window, &m_windowState.rect);\n+    m_helper->GetWindowInfo(m_window, &m_windowState.rect, nullptr, nullptr, nullptr);\n     \n     if (m_desc.Flags & DXGI_SWAP_CHAIN_FLAG_ALLOW_MODE_SWITCH) {\n       DXGI_MODE_DESC displayMode;\n@@ -523,17 +511,16 @@ namespace dxvk {\n     m_descFs.Windowed = FALSE;\n     \n     // Change the window flags to remove the decoration etc.\n-    LONG style   = ::GetWindowLongW(m_window, GWL_STYLE);\n-    LONG exstyle = ::GetWindowLongW(m_window, GWL_EXSTYLE);\n-    \n+    LONG style, exstyle;\n+    m_helper->GetWindowInfo(m_window, nullptr, nullptr, &style, &exstyle);\n+\n     m_windowState.style = style;\n     m_windowState.exstyle = exstyle;\n     \n     style   &= ~WS_OVERLAPPEDWINDOW;\n     exstyle &= ~WS_EX_OVERLAPPEDWINDOW;\n     \n-    ::SetWindowLongW(m_window, GWL_STYLE, style);\n-    ::SetWindowLongW(m_window, GWL_EXSTYLE, exstyle);\n+    m_helper->SetWindowStyles(m_window, &style, &exstyle);\n     \n     // Move the window so that it covers the entire output\n     DXGI_OUTPUT_DESC desc;\n@@ -541,9 +528,7 @@ namespace dxvk {\n     \n     const RECT rect = desc.DesktopCoordinates;\n     \n-    ::SetWindowPos(m_window, HWND_TOPMOST,\n-      rect.left, rect.top, rect.right - rect.left, rect.bottom - rect.top,\n-      SWP_FRAMECHANGED | SWP_SHOWWINDOW | SWP_NOACTIVATE);\n+    m_helper->SetWindowPos(m_window, HWND_TOPMOST, rect, SWP_FRAMECHANGED | SWP_SHOWWINDOW | SWP_NOACTIVATE);\n     \n     m_monitor = desc.Monitor;\n \n@@ -563,7 +548,7 @@ namespace dxvk {\n   \n   \n   HRESULT DxgiSwapChain::LeaveFullscreenMode() {\n-    if (!IsWindow(m_window))\n+    if (FAILED(m_helper->GetWindowInfo(m_window, nullptr, nullptr, nullptr, nullptr)))\n       return DXGI_ERROR_NOT_CURRENTLY_AVAILABLE;\n     \n     if (FAILED(RestoreDisplayMode(m_monitor)))\n@@ -586,21 +571,20 @@ namespace dxvk {\n     \n     // Only restore the window style if the application hasn't\n     // changed them. This is in line with what native DXGI does.\n-    LONG curStyle   = ::GetWindowLongW(m_window, GWL_STYLE) & ~WS_VISIBLE;\n-    LONG curExstyle = ::GetWindowLongW(m_window, GWL_EXSTYLE) & ~WS_EX_TOPMOST;\n+    LONG curStyle, curExstyle;\n+    m_helper->GetWindowInfo(m_window, nullptr, nullptr, &curStyle, &curExstyle);\n+    curStyle &= ~WS_VISIBLE;\n+    curExstyle &= ~WS_EX_TOPMOST;\n     \n     if (curStyle == (m_windowState.style & ~(WS_VISIBLE | WS_OVERLAPPEDWINDOW))\n      && curExstyle == (m_windowState.exstyle & ~(WS_EX_TOPMOST | WS_EX_OVERLAPPEDWINDOW))) {\n-      ::SetWindowLongW(m_window, GWL_STYLE,   m_windowState.style);\n-      ::SetWindowLongW(m_window, GWL_EXSTYLE, m_windowState.exstyle);\n+      m_helper->SetWindowStyles(m_window, &curStyle, &curExstyle);\n     }\n     \n     // Restore window position and apply the style\n     const RECT rect = m_windowState.rect;\n-    \n-    ::SetWindowPos(m_window, 0,\n-      rect.left, rect.top, rect.right - rect.left, rect.bottom - rect.top,\n-      SWP_FRAMECHANGED | SWP_NOZORDER | SWP_NOACTIVATE);\n+\n+    m_helper->SetWindowPos(m_window, 0, rect, SWP_FRAMECHANGED | SWP_NOZORDER | SWP_NOACTIVATE);\n     \n     return S_OK;\n   }\n@@ -634,7 +618,7 @@ namespace dxvk {\n       return hr;\n     }\n     \n-    return SetMonitorDisplayMode(outputDesc.Monitor, &selectedMode);\n+    return m_helper->SetDisplayMode(outputDesc.Monitor, &selectedMode);\n   }\n   \n   \n@@ -645,13 +629,13 @@ namespace dxvk {\n     // Restore registry settings\n     DXGI_MODE_DESC mode;\n     \n-    HRESULT hr = GetMonitorDisplayMode(\n+    HRESULT hr = m_helper->GetDisplayMode(\n       hMonitor, ENUM_REGISTRY_SETTINGS, &mode);\n     \n     if (FAILED(hr))\n       return hr;\n     \n-    return SetMonitorDisplayMode(hMonitor, &mode);\n+    return m_helper->SetDisplayMode(hMonitor, &mode);\n   }\n   \n   \n@@ -687,5 +671,20 @@ namespace dxvk {\n     \n     return DXGI_ERROR_NOT_FOUND;\n   }\n+\n+\n+  void DxgiSwapChain::GetWindowClientSize(\n+          HWND                    hWnd,\n+          UINT*                   pWidth,\n+          UINT*                   pHeight) {\n+    RECT rect = { };\n+    m_helper->GetWindowInfo(hWnd, nullptr, &rect, nullptr, nullptr);\n+    \n+    if (pWidth)\n+      *pWidth = rect.right - rect.left;\n+    \n+    if (pHeight)\n+      *pHeight = rect.bottom - rect.top;\n+  }\n   \n }\ndiff --git a/src/dxgi/dxgi_swapchain.h b/src/dxgi/dxgi_swapchain.h\nindex 05848edf915..0270d7b489b 100644\n--- a/src/dxgi/dxgi_swapchain.h\n+++ b/src/dxgi/dxgi_swapchain.h\n@@ -172,6 +172,7 @@ namespace dxvk {\n \n     Com<IDXGIFactory>               m_factory;\n     Com<IDXGIAdapter>               m_adapter;\n+    Com<IWineDXGISwapChainHelper>   m_helper;\n     \n     HWND                            m_window;\n     DXGI_SWAP_CHAIN_DESC1           m_desc;\n@@ -202,6 +203,11 @@ namespace dxvk {\n     HRESULT GetOutputFromMonitor(\n             HMONITOR                Monitor,\n             IDXGIOutput**           ppOutput);\n+\n+    void GetWindowClientSize(\n+            HWND                    hWnd,\n+            UINT*                   pWidth,\n+            UINT*                   pHeight);\n     \n   };\n   \ndiff --git a/src/dxgi/meson.build b/src/dxgi/meson.build\nindex 18d74816731..3d54c027b78 100644\n--- a/src/dxgi/meson.build\n+++ b/src/dxgi/meson.build\n@@ -15,15 +15,17 @@ dxgi_src = [\n   'dxgi_swapchain.cpp',\n ]\n \n-dxgi_dll = shared_library('dxgi'+dll_ext, dxgi_src,\n-  name_prefix         : '',\n-  dependencies        : [ dxvk_dep ],\n-  include_directories : dxvk_include_path,\n-  install             : true,\n-  vs_module_defs      : 'dxgi'+def_spec_ext,\n-  objects             : not dxvk_msvc ? 'dxgi'+def_spec_ext : [],\n-  override_options    : ['cpp_std='+dxvk_cpp_std])\n+if not dxvk_native\n+  dxgi_dll = shared_library('dxgi'+dll_ext, dxgi_src,\n+    name_prefix         : '',\n+    dependencies        : [ dxvk_dep ],\n+    include_directories : dxvk_include_path,\n+    install             : true,\n+    vs_module_defs      : 'dxgi'+def_spec_ext,\n+    objects             : not dxvk_msvc ? 'dxgi'+def_spec_ext : [],\n+    override_options    : ['cpp_std='+dxvk_cpp_std])\n \n-dxgi_dep = declare_dependency(\n-  link_with           : [ dxgi_dll ],\n-  include_directories : [ dxvk_include_path ])\n+  dxgi_dep = declare_dependency(\n+    link_with           : [ dxgi_dll ],\n+    include_directories : [ dxvk_include_path ])\n+endif\ndiff --git a/src/dxvk/dxvk_adapter.cpp b/src/dxvk/dxvk_adapter.cpp\nindex 9d28fe63e23..a7e33497bf9 100644\n--- a/src/dxvk/dxvk_adapter.cpp\n+++ b/src/dxvk/dxvk_adapter.cpp\n@@ -233,7 +233,7 @@ namespace dxvk {\n   }\n \n \n-  Rc<DxvkDevice> DxvkAdapter::createDevice(std::string clientApi, DxvkDeviceFeatures enabledFeatures) {\n+  Rc<DxvkDevice> DxvkAdapter::createDevice(std::string clientApi, DxvkDeviceFeatures enabledFeatures, PFN_vkGetInstanceProcAddr getInstanceProcAddr) {\n     DxvkDeviceExtensions devExtensions;\n \n     std::array<DxvkExt*, 16> devExtensionList = {{\n@@ -347,7 +347,7 @@ namespace dxvk {\n       throw DxvkError(\"DxvkAdapter: Failed to create device\");\n     \n     Rc<DxvkDevice> result = new DxvkDevice(clientApi, this,\n-      new vk::DeviceFn(true, m_vki->instance(), device),\n+      new vk::DeviceFn(getInstanceProcAddr, true, m_vki->instance(), device),\n       devExtensions, enabledFeatures);\n     result->initResources();\n     return result;\ndiff --git a/src/dxvk/dxvk_adapter.h b/src/dxvk/dxvk_adapter.h\nindex 4901fbe770c..3467905e717 100644\n--- a/src/dxvk/dxvk_adapter.h\n+++ b/src/dxvk/dxvk_adapter.h\n@@ -202,8 +202,9 @@ namespace dxvk {\n      * \\returns Device handle\n      */\n     Rc<DxvkDevice> createDevice(\n-            std::string         clientApi,\n-            DxvkDeviceFeatures  enabledFeatures);\n+            std::string                clientApi,\n+            DxvkDeviceFeatures         enabledFeatures,\n+            PFN_vkGetInstanceProcAddr  getInstanceProcAddr);\n     \n     /**\n      * \\brief Registers memory allocation\ndiff --git a/src/dxvk/dxvk_instance.cpp b/src/dxvk/dxvk_instance.cpp\nindex 017324f3b25..edba35a5877 100644\n--- a/src/dxvk/dxvk_instance.cpp\n+++ b/src/dxvk/dxvk_instance.cpp\n@@ -7,7 +7,7 @@\n \n namespace dxvk {\n   \n-  DxvkInstance::DxvkInstance() {\n+  DxvkInstance::DxvkInstance(PFN_vkGetInstanceProcAddr getInstanceProcAddr) {\n     Logger::info(str::format(\"Game: \", env::getExeName()));\n     Logger::info(str::format(\"DXVK: \", DXVK_VERSION));\n \n@@ -17,8 +17,8 @@ namespace dxvk {\n \n     g_vrInstance.initInstanceExtensions();\n \n-    m_vkl = new vk::LibraryFn();\n-    m_vki = new vk::InstanceFn(true, this->createInstance());\n+    m_vkl = new vk::LibraryFn(getInstanceProcAddr);\n+    m_vki = new vk::InstanceFn(getInstanceProcAddr, true, this->createInstance());\n \n     m_adapters = this->queryAdapters();\n     g_vrInstance.initDeviceExtensions(this);\ndiff --git a/src/dxvk/dxvk_instance.h b/src/dxvk/dxvk_instance.h\nindex 154f37df58b..7bd76c17a2f 100644\n--- a/src/dxvk/dxvk_instance.h\n+++ b/src/dxvk/dxvk_instance.h\n@@ -20,7 +20,7 @@ namespace dxvk {\n     \n   public:\n     \n-    DxvkInstance();\n+    DxvkInstance(PFN_vkGetInstanceProcAddr functionFinder);\n     ~DxvkInstance();\n     \n     /**\ndiff --git a/src/dxvk/dxvk_openvr.cpp b/src/dxvk/dxvk_openvr.cpp\nindex c1d60a0c682..fd7217ebc34 100644\n--- a/src/dxvk/dxvk_openvr.cpp\n+++ b/src/dxvk/dxvk_openvr.cpp\n@@ -5,7 +5,7 @@\n #pragma GCC diagnostic ignored \"-Wnon-virtual-dtor\"\n #endif\n \n-#ifdef __WINE__\n+#if defined(__WINE__) || defined(DXVK_NATIVE)\n #include <dlfcn.h>\n \n #pragma push_macro(\"_WIN32\")\n@@ -190,7 +190,7 @@ namespace dxvk {\n \n   SoHandle VrInstance::loadLibrary() {\n     SoHandle handle = nullptr;\n-    #ifdef __WINE__\n+    #if defined(__WINE__) || defined(DXVK_NATIVE)\n     // on winelib, load native openvr_api directly\n     if (!(handle = ::dlopen(\"libopenvr_api.so\", RTLD_LAZY | RTLD_NOLOAD)))\n       handle = ::dlopen(\"libopenvr_api_dxvk.so\", RTLD_LAZY | RTLD_LOCAL);\n@@ -206,7 +206,7 @@ namespace dxvk {\n \n \n   void VrInstance::freeLibrary() {\n-    #ifdef __WINE__\n+    #if defined(__WINE__) || defined(DXVK_NATIVE)\n     ::dlclose(m_ovrApi);\n     #else\n     ::FreeLibrary(m_ovrApi);\n@@ -215,7 +215,7 @@ namespace dxvk {\n \n   \n   void* VrInstance::getSym(const char* sym) {\n-    #ifdef __WINE__\n+    #if defined(__WINE__) || defined(DXVK_NATIVE)\n     return reinterpret_cast<void*>(\n       ::dlsym(m_ovrApi, sym));\n     #else\ndiff --git a/src/dxvk/meson.build b/src/dxvk/meson.build\nindex 5c4530364f1..018dfa52e2c 100644\n--- a/src/dxvk/meson.build\n+++ b/src/dxvk/meson.build\n@@ -99,7 +99,7 @@ dxvk_src = files([\n \n thread_dep = dependency('threads')\n \n-dxvk_lib = static_library('dxvk', dxvk_src, glsl_generator.process(dxvk_shaders), dxvk_version,\n+dxvk_lib = static_library('dxvk', dxvk_src, glsl_generator.process(dxvk_shaders), com_headers, dxvk_version,\n   link_with           : [ util_lib, spirv_lib ],\n   dependencies        : [ thread_dep, vkcommon_dep ] + dxvk_extradep,\n   include_directories : [ dxvk_include_path ],\ndiff --git a/src/meson.build b/src/meson.build\nindex 08000450e34..4f5567d2151 100644\n--- a/src/meson.build\n+++ b/src/meson.build\n@@ -5,4 +5,6 @@ subdir('dxvk')\n subdir('dxgi')\n subdir('dxbc')\n subdir('d3d11')\n-subdir('d3d10')\n+if not dxvk_native\n+  subdir('d3d10')\n+endif\n\\ No newline at end of file\ndiff --git a/src/spirv/meson.build b/src/spirv/meson.build\nindex 70e6ae7c44a..9b3bb4839fb 100644\n--- a/src/spirv/meson.build\n+++ b/src/spirv/meson.build\n@@ -3,6 +3,6 @@ spirv_src = files([\n   'spirv_module.cpp',\n ])\n \n-spirv_lib = static_library('spirv', spirv_src,\n+spirv_lib = static_library('spirv', spirv_src, com_headers,\n   include_directories : [ dxvk_include_path ],\n   override_options    : ['cpp_std='+dxvk_cpp_std])\ndiff --git a/src/util/com/com_guid.cpp b/src/util/com/com_guid.cpp\nindex 85f6164d525..ef7303de72c 100644\n--- a/src/util/com/com_guid.cpp\n+++ b/src/util/com/com_guid.cpp\n@@ -9,6 +9,7 @@ const GUID IDXGIVkInteropDevice::guid   = {0xe2ef5fa5,0xdc21,0x4af7,{0x90,0xc4,0\n const GUID IDXGIVkInteropSurface::guid  = {0x5546cf8c,0x77e7,0x4341,{0xb0,0x5d,0x8d,0x4d,0x50,0x00,0xe7,0x7d}};\n const GUID IDXGIVkSwapChain::guid       = {0x104001a6,0x7f36,0x4957,{0xb9,0x32,0x86,0xad,0xe9,0x56,0x7d,0x91}};\n const GUID IWineDXGISwapChainFactory::guid = {0x53cb4ff0,0xc25a,0x4164,{0xa8,0x91,0x0e,0x83,0xdb,0x0a,0x7a,0xac}};\n+const GUID IWineDXGISwapChainHelper::guid = {0xd922ca90,0x6152,0x41f9,{0x8b,0x44,0x47,0xad,0xaa,0xc2,0x2b,0x40}};\n \n std::ostream& operator << (std::ostream& os, REFIID guid) {\n   os << std::hex << std::setfill('0')\ndiff --git a/src/util/com/com_guid.h b/src/util/com/com_guid.h\nindex d1f6b01d116..e040755745e 100644\n--- a/src/util/com/com_guid.h\n+++ b/src/util/com/com_guid.h\n@@ -9,7 +9,10 @@\n # ifdef __WINE__\n #   define DXVK_DEFINE_GUID(iface) \\\n       template<> inline GUID const& __wine_uuidof<iface> () { return iface::guid; }\n-# else\n+# elif defined(DXVK_NATIVE)\n+#   define DXVK_DEFINE_GUID(iface) \\\n+      template<> inline GUID const& __dxvk_uuidof<iface> () { return iface::guid; }\n+#else\n #   define DXVK_DEFINE_GUID(iface) \\\n       template<> inline GUID const& __mingw_uuidof<iface> () { return iface::guid; }\n # endif\ndiff --git a/src/util/meson.build b/src/util/meson.build\nindex 50583f23cd6..011450fa534 100644\n--- a/src/util/meson.build\n+++ b/src/util/meson.build\n@@ -1,7 +1,4 @@\n-util_src = files([\n-  'util_env.cpp',\n-  'util_string.cpp',\n-  \n+util_src_files = [\n   'com/com_guid.cpp',\n   'com/com_private_data.cpp',\n \n@@ -12,9 +9,19 @@ util_src = files([\n   \n   'sha1/sha1.c',\n   'sha1/sha1_util.cpp',\n-])\n+]\n+\n+if dxvk_native\n+  util_src_files += 'util_env_native.cpp'\n+  util_src_files += 'thread_generic.cpp'\n+else\n+  util_src_files += 'util_env.cpp'\n+  util_src_files += 'util_string.cpp'\n+endif\n+\n+util_src = files(util_src_files)\n \n-util_lib = static_library('util', util_src,\n+util_lib = static_library('util', util_src, com_headers,\n   include_directories : [ dxvk_include_path ],\n   override_options    : ['cpp_std='+dxvk_cpp_std])\n \ndiff --git a/src/util/thread.h b/src/util/thread.h\nindex c96cb1c0808..0c2c1fc6313 100644\n--- a/src/util/thread.h\n+++ b/src/util/thread.h\n@@ -1,147 +1,5 @@\n-#pragma once\n-\n-#include <functional>\n-\n-#include \"util_error.h\"\n-\n-#include \"./com/com_include.h\"\n-\n-#include \"./rc/util_rc.h\"\n-#include \"./rc/util_rc_ptr.h\"\n-\n-namespace dxvk {\n-\n-  /**\n-   * \\brief Thread priority\n-   */\n-  enum class ThreadPriority : int32_t {\n-    Lowest      = THREAD_PRIORITY_LOWEST,\n-    Low         = THREAD_PRIORITY_BELOW_NORMAL,\n-    Normal      = THREAD_PRIORITY_NORMAL,\n-    High        = THREAD_PRIORITY_ABOVE_NORMAL,\n-    Highest     = THREAD_PRIORITY_HIGHEST,\n-  };\n-\n-  /**\n-   * \\brief Thread helper class\n-   * \n-   * This is needed mostly  for winelib builds. Wine needs to setup each thread that\n-   * calls Windows APIs. It means that in winelib builds, we can't let standard C++\n-   * library create threads and need to use Wine for that instead. We use a thin wrapper\n-   * around Windows thread functions so that the rest of code just has to use\n-   * dxvk::thread class instead of std::thread.\n-   */\n-  class ThreadFn : public RcObject {\n-    using Proc = std::function<void()>;\n-  public:\n-\n-    ThreadFn(Proc&& proc)\n-    : m_proc(std::move(proc)) {\n-      // Reference for the thread function\n-      this->incRef();\n-\n-      m_handle = ::CreateThread(nullptr, 0,\n-        ThreadFn::threadProc, this, 0, nullptr);\n-      \n-      if (m_handle == nullptr)\n-        throw DxvkError(\"Failed to create thread\");\n-    }\n-\n-    ~ThreadFn() {\n-      if (this->joinable())\n-        std::terminate();\n-    }\n-    \n-    void detach() {\n-      ::CloseHandle(m_handle);\n-      m_handle = nullptr;\n-    }\n-\n-    void join() {\n-      if(::WaitForSingleObjectEx(m_handle, INFINITE, FALSE) == WAIT_FAILED)\n-        throw DxvkError(\"Failed to join thread\");\n-      this->detach();\n-    }\n-\n-    bool joinable() const {\n-      return m_handle != nullptr;\n-    }\n-\n-    void set_priority(ThreadPriority priority) {\n-      ::SetThreadPriority(m_handle, int32_t(priority));\n-    }\n-\n-  private:\n-\n-    Proc    m_proc;\n-    HANDLE  m_handle;\n-\n-    static DWORD WINAPI threadProc(void *arg) {\n-      auto thread = reinterpret_cast<ThreadFn*>(arg);\n-      thread->m_proc();\n-      thread->decRef();\n-      return 0;\n-    }\n-\n-  };\n-\n-\n-  /**\n-   * \\brief RAII thread wrapper\n-   * \n-   * Wrapper for \\c ThreadFn that can be used\n-   * as a drop-in replacement for \\c std::thread.\n-   */\n-  class thread {\n-\n-  public:\n-\n-    thread() { }\n-\n-    explicit thread(std::function<void()>&& func)\n-    : m_thread(new ThreadFn(std::move(func))) { }\n-\n-    thread(thread&& other)\n-    : m_thread(std::move(other.m_thread)) { }\n-\n-    thread& operator = (thread&& other) {\n-      m_thread = std::move(other.m_thread);\n-      return *this;\n-    }\n-\n-    void detach() {\n-      m_thread->detach();\n-    }\n-\n-    void join() {\n-      m_thread->join();\n-    }\n-\n-    bool joinable() const {\n-      return m_thread != nullptr\n-          && m_thread->joinable();\n-    }\n-\n-    void set_priority(ThreadPriority priority) {\n-      m_thread->set_priority(priority);\n-    }\n-    \n-    static uint32_t hardware_concurrency() {\n-      SYSTEM_INFO info = { };\n-      ::GetSystemInfo(&info);\n-      return info.dwNumberOfProcessors;\n-    }\n-\n-  private:\n-\n-    Rc<ThreadFn> m_thread;\n-\n-  };\n-\n-\n-  namespace this_thread {\n-    inline void yield() {\n-      Sleep(0);\n-    }\n-  }\n-}\n+#ifdef DXVK_NATIVE\n+  #include \"thread_generic.h\"\n+#else\n+  #include \"thread_win32.h\"\n+#endif\n\\ No newline at end of file\ndiff --git a/src/util/thread_generic.cpp b/src/util/thread_generic.cpp\nnew file mode 100644\nindex 00000000000..60f2b2f3cb7\n--- /dev/null\n+++ b/src/util/thread_generic.cpp\n@@ -0,0 +1,80 @@\n+#include \"thread_generic.h\"\n+\n+#include \"./log/log.h\"\n+\n+namespace dxvk {\n+\n+    ThreadFn::ThreadFn(Proc&& proc)\n+    : m_proc(std::move(proc)) {\n+      // Reference for the thread function\n+      this->incRef();\n+\n+      pthread_create(&m_handle, NULL, ThreadFn::threadProc, this);\n+\n+      if(m_handle == 0)\n+        throw DxvkError(\"Failed to create thread\");\n+    }\n+\n+    ThreadFn::~ThreadFn() {\n+      if (this->joinable())\n+        std::terminate();\n+    }\n+\n+    void ThreadFn::join() {\n+      if(pthread_join(m_handle, NULL))\n+        throw DxvkError(\"Failed to join thread\");\n+      this->detach();\n+    }\n+\n+    bool ThreadFn::joinable() const {\n+        return m_handle != 0;\n+    }\n+\n+    void ThreadFn::detach() {\n+      pthread_detach(m_handle);\n+      m_handle = 0;\n+    }\n+\n+    void ThreadFn::set_priority(ThreadPriority priority)\n+    {\n+      // Based on wine staging server-Realtime_Priority patch\n+\n+      struct sched_param param;\n+      int policy = SCHED_OTHER;\n+\n+      switch (priority) {\n+        case ThreadPriority::Highest:\n+          policy = SCHED_FIFO;\n+          param.sched_priority = 2;\n+          break;\n+\n+        case ThreadPriority::High:\n+          policy = SCHED_FIFO;\n+          param.sched_priority = 0;\n+          break;\n+\n+        case ThreadPriority::Normal:\n+          policy = SCHED_OTHER;\n+          break;\n+\n+        case ThreadPriority::Low:\n+          policy = SCHED_IDLE;\n+          break;\n+\n+        case ThreadPriority::Lowest:\n+          policy = SCHED_BATCH;\n+          break;\n+      }\n+\n+      if (pthread_setschedparam(pthread_self(), policy, &param) == -1)\n+        Logger::warn(\"Failed to set thread priority\");\n+    }\n+\n+    void* ThreadFn::threadProc(void *arg) {\n+      auto thread = reinterpret_cast<ThreadFn*>(arg);\n+      thread->m_proc();\n+      thread->decRef();\n+      return nullptr;\n+    }\n+\n+}\n\\ No newline at end of file\ndiff --git a/src/util/thread_generic.h b/src/util/thread_generic.h\nnew file mode 100644\nindex 00000000000..0c1b6a2ff5b\n--- /dev/null\n+++ b/src/util/thread_generic.h\n@@ -0,0 +1,122 @@\n+#pragma once\n+\n+#include <functional>\n+\n+#include <sys/sysinfo.h>\n+#include <pthread.h>\n+\n+#include \"util_error.h\"\n+#include \"util_env.h\"\n+\n+#include \"./rc/util_rc.h\"\n+#include \"./rc/util_rc_ptr.h\"\n+\n+namespace dxvk {\n+\n+  /**\n+   * \\brief Thread priority\n+   */\n+  enum class ThreadPriority : int32_t {\n+    Lowest,\n+    Low,\n+    Normal,\n+    High,\n+    Highest,\n+  };\n+\n+  /**\n+   * \\brief Thread helper class\n+   * \n+   * This is needed mostly  for winelib builds. Wine needs to setup each thread that\n+   * calls Windows APIs. It means that in winelib builds, we can't let standard C++\n+   * library create threads and need to use Wine for that instead. We use a thin wrapper\n+   * around Windows thread functions so that the rest of code just has to use\n+   * dxvk::thread class instead of std::thread.\n+   */\n+  class ThreadFn : public RcObject {\n+    using Proc = std::function<void()>;\n+  public:\n+\n+    ThreadFn(Proc&& proc);\n+\n+    ~ThreadFn();\n+    \n+    void detach();\n+\n+    void join();\n+\n+    bool joinable() const;\n+\n+    void set_priority(ThreadPriority priority);\n+\n+  private:\n+\n+    Proc  m_proc;\n+    pthread_t m_handle;\n+\n+    static void* threadProc(void *arg);\n+\n+  };\n+\n+\n+  /**\n+   * \\brief RAII thread wrapper\n+   * \n+   * Wrapper for \\c ThreadFn that can be used\n+   * as a drop-in replacement for \\c std::thread.\n+   */\n+  class thread {\n+\n+  public:\n+\n+    thread() { }\n+\n+    explicit thread(std::function<void()>&& func)\n+    : m_thread(new ThreadFn(std::move(func))) { }\n+\n+    thread(thread&& other)\n+    : m_thread(std::move(other.m_thread)) { }\n+\n+    thread& operator = (thread&& other) {\n+      m_thread = std::move(other.m_thread);\n+      return *this;\n+    }\n+\n+    void detach() {\n+      m_thread->detach();\n+    }\n+\n+    void join() {\n+      m_thread->join();\n+    }\n+\n+    bool joinable() const {\n+      return m_thread != nullptr\n+          && m_thread->joinable();\n+    }\n+\n+    void set_priority(ThreadPriority priority) {\n+      m_thread->set_priority(priority);\n+    }\n+    \n+    static uint32_t hardware_concurrency() {\n+      return get_nprocs();\n+    }\n+\n+  private:\n+\n+    Rc<ThreadFn> m_thread;\n+\n+  };\n+\n+\n+  namespace this_thread {\n+    inline void yield() {\n+      pthread_yield();\n+    }\n+\n+    inline uint32_t get_id() {\n+      return pthread_self();\n+    }\n+  }\n+}\n\\ No newline at end of file\ndiff --git a/src/util/thread_win32.h b/src/util/thread_win32.h\nnew file mode 100644\nindex 00000000000..dd40569f4d4\n--- /dev/null\n+++ b/src/util/thread_win32.h\n@@ -0,0 +1,151 @@\n+#pragma once\n+\n+#include <functional>\n+\n+#include \"util_error.h\"\n+\n+#include \"./com/com_include.h\"\n+\n+#include \"./rc/util_rc.h\"\n+#include \"./rc/util_rc_ptr.h\"\n+\n+namespace dxvk {\n+\n+  /**\n+   * \\brief Thread priority\n+   */\n+  enum class ThreadPriority : int32_t {\n+    Lowest      = THREAD_PRIORITY_LOWEST,\n+    Low         = THREAD_PRIORITY_BELOW_NORMAL,\n+    Normal      = THREAD_PRIORITY_NORMAL,\n+    High        = THREAD_PRIORITY_ABOVE_NORMAL,\n+    Highest     = THREAD_PRIORITY_HIGHEST,\n+  };\n+\n+  /**\n+   * \\brief Thread helper class\n+   * \n+   * This is needed mostly  for winelib builds. Wine needs to setup each thread that\n+   * calls Windows APIs. It means that in winelib builds, we can't let standard C++\n+   * library create threads and need to use Wine for that instead. We use a thin wrapper\n+   * around Windows thread functions so that the rest of code just has to use\n+   * dxvk::thread class instead of std::thread.\n+   */\n+  class ThreadFn : public RcObject {\n+    using Proc = std::function<void()>;\n+  public:\n+\n+    ThreadFn(Proc&& proc)\n+    : m_proc(std::move(proc)) {\n+      // Reference for the thread function\n+      this->incRef();\n+\n+      m_handle = ::CreateThread(nullptr, 0,\n+        ThreadFn::threadProc, this, 0, nullptr);\n+      \n+      if (m_handle == nullptr)\n+        throw DxvkError(\"Failed to create thread\");\n+    }\n+\n+    ~ThreadFn() {\n+      if (this->joinable())\n+        std::terminate();\n+    }\n+    \n+    void detach() {\n+      ::CloseHandle(m_handle);\n+      m_handle = nullptr;\n+    }\n+\n+    void join() {\n+      if(::WaitForSingleObjectEx(m_handle, INFINITE, FALSE) == WAIT_FAILED)\n+        throw DxvkError(\"Failed to join thread\");\n+      this->detach();\n+    }\n+\n+    bool joinable() const {\n+      return m_handle != nullptr;\n+    }\n+\n+    void set_priority(ThreadPriority priority) {\n+      ::SetThreadPriority(m_handle, int32_t(priority));\n+    }\n+\n+  private:\n+\n+    Proc    m_proc;\n+    HANDLE  m_handle;\n+\n+    static DWORD WINAPI threadProc(void *arg) {\n+      auto thread = reinterpret_cast<ThreadFn*>(arg);\n+      thread->m_proc();\n+      thread->decRef();\n+      return 0;\n+    }\n+\n+  };\n+\n+\n+  /**\n+   * \\brief RAII thread wrapper\n+   * \n+   * Wrapper for \\c ThreadFn that can be used\n+   * as a drop-in replacement for \\c std::thread.\n+   */\n+  class thread {\n+\n+  public:\n+\n+    thread() { }\n+\n+    explicit thread(std::function<void()>&& func)\n+    : m_thread(new ThreadFn(std::move(func))) { }\n+\n+    thread(thread&& other)\n+    : m_thread(std::move(other.m_thread)) { }\n+\n+    thread& operator = (thread&& other) {\n+      m_thread = std::move(other.m_thread);\n+      return *this;\n+    }\n+\n+    void detach() {\n+      m_thread->detach();\n+    }\n+\n+    void join() {\n+      m_thread->join();\n+    }\n+\n+    bool joinable() const {\n+      return m_thread != nullptr\n+          && m_thread->joinable();\n+    }\n+\n+    void set_priority(ThreadPriority priority) {\n+      m_thread->set_priority(priority);\n+    }\n+    \n+    static uint32_t hardware_concurrency() {\n+      SYSTEM_INFO info = { };\n+      ::GetSystemInfo(&info);\n+      return info.dwNumberOfProcessors;\n+    }\n+\n+  private:\n+\n+    Rc<ThreadFn> m_thread;\n+\n+  };\n+\n+\n+  namespace this_thread {\n+    inline void yield() {\n+      Sleep(0);\n+    }\n+\n+    inline uint32_t get_id() {\n+      return ::GetCurrentThreadId();\n+    }\n+  }\n+}\ndiff --git a/src/util/util_env_native.cpp b/src/util/util_env_native.cpp\nnew file mode 100644\nindex 00000000000..12325c96387\n--- /dev/null\n+++ b/src/util/util_env_native.cpp\n@@ -0,0 +1,49 @@\n+#include \"util_env.h\"\n+\n+#include <string>\n+#include <fstream>\n+\n+#include <sys/stat.h>\n+#include <pthread.h>\n+\n+namespace dxvk::env {\n+\n+  std::string getEnvVar(const char* name) {\n+    char* result = std::getenv(name);\n+    return (result)\n+      ? result\n+      : \"\";\n+  }\n+  \n+  \n+  std::string getExeName() {\n+    std::string fullPath;\n+\n+    std::ifstream cmdLineFile;\n+    cmdLineFile.open(\"/proc/self/cmdline\");\n+      if(cmdLineFile.good())\n+        std::getline(cmdLineFile, fullPath);\n+    cmdLineFile.close();\n+\n+    // Find first null character, arguments are specified after it\n+    auto f = fullPath.find_first_of('\\0');\n+\n+    fullPath.erase(f, std::string::npos);\n+\n+    auto n = fullPath.find_last_of('/');\n+    \n+    return (n != std::string::npos)\n+      ? fullPath.substr(n + 1)\n+      : fullPath;\n+  }\n+  \n+  \n+  void setThreadName(const std::string& name) {\n+    pthread_setname_np(pthread_self(), name.c_str());\n+  }\n+\n+  bool createDirectory(const std::string& path) {\n+    return !mkdir(path.c_str(), DEFFILEMODE);\n+  }\n+  \n+}\n\\ No newline at end of file\ndiff --git a/src/vulkan/meson.build b/src/vulkan/meson.build\nindex 826355236e1..d09a5df97b7 100644\n--- a/src/vulkan/meson.build\n+++ b/src/vulkan/meson.build\n@@ -6,7 +6,7 @@ vkcommon_src = files([\n \n thread_dep = dependency('threads')\n \n-vkcommon_lib = static_library('vkcommon', vkcommon_src,\n+vkcommon_lib = static_library('vkcommon', vkcommon_src, com_headers,\n   dependencies        : [ thread_dep, lib_vulkan ],\n   override_options    : ['cpp_std='+dxvk_cpp_std],\n   include_directories : [ dxvk_include_path ])\ndiff --git a/src/vulkan/vulkan_loader.cpp b/src/vulkan/vulkan_loader.cpp\nindex cd2b739da4b..4434e96ce8e 100644\n--- a/src/vulkan/vulkan_loader.cpp\n+++ b/src/vulkan/vulkan_loader.cpp\n@@ -2,35 +2,26 @@\n \n namespace dxvk::vk {\n \n-#if defined(__WINE__)\n-\n-  extern \"C\"\n-  PFN_vkVoidFunction native_vkGetInstanceProcAddrWINE(VkInstance instance, const char *name);\n-  static const PFN_vkGetInstanceProcAddr GetInstanceProcAddr = native_vkGetInstanceProcAddrWINE;\n-\n-#else\n-\n-  static const PFN_vkGetInstanceProcAddr GetInstanceProcAddr = vkGetInstanceProcAddr;\n-\n-#endif\n+  LibraryLoader::LibraryLoader(PFN_vkGetInstanceProcAddr getInstanceProcAddr)\n+  : m_getInstanceProcAddr(getInstanceProcAddr) { }\n \n   PFN_vkVoidFunction LibraryLoader::sym(const char* name) const {\n-    return dxvk::vk::GetInstanceProcAddr(nullptr, name);\n+    return m_getInstanceProcAddr(nullptr, name);\n   }\n   \n   \n-  InstanceLoader::InstanceLoader(bool owned, VkInstance instance)\n-  : m_instance(instance), m_owned(owned) { }\n+  InstanceLoader::InstanceLoader(PFN_vkGetInstanceProcAddr getInstanceProcAddr, bool owned, VkInstance instance)\n+  : m_getInstanceProcAddr(getInstanceProcAddr), m_instance(instance), m_owned(owned) { }\n   \n   \n   PFN_vkVoidFunction InstanceLoader::sym(const char* name) const {\n-    return dxvk::vk::GetInstanceProcAddr(m_instance, name);\n+    return m_getInstanceProcAddr(m_instance, name);\n   }\n   \n   \n-  DeviceLoader::DeviceLoader(bool owned, VkInstance instance, VkDevice device)\n+  DeviceLoader::DeviceLoader(PFN_vkGetInstanceProcAddr getInstanceProcAddr, bool owned, VkInstance instance, VkDevice device)\n   : m_getDeviceProcAddr(reinterpret_cast<PFN_vkGetDeviceProcAddr>(\n-      dxvk::vk::GetInstanceProcAddr(instance, \"vkGetDeviceProcAddr\"))),\n+      getInstanceProcAddr(instance, \"vkGetDeviceProcAddr\"))),\n     m_device(device), m_owned(owned) { }\n   \n   \n@@ -39,20 +30,21 @@ namespace dxvk::vk {\n   }\n   \n   \n-  LibraryFn::LibraryFn() { }\n+  LibraryFn::LibraryFn(PFN_vkGetInstanceProcAddr getInstanceProcAddr)\n+  : LibraryLoader(getInstanceProcAddr) { }\n   LibraryFn::~LibraryFn() { }\n   \n   \n-  InstanceFn::InstanceFn(bool owned, VkInstance instance)\n-  : InstanceLoader(owned, instance) { }\n+  InstanceFn::InstanceFn(PFN_vkGetInstanceProcAddr getInstanceProcAddr, bool owned, VkInstance instance)\n+  : InstanceLoader(getInstanceProcAddr, owned, instance) { }\n   InstanceFn::~InstanceFn() {\n     if (m_owned)\n       this->vkDestroyInstance(m_instance, nullptr);\n   }\n   \n   \n-  DeviceFn::DeviceFn(bool owned, VkInstance instance, VkDevice device)\n-  : DeviceLoader(owned, instance, device) { }\n+  DeviceFn::DeviceFn(PFN_vkGetInstanceProcAddr vkGetInstanceProcAddr, bool owned, VkInstance instance, VkDevice device)\n+  : DeviceLoader(vkGetInstanceProcAddr, owned, instance, device) { }\n   DeviceFn::~DeviceFn() {\n     if (m_owned)\n       this->vkDestroyDevice(m_device, nullptr);\ndiff --git a/src/vulkan/vulkan_loader.h b/src/vulkan/vulkan_loader.h\nindex 334ffac3446..cff2c32a614 100644\n--- a/src/vulkan/vulkan_loader.h\n+++ b/src/vulkan/vulkan_loader.h\n@@ -14,7 +14,11 @@ namespace dxvk::vk {\n    * can be called before creating a  instance.\n    */\n   struct LibraryLoader : public RcObject {\n+    LibraryLoader(PFN_vkGetInstanceProcAddr functionFinder);\n+\n     PFN_vkVoidFunction sym(const char* name) const;\n+protected:\n+    const PFN_vkGetInstanceProcAddr m_getInstanceProcAddr;\n   };\n   \n   \n@@ -25,10 +29,11 @@ namespace dxvk::vk {\n    * called for a specific instance.\n    */\n   struct InstanceLoader : public RcObject {\n-    InstanceLoader(bool owned, VkInstance instance);\n+    InstanceLoader(PFN_vkGetInstanceProcAddr getInstanceProcAddr, bool owned, VkInstance instance);\n     PFN_vkVoidFunction sym(const char* name) const;\n     VkInstance instance() const { return m_instance; }\n   protected:\n+    const PFN_vkGetInstanceProcAddr m_getInstanceProcAddr;\n     const VkInstance m_instance;\n     const bool       m_owned;\n   };\n@@ -41,7 +46,7 @@ namespace dxvk::vk {\n    * specific device.\n    */\n   struct DeviceLoader : public RcObject {\n-    DeviceLoader(bool owned, VkInstance instance, VkDevice device);\n+    DeviceLoader(PFN_vkGetInstanceProcAddr getInstanceProcAddr, bool owned, VkInstance instance, VkDevice device);\n     PFN_vkVoidFunction sym(const char* name) const;\n     VkDevice device() const { return m_device; }\n   protected:\n@@ -58,7 +63,7 @@ namespace dxvk::vk {\n    * creating an actual Vulkan instance.\n    */\n   struct LibraryFn : LibraryLoader {\n-    LibraryFn();\n+    LibraryFn(PFN_vkGetInstanceProcAddr getInstanceProcAddr);\n     ~LibraryFn();\n     \n     VULKAN_FN(vkCreateInstance);\n@@ -74,7 +79,7 @@ namespace dxvk::vk {\n    * are independent of any Vulkan devices.\n    */\n   struct InstanceFn : InstanceLoader {\n-    InstanceFn(bool owned, VkInstance instance);\n+    InstanceFn(PFN_vkGetInstanceProcAddr getInstanceProcAddr, bool owned, VkInstance instance);\n     ~InstanceFn();\n     \n     VULKAN_FN(vkCreateDevice);\n@@ -143,7 +148,7 @@ namespace dxvk::vk {\n    * This ensures that no slow dispatch code is executed.\n    */\n   struct DeviceFn : DeviceLoader {\n-    DeviceFn(bool owned, VkInstance instance, VkDevice device);\n+    DeviceFn(PFN_vkGetInstanceProcAddr getInstanceProcAddr, bool owned, VkInstance instance, VkDevice device);\n     ~DeviceFn();\n     \n     VULKAN_FN(vkDestroyDevice);\ndiff --git a/src/vulkan/vulkan_presenter.cpp b/src/vulkan/vulkan_presenter.cpp\nindex 21444decd46..65c5d3c9f0d 100644\n--- a/src/vulkan/vulkan_presenter.cpp\n+++ b/src/vulkan/vulkan_presenter.cpp\n@@ -5,13 +5,13 @@\n namespace dxvk::vk {\n \n   Presenter::Presenter(\n-          HWND            window,\n+          VkSurfaceKHR    surface,\n     const Rc<InstanceFn>& vki,\n     const Rc<DeviceFn>&   vkd,\n           PresenterDevice device,\n     const PresenterDesc&  desc)\n-  : m_vki(vki), m_vkd(vkd), m_device(device) {\n-    if (createSurface(window) != VK_SUCCESS)\n+  : m_vki(vki), m_vkd(vkd), m_device(device), m_surface(surface) {\n+    if (checkSurface() != VK_SUCCESS)\n       throw DxvkError(\"Failed to create surface\");\n \n     if (recreateSwapChain(desc) != VK_SUCCESS)\n@@ -354,23 +354,8 @@ namespace dxvk::vk {\n     return count;\n   }\n \n-\n-  VkResult Presenter::createSurface(HWND window) {\n-    HINSTANCE instance = reinterpret_cast<HINSTANCE>(\n-      GetWindowLongPtr(window, GWLP_HINSTANCE));\n-    \n-    VkWin32SurfaceCreateInfoKHR info;\n-    info.sType      = VK_STRUCTURE_TYPE_WIN32_SURFACE_CREATE_INFO_KHR;\n-    info.pNext      = nullptr;\n-    info.flags      = 0;\n-    info.hinstance  = instance;\n-    info.hwnd       = window;\n-    \n-    VkResult status = m_vki->vkCreateWin32SurfaceKHR(\n-      m_vki->instance(), &info, nullptr, &m_surface);\n-    \n-    if (status != VK_SUCCESS)\n-      return status;\n+  VkResult Presenter::checkSurface() {\n+    VkResult status = VK_ERROR_FEATURE_NOT_PRESENT;\n     \n     VkBool32 supportStatus = VK_FALSE;\n \ndiff --git a/src/vulkan/vulkan_presenter.h b/src/vulkan/vulkan_presenter.h\nindex 1435f7fe3a4..b0c0a4ff8f0 100644\n--- a/src/vulkan/vulkan_presenter.h\n+++ b/src/vulkan/vulkan_presenter.h\n@@ -10,6 +10,8 @@\n \n #include \"vulkan_loader.h\"\n \n+typedef VkResult (*PFN_create_vulkan_surface)(VkInstance instance, void* window, VkSurfaceKHR *surface);\n+\n namespace dxvk::vk {\n \n   /**\n@@ -84,7 +86,7 @@ namespace dxvk::vk {\n   public:\n \n     Presenter(\n-            HWND            window,\n+            VkSurfaceKHR    surface,\n       const Rc<InstanceFn>& vki,\n       const Rc<DeviceFn>&   vkd,\n             PresenterDevice device,\n@@ -213,7 +215,7 @@ namespace dxvk::vk {\n             VkPresentModeKHR          presentMode,\n             uint32_t                  desired);\n \n-    VkResult createSurface(HWND window);\n+    VkResult checkSurface();\n \n     void destroySwapchain();\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Bug Fix:** In `getExeName()`, the `fullPath` variable from `/proc/self/cmdline` contains excessive `\\0` null characters. Correct this by trimming trailing nulls before further processing.\n\n2. **Implementation Suggestion:** Modify `getExeName()` to:\n   - Use separate string operations for finding the last '/' and \".exe\".\n   - Alternatively, remove trailing nulls directly instead of depending on scanning for \".exe\".\n\n3. **Log Issues:** \"World Of Tanks\" hangs when using DXVK as a native library. Investigate missing entries such as `wine_vk_device_convert_create_info` in the native logs.\n\n4. **RPM Package Suggestion:** Create RPMs similar to Lutris builds for easier testing.\n\n5. **Registry Key Error:** Change to `HKEY_CURRENT_USER\\Software\\Wine\\Direct3D\\external_d3d` for registry configuration.\n\n6. **Simplification Reminder:** Reduce unnecessary changes in the PR, like removing unused header files and using ternary operators in `meson.build`."
      }
    ],
    "codediff_length": 71721
  },
  {
    "index": 56,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/VP_DXVK_requirements.json b/VP_DXVK_requirements.json\nnew file mode 100644\nindex 00000000000..ca4a637c64b\n--- /dev/null\n+++ b/VP_DXVK_requirements.json\n@@ -0,0 +1,585 @@\n+{\n+    \"$schema\": \"https://schema.khronos.org/vulkan/profiles-0.8.0-224.json#\",\n+    \"capabilities\": {\n+        \"vulkan10requirements\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"robustBufferAccess\": true\n+                }\n+            }\n+        },\n+        \"vulkan11requirements\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceVulkan11Features\": {\n+                    \"multiview\": true\n+                }\n+            },\n+            \"properties\": {\n+                \"VkPhysicalDeviceVulkan11Properties\": {\n+                    \"maxMultiviewViewCount\": 6,\n+                    \"maxMultiviewInstanceIndex\": 134217727\n+                }\n+            }\n+        },\n+        \"vulkan12requirements\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceVulkan12Features\": {\n+                    \"uniformBufferStandardLayout\": true,\n+                    \"subgroupBroadcastDynamicId\": true,\n+                    \"imagelessFramebuffer\": true,\n+                    \"separateDepthStencilLayouts\": true,\n+                    \"hostQueryReset\": true,\n+                    \"timelineSemaphore\": true,\n+                    \"shaderSubgroupExtendedTypes\": true\n+                }\n+            },\n+            \"properties\": {\n+                \"VkPhysicalDeviceVulkan12Properties\": {\n+                    \"maxTimelineSemaphoreValueDifference\": 2147483647\n+                }\n+            }\n+        },\n+        \"vulkan13requirements\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceVulkan12Features\": {\n+                    \"vulkanMemoryModel\": true,\n+                    \"vulkanMemoryModelDeviceScope\": true,\n+                    \"bufferDeviceAddress\": true\n+                },\n+                \"VkPhysicalDeviceVulkan13Features\": {\n+                    \"robustImageAccess\": true,\n+                    \"shaderTerminateInvocation\": true,\n+                    \"shaderZeroInitializeWorkgroupMemory\": true,\n+                    \"synchronization2\": true,\n+                    \"shaderIntegerDotProduct\": true,\n+                    \"maintenance4\": true,\n+                    \"pipelineCreationCacheControl\": true,\n+                    \"subgroupSizeControl\": true,\n+                    \"computeFullSubgroups\": true,\n+                    \"shaderDemoteToHelperInvocation\": true,\n+                    \"inlineUniformBlock\": true,\n+                    \"dynamicRendering\": true\n+                }\n+            },\n+            \"properties\": {\n+                \"VkPhysicalDeviceVulkan13Properties\": {\n+                    \"maxBufferSize\": 1073741824,\n+                    \"maxInlineUniformBlockSize\": 256,\n+                    \"maxPerStageDescriptorInlineUniformBlocks\": 4,\n+                    \"maxPerStageDescriptorUpdateAfterBindInlineUniformBlocks\": 4,\n+                    \"maxDescriptorSetInlineUniformBlocks\": 4,\n+                    \"maxDescriptorSetUpdateAfterBindInlineUniformBlocks\": 4,\n+                    \"maxInlineUniformTotalSize\": 4\n+                }\n+            }\n+        },\n+        \"d3d9_baseline\": {\n+            \"extensions\": {\n+                \"VK_EXT_robustness2\": 1\n+            },\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"geometryShader\": true,\n+                    \"shaderStorageImageWriteWithoutFormat\": true,\n+                    \"imageCubeArray\": true,\n+                    \"depthClamp\": true,\n+                    \"depthBiasClamp\": true,\n+                    \"fillModeNonSolid\": true,\n+                    \"sampleRateShading\": true,\n+                    \"shaderClipDistance\": true,\n+                    \"shaderCullDistance\": true,\n+                    \"textureCompressionBC\": true,\n+                    \"occlusionQueryPrecise\": true,\n+                    \"independentBlend\": true,\n+                    \"fullDrawIndexUint32\": true,\n+\n+                    \"shaderImageGatherExtended\": true\n+                },\n+                \"VkPhysicalDeviceVulkan12Features\": {\n+                    \"samplerMirrorClampToEdge\": true\n+                },\n+                \"VkPhysicalDeviceRobustness2FeaturesEXT\": {\n+                    \"nullDescriptor\": true,\n+                    \"robustBufferAccess2\": true\n+                }\n+            }\n+        },\n+        \"d3d9_optional\": {\n+            \"extensions\": {\n+                \"VK_EXT_memory_priority\": 1,\n+                \"VK_EXT_vertex_attribute_divisor\": 1,\n+                \"VK_EXT_depth_clip_enable\": 1,\n+                \"VK_EXT_custom_border_color\": 1,\n+                \"VK_EXT_attachment_feedback_loop_layout\": 1,\n+                \"VK_EXT_non_seamless_cube_map\": 1\n+            },\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"depthBounds\": true,\n+                    \"vertexPipelineStoresAndAtomics\": true,\n+                    \"pipelineStatisticsQuery\": true,\n+                    \"samplerAnisotropy\": true\n+                },\n+                \"VkPhysicalDeviceMemoryPriorityFeaturesEXT\": {\n+                    \"memoryPriority\": true\n+                },\n+                \"VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT\": {\n+                    \"vertexAttributeInstanceRateDivisor\": true,\n+                    \"vertexAttributeInstanceRateZeroDivisor\": true\n+                },\n+                \"VkPhysicalDeviceDepthClipEnableFeaturesEXT\": {\n+                    \"depthClipEnable\": true\n+                },\n+                \"VkPhysicalDeviceCustomBorderColorFeaturesEXT\": {\n+                    \"customBorderColors\": true,\n+                    \"customBorderColorWithoutFormat\": true,\n+                },\n+                \"VkPhysicalDeviceAttachmentFeedbackLoopLayoutFeaturesEXT\": {\n+                    \"attachmentFeedbackLoopLayout\": true\n+                },\n+                \"VkPhysicalDeviceNonSeamlessCubeMapFeaturesEXT\": {\n+                    \"nonSeamlessCubeMap\": true\n+                }\n+            }\n+        },\n+        \"d3d11_baseline\": {\n+            \"extensions\": {\n+                \"VK_EXT_robustness2\": 1\n+            },\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                \t\"geometryShader\": true,\n+                    \"shaderStorageImageWriteWithoutFormat\": true,\n+                    \"depthBounds\": true,\n+\n+                    \"imageCubeArray\": true,\n+                    \"depthClamp\": true,\n+                    \"depthBiasClamp\": true,\n+                    \"fillModeNonSolid\": true,\n+                    \"sampleRateShading\": true,\n+                    \"shaderClipDistance\": true,\n+                    \"shaderCullDistance\": true,\n+                    \"textureCompressionBC\": true,\n+                    \"occlusionQueryPrecise\": true,\n+                    \"multiViewport\": true,\n+                    \"independentBlend\": true,\n+                    \"fullDrawIndexUint32\": true,\n+\n+                    \"shaderImageGatherExtended\": true\n+                },\n+                \"VkPhysicalDeviceVulkan11Features\": {\n+                    \"shaderDrawParameters\": true\n+                },\n+                \"VkPhysicalDeviceVulkan12Features\": {\n+                    \"samplerMirrorClampToEdge\": true\n+                },\n+                \"VkPhysicalDeviceRobustness2FeaturesEXT\": {\n+                    \"nullDescriptor\": true,\n+                    \"robustBufferAccess2\": true\n+                }\n+            }\n+        },\n+        \"d3d11_baseline_optional\":{\n+            \"extensions\": {\n+                \"VK_EXT_memory_priority\": 1,\n+                \"VK_EXT_vertex_attribute_divisor\": 1,\n+                \"VK_EXT_custom_border_color\": 1\n+            },\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"depthBounds\": true\n+                },\n+                \"VkPhysicalDeviceMemoryPriorityFeaturesEXT\": {\n+                    \"memoryPriority\": true\n+                },\n+                \"VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT\": {\n+                    \"vertexAttributeInstanceRateDivisor\": true,\n+                    \"vertexAttributeInstanceRateZeroDivisor\": true\n+                },\n+\n+                \"VkPhysicalDeviceCustomBorderColorFeaturesEXT\": {\n+                    \"customBorderColors\": true,\n+                    \"customBorderColorWithoutFormat\": true,\n+                }\n+            }\n+        },\n+        \"d3d11_level9_1\": {\n+            \"extensions\": {\n+                \"VK_EXT_transform_feedback\": 1,\n+                \"VK_EXT_depth_clip_enable\": 1\n+            },\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"depthClamp\": true,\n+                    \"depthBiasClamp\": true,\n+                    \"fillModeNonSolid\": true,\n+                    \"sampleRateShading\": true,\n+                    \"shaderClipDistance\": true,\n+                    \"shaderCullDistance\": true,\n+                    \"textureCompressionBC\": true\n+                },\n+                \"VkPhysicalDeviceDepthClipEnableFeaturesEXT\": {\n+                    \"depthClipEnable\": true\n+                },\n+            }\n+        },\n+        \"d3d11_level9_1_optional\": {\n+            \"extensions\": {\n+                \"VK_EXT_depth_clip_enable\": 1\n+            },\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"pipelineStatisticsQuery\": true,\n+                    \"samplerAnisotropy\": true\n+                },\n+                \"VkPhysicalDeviceDepthClipEnableFeaturesEXT\": {\n+                    \"depthClipEnable\": true\n+                }\n+            }\n+        },\n+        \"d3d11_level9_2\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"occlusionQueryPrecise\": true\n+                }\n+            }\n+        },\n+        \"d3d11_level9_3\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"independentBlend\": true,\n+                    \"multiViewport\": true\n+                }\n+            }\n+        },\n+        \"d3d11_level10_0\": {\n+            \"extensions\": {\n+                \"VK_EXT_transform_feedback\": 1\n+            },\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"fullDrawIndexUint32\": true,\n+                    \"shaderImageGatherExtended\": true\n+                },\n+                \"VkPhysicalDeviceTransformFeedbackFeaturesEXT\": {\n+                    \"transformFeedback\": true,\n+                    \"geometryStreams\": true\n+                }\n+            }\n+        },\n+        \"d3d11_level10_0_optional\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"logicOp\": true,\n+                    \"variableMultisampleRate\": true\n+                }\n+            }\n+        },\n+        \"d3d11_level10_1\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"dualSrcBlend\": true,\n+                    \"imageCubeArray\": true\n+                }\n+            }\n+        },\n+        \"d3d11_level11_0\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"drawIndirectFirstInstance\": true,\n+                    \"fragmentStoresAndAtomics\": true,\n+                    \"multiDrawIndirect\": true,\n+                    \"tessellationShader\": true\n+                }\n+            }\n+        },\n+        \"d3d11_level11_0_optional\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"shaderFloat64\": true,\n+                    \"shaderInt64\": true,\n+                    \"shaderStorageImageReadWithoutFormat\": true\n+                }\n+            }\n+        },\n+        \"d3d11_level11_1\": {\n+            \"features\": {\n+                \"VkPhysicalDeviceFeatures\": {\n+                    \"logicOp\": true,\n+                    \"variableMultisampleRate\": true,\n+                    \"vertexPipelineStoresAndAtomics\": true\n+                }\n+            }\n+        },\n+        \"d3d11_level12_0\": {\n+            \"properties\": {\n+                \"VkPhysicalDeviceProperties\": {\n+                    \"sparseProperties\": {\n+                        \"residencyStandard2DBlockShape\": true,\n+                        \"residencyAlignedMipSize\": true\n+                    }\n+                }\n+            }\n+        }\n+    },\n+    \"profiles\": {\n+        \"VP_DXVK_d3d9_baseline\": {\n+            \"version\": 1,\n+            \"api-version\": \"1.3.204\",\n+            \"label\": \"DXVK D3D9 Baseline profile\",\n+            \"description\": \"DXVK for D3D9 minimum requirements\",\n+            \"contributors\": {\n+                \"Philip Rebohle\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Joshua Ashton\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Pierre-Loup A. Griffais\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Georg Lehmann\": {\n+                    \"company\": \"DXVK\"\n+                },\n+                \"Christophe Riccio\": {\n+                    \"company\": \"LunarG\"\n+                }\n+            },\n+            \"history\": [\n+                {\n+                    \"revision\": 1,\n+                    \"date\": \"2022-08-22\",\n+                    \"author\": \"Christophe Riccio\",\n+                    \"comment\": \"Initial revision\"\n+                }\n+            ],\n+            \"capabilities\": [\n+                \"vulkan10requirements\",\n+                \"vulkan11requirements\",\n+                \"vulkan12requirements\",\n+                \"vulkan13requirements\",\n+                \"d3d9_baseline\"\n+            ]\n+        },\n+        \"VP_DXVK_d3d9_optimal\": {\n+            \"version\": 1,\n+            \"api-version\": \"1.3.224\",\n+            \"label\": \"DXVK D3D9 Optimal profile\",\n+            \"description\": \"DXVK for D3D9 including optional capabilities\",\n+            \"contributors\": {\n+                \"Philip Rebohle\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Joshua Ashton\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Pierre-Loup A. Griffais\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Georg Lehmann\": {\n+                    \"company\": \"DXVK\"\n+                },\n+                \"Christophe Riccio\": {\n+                    \"company\": \"LunarG\"\n+                }\n+            },\n+            \"history\": [\n+                {\n+                    \"revision\": 1,\n+                    \"date\": \"2022-08-22\",\n+                    \"author\": \"Christophe Riccio\",\n+                    \"comment\": \"Initial revision\"\n+                }\n+            ],\n+            \"capabilities\": [\n+                \"vulkan10requirements\",\n+                \"vulkan11requirements\",\n+                \"vulkan12requirements\",\n+                \"vulkan13requirements\",\n+                \"d3d9_baseline\",\n+                \"d3d9_optional\"\n+            ]\n+        },\n+        \"VP_DXVK_d3d10_level_10_1_baseline\": {\n+            \"version\": 1,\n+            \"api-version\": \"1.3.204\",\n+            \"label\": \"DXVK D3D10 Level 10.1 Baseline profile\",\n+            \"description\": \"DXVK for D3D10 Feature Level 10.1 minimum requirements\",\n+            \"contributors\": {\n+                \"Philip Rebohle\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Joshua Ashton\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Pierre-Loup A. Griffais\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Georg Lehmann\": {\n+                    \"company\": \"DXVK\"\n+                },\n+                \"Christophe Riccio\": {\n+                    \"company\": \"LunarG\"\n+                }\n+            },\n+            \"history\": [\n+                {\n+                    \"revision\": 1,\n+                    \"date\": \"2022-08-22\",\n+                    \"author\": \"Christophe Riccio\",\n+                    \"comment\": \"Initial revision\"\n+                }\n+            ],\n+            \"capabilities\": [\n+                \"vulkan10requirements\",\n+                \"vulkan11requirements\",\n+                \"vulkan12requirements\",\n+                \"vulkan13requirements\",\n+                \"d3d11_baseline\",\n+                \"d3d11_level9_1\",\n+                \"d3d11_level9_2\",\n+                \"d3d11_level9_3\",\n+                \"d3d11_level10_0\",\n+                \"d3d11_level10_1\"\n+            ]\n+        },\n+        \"VP_DXVK_d3d11_level_11_0_baseline\": {\n+            \"version\": 1,\n+            \"api-version\": \"1.3.204\",\n+            \"label\": \"DXVK D3D11 Level 11.0 Baseline profile\",\n+            \"description\": \"DXVK for D3D11 Feature Level 11.0 minimum requirements\",\n+            \"contributors\": {\n+                \"Philip Rebohle\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Joshua Ashton\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Pierre-Loup A. Griffais\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Georg Lehmann\": {\n+                    \"company\": \"DXVK\"\n+                },\n+                \"Christophe Riccio\": {\n+                    \"company\": \"LunarG\"\n+                }\n+            },\n+            \"history\": [\n+                {\n+                    \"revision\": 1,\n+                    \"date\": \"2022-08-22\",\n+                    \"author\": \"Christophe Riccio\",\n+                    \"comment\": \"Initial revision\"\n+                }\n+            ],\n+            \"capabilities\": [\n+                \"vulkan10requirements\",\n+                \"vulkan11requirements\",\n+                \"vulkan12requirements\",\n+                \"vulkan13requirements\",\n+                \"d3d11_baseline\",\n+                \"d3d11_level9_1\",\n+                \"d3d11_level9_2\",\n+                \"d3d11_level9_3\",\n+                \"d3d11_level10_0\",\n+                \"d3d11_level10_1\",\n+                \"d3d11_level11_0\"\n+            ]\n+        },\n+        \"VP_DXVK_d3d11_level_11_1_baseline\": {\n+            \"version\": 1,\n+            \"api-version\": \"1.3.204\",\n+            \"label\": \"DXVK D3D11 Level 11.1 Baseline profile\",\n+            \"description\": \"DXVK for D3D11 Feature Level 11.1 minimum requirements\",\n+            \"contributors\": {\n+                \"Philip Rebohle\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Joshua Ashton\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Pierre-Loup A. Griffais\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Georg Lehmann\": {\n+                    \"company\": \"DXVK\"\n+                },\n+                \"Christophe Riccio\": {\n+                    \"company\": \"LunarG\"\n+                }\n+            },\n+            \"history\": [\n+                {\n+                    \"revision\": 1,\n+                    \"date\": \"2022-08-22\",\n+                    \"author\": \"Christophe Riccio\",\n+                    \"comment\": \"Initial revision\"\n+                }\n+            ],\n+            \"capabilities\": [\n+                \"vulkan10requirements\",\n+                \"vulkan11requirements\",\n+                \"vulkan12requirements\",\n+                \"vulkan13requirements\",\n+                \"baseline\",\n+                \"d3d11_level9_1\",\n+                \"d3d11_level9_2\",\n+                \"d3d11_level9_3\",\n+                \"d3d11_level10_0\",\n+                \"d3d11_level10_1\",\n+                \"d3d11_level11_0\",\n+                \"d3d11_level11_1\"\n+            ]\n+        },\n+        \"VP_DXVK_d3d11_level_11_1_optimal\": {\n+            \"version\": 1,\n+            \"api-version\": \"1.3.204\",\n+            \"label\": \"DXVK D3D11 Level 11.1 Optimal profile\",\n+            \"description\": \"DXVK for D3D11 Feature Level 11.1 including optional capabilities\",\n+            \"contributors\": {\n+                \"Philip Rebohle\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Joshua Ashton\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Pierre-Loup A. Griffais\": {\n+                    \"company\": \"Valve\"\n+                },\n+                \"Georg Lehmann\": {\n+                    \"company\": \"DXVK\"\n+                },\n+                \"Christophe Riccio\": {\n+                    \"company\": \"LunarG\"\n+                }\n+            },\n+            \"history\": [\n+                {\n+                    \"revision\": 1,\n+                    \"date\": \"2022-08-22\",\n+                    \"author\": \"Christophe Riccio\",\n+                    \"comment\": \"Initial revision\"\n+                }\n+            ],\n+            \"capabilities\": [\n+                \"vulkan10requirements\",\n+                \"vulkan11requirements\",\n+                \"vulkan12requirements\",\n+                \"vulkan13requirements\",\n+                \"d3d11_baseline\",\n+                \"d3d11_baseline_optional\",\n+                \"d3d11_level9_1\",\n+                \"d3d11_level9_1_optional\",\n+                \"d3d11_level9_2\",\n+                \"d3d11_level9_3\",\n+                \"d3d11_level10_0\",\n+                \"d3d11_level10_0_optional\",\n+                \"d3d11_level10_1\",\n+                \"d3d11_level11_0\",\n+                \"d3d11_level11_0_optional\",\n+                \"d3d11_level11_1\"\n+            ]\n+        }\n+    }\n+}\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Implement a JSON profile for DXVK 1.10.3 requirements; consider including it in a 1.10.4 release.\n2. Address how to encode optional features in the JSON profiles; current implementation is suboptimal.\n3. Revise the `VP_DXVK_level9_baseline` structure to include optional features; use the suggested nesting format.\n4. Ensure device properties, such as `residencyStandard2DBlockShape` being `VK_TRUE`, can be expressed in profiles for Feature Level 12_0.\n5. Update shader demotion handling to set `enabled.vk13.shaderDemoteToHelperInvocation = VK_TRUE` to comply with Vulkan 1.3.\n6. Confirm that merged profiles align with project requirements; section separation for D3D9 and D3D11 must be maintained due to differing requirements."
      }
    ],
    "codediff_length": 21534
  },
  {
    "index": 57,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/meson.build b/meson.build\nindex 2174ede04dd..d70e65ef84a 100644\n--- a/meson.build\n+++ b/meson.build\n@@ -25,6 +25,8 @@ else\n   dxvk_library_path = meson.source_root() + '/lib32'\n endif\n \n+wrc = cpu_family == 'x86_64' ? find_program('x86_64-w64-mingw32-windres') : find_program('i686-w64-mingw32-windres')\n+\n code = '''#ifndef __WINE__\n #error 1\n #endif'''\ndiff --git a/src/d3d10/meson.build b/src/d3d10/meson.build\nindex 899de196e39..f3da0c5f6e2 100644\n--- a/src/d3d10/meson.build\n+++ b/src/d3d10/meson.build\n@@ -1,3 +1,24 @@\n+d3d10_res = custom_target(\n+  'version10.res',\n+  input   : 'version10.rc',\n+  output  : 'version10.o',\n+  command : [ wrc, '@INPUT@', '@OUTPUT@' ],\n+)\n+\n+d3d10_1_res = custom_target(\n+  'version10_1.res',\n+  input   : 'version10_1.rc',\n+  output  : 'version10_1.o',\n+  command : [ wrc, '@INPUT@', '@OUTPUT@' ],\n+)\n+\n+d3d10_core_res = custom_target(\n+  'version10_core.res',\n+  input   : 'version10_core.rc',\n+  output  : 'version10_core.o',\n+  command : [ wrc, '@INPUT@', '@OUTPUT@' ],\n+)\n+\n d3d10_main_src = [\n   'd3d10_main.cpp',\n   'd3d10_reflection.cpp',\n@@ -6,7 +27,7 @@ d3d10_main_src = [\n d3d10_deps = [ lib_d3dcompiler_43, lib_dxgi ]\n d3d10_deps += dxvk_winelib ? lib_d3d11 : d3d11_dep\n \n-d3d10_core_dll = shared_library('d3d10core'+dll_ext, d3d10_main_src,\n+d3d10_core_dll = shared_library('d3d10core'+dll_ext, d3d10_main_src, not dxvk_winelib ? d3d10_core_res : [],\n   name_prefix         : '',\n   dependencies        : [ d3d10_deps, dxbc_dep, dxvk_dep ],\n   include_directories : dxvk_include_path,\n@@ -15,7 +36,7 @@ d3d10_core_dll = shared_library('d3d10core'+dll_ext, d3d10_main_src,\n   vs_module_defs      : 'd3d10core'+def_spec_ext,\n   override_options    : ['cpp_std='+dxvk_cpp_std])\n \n-d3d10_dll = shared_library('d3d10'+dll_ext, d3d10_main_src,\n+d3d10_dll = shared_library('d3d10'+dll_ext, d3d10_main_src, not dxvk_winelib ? d3d10_res : [],\n   name_prefix         : '',\n   dependencies        : [ d3d10_deps, dxbc_dep, dxvk_dep ],\n   include_directories : dxvk_include_path,\n@@ -24,7 +45,7 @@ d3d10_dll = shared_library('d3d10'+dll_ext, d3d10_main_src,\n   vs_module_defs      : 'd3d10'+def_spec_ext,\n   override_options    : ['cpp_std='+dxvk_cpp_std])\n \n-d3d10_1_dll = shared_library('d3d10_1'+dll_ext, d3d10_main_src,\n+d3d10_1_dll = shared_library('d3d10_1'+dll_ext, d3d10_main_src, not dxvk_winelib ? d3d10_1_res : [],\n   name_prefix         : '',\n   dependencies        : [ d3d10_deps, dxbc_dep, dxvk_dep ],\n   include_directories : dxvk_include_path,\ndiff --git a/src/d3d10/version10.rc b/src/d3d10/version10.rc\nnew file mode 100644\nindex 00000000000..43d7a62fdbf\n--- /dev/null\n+++ b/src/d3d10/version10.rc\n@@ -0,0 +1,32 @@\n+#include <windows.h>\n+\n+// DLL version information.\n+VS_VERSION_INFO    VERSIONINFO\n+FILEVERSION        10,0,17763,1\n+PRODUCTVERSION     10,0,17763,1\n+FILEFLAGSMASK      VS_FFI_FILEFLAGSMASK\n+FILEFLAGS          0\n+FILEOS VOS_NT_WINDOWS32\n+FILETYPE VFT_DLL\n+FILESUBTYPE VFT2_UNKNOWN\n+BEGIN\n+  BLOCK \"StringFileInfo\"\n+  BEGIN\n+    BLOCK \"080904b0\"\n+    BEGIN\n+      VALUE \"CompanyName\",      \"DXVK\"\n+      VALUE \"FileDescription\",  \"Direct3D 10 Runtime\"\n+      VALUE \"FileVersion\",      \"10.0.17763.1 (WinBuild.160101.0800)\"\n+      VALUE \"InternalName\",     \"D3D10.dll\"\n+      VALUE \"LegalCopyright\",   \"zlib/libpng license\"\n+      VALUE \"OriginalFilename\", \"D3D10.dll\"\n+      VALUE \"ProductName\",      \"DXVK\"\n+      VALUE \"ProductVersion\",   \"10.0.17763.1\"\n+    END\n+  END\n+  BLOCK \"VarFileInfo\"\n+  BEGIN\n+    VALUE \"Translation\", 0x0809, 1200\n+  END\n+END\n+\ndiff --git a/src/d3d10/version10_1.rc b/src/d3d10/version10_1.rc\nnew file mode 100644\nindex 00000000000..92550d32254\n--- /dev/null\n+++ b/src/d3d10/version10_1.rc\n@@ -0,0 +1,32 @@\n+#include <windows.h>\n+\n+// DLL version information.\n+VS_VERSION_INFO    VERSIONINFO\n+FILEVERSION        10,0,17763,1\n+PRODUCTVERSION     10,0,17763,1\n+FILEFLAGSMASK      VS_FFI_FILEFLAGSMASK\n+FILEFLAGS          0\n+FILEOS VOS_NT_WINDOWS32\n+FILETYPE VFT_DLL\n+FILESUBTYPE VFT2_UNKNOWN\n+BEGIN\n+  BLOCK \"StringFileInfo\"\n+  BEGIN\n+    BLOCK \"080904b0\"\n+    BEGIN\n+      VALUE \"CompanyName\",      \"DXVK\"\n+      VALUE \"FileDescription\",  \"Direct3D 10.1 Runtime\"\n+      VALUE \"FileVersion\",      \"10.0.17763.1 (WinBuild.160101.0800)\"\n+      VALUE \"InternalName\",     \"D3D10_1.dll\"\n+      VALUE \"LegalCopyright\",   \"zlib/libpng license\"\n+      VALUE \"OriginalFilename\", \"D3D10_1.dll\"\n+      VALUE \"ProductName\",      \"DXVK\"\n+      VALUE \"ProductVersion\",   \"10.0.17763.1\"\n+    END\n+  END\n+  BLOCK \"VarFileInfo\"\n+  BEGIN\n+    VALUE \"Translation\", 0x0809, 1200\n+  END\n+END\n+\ndiff --git a/src/d3d10/version10_core.rc b/src/d3d10/version10_core.rc\nnew file mode 100644\nindex 00000000000..30e0c056b3b\n--- /dev/null\n+++ b/src/d3d10/version10_core.rc\n@@ -0,0 +1,32 @@\n+#include <windows.h>\n+\n+// DLL version information.\n+VS_VERSION_INFO    VERSIONINFO\n+FILEVERSION        10,0,17763,1\n+PRODUCTVERSION     10,0,17763,1\n+FILEFLAGSMASK      VS_FFI_FILEFLAGSMASK\n+FILEFLAGS          0\n+FILEOS VOS_NT_WINDOWS32\n+FILETYPE VFT_DLL\n+FILESUBTYPE VFT2_UNKNOWN\n+BEGIN\n+  BLOCK \"StringFileInfo\"\n+  BEGIN\n+    BLOCK \"080904b0\"\n+    BEGIN\n+      VALUE \"CompanyName\",      \"DXVK\"\n+      VALUE \"FileDescription\",  \"Direct3D 10 Runtime\"\n+      VALUE \"FileVersion\",      \"10.0.17763.1 (WinBuild.160101.0800)\"\n+      VALUE \"InternalName\",     \"D3D10Core.dll\"\n+      VALUE \"LegalCopyright\",   \"zlib/libpng license\"\n+      VALUE \"OriginalFilename\", \"D3D10Core.dll\"\n+      VALUE \"ProductName\",      \"DXVK\"\n+      VALUE \"ProductVersion\",   \"10.0.17763.1\"\n+    END\n+  END\n+  BLOCK \"VarFileInfo\"\n+  BEGIN\n+    VALUE \"Translation\", 0x0809, 1200\n+  END\n+END\n+\ndiff --git a/src/d3d11/meson.build b/src/d3d11/meson.build\nindex 15ae3d0eaef..09c2ae667aa 100644\n--- a/src/d3d11/meson.build\n+++ b/src/d3d11/meson.build\n@@ -1,3 +1,10 @@\n+d3d11_res = custom_target(\n+  'version_11.res',\n+  input   : 'version.rc',\n+  output  : 'version.o',\n+  command : [ wrc, '@INPUT@', '@OUTPUT@' ],\n+)\n+\n dxgi_common_src = [\n   '../dxgi/dxgi_format.cpp',\n   '../dxgi/dxgi_monitor.cpp',\n@@ -54,7 +61,7 @@ d3d11_src = [\n   'd3d11_view_uav.cpp',\n ]\n \n-d3d11_dll = shared_library('d3d11'+dll_ext, dxgi_common_src + d3d11_src + d3d10_src, glsl_generator.process(dxgi_shaders),\n+d3d11_dll = shared_library('d3d11'+dll_ext, dxgi_common_src + d3d11_src + d3d10_src, glsl_generator.process(dxgi_shaders), not dxvk_winelib ? d3d11_res : [],\n   name_prefix         : '',\n   dependencies        : [ lib_dxgi, dxbc_dep, dxvk_dep ],\n   include_directories : dxvk_include_path,\ndiff --git a/src/d3d11/version.rc b/src/d3d11/version.rc\nnew file mode 100644\nindex 00000000000..060ef7bc2cc\n--- /dev/null\n+++ b/src/d3d11/version.rc\n@@ -0,0 +1,32 @@\n+#include <windows.h>\n+\n+// DLL version information.\n+VS_VERSION_INFO    VERSIONINFO\n+FILEVERSION        10,0,17763,1\n+PRODUCTVERSION     10,0,17763,1\n+FILEFLAGSMASK      VS_FFI_FILEFLAGSMASK\n+FILEFLAGS          0\n+FILEOS VOS_NT_WINDOWS32\n+FILETYPE VFT_DLL\n+FILESUBTYPE VFT2_UNKNOWN\n+BEGIN\n+  BLOCK \"StringFileInfo\"\n+  BEGIN\n+    BLOCK \"080904b0\"\n+    BEGIN\n+      VALUE \"CompanyName\",      \"DXVK\"\n+      VALUE \"FileDescription\",  \"Direct3D 11 Runtime\"\n+      VALUE \"FileVersion\",      \"10.0.17763.1 (WinBuild.160101.0800)\"\n+      VALUE \"InternalName\",     \"D3D11.dll\"\n+      VALUE \"LegalCopyright\",   \"zlib/libpng license\"\n+      VALUE \"OriginalFilename\", \"D3D11.dll\"\n+      VALUE \"ProductName\",      \"DXVK\"\n+      VALUE \"ProductVersion\",   \"10.0.17763.1\"\n+    END\n+  END\n+  BLOCK \"VarFileInfo\"\n+  BEGIN\n+    VALUE \"Translation\", 0x0809, 1200\n+  END\n+END\n+\ndiff --git a/src/dxgi/meson.build b/src/dxgi/meson.build\nindex 18d74816731..1060dd61b37 100644\n--- a/src/dxgi/meson.build\n+++ b/src/dxgi/meson.build\n@@ -1,3 +1,10 @@\n+dxgi_res = custom_target(\n+  'version_dxgi.res',\n+  input   : 'version.rc',\n+  output  : 'version.o',\n+  command : [ wrc, '@INPUT@', '@OUTPUT@' ],\n+)\n+\n dxgi_shaders = files([\n   'shaders/dxgi_presenter_frag.frag',\n   'shaders/dxgi_presenter_vert.vert',\n@@ -15,7 +22,7 @@ dxgi_src = [\n   'dxgi_swapchain.cpp',\n ]\n \n-dxgi_dll = shared_library('dxgi'+dll_ext, dxgi_src,\n+dxgi_dll = shared_library('dxgi'+dll_ext, dxgi_src, not dxvk_winelib ? dxgi_res : [],\n   name_prefix         : '',\n   dependencies        : [ dxvk_dep ],\n   include_directories : dxvk_include_path,\ndiff --git a/src/dxgi/version.rc b/src/dxgi/version.rc\nnew file mode 100644\nindex 00000000000..9461d71839e\n--- /dev/null\n+++ b/src/dxgi/version.rc\n@@ -0,0 +1,32 @@\n+#include <windows.h>\n+\n+// DLL version information.\n+VS_VERSION_INFO    VERSIONINFO\n+FILEVERSION        10,0,17763,1\n+PRODUCTVERSION     10,0,17763,1\n+FILEFLAGSMASK      VS_FFI_FILEFLAGSMASK\n+FILEFLAGS          0\n+FILEOS VOS_NT_WINDOWS32\n+FILETYPE VFT_DLL\n+FILESUBTYPE VFT2_UNKNOWN\n+BEGIN\n+  BLOCK \"StringFileInfo\"\n+  BEGIN\n+    BLOCK \"080904b0\"\n+    BEGIN\n+      VALUE \"CompanyName\",      \"DXVK\"\n+      VALUE \"FileDescription\",  \"DirectX Graphics Infrastructure\"\n+      VALUE \"FileVersion\",      \"10.0.17763.1 (WinBuild.160101.0800)\"\n+      VALUE \"InternalName\",     \"dxgi.dll\"\n+      VALUE \"LegalCopyright\",   \"zlib/libpng license\"\n+      VALUE \"OriginalFilename\", \"dxgi.dll\"\n+      VALUE \"ProductName\",      \"DXVK\"\n+      VALUE \"ProductVersion\",   \"10.0.17763.1\"\n+    END\n+  END\n+  BLOCK \"VarFileInfo\"\n+  BEGIN\n+    VALUE \"Translation\", 0x0809, 1200\n+  END\n+END\n+\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. The `winelib` build doesn't pass DLL version info due to symlinking with fakedlls; current implementation keeps `--winelib` unchanged.\n2. Avoid using MinGW for `winelib` builds, maintain compatibility with Wine's wrc; report any differing experiences.\n3. Modify `meson.build` to implement `wrc` and `winebuild` commands consistently within the `dxvk_winelib` block (as shown in the proposed patch).\n4. Adjust target installation paths to `libdir/fakedlls` for DLL outputs.\n5. Proposal to leave out unnecessary `winelib` fakedll implementation unless a clear benefit becomes apparent; may require reversions of unintended commits.\n6. Confirm fix for compilation issues on winelib systems when MinGW isn't present; ensure user-friendly builds."
      }
    ],
    "codediff_length": 9313
  },
  {
    "index": 58,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/libraries/BluetoothSerial/examples/SerialToSerialBTM/SerialToSerialBTM.ino b/libraries/BluetoothSerial/examples/SerialToSerialBTM/SerialToSerialBTM.ino\nnew file mode 100644\nindex 00000000000..73f3dc058b4\n--- /dev/null\n+++ b/libraries/BluetoothSerial/examples/SerialToSerialBTM/SerialToSerialBTM.ino\n@@ -0,0 +1,56 @@\n+//This example code is in the Public Domain (or CC0 licensed, at your option.)\n+//By Victor Tchistiak - 2019\n+//\n+//This example demostrates master mode bluetooth connection and pin \n+//it creates a bridge between Serial and Classical Bluetooth (SPP)\n+//this is an extention of the SerialToSerialBT example by Evandro Copercini - 2018\n+//\n+\n+#include \"BluetoothSerial.h\"\n+\n+BluetoothSerial SerialBT;\n+\n+String MACadd = \"AA:BB:CC:11:22:33\";\n+uint8_t address[6]  = {0xAA, 0xBB, 0xCC, 0x11, 0x22, 0x33};\n+//uint8_t address[6]  = {0x00, 0x1D, 0xA5, 0x02, 0xC3, 0x22};\n+String name = \"OBDII\";\n+char *pin = \"1234\"; //<- standard pin would be provided by default\n+bool connected;\n+\n+void setup() {\n+  Serial.begin(115200);\n+  //SerialBT.setPin(pin);\n+  SerialBT.begin(\"ESP32test\", true); \n+  //SerialBT.setPin(pin);\n+  Serial.println(\"The device started in master mode, make sure remote BT device is on!\");\n+  \n+  // connect(address) is fast (upto 10 secs max), connect(name) is slow (upto 30 secs max) as it needs\n+  // to resolve name to address first, but it allows to connect to different devices with the same name.\n+  // Set CoreDebugLevel to Info to view devices bluetooth address and device names\n+  connected = SerialBT.connect(name);\n+  //connected = SerialBT.connect(address);\n+  \n+  if(connected) {\n+    Serial.println(\"Connected Succesfully!\");\n+  } else {\n+    while(!SerialBT.connected(10000)) {\n+      Serial.println(\"Failed to connect. Make sure remote device is available and in range, then restart app.\"); \n+    }\n+  }\n+  // disconnect() may take upto 10 secs max\n+  if (SerialBT.disconnect()) {\n+    Serial.println(\"Disconnected Succesfully!\");\n+  }\n+  // this would reconnect to the name(will use address, if resolved) or address used with connect(name/address).\n+  SerialBT.connect();\n+}\n+\n+void loop() {\n+  if (Serial.available()) {\n+    SerialBT.write(Serial.read());\n+  }\n+  if (SerialBT.available()) {\n+    Serial.write(SerialBT.read());\n+  }\n+  delay(20);\n+}\ndiff --git a/libraries/BluetoothSerial/examples/bt_remove_paired_devices/bt_remove_paired_devices.ino b/libraries/BluetoothSerial/examples/bt_remove_paired_devices/bt_remove_paired_devices.ino\nnew file mode 100755\nindex 00000000000..c316a73b2bc\n--- /dev/null\n+++ b/libraries/BluetoothSerial/examples/bt_remove_paired_devices/bt_remove_paired_devices.ino\n@@ -0,0 +1,87 @@\n+//This example code is in the Public Domain (or CC0 licensed, at your option.)\n+//By Victor Tchistiak - 2019\n+//\n+//This example demonstrates reading and removing paired devices stored on the ESP32 flash memory\n+//Sometimes you may find your ESP32 device could not connect to the remote device despite\n+//many successful connections earlier. This is most likely a result of client replacing your paired\n+//device info with new one from other device. The BT clients store connection info for paired devices,\n+//but it is limited to a few devices only. When new device pairs and number of stored devices is exceeded,\n+//one of the previously paired devices would be replaced with new one.\n+//The only remedy is to delete this saved bound device from your device flash memory\n+//and pair with the other device again.\n+//\n+#include \"esp_bt_main.h\"\n+#include \"esp_bt_device.h\"\n+#include\"esp_gap_bt_api.h\"\n+#include \"esp_err.h\"\n+\n+#define REMOVE_BONDED_DEVICES 0   // <- Set to 0 to view all bonded devices addresses, set to 1 to remove\n+\n+#define PAIR_MAX_DEVICES 20\n+uint8_t pairedDeviceBtAddr[PAIR_MAX_DEVICES][6];\n+char bda_str[18];\n+\n+bool initBluetooth()\n+{\n+  if(!btStart()) {\n+    Serial.println(\"Failed to initialize controller\");\n+    return false;\n+  }\n+ \n+  if(esp_bluedroid_init() != ESP_OK) {\n+    Serial.println(\"Failed to initialize bluedroid\");\n+    return false;\n+  }\n+ \n+  if(esp_bluedroid_enable() != ESP_OK) {\n+    Serial.println(\"Failed to enable bluedroid\");\n+    return false;\n+  }\n+  return true;\n+}\n+\n+char *bda2str(const uint8_t* bda, char *str, size_t size)\n+{\n+  if (bda == NULL || str == NULL || size < 18) {\n+    return NULL;\n+  }\n+  sprintf(str, \"%02x:%02x:%02x:%02x:%02x:%02x\",\n+          bda[0], bda[1], bda[2], bda[3], bda[4], bda[5]);\n+  return str;\n+}\n+ \n+void setup() {\n+  Serial.begin(115200);\n+ \n+  initBluetooth();\n+  Serial.print(\"ESP32 bluetooth address: \"); Serial.println(bda2str(esp_bt_dev_get_address(), bda_str, 18));\n+  // Get the numbers of bonded/paired devices in the BT module\n+  int count = esp_bt_gap_get_bond_device_num();\n+  if(!count) {\n+    Serial.println(\"No bonded device found.\");\n+  } else {\n+    Serial.print(\"Bonded device count: \"); Serial.println(count);\n+    if(PAIR_MAX_DEVICES < count) {\n+      count = PAIR_MAX_DEVICES; \n+      Serial.print(\"Reset bonded device count: \"); Serial.println(count);\n+    }\n+    esp_err_t tError =  esp_bt_gap_get_bond_device_list(&count, pairedDeviceBtAddr);\n+    if(ESP_OK == tError) {\n+      for(int i = 0; i < count; i++) {\n+        Serial.print(\"Found bonded device # \"); Serial.print(i); Serial.print(\" -> \");\n+        Serial.println(bda2str(pairedDeviceBtAddr[i], bda_str, 18));     \n+        if(REMOVE_BONDED_DEVICES) {\n+          esp_err_t tError = esp_bt_gap_remove_bond_device(pairedDeviceBtAddr[i]);\n+          if(ESP_OK == tError) {\n+            Serial.print(\"Removed bonded device # \"); \n+          } else {\n+            Serial.print(\"Failed to remove bonded device # \");\n+          }\n+          Serial.println(i);\n+        }\n+      }        \n+    }\n+  }\n+}\n+ \n+void loop() {}\ndiff --git a/libraries/BluetoothSerial/src/BluetoothSerial.cpp b/libraries/BluetoothSerial/src/BluetoothSerial.cpp\nold mode 100644\nnew mode 100755\nindex d3d09216303..758ee08c296\n--- a/libraries/BluetoothSerial/src/BluetoothSerial.cpp\n+++ b/libraries/BluetoothSerial/src/BluetoothSerial.cpp\n@@ -53,15 +53,80 @@ static EventGroupHandle_t _spp_event_group = NULL;\n static boolean secondConnectionAttempt;\n static esp_spp_cb_t * custom_spp_callback = NULL;\n \n+#define INQ_LEN 0x10\n+#define INQ_NUM_RSPS 20\n+#define READY_TIMEOUT (10 * 1000)\n+#define SCAN_TIMEOUT (INQ_LEN * 2 * 1000)\n+static esp_bd_addr_t _peer_bd_addr;\n+static char _remote_name[ESP_BT_GAP_MAX_BDNAME_LEN + 1];\n+static bool _isRemoteAddressSet;\n+static bool _isMaster;\n+static esp_bt_pin_code_t _pin_code;\n+static int _pin_len;\n+static bool _isPinSet;\n+static bool _enableSSP;\n+\n #define SPP_RUNNING     0x01\n #define SPP_CONNECTED   0x02\n #define SPP_CONGESTED   0x04\n+#define SPP_DISCONNECTED 0x08\n \n typedef struct {\n         size_t len;\n         uint8_t data[];\n } spp_packet_t;\n \n+static char *bda2str(esp_bd_addr_t bda, char *str, size_t size)\n+{\n+  if (bda == NULL || str == NULL || size < 18) {\n+    return NULL;\n+  }\n+\n+  uint8_t *p = bda;\n+  sprintf(str, \"%02x:%02x:%02x:%02x:%02x:%02x\",\n+          p[0], p[1], p[2], p[3], p[4], p[5]);\n+  return str;\n+}\n+\n+static bool get_name_from_eir(uint8_t *eir, char *bdname, uint8_t *bdname_len)\n+{\n+    if (!eir || !bdname || !bdname_len) {\n+        return false;\n+    }\n+\n+    uint8_t *rmt_bdname, rmt_bdname_len;\n+    *bdname = *bdname_len = rmt_bdname_len = 0;\n+\n+    rmt_bdname = esp_bt_gap_resolve_eir_data(eir, ESP_BT_EIR_TYPE_CMPL_LOCAL_NAME, &rmt_bdname_len);\n+    if (!rmt_bdname) {\n+        rmt_bdname = esp_bt_gap_resolve_eir_data(eir, ESP_BT_EIR_TYPE_SHORT_LOCAL_NAME, &rmt_bdname_len);\n+    }\n+    if (rmt_bdname) {\n+        rmt_bdname_len = rmt_bdname_len > ESP_BT_GAP_MAX_BDNAME_LEN ? ESP_BT_GAP_MAX_BDNAME_LEN : rmt_bdname_len;\n+        memcpy(bdname, rmt_bdname, rmt_bdname_len);\n+        bdname[rmt_bdname_len] = 0;\n+        *bdname_len = rmt_bdname_len;\n+        return true;\n+    }\n+    return false;\n+}\n+\n+static bool btSetPin() {\n+    esp_bt_pin_type_t pin_type;\n+    if (_isPinSet) {\n+        if (_pin_len) {\n+            log_i(\"pin set\");\n+            pin_type = ESP_BT_PIN_TYPE_FIXED;\n+        } else {\n+            _isPinSet = false;\n+            log_i(\"pin reset\");\n+            pin_type = ESP_BT_PIN_TYPE_VARIABLE; // pin_code would be ignored (default)\n+        }\n+        return (esp_bt_gap_set_pin(pin_type, _pin_len, _pin_code) == ESP_OK);        \n+    }\n+    return false;\n+}\n+\n static esp_err_t _spp_queue_packet(uint8_t *data, size_t len){\n     if(!data || !len){\n         log_w(\"No data provided\");\n@@ -159,29 +224,34 @@ static void esp_spp_cb(esp_spp_cb_event_t event, esp_spp_cb_param_t *param)\n     case ESP_SPP_INIT_EVT:\n         log_i(\"ESP_SPP_INIT_EVT\");\n         esp_bt_gap_set_scan_mode(ESP_BT_SCAN_MODE_CONNECTABLE_DISCOVERABLE);\n-        esp_spp_start_srv(ESP_SPP_SEC_NONE, ESP_SPP_ROLE_SLAVE, 0, _spp_server_name);\n+        if (!_isMaster) {\n+            log_i(\"ESP_SPP_INIT_EVT: slave: start\");\n+            esp_spp_start_srv(ESP_SPP_SEC_NONE, ESP_SPP_ROLE_SLAVE, 0, _spp_server_name);\n+        }\n         xEventGroupSetBits(_spp_event_group, SPP_RUNNING);\n         break;\n \n     case ESP_SPP_SRV_OPEN_EVT://Server connection open\n+        log_i(\"ESP_SPP_SRV_OPEN_EVT\");\n         if (!_spp_client){\n             _spp_client = param->open.handle;\n         } else {\n             secondConnectionAttempt = true;\n             esp_spp_disconnect(param->open.handle);\n         }\n+        xEventGroupClearBits(_spp_event_group, SPP_DISCONNECTED);\n         xEventGroupSetBits(_spp_event_group, SPP_CONNECTED);\n-        log_i(\"ESP_SPP_SRV_OPEN_EVT\");\n         break;\n \n     case ESP_SPP_CLOSE_EVT://Client connection closed\n+        log_i(\"ESP_SPP_CLOSE_EVT\");\n         if(secondConnectionAttempt) {\n             secondConnectionAttempt = false;\n         } else {\n             _spp_client = 0;\n-        }\n+            xEventGroupSetBits(_spp_event_group, SPP_DISCONNECTED);\n+        }        \n         xEventGroupClearBits(_spp_event_group, SPP_CONNECTED);\n-        log_i(\"ESP_SPP_CLOSE_EVT\");\n         break;\n \n     case ESP_SPP_CONG_EVT://connection congestion status changed\n@@ -216,25 +286,149 @@ static void esp_spp_cb(esp_spp_cb_event_t event, esp_spp_cb_param_t *param)\n         }\n         break;\n \n-        //should maybe delete those.\n     case ESP_SPP_DISCOVERY_COMP_EVT://discovery complete\n         log_i(\"ESP_SPP_DISCOVERY_COMP_EVT\");\n+        if (param->disc_comp.status == ESP_SPP_SUCCESS) {\n+            log_i(\"ESP_SPP_DISCOVERY_COMP_EVT: spp connect to remote\");\n+            esp_spp_connect(ESP_SPP_SEC_AUTHENTICATE, ESP_SPP_ROLE_MASTER, param->disc_comp.scn[0], _peer_bd_addr);\n+        }\n         break;\n+\n     case ESP_SPP_OPEN_EVT://Client connection open\n         log_i(\"ESP_SPP_OPEN_EVT\");\n+        if (!_spp_client){\n+                _spp_client = param->open.handle;\n+        } else {\n+            secondConnectionAttempt = true;\n+            esp_spp_disconnect(param->open.handle);\n+        }\n+        xEventGroupClearBits(_spp_event_group, SPP_DISCONNECTED);\n+        xEventGroupSetBits(_spp_event_group, SPP_CONNECTED);\n         break;\n+\n     case ESP_SPP_START_EVT://server started\n         log_i(\"ESP_SPP_START_EVT\");\n         break;\n+\n     case ESP_SPP_CL_INIT_EVT://client initiated a connection\n         log_i(\"ESP_SPP_CL_INIT_EVT\");\n         break;\n+\n     default:\n         break;\n     }\n     if(custom_spp_callback)(*custom_spp_callback)(event, param);\n }\n \n+static void esp_bt_gap_cb(esp_bt_gap_cb_event_t event, esp_bt_gap_cb_param_t *param)\n+{\n+    switch(event){\n+        case ESP_BT_GAP_DISC_RES_EVT:\n+            log_i(\"ESP_BT_GAP_DISC_RES_EVT\");\n+            char bda_str[18];\n+            log_i(\"Scanned device: %s\", bda2str(param->disc_res.bda, bda_str, 18));\n+            for (int i = 0; i < param->disc_res.num_prop; i++) {\n+                uint8_t peer_bdname_len;\n+                char peer_bdname[ESP_BT_GAP_MAX_BDNAME_LEN + 1];\n+                switch(param->disc_res.prop[i].type) {\n+                    case ESP_BT_GAP_DEV_PROP_EIR:  \n+                        if (get_name_from_eir((uint8_t*)param->disc_res.prop[i].val, peer_bdname, &peer_bdname_len)) {\n+                            log_i(\"ESP_BT_GAP_DISC_RES_EVT : EIR : %s : %d\", peer_bdname, peer_bdname_len);\n+                            if (strlen(_remote_name) == peer_bdname_len\n+                                && strncmp(peer_bdname, _remote_name, peer_bdname_len) == 0) {\n+                                log_v(\"ESP_BT_GAP_DISC_RES_EVT : SPP_START_DISCOVERY_EIR : %s\", peer_bdname, peer_bdname_len);\n+                                _isRemoteAddressSet = true;\n+                                memcpy(_peer_bd_addr, param->disc_res.bda, ESP_BD_ADDR_LEN);\n+                                esp_bt_gap_cancel_discovery();\n+                                esp_spp_start_discovery(_peer_bd_addr);\n+                            }\n+                        }\n+                        break;\n+\n+                    case ESP_BT_GAP_DEV_PROP_BDNAME:\n+                        peer_bdname_len = param->disc_res.prop[i].len;\n+                        memcpy(peer_bdname, param->disc_res.prop[i].val, peer_bdname_len);\n+                        peer_bdname_len--; // len includes 0 terminator\n+                        log_v(\"ESP_BT_GAP_DISC_RES_EVT : BDNAME :  %s : %d\", peer_bdname, peer_bdname_len);\n+                        if (strlen(_remote_name) == peer_bdname_len\n+                            && strncmp(peer_bdname, _remote_name, peer_bdname_len) == 0) {\n+                            log_i(\"ESP_BT_GAP_DISC_RES_EVT : SPP_START_DISCOVERY_BDNAME : %s\", peer_bdname);\n+                            _isRemoteAddressSet = true;\n+                            memcpy(_peer_bd_addr, param->disc_res.bda, ESP_BD_ADDR_LEN);\n+                            esp_bt_gap_cancel_discovery();\n+                            esp_spp_start_discovery(_peer_bd_addr);\n+                        } \n+                        break;\n+\n+                    case ESP_BT_GAP_DEV_PROP_COD:\n+                        //log_i(\"ESP_BT_GAP_DEV_PROP_COD\");\n+                        break;\n+\n+                    case ESP_BT_GAP_DEV_PROP_RSSI:\n+                        //log_i(\"ESP_BT_GAP_DEV_PROP_RSSI\");\n+                        break;\n+                        \n+                    default:\n+                        break;\n+                }\n+                if (_isRemoteAddressSet)\n+                    break;\n+            }\n+            break;\n+        case ESP_BT_GAP_DISC_STATE_CHANGED_EVT:\n+            log_i(\"ESP_BT_GAP_DISC_STATE_CHANGED_EVT\");\n+            break;\n+\n+        case ESP_BT_GAP_RMT_SRVCS_EVT:\n+            log_i( \"ESP_BT_GAP_RMT_SRVCS_EVT\");\n+            break;\n+\n+        case ESP_BT_GAP_RMT_SRVC_REC_EVT:\n+            log_i(\"ESP_BT_GAP_RMT_SRVC_REC_EVT\");\n+            break;\n+\n+        case ESP_BT_GAP_AUTH_CMPL_EVT:\n+            if (param->auth_cmpl.stat == ESP_BT_STATUS_SUCCESS) {\n+                log_v(\"authentication success: %s\", param->auth_cmpl.device_name);\n+            } else {\n+                log_e(\"authentication failed, status:%d\", param->auth_cmpl.stat);\n+            }\n+            break;\n+\n+        case ESP_BT_GAP_PIN_REQ_EVT:\n+            // default pairing pins\n+            log_i(\"ESP_BT_GAP_PIN_REQ_EVT min_16_digit:%d\", param->pin_req.min_16_digit);\n+            if (param->pin_req.min_16_digit) {\n+                log_i(\"Input pin code: 0000 0000 0000 0000\");\n+                esp_bt_pin_code_t pin_code;\n+                memset(pin_code, '0', ESP_BT_PIN_CODE_LEN);\n+                esp_bt_gap_pin_reply(param->pin_req.bda, true, 16, pin_code);\n+            } else {\n+                log_i(\"Input pin code: 1234\");\n+                esp_bt_pin_code_t pin_code;\n+                memcpy(pin_code, \"1234\", 4);\n+                esp_bt_gap_pin_reply(param->pin_req.bda, true, 4, pin_code);\n+            }\n+            break;\n+       \n+        case ESP_BT_GAP_CFM_REQ_EVT:\n+            log_i(\"ESP_BT_GAP_CFM_REQ_EVT Please compare the numeric value: %d\", param->cfm_req.num_val);\n+            esp_bt_gap_ssp_confirm_reply(param->cfm_req.bda, true);\n+            break;\n+\n+        case ESP_BT_GAP_KEY_NOTIF_EVT:\n+            log_i(\"ESP_BT_GAP_KEY_NOTIF_EVT passkey:%d\", param->key_notif.passkey);\n+            break;\n+\n+        case ESP_BT_GAP_KEY_REQ_EVT:\n+            log_i(\"ESP_BT_GAP_KEY_REQ_EVT Please enter passkey!\");\n+            break;\n+\n+        default:\n+            break;\n+    }\n+}\n+\n static bool _init_bt(const char *deviceName)\n {\n     if(!_spp_event_group){\n@@ -245,6 +439,7 @@ static bool _init_bt(const char *deviceName)\n         }\n         xEventGroupClearBits(_spp_event_group, 0xFFFFFF);\n         xEventGroupSetBits(_spp_event_group, SPP_CONGESTED);\n+        xEventGroupSetBits(_spp_event_group, SPP_DISCONNECTED);\n     }\n     if (_spp_rx_queue == NULL){\n         _spp_rx_queue = xQueueCreate(RX_QUEUE_SIZE, sizeof(uint8_t)); //initialize the queue\n@@ -297,6 +492,11 @@ static bool _init_bt(const char *deviceName)\n         }\n     }\n \n+    if (_isMaster && esp_bt_gap_register_callback(esp_bt_gap_cb) != ESP_OK) {\n+        log_e(\"gap register failed\");\n+        return false;\n+    }\n+\n     if (esp_spp_register_callback(esp_spp_cb) != ESP_OK){\n         log_e(\"spp register failed\");\n         return false;\n@@ -307,8 +507,20 @@ static bool _init_bt(const char *deviceName)\n         return false;\n     }\n \n+    log_i(\"device name set\");\n     esp_bt_dev_set_device_name(deviceName);\n \n+    if (_isPinSet) {\n+        btSetPin();\n+    }\n+\n+    if (_enableSSP) {\n+        log_i(\"Simple Secure Pairing\");\n+        esp_bt_sp_param_t param_type = ESP_BT_SP_IOCAP_MODE;\n+        esp_bt_io_cap_t iocap = ESP_BT_IO_CAP_IO;\n+        esp_bt_gap_set_security_param(param_type, &iocap, sizeof(uint8_t));\n+    }\n+\n     // the default BTA_DM_COD_LOUDSPEAKER does not work with the macOS BT stack\n     esp_bt_cod_t cod;\n     cod.major = 0b00001;\n@@ -318,7 +530,6 @@ static bool _init_bt(const char *deviceName)\n         log_e(\"set cod failed\");\n         return false;\n     }\n-\n     return true;\n }\n \n@@ -361,6 +572,11 @@ static bool _stop_bt()\n     return true;\n }\n \n+static bool waitForConnect(int timeout) {\n+    TickType_t xTicksToWait = timeout / portTICK_PERIOD_MS;\n+    return (xEventGroupWaitBits(_spp_event_group, SPP_CONNECTED, pdFALSE, pdTRUE, xTicksToWait) != 0);\n+}\n+\n /*\n  * Serial Bluetooth Arduino\n  *\n@@ -376,8 +592,9 @@ BluetoothSerial::~BluetoothSerial(void)\n     _stop_bt();\n }\n \n-bool BluetoothSerial::begin(String localName)\n+bool BluetoothSerial::begin(String localName, bool isMaster)\n {\n+    _isMaster = isMaster;\n     if (localName.length()){\n         local_name = localName;\n     }\n@@ -445,4 +662,129 @@ esp_err_t BluetoothSerial::register_callback(esp_spp_cb_t * callback)\n     return ESP_OK;\n }\n \n+//Simple Secure Pairing\n+void BluetoothSerial::enableSSP() {\n+    _enableSSP = true;\n+}\n+/*\n+     * Set default parameters for Legacy Pairing\n+     * Use fixed pin code\n+*/\n+bool BluetoothSerial::setPin(const char *pin) {\n+    bool isEmpty =  !(pin  && *pin);\n+    if (isEmpty && !_isPinSet) {\n+        return true; // nothing to do\n+    } else if (!isEmpty){\n+        _pin_len = strlen(pin);\n+        memcpy(_pin_code, pin, _pin_len);\n+    } else {\n+        _pin_len = 0; // resetting pin to none (default)\n+    }\n+    _pin_code[_pin_len] = 0;\n+    _isPinSet = true;\n+    if (isReady(false, READY_TIMEOUT)) {\n+        btSetPin();\n+    }\n+    return true;\n+}\n+\n+bool BluetoothSerial::connect(String remoteName)\n+{\n+    if (!isReady(true, READY_TIMEOUT)) return false;\n+    if (remoteName && remoteName.length() < 1) {\n+        log_e(\"No remote name is provided\");\n+        return false; \n+    }\n+    disconnect();\n+    _isRemoteAddressSet = false;\n+    strncpy(_remote_name, remoteName.c_str(), ESP_BT_GAP_MAX_BDNAME_LEN);\n+    _remote_name[ESP_BT_GAP_MAX_BDNAME_LEN] = 0;\n+    log_i(\"master : remoteName\");\n+    // will first resolve name to address\n+    esp_bt_gap_set_scan_mode(ESP_BT_SCAN_MODE_CONNECTABLE_DISCOVERABLE);\n+    if (esp_bt_gap_start_discovery(ESP_BT_INQ_MODE_GENERAL_INQUIRY, INQ_LEN, INQ_NUM_RSPS) == ESP_OK) {\n+        return waitForConnect(SCAN_TIMEOUT);\n+    }\n+    return false;\n+}\n+\n+bool BluetoothSerial::connect(uint8_t remoteAddress[])\n+{\n+    if (!isReady(true, READY_TIMEOUT)) return false;\n+    if (!remoteAddress) {\n+        log_e(\"No remote address is provided\");\n+        return false; \n+    }\n+    disconnect();\n+    _remote_name[0] = 0;\n+    _isRemoteAddressSet = true;\n+    memcpy(_peer_bd_addr, remoteAddress, ESP_BD_ADDR_LEN);\n+    log_i(\"master : remoteAddress\");\n+    if (esp_spp_start_discovery(_peer_bd_addr) == ESP_OK) {\n+        return waitForConnect(READY_TIMEOUT);\n+    }\n+    return false;\n+}\n+\n+bool BluetoothSerial::connect()\n+{\n+    if (!isReady(true, READY_TIMEOUT)) return false;\n+    if (_isRemoteAddressSet){\n+        disconnect();\n+        // use resolved or set address first\n+        log_i(\"master : remoteAddress\");\n+        if (esp_spp_start_discovery(_peer_bd_addr) == ESP_OK) {\n+            return waitForConnect(READY_TIMEOUT);\n+        }\n+        return false;\n+    } else if (_remote_name[0]) {\n+        disconnect();\n+        log_i(\"master : remoteName\");\n+        // will resolve name to address first - it may take a while\n+        esp_bt_gap_set_scan_mode(ESP_BT_SCAN_MODE_CONNECTABLE_DISCOVERABLE);\n+        if (esp_bt_gap_start_discovery(ESP_BT_INQ_MODE_GENERAL_INQUIRY, INQ_LEN, INQ_NUM_RSPS) == ESP_OK) {\n+            return waitForConnect(SCAN_TIMEOUT);\n+        }\n+        return false;\n+    }\n+    log_e(\"Neither Remote name nor address was provided\");\n+    return false;\n+}\n+\n+bool BluetoothSerial::disconnect() {\n+    if (_spp_client) {\n+        flush();\n+        log_i(\"disconnecting\");\n+        if (esp_spp_disconnect(_spp_client) == ESP_OK) {\n+            TickType_t xTicksToWait = READY_TIMEOUT / portTICK_PERIOD_MS;\n+            return (xEventGroupWaitBits(_spp_event_group, SPP_DISCONNECTED, pdFALSE, pdTRUE, xTicksToWait) != 0);\n+        }\n+    }\n+    return false;\n+}\n+\n+bool BluetoothSerial::unpairDevice(uint8_t remoteAddress[]) {\n+    if (isReady(false, READY_TIMEOUT)) {\n+        log_i(\"removing bonded device\");\n+        return (esp_bt_gap_remove_bond_device(remoteAddress) == ESP_OK);\n+    }\n+    return false;\n+}\n+\n+bool BluetoothSerial::connected(int timeout) {\n+    return waitForConnect(timeout);\n+}\n+\n+bool BluetoothSerial::isReady(bool checkMaster, int timeout) {\n+    if (checkMaster && !_isMaster) {\n+        log_e(\"Master mode is not active. Call begin(localName, true) to enable Master mode\");\n+        return false;\n+    }\n+    if (!btStarted()) {\n+        log_e(\"BT is not initialized. Call begin() first\");\n+        return false;\n+    }\n+    TickType_t xTicksToWait = timeout / portTICK_PERIOD_MS;\n+    return (xEventGroupWaitBits(_spp_event_group, SPP_RUNNING, pdFALSE, pdTRUE, xTicksToWait) != 0);\n+}\n #endif\ndiff --git a/libraries/BluetoothSerial/src/BluetoothSerial.h b/libraries/BluetoothSerial/src/BluetoothSerial.h\nold mode 100644\nnew mode 100755\nindex 3f4372e55d2..68269fa9ae6\n--- a/libraries/BluetoothSerial/src/BluetoothSerial.h\n+++ b/libraries/BluetoothSerial/src/BluetoothSerial.h\n@@ -30,7 +30,7 @@ class BluetoothSerial: public Stream\n         BluetoothSerial(void);\n         ~BluetoothSerial(void);\n \n-        bool begin(String localName=String());\n+        bool begin(String localName=String(), bool isMaster=false);\n         int available(void);\n         int peek(void);\n         bool hasClient(void);\n@@ -41,6 +41,16 @@ class BluetoothSerial: public Stream\n         void end(void);\n         esp_err_t register_callback(esp_spp_cb_t * callback);\n \n+        void enableSSP();\n+        bool setPin(const char *pin);\n+        bool connect(String remoteName);\n+        bool connect(uint8_t remoteAddress[]);\n+        bool connect();\n+        bool connected(int timeout=0);\n+        bool isReady(bool checkMaster=false, int timeout=0);\n+        bool disconnect();\n+        bool unpairDevice(uint8_t remoteAddress[]);\n+\n     private:\n         String local_name;\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Timeout Handling:** Implement user-defined timeouts in `connect()` and `disconnect()` methods to prevent crashes from concurrency issues. \n\n2. **Pin Usage:** If the default pin is `1234`, avoid setting it explicitly in the code (comment out lines involving pin setup if default is used).\n\n3. **Connection Strategy:** Prioritize Bluetooth address over device name for connections to avoid conflicts with multiple devices. \n\n4. **Debugging:** Set `CoreDebugLevel` to debug; check `connect()` and `SerialBT.connected()` return values for connection status.\n\n5. **Pairing Issues:** Run `bt_remove_paired_devices` to clear old paired devices; ensure the target BT device is discoverable.\n\n6. **Error Handling:** Address potential stack smashing issues causing reboots; review memory allocation and usage patterns specific to ESP32."
      }
    ],
    "codediff_length": 24034
  },
  {
    "index": 59,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/cores/esp32/esp32-hal-i2c.c b/cores/esp32/esp32-hal-i2c.c\nindex a6b538d8e4d..ffaee6930b4 100644\n--- a/cores/esp32/esp32-hal-i2c.c\n+++ b/cores/esp32/esp32-hal-i2c.c\n@@ -31,6 +31,8 @@\n #define DR_REG_I2C_EXT_BASE_FIXED               0x60013000\n #define DR_REG_I2C1_EXT_BASE_FIXED              0x60027000\n \n+#define COMMAND_BUFFER_LENGTH                   16\n+\n struct i2c_struct_t {\n     i2c_dev_t * dev;\n #if !CONFIG_DISABLE_HAL_LOCKS\n@@ -127,26 +129,25 @@ void i2cSetCmd(i2c_t * i2c, uint8_t index, uint8_t op_code, uint8_t byte_num, bo\n     i2c->dev->command[index].op_code = op_code;\n }\n \n-void i2cResetCmd(i2c_t * i2c){\n-    int i;\n+void i2cResetCmd(i2c_t * i2c) {\n+    uint8_t i;\n     for(i=0;i<16;i++){\n         i2c->dev->command[i].val = 0;\n     }\n }\n \n-void i2cResetFiFo(i2c_t * i2c)\n-{\n+void i2cResetFiFo(i2c_t * i2c) {\n     i2c->dev->fifo_conf.tx_fifo_rst = 1;\n     i2c->dev->fifo_conf.tx_fifo_rst = 0;\n     i2c->dev->fifo_conf.rx_fifo_rst = 1;\n     i2c->dev->fifo_conf.rx_fifo_rst = 0;\n }\n \n-i2c_err_t i2cWrite(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * data, uint8_t len, bool sendStop)\n+i2c_err_t i2cWrite(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * data, uint16_t len, bool sendStop)\n {\n     int i;\n-    uint8_t index = 0;\n-    uint8_t dataLen = len + (addr_10bit?2:1);\n+    uint16_t index = 0;\n+    uint16_t dataLen = len + (addr_10bit?2:1);\n     address = (address << 1);\n \n     if(i2c == NULL){\n@@ -244,12 +245,25 @@ i2c_err_t i2cWrite(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * dat\n     return I2C_ERROR_OK;\n }\n \n-i2c_err_t i2cRead(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * data, uint8_t len, bool sendStop)\n+uint8_t inc( uint8_t* index )\n+{\n+    uint8_t i = index[ 0 ];\n+    if (++index[ 0 ] == COMMAND_BUFFER_LENGTH)\n+    {\n+        index[ 0  ] = 0;\n+    }\n+\n+    return i;\n+}\n+\n+i2c_err_t i2cRead(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * data, uint16_t len, bool sendStop)\n {\n     address = (address << 1) | 1;\n     uint8_t addrLen = (addr_10bit?2:1);\n-    uint8_t index = 0;\n-    uint8_t cmdIdx;\n+    uint8_t amountRead[16];\n+    uint16_t index = 0;\n+    uint8_t cmdIdx = 0, currentCmdIdx = 0, nextCmdCount;\n+    bool stopped = false, isEndNear = false;\n     uint8_t willRead;\n \n     if(i2c == NULL){\n@@ -269,62 +283,42 @@ i2c_err_t i2cRead(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * data\n     i2cResetCmd(i2c);\n \n     //CMD START\n-    i2cSetCmd(i2c, 0, I2C_CMD_RSTART, 0, false, false, false);\n+    i2cSetCmd(i2c, cmdIdx++, I2C_CMD_RSTART, 0, false, false, false);\n \n     //CMD WRITE ADDRESS\n     i2c->dev->fifo_data.val = address & 0xFF;\n     if(addr_10bit) {\n         i2c->dev->fifo_data.val = (address >> 8) & 0xFF;\n     }\n-    i2cSetCmd(i2c, 1, I2C_CMD_WRITE, addrLen, false, false, true);\n+    i2cSetCmd(i2c, cmdIdx++, I2C_CMD_WRITE, addrLen, false, false, true);\n+    nextCmdCount = cmdIdx;\n \n-    while(len) {\n-        cmdIdx = (index)?0:2;\n-        willRead = (len > 32)?32:(len-1);\n-        if(cmdIdx){\n-            i2cResetFiFo(i2c);\n-        }\n-\n-        if(willRead){\n-            i2cSetCmd(i2c, cmdIdx++, I2C_CMD_READ, willRead, false, false, false);\n-        }\n-\n-        if((len - willRead) > 1) {\n-            i2cSetCmd(i2c, cmdIdx++, I2C_CMD_END, 0, false, false, false);\n-        } else {\n-            willRead++;\n-            i2cSetCmd(i2c, cmdIdx++, I2C_CMD_READ, 1, true, false, false);\n-            if(sendStop) {\n-                i2cSetCmd(i2c, cmdIdx++, I2C_CMD_STOP, 0, false, false, false);\n-            }\n-        }\n-\n-        //Clear Interrupts\n-        i2c->dev->int_clr.val = 0xFFFFFFFF;\n-\n-        //START Transmission\n-        i2c->dev->ctr.trans_start = 1;\n+    //Clear Interrupts\n+    i2c->dev->int_clr.val = 0x00001FFF;\n \n+    //START Transmission\n+    i2c->dev->ctr.trans_start = 1;\n+    while (!stopped) {\n         //WAIT Transmission\n         uint32_t startAt = millis();\n         while(1) {\n             //have been looping for too long\n-            if((millis() - startAt)>50){\n-                log_e(\"Timeout! Addr: %x\", address >> 1);\n+            if((millis() - startAt)>50) {\n+                log_e(\"Timeout! Addr: %x, index %d\", (address >> 1), index);\n                 I2C_MUTEX_UNLOCK();\n                 return I2C_ERROR_BUS;\n             }\n \n             //Bus failed (maybe check for this while waiting?\n             if(i2c->dev->int_raw.arbitration_lost) {\n-                log_e(\"Bus Fail! Addr: %x\", address >> 1);\n+                log_e(\"Bus Fail! Addr: %x\", (address >> 1));\n                 I2C_MUTEX_UNLOCK();\n                 return I2C_ERROR_BUS;\n             }\n \n             //Bus timeout\n             if(i2c->dev->int_raw.time_out) {\n-                log_e(\"Bus Timeout! Addr: %x\", address >> 1);\n+                log_e(\"Bus Timeout! Addr: %x, index %d\", (address >> 1), index );\n                 I2C_MUTEX_UNLOCK();\n                 return I2C_ERROR_TIMEOUT;\n             }\n@@ -332,23 +326,47 @@ i2c_err_t i2cRead(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * data\n             //Transmission did not finish and ACK_ERR is set\n             if(i2c->dev->int_raw.ack_err) {\n                 log_w(\"Ack Error! Addr: %x\", address >> 1);\n+                while((i2c->dev->status_reg.bus_busy) && ((millis() - startAt)<50));\n                 I2C_MUTEX_UNLOCK();\n                 return I2C_ERROR_ACK;\n             }\n \n-            if(i2c->dev->command[cmdIdx-1].done) {\n-                break;\n+            // Save bytes from the buffer as they arrive instead of doing them at the end of the loop since there is no\n+            // pause from an END operation in this approach.\n+            if((!isEndNear) && (nextCmdCount < 2)) {\n+                if (willRead = ((len>32)?32:len)) {\n+                    if (willRead > 1) {\n+                        i2cSetCmd(i2c, cmdIdx, I2C_CMD_READ, (amountRead[ inc( &cmdIdx ) ] = willRead -1), false, false, false);\n+                        nextCmdCount++;\n+                    }\n+                    i2cSetCmd(i2c, cmdIdx, I2C_CMD_READ, (amountRead[ inc( &cmdIdx ) ] = 1), (len<=32), false, false);\n+                    nextCmdCount++;\n+                    len -= willRead;\n+                } else {\n+                    i2cSetCmd(i2c, inc( &cmdIdx ), I2C_CMD_STOP, 0, false, false, false);\n+                    isEndNear = true;\n+                    nextCmdCount++;\n+                }\n             }\n-        }\n \n-        int i = 0;\n-        while(i<willRead) {\n-            i++;\n-            data[index++] = i2c->dev->fifo_data.val & 0xFF;\n+            if(i2c->dev->command[currentCmdIdx].done) {\n+                nextCmdCount--;\n+                if (i2c->dev->command[currentCmdIdx].op_code == I2C_CMD_READ) {\n+                    while(amountRead[currentCmdIdx]>0) {\n+                        data[index++] = i2c->dev->fifo_data.val & 0xFF;\n+                        amountRead[currentCmdIdx]--;\n+                    }\n+                    i2cResetFiFo(i2c);\n+                } else if (i2c->dev->command[currentCmdIdx].op_code == I2C_CMD_STOP) {\n+                    stopped = true;\n+                }\n+                inc( &currentCmdIdx );\n+                break;\n+            }\n         }\n-        len -= willRead;\n     }\n     I2C_MUTEX_UNLOCK();\n+\n     return I2C_ERROR_OK;\n }\n \n@@ -425,7 +443,7 @@ i2c_t * i2cInit(uint8_t i2c_num, uint16_t slave_addr, bool addr_10bit_en)\n         DPORT_SET_PERI_REG_MASK(DPORT_PERIP_CLK_EN_REG,DPORT_I2C_EXT1_CLK_EN);\n         DPORT_CLEAR_PERI_REG_MASK(DPORT_PERIP_RST_EN_REG,DPORT_I2C_EXT1_RST);\n     }\n-    \n+\n     I2C_MUTEX_LOCK();\n     i2c->dev->ctr.val = 0;\n     i2c->dev->ctr.ms_mode = (slave_addr == 0);\n@@ -434,7 +452,7 @@ i2c_t * i2cInit(uint8_t i2c_num, uint16_t slave_addr, bool addr_10bit_en)\n     i2c->dev->ctr.clk_en = 1;\n \n     //the max clock number of receiving  a data\n-    i2c->dev->timeout.tout = 400000;//clocks max=1048575\n+    i2c->dev->timeout.tout = 1048575;//clocks max=1048575\n     //disable apb nonfifo access\n     i2c->dev->fifo_conf.nonfifo_en = 0;\n \ndiff --git a/cores/esp32/esp32-hal-i2c.h b/cores/esp32/esp32-hal-i2c.h\nindex 3e9886109bd..f26c7ab2a60 100644\n--- a/cores/esp32/esp32-hal-i2c.h\n+++ b/cores/esp32/esp32-hal-i2c.h\n@@ -48,8 +48,8 @@ i2c_err_t i2cDetachSCL(i2c_t * i2c, int8_t scl);\n i2c_err_t i2cAttachSDA(i2c_t * i2c, int8_t sda);\n i2c_err_t i2cDetachSDA(i2c_t * i2c, int8_t sda);\n \n-i2c_err_t i2cWrite(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * data, uint8_t len, bool sendStop);\n-i2c_err_t i2cRead(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * data, uint8_t len, bool sendStop);\n+i2c_err_t i2cWrite(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * data, uint16_t len, bool sendStop);\n+i2c_err_t i2cRead(i2c_t * i2c, uint16_t address, bool addr_10bit, uint8_t * data, uint16_t len, bool sendStop);\n \n void i2cReset(i2c_t* i2c);\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. To resolve the issue with `I2C_END_DETECT_INT_ST`, ensure your sequence following the interrupt is correct. It's vital that `trans_start`=1 follows the appropriate I2C read/stop commands. Review timing between commands.\n\n2. Your current implementation allows only 3-byte reads, but this can lead to complications when trying to read larger blocks (like 36 bytes). Consider adjusting the buffer size or splitting the read commands differently to avoid END command failures.\n\n3. Since you're experiencing I2C timeouts and state machine inconsistencies, consider using bus pull-up resistors to stabilize the signal.\n\n4. Avoid unnecessary delays between END and START commands to maintain I2C compliance. \n\n5. For performance monitoring, implement a check on message success rates during reads with varying data sizes to determine error patterns.\n\n6. Utilize a CRC for integrity validation instead of byte-wise comparison. Research lightweight CRC implementations to minimize processing impact.\n\n7. Commit your recent changes to ensure stability with the modified ISR handling multiple commands.\n\n8. Streamline the handling of transaction interruptions (e.g., `SendStop` needing to be handled more effectively in `endTransmission`)."
      }
    ],
    "codediff_length": 8889
  },
  {
    "index": 60,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/libraries/HTTPClient/src/HTTPClient.cpp b/libraries/HTTPClient/src/HTTPClient.cpp\nindex 62a9c44901b..1733d0cede1 100644\n--- a/libraries/HTTPClient/src/HTTPClient.cpp\n+++ b/libraries/HTTPClient/src/HTTPClient.cpp\n@@ -495,7 +495,7 @@ void HTTPClient::setTimeout(uint16_t timeout)\n {\n     _tcpTimeout = timeout;\n     if(connected()) {\n-        _client->setTimeout((timeout + 500) / 1000);\n+        _client->setTimeout(timeout);\n     }\n }\n \n@@ -1165,7 +1165,7 @@ bool HTTPClient::connect(void)\n     }\n \n     // set Timeout for WiFiClient and for Stream::readBytesUntil() and Stream::readStringUntil()\n-    _client->setTimeout((_tcpTimeout + 500) / 1000);\t\n+    _client->setTimeout(_tcpTimeout);\t\n \n     log_d(\" connected to %s:%u\", _host.c_str(), _port);\n \ndiff --git a/libraries/HTTPUpdate/examples/httpUpdateSecure/httpUpdateSecure.ino b/libraries/HTTPUpdate/examples/httpUpdateSecure/httpUpdateSecure.ino\nindex 2028d192c06..e528a9fdb1c 100644\n--- a/libraries/HTTPUpdate/examples/httpUpdateSecure/httpUpdateSecure.ino\n+++ b/libraries/HTTPUpdate/examples/httpUpdateSecure/httpUpdateSecure.ino\n@@ -96,7 +96,7 @@ void loop() {\n     client.setCACert(rootCACertificate);\n \n     // Reading data over SSL may be slow, use an adequate timeout\n-    client.setTimeout(12000 / 1000); // timeout argument is defined in seconds for setTimeout\n+    client.setTimeout(12000); // timeout argument is defined in miliseconds for setTimeout\n \n     // The line below is optional. It can be used to blink the LED on the board during flashing\n     // The LED will be on during download of one buffer of data from the network. The LED will\ndiff --git a/libraries/WebServer/src/WebServer.cpp b/libraries/WebServer/src/WebServer.cpp\nindex 8af04ac3f91..0d99f3680a1 100644\n--- a/libraries/WebServer/src/WebServer.cpp\n+++ b/libraries/WebServer/src/WebServer.cpp\n@@ -303,7 +303,7 @@ void WebServer::handleClient() {\n         if (_parseRequest(_currentClient)) {\n           // because HTTP_MAX_SEND_WAIT is expressed in milliseconds,\n           // it must be divided by 1000\n-          _currentClient.setTimeout(HTTP_MAX_SEND_WAIT / 1000);\n+          _currentClient.setTimeout(HTTP_MAX_SEND_WAIT); /* / 1000 removed, WifiClient setTimeout changed to ms */\n           _contentLength = CONTENT_LENGTH_NOT_SET;\n           _handleRequest();\n \ndiff --git a/libraries/WiFi/src/WiFiClient.cpp b/libraries/WiFi/src/WiFiClient.cpp\nindex 91247d17386..52c73b67300 100644\n--- a/libraries/WiFi/src/WiFiClient.cpp\n+++ b/libraries/WiFi/src/WiFiClient.cpp\n@@ -211,6 +211,8 @@ void WiFiClient::stop()\n     clientSocketHandle = NULL;\n     _rxBuffer = NULL;\n     _connected = false;\n+    _lastReadTimeout = 0;\n+    _lastWriteTimeout = 0;\n }\n \n int WiFiClient::connect(IPAddress ip, uint16_t port)\n@@ -331,25 +333,6 @@ int WiFiClient::getSocketOption(int level, int option, const void* value, size_t\n     return res;\n }\n \n-\n-int WiFiClient::setTimeout(uint32_t seconds)\n-{\n-    Client::setTimeout(seconds * 1000); // This should be here?\n-    _timeout = seconds * 1000;\n-    if(fd() >= 0) {\n-        struct timeval tv;\n-        tv.tv_sec = seconds;\n-        tv.tv_usec = 0;\n-        if(setSocketOption(SO_RCVTIMEO, (char *)&tv, sizeof(struct timeval)) < 0) {\n-            return -1;\n-        }\n-        return setSocketOption(SO_SNDTIMEO, (char *)&tv, sizeof(struct timeval));\n-    }\n-    else {\n-        return 0;\n-    }\n-}\n-\n int WiFiClient::setOption(int option, int *value)\n {\n     return setSocketOption(IPPROTO_TCP, option, (const void*)value, sizeof(int));\n@@ -418,6 +401,18 @@ size_t WiFiClient::write(const uint8_t *buf, size_t size)\n         tv.tv_usec = WIFI_CLIENT_SELECT_TIMEOUT_US;\n         retry--;\n \n+        if(_lastWriteTimeout != _timeout){\n+            if(fd() >= 0){\n+                struct timeval timeout_tv;\n+                timeout_tv.tv_sec = _timeout / 1000;\n+                timeout_tv.tv_usec = (_timeout % 1000) * 1000;\n+                if(setSocketOption(SO_SNDTIMEO, (char *)&timeout_tv, sizeof(struct timeval)) >= 0)\n+                {\n+                    _lastWriteTimeout = _timeout;\n+                }\n+            }\n+        }\n+\n         if(select(socketFileDescriptor + 1, NULL, &set, NULL, &tv) < 0) {\n             return 0;\n         }\n@@ -477,6 +472,18 @@ size_t WiFiClient::write(Stream &stream)\n \n int WiFiClient::read(uint8_t *buf, size_t size)\n {\n+    if(_lastReadTimeout != _timeout){\n+        if(fd() >= 0){\n+            struct timeval timeout_tv;\n+            timeout_tv.tv_sec = _timeout / 1000;\n+            timeout_tv.tv_usec = (_timeout % 1000) * 1000;\n+            if(setSocketOption(SO_RCVTIMEO, (char *)&timeout_tv, sizeof(struct timeval)) >= 0)\n+            {\n+                _lastReadTimeout = _timeout;\n+            }\n+        }\n+    }\n+\n     int res = -1;\n     if (_rxBuffer) {\n         res = _rxBuffer->read(buf, size);\ndiff --git a/libraries/WiFi/src/WiFiClient.h b/libraries/WiFi/src/WiFiClient.h\nindex cdb0e0539e9..7ff753ef3e2 100644\n--- a/libraries/WiFi/src/WiFiClient.h\n+++ b/libraries/WiFi/src/WiFiClient.h\n@@ -33,7 +33,6 @@ class ESPLwIPClient : public Client\n public:\n         virtual int connect(IPAddress ip, uint16_t port, int32_t timeout) = 0;\n         virtual int connect(const char *host, uint16_t port, int32_t timeout) = 0;\n-        virtual int setTimeout(uint32_t seconds) = 0;\n };\n \n class WiFiClient : public ESPLwIPClient\n@@ -43,6 +42,8 @@ class WiFiClient : public ESPLwIPClient\n     std::shared_ptr<WiFiClientRxBuffer> _rxBuffer;\n     bool _connected;\n     int _timeout;\n+    int _lastWriteTimeout;\n+    int _lastReadTimeout;\n \n public:\n     WiFiClient *next;\n@@ -91,7 +92,6 @@ class WiFiClient : public ESPLwIPClient\n     int getSocketOption(int level, int option, const void* value, size_t size);\n     int setOption(int option, int *value);\n     int getOption(int option, int *value);\n-    int setTimeout(uint32_t seconds);\n     int setNoDelay(bool nodelay);\n     bool getNoDelay();\n \ndiff --git a/libraries/WiFiClientSecure/src/WiFiClientSecure.cpp b/libraries/WiFiClientSecure/src/WiFiClientSecure.cpp\nindex 4d4702ba84d..b3c64129d75 100644\n--- a/libraries/WiFiClientSecure/src/WiFiClientSecure.cpp\n+++ b/libraries/WiFiClientSecure/src/WiFiClientSecure.cpp\n@@ -54,6 +54,8 @@ WiFiClientSecure::WiFiClientSecure(int sock)\n {\n     _connected = false;\n     _timeout = 30000; // Same default as ssl_client\n+    _lastReadTimeout = 0;\n+    _lastWriteTimeout = 0;\n \n     sslclient = new sslclient_context;\n     ssl_init(sslclient);\n@@ -94,6 +96,8 @@ void WiFiClientSecure::stop()\n         sslclient->socket = -1;\n         _connected = false;\n         _peek = -1;\n+        _lastReadTimeout = 0;\n+        _lastWriteTimeout = 0;\n     }\n     stop_ssl_socket(sslclient, _CA_cert, _cert, _private_key);\n }\n@@ -199,6 +203,16 @@ size_t WiFiClientSecure::write(const uint8_t *buf, size_t size)\n     if (!_connected) {\n         return 0;\n     }\n+    if(_lastWriteTimeout != _timeout){\n+        struct timeval timeout_tv;\n+        timeout_tv.tv_sec = _timeout / 1000;\n+        timeout_tv.tv_usec = (_timeout % 1000) * 1000;\n+        if(setSocketOption(SO_SNDTIMEO, (char *)&timeout_tv, sizeof(struct timeval)) >= 0)\n+        {\n+            _lastWriteTimeout = _timeout;\n+        }\n+    }\n+\n     int res = send_ssl_data(sslclient, buf, size);\n     if (res < 0) {\n         stop();\n@@ -209,6 +223,18 @@ size_t WiFiClientSecure::write(const uint8_t *buf, size_t size)\n \n int WiFiClientSecure::read(uint8_t *buf, size_t size)\n {\n+    if(_lastReadTimeout != _timeout){\n+        if(fd() >= 0){\n+            struct timeval timeout_tv;\n+            timeout_tv.tv_sec = _timeout / 1000;\n+            timeout_tv.tv_usec = (_timeout % 1000) * 1000;\n+            if(setSocketOption(SO_RCVTIMEO, (char *)&timeout_tv, sizeof(struct timeval)) >= 0)\n+            {\n+                _lastReadTimeout = _timeout;\n+            }\n+        }\n+    }\n+\n     int peeked = 0;\n     int avail = available();\n     if ((!buf && size) || avail <= 0) {\n@@ -396,4 +422,3 @@ int WiFiClientSecure::fd() const\n {\n     return sslclient->socket;\n }\n-\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Timeout API Change**: Changing `setTimeout(seconds)` to `Stream::setTimeout(milliseconds)` is a breaking change that will cause existing code expecting seconds to misbehave (e.g., a value of `5` now sets a timeout of `5ms` instead of `5s`). This needs immediate attention and extensive testing before release.\n\n2. **WiFiClient/Client Compatibility**: The removal of `setTimeout` from `WiFiClient` and `WiFiClientSecure` breaks compatibility for libraries relying on this method. Consider restoring the method for backward compatibility or provide a clear migration path.\n\n3. **Non-blocking Reads**: Ensure that `read()` only processes available data to prevent blocking in embedded environments, as this can lead to performance degradation.\n\n4. **Proposed Solution**: Introduce a `setTimeout(float seconds)` method to allow both seconds and milliseconds input, maintaining compatibility and providing usability for existing implementations."
      }
    ],
    "codediff_length": 8041
  },
  {
    "index": 61,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/cores/esp32/esp32-hal-ledc.c b/cores/esp32/esp32-hal-ledc.c\nindex 76d522c2313..2005777d7bd 100644\n--- a/cores/esp32/esp32-hal-ledc.c\n+++ b/cores/esp32/esp32-hal-ledc.c\n@@ -19,6 +19,8 @@\n #include \"esp32-hal-ledc.h\"\n #include \"driver/ledc.h\"\n #include \"esp32-hal-periman.h\"\n+#include \"soc/gpio_sig_map.h\"\n+#include \"esp_rom_gpio.h\"\n \n #ifdef SOC_LEDC_SUPPORT_HS_MODE\n #define LEDC_CHANNELS           (SOC_LEDC_CHANNEL_NUM<<1)\n@@ -40,7 +42,7 @@ typedef struct {\n     int used_channels : LEDC_CHANNELS;              // Used channels as a bits\n } ledc_periph_t;\n \n-ledc_periph_t ledc_handle;\n+ledc_periph_t ledc_handle = {0};\n \n static bool fade_initialized = false;\n \n@@ -58,15 +60,28 @@ static bool ledcDetachBus(void * bus){\n \n bool ledcAttachChannel(uint8_t pin, uint32_t freq, uint8_t resolution, uint8_t channel)\n {\n-    if (channel >= LEDC_CHANNELS || resolution > LEDC_MAX_BIT_WIDTH)\n-    {\n-        log_e(\"Channel %u is not available! (maximum %u) or bit width too big (maximum %u)\", channel, LEDC_CHANNELS, LEDC_MAX_BIT_WIDTH);\n+    if(channel >= LEDC_CHANNELS || ledc_handle.used_channels & (1UL << channel)){\n+        log_e(\"Channel %u is not available (maximum %u) or already used!\", channel, LEDC_CHANNELS);\n+        return false;\n+    }\n+    if (freq == 0) {\n+        log_e(\"LEDC pin %u - frequency can't be zero.\", pin);\n+        return false;\n+    }\n+    if (resolution == 0 || resolution > LEDC_MAX_BIT_WIDTH){\n+        log_e(\"LEDC pin %u - resolution is zero or it is too big (maximum %u)\", pin, LEDC_MAX_BIT_WIDTH);\n         return false;\n     }\n \n     perimanSetBusDeinit(ESP32_BUS_TYPE_LEDC, ledcDetachBus);\n     ledc_channel_handle_t *bus = (ledc_channel_handle_t*)perimanGetPinBus(pin, ESP32_BUS_TYPE_LEDC);\n-    if(bus != NULL && !perimanClearPinBus(pin)){\n+    if(bus != NULL){\n+        log_e(\"Pin %u is already attached to LEDC (channel %u, resolution %u)\", pin, bus->channel, bus->channel_resolution);\n+        return false;\n+    }\n+\n+    if(!perimanClearPinBus(pin)){\n+        log_e(\"Pin %u is already attached to another bus and failed to detach\", pin);\n         return false;\n     }\n \n@@ -119,12 +134,12 @@ bool ledcAttachChannel(uint8_t pin, uint32_t freq, uint8_t resolution, uint8_t c\n \n bool ledcAttach(uint8_t pin, uint32_t freq, uint8_t resolution)\n {\n-    uint8_t free_channel = ~ledc_handle.used_channels & (ledc_handle.used_channels+1);\n-    if (free_channel == 0 || resolution > LEDC_MAX_BIT_WIDTH){\n-        log_e(\"No more LEDC channels available! (maximum %u) or bit width too big (maximum %u)\", LEDC_CHANNELS, LEDC_MAX_BIT_WIDTH);\n+    int free_channel = ~ledc_handle.used_channels & (ledc_handle.used_channels+1);\n+    if (free_channel == 0){\n+        log_e(\"No more LEDC channels available! (maximum is %u channels)\", LEDC_CHANNELS);\n         return false;\n     }\n-    int channel = log2(free_channel & -free_channel);\n+    uint8_t channel = __builtin_ctz(free_channel); // Convert the free_channel bit to channel number\n \n     return ledcAttachChannel(pin, freq, resolution, channel);\n }\n@@ -239,9 +254,12 @@ uint32_t ledcChangeFrequency(uint8_t pin, uint32_t freq, uint8_t resolution)\n {\n     ledc_channel_handle_t *bus = (ledc_channel_handle_t*)perimanGetPinBus(pin, ESP32_BUS_TYPE_LEDC);\n     if(bus != NULL){\n-\n-        if(resolution > LEDC_MAX_BIT_WIDTH){\n-            log_e(\"LEDC resolution too big (maximum %u)\", LEDC_MAX_BIT_WIDTH);\n+        if (freq == 0) {\n+            log_e(\"LEDC pin %u - frequency can't be zero.\", pin);\n+            return 0;\n+        }\n+        if (resolution == 0 || resolution > LEDC_MAX_BIT_WIDTH){\n+            log_e(\"LEDC pin %u - resolution is zero or it is too big (maximum %u)\", pin, LEDC_MAX_BIT_WIDTH);\n             return 0;\n         }\n         uint8_t group=(bus->channel/8), timer=((bus->channel/2)%4);\n@@ -265,6 +283,21 @@ uint32_t ledcChangeFrequency(uint8_t pin, uint32_t freq, uint8_t resolution)\n     return 0;\n }\n \n+bool ledcOutputInvert(uint8_t pin, bool out_invert)\n+{\n+    ledc_channel_handle_t *bus = (ledc_channel_handle_t*)perimanGetPinBus(pin, ESP32_BUS_TYPE_LEDC);\n+    if(bus != NULL){\n+        gpio_set_level(pin, out_invert);\n+    #ifdef SOC_LEDC_SUPPORT_HS_MODE\n+        esp_rom_gpio_connect_out_signal(pin, ((bus->channel/8 == 0) ? LEDC_HS_SIG_OUT0_IDX : LEDC_LS_SIG_OUT0_IDX) + ((bus->channel)%8), out_invert, 0);\n+    #else\n+        esp_rom_gpio_connect_out_signal(pin, LEDC_LS_SIG_OUT0_IDX + ((bus->channel)%8), out_invert, 0);\n+    #endif\n+        return true;\n+    }\n+    return false;\n+}\n+\n static IRAM_ATTR bool ledcFnWrapper(const ledc_cb_param_t *param, void *user_arg)\n {\n     if (param->event == LEDC_FADE_END_EVT) {\ndiff --git a/cores/esp32/esp32-hal-ledc.h b/cores/esp32/esp32-hal-ledc.h\nindex 2d2c42e9369..94dcf7509d1 100644\n--- a/cores/esp32/esp32-hal-ledc.h\n+++ b/cores/esp32/esp32-hal-ledc.h\n@@ -45,20 +45,150 @@ typedef struct {\n #endif\n } ledc_channel_handle_t;\n \n-//channel 0-15 resolution 1-16bits freq limits depend on resolution\n-bool        ledcAttach(uint8_t pin, uint32_t freq, uint8_t resolution);\n-bool        ledcAttachChannel(uint8_t pin, uint32_t freq, uint8_t resolution, uint8_t channel);\n-bool        ledcWrite(uint8_t pin, uint32_t duty);\n-uint32_t    ledcWriteTone(uint8_t pin, uint32_t freq);\n-uint32_t    ledcWriteNote(uint8_t pin, note_t note, uint8_t octave);\n-uint32_t    ledcRead(uint8_t pin);\n-uint32_t    ledcReadFreq(uint8_t pin);\n-bool        ledcDetach(uint8_t pin);\n-uint32_t    ledcChangeFrequency(uint8_t pin, uint32_t freq, uint8_t resolution);\n+/**\n+ * @brief Attach a pin to the LEDC driver, with a given frequency and resolution.\n+ *        Channel is automatically assigned.\n+ *\n+ * @param pin GPIO pin\n+ * @param freq frequency of PWM signal\n+ * @param resolution resolution for LEDC pin\n+ *\n+ * @return true if configuration is successful and pin was successfully attached, false otherwise.\n+ */\n+bool ledcAttach(uint8_t pin, uint32_t freq, uint8_t resolution);\n+\n+/**\n+ * @brief Attach a pin to the LEDC driver, with a given frequency, resolution and channel.\n+ *\n+ * @param pin GPIO pin\n+ * @param freq frequency of PWM signal\n+ * @param resolution resolution for LEDC pin\n+ * @param channel LEDC channel to attach to\n+ *\n+ * @return true if configuration is successful and pin was successfully attached, false otherwise.\n+ */\n+bool ledcAttachChannel(uint8_t pin, uint32_t freq, uint8_t resolution, uint8_t channel);\n+\n+/**\n+ * @brief Set the duty cycle of a given pin.\n+ *\n+ * @param pin GPIO pin\n+ * @param duty duty cycle to set\n+ *\n+ * @return true if duty cycle was successfully set, false otherwise.\n+ */\n+bool ledcWrite(uint8_t pin, uint32_t duty);\n+\n+/**\n+ * @brief Sets the duty to 50 % PWM tone on selected frequency.\n+ *\n+ * @param pin GPIO pin\n+ * @param freq select frequency of pwm signal. If frequency is 0, duty will be set to 0.\n+ *\n+ * @return frequency if tone was successfully set.\n+ *         If ``0`` is returned, error occurs and LEDC pin was not configured.\n+ */\n+uint32_t ledcWriteTone(uint8_t pin, uint32_t freq);\n+\n+/**\n+ * @brief Sets the LEDC pin to specific note.\n+ *\n+ * @param pin GPIO pin\n+ * @param note select note to be set (NOTE_C, NOTE_Cs, NOTE_D, NOTE_Eb, NOTE_E, NOTE_F, NOTE_Fs, NOTE_G, NOTE_Gs, NOTE_A, NOTE_Bb, NOTE_B).\n+ * @param octave select octave for note.\n+ *\n+ * @return frequency if note was successfully set.\n+ *         If ``0`` is returned, error occurs and LEDC pin was not configured.\n+ */\n+uint32_t ledcWriteNote(uint8_t pin, note_t note, uint8_t octave);\n+\n+/**\n+ * @brief Read the duty cycle of a given LEDC pin.\n+ *\n+ * @param pin GPIO pin\n+ *\n+ * @return duty cycle of selected LEDC pin.\n+ */\n+uint32_t ledcRead(uint8_t pin);\n+\n+/**\n+ * @brief Read the frequency of a given LEDC pin.\n+ *\n+ * @param pin GPIO pin\n+ *\n+ * @return frequency of selected LEDC pin.\n+ */\n+uint32_t ledcReadFreq(uint8_t pin);\n+\n+/**\n+ * @brief Detach a pin from the LEDC driver.\n+ *\n+ * @param pin GPIO pin\n+ *\n+ * @return true if pin was successfully detached, false otherwise.\n+ */\n+bool ledcDetach(uint8_t pin);\n+\n+/**\n+ * @brief Change the frequency and resolution of a given LEDC pin.\n+ * \n+ * @param pin GPIO pin\n+ * @param freq frequency of PWM signal\n+ * @param resolution resolution for LEDC pin\n+ * \n+ * @return frequency configured for the LEDC channel.\n+ *         If ``0`` is returned, error occurs and LEDC pin was not configured.\n+ */\n+uint32_t ledcChangeFrequency(uint8_t pin, uint32_t freq, uint8_t resolution);\n+\n+/**\n+ * @brief Sets inverting of the output signal for a given LEDC pin.\n+ * \n+ * @param pin GPIO pin\n+ * @param out_invert select, if output should be inverted (true = inverting output).\n+ * \n+ * @return true if output inverting was successfully set, false otherwise.\n+ */\n+bool ledcOutputInvert(uint8_t pin, bool out_invert);\n \n //Fade functions\n+/**\n+ * @brief Setup and start a fade on a given LEDC pin.\n+ * \n+ * @param pin GPIO pin\n+ * @param start_duty initial duty cycle of the fade\n+ * @param target_duty target duty cycle of the fade\n+ * @param max_fade_time_ms maximum fade time in milliseconds\n+ * \n+ * @return true if fade was successfully set and started, false otherwise.\n+ */\n bool ledcFade(uint8_t pin, uint32_t start_duty, uint32_t target_duty, int max_fade_time_ms);\n+\n+/**\n+ * @brief Setup and start a fade on a given LEDC pin with a callback function.\n+ * \n+ * @param pin GPIO pin\n+ * @param start_duty initial duty cycle of the fade\n+ * @param target_duty target duty cycle of the fade\n+ * @param max_fade_time_ms maximum fade time in milliseconds\n+ * @param userFunc callback function to be called after fade is finished\n+ * \n+ * @return true if fade was successfully set and started, false otherwise.\n+ */\n bool ledcFadeWithInterrupt(uint8_t pin, uint32_t start_duty, uint32_t target_duty, int max_fade_time_ms, void (*userFunc)(void));\n+\n+/**\n+ * @brief Setup and start a fade on a given LEDC pin with a callback function and argument.\n+ * \n+ * @param pin GPIO pin\n+ * @param start_duty initial duty cycle of the fade\n+ * @param target_duty target duty cycle of the fade\n+ * @param max_fade_time_ms maximum fade time in milliseconds\n+ * @param userFunc callback function to be called after fade is finished\n+ * @param arg argument to be passed to the callback function\n+ * \n+ * @return true if fade was successfully set and started, false otherwise.\n+ */\n bool ledcFadeWithInterruptArg(uint8_t pin, uint32_t start_duty, uint32_t target_duty, int max_fade_time_ms, void (*userFunc)(void*), void * arg);\n \n #ifdef __cplusplus\ndiff --git a/cores/esp32/io_pin_remap.h b/cores/esp32/io_pin_remap.h\nindex 9f09e2b8de2..853cdfa7e81 100644\n--- a/cores/esp32/io_pin_remap.h\n+++ b/cores/esp32/io_pin_remap.h\n@@ -53,14 +53,16 @@ int8_t gpioNumberToDigitalPin(int8_t gpioNumber);\n #define i2cSlaveInit(num, sda, scl, slaveID, frequency, rx_len, tx_len)     i2cSlaveInit(num, digitalPinToGPIONumber(sda), digitalPinToGPIONumber(scl), slaveID, frequency, rx_len, tx_len)\n \n // cores/esp32/esp32-hal-ledc.h\n-#define ledcAttach(pin, freq, resolution)           ledcAttach(digitalPinToGPIONumber(pin), freq, resolution)\n-#define ledcWrite(pin, duty)                        ledcWrite(digitalPinToGPIONumber(pin), duty)\n-#define ledcWriteTone(pin, freq)                    ledcWriteTone(digitalPinToGPIONumber(pin), freq)\n-#define ledcWriteNote(pin, note, octave)            ledcWriteNote(digitalPinToGPIONumber(pin), note, octave)\n-#define ledcRead(pin)                               ledcRead(digitalPinToGPIONumber(pin))\n-#define ledcReadFreq(pin)                           ledcReadFreq(digitalPinToGPIONumber(pin))\n-#define ledcDetach(pin)                             ledcDetach(digitalPinToGPIONumber(pin))\n-#define ledcChangeFrequency(pin, freq, resolution)  ledcChangeFrequency(digitalPinToGPIONumber(pin), freq, resolution)\n+#define ledcAttach(pin, freq, resolution)                       ledcAttach(digitalPinToGPIONumber(pin), freq, resolution)\n+#define ledcAttachChannel(pin, freq, resolution, channel)       ledcAttachChannel(digitalPinToGPIONumber(pin), freq, resolution, channel)\n+#define ledcWrite(pin, duty)                                    ledcWrite(digitalPinToGPIONumber(pin), duty)\n+#define ledcWriteTone(pin, freq)                                ledcWriteTone(digitalPinToGPIONumber(pin), freq)\n+#define ledcWriteNote(pin, note, octave)                        ledcWriteNote(digitalPinToGPIONumber(pin), note, octave)\n+#define ledcRead(pin)                                           ledcRead(digitalPinToGPIONumber(pin))\n+#define ledcReadFreq(pin)                                       ledcReadFreq(digitalPinToGPIONumber(pin))\n+#define ledcDetach(pin)                                         ledcDetach(digitalPinToGPIONumber(pin))\n+#define ledcChangeFrequency(pin, freq, resolution)              ledcChangeFrequency(digitalPinToGPIONumber(pin), freq, resolution)\n+#define ledcOutputInvert(pin, out_invert)                       ledcOutputInvert(digitalPinToGPIONumber(pin), out_invert)\n \n #define ledcFade(pin, start_duty, target_duty, max_fade_time_ms)                                ledcFade(digitalPinToGPIONumber(pin), start_duty, target_duty, max_fade_time_ms)\n #define ledcFadeWithInterrupt(pin, start_duty, target_duty, max_fade_time_ms, userFunc)         ledcFadeWithInterrupt(digitalPinToGPIONumber(pin), start_duty, target_duty, max_fade_time_ms, userFunc)\ndiff --git a/docs/en/api/ledc.rst b/docs/en/api/ledc.rst\nindex 1abeea2f6ee..200e19f81e5 100644\n--- a/docs/en/api/ledc.rst\n+++ b/docs/en/api/ledc.rst\n@@ -26,8 +26,7 @@ Arduino-ESP32 LEDC API\n ledcAttach\n **********\n \n-This function is used to setup LEDC pin with given frequency and resolution.\n-LEDC channel will be selected automatically.\n+This function is used to setup LEDC pin with given frequency and resolution. LEDC channel will be selected automatically.\n \n .. code-block:: arduino\n \n@@ -35,10 +34,10 @@ LEDC channel will be selected automatically.\n \n * ``pin`` select LEDC pin.\n * ``freq`` select frequency of pwm.\n-* ``resolution`` select resolution for LEDC channel. \n- \n+* ``resolution`` select resolution for LEDC channel.\n+\n   * range is 1-14 bits (1-20 bits for ESP32).\n-  \n+\n This function will return ``true`` if configuration is successful.\n If ``false`` is returned, error occurs and LEDC channel was not configured.\n \n@@ -49,15 +48,16 @@ This function is used to setup LEDC pin with given frequency, resolution and cha\n \n .. code-block:: arduino\n \n-    bool ledcAttachChannel(uint8_t pin, uint32_t freq, uint8_t resolution, uint8_t channel);\n+    bool ledcAttachChannel(uint8_t pin, uint32_t freq, uint8_t resolution, int8_t channel);\n \n * ``pin`` select LEDC pin.\n * ``freq`` select frequency of pwm.\n-* ``resolution`` select resolution for LEDC channel. \n-* ``channel`` select LEDC channel.\n- \n+* ``resolution`` select resolution for LEDC channel.\n+\n   * range is 1-14 bits (1-20 bits for ESP32).\n-  \n+\n+* ``channel`` select LEDC channel.\n+\n This function will return ``true`` if configuration is successful.\n If ``false`` is returned, error occurs and LEDC channel was not configured.\n \n@@ -171,6 +171,21 @@ This function is used to set frequency for the LEDC pin.\n This function will return ``frequency`` configured for the LEDC channel.\n If ``0`` is returned, error occurs and the LEDC channel frequency was not set.\n \n+ledcOutputInvert\n+****************\n+\n+This function is used to set inverting output for the LEDC pin.\n+\n+.. code-block:: arduino\n+\n+    bool ledcOutputInvert(uint8_t pin, bool out_invert);\n+\n+* ``pin`` select LEDC pin.\n+* ``out_invert`` select, if output should be inverted (true = inverting output).\n+  \n+This function returns ``true`` if setting inverting output was successful.\n+If ``false`` is returned, an error occurred and the inverting output was not set.\n+\n ledcFade\n ********\n \ndiff --git a/docs/en/migration_guides/2.x_to_3.0.rst b/docs/en/migration_guides/2.x_to_3.0.rst\nindex 452a7fb21b4..b07af795f77 100644\n--- a/docs/en/migration_guides/2.x_to_3.0.rst\n+++ b/docs/en/migration_guides/2.x_to_3.0.rst\n@@ -63,8 +63,10 @@ New APIs\n ********\n \n * ``ledcAttach`` used to set up the LEDC pin (merged ``ledcSetup`` and ``ledcAttachPin`` functions).\n-* ``timerGetFrequency`` used to get the actual frequency of the timer.\n-* ``timerAttachInterruptArg`` used to attach the interrupt to a timer using arguments.\n+* ``ledcOutputInvert`` used to attach the interrupt to a timer using arguments.\n+* ``ledcFade`` used to set up and start a fade on a given LEDC pin.\n+* ``ledcFadeWithInterrupt`` used to set up and start a fade on a given LEDC pin with an interrupt.\n+* ``ledcFadeWithInterruptArg`` used to set up and start a fade on a given LEDC pin with an interrupt using arguments.\n \n Changes in APIs\n ***************\ndiff --git a/libraries/ESP32/examples/AnalogOut/LEDCFade/LEDCFade.ino b/libraries/ESP32/examples/AnalogOut/LEDCFade/LEDCFade.ino\nindex 002df746014..19c2be3428d 100644\n--- a/libraries/ESP32/examples/AnalogOut/LEDCFade/LEDCFade.ino\n+++ b/libraries/ESP32/examples/AnalogOut/LEDCFade/LEDCFade.ino\n@@ -33,7 +33,7 @@ void setup() {\n   Serial.begin(115200);\n   while(!Serial) delay(10);\n \n-  // Setup timer and attach timer to a led pins\n+  // Setup timer with given frequency, resolution and attach it to a led pin with auto-selected channel\n   ledcAttach(LED_PIN, LEDC_BASE_FREQ, LEDC_TIMER_12_BIT);\n \n   // Setup and start fade on led (duty from 0 to 4095)\ndiff --git a/libraries/ESP32/examples/AnalogOut/ledcWrite_RGB/ledcWrite_RGB.ino b/libraries/ESP32/examples/AnalogOut/ledcWrite_RGB/ledcWrite_RGB.ino\nindex 1104a6b4c63..0135ab1d0c1 100644\n--- a/libraries/ESP32/examples/AnalogOut/ledcWrite_RGB/ledcWrite_RGB.ino\n+++ b/libraries/ESP32/examples/AnalogOut/ledcWrite_RGB/ledcWrite_RGB.ino\n@@ -26,7 +26,7 @@ void setup()\n   delay(10); \n   \n   // Initialize pins as LEDC channels \n-  // resolution 1-16 bits, freq limits depend on resolution\n+  // resolution 1-16 bits, freq limits depend on resolution, channel is automatically selected\n   ledcAttach(ledR, 12000, 8); // 12 kHz PWM, 8-bit resolution\n   ledcAttach(ledG, 12000, 8);\n   ledcAttach(ledB, 12000, 8);\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Parameter Dependency**: Validate interaction between frequency and resolution, as there are configurations where they can exceed max clock frequency. Consider revising the resolution 0 behavior to avoid user confusion regarding PWM duty.\n\n2. **Static Utility Function**: Implement a static method to compute maximum frequency based on given resolution, especially for varying runtime conditions (e.g., low power mode).\n\n3. **Peripheral Management**: Utilize the Peripheral Manager API in Arduino Core 3.0.0. Confirm that `perimanClearPinBus()` effectively detaches any assigned peripheral before reassignment.\n\n4. **SigmaDelta Issue**: The order of operations affects functionality when using SigmaDelta and LEDC. Ensure that SigmaDelta is initialized and checked for consistency as it had previous issues (resolved in PR #9268).\n\n5. **Testing Required**: Perform additional testing to ensure proper functionality transitioning between peripherals, confirming no residual states affect performance."
      }
    ],
    "codediff_length": 18065
  },
  {
    "index": 62,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/cores/esp32/HardwareSerial.cpp b/cores/esp32/HardwareSerial.cpp\nindex ba8429a5dac..323482a6bbf 100644\n--- a/cores/esp32/HardwareSerial.cpp\n+++ b/cores/esp32/HardwareSerial.cpp\n@@ -122,11 +122,13 @@ void serialEventRun(void)\n \n HardwareSerial::HardwareSerial(int uart_nr) : \n _uart_nr(uart_nr), \n-_uart(NULL), \n+_uart(NULL),\n _rxBufferSize(256),\n _txBufferSize(0), \n _onReceiveCB(NULL), \n _onReceiveErrorCB(NULL),\n+_onReceiveTimeout(true),\n+_rxTimeout(10),\n _eventTask(NULL)\n #if !CONFIG_DISABLE_HAL_LOCKS\n     ,_lock(NULL)\n@@ -183,18 +185,49 @@ void HardwareSerial::onReceiveError(OnReceiveErrorCb function)\n     HSERIAL_MUTEX_UNLOCK();\n }\n \n-void HardwareSerial::onReceive(OnReceiveCb function)\n+void HardwareSerial::onReceive(OnReceiveCb function, bool onlyOnTimeout)\n {\n     HSERIAL_MUTEX_LOCK();\n     // function may be NULL to cancel onReceive() from its respective task \n     _onReceiveCB = function;\n+    // When Rx timeout is Zero (disabled), there is only one possible option that is callback when FIFO reaches 120 bytes\n+    _onReceiveTimeout = _rxTimeout > 0 ? onlyOnTimeout : false;\n+\n     // this can be called after Serial.begin(), therefore it shall create the event task\n     if (function != NULL && _uart != NULL && _eventTask == NULL) {\n-        _createEventTask(this);\n+        _createEventTask(this); // Create event task\n     }\n     HSERIAL_MUTEX_UNLOCK();\n }\n \n+// timout is calculates in time to receive UART symbols at the UART baudrate.\n+// the estimation is about 11 bits per symbol (SERIAL_8N1)\n+void HardwareSerial::setRxTimeout(uint8_t symbols_timeout)\n+{\n+    HSERIAL_MUTEX_LOCK();\n+    \n+    // Zero disables timeout, thus, onReceive callback will only be called when RX FIFO reaches 120 bytes\n+    // Any non-zero value will activate onReceive callback based on UART baudrate with about 11 bits per symbol \n+    _rxTimeout = symbols_timeout;   \n+    if (!symbols_timeout) _onReceiveTimeout = false;  // only when RX timeout is disabled, we also must disable this flag \n+\n+    if(_uart != NULL) uart_set_rx_timeout(_uart_nr, _rxTimeout); // Set new timeout\n+    \n+    HSERIAL_MUTEX_UNLOCK();\n+}\n+\n+void HardwareSerial::eventQueueReset()\n+{\n+    QueueHandle_t uartEventQueue = NULL;\n+    if (_uart == NULL) {\n+\t    return;\n+    }\n+    uartGetEventQueue(_uart, &uartEventQueue);\n+    if (uartEventQueue != NULL) {\n+        xQueueReset(uartEventQueue);\n+    }\n+}\n+\n void HardwareSerial::_uartEventTask(void *args)\n {\n     HardwareSerial *uart = (HardwareSerial *)args;\n@@ -207,14 +240,16 @@ void HardwareSerial::_uartEventTask(void *args)\n             if(xQueueReceive(uartEventQueue, (void * )&event, (portTickType)portMAX_DELAY)) {\n                 switch(event.type) {\n                     case UART_DATA:\n-                        if(uart->_onReceiveCB && uart->available() > 0) uart->_onReceiveCB();\n+                        if(uart->_onReceiveCB && uart->available() > 0 && \n+                            ((uart->_onReceiveTimeout && event.timeout_flag) || !uart->_onReceiveTimeout) ) \n+                                uart->_onReceiveCB();\n                         break;\n                     case UART_FIFO_OVF:\n                         log_w(\"UART%d FIFO Overflow. Consider adding Hardware Flow Control to your Application.\", uart->_uart_nr);\n                         if(uart->_onReceiveErrorCB) uart->_onReceiveErrorCB(UART_FIFO_OVF_ERROR);\n                         break;\n                     case UART_BUFFER_FULL:\n-                        log_w(\"UART%d Buffer Full. Consider encreasing your buffer size of your Application.\", uart->_uart_nr);\n+                        log_w(\"UART%d Buffer Full. Consider increasing your buffer size of your Application.\", uart->_uart_nr);\n                         if(uart->_onReceiveErrorCB) uart->_onReceiveErrorCB(UART_BUFFER_FULL_ERROR);\n                         break;\n                     case UART_BREAK:\n@@ -317,6 +352,12 @@ void HardwareSerial::begin(unsigned long baud, uint32_t config, int8_t rxPin, in\n     if (_uart != NULL && (_onReceiveCB != NULL || _onReceiveErrorCB != NULL) && _eventTask == NULL) {\n         _createEventTask(this);\n     }\n+\n+    // Set UART RX timeout\n+    if (_uart != NULL) {\n+        uart_set_rx_timeout(_uart_nr, _rxTimeout);\n+    }\n+\n     HSERIAL_MUTEX_UNLOCK();\n }\n \ndiff --git a/cores/esp32/HardwareSerial.h b/cores/esp32/HardwareSerial.h\nindex 4291c046b86..d886bdc5c31 100644\n--- a/cores/esp32/HardwareSerial.h\n+++ b/cores/esp32/HardwareSerial.h\n@@ -73,10 +73,31 @@ class HardwareSerial: public Stream\n     HardwareSerial(int uart_nr);\n     ~HardwareSerial();\n \n-    // onReceive will setup a callback for whenever UART data is received\n-    // it will work as UART Rx interrupt -- Using C++ 11 std::fuction \n-    void onReceive(OnReceiveCb function);\n+    // setRxTimeout sets the timeout after which onReceive callback will be called (after receiving data, it waits for this time of UART rx inactivity to call the callback fnc)\n+    // param symbols_timeout defines a timeout threshold in uart symbol periods. Setting 0 symbol timeout disables the callback call by timeout.\n+    //                       Maximum timeout setting is calculacted automatically by IDF. If set above the maximum, it is ignored and an error is printed on Serial0 (check console).\n+    //                       Examples: Maximum for 11 bits symbol is 92 (SERIAL_8N2, SERIAL_8E1, SERIAL_8O1, etc), Maximum for 10 bits symbol is 101 (SERIAL_8N1).\n+    //                       For example symbols_timeout=1 defines a timeout equal to transmission time of one symbol (~11 bit) on current baudrate. \n+    //                       For a baudrate of 9600, SERIAL_8N1 (10 bit symbol) and symbols_timeout = 3, the timeout would be 3 / (9600 / 10) = 3.125 ms\n+    void setRxTimeout(uint8_t symbols_timeout);\n+\n+    // onReceive will setup a callback that will be called whenever an UART interruption occurs (UART_INTR_RXFIFO_FULL or UART_INTR_RXFIFO_TOUT)\n+    // UART_INTR_RXFIFO_FULL interrupt triggers at UART_FULL_THRESH_DEFAULT bytes received (defined as 120 bytes by default in IDF)\n+    // UART_INTR_RXFIFO_TOUT interrupt triggers at UART_TOUT_THRESH_DEFAULT symbols passed without any reception (defined as 10 symbos by default in IDF)\n+    // onlyOnTimeout parameter will define how onReceive will behave:\n+    // Default: true -- The callback will only be called when RX Timeout happens. \n+    //                  Whole stream of bytes will be ready for being read on the callback function at once.\n+    //                  This option may lead to Rx Overflow depending on the Rx Buffer Size and number of bytes received in the streaming\n+    //         false -- The callback will be called when FIFO reaches 120 bytes and also on RX Timeout.\n+    //                  The stream of incommig bytes will be \"split\" into blocks of 120 bytes on each callback.\n+    //                  This option avoid any sort of Rx Overflow, but leaves the UART packet reassembling work to the Application.\n+    void onReceive(OnReceiveCb function, bool onlyOnTimeout = true);\n+\n+    // onReceive will be called on error events (see hardwareSerial_error_t)\n     void onReceiveError(OnReceiveErrorCb function);\n+\n+    // eventQueueReset clears all events in the queue (the events that trigger onReceive and onReceiveError) - maybe usefull in some use cases\n+    void eventQueueReset();\n  \n     void begin(unsigned long baud, uint32_t config=SERIAL_8N1, int8_t rxPin=-1, int8_t txPin=-1, bool invert=false, unsigned long timeout_ms = 20000UL, uint8_t rxfifo_full_thrhd = 112);\n     void end(bool fullyTerminate = true);\n@@ -140,6 +161,9 @@ class HardwareSerial: public Stream\n     size_t _rxBufferSize;\n     size_t _txBufferSize;\n     OnReceiveCb _onReceiveCB;\n+    // _onReceive and _rxTimeout have be consistent when timeout is disabled\n+    bool _onReceiveTimeout;\n+    uint8_t _rxTimeout;\n     OnReceiveErrorCb _onReceiveErrorCB;\n     TaskHandle_t _eventTask;\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **UART2 Issues**: Data loss noted after transitioning from version 1.xx to 2.02. Users must confirm functionality with the latest version or revert to 2.0.3.\n\n2. **Callback Logic**: The `onReceive` callback now triggers only on timeout or after 120 bytes, not both. Consider adding logic to identify if the callback is due to a timeout or data limit breach.\n\n3. **Function Naming**: Change `onReceiveTimeout()` to `setRxTimeout()` for clarity regarding its purpose.\n\n4. **Critical Timeout Settings**: Retain `setRxTimeout()` for precise Modbus timing (3.5 symbols). Removing it affects users reliant on accurate timing.\n\n5. **Safety Checks**: Ensure `onReceive()` maintains functionality when `setRxTimeout()` is set to zero, handling user calls in any sequence. \n\n**Next Steps**: Verify these updates and confirm readiness for merge."
      }
    ],
    "codediff_length": 7952
  },
  {
    "index": 63,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 5290b2cc9c8..d59a8b8e210 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -3,6 +3,7 @@ set(CORE_SRCS\n   cores/esp32/cbuf.cpp\n   cores/esp32/esp32-hal-adc.c\n   cores/esp32/esp32-hal-bt.c\n+  cores/esp32/esp32-hal-cpu.c\n   cores/esp32/esp32-hal-dac.c\n   cores/esp32/esp32-hal-gpio.c\n   cores/esp32/esp32-hal-i2c.c\ndiff --git a/boards.txt b/boards.txt\nindex 17fed9f95f6..42a6f5afd46 100644\n--- a/boards.txt\n+++ b/boards.txt\n@@ -50,11 +50,11 @@ esp32.menu.PartitionScheme.min_spiffs.upload.maximum_size=1966080\n esp32.menu.PartitionScheme.fatflash=16M Fat\n esp32.menu.PartitionScheme.fatflash.build.partitions=ffat\n \n-esp32.menu.CPUFreq.240=240MHz\n+esp32.menu.CPUFreq.240=240MHz (WiFi/BT)\n esp32.menu.CPUFreq.240.build.f_cpu=240000000L\n-esp32.menu.CPUFreq.160=160MHz\n+esp32.menu.CPUFreq.160=160MHz (WiFi/BT)\n esp32.menu.CPUFreq.160.build.f_cpu=160000000L\n-esp32.menu.CPUFreq.80=80MHz\n+esp32.menu.CPUFreq.80=80MHz (WiFi/BT)\n esp32.menu.CPUFreq.80.build.f_cpu=80000000L\n esp32.menu.CPUFreq.40=40MHz (40MHz XTAL)\n esp32.menu.CPUFreq.40.build.f_cpu=40000000L\n@@ -62,22 +62,10 @@ esp32.menu.CPUFreq.26=26MHz (26MHz XTAL)\n esp32.menu.CPUFreq.26.build.f_cpu=26000000L\n esp32.menu.CPUFreq.20=20MHz (40MHz XTAL)\n esp32.menu.CPUFreq.20.build.f_cpu=20000000L\n-esp32.menu.CPUFreq.13=13MHz\n+esp32.menu.CPUFreq.13=13MHz (26MHz XTAL)\n esp32.menu.CPUFreq.13.build.f_cpu=13000000L\n esp32.menu.CPUFreq.10=10MHz (40MHz XTAL)\n esp32.menu.CPUFreq.10.build.f_cpu=10000000L\n-esp32.menu.CPUFreq.8=8MHz (40MHz XTAL)\n-esp32.menu.CPUFreq.8.build.f_cpu=8000000L\n-esp32.menu.CPUFreq.5=5MHz\n-esp32.menu.CPUFreq.5.build.f_cpu=5000000L\n-esp32.menu.CPUFreq.4=4MHz\n-esp32.menu.CPUFreq.4.build.f_cpu=4000000L\n-esp32.menu.CPUFreq.3=3MHz\n-esp32.menu.CPUFreq.3.build.f_cpu=3000000L\n-esp32.menu.CPUFreq.2=2MHz\n-esp32.menu.CPUFreq.2.build.f_cpu=2000000L\n-esp32.menu.CPUFreq.1=1MHz\n-esp32.menu.CPUFreq.1.build.f_cpu=1000000L\n \n esp32.menu.FlashMode.qio=QIO\n esp32.menu.FlashMode.qio.build.flash_mode=dio\ndiff --git a/cores/esp32/esp32-hal-cpu.c b/cores/esp32/esp32-hal-cpu.c\nnew file mode 100644\nindex 00000000000..d9e95dc8067\n--- /dev/null\n+++ b/cores/esp32/esp32-hal-cpu.c\n@@ -0,0 +1,211 @@\n+// Copyright 2015-2016 Espressif Systems (Shanghai) PTE LTD\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+\n+//     http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+#include \"sdkconfig.h\"\n+#include \"freertos/FreeRTOS.h\"\n+#include \"freertos/semphr.h\"\n+#include \"freertos/task.h\"\n+#include \"freertos/xtensa_timer.h\"\n+#include \"esp_attr.h\"\n+#include \"esp_log.h\"\n+#include \"soc/rtc.h\"\n+#include \"soc/rtc_cntl_reg.h\"\n+#include \"rom/rtc.h\"\n+#include \"soc/apb_ctrl_reg.h\"\n+#include \"esp32-hal.h\"\n+#include \"esp32-hal-cpu.h\"\n+\n+typedef struct apb_change_cb_s {\n+        struct apb_change_cb_s * next;\n+        void * arg;\n+        apb_change_cb_t cb;\n+} apb_change_t;\n+\n+const uint32_t MHZ = 1000000;\n+\n+static apb_change_t * apb_change_callbacks = NULL;\n+static xSemaphoreHandle apb_change_lock = NULL;\n+\n+static void initApbChangeCallback(){\n+    static volatile bool initialized = false;\n+    if(!initialized){\n+        initialized = true;\n+        apb_change_lock = xSemaphoreCreateMutex();\n+        if(!apb_change_lock){\n+            initialized = false;\n+        }\n+    }\n+}\n+\n+static void triggerApbChangeCallback(apb_change_ev_t ev_type, uint32_t old_apb, uint32_t new_apb){\n+    initApbChangeCallback();\n+    xSemaphoreTake(apb_change_lock, portMAX_DELAY);\n+    apb_change_t * r = apb_change_callbacks;\n+    while(r != NULL){\n+        r->cb(r->arg, ev_type, old_apb, new_apb);\n+        r=r->next;\n+    }\n+    xSemaphoreGive(apb_change_lock);\n+}\n+\n+bool addApbChangeCallback(void * arg, apb_change_cb_t cb){\n+    initApbChangeCallback();\n+    apb_change_t * c = (apb_change_t*)malloc(sizeof(apb_change_t));\n+    if(!c){\n+        log_e(\"Callback Object Malloc Failed\");\n+        return false;\n+    }\n+    c->next = NULL;\n+    c->arg = arg;\n+    c->cb = cb;\n+    xSemaphoreTake(apb_change_lock, portMAX_DELAY);\n+    if(apb_change_callbacks == NULL){\n+        apb_change_callbacks = c;\n+    } else {\n+        apb_change_t * r = apb_change_callbacks;\n+        if(r->cb != cb || r->arg != arg){\n+            while(r->next){\n+                r = r->next;\n+                if(r->cb == cb && r->arg == arg){\n+                    free(c);\n+                    goto unlock_and_exit;\n+                }\n+            }\n+            r->next = c;\n+        }\n+    }\n+unlock_and_exit:\n+    xSemaphoreGive(apb_change_lock);\n+    return true;\n+}\n+\n+bool removeApbChangeCallback(void * arg, apb_change_cb_t cb){\n+    initApbChangeCallback();\n+    xSemaphoreTake(apb_change_lock, portMAX_DELAY);\n+    apb_change_t * r = apb_change_callbacks;\n+    if(r == NULL){\n+        xSemaphoreGive(apb_change_lock);\n+        return false;\n+    }\n+    if(r->cb == cb && r->arg == arg){\n+        apb_change_callbacks = r->next;\n+        free(r);\n+    } else {\n+        while(r->next && (r->next->cb != cb || r->next->arg != arg)){\n+            r = r->next;\n+        }\n+        if(r->next == NULL || r->next->cb != cb || r->next->arg != arg){\n+            xSemaphoreGive(apb_change_lock);\n+            return false;\n+        }\n+        apb_change_t * c = r->next;\n+        r->next = c->next;\n+        free(c);\n+    }\n+    xSemaphoreGive(apb_change_lock);\n+    return true;\n+}\n+\n+static uint32_t calculateApb(rtc_cpu_freq_config_t * conf){\n+    if(conf->freq_mhz >= 80){\n+        return 80 * MHZ;\n+    }\n+    return (conf->source_freq_mhz * MHZ) / conf->div;\n+}\n+\n+void esp_timer_impl_update_apb_freq(uint32_t apb_ticks_per_us); //private in IDF\n+\n+bool setCpuFrequencyMhz(uint32_t cpu_freq_mhz){\n+    rtc_cpu_freq_config_t conf, cconf;\n+    uint32_t capb, apb;\n+    //Get XTAL Frequency and calculate min CPU MHz\n+    rtc_xtal_freq_t xtal = rtc_clk_xtal_freq_get();\n+    uint32_t min_cpu_mhz = 10;\n+    if(xtal > RTC_XTAL_FREQ_AUTO){\n+        if(xtal < RTC_XTAL_FREQ_40M) {\n+            min_cpu_mhz = xtal / 2; //13Mhz for 26Mhz XTAL\n+            if(cpu_freq_mhz <= xtal && cpu_freq_mhz != xtal && cpu_freq_mhz != (xtal/2)){\n+                log_e(\"Bad frequency: %u MHz! Options are: 240, 160, 80, %u and %u MHz\", cpu_freq_mhz, xtal, xtal/2);\n+                return false;\n+            }\n+        } else if(cpu_freq_mhz <= xtal && cpu_freq_mhz != xtal && cpu_freq_mhz != (xtal/2) && cpu_freq_mhz != (xtal/4)){\n+            log_e(\"Bad frequency: %u MHz! Options are: 240, 160, 80, %u, %u and %u MHz\", cpu_freq_mhz, xtal, xtal/2, xtal/4);\n+            return false;\n+        }\n+    }\n+    if(cpu_freq_mhz > xtal && cpu_freq_mhz != 240 && cpu_freq_mhz != 160 && cpu_freq_mhz != 80){\n+        if(xtal >= RTC_XTAL_FREQ_40M){\n+            log_e(\"Bad frequency: %u MHz! Options are: 240, 160, 80, %u, %u and %u MHz\", cpu_freq_mhz, xtal, xtal/2, xtal/4);\n+        } else {\n+            log_e(\"Bad frequency: %u MHz! Options are: 240, 160, 80, %u and %u MHz\", cpu_freq_mhz, xtal, xtal/2);\n+        }\n+        return false;\n+    }\n+    //Get current CPU clock configuration\n+    rtc_clk_cpu_freq_get_config(&cconf);\n+    //return if frequency has not changed\n+    if(cconf.freq_mhz == cpu_freq_mhz){\n+        return true;\n+    }\n+    //Get configuration for the new CPU frequency\n+    if(!rtc_clk_cpu_freq_mhz_to_config(cpu_freq_mhz, &conf)){\n+        log_e(\"CPU clock could not be set to %u MHz\", cpu_freq_mhz);\n+        return false;\n+    }\n+    //Current APB\n+    capb = calculateApb(&cconf);\n+    //New APB\n+    apb = calculateApb(&conf);\n+    log_d(\"%s: %u / %u = %u Mhz, APB: %u Hz\", (conf.source == RTC_CPU_FREQ_SRC_PLL)?\"PLL\":((conf.source == RTC_CPU_FREQ_SRC_APLL)?\"APLL\":((conf.source == RTC_CPU_FREQ_SRC_XTAL)?\"XTAL\":\"8M\")), conf.source_freq_mhz, conf.div, conf.freq_mhz, apb);\n+    //Call peripheral functions before the APB change\n+    if(apb_change_callbacks){\n+        triggerApbChangeCallback(APB_BEFORE_CHANGE, capb, apb);\n+    }\n+    //Make the frequency change\n+    rtc_clk_cpu_freq_set_config_fast(&conf);\n+    if(capb != apb){\n+        //Update REF_TICK (uncomment if REF_TICK is different than 1MHz)\n+        //if(conf.freq_mhz < 80){\n+        //    ESP_REG(APB_CTRL_XTAL_TICK_CONF_REG) = conf.freq_mhz / (REF_CLK_FREQ / MHZ) - 1;\n+        //}\n+        //Update APB Freq REG\n+        rtc_clk_apb_freq_update(apb);\n+        //Update esp_timer divisor\n+        esp_timer_impl_update_apb_freq(apb / MHZ);\n+    }\n+    //Update FreeRTOS Tick Divisor\n+    uint32_t fcpu = (conf.freq_mhz >= 80)?(conf.freq_mhz * MHZ):(apb);\n+    _xt_tick_divisor = fcpu / XT_TICK_PER_SEC;\n+    //Call peripheral functions after the APB change\n+    if(apb_change_callbacks){\n+        triggerApbChangeCallback(APB_AFTER_CHANGE, capb, apb);\n+    }\n+    return true;\n+}\n+\n+uint32_t getCpuFrequencyMhz(){\n+    rtc_cpu_freq_config_t conf;\n+    rtc_clk_cpu_freq_get_config(&conf);\n+    return conf.freq_mhz;\n+}\n+\n+uint32_t getXtalFrequencyMhz(){\n+    return rtc_clk_xtal_freq_get();\n+}\n+\n+uint32_t getApbFrequency(){\n+    rtc_cpu_freq_config_t conf;\n+    rtc_clk_cpu_freq_get_config(&conf);\n+    return calculateApb(&conf);\n+}\ndiff --git a/cores/esp32/esp32-hal-cpu.h b/cores/esp32/esp32-hal-cpu.h\nnew file mode 100644\nindex 00000000000..646b59858f5\n--- /dev/null\n+++ b/cores/esp32/esp32-hal-cpu.h\n@@ -0,0 +1,48 @@\n+// Copyright 2015-2016 Espressif Systems (Shanghai) PTE LTD\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+\n+//     http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+#ifndef _ESP32_HAL_CPU_H_\n+#define _ESP32_HAL_CPU_H_\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+#include <stdint.h>\n+#include <stdbool.h>\n+#include <stdlib.h>\n+\n+typedef enum { APB_BEFORE_CHANGE, APB_AFTER_CHANGE } apb_change_ev_t;\n+\n+typedef void (* apb_change_cb_t)(void * arg, apb_change_ev_t ev_type, uint32_t old_apb, uint32_t new_apb);\n+\n+bool addApbChangeCallback(void * arg, apb_change_cb_t cb);\n+bool removeApbChangeCallback(void * arg, apb_change_cb_t cb);\n+\n+//function takes the following frequencies as valid values:\n+//  240, 160, 80    <<< For all XTAL types\n+//  40, 20, 10      <<< For 40MHz XTAL\n+//  26, 13          <<< For 26MHz XTAL\n+//  24, 12          <<< For 24MHz XTAL\n+bool setCpuFrequencyMhz(uint32_t cpu_freq_mhz);\n+\n+uint32_t getCpuFrequencyMhz();  // In MHz\n+uint32_t getXtalFrequencyMhz(); // In MHz\n+uint32_t getApbFrequency();     // In Hz\n+\n+#ifdef __cplusplus\n+}\n+#endif\n+\n+#endif /* _ESP32_HAL_CPU_H_ */\ndiff --git a/cores/esp32/esp32-hal-i2c.c b/cores/esp32/esp32-hal-i2c.c\nindex 174e437682b..f8c384afb7f 100644\n--- a/cores/esp32/esp32-hal-i2c.c\n+++ b/cores/esp32/esp32-hal-i2c.c\n@@ -24,7 +24,7 @@\n #include \"soc/i2c_struct.h\"\n #include \"soc/dport_reg.h\"\n #include \"esp_attr.h\"\n-\n+#include \"esp32-hal-cpu.h\" // cpu clock change support 31DEC2018\n //#define I2C_DEV(i)   (volatile i2c_dev_t *)((i)?DR_REG_I2C1_EXT_BASE:DR_REG_I2C_EXT_BASE)\n //#define I2C_DEV(i)   ((i2c_dev_t *)(REG_I2C_BASE(i)))\n #define I2C_SCL_IDX(p)  ((p==0)?I2CEXT0_SCL_OUT_IDX:((p==1)?I2CEXT1_SCL_OUT_IDX:0))\n@@ -206,8 +206,8 @@ static i2c_t _i2c_bus_array[2] = {\n     {(volatile i2c_dev_t *)(DR_REG_I2C1_EXT_BASE_FIXED), 1, -1, -1,I2C_NONE,I2C_NONE,I2C_ERROR_OK,NULL,NULL,NULL,0,0,0,0,0}\n };\n #else\n-#define I2C_MUTEX_LOCK()    do {} while (xSemaphoreTake(i2c->lock, portMAX_DELAY) != pdPASS)\n-#define I2C_MUTEX_UNLOCK()  xSemaphoreGive(i2c->lock)\n+#define I2C_MUTEX_LOCK()    do {} while (xSemaphoreTakeRecursive(i2c->lock, portMAX_DELAY) != pdPASS)\n+#define I2C_MUTEX_UNLOCK()  xSemaphoreGiveRecursive(i2c->lock)\n \n static i2c_t _i2c_bus_array[2] = {\n     {(volatile i2c_dev_t *)(DR_REG_I2C_EXT_BASE_FIXED), NULL, 0, -1, -1, I2C_NONE,I2C_NONE,I2C_ERROR_OK,NULL,NULL,NULL,0,0,0,0,0,0},\n@@ -445,6 +445,39 @@ static void IRAM_ATTR i2cTriggerDumps(i2c_t * i2c, uint8_t trigger, const char l\n }\n  // end of debug support routines\n  \n+/* Start of CPU Clock change Support\n+*/\n+\n+static void i2cApbChangeCallback(void * arg, apb_change_ev_t ev_type, uint32_t old_apb, uint32_t new_apb){\n+    i2c_t* i2c = (i2c_t*) arg; // recover data\n+    if(i2c == NULL) {  // point to peripheral control block does not exits\n+        return false;\n+    }\n+    uint32_t oldFreq=0;\n+    switch(ev_type){\n+        case APB_BEFORE_CHANGE : \n+            if(new_apb < 3000000) {// too slow\n+                log_e(\"apb speed %d too slow\",new_apb);\n+                break;\n+            }\n+            I2C_MUTEX_LOCK(); // lock will spin until current transaction is completed\n+            break;\n+        case APB_AFTER_CHANGE :\n+            oldFreq = (i2c->dev->scl_low_period.period+i2c->dev->scl_high_period.period); //read old apbCycles \n+            if(oldFreq>0) { // was configured with value\n+                oldFreq = old_apb / oldFreq;\n+                i2cSetFrequency(i2c,oldFreq);\n+            }\n+            I2C_MUTEX_UNLOCK();\n+            break;\n+        default : \n+            log_e(\"unk ev %u\",ev_type);\n+            I2C_MUTEX_UNLOCK();\n+    }\n+    return;\n+}\n+/* End of CPU Clock change Support\n+*/ \n static void IRAM_ATTR i2cSetCmd(i2c_t * i2c, uint8_t index, uint8_t op_code, uint8_t byte_num, bool ack_val, bool ack_exp, bool ack_check)\n {\n     I2C_COMMAND_t cmd;\n@@ -1221,6 +1254,12 @@ i2c_err_t i2cProcQueue(i2c_t * i2c, uint32_t *readCount, uint16_t timeOutMillis)\n             I2C_MUTEX_UNLOCK();\n             return I2C_ERROR_MEMORY;\n         }\n+        if( !addApbChangeCallback( i2c, i2cApbChangeCallback)) {\n+            log_e(\"install apb Callback failed\");\n+            I2C_MUTEX_UNLOCK();\n+            return I2C_ERROR_DEV;\n+        }\n+\n     }\n     //hang until it completes.\n \n@@ -1352,6 +1391,9 @@ static void i2cReleaseISR(i2c_t * i2c)\n     if(i2c->intr_handle) {\n         esp_intr_free(i2c->intr_handle);\n         i2c->intr_handle=NULL;\n+        if (!removeApbChangeCallback( i2c, i2cApbChangeCallback)) {\n+            log_e(\"unable to release apbCallback\");\n+        }\n     }\n }\n \n@@ -1437,8 +1479,7 @@ i2c_err_t i2cDetachSDA(i2c_t * i2c, int8_t sda)\n  * PUBLIC API\n  * */\n // 24Nov17 only supports Master Mode\n-i2c_t * i2cInit(uint8_t i2c_num, int8_t sda, int8_t scl, uint32_t frequency) //before this is called, pins should be detached, else glitch\n-{\n+i2c_t * i2cInit(uint8_t i2c_num, int8_t sda, int8_t scl, uint32_t frequency) {\n   log_v(\"num=%d sda=%d scl=%d freq=%d\",i2c_num, sda, scl, frequency);\n     if(i2c_num > 1) {\n         return NULL;\n@@ -1446,6 +1487,7 @@ i2c_t * i2cInit(uint8_t i2c_num, int8_t sda, int8_t scl, uint32_t frequency) //b\n \n     i2c_t * i2c = &_i2c_bus_array[i2c_num];\n \n+    // pins should be detached, else glitch\n     if(i2c->sda >= 0){\n         i2cDetachSDA(i2c, i2c->sda);\n     }\n@@ -1457,7 +1499,7 @@ i2c_t * i2cInit(uint8_t i2c_num, int8_t sda, int8_t scl, uint32_t frequency) //b\n \n #if !CONFIG_DISABLE_HAL_LOCKS\n     if(i2c->lock == NULL) {\n-        i2c->lock = xSemaphoreCreateMutex();\n+        i2c->lock = xSemaphoreCreateRecursiveMutex();\n         if(i2c->lock == NULL) {\n             return NULL;\n         }\n@@ -1604,7 +1646,8 @@ i2c_err_t i2cRead(i2c_t * i2c, uint16_t address, uint8_t* buff, uint16_t size, b\n     return last_error;\n }\n \n-#define MIN_I2C_CLKS 100\n+#define MIN_I2C_CLKS 100              // minimum ratio between cpu and i2c Bus clocks\n+#define INTERRUPT_CYCLE_OVERHEAD 16000 // number of cpu clocks necessary to respond to interrupt\n i2c_err_t i2cSetFrequency(i2c_t * i2c, uint32_t clk_speed)\n {\n     if(i2c == NULL) {\n@@ -1614,17 +1657,18 @@ i2c_err_t i2cSetFrequency(i2c_t * i2c, uint32_t clk_speed)\n     uint32_t period = (apb/clk_speed) / 2;\n \n     if((apb/8192 > clk_speed)||(apb/MIN_I2C_CLKS < clk_speed)){ //out of bounds\n-        log_w(\"i2c freq(%d) out of bounds.vs APB Clock(%d), min=%d, max=%d\",clk_speed,apb,(apb/8192),(apb/MIN_I2C_CLKS));\n+        log_d(\"i2c freq(%d) out of bounds.vs APB Clock(%d), min=%d, max=%d\",clk_speed,apb,(apb/8192),(apb/MIN_I2C_CLKS));\n     }\n     if(period < (MIN_I2C_CLKS/2) ){\n         period = (MIN_I2C_CLKS/2);\n         clk_speed = apb/(period*2);\n-        log_w(\"APB Freq too slow, Reducing i2c Freq to %d Hz\",clk_speed);\n+        log_d(\"APB Freq too slow, Reducing i2c Freq to %d Hz\",clk_speed);\n     } else if ( period> 4095) {\n         period = 4095;\n         clk_speed = apb/(period*2);\n-        log_w(\"APB Freq too fast, Increasing i2c Freq to %d Hz\",clk_speed);\n+        log_d(\"APB Freq too fast, Increasing i2c Freq to %d Hz\",clk_speed);\n     }\n+    log_v(\"freq=%dHz\",clk_speed);\n       \n     uint32_t halfPeriod = period/2;\n     uint32_t quarterPeriod = period/4;\n@@ -1633,14 +1677,19 @@ i2c_err_t i2cSetFrequency(i2c_t * i2c, uint32_t clk_speed)\n \n     I2C_FIFO_CONF_t f;\n \n-    // Adjust Fifo thresholds based on frequency\n     f.val    = i2c->dev->fifo_conf.val;\n-    uint32_t a = (clk_speed / 50000L )+1; \n-    if (a > 24) a=24;   \n-    f.rx_fifo_full_thrhd = 32 - a;\n-    f.tx_fifo_empty_thrhd = a;\n+/*  Adjust Fifo thresholds based on differential between cpu frequency and bus clock.\n+    The fifo_delta is calculated such that at least INTERRUPT_CYCLE_OVERHEAD cpu clocks are\n+    available when a Fifo interrupt is triggered.  This allows enough room in the Fifo so that\n+    interrupt latency does not cause a Fifo overflow/underflow event.\n+*/\n+    log_v(\"cpu Freq=%dMhz, i2c Freq=%dHz\",getCpuFrequencyMhz(),clk_speed);\n+    uint32_t fifo_delta = (INTERRUPT_CYCLE_OVERHEAD/((getCpuFrequencyMhz()*1000000 / clk_speed)*10))+1; \n+    if (fifo_delta > 24) fifo_delta=24;   \n+    f.rx_fifo_full_thrhd = 32 - fifo_delta;\n+    f.tx_fifo_empty_thrhd = fifo_delta;\n     i2c->dev->fifo_conf.val = f.val; // set thresholds\n-    log_v(\"Fifo threshold=%d\",a);\n+    log_v(\"Fifo delta=%d\",fifo_delta);\n \n     //the clock num during SCL is low level\n     i2c->dev->scl_low_period.period = period;\n@@ -1696,6 +1745,8 @@ uint32_t i2cGetStatus(i2c_t * i2c){\n     }\n     else return 0;\n }\n+\n+\n /* todo\n   22JUL18\n     need to add multi-thread capability, use dq.queueEvent as the group marker. When multiple threads\ndiff --git a/cores/esp32/esp32-hal-ledc.c b/cores/esp32/esp32-hal-ledc.c\nindex 4d10d4eecdf..b23a17db335 100644\n--- a/cores/esp32/esp32-hal-ledc.c\n+++ b/cores/esp32/esp32-hal-ledc.c\n@@ -53,6 +53,33 @@ xSemaphoreHandle _ledc_sys_lock;\n #define LEDC_CHAN(g,c) LEDC.channel_group[(g)].channel[(c)]\n #define LEDC_TIMER(g,t) LEDC.timer_group[(g)].timer[(t)]\n \n+static void _on_apb_change(void * arg, apb_change_ev_t ev_type, uint32_t old_apb, uint32_t new_apb){\n+    if(ev_type == APB_AFTER_CHANGE && old_apb != new_apb){\n+        uint32_t iarg = (uint32_t)arg;\n+        uint8_t chan = iarg;\n+        uint8_t group=(chan/8), timer=((chan/2)%4);\n+        old_apb /= 1000000;\n+        new_apb /= 1000000;\n+        if(LEDC_TIMER(group, timer).conf.tick_sel){\n+            LEDC_MUTEX_LOCK();\n+            uint32_t old_div = LEDC_TIMER(group, timer).conf.clock_divider;\n+            uint32_t div_num = (new_apb * old_div) / old_apb;\n+            if(div_num > LEDC_DIV_NUM_HSTIMER0_V){\n+                new_apb = REF_CLK_FREQ / 1000000;\n+                div_num = (new_apb * old_div) / old_apb;\n+                if(div_num > LEDC_DIV_NUM_HSTIMER0_V) {\n+                    div_num = LEDC_DIV_NUM_HSTIMER0_V;//lowest clock possible\n+                }\n+                LEDC_TIMER(group, timer).conf.tick_sel = 0;\n+            } else if(div_num < 256) {\n+                div_num = 256;//highest clock possible\n+            }\n+            LEDC_TIMER(group, timer).conf.clock_divider = div_num;\n+            LEDC_MUTEX_UNLOCK();\n+        }\n+    }\n+}\n+\n //uint32_t frequency = (80MHz or 1MHz)/((div_num / 256.0)*(1 << bit_num));\n static void _ledcSetupTimer(uint8_t chan, uint32_t div_num, uint8_t bit_num, bool apb_clk)\n {\n@@ -78,6 +105,8 @@ static void _ledcSetupTimer(uint8_t chan, uint32_t div_num, uint8_t bit_num, boo\n     LEDC_TIMER(group, timer).conf.rst = 1;//This bit is used to reset timer the counter will be 0 after reset.\n     LEDC_TIMER(group, timer).conf.rst = 0;\n     LEDC_MUTEX_UNLOCK();\n+    uint32_t iarg = chan;\n+    addApbChangeCallback((void*)iarg, _on_apb_change);\n }\n \n //max div_num 0x3FFFF (262143)\ndiff --git a/cores/esp32/esp32-hal-misc.c b/cores/esp32/esp32-hal-misc.c\nindex 3a22346b995..06ed677d5d2 100644\n--- a/cores/esp32/esp32-hal-misc.c\n+++ b/cores/esp32/esp32-hal-misc.c\n@@ -27,6 +27,7 @@\n #include <sys/time.h>\n #include \"soc/rtc.h\"\n #include \"soc/rtc_cntl_reg.h\"\n+#include \"soc/apb_ctrl_reg.h\"\n #include \"rom/rtc.h\"\n #include \"esp_task_wdt.h\"\n #include \"esp32-hal.h\"\n@@ -100,57 +101,19 @@ void disableCore1WDT(){\n }\n #endif\n \n-static uint32_t _cpu_freq_mhz = CONFIG_ESP32_DEFAULT_CPU_FREQ_MHZ;\n-static uint32_t _sys_time_multiplier = 1;\n-\n-bool setCpuFrequency(uint32_t cpu_freq_mhz){\n-    rtc_cpu_freq_config_t conf, cconf;\n-    rtc_clk_cpu_freq_get_config(&cconf);\n-    if(cconf.freq_mhz == cpu_freq_mhz && _cpu_freq_mhz == cpu_freq_mhz){\n-        return true;\n-    }\n-    if(!rtc_clk_cpu_freq_mhz_to_config(cpu_freq_mhz, &conf)){\n-        log_e(\"CPU clock could not be set to %u MHz\", cpu_freq_mhz);\n-        return false;\n-    }\n-#if ARDUHAL_LOG_LEVEL >= ARDUHAL_LOG_LEVEL_INFO\n-    log_i(\"%s: %u / %u = %u Mhz\", (conf.source == RTC_CPU_FREQ_SRC_PLL)?\"PLL\":((conf.source == RTC_CPU_FREQ_SRC_APLL)?\"APLL\":((conf.source == RTC_CPU_FREQ_SRC_XTAL)?\"XTAL\":\"8M\")), conf.source_freq_mhz, conf.div, conf.freq_mhz);\n-    delay(10);\n-#endif\n-    rtc_clk_cpu_freq_set_config_fast(&conf);\n-    _cpu_freq_mhz = conf.freq_mhz;\n-    _sys_time_multiplier = 80000000 / getApbFrequency();\n-    return true;\n-}\n-\n-uint32_t getCpuFrequency(){\n-    rtc_cpu_freq_config_t conf;\n-    rtc_clk_cpu_freq_get_config(&conf);\n-    return conf.freq_mhz;\n-}\n-\n-uint32_t getApbFrequency(){\n-    rtc_cpu_freq_config_t conf;\n-    rtc_clk_cpu_freq_get_config(&conf);\n-    if(conf.freq_mhz >= 80){\n-        return 80000000;\n-    }\n-    return (conf.source_freq_mhz * 1000000) / conf.div;\n-}\n-\n unsigned long IRAM_ATTR micros()\n {\n-    return (unsigned long) (esp_timer_get_time()) * _sys_time_multiplier;\n+    return (unsigned long) (esp_timer_get_time());\n }\n \n unsigned long IRAM_ATTR millis()\n {\n-    return (unsigned long) (micros() / 1000);\n+    return (unsigned long) (esp_timer_get_time() / 1000);\n }\n \n void delay(uint32_t ms)\n {\n-    vTaskDelay((ms * _cpu_freq_mhz) / (portTICK_PERIOD_MS * 240));\n+    vTaskDelay(ms / portTICK_PERIOD_MS);\n }\n \n void IRAM_ATTR delayMicroseconds(uint32_t us)\n@@ -183,8 +146,10 @@ bool btInUse(){ return false; }\n \n void initArduino()\n {\n+    //init proper ref tick value for PLL (uncomment if REF_TICK is different than 1MHz)\n+    //ESP_REG(APB_CTRL_PLL_TICK_CONF_REG) = APB_CLK_FREQ / REF_CLK_FREQ - 1;\n #ifdef F_CPU\n-    setCpuFrequency(F_CPU/1000000L);\n+    setCpuFrequencyMhz(F_CPU/1000000);\n #endif\n #if CONFIG_SPIRAM_SUPPORT\n     psramInit();\ndiff --git a/cores/esp32/esp32-hal-sigmadelta.c b/cores/esp32/esp32-hal-sigmadelta.c\nindex 64355318abe..098181c77ae 100644\n--- a/cores/esp32/esp32-hal-sigmadelta.c\n+++ b/cores/esp32/esp32-hal-sigmadelta.c\n@@ -31,6 +31,26 @@\n xSemaphoreHandle _sd_sys_lock;\n #endif\n \n+static void _on_apb_change(void * arg, apb_change_ev_t ev_type, uint32_t old_apb, uint32_t new_apb){\n+    if(old_apb == new_apb){\n+        return;\n+    }\n+    uint32_t iarg = (uint32_t)arg;\n+    uint8_t channel = iarg;\n+    if(ev_type == APB_BEFORE_CHANGE){\n+        SIGMADELTA.cg.clk_en = 0;\n+    } else {\n+        old_apb /= 1000000;\n+        new_apb /= 1000000;\n+        SD_MUTEX_LOCK();\n+        uint32_t old_prescale = SIGMADELTA.channel[channel].prescale + 1;\n+        SIGMADELTA.channel[channel].prescale = ((new_apb * old_prescale) / old_apb) - 1;\n+        SIGMADELTA.cg.clk_en = 0;\n+        SIGMADELTA.cg.clk_en = 1;\n+        SD_MUTEX_UNLOCK();\n+    }\n+}\n+\n uint32_t sigmaDeltaSetup(uint8_t channel, uint32_t freq) //chan 0-7 freq 1220-312500\n {\n     if(channel > 7) {\n@@ -53,6 +73,8 @@ uint32_t sigmaDeltaSetup(uint8_t channel, uint32_t freq) //chan 0-7 freq 1220-31\n     SIGMADELTA.cg.clk_en = 0;\n     SIGMADELTA.cg.clk_en = 1;\n     SD_MUTEX_UNLOCK();\n+    uint32_t iarg = channel;\n+    addApbChangeCallback((void*)iarg, _on_apb_change);\n     return apb_freq/((prescale + 1) * 256);\n }\n \ndiff --git a/cores/esp32/esp32-hal-spi.c b/cores/esp32/esp32-hal-spi.c\nindex b262bdaaa0f..d28abf4a5ba 100644\n--- a/cores/esp32/esp32-hal-spi.c\n+++ b/cores/esp32/esp32-hal-spi.c\n@@ -372,6 +372,18 @@ void spiSetBitOrder(spi_t * spi, uint8_t bitOrder)\n     SPI_MUTEX_UNLOCK();\n }\n \n+static void _on_apb_change(void * arg, apb_change_ev_t ev_type, uint32_t old_apb, uint32_t new_apb)\n+{\n+    spi_t * spi = (spi_t *)arg;\n+    if(ev_type == APB_BEFORE_CHANGE){\n+        SPI_MUTEX_LOCK();\n+        while(spi->dev->cmd.usr);\n+    } else {\n+        spi->dev->clock.val = spiFrequencyToClockDiv(old_apb / ((spi->dev->clock.clkdiv_pre + 1) * (spi->dev->clock.clkcnt_n + 1)));\n+        SPI_MUTEX_UNLOCK();\n+    }\n+}\n+\n void spiStopBus(spi_t * spi)\n {\n     if(!spi) {\n@@ -388,6 +400,7 @@ void spiStopBus(spi_t * spi)\n     spi->dev->ctrl2.val = 0;\n     spi->dev->clock.val = 0;\n     SPI_MUTEX_UNLOCK();\n+    removeApbChangeCallback(spi, _on_apb_change);\n }\n \n spi_t * spiStartBus(uint8_t spi_num, uint32_t clockDiv, uint8_t dataMode, uint8_t bitOrder)\n@@ -434,6 +447,7 @@ spi_t * spiStartBus(uint8_t spi_num, uint32_t clockDiv, uint8_t dataMode, uint8_\n     }\n     SPI_MUTEX_UNLOCK();\n \n+    addApbChangeCallback(spi, _on_apb_change);\n     return spi;\n }\n \n@@ -1008,17 +1022,17 @@ void IRAM_ATTR spiWritePixelsNL(spi_t * spi, const void * data_in, size_t len){\n  * */\n \n typedef union {\n-    uint32_t regValue;\n+    uint32_t value;\n     struct {\n-        unsigned regL :6;\n-        unsigned regH :6;\n-        unsigned regN :6;\n-        unsigned regPre :13;\n-        unsigned regEQU :1;\n+            uint32_t clkcnt_l:       6;                     /*it must be equal to spi_clkcnt_N.*/\n+            uint32_t clkcnt_h:       6;                     /*it must be floor((spi_clkcnt_N+1)/2-1).*/\n+            uint32_t clkcnt_n:       6;                     /*it is the divider of spi_clk. So spi_clk frequency is system/(spi_clkdiv_pre+1)/(spi_clkcnt_N+1)*/\n+            uint32_t clkdiv_pre:    13;                     /*it is pre-divider of spi_clk.*/\n+            uint32_t clk_equ_sysclk: 1;                     /*1: spi_clk is eqaul to system 0: spi_clk is divided from system clock.*/\n     };\n } spiClk_t;\n \n-#define ClkRegToFreq(reg) (apb_freq / (((reg)->regPre + 1) * ((reg)->regN + 1)))\n+#define ClkRegToFreq(reg) (apb_freq / (((reg)->clkdiv_pre + 1) * ((reg)->clkcnt_n + 1)))\n \n uint32_t spiClockDivToFrequency(uint32_t clockDiv)\n {\n@@ -1038,7 +1052,7 @@ uint32_t spiFrequencyToClockDiv(uint32_t freq)\n     const spiClk_t minFreqReg = { 0x7FFFF000 };\n     uint32_t minFreq = ClkRegToFreq((spiClk_t*) &minFreqReg);\n     if(freq < minFreq) {\n-        return minFreqReg.regValue;\n+        return minFreqReg.value;\n     }\n \n     uint8_t calN = 1;\n@@ -1051,18 +1065,18 @@ uint32_t spiFrequencyToClockDiv(uint32_t freq)\n         int32_t calPre;\n         int8_t calPreVari = -2;\n \n-        reg.regN = calN;\n+        reg.clkcnt_n = calN;\n \n         while(calPreVari++ <= 1) {\n-            calPre = (((apb_freq / (reg.regN + 1)) / freq) - 1) + calPreVari;\n+            calPre = (((apb_freq / (reg.clkcnt_n + 1)) / freq) - 1) + calPreVari;\n             if(calPre > 0x1FFF) {\n-                reg.regPre = 0x1FFF;\n+                reg.clkdiv_pre = 0x1FFF;\n             } else if(calPre <= 0) {\n-                reg.regPre = 0;\n+                reg.clkdiv_pre = 0;\n             } else {\n-                reg.regPre = calPre;\n+                reg.clkdiv_pre = calPre;\n             }\n-            reg.regL = ((reg.regN + 1) / 2);\n+            reg.clkcnt_l = ((reg.clkcnt_n + 1) / 2);\n             calFreq = ClkRegToFreq(&reg);\n             if(calFreq == (int32_t) freq) {\n                 memcpy(&bestReg, &reg, sizeof(bestReg));\n@@ -1079,6 +1093,6 @@ uint32_t spiFrequencyToClockDiv(uint32_t freq)\n         }\n         calN++;\n     }\n-    return bestReg.regValue;\n+    return bestReg.value;\n }\n \ndiff --git a/cores/esp32/esp32-hal-timer.c b/cores/esp32/esp32-hal-timer.c\nindex 8fcee55f8e1..c6b7fbf5d97 100644\n--- a/cores/esp32/esp32-hal-timer.c\n+++ b/cores/esp32/esp32-hal-timer.c\n@@ -184,6 +184,18 @@ bool timerAlarmEnabled(hw_timer_t *timer){\n     return timer->dev->config.alarm_en;\n }\n \n+static void _on_apb_change(void * arg, apb_change_ev_t ev_type, uint32_t old_apb, uint32_t new_apb){\n+    hw_timer_t * timer = (hw_timer_t *)arg;\n+    if(ev_type == APB_BEFORE_CHANGE){\n+        timer->dev->config.enable = 0;\n+    } else {\n+        old_apb /= 1000000;\n+        new_apb /= 1000000;\n+        timer->dev->config.divider = (new_apb * timer->dev->config.divider) / old_apb;\n+        timer->dev->config.enable = 1;\n+    }\n+}\n+\n hw_timer_t * timerBegin(uint8_t num, uint16_t divider, bool countUp){\n     if(num > 3){\n         return NULL;\n@@ -205,12 +217,14 @@ hw_timer_t * timerBegin(uint8_t num, uint16_t divider, bool countUp){\n     timerAttachInterrupt(timer, NULL, false);\n     timerWrite(timer, 0);\n     timer->dev->config.enable = 1;\n+    addApbChangeCallback(timer, _on_apb_change);\n     return timer;\n }\n \n void timerEnd(hw_timer_t *timer){\n     timer->dev->config.enable = 0;\n     timerAttachInterrupt(timer, NULL, false);\n+    removeApbChangeCallback(timer, _on_apb_change);\n }\n \n void timerAttachInterrupt(hw_timer_t *timer, void (*fn)(void), bool edge){\n@@ -271,23 +285,23 @@ void timerDetachInterrupt(hw_timer_t *timer){\n uint64_t timerReadMicros(hw_timer_t *timer){\n     uint64_t timer_val = timerRead(timer);\n     uint16_t div = timerGetDivider(timer);\n-    return timer_val * div / 80;\n+    return timer_val * div / (getApbFrequency() / 1000000);\n }\n \n double timerReadSeconds(hw_timer_t *timer){\n     uint64_t timer_val = timerRead(timer);\n     uint16_t div = timerGetDivider(timer);\n-    return (double)timer_val * div / 80000000;\n+    return (double)timer_val * div / getApbFrequency();\n }\n \n uint64_t timerAlarmReadMicros(hw_timer_t *timer){\n     uint64_t timer_val = timerAlarmRead(timer);\n     uint16_t div = timerGetDivider(timer);\n-    return timer_val * div / 80;\n+    return timer_val * div / (getApbFrequency() / 1000000);\n }\n \n double timerAlarmReadSeconds(hw_timer_t *timer){\n     uint64_t timer_val = timerAlarmRead(timer);\n     uint16_t div = timerGetDivider(timer);\n-    return (double)timer_val * div / 80000000;\n+    return (double)timer_val * div / getApbFrequency();\n }\ndiff --git a/cores/esp32/esp32-hal-uart.c b/cores/esp32/esp32-hal-uart.c\nindex a76c2409f22..9e60d6bedf1 100644\n--- a/cores/esp32/esp32-hal-uart.c\n+++ b/cores/esp32/esp32-hal-uart.c\n@@ -67,6 +67,8 @@ static uart_t _uart_bus_array[3] = {\n };\n #endif\n \n+static void uart_on_apb_change(void * arg, apb_change_ev_t ev_type, uint32_t old_apb, uint32_t new_apb);\n+\n static void IRAM_ATTR _uart_isr(void *arg)\n {\n     uint8_t i, c;\n@@ -216,6 +218,7 @@ uart_t* uartBegin(uint8_t uart_nr, uint32_t baudrate, uint32_t config, int8_t rx\n         uartAttachTx(uart, txPin, inverted);\n     }\n \n+    addApbChangeCallback(uart, uart_on_apb_change);\n     return uart;\n }\n \n@@ -224,11 +227,10 @@ void uartEnd(uart_t* uart)\n     if(uart == NULL) {\n         return;\n     }\n+    removeApbChangeCallback(uart, uart_on_apb_change);\n \n     UART_MUTEX_LOCK();\n     if(uart->queue != NULL) {\n-        uint8_t c;\n-        while(xQueueReceive(uart->queue, &c, 0));\n         vQueueDelete(uart->queue);\n         uart->queue = NULL;\n     }\n@@ -248,8 +250,6 @@ size_t uartResizeRxBuffer(uart_t * uart, size_t new_size) {\n \n     UART_MUTEX_LOCK();\n     if(uart->queue != NULL) {\n-        uint8_t c;\n-        while(xQueueReceive(uart->queue, &c, 0));\n         vQueueDelete(uart->queue);\n         uart->queue = xQueueCreate(new_size, sizeof(uint8_t));\n         if(uart->queue == NULL) {\n@@ -319,10 +319,9 @@ void uartWriteBuf(uart_t* uart, const uint8_t * data, size_t len)\n     }\n     UART_MUTEX_LOCK();\n     while(len) {\n-        while(len && uart->dev->status.txfifo_cnt < 0x7F) {\n-            uart->dev->fifo.rw_byte = *data++;\n-            len--;\n-        }\n+        while(uart->dev->status.txfifo_cnt == 0x7F);\n+        uart->dev->fifo.rw_byte = *data++;\n+        len--;\n     }\n     UART_MUTEX_UNLOCK();\n }\n@@ -359,13 +358,49 @@ void uartSetBaudRate(uart_t* uart, uint32_t baud_rate)\n     UART_MUTEX_UNLOCK();\n }\n \n+static void uart_on_apb_change(void * arg, apb_change_ev_t ev_type, uint32_t old_apb, uint32_t new_apb)\n+{\n+    uart_t* uart = (uart_t*)arg;\n+    if(ev_type == APB_BEFORE_CHANGE){\n+        UART_MUTEX_LOCK();\n+        //disabple interrupt\n+        uart->dev->int_ena.val = 0;\n+        uart->dev->int_clr.val = 0xffffffff;\n+        // read RX fifo\n+        uint8_t c;\n+        BaseType_t xHigherPriorityTaskWoken;\n+        while(uart->dev->status.rxfifo_cnt != 0 || (uart->dev->mem_rx_status.wr_addr != uart->dev->mem_rx_status.rd_addr)) {\n+            c = uart->dev->fifo.rw_byte;\n+            if(uart->queue != NULL && !xQueueIsQueueFullFromISR(uart->queue)) {\n+                xQueueSendFromISR(uart->queue, &c, &xHigherPriorityTaskWoken);\n+            }\n+        }\n+        // wait TX empty\n+        while(uart->dev->status.txfifo_cnt || uart->dev->status.st_utx_out);\n+    } else {\n+        //todo:\n+        // set baudrate\n+        uint32_t clk_div = (uart->dev->clk_div.div_int << 4) | (uart->dev->clk_div.div_frag & 0x0F);\n+        uint32_t baud_rate = ((old_apb<<4)/clk_div);\n+        clk_div = ((new_apb<<4)/baud_rate);\n+        uart->dev->clk_div.div_int = clk_div>>4 ;\n+        uart->dev->clk_div.div_frag = clk_div & 0xf;\n+        //enable interrupts\n+        uart->dev->int_ena.rxfifo_full = 1;\n+        uart->dev->int_ena.frm_err = 1;\n+        uart->dev->int_ena.rxfifo_tout = 1;\n+        uart->dev->int_clr.val = 0xffffffff;\n+        UART_MUTEX_UNLOCK();\n+    }\n+}\n+\n uint32_t uartGetBaudRate(uart_t* uart)\n {\n     if(uart == NULL) {\n         return 0;\n     }\n     uint32_t clk_div = (uart->dev->clk_div.div_int << 4) | (uart->dev->clk_div.div_frag & 0x0F);\n-    return ((UART_CLK_FREQ<<4)/clk_div);\n+    return ((getApbFrequency()<<4)/clk_div);\n }\n \n static void IRAM_ATTR uart0_write_char(char c)\n@@ -505,7 +540,7 @@ uartDetectBaudrate(uart_t *uart)\n     uart->dev->auto_baud.en = 0;\n     uartStateDetectingBaudrate = false; // Initialize for the next round\n \n-    unsigned long baudrate = UART_CLK_FREQ / divisor;\n+    unsigned long baudrate = getApbFrequency() / divisor;\n \n     static const unsigned long default_rates[] = {300, 600, 1200, 2400, 4800, 9600, 19200, 38400, 57600, 74880, 115200, 230400, 256000, 460800, 921600, 1843200, 3686400};\n \ndiff --git a/cores/esp32/esp32-hal.h b/cores/esp32/esp32-hal.h\nindex 33595efdaa6..36ffccac231 100644\n--- a/cores/esp32/esp32-hal.h\n+++ b/cores/esp32/esp32-hal.h\n@@ -62,6 +62,7 @@ void yield(void);\n #include \"esp32-hal-timer.h\"\n #include \"esp32-hal-bt.h\"\n #include \"esp32-hal-psram.h\"\n+#include \"esp32-hal-cpu.h\"\n \n #ifndef BOARD_HAS_PSRAM\n #ifdef CONFIG_SPIRAM_SUPPORT\n@@ -87,15 +88,6 @@ void enableCore1WDT();\n void disableCore1WDT();\n #endif\n \n-//function takes the following frequencies as valid values:\n-//  240, 160, 80                     <<< For all XTAL types\n-//  40, 20, 13, 10, 8, 5, 4, 3, 2, 1 <<< For 40MHz XTAL\n-//  26, 13, 5, 4, 3, 2, 1            <<< For 26MHz XTAL\n-//  24, 12, 8, 6, 4, 3, 2, 1         <<< For 24MHz XTAL\n-bool setCpuFrequency(uint32_t cpu_freq_mhz);\n-uint32_t getCpuFrequency();\n-uint32_t getApbFrequency();\n-\n unsigned long micros();\n unsigned long millis();\n void delay(uint32_t);\ndiff --git a/libraries/Wire/src/Wire.h b/libraries/Wire/src/Wire.h\nindex 031ea3e5740..37288beb686 100644\n--- a/libraries/Wire/src/Wire.h\n+++ b/libraries/Wire/src/Wire.h\n@@ -30,7 +30,7 @@\n #include \"freertos/queue.h\"\n #include \"Stream.h\"\n \n-#define STICKBREAKER V1.0.1\n+#define STICKBREAKER 'V1.1.0'\n #define I2C_BUFFER_LENGTH 128\n typedef void(*user_onRequest)(void);\n typedef void(*user_onReceive)(uint8_t*, int);\n@@ -138,6 +138,7 @@ extern TwoWire Wire1;\n \n \n /*\n+V1.1.0 08JAN2019 Support CPU Clock frequency changes\n V1.0.2 30NOV2018 stop returning I2C_ERROR_CONTINUE on ReSTART operations, regain compatibility with Arduino libs\n V1.0.1 02AUG2018 First Fix after release, Correct ReSTART handling, change Debug control, change begin()\n   to a function, this allow reporting if bus cannot be initialized, Wire.begin() can be used to recover\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Clock Handling**: Improve handling of `micros()` during clock changes to prevent negative time values. Investigate a fix for FreeRTOS reference tick implementation.\n   \n2. **Callback Mechanism**: Discuss integration of frequency change callbacks for power management with @igrr. Current power management callback limitation affects peripheral frequency adjustments.\n\n3. **UART & LEDC References**: Switch to using `REF_TICK` for UART and LEDC to stabilize frequency changes, while assessing implications of changing its hard-defined 1MHz setting.\n\n4. **APB Frequency Constraints**: Ensure APB operates at 80MHz for WiFi functionality, necessitating a minimum CPU frequency of 80MHz.\n\n5. **Logging Issues**: Remove `log_v` calls from `esp32-hal-i2c.c` to reduce debug noise or implement a runtime suppression method."
      }
    ],
    "codediff_length": 37152
  },
  {
    "index": 64,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/boards.txt b/boards.txt\nindex a2f8f8ed867..c343d138322 100644\n--- a/boards.txt\n+++ b/boards.txt\n@@ -3348,18 +3348,18 @@ ttgo-lora32.build.bootloader_addr=0x1000\n ttgo-lora32.build.target=esp32\n ttgo-lora32.build.mcu=esp32\n ttgo-lora32.build.core=esp32\n-ttgo-lora32.build.board=TTGO_LoRa32\n+ttgo-lora32.build.board=TTGO_LORA32\n \n ttgo-lora32.menu.Revision.TTGO_LoRa32_V1=TTGO LoRa32 V1 (No TFCard)\n-ttgo-lora32.menu.Revision.TTGO_LoRa32_V1.build.board=TTGO_LoRa32_V1\n+ttgo-lora32.menu.Revision.TTGO_LoRa32_V1.build.board=TTGO_LORA32_V1\n ttgo-lora32.menu.Revision.TTGO_LoRa32_V1.build.variant=ttgo-lora32-v1\n \n ttgo-lora32.menu.Revision.TTGO_LoRa32_V2=TTGO LoRa32 V2\n-ttgo-lora32.menu.Revision.TTGO_LoRa32_V2.build.board=TTGO_LoRa32_V2\n+ttgo-lora32.menu.Revision.TTGO_LoRa32_V2.build.board=TTGO_LORA32_V2\n ttgo-lora32.menu.Revision.TTGO_LoRa32_V2.build.variant=ttgo-lora32-v2\n \n ttgo-lora32.menu.Revision.TTGO_LoRa32_v21new=TTGO LoRa32 V2.1 (1.6.1)\n-ttgo-lora32.menu.Revision.TTGO_LoRa32_v21new.build.board=TTGO_LoRa32_v21new\n+ttgo-lora32.menu.Revision.TTGO_LoRa32_v21new.build.board=TTGO_LORA32_V21NEW\n ttgo-lora32.menu.Revision.TTGO_LoRa32_v21new.build.variant=ttgo-lora32-v21new\n \n ttgo-lora32.build.f_cpu=240000000L\n@@ -3569,7 +3569,7 @@ ttgo-t7-v13-mini32.build.target=esp32\n ttgo-t7-v13-mini32.build.mcu=esp32\n ttgo-t7-v13-mini32.build.core=esp32\n ttgo-t7-v13-mini32.build.variant=ttgo-t7-v13-mini32\n-ttgo-t7-v13-mini32.build.board=TTGO_T7_V13_Mini32\n+ttgo-t7-v13-mini32.build.board=TTGO_T7_V13_MINI32\n \n ttgo-t7-v13-mini32.build.f_cpu=240000000L\n ttgo-t7-v13-mini32.build.flash_size=4MB\n@@ -3701,7 +3701,7 @@ ttgo-t7-v14-mini32.build.target=esp32\n ttgo-t7-v14-mini32.build.mcu=esp32\n ttgo-t7-v14-mini32.build.core=esp32\n ttgo-t7-v14-mini32.build.variant=ttgo-t7-v14-mini32\n-ttgo-t7-v14-mini32.build.board=TTGO_T7_V14_Mini32\n+ttgo-t7-v14-mini32.build.board=TTGO_T7_V14_MINI32\n \n ttgo-t7-v14-mini32.build.f_cpu=240000000L\n ttgo-t7-v14-mini32.build.flash_size=4MB\n@@ -3831,7 +3831,7 @@ ttgo-t-oi-plus.build.target=esp\n ttgo-t-oi-plus.build.mcu=esp32c3\n ttgo-t-oi-plus.build.core=esp32\n ttgo-t-oi-plus.build.variant=ttgo-t-oi-plus\n-ttgo-t-oi-plus.build.board=TTGO-T-OI-PLUS_DEV\n+ttgo-t-oi-plus.build.board=TTGO_T_OI_PLUS_DEV\n ttgo-t-oi-plus.build.bootloader_addr=0x0\n \n ttgo-t-oi-plus.build.cdc_on_boot=0\n@@ -6291,7 +6291,7 @@ pocket_32.build.target=esp32\n pocket_32.build.mcu=esp32\n pocket_32.build.core=esp32\n pocket_32.build.variant=pocket_32\n-pocket_32.build.board=Pocket32\n+pocket_32.build.board=POCKET32\n \n pocket_32.build.f_cpu=240000000L\n pocket_32.build.flash_mode=dio\n@@ -6363,7 +6363,7 @@ WeMosBat.build.target=esp32\n WeMosBat.build.mcu=esp32\n WeMosBat.build.core=esp32\n WeMosBat.build.variant=pocket_32\n-WeMosBat.build.board=Pocket32\n+WeMosBat.build.board=POCKET32\n \n WeMosBat.build.f_cpu=240000000L\n WeMosBat.build.flash_mode=dio\n@@ -6472,7 +6472,7 @@ espea32.build.target=esp32\n espea32.build.mcu=esp32\n espea32.build.core=esp32\n espea32.build.variant=espea32\n-espea32.build.board=ESPea32\n+espea32.build.board=ESPEA32\n \n espea32.build.f_cpu=240000000L\n espea32.build.flash_mode=dio\n@@ -6616,7 +6616,7 @@ node32s.build.target=esp32\n node32s.build.mcu=esp32\n node32s.build.core=esp32\n node32s.build.variant=node32s\n-node32s.build.board=Node32s\n+node32s.build.board=NODE32S\n \n node32s.build.f_cpu=240000000L\n node32s.build.flash_mode=dio\n@@ -10319,7 +10319,7 @@ nodemcu-32s.build.target=esp32\n nodemcu-32s.build.mcu=esp32\n nodemcu-32s.build.core=esp32\n nodemcu-32s.build.variant=nodemcu-32s\n-nodemcu-32s.build.board=NodeMCU_32S\n+nodemcu-32s.build.board=NODEMCU_32S\n \n nodemcu-32s.build.f_cpu=240000000L\n nodemcu-32s.build.flash_mode=dio\n@@ -10555,7 +10555,7 @@ esp32vn-iot-uno.build.target=esp32\n esp32vn-iot-uno.build.mcu=esp32\n esp32vn-iot-uno.build.core=esp32\n esp32vn-iot-uno.build.variant=esp32vn-iot-uno\n-esp32vn-iot-uno.build.board=esp32vn_iot_uno\n+esp32vn-iot-uno.build.board=ESP32VN_IOT_UNO\n \n esp32vn-iot-uno.build.f_cpu=240000000L\n esp32vn-iot-uno.build.flash_mode=dio\n@@ -11149,7 +11149,7 @@ espino32.build.target=esp32\n espino32.build.mcu=esp32\n espino32.build.core=esp32\n espino32.build.variant=espino32\n-espino32.build.board=ESPino32\n+espino32.build.board=ESPINO32\n \n espino32.build.f_cpu=240000000L\n espino32.build.flash_mode=dio\n@@ -11221,7 +11221,7 @@ m5stack-core-esp32.build.target=esp32\n m5stack-core-esp32.build.mcu=esp32\n m5stack-core-esp32.build.core=esp32\n m5stack-core-esp32.build.variant=m5stack_core_esp32\n-m5stack-core-esp32.build.board=M5Stack_Core_ESP32\n+m5stack-core-esp32.build.board=M5STACK_CORE_ESP32\n \n m5stack-core-esp32.build.f_cpu=240000000L\n m5stack-core-esp32.build.flash_size=4MB\n@@ -11397,7 +11397,7 @@ m5stack-station.build.target=esp32\n m5stack-station.build.mcu=esp32\n m5stack-station.build.core=esp32\n m5stack-station.build.variant=m5stack_station\n-m5stack-station.build.board=M5Stack_Station\n+m5stack-station.build.board=M5STACK_STATION\n \n m5stack-station.build.f_cpu=240000000L\n m5stack-station.build.flash_size=16MB\n@@ -11487,7 +11487,7 @@ m5stick-c.build.target=esp32\n m5stick-c.build.mcu=esp32\n m5stick-c.build.core=esp32\n m5stick-c.build.variant=m5stick_c\n-m5stick-c.build.board=M5Stick_C\n+m5stick-c.build.board=M5STICK_C\n \n m5stick-c.build.f_cpu=240000000L\n m5stick-c.build.flash_size=4MB\n@@ -11560,7 +11560,7 @@ m5stack-atom.build.target=esp32\n m5stack-atom.build.mcu=esp32\n m5stack-atom.build.core=esp32\n m5stack-atom.build.variant=m5stack_atom\n-m5stack-atom.build.board=M5Stack_ATOM\n+m5stack-atom.build.board=M5STACK_ATOM\n \n m5stack-atom.build.f_cpu=240000000L\n m5stack-atom.build.flash_size=4MB\n@@ -11637,7 +11637,7 @@ m5stack-atoms3.build.target=esp32s3\n m5stack-atoms3.build.mcu=esp32s3\n m5stack-atoms3.build.core=esp32\n m5stack-atoms3.build.variant=m5stack_atoms3\n-m5stack-atoms3.build.board=M5Stack_ATOMS3\n+m5stack-atoms3.build.board=M5STACK_ATOMS3\n \n m5stack-atoms3.build.usb_mode=1\n m5stack-atoms3.build.cdc_on_boot=0\n@@ -11827,7 +11827,7 @@ m5stack-core2.build.target=esp32\n m5stack-core2.build.mcu=esp32\n m5stack-core2.build.core=esp32\n m5stack-core2.build.variant=m5stack_core2\n-m5stack-core2.build.board=M5STACK_Core2\n+m5stack-core2.build.board=M5STACK_CORE2\n \n m5stack-core2.build.f_cpu=240000000L\n m5stack-core2.build.flash_size=16MB\n@@ -11944,7 +11944,7 @@ m5stack-timer-cam.build.target=esp32\n m5stack-timer-cam.build.mcu=esp32\n m5stack-timer-cam.build.core=esp32\n m5stack-timer-cam.build.variant=m5stack_timer_cam\n-m5stack-timer-cam.build.board=M5Stack-Timer-CAM\n+m5stack-timer-cam.build.board=M5STACK_TIMER_CAM\n \n m5stack-timer-cam.build.f_cpu=240000000L\n m5stack-timer-cam.build.flash_size=4MB\n@@ -12053,7 +12053,7 @@ m5stack-coreink.build.target=esp32\n m5stack-coreink.build.mcu=esp32\n m5stack-coreink.build.core=esp32\n m5stack-coreink.build.variant=m5stack_coreink\n-m5stack-coreink.build.board=M5Stack_CoreInk\n+m5stack-coreink.build.board=M5STACK_COREINK\n \n m5stack-coreink.build.f_cpu=240000000L\n m5stack-coreink.build.flash_size=4MB\n@@ -12227,7 +12227,7 @@ heltec_wifi_kit_32.build.target=esp32\n heltec_wifi_kit_32.build.mcu=esp32\n heltec_wifi_kit_32.build.core=esp32\n heltec_wifi_kit_32.build.variant=heltec_wifi_kit_32\n-heltec_wifi_kit_32.build.board=heltec_wifi_kit_32\n+heltec_wifi_kit_32.build.board=HELTEC_WIFI_KIT_32\n \n heltec_wifi_kit_32.build.f_cpu=240000000L\n heltec_wifi_kit_32.build.flash_size=4MB\n@@ -12316,7 +12316,7 @@ heltec_wifi_kit_32_V3.build.target=esp32s3\n heltec_wifi_kit_32_V3.build.mcu=esp32s3\n heltec_wifi_kit_32_V3.build.core=esp32\n heltec_wifi_kit_32_V3.build.variant=heltec_wifi_kit_32_V3\n-heltec_wifi_kit_32_V3.build.board=heltec_wifi_kit_32_V3\n+heltec_wifi_kit_32_V3.build.board=HELTEC_WIFI_KIT_32_V3\n \n heltec_wifi_kit_32_V3.build.usb_mode=1\n heltec_wifi_kit_32_V3.build.cdc_on_boot=0\n@@ -12415,7 +12415,7 @@ heltec_wifi_lora_32.build.target=esp32\n heltec_wifi_lora_32.build.mcu=esp32\n heltec_wifi_lora_32.build.core=esp32\n heltec_wifi_lora_32.build.variant=heltec_wifi_lora_32\n-heltec_wifi_lora_32.build.board=heltec_wifi_lora_32\n+heltec_wifi_lora_32.build.board=HELTEC_WIFI_LORA_32\n \n heltec_wifi_lora_32.build.f_cpu=240000000L\n heltec_wifi_lora_32.build.flash_size=4MB\n@@ -12552,7 +12552,7 @@ heltec_wifi_lora_32_V2.build.target=esp32\n heltec_wifi_lora_32_V2.build.mcu=esp32\n heltec_wifi_lora_32_V2.build.core=esp32\n heltec_wifi_lora_32_V2.build.variant=heltec_wifi_lora_32_V2\n-heltec_wifi_lora_32_V2.build.board=heltec_wifi_lora_32_V2\n+heltec_wifi_lora_32_V2.build.board=HELTEC_WIFI_LORA_32_V2\n \n heltec_wifi_lora_32_V2.build.f_cpu=240000000L\n heltec_wifi_lora_32_V2.build.flash_size=8MB\n@@ -12668,7 +12668,7 @@ heltec_wifi_lora_32_V3.build.target=esp32s3\n heltec_wifi_lora_32_V3.build.mcu=esp32s3\n heltec_wifi_lora_32_V3.build.core=esp32\n heltec_wifi_lora_32_V3.build.variant=heltec_wifi_lora_32_V3\n-heltec_wifi_lora_32_V3.build.board=heltec_wifi_32_lora_V3\n+heltec_wifi_lora_32_V3.build.board=HELTEC_WIFI_32_LORA_V3\n \n heltec_wifi_lora_32_V3.build.usb_mode=1\n heltec_wifi_lora_32_V3.build.cdc_on_boot=0\n@@ -12810,7 +12810,7 @@ heltec_wireless_stick.build.target=esp32\n heltec_wireless_stick.build.mcu=esp32\n heltec_wireless_stick.build.core=esp32\n heltec_wireless_stick.build.variant=heltec_wireless_stick\n-heltec_wireless_stick.build.board=heltec_wireless_stick\n+heltec_wireless_stick.build.board=HELTEC_WIRELESS_STICK\n \n heltec_wireless_stick.build.f_cpu=240000000L\n heltec_wireless_stick.build.flash_size=8MB\n@@ -12923,7 +12923,7 @@ heltec_wireless_stick_lite.build.target=esp32\n heltec_wireless_stick_lite.build.mcu=esp32\n heltec_wireless_stick_lite.build.core=esp32\n heltec_wireless_stick_lite.build.variant=heltec_wireless_stick_lite\n-heltec_wireless_stick_lite.build.board=heltec_wireless_stick_LITE\n+heltec_wireless_stick_lite.build.board=HELTEC_WIRELESS_STICK_LITE\n \n heltec_wireless_stick_lite.build.f_cpu=240000000L\n heltec_wireless_stick_lite.build.flash_size=4MB\n@@ -13126,7 +13126,7 @@ CoreESP32.build.target=esp32\n CoreESP32.build.mcu=esp32\n CoreESP32.build.core=esp32\n CoreESP32.build.variant=Microduino-esp32\n-CoreESP32.build.board=CoreESP32\n+CoreESP32.build.board=COREESP32\n \n CoreESP32.build.f_cpu=240000000L\n CoreESP32.build.flash_mode=dio\n@@ -13894,7 +13894,7 @@ t-beam.build.target=esp32\n t-beam.build.mcu=esp32\n t-beam.build.core=esp32\n t-beam.build.variant=tbeam\n-t-beam.build.board=TBeam\n+t-beam.build.board=TBEAM\n \n t-beam.menu.Revision.Radio_SX1262=Radio-SX1262\n t-beam.menu.Revision.Radio_SX1262.build.board=TBEAM_USE_RADIO_SX1262\n@@ -13983,7 +13983,7 @@ d-duino-32.build.target=esp32\n d-duino-32.build.mcu=esp32\n d-duino-32.build.core=esp32\n d-duino-32.build.variant=d-duino-32\n-d-duino-32.build.board=D_Duino_32\n+d-duino-32.build.board=D_DUINO_32\n \n d-duino-32.build.f_cpu=240000000L\n d-duino-32.build.flash_size=4MB\n@@ -14069,7 +14069,7 @@ lopy.build.target=esp32\n lopy.build.mcu=esp32\n lopy.build.core=esp32\n lopy.build.variant=lopy\n-lopy.build.board=LoPy\n+lopy.build.board=LOPY\n \n lopy.build.f_cpu=240000000L\n lopy.build.flash_mode=dio\n@@ -14140,7 +14140,7 @@ lopy4.build.target=esp32\n lopy4.build.mcu=esp32\n lopy4.build.core=esp32\n lopy4.build.variant=lopy4\n-lopy4.build.board=LoPy4\n+lopy4.build.board=LOPY4\n \n lopy4.build.f_cpu=240000000L\n lopy4.build.flash_mode=dio\n@@ -14294,7 +14294,7 @@ fm-devkit.build.target=esp32\n fm-devkit.build.mcu=esp32\n fm-devkit.build.core=esp32\n fm-devkit.build.variant=fm-devkit\n-fm-devkit.build.board=fm_devkit\n+fm-devkit.build.board=FM_DEVKIT\n \n fm-devkit.build.f_cpu=240000000L\n fm-devkit.build.flash_size=4MB\n@@ -14581,7 +14581,7 @@ twatch.build.target=esp32\n twatch.build.mcu=esp32\n twatch.build.core=esp32\n twatch.build.variant=twatch\n-twatch.build.board=TWatch\n+twatch.build.board=TWATCH\n \n twatch.menu.Revision.TWATCH_BASE=T-Watch Base\n twatch.menu.Revision.TWATCH_BASE.build.board=TWATCH_BASE\n@@ -15442,7 +15442,7 @@ piranha_esp-32.build.target=esp32\n piranha_esp-32.build.mcu=esp32\n piranha_esp-32.build.core=esp32\n piranha_esp-32.build.variant=piranha_esp-32\n-piranha_esp-32.build.board=Piranha\n+piranha_esp-32.build.board=PIRANHA\n \n piranha_esp-32.build.f_cpu=240000000L\n piranha_esp-32.build.flash_mode=dio\n@@ -15523,7 +15523,7 @@ metro_esp-32.build.target=esp32\n metro_esp-32.build.mcu=esp32\n metro_esp-32.build.core=esp32\n metro_esp-32.build.variant=metro_esp-32\n-metro_esp-32.build.board=Metro\n+metro_esp-32.build.board=METRO\n \n metro_esp-32.build.f_cpu=240000000L\n metro_esp-32.build.flash_mode=dio\n@@ -15604,7 +15604,7 @@ sensesiot_weizen.build.target=esp32\n sensesiot_weizen.build.mcu=esp32\n sensesiot_weizen.build.core=esp32\n sensesiot_weizen.build.variant=esp32\n-sensesiot_weizen.build.board=sensesiot_weizen\n+sensesiot_weizen.build.board=SENSESIOT_WEIZEN\n \n sensesiot_weizen.build.f_cpu=240000000L\n sensesiot_weizen.build.flash_mode=dio\n@@ -15880,7 +15880,7 @@ OpenKB.build.target=esp32\n OpenKB.build.mcu=esp32\n OpenKB.build.core=esp32\n OpenKB.build.variant=openkb\n-OpenKB.build.board=openkb\n+OpenKB.build.board=OPENKB\n \n OpenKB.build.f_cpu=240000000L\n OpenKB.build.flash_mode=dio\n@@ -15953,7 +15953,7 @@ wifiduino32.build.target=esp32\n wifiduino32.build.mcu=esp32\n wifiduino32.build.core=esp32\n wifiduino32.build.variant=wifiduino32\n-wifiduino32.build.board=Wifiduino32\n+wifiduino32.build.board=WIFIDUINO32\n \n wifiduino32.build.f_cpu=240000000L\n wifiduino32.build.flash_mode=dio\n@@ -16037,7 +16037,7 @@ wifiduino32c3.build.target=esp\n wifiduino32c3.build.mcu=esp32c3\n wifiduino32c3.build.core=esp32\n wifiduino32c3.build.variant=wifiduinov2\n-wifiduino32c3.build.board=WiFiduinoV2\n+wifiduino32c3.build.board=WIFIDUINOV2\n wifiduino32c3.build.bootloader_addr=0x0\n \n wifiduino32c3.build.cdc_on_boot=0\n@@ -16193,7 +16193,7 @@ wifiduino32s3.build.target=esp32s3\n wifiduino32s3.build.mcu=esp32s3\n wifiduino32s3.build.core=esp32\n wifiduino32s3.build.variant=wifiduino32s3\n-wifiduino32s3.build.board=WiFiduino32S3\n+wifiduino32s3.build.board=WIFIDUINO32S3\n \n wifiduino32s3.build.usb_mode=1\n wifiduino32s3.build.cdc_on_boot=0\n@@ -16580,7 +16580,7 @@ ET-Board.build.target=esp32\n ET-Board.build.mcu=esp32\n ET-Board.build.core=esp32\n ET-Board.build.variant=ET-Board\n-ET-Board.build.board=ET-Board\n+ET-Board.build.board=ET_BOARD\n ET-Board.build.f_cpu=240000000L\n ET-Board.build.flash_mode=dio\n ET-Board.build.flash_size=4MB\n@@ -16751,7 +16751,7 @@ uPesy_wrover.build.target=esp32\n uPesy_wrover.build.mcu=esp32\n uPesy_wrover.build.core=esp32\n uPesy_wrover.build.variant=uPesy_esp32_wrover_devkit\n-uPesy_wrover.build.board=uPesy_WROVER\n+uPesy_wrover.build.board=UPESY_WROVER\n \n uPesy_wrover.build.f_cpu=240000000L\n uPesy_wrover.build.flash_size=4MB\n@@ -16868,7 +16868,7 @@ uPesy_wroom.build.target=esp32\n uPesy_wroom.build.mcu=esp32\n uPesy_wroom.build.core=esp32\n uPesy_wroom.build.variant=uPesy_esp32_wroom_devkit\n-uPesy_wroom.build.board=uPesy_WROOM\n+uPesy_wroom.build.board=UPESY_WROOM\n \n uPesy_wroom.build.f_cpu=240000000L\n uPesy_wroom.build.flash_size=4MB\n@@ -17513,7 +17513,7 @@ deneyapkart1Av2.build.target=esp32s3\n deneyapkart1Av2.build.mcu=esp32s3\n deneyapkart1Av2.build.core=esp32\n deneyapkart1Av2.build.variant=deneyapkart1Av2\n-deneyapkart1Av2.build.board=DYDK1Av2\n+deneyapkart1Av2.build.board=DYDK1AV2\n \n deneyapkart1Av2.build.usb_mode=1\n deneyapkart1Av2.build.cdc_on_boot=1\n@@ -17928,7 +17928,7 @@ deneyapminiv2.build.target=esp32s2\n deneyapminiv2.build.mcu=esp32s2\n deneyapminiv2.build.core=esp32\n deneyapminiv2.build.variant=deneyapminiv2\n-deneyapminiv2.build.board=DYMv2\n+deneyapminiv2.build.board=DYMV2\n \n deneyapminiv2.build.cdc_on_boot=1\n deneyapminiv2.build.msc_on_boot=0\n@@ -18284,7 +18284,7 @@ esp32-trueverit-iot-driver.build.target=esp32\n esp32-trueverit-iot-driver.build.mcu=esp32\n esp32-trueverit-iot-driver.build.core=esp32\n esp32-trueverit-iot-driver.build.variant=esp32-trueverit-iot-driver\n-esp32-trueverit-iot-driver.build.board=Trueverit_ESP32_Universal_IoT_Driver\n+esp32-trueverit-iot-driver.build.board=TRUEVERIT_ESP32_UNIVERSAL_IOT_DRIVER\n \n esp32-trueverit-iot-driver.build.f_cpu=240000000L\n esp32-trueverit-iot-driver.build.flash_mode=dio\n@@ -18352,7 +18352,7 @@ esp32-trueverit-iot-driver-mkii.build.target=esp32\n esp32-trueverit-iot-driver-mkii.build.mcu=esp32\n esp32-trueverit-iot-driver-mkii.build.core=esp32\n esp32-trueverit-iot-driver-mkii.build.variant=esp32-trueverit-iot-driver-mkii\n-esp32-trueverit-iot-driver-mkii.build.board=Trueverit_ESP32_Universal_IoT_Driver_MK_II\n+esp32-trueverit-iot-driver-mkii.build.board=TRUEVERIT_ESP32_UNIVERSAL_IOT_DRIVER_MK_II\n \n esp32-trueverit-iot-driver-mkii.build.f_cpu=240000000L\n esp32-trueverit-iot-driver-mkii.build.flash_mode=dio\n@@ -18424,7 +18424,7 @@ atmegazero_esp32s2.build.target=esp32s2\n atmegazero_esp32s2.build.mcu=esp32s2\n atmegazero_esp32s2.build.core=esp32\n atmegazero_esp32s2.build.variant=atmegazero_esp32s2\n-atmegazero_esp32s2.build.board=atmegazero_esp32s2\n+atmegazero_esp32s2.build.board=ATMEGAZERO_ESP32S2\n \n atmegazero_esp32s2.build.cdc_on_boot=1\n atmegazero_esp32s2.build.msc_on_boot=0\n@@ -19251,7 +19251,7 @@ lionbit.build.target=esp32\n lionbit.build.mcu=esp32\n lionbit.build.core=esp32\n lionbit.build.variant=lionbit\n-lionbit.build.board=Lion:Bit_Dev_Board\n+lionbit.build.board=LIONBIT_DEV_BOARD\n \n lionbit.build.f_cpu=240000000L\n lionbit.build.flash_size=4MB\n@@ -19489,7 +19489,7 @@ AirM2M_CORE_ESP32C3.build.target=esp\n AirM2M_CORE_ESP32C3.build.mcu=esp32c3\n AirM2M_CORE_ESP32C3.build.core=esp32\n AirM2M_CORE_ESP32C3.build.variant=AirM2M_CORE_ESP32C3\n-AirM2M_CORE_ESP32C3.build.board=AirM2M_CORE_ESP32C3\n+AirM2M_CORE_ESP32C3.build.board=AIRM2M_CORE_ESP32C3\n AirM2M_CORE_ESP32C3.build.bootloader_addr=0x0\n \n AirM2M_CORE_ESP32C3.build.cdc_on_boot=0\n@@ -19755,7 +19755,7 @@ connaxio_espoir.build.target=esp32\n connaxio_espoir.build.mcu=esp32\n connaxio_espoir.build.core=esp32\n connaxio_espoir.build.variant=connaxio_espoir\n-connaxio_espoir.build.board=connaxio_espoir\n+connaxio_espoir.build.board=CONNAXIO_ESPOIR\n \n connaxio_espoir.build.f_cpu=240000000L\n connaxio_espoir.build.flash_size=4MB\n@@ -20127,7 +20127,7 @@ Bee_Motion_S3.build.target=esp32s3\n Bee_Motion_S3.build.mcu=esp32s3\n Bee_Motion_S3.build.core=esp32\n Bee_Motion_S3.build.variant=Bee_Motion_S3\n-Bee_Motion_S3.build.board=BeeMotionS3\n+Bee_Motion_S3.build.board=BEEMOTIONS3\n \n Bee_Motion_S3.build.cdc_on_boot=1\n Bee_Motion_S3.build.msc_on_boot=1\n@@ -20236,7 +20236,7 @@ Bee_Motion.build.target=esp32s2\n Bee_Motion.build.mcu=esp32s2\n Bee_Motion.build.core=esp32\n Bee_Motion.build.variant=Bee_Motion\n-Bee_Motion.build.board=Bee_Motion\n+Bee_Motion.build.board=BEE_MOTION\n \n Bee_Motion.build.cdc_on_boot=1\n Bee_Motion.build.msc_on_boot=1\n@@ -20337,7 +20337,7 @@ Bee_Motion_Mini.build.target=esp\n Bee_Motion_Mini.build.mcu=esp32c3\n Bee_Motion_Mini.build.core=esp32\n Bee_Motion_Mini.build.variant=Bee_Motion_Mini\n-Bee_Motion_Mini.build.board=Bee_Motion_Mini\n+Bee_Motion_Mini.build.board=BEE_MOTION_MINI\n Bee_Motion_Mini.build.bootloader_addr=0x0\n \n Bee_Motion_Mini.build.cdc_on_boot=1\n@@ -20452,7 +20452,7 @@ Bee_S3.build.target=esp32s3\n Bee_S3.build.mcu=esp32s3\n Bee_S3.build.core=esp32\n Bee_S3.build.variant=Bee_S3\n-Bee_S3.build.board=Bee_S3\n+Bee_S3.build.board=BEE_S3\n \n Bee_S3.build.usb_mode=1\n Bee_S3.build.cdc_on_boot=1\n@@ -20687,7 +20687,7 @@ unphone8.build.target=esp32s3\n unphone8.build.mcu=esp32s3\n unphone8.build.core=esp32\n unphone8.build.variant=unphone8\n-unphone8.build.board=unphone8\n+unphone8.build.board=UNPHONE8\n \n unphone8.build.usb_mode=1\n unphone8.build.cdc_on_boot=0\n@@ -20837,7 +20837,7 @@ unphone9.build.target=esp32s3\n unphone9.build.mcu=esp32s3\n unphone9.build.core=esp32\n unphone9.build.variant=unphone9\n-unphone9.build.board=unphone9\n+unphone9.build.board=UNPHONE9\n \n unphone9.build.usb_mode=1\n unphone9.build.cdc_on_boot=1\n@@ -21448,7 +21448,7 @@ roboheart_hercules.build.target=esp32\n roboheart_hercules.build.mcu=esp32\n roboheart_hercules.build.core=esp32\n roboheart_hercules.build.variant=roboheart_hercules\n-roboheart_hercules.build.board=roboheart_hercules\n+roboheart_hercules.build.board=ROBOHEART_HERCULES\n \n roboheart_hercules.build.f_cpu=240000000L\n roboheart_hercules.build.flash_size=4MB\n@@ -21894,7 +21894,7 @@ Edgebox-ESP-100.build.target=esp32s3\n Edgebox-ESP-100.build.mcu=esp32s3\n Edgebox-ESP-100.build.core=esp32\n Edgebox-ESP-100.build.variant=Edgebox-ESP-100\n-Edgebox-ESP-100.build.board=Edgebox-ESP-100\n+Edgebox-ESP-100.build.board=EDGEBOX_ESP_100\n \n Edgebox-ESP-100.build.usb_mode=1\n Edgebox-ESP-100.build.cdc_on_boot=0\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Fix the `HELTEC_WIFI_32` board definition to uppercase, as it currently causes issues.\n2. Leave all other board names as they are to avoid breaking existing libraries (e.g., M5Unified, LovyanGFX).\n3. Implement a convention for all future board constants to be in uppercase.\n4. Consider adding validation to the boards test script to enforce this naming rule.\n5. Address ambiguity around the meaning of \"revisions\" in board definitions where applicable, avoiding changes unless necessary.\n6. Confirm near-term implementation details; consider a code review deadline for clarity."
      }
    ],
    "codediff_length": 20246
  },
  {
    "index": 65,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/include/modules/xworkspaces.hpp b/include/modules/xworkspaces.hpp\nindex cd6522e71..495ed8ee3 100644\n--- a/include/modules/xworkspaces.hpp\n+++ b/include/modules/xworkspaces.hpp\n@@ -1,6 +1,8 @@\n #pragma once\n \n #include <bitset>\n+#include <mutex>\n+#include <set>\n \n #include \"components/config.hpp\"\n #include \"components/types.hpp\"\n@@ -69,9 +71,10 @@ namespace modules {\n     void set_desktop_urgent(xcb_window_t window);\n \n     bool input(string&& cmd);\n-    vector<string> get_desktop_names();\n \n    private:\n+    static vector<string> get_desktop_names();\n+\n     static constexpr const char* DEFAULT_ICON{\"icon-default\"};\n     static constexpr const char* DEFAULT_LABEL_STATE{\"%icon% %name%\"};\n     static constexpr const char* DEFAULT_LABEL_MONITOR{\"%name%\"};\n@@ -94,7 +97,10 @@ namespace modules {\n     unsigned int m_current_desktop;\n     string m_current_desktop_name;\n \n-    vector<xcb_window_t> m_clientlist;\n+    /**\n+     * Maps an xcb window to its desktop number\n+     */\n+    map<xcb_window_t, unsigned int> m_clients;\n     vector<unique_ptr<viewport>> m_viewports;\n     map<desktop_state, label_t> m_labels;\n     label_t m_monitorlabel;\n@@ -104,8 +110,12 @@ namespace modules {\n     bool m_scroll{true};\n     size_t m_index{0};\n \n+    // The following mutex is here to protect the data of this modules.\n+    // This can't be achieved using m_buildlock since we \"CRTP override\" get_output().\n+    mutable mutex m_workspace_mutex;\n+\n     event_timer m_timer{0L, 25L};\n   };\n-}\n+}  // namespace modules\n \n POLYBAR_NS_END\ndiff --git a/src/modules/xworkspaces.cpp b/src/modules/xworkspaces.cpp\nindex da94264be..1515ca4e7 100644\n--- a/src/modules/xworkspaces.cpp\n+++ b/src/modules/xworkspaces.cpp\n@@ -1,9 +1,10 @@\n+#include \"modules/xworkspaces.hpp\"\n+\n #include <algorithm>\n #include <utility>\n \n #include \"drawtypes/iconset.hpp\"\n #include \"drawtypes/label.hpp\"\n-#include \"modules/xworkspaces.hpp\"\n #include \"utils/factory.hpp\"\n #include \"utils/math.hpp\"\n #include \"x11/atoms.hpp\"\n@@ -17,7 +18,7 @@ namespace {\n   inline bool operator==(const position& a, const position& b) {\n     return a.x + a.y == b.x + b.y;\n   }\n-}\n+}  // namespace\n \n namespace modules {\n   template class module<xworkspaces_module>;\n@@ -86,21 +87,25 @@ namespace modules {\n     m_current_desktop_name = m_desktop_names[m_current_desktop];\n \n     rebuild_desktops();\n-    rebuild_desktop_states();\n \n     // Get _NET_CLIENT_LIST\n     rebuild_clientlist();\n+    rebuild_desktop_states();\n   }\n \n   /**\n    * Handler for XCB_PROPERTY_NOTIFY events\n    */\n   void xworkspaces_module::handle(const evt::property_notify& evt) {\n-    if (evt->atom == m_ewmh->_NET_CLIENT_LIST) {\n+    std::lock_guard<std::mutex> lock(m_workspace_mutex);\n+\n+    if (evt->atom == m_ewmh->_NET_CLIENT_LIST || evt->atom == m_ewmh->_NET_WM_DESKTOP) {\n       rebuild_clientlist();\n+      rebuild_desktop_states();\n     } else if (evt->atom == m_ewmh->_NET_DESKTOP_NAMES || evt->atom == m_ewmh->_NET_NUMBER_OF_DESKTOPS) {\n       m_desktop_names = get_desktop_names();\n       rebuild_desktops();\n+      rebuild_clientlist();\n       rebuild_desktop_states();\n     } else if (evt->atom == m_ewmh->_NET_CURRENT_DESKTOP) {\n       m_current_desktop = ewmh_util::get_current_desktop();\n@@ -123,28 +128,21 @@ namespace modules {\n    * Rebuild the list of managed clients\n    */\n   void xworkspaces_module::rebuild_clientlist() {\n-    vector<xcb_window_t> clients = ewmh_util::get_client_list();\n-    vector<xcb_window_t> diff;\n-    std::sort(clients.begin(), clients.end());\n-    std::sort(m_clientlist.begin(), m_clientlist.end());\n-\n-    if (m_clientlist.size() > clients.size()) {\n-      std::set_difference(\n-          m_clientlist.begin(), m_clientlist.end(), clients.begin(), clients.end(), back_inserter(diff));\n-      for (auto&& win : diff) {\n-        // untrack window\n-        m_clientlist.erase(std::remove(m_clientlist.begin(), m_clientlist.end(), win), m_clientlist.end());\n-      }\n-    } else {\n-      std::set_difference(\n-          clients.begin(), clients.end(), m_clientlist.begin(), m_clientlist.end(), back_inserter(diff));\n-      for (auto&& win : diff) {\n-        // listen for wm_hint (urgency) changes\n-        m_connection.ensure_event_mask(win, XCB_EVENT_MASK_PROPERTY_CHANGE);\n-        // track window\n-        m_clientlist.emplace_back(win);\n+    vector<xcb_window_t> newclients = ewmh_util::get_client_list();\n+    std::sort(newclients.begin(), newclients.end());\n+\n+    for (auto&& client : newclients) {\n+      if (m_clients.count(client) == 0) {\n+        // new client: listen for changes (wm_hint or desktop)\n+        m_connection.ensure_event_mask(client, XCB_EVENT_MASK_PROPERTY_CHANGE);\n       }\n     }\n+\n+    // rebuild entire mapping of clients to desktops\n+    m_clients.clear();\n+    for (auto&& client : newclients) {\n+      m_clients[client] = ewmh_util::get_desktop_from_window(client);\n+    }\n   }\n \n   /**\n@@ -209,13 +207,20 @@ namespace modules {\n    * Update active state of current desktops\n    */\n   void xworkspaces_module::rebuild_desktop_states() {\n+    std::set<unsigned int> occupied_desks;\n+    for (auto&& c : m_clients) {\n+      occupied_desks.insert(c.second);\n+    }\n+\n     for (auto&& v : m_viewports) {\n       for (auto&& d : v->desktops) {\n         if (m_desktop_names[d->index] == m_current_desktop_name) {\n           d->state = desktop_state::ACTIVE;\n+        } else if (occupied_desks.count(d->index) > 0) {\n+          d->state = desktop_state::OCCUPIED;\n         } else {\n           d->state = desktop_state::EMPTY;\n-        } \n+        }\n \n         d->label = m_labels.at(d->state)->clone();\n         d->label->reset_tokens();\n@@ -226,14 +231,13 @@ namespace modules {\n     }\n   }\n \n-  vector<string> xworkspaces_module::get_desktop_names(){\n+  vector<string> xworkspaces_module::get_desktop_names() {\n     vector<string> names = ewmh_util::get_desktop_names();\n     unsigned int desktops_number = ewmh_util::get_number_of_desktops();\n-    if(desktops_number == names.size()) {\n+    if (desktops_number == names.size()) {\n       return names;\n-    }\n-    else if(desktops_number < names.size()) {\n-      names.erase(names.begin()+desktops_number, names.end());\n+    } else if (desktops_number < names.size()) {\n+      names.erase(names.begin() + desktops_number, names.end());\n       return names;\n     }\n     for (unsigned int i = names.size(); i < desktops_number + 1; i++) {\n@@ -247,7 +251,7 @@ namespace modules {\n    */\n   void xworkspaces_module::set_desktop_urgent(xcb_window_t window) {\n     auto desk = ewmh_util::get_desktop_from_window(window);\n-    if(desk == m_current_desktop)\n+    if (desk == m_current_desktop)\n       // ignore if current desktop is urgent\n       return;\n     for (auto&& v : m_viewports) {\n@@ -264,7 +268,6 @@ namespace modules {\n         }\n       }\n     }\n-\n   }\n \n   /**\n@@ -276,6 +279,8 @@ namespace modules {\n    * Generate module output\n    */\n   string xworkspaces_module::get_output() {\n+    std::unique_lock<std::mutex> lock(m_workspace_mutex);\n+\n     // Get the module output early so that\n     // the format prefix/suffix also gets wrapped\n     // with the cmd handlers\n@@ -335,6 +340,8 @@ namespace modules {\n    * Handle user input event\n    */\n   bool xworkspaces_module::input(string&& cmd) {\n+    std::lock_guard<std::mutex> lock(m_workspace_mutex);\n+\n     size_t len{strlen(EVENT_PREFIX)};\n     if (cmd.compare(0, len, EVENT_PREFIX) != 0) {\n       return false;\n@@ -372,6 +379,6 @@ namespace modules {\n \n     return true;\n   }\n-}\n+}  // namespace modules\n \n POLYBAR_NS_END\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Change `m_clientlist` to `vector<pair<xcb_window_t, unsigned int>>` to track windows by desktop, simplifying removal and tracking.\n2. Implement `m_occupied_desktops` as a tally for each desktop, using a vector where each index represents the desktop and values represent window counts. Rename to `m_desktop_client_count` for clarity.\n3. Ensure that when a window is removed, the desktop count in `m_desktop_client_count` is decremented appropriately.\n4. Address a potential race condition when multiple bars use the `xworkspaces` module; confirm that data structures for each module are distinct.\n5. Investigate odd behavior where desktops are marked unoccupied despite existing windows. \n6. Reduce logging to maintain cleaner operations and facilitate easier debugging. Further testing required with other window managers."
      }
    ],
    "codediff_length": 7547
  },
  {
    "index": 66,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/include/modules/battery.hpp b/include/modules/battery.hpp\nindex 57dce08e1..314eeaa49 100644\n--- a/include/modules/battery.hpp\n+++ b/include/modules/battery.hpp\n@@ -2,11 +2,13 @@\n \n #include \"common.hpp\"\n #include \"modules/meta/inotify_module.hpp\"\n+#include \"modules/meta/input_handler.hpp\"\n \n POLYBAR_NS\n \n namespace modules {\n-  class battery_module : public inotify_module<battery_module> {\n+  class battery_module : public inotify_module<battery_module>,\n+                         public input_handler {\n    public:\n     enum class state {\n       NONE = 0,\n@@ -53,6 +55,7 @@ namespace modules {\n     bool on_event(inotify_event* event);\n     string get_format() const;\n     bool build(builder* builder, const string& tag) const;\n+    string get_output();\n \n    protected:\n     state current_state();\n@@ -60,6 +63,7 @@ namespace modules {\n     string current_time();\n     string current_consumption();\n     void subthread();\n+    bool input(string&& cmd);\n \n    private:\n     static constexpr const char* FORMAT_CHARGING{\"format-charging\"};\n@@ -70,8 +74,12 @@ namespace modules {\n     static constexpr const char* TAG_BAR_CAPACITY{\"<bar-capacity>\"};\n     static constexpr const char* TAG_RAMP_CAPACITY{\"<ramp-capacity>\"};\n     static constexpr const char* TAG_LABEL_CHARGING{\"<label-charging>\"};\n+    static constexpr const char* TAG_LABEL_ALT_CHARGING{\"<label-alt-charging>\"};\n     static constexpr const char* TAG_LABEL_DISCHARGING{\"<label-discharging>\"};\n+    static constexpr const char* TAG_LABEL_ALT_DISCHARGING{\"<label-alt-discharging>\"};\n     static constexpr const char* TAG_LABEL_FULL{\"<label-full>\"};\n+    static constexpr const char* TAG_LABEL_ALT_FULL{\"<label-alt-full>\"};\n+    static constexpr auto EVENT_TOGGLE = \"batterytoggle\";\n \n     static const size_t SKIP_N_UNCHANGED{3_z};\n \n@@ -81,8 +89,11 @@ namespace modules {\n     unique_ptr<consumption_reader> m_consumption_reader;\n \n     label_t m_label_charging;\n+    label_t m_label_alt_charging;\n     label_t m_label_discharging;\n+    label_t m_label_alt_discharging;\n     label_t m_label_full;\n+    label_t m_label_alt_full;\n     animation_t m_animation_charging;\n     progressbar_t m_bar_capacity;\n     ramp_t m_ramp_capacity;\n@@ -102,6 +113,9 @@ namespace modules {\n     chrono::duration<double> m_interval{};\n     chrono::system_clock::time_point m_lastpoll;\n     thread m_subthread;\n+\n+    atomic<bool> m_toggleable{false};\n+    atomic<bool> m_toggled{false};\n   };\n }\n \ndiff --git a/include/modules/meta/base.hpp b/include/modules/meta/base.hpp\nindex 2659ce11c..f03f04e0f 100644\n--- a/include/modules/meta/base.hpp\n+++ b/include/modules/meta/base.hpp\n@@ -88,6 +88,7 @@ namespace modules {\n     void add(string name, string fallback, vector<string>&& tags, vector<string>&& whitelist = {});\n     bool has(const string& tag, const string& format_name);\n     bool has(const string& tag);\n+    bool has_non_tag(const string& format_name);\n     shared_ptr<module_format> get(const string& format_name);\n \n    protected:\ndiff --git a/include/modules/network.hpp b/include/modules/network.hpp\nindex 4165a2bf5..bd72aec4d 100644\n--- a/include/modules/network.hpp\n+++ b/include/modules/network.hpp\n@@ -3,13 +3,15 @@\n #include \"adapters/net.hpp\"\n #include \"components/config.hpp\"\n #include \"modules/meta/timer_module.hpp\"\n+#include \"modules/meta/input_handler.hpp\"\n \n POLYBAR_NS\n \n namespace modules {\n   enum class connection_state { NONE = 0, CONNECTED, DISCONNECTED, PACKETLOSS };\n \n-  class network_module : public timer_module<network_module> {\n+  class network_module : public timer_module<network_module>,\n+                         public input_handler {\n    public:\n     explicit network_module(const bar_settings&, string);\n \n@@ -17,9 +19,11 @@ namespace modules {\n     bool update();\n     string get_format() const;\n     bool build(builder* builder, const string& tag) const;\n+    string get_output();\n \n    protected:\n     void subthread_routine();\n+    bool input(string&& cmd);\n \n    private:\n     static constexpr auto FORMAT_CONNECTED = \"format-connected\";\n@@ -28,9 +32,12 @@ namespace modules {\n     static constexpr auto TAG_RAMP_SIGNAL = \"<ramp-signal>\";\n     static constexpr auto TAG_RAMP_QUALITY = \"<ramp-quality>\";\n     static constexpr auto TAG_LABEL_CONNECTED = \"<label-connected>\";\n+    static constexpr auto TAG_LABEL_ALT_CONNECTED = \"<label-alt-connected>\";\n     static constexpr auto TAG_LABEL_DISCONNECTED = \"<label-disconnected>\";\n     static constexpr auto TAG_LABEL_PACKETLOSS = \"<label-packetloss>\";\n+    static constexpr auto TAG_LABEL_ALT_PACKETLOSS = \"<label-alt-packetloss>\";\n     static constexpr auto TAG_ANIMATION_PACKETLOSS = \"<animation-packetloss>\";\n+    static constexpr auto EVENT_TOGGLE = \"networktoggle\";\n \n     net::wired_t m_wired;\n     net::wireless_t m_wireless;\n@@ -39,9 +46,12 @@ namespace modules {\n     ramp_t m_ramp_quality;\n     animation_t m_animation_packetloss;\n     map<connection_state, label_t> m_label;\n+    map<connection_state, label_t> m_label_alt;\n \n     atomic<bool> m_connected{false};\n     atomic<bool> m_packetloss{false};\n+    atomic<bool> m_toggleable{false};\n+    atomic<bool> m_toggled{false};\n \n     int m_signal{0};\n     int m_quality{0};\ndiff --git a/src/modules/battery.cpp b/src/modules/battery.cpp\nindex d9f4b44d9..a8a0acf25 100644\n--- a/src/modules/battery.cpp\n+++ b/src/modules/battery.cpp\n@@ -129,12 +129,15 @@ namespace modules {\n     }\n     if (m_formatter->has(TAG_LABEL_CHARGING, FORMAT_CHARGING)) {\n       m_label_charging = load_optional_label(m_conf, name(), TAG_LABEL_CHARGING, \"%percentage%%\");\n+      m_label_alt_charging = load_optional_label(m_conf, name(), TAG_LABEL_ALT_CHARGING, \"\");\n     }\n     if (m_formatter->has(TAG_LABEL_DISCHARGING, FORMAT_DISCHARGING)) {\n       m_label_discharging = load_optional_label(m_conf, name(), TAG_LABEL_DISCHARGING, \"%percentage%%\");\n+      m_label_alt_discharging = load_optional_label(m_conf, name(), TAG_LABEL_ALT_DISCHARGING, \"\");\n     }\n     if (m_formatter->has(TAG_LABEL_FULL, FORMAT_FULL)) {\n       m_label_full = load_optional_label(m_conf, name(), TAG_LABEL_FULL, \"%percentage%%\");\n+      m_label_alt_full = load_optional_label(m_conf, name(), TAG_LABEL_ALT_FULL, \"\");\n     }\n \n     // Create inotify watches\n@@ -143,12 +146,31 @@ namespace modules {\n \n     // Setup time if token is used\n     if ((m_label_charging && m_label_charging->has_token(\"%time%\")) ||\n-        (m_label_discharging && m_label_discharging->has_token(\"%time%\"))) {\n+        (m_label_alt_charging && m_label_alt_charging->has_token(\"%time%\")) ||\n+        (m_label_discharging && m_label_discharging->has_token(\"%time%\")) ||\n+        (m_label_alt_discharging && m_label_alt_discharging->has_token(\"%time%\"))) {\n       if (!m_bar.locale.empty()) {\n         setlocale(LC_TIME, m_bar.locale.c_str());\n       }\n       m_timeformat = m_conf.get(name(), \"time-format\", \"%H:%M:%S\"s);\n     }\n+\n+    // Check that formats can be toggled\n+    const auto format_is_toggleable = [&](const string& format) {\n+      return m_formatter->has(TAG_BAR_CAPACITY, format) ||\n+             (m_formatter->has(TAG_RAMP_CAPACITY, format) && m_ramp_capacity && *m_ramp_capacity) ||\n+             m_formatter->has_non_tag(format);\n+    };\n+\n+    m_toggleable = (m_label_charging && *m_label_charging && m_label_alt_charging && *m_label_alt_charging) ||\n+                   (m_formatter->has(TAG_ANIMATION_CHARGING, FORMAT_CHARGING) && m_animation_charging && *m_animation_charging) ||\n+                   format_is_toggleable(FORMAT_CHARGING);\n+    m_toggleable = m_toggleable &&\n+                   ((m_label_discharging && *m_label_discharging && m_label_alt_discharging && *m_label_alt_discharging) ||\n+                   format_is_toggleable(FORMAT_DISCHARGING));\n+    m_toggleable = m_toggleable &&\n+                   ((m_label_full && *m_label_full && m_label_alt_full && *m_label_alt_full) ||\n+                   format_is_toggleable(FORMAT_FULL));\n   }\n \n   /**\n@@ -214,24 +236,35 @@ namespace modules {\n     m_state = state;\n     m_percentage = percentage;\n \n-    const auto label = [this] {\n-      if (m_state == battery_module::state::FULL) {\n-        return m_label_full;\n-      } else if (m_state == battery_module::state::DISCHARGING) {\n-        return m_label_discharging;\n-      } else {\n-        return m_label_charging;\n-      }\n-    }();\n-\n-    if (label) {\n-      label->reset_tokens();\n-      label->replace_token(\"%percentage%\", to_string(m_percentage));\n-      label->replace_token(\"%consumption%\", current_consumption());\n+    const auto replace_tokens = [&](label_t label) {\n+      if (label) {\n+        label->reset_tokens();\n+        label->replace_token(\"%percentage%\", to_string(m_percentage));\n+        label->replace_token(\"%consumption%\", current_consumption());\n \n-      if (m_state != battery_module::state::FULL && !m_timeformat.empty()) {\n-        label->replace_token(\"%time%\", current_time());\n+        if (m_state != battery_module::state::FULL && !m_timeformat.empty()) {\n+          label->replace_token(\"%time%\", current_time());\n+        }\n       }\n+    };\n+\n+    switch (m_state) {\n+      case battery_module::state::FULL:\n+        replace_tokens(m_label_full);\n+        replace_tokens(m_label_alt_full);\n+        break;\n+      case battery_module::state::DISCHARGING:\n+        replace_tokens(m_label_discharging);\n+        replace_tokens(m_label_alt_discharging);\n+        break;\n+      case battery_module::state::CHARGING:\n+        replace_tokens(m_label_charging);\n+        replace_tokens(m_label_alt_charging);\n+        break;\n+      case battery_module::state::NONE:\n+        // fall-through\n+      default:\n+        m_log.warn(\"Unsupported battery state: %d\", m_state);\n     }\n \n     return true;\n@@ -261,11 +294,11 @@ namespace modules {\n     } else if (tag == TAG_RAMP_CAPACITY) {\n       builder->node(m_ramp_capacity->get_by_percentage(m_percentage));\n     } else if (tag == TAG_LABEL_CHARGING) {\n-      builder->node(m_label_charging);\n+      builder->node(m_toggled ? m_label_alt_charging : m_label_charging);\n     } else if (tag == TAG_LABEL_DISCHARGING) {\n-      builder->node(m_label_discharging);\n+      builder->node(m_toggled ? m_label_alt_discharging : m_label_discharging);\n     } else if (tag == TAG_LABEL_FULL) {\n-      builder->node(m_label_full);\n+      builder->node(m_toggled ? m_label_alt_full : m_label_full);\n     } else {\n       return false;\n     }\n@@ -273,6 +306,24 @@ namespace modules {\n     return true;\n   }\n \n+  /**\n+   * Build module output and wrap it in a click handler use\n+   * to alter labels output\n+   */\n+  string battery_module::get_output() {\n+    string output{module::get_output()};\n+\n+    if (m_toggleable) {\n+      m_builder->cmd(mousebtn::LEFT, EVENT_TOGGLE);\n+      m_builder->append(output);\n+      m_builder->cmd_close();\n+    } else {\n+      m_builder->append(output);\n+    }\n+\n+    return m_builder->flush();\n+  }\n+\n   /**\n    * Get the current battery state\n    */\n@@ -350,6 +401,19 @@ namespace modules {\n \n     m_log.trace(\"%s: End of subthread\", name());\n   }\n+\n+  /**\n+   * Handle input command\n+   */\n+  bool battery_module::input(string&& cmd) {\n+    if (cmd != EVENT_TOGGLE) {\n+      return false;\n+    }\n+    m_toggled = !m_toggled;\n+    broadcast();\n+    return true;\n+  }\n+\n }\n \n POLYBAR_NS_END\ndiff --git a/src/modules/meta/base.cpp b/src/modules/meta/base.cpp\nindex b8d5d9fe7..ad70d6aea 100644\n--- a/src/modules/meta/base.cpp\n+++ b/src/modules/meta/base.cpp\n@@ -149,6 +149,26 @@ namespace modules {\n     return false;\n   }\n \n+  bool module_formatter::has_non_tag(const string& format_name) {\n+    auto format = m_formats.find(format_name);\n+    if (format == m_formats.end()) {\n+      throw undefined_format(format_name);\n+    }\n+    string value{format->second->value};\n+    size_t start, end;\n+    while ((start = value.find('<')) != string::npos &&\n+           (end = value.find('>', start)) != string::npos) {\n+      if (start > 0) {\n+          auto trimmed = string_util::ltrim(value.substr(0, start), ' ');\n+          if (!trimmed.empty()) {\n+            return true;\n+          }\n+      }\n+      value.erase(0, end + 1);\n+    }\n+    return !value.empty();\n+  }\n+\n   shared_ptr<module_format> module_formatter::get(const string& format_name) {\n     auto format = m_formats.find(format_name);\n     if (format == m_formats.end()) {\ndiff --git a/src/modules/network.cpp b/src/modules/network.cpp\nindex c46bb29e2..3ed1d7782 100644\n--- a/src/modules/network.cpp\n+++ b/src/modules/network.cpp\n@@ -27,6 +27,11 @@ namespace modules {\n     m_formatter->add(FORMAT_CONNECTED, TAG_LABEL_CONNECTED, {TAG_RAMP_SIGNAL, TAG_RAMP_QUALITY, TAG_LABEL_CONNECTED});\n     m_formatter->add(FORMAT_DISCONNECTED, TAG_LABEL_DISCONNECTED, {TAG_LABEL_DISCONNECTED});\n \n+    const auto state_is_toggleable = [&](const connection_state& state) {\n+      return m_label[state] && *m_label[state] &&\n+        m_label_alt[state] && *m_label_alt[state];\n+    };\n+\n     // Create elements for format-connected\n     if (m_formatter->has(TAG_RAMP_SIGNAL, FORMAT_CONNECTED)) {\n       m_ramp_signal = load_ramp(m_conf, name(), TAG_RAMP_SIGNAL);\n@@ -37,7 +42,13 @@ namespace modules {\n     if (m_formatter->has(TAG_LABEL_CONNECTED, FORMAT_CONNECTED)) {\n       m_label[connection_state::CONNECTED] =\n           load_optional_label(m_conf, name(), TAG_LABEL_CONNECTED, \"%ifname% %local_ip%\");\n+      m_label_alt[connection_state::CONNECTED] =\n+          load_optional_label(m_conf, name(), TAG_LABEL_ALT_CONNECTED, \"\");\n     }\n+    m_toggleable = state_is_toggleable(connection_state::CONNECTED) ||\n+                   (m_ramp_signal && *m_ramp_signal) ||\n+                   (m_ramp_quality && *m_ramp_quality) ||\n+                   m_formatter->has_non_tag(FORMAT_CONNECTED);\n \n     // Create elements for format-disconnected\n     if (m_formatter->has(TAG_LABEL_DISCONNECTED, FORMAT_DISCONNECTED)) {\n@@ -53,10 +64,15 @@ namespace modules {\n \n       if (m_formatter->has(TAG_LABEL_PACKETLOSS, FORMAT_PACKETLOSS)) {\n         m_label[connection_state::PACKETLOSS] = load_optional_label(m_conf, name(), TAG_LABEL_PACKETLOSS, \"\");\n+        m_label_alt[connection_state::PACKETLOSS] = load_optional_label(m_conf, name(), TAG_LABEL_ALT_PACKETLOSS, \"\");\n       }\n       if (m_formatter->has(TAG_ANIMATION_PACKETLOSS, FORMAT_PACKETLOSS)) {\n         m_animation_packetloss = load_animation(m_conf, name(), TAG_ANIMATION_PACKETLOSS);\n       }\n+      m_toggleable = m_toggleable &&\n+                     (state_is_toggleable(connection_state::PACKETLOSS) ||\n+                     (m_animation_packetloss && *m_animation_packetloss) ||\n+                     m_formatter->has_non_tag(FORMAT_PACKETLOSS));\n     }\n \n     // Get an intstance of the network interface\n@@ -128,9 +144,15 @@ namespace modules {\n     if (m_label[connection_state::CONNECTED]) {\n       replace_tokens(m_label[connection_state::CONNECTED]);\n     }\n+    if (m_label_alt[connection_state::CONNECTED]) {\n+      replace_tokens(m_label_alt[connection_state::CONNECTED]);\n+    }\n     if (m_label[connection_state::PACKETLOSS]) {\n       replace_tokens(m_label[connection_state::PACKETLOSS]);\n     }\n+    if (m_label_alt[connection_state::PACKETLOSS]) {\n+      replace_tokens(m_label_alt[connection_state::PACKETLOSS]);\n+    }\n \n     return true;\n   }\n@@ -147,11 +169,13 @@ namespace modules {\n \n   bool network_module::build(builder* builder, const string& tag) const {\n     if (tag == TAG_LABEL_CONNECTED) {\n-      builder->node(m_label.at(connection_state::CONNECTED));\n+      builder->node(m_toggled ? m_label_alt.at(connection_state::CONNECTED)\n+                              : m_label.at(connection_state::CONNECTED));\n     } else if (tag == TAG_LABEL_DISCONNECTED) {\n       builder->node(m_label.at(connection_state::DISCONNECTED));\n     } else if (tag == TAG_LABEL_PACKETLOSS) {\n-      builder->node(m_label.at(connection_state::PACKETLOSS));\n+      builder->node(m_toggled ? m_label_alt.at(connection_state::PACKETLOSS)\n+                              : m_label.at(connection_state::PACKETLOSS));\n     } else if (tag == TAG_ANIMATION_PACKETLOSS) {\n       builder->node(m_animation_packetloss->get());\n     } else if (tag == TAG_RAMP_SIGNAL) {\n@@ -164,6 +188,20 @@ namespace modules {\n     return true;\n   }\n \n+  string network_module::get_output() {\n+    string output{module::get_output()};\n+\n+    if (m_toggleable) {\n+      m_builder->cmd(mousebtn::LEFT, EVENT_TOGGLE);\n+      m_builder->append(output);\n+      m_builder->cmd_close();\n+    } else {\n+      m_builder->append(output);\n+    }\n+\n+    return m_builder->flush();\n+  }\n+\n   void network_module::subthread_routine() {\n     const chrono::milliseconds framerate{m_animation_packetloss->framerate()};\n     const auto dur = chrono::duration<double>(framerate);\n@@ -177,6 +215,15 @@ namespace modules {\n \n     m_log.trace(\"%s: Reached end of network subthread\", name());\n   }\n+\n+  bool network_module::input(string&& cmd) {\n+    if (cmd != EVENT_TOGGLE) {\n+      return false;\n+    }\n+    m_toggled = !m_toggled;\n+    broadcast();\n+    return true;\n+  }\n }\n \n POLYBAR_NS_END\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Code Duplication**: The current implementation requires copy-pasting code across modules to handle click events, which is inefficient. Suggest a centralized approach to integrate toggleable labels directly into the label drawtype or formatter.\n\n2. **Event Handling Issue**: Click events are module type-specific, causing multiple identical modules to conflict and send events to the same instance. Address this by assigning unique IDs to module instances for better event handling.\n\n3. **Toggleable Modules Feature**: Implement toggleable modules as an alternative to toggleable labels, allowing cycling between modules defined in a single position.\n\n4. **Configurable Click Actions**: Propose user-configurable click actions (e.g., single vs. double click) for toggling and internal actions within modules. Settings for these actions should reside in the bar settings section.\n\n5. **Next Steps**: Prioritize resolving issue #1172 before further development."
      }
    ],
    "codediff_length": 17040
  },
  {
    "index": 67,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/dlib/test/type_safe_union.cpp b/dlib/test/type_safe_union.cpp\nindex 28e2c65601..9f65a12b3d 100644\n--- a/dlib/test/type_safe_union.cpp\n+++ b/dlib/test/type_safe_union.cpp\n@@ -429,7 +429,6 @@ namespace\n                 b = 3;\n                 b = std::move(a);\n \n-                DLIB_TEST(a.get<int>() == 3);\n                 DLIB_TEST(b.get<std::string>() == \"asdf\");\n             }\n \n@@ -458,11 +457,214 @@ namespace\n                 DLIB_TEST(!a.contains<ptr_t>());\n                 DLIB_TEST(*b.get<ptr_t>() == \"asdf\");\n             }\n-        }\n \n-    };\n+            {\n+                //testing copy semantics and move semantics\n+\n+                struct mytype\n+                {\n+                    mytype(int i_ = 0) : i(i_) {}\n+\n+                    mytype(const mytype& other) : i(other.i) {}\n+                    mytype& operator=(const mytype& other) {i = other.i; return *this;}\n+\n+                    mytype(mytype&& other) : i(other.i) {other.i = 0;}\n+                    mytype& operator=(mytype&& other) {i = other.i ; other.i = 0; return *this;}\n+\n+                    int i = 0;\n+                };\n+\n+                using tsu = type_safe_union<int,mytype>;\n+\n+                {\n+                    mytype a(10);\n+                    tsu ta(a); //copy constructor\n+                    DLIB_TEST(a.i == 10);\n+                    DLIB_TEST(ta.cast_to<mytype>().i == 10);\n+                }\n+\n+                {\n+                    mytype a(10);\n+                    tsu ta;\n+                    ta = a; //copy assign\n+                    DLIB_TEST(a.i == 10);\n+                    DLIB_TEST(ta.cast_to<mytype>().i == 10);\n+                }\n+\n+                {\n+                    mytype a(10);\n+                    tsu ta(std::move(a)); //move constructor\n+                    DLIB_TEST(a.i == 0);\n+                    DLIB_TEST(ta.cast_to<mytype>().i == 10);\n+                }\n+\n+                {\n+                    mytype a(10);\n+                    tsu ta;\n+                    ta = std::move(a); //move assign\n+                    DLIB_TEST(a.i == 0);\n+                    DLIB_TEST(ta.cast_to<mytype>().i == 10);\n+                }\n+\n+                {\n+                    tsu ta(mytype(10));\n+                    DLIB_TEST(ta.cast_to<mytype>().i == 10);\n+                    tsu tb(ta); //copy constructor\n+                    DLIB_TEST(ta.cast_to<mytype>().i == 10);\n+                    DLIB_TEST(tb.cast_to<mytype>().i == 10);\n+                }\n+\n+                {\n+                    tsu ta(mytype(10));\n+                    DLIB_TEST(ta.cast_to<mytype>().i == 10);\n+                    tsu tb;\n+                    tb = ta; //copy assign\n+                    DLIB_TEST(ta.cast_to<mytype>().i == 10);\n+                    DLIB_TEST(tb.cast_to<mytype>().i == 10);\n+                }\n+\n+                {\n+                    tsu ta(mytype(10));\n+                    DLIB_TEST(ta.cast_to<mytype>().i == 10);\n+                    tsu tb(std::move(ta)); //move constructor\n+                    DLIB_TEST(ta.is_empty());\n+                    DLIB_TEST(tb.cast_to<mytype>().i == 10);\n+                }\n+\n+                {\n+                    tsu ta(mytype(10));\n+                    DLIB_TEST(ta.cast_to<mytype>().i == 10);\n+                    tsu tb;\n+                    tb = std::move(ta); //move assign\n+                    DLIB_TEST(ta.is_empty());\n+                    DLIB_TEST(tb.cast_to<mytype>().i == 10);\n+                }\n+            }\n \n+            {\n+                //testing emplace(), copy semantics, move semantics, swap, overloaded, and new visitor\n+                type_safe_union<int, float, std::string> a, b;\n+                a.emplace<std::string>(\"hello world\");\n+\n+                DLIB_TEST(a.contains<std::string>());\n+                b = a; //copy\n+                DLIB_TEST(a.contains<std::string>());\n+                DLIB_TEST(b.contains<std::string>());\n+                DLIB_TEST(a.cast_to<std::string>() == \"hello world\");\n+                DLIB_TEST(b.cast_to<std::string>() == \"hello world\");\n+                a = 1;\n+                DLIB_TEST(a.contains<int>());\n+                DLIB_TEST(a.cast_to<int>() == 1);\n+                b = std::move(a);\n+                DLIB_TEST(b.contains<int>());\n+                DLIB_TEST(b.cast_to<int>() == 1);\n+                DLIB_TEST(a.is_empty());\n+                DLIB_TEST(a.get_current_type_id() == 0);\n+                swap(a, b);\n+                DLIB_TEST(a.contains<int>());\n+                DLIB_TEST(a.cast_to<int>() == 1);\n+                DLIB_TEST(b.is_empty());\n+                DLIB_TEST(b.get_current_type_id() == 0);\n+                //visit can return non-void types\n+                auto ret = a.visit(overloaded(\n+                    [](int) {\n+                        return std::string(\"int\");\n+                    },\n+                    [](float) {\n+                        return std::string(\"float\");\n+                    },\n+                    [](const std::string&) {\n+                        return std::string(\"std::string\");\n+                    }\n+                ));\n+                static_assert(std::is_same<std::string, decltype(ret)>::value, \"bad return type\");\n+                DLIB_TEST(ret == \"int\");\n+                //apply_to_contents can only return void\n+                a = std::string(\"hello there!\");\n+                std::string str;\n+                a.apply_to_contents(overloaded(\n+                    [&str](int) {\n+                        str = std::string(\"int\");\n+                    },\n+                    [&str](float) {\n+                        str = std::string(\"float\");\n+                    },\n+                    [&str](const std::string& item) {\n+                        str = item;\n+                    }\n+                ));\n+                DLIB_TEST(str == \"hello there!\");\n+            }\n \n+            {\n+                //nested unions\n+                using tsu_a = type_safe_union<int,float,std::string>;\n+                using tsu_b = type_safe_union<int,float,std::string,tsu_a>;\n+\n+                tsu_b object(dlib::in_place_tag<tsu_a>{}, std::string(\"hello from bottom node\"));\n+                DLIB_TEST(object.contains<tsu_a>());\n+                DLIB_TEST(object.get<tsu_a>().get<std::string>() == \"hello from bottom node\");\n+                auto ret = object.visit(overloaded(\n+                    [](int) {\n+                        return std::string(\"int\");\n+                    },\n+                    [](float) {\n+                        return std::string(\"float\");\n+                    },\n+                    [](std::string) {\n+                        return std::string(\"std::string\");\n+                    },\n+                    [](const tsu_a& item) {\n+                        return item.visit(overloaded(\n+                            [](int) {\n+                                return std::string(\"nested int\");\n+                            },\n+                            [](float) {\n+                                return std::string(\"nested float\");\n+                            },\n+                            [](std::string str) {\n+                                return str;\n+                            }\n+                        ));\n+                    }\n+                ));\n+                static_assert(std::is_same<std::string, decltype(ret)>::value, \"bad type\");\n+                DLIB_TEST(ret == \"hello from bottom node\");\n+            }\n+\n+            {\n+                //\"private\" visitor\n+                using tsu = type_safe_union<int,float,std::string>;\n+\n+                class visitor_private\n+                {\n+                private:\n+                    std::string operator()(int)\n+                    {\n+                        return std::string(\"int\");\n+                    }\n+\n+                    std::string operator()(float)\n+                    {\n+                        return std::string(\"float\");\n+                    }\n+\n+                    std::string operator()(const std::string& str)\n+                    {\n+                        return str;\n+                    }\n+\n+                    friend tsu;\n+                };\n+\n+                visitor_private visitor;\n+                tsu a = std::string(\"hello from private visitor\");\n+                auto ret = a.visit(visitor);\n+                static_assert(std::is_same<std::string, decltype(ret)>::value, \"bad type\");\n+                DLIB_TEST(ret == \"hello from private visitor\");\n+            }\n+        }\n+    };\n \n     class type_safe_union_tester : public tester\n     {\ndiff --git a/dlib/type_safe_union/type_safe_union_kernel.h b/dlib/type_safe_union/type_safe_union_kernel.h\nindex c206992933..87efcfd66b 100644\n--- a/dlib/type_safe_union/type_safe_union_kernel.h\n+++ b/dlib/type_safe_union/type_safe_union_kernel.h\n@@ -4,18 +4,14 @@\n #define DLIB_TYPE_SAFE_UNIOn_h_\n \n #include \"type_safe_union_kernel_abstract.h\"\n-#include \"../algs.h\"\n-#include \"../noncopyable.h\"\n-#include \"../serialize.h\"\n #include <new>\n #include <iostream>\n #include <type_traits>\n+#include <functional>\n+#include \"../serialize.h\"\n \n namespace dlib\n {\n-\n-// ----------------------------------------------------------------------------------------\n-\n     class bad_type_safe_union_cast : public std::bad_cast \n     {\n     public:\n@@ -25,38 +21,92 @@ namespace dlib\n           }\n     };\n \n-// ----------------------------------------------------------------------------------------\n-\n-    struct _void{};\n-    inline void serialize( const _void&, std::ostream&){}\n-    inline void deserialize(  _void&, std::istream&){}\n-\n-// ----------------------------------------------------------------------------------------\n-\n-    template <\n-        typename T1,\n-        typename T2 = _void,\n-        typename T3 = _void,\n-        typename T4 = _void,\n-        typename T5 = _void, \n-        typename T6 = _void,\n-        typename T7 = _void,\n-        typename T8 = _void,\n-        typename T9 = _void,\n-        typename T10 = _void,\n-\n-        typename T11 = _void,\n-        typename T12 = _void,\n-        typename T13 = _void,\n-        typename T14 = _void,\n-        typename T15 = _void,\n-        typename T16 = _void,\n-        typename T17 = _void,\n-        typename T18 = _void,\n-        typename T19 = _void,\n-        typename T20 = _void\n-        >\n-    class type_safe_union : noncopyable\n+    template<typename T>\n+    struct in_place_tag {};\n+\n+    namespace internal\n+    {\n+        // ---------------------------------------------------------------------\n+        template <typename T, typename... Rest>\n+        struct is_any : std::false_type {};\n+\n+        template <typename T, typename First>\n+        struct is_any<T,First> : std::is_same<T,First> {};\n+\n+        template <typename T, typename First, typename... Rest>\n+        struct is_any<T,First,Rest...> : std::integral_constant<bool, std::is_same<T,First>::value || is_any<T,Rest...>::value> {};\n+\n+        // ---------------------------------------------------------------------\n+        namespace detail\n+        {\n+            struct empty {};\n+\n+            template<typename T>\n+            struct variant_type_placeholder {using type = T;};\n+\n+            template <\n+                    size_t nVariantTypes,\n+                    size_t Counter,\n+                    size_t I,\n+                    typename... VariantTypes\n+            >\n+            struct variant_get_type_impl {};\n+\n+            template <\n+                    size_t nVariantTypes,\n+                    size_t Counter,\n+                    size_t I,\n+                    typename VariantTypeFirst,\n+                    typename... VariantTypeRest\n+            >\n+            struct variant_get_type_impl<nVariantTypes, Counter, I, VariantTypeFirst, VariantTypeRest...>\n+                    :   std::conditional<(Counter < nVariantTypes),\n+                            typename std::conditional<(I == Counter),\n+                                    variant_type_placeholder<VariantTypeFirst>,\n+                                    variant_get_type_impl<nVariantTypes, Counter+1, I, VariantTypeRest...>\n+                            >::type,\n+                            empty\n+                    >::type {};\n+        }\n+\n+        template <size_t I, typename... VariantTypes>\n+        struct variant_get_type : detail::variant_get_type_impl<sizeof...(VariantTypes), 0, I, VariantTypes...> {};\n+\n+        // ---------------------------------------------------------------------\n+        namespace detail\n+        {\n+            template <\n+                    size_t nVariantTypes,\n+                    size_t Counter,\n+                    typename T,\n+                    typename... VariantTypes\n+            >\n+            struct variant_type_id_impl : std::integral_constant<int,-1> {};\n+\n+            template <\n+                    size_t nVariantTypes,\n+                    size_t Counter,\n+                    typename T,\n+                    typename VariantTypeFirst,\n+                    typename... VariantTypesRest\n+            >\n+            struct variant_type_id_impl<nVariantTypes,Counter,T,VariantTypeFirst,VariantTypesRest...>\n+                    :   std::conditional<(Counter < nVariantTypes),\n+                            typename std::conditional<std::is_same<T,VariantTypeFirst>::value,\n+                                    std::integral_constant<int,Counter+1>,\n+                                    variant_type_id_impl<nVariantTypes,Counter + 1, T, VariantTypesRest...>\n+                            >::type,\n+                            std::integral_constant<int,-1>\n+                    >::type {};\n+        }\n+\n+        template <typename T, typename... VariantTypes>\n+        struct variant_type_id : detail::variant_type_id_impl<sizeof...(VariantTypes), 0, T, VariantTypes...> {};\n+        // ---------------------------------------------------------------------\n+    }\n+\n+    template <typename... Types>\n+    class type_safe_union\n     {\n         /*!\n             CONVENTION\n@@ -65,46 +115,141 @@ namespace dlib\n                 - mem == the aligned block of memory on the stack which is\n                   where objects in the union are stored\n         !*/\n+    public:\n+        template <typename T>\n+        static constexpr int get_type_id ()\n+        {\n+            return internal::variant_type_id<T,Types...>::value;\n+        }\n \n     private:\n+        template<typename T>\n+        struct is_valid : internal::is_any<T,Types...> {};\n \n-        template <typename T, typename U>\n-        void invoke_on (\n-            T& obj,\n-            U& item\n-        ) const\n+        template<typename T>\n+        using is_valid_check = typename std::enable_if<is_valid<T>::value, bool>::type;\n+\n+        template <size_t I>\n+        struct get_type : internal::variant_get_type<I,Types...> {};\n+\n+        template <size_t I>\n+        using get_type_t = typename get_type<I>::type;\n+\n+        using T0 = get_type_t<0>;\n+\n+        template<typename F, typename T>\n+        struct return_type\n+        {\n+            using type = decltype(std::declval<F>()(std::declval<T>()));\n+        };\n+\n+        template<typename F, typename T>\n+        using return_type_t = typename return_type<F,T>::type;\n+\n+        typename std::aligned_union<0, Types...>::type mem;\n+        int type_identity = 0;\n+\n+        template<\n+            size_t I,\n+            typename F\n+        >\n+        auto visit_impl(\n+            F&&\n+        ) -> typename std::enable_if<\n+                (I == sizeof...(Types)) &&\n+                std::is_same<void, return_type_t<F, T0&>>::value\n+        >::type\n         {\n-            obj(item);\n         }\n \n-        template <typename T>\n-        void invoke_on (\n-            T& ,\n-            _void \n-        ) const\n+        template<\n+            size_t I,\n+            typename F\n+        >\n+        auto visit_impl(\n+            F&&\n+        ) -> typename std::enable_if<\n+                (I == sizeof...(Types)) &&\n+                ! std::is_same<void, return_type_t<F, T0&>>::value,\n+                return_type_t<F, T0&>\n+        >::type\n+        {\n+            return return_type_t<F, T0&>{};\n+        }\n+\n+        template<\n+            size_t I,\n+            typename F\n+        >\n+        auto visit_impl(\n+            F&& f\n+        )  -> typename std::enable_if<\n+                (I < sizeof...(Types)),\n+                return_type_t<F, T0&>\n+        >::type\n         {\n+            if (type_identity == (I+1))\n+                return std::forward<F>(f)(unchecked_get<get_type_t<I>>());\n+            else\n+                return visit_impl<I+1>(std::forward<F>(f));\n         }\n \n-        // member data\n-        typename std::aligned_union<0, T1,T2,T3,T4,T5, \n-                                       T6,T7,T8,T9,T10,\n-                                       T11,T12,T13,T14,T15,\n-                                       T16,T17,T18,T19,T20>::type mem;\n-        int type_identity;\n+        template<\n+            size_t I,\n+            typename F\n+        >\n+        auto visit_impl(\n+            F&&\n+        ) const -> typename std::enable_if<\n+                (I == sizeof...(Types)) &&\n+                std::is_same<void, return_type_t<F, const T0&>>::value\n+        >::type\n+        {\n+        }\n \n-        // --------------------------------------------\n+        template<\n+            size_t I,\n+            typename F\n+        >\n+        auto visit_impl(\n+            F&&\n+        ) const -> typename std::enable_if<\n+                (I == sizeof...(Types)) &&\n+                ! std::is_same<void, return_type_t<F, const T0&>>::value,\n+                return_type_t<F, const T0&>\n+        >::type\n+        {\n+            return return_type_t<F, const T0&>{};\n+        }\n+\n+        template<\n+            size_t I,\n+            typename F\n+        >\n+        auto visit_impl(\n+            F&& f\n+        ) const -> typename std::enable_if<\n+                (I < sizeof...(Types)),\n+                return_type_t<F, const T0&>\n+        >::type\n+        {\n+            if (type_identity == (I+1))\n+                return std::forward<F>(f)(unchecked_get<get_type_t<I>>());\n+            else\n+                return visit_impl<I+1>(std::forward<F>(f));\n+        }\n \n         template <typename T>\n-        void validate_type() const\n+        const T& unchecked_get() const\n         {\n-            // ERROR: You are trying to get a type of object that isn't\n-            // representable by this type_safe_union.\n-            static_assert(is_any<T,T1,T2,T3,T4,T5,\n-                                   T6,T7,T8,T9,T10,\n-                                   T11,T12,T13,T14,T15,\n-                                   T16,T17,T18,T19,T20>::value, \"Type T isn't one of the ones given to this object's template arguments.\");\n+            return *reinterpret_cast<const T*>(&mem);\n         }\n \n+        template <typename T>\n+        T& unchecked_get()\n+        {\n+            return *reinterpret_cast<T*>(&mem);\n+        }\n \n         struct destruct_helper\n         {\n@@ -115,124 +260,158 @@ namespace dlib\n             }\n         };\n \n-        void destruct (\n-        ) \n-        /*!\n-            ensures\n-                - #is_empty() == true\n-        !*/\n+        void destruct ()\n         {\n-            // destruct whatever is in this object\n-            apply_to_contents(destruct_helper());\n-\n-            // mark this object as being empty\n+            visit(destruct_helper{});\n             type_identity = 0;\n         }\n \n-        template <typename T>\n+        template <typename T, typename... Args>\n         void construct (\n-        )  \n-        { \n-            if (type_identity != get_type_id<T>())\n+            Args&&... args\n+        )\n+        {\n+            destruct();\n+            new(&mem) T(std::forward<Args>(args)...);\n+            type_identity = get_type_id<T>();\n+        }\n+\n+        struct helper_forward\n+        {\n+            helper_forward(type_safe_union& me) : _me(me) {}\n+\n+            template<typename T>\n+            void operator()(T&& x)\n             {\n-                destruct(); \n-                new(&mem) T(); \n-                type_identity = get_type_id<T>();\n+                using U = typename std::decay<T>::type;\n+\n+                if (_me.type_identity != get_type_id<U>())\n+                {\n+                    _me.construct<U>(std::forward<T>(x));\n+                }\n+                else\n+                {\n+                    _me.template unchecked_get<U>() = std::forward<T>(x);\n+                }\n             }\n-        }\n \n-        template <typename T>\n-        void construct (\n-            T&& item\n-        )  \n-        { \n-            using U = typename std::decay<T>::type;\n-            if (type_identity != get_type_id<U>())\n+            type_safe_union& _me;\n+        };\n+\n+        struct helper_move\n+        {\n+            helper_move(type_safe_union& me) : _me(me) {}\n+\n+            template<typename T>\n+            void operator()(T& x)\n             {\n-                destruct(); \n-                new(&mem) U(std::forward<T>(item)); \n-                type_identity = get_type_id<U>();\n+                if (_me.type_identity != get_type_id<T>())\n+                {\n+                    _me.construct<T>(std::move(x));\n+                }\n+                else\n+                {\n+                    _me.template unchecked_get<T>() = std::move(x);\n+                }\n             }\n-        }\n \n-        template <typename T> \n-        T& unchecked_get(\n-        ) \n-        /*!\n-            requires\n-                - contains<T>() == true\n-            ensures\n-                - returns a non-const reference to the T object\n-        !*/\n-        { \n-            return *reinterpret_cast<T*>(&mem); \n-        }\n+            type_safe_union& _me;\n+        };\n \n-        template <typename T> \n-        const T& unchecked_get(\n-        ) const\n-        /*!\n-            requires\n-                - contains<T>() == true\n-            ensures\n-                - returns a const reference to the T object\n-        !*/\n-        { \n-            return *reinterpret_cast<const T*>(&mem); \n+        struct swap_helper\n+        {\n+            swap_helper(type_safe_union& me) : _me(me) {}\n+\n+            template<typename T>\n+            void operator()(T& x)\n+            {\n+                using std::swap;\n+                swap(_me.unchecked_get<T>(), x); //really you want to use cast_to<T>(), BUT, swap is supposed to be nothrow\n+            }\n+\n+            type_safe_union& _me;\n+        };\n+\n+    public:\n+\n+        type_safe_union() = default;\n+\n+        type_safe_union (\n+            const type_safe_union& item\n+        ) : type_safe_union()\n+        {\n+            item.visit(helper_forward{*this});\n         }\n \n-        template <typename T>\n-        void operator() (T& item) \n-        /*\n-            This function is used by the swap function of this class.  See that\n-            function to see how this works.\n-        */\n+        type_safe_union& operator=(\n+            const type_safe_union& item\n+        )\n         {\n-            exchange(get<T>(), item);\n+            if (item.is_empty())\n+                destruct();\n+            else\n+                item.visit(helper_forward{*this});\n+            return *this;\n         }\n \n-    public:\n+        type_safe_union (\n+            type_safe_union&& item\n+        ) : type_safe_union()\n+        {\n+            item.visit(helper_move{*this});\n+            item.destruct();\n+        }\n \n-        typedef T1 type1;\n-        typedef T2 type2;\n-        typedef T3 type3;\n-        typedef T4 type4;\n-        typedef T5 type5;\n-        typedef T6 type6;\n-        typedef T7 type7;\n-        typedef T8 type8;\n-        typedef T9 type9;\n-        typedef T10 type10;\n-        typedef T11 type11;\n-        typedef T12 type12;\n-        typedef T13 type13;\n-        typedef T14 type14;\n-        typedef T15 type15;\n-        typedef T16 type16;\n-        typedef T17 type17;\n-        typedef T18 type18;\n-        typedef T19 type19;\n-        typedef T20 type20;\n-\n-\n-        type_safe_union() : type_identity(0) \n-        { \n+        type_safe_union& operator= (\n+            type_safe_union&& item\n+        )\n+        {\n+            if (item.is_empty())\n+            {\n+                destruct();\n+            }\n+            else\n+            {\n+                item.visit(helper_move{*this});\n+                item.destruct();\n+            }\n+            return *this;\n         }\n \n-        template <typename T>\n+        template <\n+            typename T,\n+            is_valid_check<typename std::decay<T>::type> = true\n+        >\n         type_safe_union (\n             T&& item\n-        ) : type_identity(0)\n+        ) : type_safe_union()\n+        {\n+            helper_forward{*this}(std::forward<T>(item));\n+        }\n+\n+        template <\n+            typename T,\n+            is_valid_check<typename std::decay<T>::type> = true\n+        >\n+        type_safe_union& operator= (\n+            T&& item\n+        )\n         {\n-            validate_type<typename std::decay<T>::type>();\n-            construct(std::forward<T>(item));\n+            helper_forward{*this}(std::forward<T>(item));\n+            return *this;\n         }\n \n+        template <\n+            typename T,\n+            typename... Args,\n+            is_valid_check<T> = true\n+        >\n         type_safe_union (\n-            type_safe_union&& item\n-        ) : type_safe_union() \n+            in_place_tag<T>,\n+            Args&&... args\n+        )\n         {\n-            swap(item);\n+            construct<T,Args...>(std::forward<Args>(args)...);\n         }\n \n         ~type_safe_union()\n@@ -240,373 +419,205 @@ namespace dlib\n             destruct();\n         }\n \n-        template <typename T>\n-        static int get_type_id (\n-        ) \n-        {\n-            if (std::is_same<T,T1>::value) return 1;\n-            if (std::is_same<T,T2>::value) return 2;\n-            if (std::is_same<T,T3>::value) return 3;\n-            if (std::is_same<T,T4>::value) return 4;\n-            if (std::is_same<T,T5>::value) return 5;\n-\n-            if (std::is_same<T,T6>::value) return 6;\n-            if (std::is_same<T,T7>::value) return 7;\n-            if (std::is_same<T,T8>::value) return 8;\n-            if (std::is_same<T,T9>::value) return 9;\n-            if (std::is_same<T,T10>::value) return 10;\n-\n-            if (std::is_same<T,T11>::value) return 11;\n-            if (std::is_same<T,T12>::value) return 12;\n-            if (std::is_same<T,T13>::value) return 13;\n-            if (std::is_same<T,T14>::value) return 14;\n-            if (std::is_same<T,T15>::value) return 15;\n-\n-            if (std::is_same<T,T16>::value) return 16;\n-            if (std::is_same<T,T17>::value) return 17;\n-            if (std::is_same<T,T18>::value) return 18;\n-            if (std::is_same<T,T19>::value) return 19;\n-            if (std::is_same<T,T20>::value) return 20;\n-\n-            // return a number that doesn't match any of the\n-            // valid states of type_identity\n-            return -1;\n+        void clear()\n+        {\n+            destruct();\n         }\n \n-        template <typename T>\n-        bool contains (\n-        ) const\n+        template <\n+            typename T,\n+            typename... Args,\n+            is_valid_check<T> = true\n+        >\n+        void emplace(\n+            Args&&... args\n+        )\n         {\n-            return type_identity == get_type_id<T>();\n+            construct<T,Args...>(std::forward<Args>(args)...);\n         }\n \n-        bool is_empty (\n-        ) const\n+        template <typename F>\n+        auto visit(\n+            F&& f\n+        ) -> decltype(visit_impl<0>(std::forward<F>(f)))\n         {\n-            return type_identity == 0;\n+            return visit_impl<0>(std::forward<F>(f));\n         }\n \n+        template <typename F>\n+        auto visit(\n+            F&& f\n+        ) const -> decltype(visit_impl<0>(std::forward<F>(f)))\n+        {\n+            return visit_impl<0>(std::forward<F>(f));\n+        }\n \n-    public:\n-\n-        template <\n-            typename t1, typename t2, typename t3, typename t4, typename t5,\n-            typename t6, typename t7, typename t8, typename t9, typename t10,\n-            typename t11, typename t12, typename t13, typename t14, typename t15,\n-            typename t16, typename t17, typename t18, typename t19, typename t20\n-            >\n-        friend void serialize (\n-            const type_safe_union<t1,t2,t3,t4,t5,t6,t7,t8,t9,t10, t11,t12,t13,t14,t15,t16,t17,t18,t19,t20>& item,\n-            std::ostream& out\n-        );\n-\n-\n-        template <\n-            typename T\n-            >\n-        void apply_to_contents (\n-            T& obj\n-        ) \n+        template <typename F>\n+        void apply_to_contents(\n+            F&& f\n+        )\n         {\n-            switch (type_identity)\n-            {\n-                // do nothing because we are empty\n-                case 0: break;\n-\n-                case 1: invoke_on(obj,unchecked_get<T1>());  break;\n-                case 2: invoke_on(obj,unchecked_get<T2>());  break;\n-                case 3: invoke_on(obj,unchecked_get<T3>());  break;\n-                case 4: invoke_on(obj,unchecked_get<T4>());  break;\n-                case 5: invoke_on(obj,unchecked_get<T5>());  break;\n-\n-                case 6: invoke_on(obj,unchecked_get<T6>());  break;\n-                case 7: invoke_on(obj,unchecked_get<T7>());  break;\n-                case 8: invoke_on(obj,unchecked_get<T8>());  break;\n-                case 9: invoke_on(obj,unchecked_get<T9>());  break;\n-                case 10: invoke_on(obj,unchecked_get<T10>());  break;\n-\n-                case 11: invoke_on(obj,unchecked_get<T11>());  break;\n-                case 12: invoke_on(obj,unchecked_get<T12>());  break;\n-                case 13: invoke_on(obj,unchecked_get<T13>());  break;\n-                case 14: invoke_on(obj,unchecked_get<T14>());  break;\n-                case 15: invoke_on(obj,unchecked_get<T15>());  break;\n-\n-                case 16: invoke_on(obj,unchecked_get<T16>());  break;\n-                case 17: invoke_on(obj,unchecked_get<T17>());  break;\n-                case 18: invoke_on(obj,unchecked_get<T18>());  break;\n-                case 19: invoke_on(obj,unchecked_get<T19>());  break;\n-                case 20: invoke_on(obj,unchecked_get<T20>());  break;\n-            }\n+            visit(std::forward<F>(f));\n         }\n \n-        template <\n-            typename T\n-            >\n-        void apply_to_contents (\n-            const T& obj\n-        ) \n+        template <typename F>\n+        void apply_to_contents(\n+            F&& f\n+        ) const\n         {\n-            switch (type_identity)\n-            {\n-                // do nothing because we are empty\n-                case 0: break;\n-\n-                case 1: invoke_on(obj,unchecked_get<T1>());  break;\n-                case 2: invoke_on(obj,unchecked_get<T2>());  break;\n-                case 3: invoke_on(obj,unchecked_get<T3>());  break;\n-                case 4: invoke_on(obj,unchecked_get<T4>());  break;\n-                case 5: invoke_on(obj,unchecked_get<T5>());  break;\n-\n-                case 6: invoke_on(obj,unchecked_get<T6>());  break;\n-                case 7: invoke_on(obj,unchecked_get<T7>());  break;\n-                case 8: invoke_on(obj,unchecked_get<T8>());  break;\n-                case 9: invoke_on(obj,unchecked_get<T9>());  break;\n-                case 10: invoke_on(obj,unchecked_get<T10>());  break;\n-\n-                case 11: invoke_on(obj,unchecked_get<T11>());  break;\n-                case 12: invoke_on(obj,unchecked_get<T12>());  break;\n-                case 13: invoke_on(obj,unchecked_get<T13>());  break;\n-                case 14: invoke_on(obj,unchecked_get<T14>());  break;\n-                case 15: invoke_on(obj,unchecked_get<T15>());  break;\n-\n-                case 16: invoke_on(obj,unchecked_get<T16>());  break;\n-                case 17: invoke_on(obj,unchecked_get<T17>());  break;\n-                case 18: invoke_on(obj,unchecked_get<T18>());  break;\n-                case 19: invoke_on(obj,unchecked_get<T19>());  break;\n-                case 20: invoke_on(obj,unchecked_get<T20>());  break;\n-            }\n+            visit(std::forward<F>(f));\n         }\n \n-        template <\n-            typename T\n-            >\n-        void apply_to_contents (\n-            T& obj\n+        template <typename T>\n+        bool contains (\n         ) const\n         {\n-            switch (type_identity)\n-            {\n-                // do nothing because we are empty\n-                case 0: break;\n-\n-                case 1: invoke_on(obj,unchecked_get<T1>());  break;\n-                case 2: invoke_on(obj,unchecked_get<T2>());  break;\n-                case 3: invoke_on(obj,unchecked_get<T3>());  break;\n-                case 4: invoke_on(obj,unchecked_get<T4>());  break;\n-                case 5: invoke_on(obj,unchecked_get<T5>());  break;\n-\n-                case 6: invoke_on(obj,unchecked_get<T6>());  break;\n-                case 7: invoke_on(obj,unchecked_get<T7>());  break;\n-                case 8: invoke_on(obj,unchecked_get<T8>());  break;\n-                case 9: invoke_on(obj,unchecked_get<T9>());  break;\n-                case 10: invoke_on(obj,unchecked_get<T10>());  break;\n-\n-                case 11: invoke_on(obj,unchecked_get<T11>());  break;\n-                case 12: invoke_on(obj,unchecked_get<T12>());  break;\n-                case 13: invoke_on(obj,unchecked_get<T13>());  break;\n-                case 14: invoke_on(obj,unchecked_get<T14>());  break;\n-                case 15: invoke_on(obj,unchecked_get<T15>());  break;\n-\n-                case 16: invoke_on(obj,unchecked_get<T16>());  break;\n-                case 17: invoke_on(obj,unchecked_get<T17>());  break;\n-                case 18: invoke_on(obj,unchecked_get<T18>());  break;\n-                case 19: invoke_on(obj,unchecked_get<T19>());  break;\n-                case 20: invoke_on(obj,unchecked_get<T20>());  break;\n-            }\n+            return type_identity == get_type_id<T>();\n         }\n \n-        template <\n-            typename T\n-            >\n-        void apply_to_contents (\n-            const T& obj\n+        bool is_empty (\n         ) const\n         {\n-            switch (type_identity)\n-            {\n-                // do nothing because we are empty\n-                case 0: break;\n-\n-                case 1: invoke_on(obj,unchecked_get<T1>());  break;\n-                case 2: invoke_on(obj,unchecked_get<T2>());  break;\n-                case 3: invoke_on(obj,unchecked_get<T3>());  break;\n-                case 4: invoke_on(obj,unchecked_get<T4>());  break;\n-                case 5: invoke_on(obj,unchecked_get<T5>());  break;\n-\n-                case 6: invoke_on(obj,unchecked_get<T6>());  break;\n-                case 7: invoke_on(obj,unchecked_get<T7>());  break;\n-                case 8: invoke_on(obj,unchecked_get<T8>());  break;\n-                case 9: invoke_on(obj,unchecked_get<T9>());  break;\n-                case 10: invoke_on(obj,unchecked_get<T10>());  break;\n-\n-                case 11: invoke_on(obj,unchecked_get<T11>());  break;\n-                case 12: invoke_on(obj,unchecked_get<T12>());  break;\n-                case 13: invoke_on(obj,unchecked_get<T13>());  break;\n-                case 14: invoke_on(obj,unchecked_get<T14>());  break;\n-                case 15: invoke_on(obj,unchecked_get<T15>());  break;\n-\n-                case 16: invoke_on(obj,unchecked_get<T16>());  break;\n-                case 17: invoke_on(obj,unchecked_get<T17>());  break;\n-                case 18: invoke_on(obj,unchecked_get<T18>());  break;\n-                case 19: invoke_on(obj,unchecked_get<T19>());  break;\n-                case 20: invoke_on(obj,unchecked_get<T20>());  break;\n-            }\n+            return type_identity == 0;\n+        }\n+\n+        int get_current_type_id() const\n+        {\n+            return type_identity;\n         }\n \n         void swap (\n             type_safe_union& item\n         )\n         {\n-            // if both *this and item contain the same type of thing\n             if (type_identity == item.type_identity)\n             {\n-                // swap the things in this and item.  \n-                item.apply_to_contents(*this);\n+                item.visit(swap_helper{*this});\n             }\n-            else if (type_identity == 0)\n+            else if (is_empty())\n             {\n-                // *this doesn't contain anything.  So swap this and item and\n-                // then destruct item.\n-                item.apply_to_contents(*this);\n+                item.visit(helper_move{*this});\n                 item.destruct();\n             }\n-            else if (item.type_identity == 0)\n+            else if (item.is_empty())\n             {\n-                // *this doesn't contain anything.  So swap this and item and\n-                // then destruct this.\n-                apply_to_contents(item);\n+                visit(helper_move{item});\n                 destruct();\n             }\n             else\n             {\n-                type_safe_union temp;\n-                // swap *this into temp\n-                apply_to_contents(temp);\n-                // swap item into *this\n-                item.apply_to_contents(*this);\n-                // swap temp into item\n-                temp.apply_to_contents(item);\n+                type_safe_union tmp;\n+                swap(tmp);      // this -> tmp\n+                swap(item);     // item -> this\n+                tmp.swap(item); // tmp (this) -> item\n             }\n         }\n \n-        template <typename T> \n+        template <\n+            typename T,\n+            is_valid_check<T> = true\n+        >\n         T& get(\n-        ) \n-        { \n-            validate_type<T>();\n-            construct<T>();  \n-            return *reinterpret_cast<T*>(&mem); \n+        )\n+        {\n+            if (type_identity != get_type_id<T>())\n+                construct<T>();\n+            return unchecked_get<T>();\n         }\n \n-        template <typename T>\n+        template <\n+            typename T,\n+            is_valid_check<T> = true\n+        >\n         const T& cast_to (\n         ) const\n         {\n-            validate_type<T>();\n             if (contains<T>())\n-                return *reinterpret_cast<const T*>(&mem);\n+                return unchecked_get<T>();\n             else\n                 throw bad_type_safe_union_cast();\n         }\n \n-        template <typename T>\n+        template <\n+            typename T,\n+            is_valid_check<T> = true\n+        >\n         T& cast_to (\n-        ) \n+        )\n         {\n-            validate_type<T>();\n             if (contains<T>())\n-                return *reinterpret_cast<T*>(&mem);\n+                return unchecked_get<T>();\n             else\n                 throw bad_type_safe_union_cast();\n         }\n-\n-        template <typename T>\n-        type_safe_union& operator= (T&& item) { get<typename std::decay<T>::type>() = std::forward<T>(item); return *this; }\n-\n-        type_safe_union& operator= (type_safe_union&& item) { swap(item); return *this; }\n-\n     };\n \n-// ----------------------------------------------------------------------------------------\n-\n-    template <\n-        typename T1, typename T2, typename T3, typename T4, typename T5,\n-        typename T6, typename T7, typename T8, typename T9, typename T10,\n-        typename T11, typename T12, typename T13, typename T14, typename T15,\n-        typename T16, typename T17, typename T18, typename T19, typename T20\n-        >\n+    template <typename ...Types>\n     inline void swap (\n-        type_safe_union<T1,T2,T3,T4,T5,T6,T7,T8,T9,T10, T11,T12,T13,T14,T15,T16,T17,T18,T19,T20>& a, \n-        type_safe_union<T1,T2,T3,T4,T5,T6,T7,T8,T9,T10, T11,T12,T13,T14,T15,T16,T17,T18,T19,T20>& b \n-    ) { a.swap(b); }   \n-\n-// ----------------------------------------------------------------------------------------\n-\n-    template <\n-        typename from, \n-        typename T1, typename T2, typename T3, typename T4, typename T5,\n-        typename T6, typename T7, typename T8, typename T9, typename T10,\n-        typename T11, typename T12, typename T13, typename T14, typename T15,\n-        typename T16, typename T17, typename T18, typename T19, typename T20\n-        >\n-    struct is_convertible<from,\n-        type_safe_union<T1,T2,T3,T4,T5,T6,T7,T8,T9,T10, T11,T12,T13,T14,T15,T16,T17,T18,T19,T20> >\n-    {\n-        const static bool value = is_convertible<from,T1>::value ||\n-                                  is_convertible<from,T2>::value ||\n-                                  is_convertible<from,T3>::value ||\n-                                  is_convertible<from,T4>::value ||\n-                                  is_convertible<from,T5>::value ||\n-                                  is_convertible<from,T6>::value ||\n-                                  is_convertible<from,T7>::value ||\n-                                  is_convertible<from,T8>::value ||\n-                                  is_convertible<from,T9>::value ||\n-                                  is_convertible<from,T10>::value ||\n-                                  is_convertible<from,T11>::value ||\n-                                  is_convertible<from,T12>::value ||\n-                                  is_convertible<from,T13>::value ||\n-                                  is_convertible<from,T14>::value ||\n-                                  is_convertible<from,T15>::value ||\n-                                  is_convertible<from,T16>::value ||\n-                                  is_convertible<from,T17>::value ||\n-                                  is_convertible<from,T18>::value ||\n-                                  is_convertible<from,T19>::value ||\n-                                  is_convertible<from,T20>::value;\n-    };\n+        type_safe_union<Types...>& a,\n+        type_safe_union<Types...>& b\n+    ) { a.swap(b); }\n \n-// ----------------------------------------------------------------------------------------\n-\n-    namespace impl_tsu\n+    namespace detail\n     {\n         struct serialize_helper\n         {\n-            /*\n-                This is a function object to help us serialize type_safe_unions\n-            */\n+            serialize_helper(std::ostream& out_) : out(out_) {}\n \n-            std::ostream& out;\n-            serialize_helper(std::ostream& out_): out(out_) {}\n             template <typename T>\n-            void operator() (const T& item) const { serialize(item, out); } \n-        };\n-    }\n+            void operator() (const T& item) const \n+            { \n+                serialize(item, out); \n+            } \n \n-    template <\n-        typename T1, typename T2, typename T3, typename T4, typename T5,\n-        typename T6, typename T7, typename T8, typename T9, typename T10,\n-        typename T11, typename T12, typename T13, typename T14, typename T15,\n-        typename T16, typename T17, typename T18, typename T19, typename T20\n+            std::ostream& out;\n+        };  \n+\n+        template<\n+            size_t I,\n+            typename... Types\n         >\n-    void serialize (\n-        const type_safe_union<T1,T2,T3,T4,T5,T6,T7,T8,T9,T10, T11,T12,T13,T14,T15,T16,T17,T18,T19,T20>& item,\n+        inline typename std::enable_if<(I == sizeof...(Types))>::type deserialize_helper(\n+            std::istream&, \n+            int, \n+            type_safe_union<Types...>&\n+        )\n+        {\n+        }\n+        \n+        template<\n+            size_t I,\n+            typename... Types\n+        >\n+        inline typename std::enable_if<(I < sizeof...(Types))>::type deserialize_helper(\n+            std::istream& in, \n+            int index, \n+            type_safe_union<Types...>& x\n+        )\n+        {\n+            using T = typename internal::variant_get_type<I, Types...>::type;\n+            \n+            if (index == (I+1))\n+            {\n+                deserialize(x.template get<T>(), in);\n+            }\n+            else\n+            {\n+                deserialize_helper<I+1>(in, index, x);\n+            }\n+        }        \n+    }\n+\n+    template<typename... Types>\n+    inline void serialize (\n+        const type_safe_union<Types...>& item,\n         std::ostream& out\n     )\n     {\n         try\n         {\n-            // save the type_identity\n-            serialize(item.type_identity, out);\n-            item.apply_to_contents(dlib::impl_tsu::serialize_helper(out));\n+            serialize(item.get_current_type_id(), out);\n+            item.visit(detail::serialize_helper(out));\n         }\n         catch (serialization_error& e)\n         {\n@@ -614,66 +625,73 @@ namespace dlib\n         }\n     }\n \n-// ----------------------------------------------------------------------------------------\n-\n-    template <\n-        typename T1, typename T2, typename T3, typename T4, typename T5,\n-        typename T6, typename T7, typename T8, typename T9, typename T10,\n-        typename T11, typename T12, typename T13, typename T14, typename T15,\n-        typename T16, typename T17, typename T18, typename T19, typename T20\n-        >\n-    void deserialize (\n-        type_safe_union<T1,T2,T3,T4,T5,T6,T7,T8,T9,T10, T11,T12,T13,T14,T15,T16,T17,T18,T19,T20>&  item,\n+    template<typename... Types>\n+    inline void deserialize (\n+        type_safe_union<Types...>& item,\n         std::istream& in\n     )\n     {\n         try\n         {\n-            typedef type_safe_union<T1,T2,T3,T4,T5,T6,T7,T8,T9,T10, T11,T12,T13,T14,T15,T16,T17,T18,T19,T20> tsu_type;\n+            int index = -1;\n+            deserialize(index, in);\n \n-            int type_identity;\n-            deserialize(type_identity, in);\n-            switch (type_identity)\n-            {\n-                // swap an empty type_safe_union into item since it should be in the empty state\n-                case 0: tsu_type().swap(item); break;\n-\n-                case 1: deserialize(item.template get<T1>(), in);  break;\n-                case 2: deserialize(item.template get<T2>(), in);  break;\n-                case 3: deserialize(item.template get<T3>(), in);  break;\n-                case 4: deserialize(item.template get<T4>(), in);  break;\n-                case 5: deserialize(item.template get<T5>(), in);  break;\n-\n-                case 6: deserialize(item.template get<T6>(), in);  break;\n-                case 7: deserialize(item.template get<T7>(), in);  break;\n-                case 8: deserialize(item.template get<T8>(), in);  break;\n-                case 9: deserialize(item.template get<T9>(), in);  break;\n-                case 10: deserialize(item.template get<T10>(), in);  break;\n-\n-                case 11: deserialize(item.template get<T11>(), in);  break;\n-                case 12: deserialize(item.template get<T12>(), in);  break;\n-                case 13: deserialize(item.template get<T13>(), in);  break;\n-                case 14: deserialize(item.template get<T14>(), in);  break;\n-                case 15: deserialize(item.template get<T15>(), in);  break;\n-\n-                case 16: deserialize(item.template get<T16>(), in);  break;\n-                case 17: deserialize(item.template get<T17>(), in);  break;\n-                case 18: deserialize(item.template get<T18>(), in);  break;\n-                case 19: deserialize(item.template get<T19>(), in);  break;\n-                case 20: deserialize(item.template get<T20>(), in);  break;\n-\n-                default: throw serialization_error(\"Corrupt data detected while deserializing type_safe_union\");\n-            }\n+            if (index == 0)\n+                item.clear();\n+            else if (index > 0 && index <= (int)sizeof...(Types))\n+                detail::deserialize_helper<0>(in, index, item);\n+            else\n+                throw serialization_error(\"bad index value. Should be in range [0,sizeof...(Types))\");\n         }\n-        catch (serialization_error& e)\n+        catch(serialization_error& e)\n         {\n             throw serialization_error(e.info + \"\\n   while deserializing an object of type type_safe_union\");\n         }\n     }\n \n-// ----------------------------------------------------------------------------------------\n+    #if __cplusplus >= 201703L\n \n-}\n+    template<typename ...Base>\n+    struct overloaded_helper : Base...\n+    {\n+        template<typename... T>\n+        overloaded_helper(T&& ... t) : Base{std::forward<T>(t)}... {}\n+\n+        using Base::operator()...;\n+    };\n+\n+    #else\n \n-#endif // DLIB_TYPE_SAFE_UNIOn_h_\n+    template<typename Base, typename ... BaseRest>\n+    struct overloaded_helper: Base, overloaded_helper<BaseRest...>\n+    {\n+        template<typename T, typename ... TRest>\n+        overloaded_helper(T&& t, TRest&& ...trest) :\n+            Base{std::forward<T>(t)},\n+            overloaded_helper<BaseRest...>{std::forward<TRest>(trest)...}\n+        {}\n+\n+        using Base::operator();\n+        using overloaded_helper<BaseRest...>::operator();\n+    };\n+\n+    template<typename Base>\n+    struct overloaded_helper<Base> : Base\n+    {\n+        template<typename T>\n+        overloaded_helper<Base>(T&& t) : Base{std::forward<T>(t)}\n+        {}\n+\n+        using Base::operator();\n+    };\n+\n+    #endif //__cplusplus >= 201703L\n+\n+    template<typename... T>\n+    overloaded_helper<typename std::decay<T>::type...> overloaded(T&&... t)\n+    {\n+        return overloaded_helper<typename std::decay<T>::type...>{std::forward<T>(t)...};\n+    }\n+}\n \n+#endif // DLIB_TYPE_SAFE_UNIOn_h_\n\\ No newline at end of file\ndiff --git a/dlib/type_safe_union/type_safe_union_kernel_abstract.h b/dlib/type_safe_union/type_safe_union_kernel_abstract.h\nindex 9c8ed7c8dd..bb485ae81c 100644\n--- a/dlib/type_safe_union/type_safe_union_kernel_abstract.h\n+++ b/dlib/type_safe_union/type_safe_union_kernel_abstract.h\n@@ -3,9 +3,6 @@\n #undef DLIB_TYPE_SAFE_UNION_KERNEl_ABSTRACT_\n #ifdef DLIB_TYPE_SAFE_UNION_KERNEl_ABSTRACT_\n \n-#include \"../algs.h\"\n-#include \"../noncopyable.h\"\n-\n namespace dlib\n {\n \n@@ -21,29 +18,31 @@ namespace dlib\n \n // ----------------------------------------------------------------------------------------\n \n-    template <\n-        typename T1,\n-        typename T2 = _void,  // _void indicates parameter not used.\n-        typename T3 = _void,\n-        typename T4 = _void,\n-        typename T5 = _void, \n-        typename T6 = _void,\n-        typename T7 = _void,\n-        typename T8 = _void,\n-        typename T9 = _void,\n-        typename T10 = _void,\n-        typename T11 = _void,\n-        typename T12 = _void,\n-        typename T13 = _void,\n-        typename T14 = _void,\n-        typename T15 = _void,\n-        typename T16 = _void,\n-        typename T17 = _void,\n-        typename T18 = _void,\n-        typename T19 = _void,\n-        typename T20 = _void\n-        >\n-    class type_safe_union : noncopyable\n+    template<typename T>\n+    struct in_place_tag {};\n+    /*!\n+        This is an empty class type used as a special disambiguation tag to be\n+        passed as the first argument to the constructor of type_safe_union that performs\n+        in-place construction of an object.\n+\n+        Here is an example of its usage:\n+\n+        struct A\n+        {\n+            int i = 0;\n+            int j = 0;\n+\n+            A(int i_, int j_) : i(i_), j(j_) {}\n+        };\n+\n+        using tsu = type_safe_union<A,std::string>;\n+\n+        tsu a(in_place_tag<A>{}, 0, 1);\n+    !*/\n+// ----------------------------------------------------------------------------------------\n+\n+    template <typename... Types>\n+    class type_safe_union\n     {\n         /*!\n             REQUIREMENTS ON ALL TEMPLATE ARGUMENTS\n@@ -71,55 +70,93 @@ namespace dlib\n \n     public:\n \n-        typedef T1 type1;\n-        typedef T2 type2;\n-        typedef T3 type3;\n-        typedef T4 type4;\n-        typedef T5 type5;\n-        typedef T6 type6;\n-        typedef T7 type7;\n-        typedef T8 type8;\n-        typedef T9 type9;\n-        typedef T10 type10;\n-        typedef T11 type11;\n-        typedef T12 type12;\n-        typedef T13 type13;\n-        typedef T14 type14;\n-        typedef T15 type15;\n-        typedef T16 type16;\n-        typedef T17 type17;\n-        typedef T18 type18;\n-        typedef T19 type19;\n-        typedef T20 type20;\n-\n         type_safe_union(\n-        );\n+        ) = default;\n         /*!\n             ensures\n                 - this object is properly initialized\n         !*/\n \n-        template <typename T>\n         type_safe_union (\n-            T&& item\n+            const type_safe_union& item\n+        )\n+        /*!\n+            ensures\n+                - copy constructs *this from item\n+        !*/\n+\n+        type_safe_union& operator=(\n+            const type_safe_union& item\n         );\n         /*!\n-            requires\n-                - T must be one of the types given to this object's template arguments\n             ensures\n-                - this object is properly initialized\n-                - #get<T>() == item\n-                  (i.e. this object will contain a copy of item, or we move item if it's an rvalue)\n+                - copy assigns *this from item\n         !*/\n \n         type_safe_union (\n             type_safe_union&& item\n-        ); \n+        );\n         /*!\n             ensures\n                 - move constructs *this from item.\n         !*/\n \n+        type_safe_union& operator= (\n+            type_safe_union&& item\n+        );\n+        /*!\n+            ensures\n+                - move assigns *this from item.\n+        !*/\n+\n+        template <\n+            typename T\n+        >\n+        type_safe_union (\n+            T&& item\n+        );\n+        /*!\n+            requires\n+                - std::decay_t<T> must be one of the types given to this object's template arguments\n+            ensures\n+                - constructs *this from item using perfect forwarding (converting constructor)\n+                - #get<T>() == std::forward<T>(item)\n+                  (i.e. this object will either contain a copy of item or will have moved item into *this\n+                   depending on the reference type)\n+        !*/\n+\n+        template <\n+            typename T\n+        >\n+        type_safe_union& operator= (\n+            T&& item\n+        );\n+        /*!\n+            requires\n+                - std::decay_t<T> must be one of the types given to this object's template arguments\n+            ensures\n+                - assigns *this from item using perfect forwarding (converting assignment)\n+                - #get<T> == std::forward<T>(item)\n+                  (i.e. this object will either contain a copy of item or will have moved item into *this\n+                   depending on the reference type)\n+        !*/\n+\n+        template <\n+            typename T,\n+            typename... Args\n+        >\n+        type_safe_union (\n+            in_place_tag<T>,\n+            Args&&... args\n+        );\n+        /*!\n+            requires\n+                - T must be one of the types given to this object's template arguments\n+            ensures\n+                - constructs *this with type T using constructor-arguments args...\n+                  (i.e. efficiently performs *this = T(args...))\n+        !*/\n+\n         ~type_safe_union(\n         );\n         /*!\n@@ -127,14 +164,36 @@ namespace dlib\n                 - all resources associated with this object have been freed\n         !*/\n \n+        void clear();\n+        /*!\n+            ensures\n+                - all resources associated with this object have been freed\n+                - #is_empty() == true\n+        !*/\n+\n+        template <\n+            typename T,\n+            typename... Args\n+        >\n+        void emplace(\n+            Args&&... args\n+        );\n+        /*!\n+            requires\n+                - T must be one of the types given to this object's template arguments\n+            ensures\n+                - re-assigns *this with type T using constructor-arguments args...\n+                  (i.e. efficiently performs *this = T(args...))\n+        !*/\n+\n         template <typename T>\n-        static int get_type_id (\n+        static constexpr int get_type_id (\n         );\n         /*!\n            ensures\n               - if (T is the same type as one of the template arguments) then\n-                 - returns a number indicating which template argument it is.\n-                   (e.g. if T is the same type as T3 then this function returns 3)\n+                 - returns a number indicating which template argument it is. In particular,\n+                   if it's the first template argument it returns 1, if the second then 2, and so on.\n                - else\n                   - returns -1\n         !*/\n@@ -160,68 +219,64 @@ namespace dlib\n                     - returns false\n         !*/\n \n-        template <typename T>\n-        void apply_to_contents (\n-            T& obj\n-        );\n+        int get_current_type_id(\n+        ) const;\n         /*!\n-            requires\n-                - obj is a function object capable of operating on all the types contained\n-                  in this type_safe_union.  I.e.  obj(this->get<U>()) must be a valid\n-                  expression for all the possible U types.\n             ensures\n-                - if (is_empty() == false) then\n-                    - Let U denote the type of object currently contained in this type_safe_union\n-                    - calls obj(this->get<U>())\n-                    - The object returned by this->get<U>() will be non-const\n+                - returns type_identity, i.e, the index of the currently held type.\n+                  For example if the current type is the first template argument it returns 1, if it's the second then 2, and so on.\n+                  If the current object is empty, i.e. is_empty() == true, then\n+                    - returns 0\n         !*/\n \n-        template <typename T>\n-        void apply_to_contents (\n-            const T& obj\n+        template <typename F>\n+        auto visit(\n+            F&& f\n         );\n         /*!\n             requires\n-                - obj is a function object capable of operating on all the types contained\n-                  in this type_safe_union.  I.e.  obj(this->get<U>()) must be a valid\n+                - f is a callable object capable of operating on all the types contained\n+                  in this type_safe_union.  I.e.  std::forward<F>(f)(this->get<U>()) must be a valid\n                   expression for all the possible U types.\n             ensures\n                 - if (is_empty() == false) then\n                     - Let U denote the type of object currently contained in this type_safe_union\n-                    - calls obj(this->get<U>())\n-                    - The object returned by this->get<U>() will be non-const\n+                    - returns std::forward<F>(f)(this->get<U>())\n+                    - The object passed to f() (i.e. by this->get<U>()) will be non-const.\n         !*/\n \n-        template <typename T>\n-        void apply_to_contents (\n-            T& obj\n+        template <typename F>\n+        auto visit(\n+            F&& f\n         ) const;\n         /*!\n             requires\n-                - obj is a function object capable of operating on all the types contained\n-                  in this type_safe_union.  I.e.  obj(this->get<U>()) must be a valid\n+                - f is a callable object capable of operating on all the types contained\n+                  in this type_safe_union.  I.e.  std::forward<F>(f)(this->get<U>()) must be a valid\n                   expression for all the possible U types.\n             ensures\n                 - if (is_empty() == false) then\n                     - Let U denote the type of object currently contained in this type_safe_union\n-                    - calls obj(this->get<U>())\n-                    - The object returned by this->get<U>() will be const\n+                    - returns std::forward<F>(f)(this->get<U>())\n+                    - The object passed to f() (i.e. by this->get<U>()) will be const.\n         !*/\n \n-        template <typename T>\n-        void apply_to_contents (\n-            const T& obj\n+        template <typename F>\n+        void apply_to_contents(\n+            F&& f\n+        );\n+        /*!\n+            ensures:\n+                equivalent to calling visit(std::forward<F>(f)) with void return type\n+        !*/\n+\n+        template <typename F>\n+        void apply_to_contents(\n+            F&& f\n         ) const;\n         /*!\n-            requires\n-                - obj is a function object capable of operating on all the types contained\n-                  in this type_safe_union.  I.e.  obj(this->get<U>()) must be a valid\n-                  expression for all the possible U types.\n-            ensures\n-                - if (is_empty() == false) then\n-                    - Let U denote the type of object currently contained in this type_safe_union\n-                    - calls obj(this->get<U>())\n-                    - The object returned by this->get<U>() will be const\n+            ensures:\n+                equivalent to calling visit(std::forward<F>(f)) with void return type\n         !*/\n \n         template <typename T> \n@@ -268,28 +323,6 @@ namespace dlib\n                     - throws bad_type_safe_union_cast\n         !*/\n \n-        template <typename T>\n-        type_safe_union& operator= (\n-            T&& item\n-        );\n-        /*!\n-            requires\n-                - T must be one of the types given to this object's template arguments\n-            ensures\n-                - #get<T>() == item\n-                  (i.e. this object will contain a copy of item, or we move item if it's an rvalue)\n-                - returns *this\n-        !*/\n-\n-        type_safe_union& operator= (\n-            type_safe_union&& item\n-        ); \n-        /*!\n-            ensures\n-                - Allows moving item into *this.  In fact, this is done by this->swap(item).\n-                - returns *this\n-        !*/\n-\n         void swap (\n             type_safe_union& item\n         );\n@@ -340,7 +373,51 @@ namespace dlib\n \n // ----------------------------------------------------------------------------------------\n \n+    template<typename... T>\n+    overloaded_helper<typename std::decay<T>::type...> overloaded(T&&... t)\n+    {\n+        return overloaded_helper<typename std::decay<T>::type...>{std::forward<T>(t)...};\n+    }\n+    /*!\n+        This is a helper function for passing many callable objects (usually lambdas)\n+        to either apply_to_contents() or visit(), that combine to make a complete\n+        visitor. A picture paints a thousand words:\n+\n+        using tsu = type_safe_union<int,float,std::string>;\n+\n+        tsu a = std::string(\"hello there\");\n+\n+        std::string result;\n+\n+        a.apply_to_contents(overloaded(\n+            [&result](int) {\n+                result = std::string(\"int\");\n+            },\n+            [&result](float) {\n+                result = std::string(\"float\");\n+            },\n+            [&result](const std::string& item) {\n+                result = item;\n+            }\n+        ));\n+\n+        assert(result == \"hello there\");\n+        result = \"\";\n+\n+        result = a.visit(overloaded(\n+            [](int) {\n+                return std::string(\"int\");\n+            },\n+            [](float) {\n+                return std::string(\"float\");\n+            },\n+            [](const std::string& item) {\n+                return item;\n+            }\n+        ));\n+\n+        assert(result == \"hello there\");\n+    !*/\n }\n \n #endif // DLIB_TYPE_SAFE_UNION_KERNEl_ABSTRACT_\n-\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Exception Handling:** Current design of `type_safe_union` does not handle exceptions in constructors. Consider implementing exception handling similar to `std::variant` for consistency. We need to explicitly decide on this.\n\n2. **Move Semantics:** Using `swap()` in move semantics may lead to inefficiencies. A breaking change could impact current clients; ensure release notes clarify any behavioral changes. Clients should use `swap()` explicitly if desired.\n\n3. **Documentation for `apply_to_contents()`:** Add documentation indicating that it supports private `operator()` functions if `type_safe_union` is a friend type. Clarify that `visit()` uses `std::result_of`, impacting its behavior with friend types.\n\n4. **Code Refactoring:** Refactored constructors/assignment operators to use universal references for improved code efficiency. Confirm acceptance of this change."
      }
    ],
    "codediff_length": 63747
  },
  {
    "index": 68,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/dlib/algs.h b/dlib/algs.h\nindex b6af983c1b..1a5038d5de 100644\n--- a/dlib/algs.h\n+++ b/dlib/algs.h\n@@ -370,7 +370,7 @@ namespace dlib\n         and the fact that this has a different name (global swap has the same name as\n         the member functions called swap) makes them compile right.\n \n-        So this is a workaround but not too ugly of one.  But hopefully I get get\n+        So this is a workaround but not too ugly of one.  But hopefully I can get\n         rid of this in a few years.  So this function is already deprecated. \n \n         This also means you should NOT use this function in your own code unless\ndiff --git a/dlib/array2d/array2d_kernel.h b/dlib/array2d/array2d_kernel.h\nindex c84cf936c1..b4736ed18e 100644\n--- a/dlib/array2d/array2d_kernel.h\n+++ b/dlib/array2d/array2d_kernel.h\n@@ -117,14 +117,16 @@ namespace dlib\n         private:\n \n             row(T* data_, long cols) : data(data_), nc_(cols) {}\n+            row(row&& r) = default;\n+            row& operator=(row&& r) = default;\n \n-            T* data; \n-            long nc_;\n+            T* data = nullptr;\n+            long nc_ = 0;\n \n \n             // restricted functions\n-            row(){}\n-            row& operator=(row&);\n+            row(const row&) = delete;\n+            row& operator=(const row&) = delete;\n         };\n \n         // -----------------------------------\ndiff --git a/dlib/bayes_utils/bayes_utils.h b/dlib/bayes_utils/bayes_utils.h\nindex 04b3d11876..c5ebc19b92 100644\n--- a/dlib/bayes_utils/bayes_utils.h\n+++ b/dlib/bayes_utils/bayes_utils.h\n@@ -1518,7 +1518,6 @@ namespace dlib\n \n \n                 bool message_sent = true;\n-                std::vector<unsigned long>::iterator iter;\n                 while (message_sent)\n                 {\n                     message_sent = false;\ndiff --git a/dlib/crc32/crc32_kernel_1.h b/dlib/crc32/crc32_kernel_1.h\nindex 4c679d2f29..16e5fc7d02 100644\n--- a/dlib/crc32/crc32_kernel_1.h\n+++ b/dlib/crc32/crc32_kernel_1.h\n@@ -26,10 +26,10 @@ namespace dlib\n         // this is here for backwards compatibility with older versions of dlib.\n         typedef crc32 kernel_1a;\n \n-        inline crc32 (        \n+        inline crc32 (\n         );\n \n-        inline crc32 (        \n+        inline crc32 (\n             const std::string& item\n         );\n \n@@ -65,10 +65,6 @@ namespace dlib\n             crc32& item\n         );\n \n-        inline crc32& operator=(\n-            const crc32&\n-        );  \n-\n     private:\n \n         unsigned long checksum;\n@@ -147,7 +143,7 @@ namespace dlib\n // ----------------------------------------------------------------------------------------\n \n     crc32::\n-    crc32 (        \n+    crc32 (\n     )\n     {\n         checksum = 0xFFFFFFFF;\n@@ -243,17 +239,6 @@ namespace dlib\n         exchange(checksum,item.checksum);\n     }\n \n-// ----------------------------------------------------------------------------------------\n-\n-    crc32& crc32::\n-    operator=(\n-        const crc32& item\n-    )\n-    {\n-        checksum = item.checksum;\n-        return *this;\n-    }\n-\n // ----------------------------------------------------------------------------------------\n \n }\ndiff --git a/dlib/crc32/crc32_kernel_abstract.h b/dlib/crc32/crc32_kernel_abstract.h\nindex 76da49fbc0..f80a694e3a 100644\n--- a/dlib/crc32/crc32_kernel_abstract.h\n+++ b/dlib/crc32/crc32_kernel_abstract.h\n@@ -31,7 +31,7 @@ namespace dlib\n                 - #*this is properly initialized\n         !*/\n \n-        crc32 (        \n+        crc32 (\n             const std::string& item\n         );\n         /*!\ndiff --git a/dlib/cuda/cpu_dlib.cpp b/dlib/cuda/cpu_dlib.cpp\nindex 2d8e1e453a..60bac3b6a8 100644\n--- a/dlib/cuda/cpu_dlib.cpp\n+++ b/dlib/cuda/cpu_dlib.cpp\n@@ -2424,7 +2424,7 @@ namespace dlib\n             float* t = &output(0,0);\n \n             // now fill in the Toeplitz output matrix for the n-th sample in data.  \n-            size_t cnt = 0;\n+            long cnt = 0;\n             const long max_r = data.nr() + padding_y-(filter_nr-1);\n             const long max_c = data.nc() + padding_x-(filter_nc-1);\n             for (long r = -padding_y; r < max_r; r+=stride_y)\ndiff --git a/dlib/dnn/core.h b/dlib/dnn/core.h\nindex 15424c76c3..bfc41cd962 100644\n--- a/dlib/dnn/core.h\n+++ b/dlib/dnn/core.h\n@@ -2259,7 +2259,7 @@ namespace dlib\n         void back_propagate_error(\n             const tensor& /*x*/,\n             const tensor& /*gradient_input*/,\n-            zero_gradients zero_grads = zero_gradients::yes\n+            zero_gradients /*zero_grads*/ = zero_gradients::yes\n         )\n         {\n             // nothing to do\n@@ -3746,7 +3746,7 @@ namespace dlib\n                 typename visitor\n                 >\n             static void visit(\n-                net_type& net,\n+                net_type&,\n                 const add_tag_layer<tag_id,SUBNET>& next_net,\n                 visitor&& v\n             )\n@@ -3760,7 +3760,7 @@ namespace dlib\n                 typename visitor\n                 >\n             static void visit(\n-                net_type& net,\n+                net_type&,\n                 add_tag_layer<tag_id,SUBNET>& next_net,\n                 visitor&& v\n             )\ndiff --git a/dlib/dnn/input.h b/dlib/dnn/input.h\nindex 80204a7e84..075ac2bc34 100644\n--- a/dlib/dnn/input.h\n+++ b/dlib/dnn/input.h\n@@ -476,7 +476,6 @@ namespace dlib\n         typedef matrix<T,NR,NC,MM,L> input_type;\n \n         input() {}\n-        input(const input&) {}\n \n         template <typename mm>\n         input(const input<array2d<T,mm>>&) {}\n@@ -728,25 +727,25 @@ namespace dlib\n \n         }\n \n-        friend void serialize(const input& item, std::ostream& out)\n+        friend void serialize(const input&, std::ostream& out)\n         {\n             serialize(\"input<array2d>\", out);\n         }\n \n-        friend void deserialize(input& item, std::istream& in)\n+        friend void deserialize(input&, std::istream& in)\n         {\n             std::string version;\n             deserialize(version, in);\n             if (version != \"input<array2d>\")\n                 throw serialization_error(\"Unexpected version found while deserializing dlib::input.\");\n         }\n-        friend std::ostream& operator<<(std::ostream& out, const input& item)\n+        friend std::ostream& operator<<(std::ostream& out, const input&)\n         {\n             out << \"input<array2d>\";\n             return out;\n         }\n \n-        friend void to_xml(const input& item, std::ostream& out)\n+        friend void to_xml(const input&, std::ostream& out)\n         {\n             out << \"<input/>\";\n         }\ndiff --git a/dlib/dnn/visitors.h b/dlib/dnn/visitors.h\nindex 5b37a71b0d..b3b892310d 100644\n--- a/dlib/dnn/visitors.h\n+++ b/dlib/dnn/visitors.h\n@@ -552,7 +552,7 @@ namespace dlib\n             visitor_net_to_dot(std::ostream& out) : out(out) {}\n \n             template <typename input_layer_type>\n-            void operator()(size_t i, input_layer_type& l)\n+            void operator()(size_t i, input_layer_type&)\n             {\n                 start_node(i, \"input\");\n                 end_node();\n@@ -609,7 +609,7 @@ namespace dlib\n             }\n \n             template <template <typename> class TAG, typename U>\n-            void operator()(size_t i, const add_skip_layer<TAG, U>&)\n+            void operator()(size_t, const add_skip_layer<TAG, U>&)\n             {\n                 const auto t = tag_id<TAG>::id;\n                 from = tag_to_layer.at(t);\n@@ -877,7 +877,7 @@ namespace dlib\n             }\n \n             template <template <typename> class... TAGS, typename U, typename E>\n-            void operator()(size_t i, const add_layer<concat_<TAGS...>, U, E>& l)\n+            void operator()(size_t i, const add_layer<concat_<TAGS...>, U, E>&)\n             {\n                 start_node(i, \"concat\");\n                 end_node();\n@@ -920,7 +920,7 @@ namespace dlib\n             }\n \n             template <typename T, typename U, typename E>\n-            void operator()(size_t i, const add_layer<T, U, E>& l)\n+            void operator()(size_t i, const add_layer<T, U, E>&)\n             {\n                 start_node(i, \"unhandled layer\");\n                 update(i);\ndiff --git a/dlib/geometry/rectangle.h b/dlib/geometry/rectangle.h\nindex 35f89eceec..ef128fea19 100644\n--- a/dlib/geometry/rectangle.h\n+++ b/dlib/geometry/rectangle.h\n@@ -750,7 +750,7 @@ namespace dlib\n \n     // Circumvent what appears to be a bug in Visual Studio 2019's optimizer\n     // (see: https://forum.juce.com/t/warning-in-the-lastest-vs2019/38267)\n-#if defined (_MSVC_VER)\n+#if defined (_MSC_VER)\n #pragma warning ( push )\n #pragma warning ( disable: 4723 )\n #endif\n@@ -774,7 +774,7 @@ namespace dlib\n             return centered_rect(rect, (long)std::round(rect.width()*scale), (long)std::round(rect.height()*scale));\n         }\n     }\n-#if defined (_MSVC_VER)\n+#if defined (_MSC_VER)\n #pragma warning ( pop )\n #endif\n \ndiff --git a/dlib/interfaces/map_pair.h b/dlib/interfaces/map_pair.h\nindex 64310152eb..af1b07c471 100644\n--- a/dlib/interfaces/map_pair.h\n+++ b/dlib/interfaces/map_pair.h\n@@ -31,6 +31,9 @@ namespace dlib\n         typedef T1 key_type;\n         typedef T2 value_type;\n \n+        map_pair() = default;\n+        map_pair(const map_pair&) = default;\n+\n         virtual ~map_pair(\n         )=0;\n \ndiff --git a/dlib/pixel.h b/dlib/pixel.h\nindex c189bae142..42b50b2cd4 100644\n--- a/dlib/pixel.h\n+++ b/dlib/pixel.h\n@@ -710,6 +710,12 @@ namespace dlib\n         }\n     // -----------------------------\n \n+        // Apparently Visual Studio's optimizer complains about branches that would not be taken anyway.\n+#if defined (_MSC_VER)\n+#pragma warning ( push )\n+#pragma warning ( disable: 4756 )\n+#endif\n+\n         template < typename P1, typename P2 >\n         typename enable_if_c<pixel_traits<P1>::grayscale && pixel_traits<P2>::grayscale>::type\n         assign(P1& dest, const P2& src) \n@@ -728,6 +734,10 @@ namespace dlib\n                 dest = pixel_traits<P1>::max();\n         }\n \n+#if defined (_MSC_VER)\n+#pragma warning ( pop )\n+#endif\n+\n     // -----------------------------\n     // -----------------------------\n     // -----------------------------\ndiff --git a/dlib/static_map/static_map_kernel_1.h b/dlib/static_map/static_map_kernel_1.h\nindex a7b627ae62..80cff2ee11 100644\n--- a/dlib/static_map/static_map_kernel_1.h\n+++ b/dlib/static_map/static_map_kernel_1.h\n@@ -47,12 +47,12 @@ namespace dlib\n                 - if (current_element_valid()) then\n                     - element() == mp\n         !*/\n-        \n+       \n         class mpair : public map_pair<domain,range>\n         {\n         public:\n-            const domain* d;\n-            range* r;\n+            const domain* d = nullptr;\n+            range* r = nullptr;\n \n             const domain& key( \n             ) const { return *d; }\ndiff --git a/dlib/svm/assignment_function.h b/dlib/svm/assignment_function.h\nindex fdacb2c177..e486cfb6c4 100644\n--- a/dlib/svm/assignment_function.h\n+++ b/dlib/svm/assignment_function.h\n@@ -154,7 +154,7 @@ namespace dlib\n             {\n                 // max_cost_assignment() only works with integer matrices, so convert from\n                 // double to integer.\n-                const double scale = (std::numeric_limits<dlib::int64>::max()/1000)/max(abs(cost));\n+                const double scale = static_cast<double>(std::numeric_limits<dlib::int64>::max())/1000/max(abs(cost));\n                 matrix<dlib::int64> int_cost = matrix_cast<dlib::int64>(round(cost*scale));\n                 assignment = max_cost_assignment(int_cost);\n                 assignment.resize(lhs.size());\ndiff --git a/dlib/svm/function.h b/dlib/svm/function.h\nindex f5a62a9f71..9d6ab1e58b 100644\n--- a/dlib/svm/function.h\n+++ b/dlib/svm/function.h\n@@ -43,15 +43,6 @@ namespace dlib\n         decision_function (\n         ) : b(0), kernel_function(K()) {}\n \n-        decision_function (\n-            const decision_function& d\n-        ) : \n-            alpha(d.alpha), \n-            b(d.b),\n-            kernel_function(d.kernel_function),\n-            basis_vectors(d.basis_vectors) \n-        {}\n-\n         decision_function (\n             const scalar_vector_type& alpha_,\n             const scalar_type& b_,\n@@ -137,14 +128,6 @@ namespace dlib\n         probabilistic_function (\n         ) : alpha(0), beta(0), decision_funct(function_type()) {}\n \n-        probabilistic_function (\n-            const probabilistic_function& d\n-        ) : \n-            alpha(d.alpha),\n-            beta(d.beta),\n-            decision_funct(d.decision_funct)\n-        {}\n-\n         probabilistic_function (\n             const scalar_type a_,\n             const scalar_type b_,\n@@ -232,14 +215,6 @@ namespace dlib\n             decision_funct(d.decision_funct)\n         {}\n \n-        probabilistic_decision_function (\n-            const probabilistic_decision_function& d\n-        ) : \n-            alpha(d.alpha),\n-            beta(d.beta),\n-            decision_funct(d.decision_funct)\n-        {}\n-\n         probabilistic_decision_function (\n             const scalar_type a_,\n             const scalar_type b_,\n@@ -353,16 +328,6 @@ namespace dlib\n                 );\n         }\n \n-        distance_function (\n-            const distance_function& d\n-        ) : \n-            alpha(d.alpha), \n-            b(d.b),\n-            kernel_function(d.kernel_function),\n-            basis_vectors(d.basis_vectors) \n-        {\n-        }\n-\n         distance_function (\n             const scalar_vector_type& alpha_,\n             const scalar_type& b_,\n@@ -586,13 +551,6 @@ namespace dlib\n         normalized_function (\n         ){}\n \n-        normalized_function (\n-            const normalized_function& f\n-        ) :\n-            normalizer(f.normalizer),\n-            function(f.function)\n-        {}\n-\n         const std::vector<result_type> get_labels(\n         ) const { return function.get_labels(); }\n \n@@ -673,10 +631,6 @@ namespace dlib\n         projection_function (\n         ) {}\n \n-        projection_function (\n-            const projection_function& f\n-        ) : weights(f.weights), kernel_function(f.kernel_function), basis_vectors(f.basis_vectors) {}\n-\n         projection_function (\n             const scalar_matrix_type& weights_,\n             const K& kernel_function_,\ndiff --git a/dlib/svm/function_abstract.h b/dlib/svm/function_abstract.h\nindex 783a68c50e..3656059373 100644\n--- a/dlib/svm/function_abstract.h\n+++ b/dlib/svm/function_abstract.h\n@@ -64,14 +64,6 @@ namespace dlib\n                 - #basis_vectors.nr() == 0\n         !*/\n \n-        decision_function (\n-            const decision_function& f\n-        );\n-        /*!\n-            ensures\n-                - #*this is a copy of f\n-        !*/\n-\n         decision_function (\n             const scalar_vector_type& alpha_,\n             const scalar_type& b_,\n@@ -169,14 +161,6 @@ namespace dlib\n                 - #decision_funct has its initial value\n         !*/\n \n-        probabilistic_function (\n-            const probabilistic_function& f\n-        );\n-        /*!\n-            ensures\n-                - #*this is a copy of f\n-        !*/\n-\n         probabilistic_function (\n             const scalar_type a,\n             const scalar_type b,\n@@ -282,15 +266,7 @@ namespace dlib\n         !*/\n \n         probabilistic_decision_function (\n-            const probabilistic_decision_function& f\n-        );\n-        /*!\n-            ensures\n-                - #*this is a copy of f\n-        !*/\n-\n-        probabilistic_decision_function (\n-            const probabilistic_function<decision_function<K> >& d\n+            const probabilistic_function<decision_function<K> >& f\n         );\n         /*!\n             ensures\n@@ -445,17 +421,6 @@ namespace dlib\n                     - #get_basis_vectors() == f.basis_vectors\n         !*/\n \n-        distance_function (\n-            const distance_function& f\n-        );\n-        /*!\n-            requires\n-                - f is a valid distance_function.  In particular, this means that\n-                  f.alpha.size() == f.basis_vectors.size()\n-            ensures\n-                - #*this is a copy of f\n-        !*/\n-\n         distance_function (\n             const scalar_vector_type& alpha,\n             const scalar_type& squared_norm,\n@@ -679,14 +644,6 @@ namespace dlib\n                 - the members of this object have their default values\n         !*/\n \n-        normalized_function (\n-            const normalized_function& f\n-        );\n-        /*!\n-            ensures\n-                - #*this is a copy of f\n-        !*/\n-\n         normalized_function (\n             const vector_normalizer<sample_type>& normalizer_,\n             const function_type& funct \n@@ -791,14 +748,6 @@ namespace dlib\n                 - #basis_vectors.size() == 0\n         !*/\n \n-        projection_function (\n-            const projection_function& f\n-        );\n-        /*!\n-            ensures\n-                - #*this is a copy of f\n-        !*/\n-\n         projection_function (\n             const scalar_matrix_type& weights_,\n             const K& kernel_function_,\ndiff --git a/dlib/svm/pegasos.h b/dlib/svm/pegasos.h\nindex 8dc2fb0a57..60e79862f0 100644\n--- a/dlib/svm/pegasos.h\n+++ b/dlib/svm/pegasos.h\n@@ -655,7 +655,7 @@ namespace dlib\n \n         trainer_type trainer;\n         scalar_type min_learning_rate;\n-        bool verbose;\n+        bool verbose = true;\n         bool use_cache;\n         long cache_size;\n \ndiff --git a/dlib/svm/structural_svm_assignment_problem.h b/dlib/svm/structural_svm_assignment_problem.h\nindex 963af16318..2998f1a6f6 100644\n--- a/dlib/svm/structural_svm_assignment_problem.h\n+++ b/dlib/svm/structural_svm_assignment_problem.h\n@@ -247,7 +247,7 @@ namespace dlib\n             {\n                 // max_cost_assignment() only works with integer matrices, so convert from\n                 // double to integer.\n-                const double scale = (std::numeric_limits<dlib::int64>::max()/1000)/max(abs(cost));\n+                const double scale = static_cast<double>(std::numeric_limits<dlib::int64>::max())/1000/max(abs(cost));\n                 matrix<dlib::int64> int_cost = matrix_cast<dlib::int64>(round(cost*scale));\n                 assignment = max_cost_assignment(int_cost);\n                 assignment.resize(samples[idx].first.size());\ndiff --git a/dlib/test/CMakeLists.txt b/dlib/test/CMakeLists.txt\nindex 47a71a1b22..895a07adc7 100644\n--- a/dlib/test/CMakeLists.txt\n+++ b/dlib/test/CMakeLists.txt\n@@ -166,13 +166,22 @@ set (tests\n # cmake that they are part of our target (which is the executable named dtest)\n ADD_EXECUTABLE(${target_name} main.cpp tester.cpp ${tests})\n \n-# Turn on all warnings when using gcc.\n if (CMAKE_COMPILER_IS_GNUCXX)\n-   add_definitions(\"-W -Wall\")\n+   # Turn on all warnings, and treat them as errors.\n+   add_definitions(\"-W -Wall -Wextra -Werror\")\n    # I don't care about unused testing functions though.  I like to keep them\n    # around.  Don't warn about it.\n    add_definitions(\"-Wno-unused-function\")\n    add_definitions(\"-Wno-strict-overflow\")\n+   add_definitions(\"-Wno-maybe-uninitialized\")\n+elseif (MSVC)\n+   # Treat warnings as errors.\n+   add_definitions(\"/WX\")\n+else() # basically Clang\n+   # Treat warnings as errors, but do not turn on all warnings.\n+   add_definitions(\"-W -Werror\")\n+   # This is for the comment in face_detection_ex.cpp that says \"faces/*.jpg\"\n+   add_definitions(\"-Wno-comment\")\n endif()\n \n \n@@ -181,6 +190,12 @@ TARGET_LINK_LIBRARIES(${target_name} dlib::dlib )\n \n if (NOT DLIB_NO_GUI_SUPPORT)\n    add_subdirectory(gui)\n-   add_subdirectory(examples)\n    add_subdirectory(tools)\n+\n+   if (CMAKE_COMPILER_IS_GNUCXX)\n+      # The tutorials set some variables that are not used.\n+      add_definitions(\"-Wno-unused-but-set-variable\")\n+   endif()\n+\n+   add_subdirectory(examples)\n endif()\ndiff --git a/dlib/test/compress_stream.cpp b/dlib/test/compress_stream.cpp\nindex 6f0cbc6058..be6e46440e 100644\n--- a/dlib/test/compress_stream.cpp\n+++ b/dlib/test/compress_stream.cpp\n@@ -75,7 +75,7 @@ namespace\n             bool detected_error = false;\n             try {\n                 test.decompress(sin,sout);\n-            } catch ( typename cs::decompression_error& e )\n+            } catch ( typename cs::decompression_error& )\n             {\n                 detected_error = true;\n                 ++count;\ndiff --git a/dlib/test/geometry.cpp b/dlib/test/geometry.cpp\nindex 7519220ea0..f6781e0252 100644\n--- a/dlib/test/geometry.cpp\n+++ b/dlib/test/geometry.cpp\n@@ -367,6 +367,19 @@ namespace\n             }\n         }\n \n+        {\n+            const rectangle input(1,1,6,4); \n+            const rectangle output = set_rect_area(input,4*input.area());\n+            DLIB_TEST(output.area() == 4*input.area());\n+            DLIB_TEST(output.width() == 2*input.width());\n+            DLIB_TEST(output.height() == 2*input.height());\n+\n+            const auto input_center = center(input);\n+            const auto output_center = center(output);\n+            DLIB_TEST(std::abs(input_center.x() - output_center.x()) <= 1);\n+            DLIB_TEST(std::abs(input_center.y() - output_center.y()) <= 1);\n+        }\n+\n     }\n \n // ----------------------------------------------------------------------------------------\ndiff --git a/dlib/test/gui/main.cpp b/dlib/test/gui/main.cpp\nindex d61aba8c02..268444bfda 100644\n--- a/dlib/test/gui/main.cpp\n+++ b/dlib/test/gui/main.cpp\n@@ -411,7 +411,6 @@ class win : public drawable_window\n         group1(*this),\n         group2(*this),\n         group3(*this),\n-        keyboard_count(1),\n         keydown(*this),\n         keyup(*this),\n         l1(*this),\n@@ -759,7 +758,6 @@ class win : public drawable_window\n     widget_group group1;\n     widget_group group2;\n     widget_group group3;\n-    int keyboard_count;\n     label keydown;\n     label keyup;\n     label l1;\ndiff --git a/dlib/test/invoke.cpp b/dlib/test/invoke.cpp\nindex 02c36f0304..c63baebeae 100644\n--- a/dlib/test/invoke.cpp\n+++ b/dlib/test/invoke.cpp\n@@ -323,6 +323,9 @@ namespace\n         static_assert(dlib::invoke(multiply_ints, 2, 5) == 10, \"this should be constexpr\");\n         static_assert(dlib::invoke_r<long>(multiply_ints, 2, 5) == 10, \"this should be constexpr\");\n         constexpr constexpr_object constexpr_obj;\n+#if defined (_MSC_VER)\n+        constexpr_obj; // avoid warning C4101: 'constexpr_obj': unreferenced local variable\n+#endif\n         static_assert(dlib::invoke(&constexpr_object::multiply_ints, constexpr_obj, 2, 5) == 10, \"this should be constexpr\");\n         static_assert(dlib::invoke_r<long>(&constexpr_object::multiply_ints, constexpr_obj, 2, 5) == 10, \"this should be constexpr\");\n     }\ndiff --git a/dlib/unordered_pair.h b/dlib/unordered_pair.h\nindex 9ea75b9128..1043278968 100644\n--- a/dlib/unordered_pair.h\n+++ b/dlib/unordered_pair.h\n@@ -65,6 +65,14 @@ namespace dlib\n                 - #first and #second contain copies of the items a and b.\n         !*/ {}\n \n+        unordered_pair (\n+            const unordered_pair& p\n+        ) = default;\n+        /*!\n+            ensures\n+                - #*this is a copy of p\n+        !*/\n+\n         template <typename U>\n         unordered_pair (\n             const unordered_pair <U>& p\ndiff --git a/examples/dnn_instance_segmentation_train_ex.cpp b/examples/dnn_instance_segmentation_train_ex.cpp\nindex e472dfa00c..18ce7be349 100644\n--- a/examples/dnn_instance_segmentation_train_ex.cpp\n+++ b/examples/dnn_instance_segmentation_train_ex.cpp\n@@ -29,9 +29,6 @@\n #include <dlib/dir_nav.h>\n #include <iterator>\n #include <thread>\n-#if __cplusplus >= 201703L || (defined(_MSVC_LANG) && _MSVC_LANG >= 201703L)\n-#include <execution>\n-#endif // __cplusplus >= 201703L\n \n using namespace std;\n using namespace dlib;\n@@ -555,14 +552,13 @@ std::vector<std::vector<truth_instance>> load_all_truth_instances(const std::vec\n {\n     std::vector<std::vector<truth_instance>> truth_instances(listing.size());\n \n-    std::transform(\n-#if __cplusplus >= 201703L || (defined(_MSVC_LANG) && _MSVC_LANG >= 201703L)\n-        std::execution::par,\n-#endif // __cplusplus >= 201703L\n-        listing.begin(),\n-        listing.end(),\n-        truth_instances.begin(),\n-        load_truth_instances\n+    parallel_for(\n+        0,\n+        listing.size(),\n+        [&](size_t index)\n+        {\n+            truth_instances[index] = load_truth_instances(listing[index]);\n+        }\n     );\n \n     return truth_instances;\ndiff --git a/examples/object_detector_advanced_ex.cpp b/examples/object_detector_advanced_ex.cpp\nindex 718994e27c..05e7affb9e 100644\n--- a/examples/object_detector_advanced_ex.cpp\n+++ b/examples/object_detector_advanced_ex.cpp\n@@ -179,7 +179,7 @@ class very_simple_feature_extractor : noncopyable\n     inline friend void serialize   ( const very_simple_feature_extractor& item, std::ostream& out)  { serialize(item.feat_image, out); }\n     inline friend void deserialize ( very_simple_feature_extractor& item, std::istream& in ) { deserialize(item.feat_image, in); }\n \n-    void copy_configuration ( const very_simple_feature_extractor& item){}\n+    void copy_configuration ( const very_simple_feature_extractor&){}\n \n private:\n     array2d<unsigned char> feat_image;\ndiff --git a/examples/server_iostream_ex.cpp b/examples/server_iostream_ex.cpp\nindex 81fa300111..05edcd2838 100644\n--- a/examples/server_iostream_ex.cpp\n+++ b/examples/server_iostream_ex.cpp\n@@ -34,10 +34,10 @@ class serv : public server_iostream\n         std::istream& in,\n         std::ostream& out,\n         const std::string& foreign_ip,\n-        const std::string& local_ip,\n-        unsigned short foreign_port,\n-        unsigned short local_port,\n-        uint64 connection_id\n+        const std::string& /*local_ip*/,\n+        unsigned short /*foreign_port*/,\n+        unsigned short /*local_port*/,\n+        uint64 /*connection_id*/\n     )\n     {\n         // The details of the connection are contained in the last few arguments to\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Warnings Management**: Remove `-Werror` from `dlib/CMakeLists.txt`. Consider adding `-Wno-maybe-uninitialized` when building tests to avoid failure due to unused variables.\n\n2. **Code Cleanup**: Address unused variable warnings in `matrix_ex.cpp`. Ensure all assigned variables are utilized.\n\n3. **Execution Policies**: Modify execution policy conditional in code:\n   - Change:\n     ```cpp\n     #if __cplusplus >= 201703L || (defined(_MSVC_LANG) && _MSVC_LANG >= 201703L)\n     ```\n     to:\n     ```cpp\n     #if defined(_MSVC_LANG) && _MSVC_LANG >= 201703L\n     ```\n   This enables execution policies on Windows without version checking.\n\n4. **Dependencies**: For instance segmentation, switch to `dlib's parallel_for()` to eliminate reliance on TBB with C++17.\n\n5. **Build Verification**: Confirm warnings consistency between local builds and CI environments."
      }
    ],
    "codediff_length": 25885
  },
  {
    "index": 69,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/dlib/dnn/input.h b/dlib/dnn/input.h\nindex 28167ac2e9..213092ad9c 100644\n--- a/dlib/dnn/input.h\n+++ b/dlib/dnn/input.h\n@@ -31,6 +31,8 @@ namespace dlib\n     template <size_t NR, size_t NC=NR>\n     class input_rgb_image_sized;\n \n+    class input_rgb_image_pair;\n+\n     class input_rgb_image\n     {\n     public:\n@@ -54,7 +56,11 @@ namespace dlib\n         template <size_t NR, size_t NC>\n         inline input_rgb_image (\n             const input_rgb_image_sized<NR,NC>& item\n-        ); \n+        );\n+\n+        inline input_rgb_image (\n+            const input_rgb_image_pair& item\n+        );\n \n         float get_avg_red()   const { return avg_red; }\n         float get_avg_green() const { return avg_green; }\n@@ -87,7 +93,7 @@ namespace dlib\n                 );\n             }\n \n-            \n+\n             // initialize data to the right size to contain the stuff in the iterator range.\n             data.set_size(std::distance(ibegin,iend), 3, nr, nc);\n \n@@ -127,7 +133,7 @@ namespace dlib\n         {\n             std::string version;\n             deserialize(version, in);\n-            if (version != \"input_rgb_image\" && version != \"input_rgb_image_sized\")\n+            if (version != \"input_rgb_image\" && version != \"input_rgb_image_sized\" && version != \"input_rgb_image_pair\")\n                 throw serialization_error(\"Unexpected version found while deserializing dlib::input_rgb_image.\");\n             deserialize(item.avg_red, in);\n             deserialize(item.avg_green, in);\n@@ -216,7 +222,7 @@ namespace dlib\n                 );\n             }\n \n-            \n+\n             // initialize data to the right size to contain the stuff in the iterator range.\n             data.set_size(std::distance(ibegin,iend), 3, NR, NC);\n \n@@ -303,6 +309,164 @@ namespace dlib\n         avg_blue(item.get_avg_blue())\n     {}\n \n+// ----------------------------------------------------------------------------------------\n+\n+    class input_rgb_image_pair\n+    {\n+    public:\n+        typedef std::pair<matrix<rgb_pixel>, matrix<rgb_pixel>> input_type;\n+\n+        input_rgb_image_pair (\n+        ) :\n+            avg_red(122.782),\n+            avg_green(117.001),\n+            avg_blue(104.298)\n+        {\n+        }\n+\n+        input_rgb_image_pair (\n+            float avg_red,\n+            float avg_green,\n+            float avg_blue\n+        ) : avg_red(avg_red), avg_green(avg_green), avg_blue(avg_blue)\n+        {}\n+\n+        inline input_rgb_image_pair (\n+            const input_rgb_image& item\n+        ) :\n+            avg_red(item.get_avg_red()),\n+            avg_green(item.get_avg_green()),\n+            avg_blue(item.get_avg_blue())\n+        {}\n+\n+        template <size_t NR, size_t NC>\n+        inline input_rgb_image_pair (\n+            const input_rgb_image_sized<NR, NC>& item\n+        ) :\n+            avg_red(item.get_avg_red()),\n+            avg_green(item.get_avg_green()),\n+            avg_blue(item.get_avg_blue())\n+        {}\n+\n+        float get_avg_red()   const { return avg_red; }\n+        float get_avg_green() const { return avg_green; }\n+        float get_avg_blue()  const { return avg_blue; }\n+\n+        bool image_contained_point ( const tensor& data, const point& p) const { return get_rect(data).contains(p); }\n+        drectangle tensor_space_to_image_space ( const tensor& /*data*/, drectangle r) const { return r; }\n+        drectangle image_space_to_tensor_space ( const tensor& /*data*/, double /*scale*/, drectangle r ) const { return r; }\n+\n+        template <typename forward_iterator>\n+        void to_tensor (\n+            forward_iterator ibegin,\n+            forward_iterator iend,\n+            resizable_tensor& data\n+        ) const\n+        {\n+            DLIB_CASSERT(std::distance(ibegin, iend) > 0);\n+            const auto nr = ibegin->first.nr();\n+            const auto nc = ibegin->first.nc();\n+\n+            // make sure all the input matrices have the same dimensions\n+            for (auto i = ibegin; i != iend; ++i)\n+            {\n+                DLIB_CASSERT(i->first.nr() == nr && i->first.nc()==nc &&\n+                             i->second.nr() == nr && i->second.nc() == nc,\n+                    \"\\t input_rgb_image_pair::to_tensor()\"\n+                    << \"\\n\\t All matrices given to to_tensor() must have the same dimensions.\"\n+                    << \"\\n\\t nr: \" << nr\n+                    << \"\\n\\t nc: \" << nc\n+                    << \"\\n\\t i->first.nr(): \" << i->first.nr()\n+                    << \"\\n\\t i->first.nc(): \" << i->first.nc()\n+                    << \"\\n\\t i->second.nr(): \" << i->second.nr()\n+                    << \"\\n\\t i->second.nc(): \" << i->second.nc()\n+                );\n+            }\n+\n+            // initialize data to the right size to contain the stuff in the iterator range.\n+            data.set_size(2 * std::distance(ibegin, iend), 3, nr, nc);\n+\n+            const size_t offset = nr * nc;\n+            const size_t offset2 = data.size() / 2;\n+            auto ptr = data.host();\n+            for (auto i = ibegin; i != iend; ++i)\n+            {\n+                for (long r = 0; r < nr; ++r)\n+                {\n+                    for (long c = 0; c < nc; ++c)\n+                    {\n+                        rgb_pixel temp_first = i->first(r, c);\n+                        rgb_pixel temp_second = i->second(r, c);\n+                        auto p = ptr++;\n+                        *p = (temp_first.red - avg_red) / 256.0;\n+                        *(p + offset2) = (temp_second.red - avg_red) / 256.0;\n+                        p += offset;\n+                        *p = (temp_first.green - avg_green) / 256.0;\n+                        *(p + offset2) = (temp_second.green - avg_green) / 256.0;\n+                        p += offset;\n+                        *p = (temp_first.blue - avg_blue) / 256.0;\n+                        *(p + offset2) = (temp_second.blue - avg_blue) / 256.0;\n+                        p += offset;\n+                    }\n+                }\n+                ptr += offset * (data.k() - 1);\n+            }\n+        }\n+\n+        friend void serialize(const input_rgb_image_pair& item, std::ostream& out)\n+        {\n+            serialize(\"input_rgb_image_pair\", out);\n+            serialize(item.avg_red, out);\n+            serialize(item.avg_green, out);\n+            serialize(item.avg_blue, out);\n+        }\n+\n+        friend void deserialize(input_rgb_image_pair& item, std::istream& in)\n+        {\n+            std::string version;\n+            deserialize(version, in);\n+            if (version != \"input_rgb_image_pair\" && version != \"input_rgb_image\" && version != \"input_rgb_image_sized\")\n+                throw serialization_error(\"Unexpected version found while deserializing dlib::input_rgb_image_pair.\");\n+\n+            deserialize(item.avg_red, in);\n+            deserialize(item.avg_green, in);\n+            deserialize(item.avg_blue, in);\n+            // read and discard the sizes if this was really a sized input layer.\n+            if (version == \"input_rgb_image_sized\")\n+            {\n+                size_t nr, nc;\n+                deserialize(nr, in);\n+                deserialize(nc, in);\n+            }\n+        }\n+\n+        friend std::ostream& operator<<(std::ostream& out, const input_rgb_image_pair& item)\n+        {\n+            out << \"input_rgb_image_pair(\"<< item.avg_red<<\",\"<<item.avg_green<<\",\"<<item.avg_blue << \")\";\n+            return out;\n+        }\n+\n+        friend void to_xml(const input_rgb_image_pair& item, std::ostream& out)\n+        {\n+            out << \"<input_rgb_image_pair r='\"<<item.avg_red<<\"' g='\"<<item.avg_green<<\"' b='\"<<item.avg_blue<<\"'/>\";\n+        }\n+\n+    private:\n+        float avg_red;\n+        float avg_green;\n+        float avg_blue;\n+    };\n+\n+// ----------------------------------------------------------------------------------------\n+\n+    input_rgb_image::\n+    input_rgb_image (\n+        const input_rgb_image_pair& item\n+    ) : avg_red(item.get_avg_red()),\n+        avg_green(item.get_avg_green()),\n+        avg_blue(item.get_avg_blue())\n+    {}\n+\n // ----------------------------------------------------------------------------------------\n \n     template <typename T, long NR, long NC, typename MM, typename L>\ndiff --git a/dlib/dnn/input_abstract.h b/dlib/dnn/input_abstract.h\nindex 24fe6de6e4..eb41d548c6 100644\n--- a/dlib/dnn/input_abstract.h\n+++ b/dlib/dnn/input_abstract.h\n@@ -271,6 +271,115 @@ namespace dlib\n \n     };\n \n+// ----------------------------------------------------------------------------------------\n+\n+    class input_rgb_image_pair\n+    {\n+        /*!\n+            WHAT THIS OBJECT REPRESENTS\n+                This input layer works with std::pair of RGB images of type matrix<rgb_pixel>.\n+                It is useful when you want to input image pairs that are related to each other,\n+                for instance, they are different distorted views of the same original image.\n+                It is mainly supposed to be used with unsupervised loss functions such as\n+                loss_barlow_twins_. You can also convert between input_rgb_image and\n+                input_rgb_image_pair by copy construction or assignment.\n+        !*/\n+    public:\n+        typedef std::pair<matrix<rgb_pixel>, matrix<rgb_pixel>> input_type;\n+\n+        input_rgb_image_pair (\n+        );\n+        /*!\n+            ensures\n+                - #get_avg_red()   == 122.782\n+                - #get_avg_green() == 117.001\n+                - #get_avg_blue()  == 104.298\n+        !*/\n+\n+        input_rgb_image_pair (\n+            float avg_red,\n+            float avg_green,\n+            float avg_blue\n+        );\n+        /*!\n+            ensures\n+                - #get_avg_red() == avg_red\n+                - #get_avg_green() == avg_green\n+                - #get_avg_blue() == avg_blue\n+        !*/\n+\n+        inline input_rgb_image_pair (\n+            const input_rgb_image& item\n+        );\n+        /*!\n+            ensures\n+                - #get_avg_red() == item.get_avg_red()\n+                - #get_avg_green() == item.get_avg_green()\n+                - #get_avg_blue() == item.get_avg_blue()\n+        !*/\n+\n+        template <size_t NR, size_t NC>\n+        inline input_rgb_image_pair (\n+            const input_rgb_image_sized<NR, NC>& item\n+        );\n+        /*!\n+            ensures\n+                - #get_avg_red() == item.get_avg_red()\n+                - #get_avg_green() == item.get_avg_green()\n+                - #get_avg_blue() == item.get_avg_blue()\n+        !*/\n+\n+        float get_avg_red(\n+        ) const;\n+        /*!\n+            ensures\n+                - returns the value subtracted from the red color channel.\n+        !*/\n+\n+        float get_avg_green(\n+        ) const;\n+        /*!\n+            ensures\n+                - returns the value subtracted from the green color channel.\n+        !*/\n+\n+        float get_avg_blue(\n+        ) const;\n+        /*!\n+            ensures\n+                - returns the value subtracted from the blue color channel.\n+        !*/\n+\n+        void to_tensor (\n+            forward_iterator ibegin,\n+            forward_iterator iend,\n+            resizable_tensor& data\n+        ) const;\n+        /*!\n+            requires\n+                - [ibegin, iend) is an iterator range over input_type objects.\n+                - std::distance(ibegin,iend) > 0\n+                - The input range should contain images that all have the same\n+                  dimensions.\n+            ensures\n+                - Converts the iterator range into a tensor and stores it into #data.  In\n+                  particular, if the input images have R rows, C columns then we will have:\n+                    - #data.num_samples() == 2 * std::distance(ibegin,iend)\n+                    - #data.nr() == R\n+                    - #data.nc() == C\n+                    - #data.k() == 3\n+                  Moreover, each color channel is normalized by having its average value\n+                  subtracted (according to get_avg_red(), get_avg_green(), or\n+                  get_avg_blue()) and then is divided by 256.0.\n+                  Additionally, the first elements in each pair are placed in the first half\n+                  of the batch, and the second elements in the second half.\n+        !*/\n+\n+        // Provided for compatibility with input_rgb_image_pyramid's interface\n+        bool image_contained_point ( const tensor& data, const point& p) const { return get_rect(data).contains(p); }\n+        drectangle tensor_space_to_image_space ( const tensor& /*data*/, drectangle r) const { return r; }\n+        drectangle image_space_to_tensor_space ( const tensor& /*data*/, double /*scale*/, drectangle r ) const { return r; }\n+\n // ----------------------------------------------------------------------------------------\n \n     template <\ndiff --git a/dlib/dnn/loss.h b/dlib/dnn/loss.h\nindex af7a17ff14..a553506fa4 100644\n--- a/dlib/dnn/loss.h\n+++ b/dlib/dnn/loss.h\n@@ -3970,6 +3970,155 @@ namespace dlib\n \n     template <template <typename> class TAG_1, template <typename> class TAG_2, template <typename> class TAG_3, typename SUBNET>\n     using loss_yolo = add_loss_layer<loss_yolo_<TAG_1, TAG_2, TAG_3>, SUBNET>;\n+\n+// ----------------------------------------------------------------------------------------\n+\n+    class loss_barlow_twins_\n+    {\n+    public:\n+\n+        loss_barlow_twins_() = default;\n+\n+        loss_barlow_twins_(float lambda) : lambda(lambda)\n+        {\n+            DLIB_CASSERT(lambda > 0);\n+        }\n+\n+        template <\n+            typename SUBNET\n+        >\n+        double compute_loss_value_and_gradient (\n+            const tensor& input_tensor,\n+            SUBNET& sub\n+        ) const\n+        {\n+            const tensor& output_tensor = sub.get_output();\n+            tensor& grad = sub.get_gradient_input();\n+\n+            DLIB_CASSERT(sub.sample_expansion_factor() == 2);\n+            DLIB_CASSERT(input_tensor.num_samples() != 0);\n+            DLIB_CASSERT(input_tensor.num_samples() % sub.sample_expansion_factor() == 0);\n+            DLIB_CASSERT(input_tensor.num_samples() == grad.num_samples());\n+            DLIB_CASSERT(input_tensor.num_samples() == output_tensor.num_samples());\n+            DLIB_CASSERT(output_tensor.nr() == 1 && output_tensor.nc() == 1);\n+            DLIB_CASSERT(grad.nr() == 1 && grad.nc() == 1);\n+\n+            const auto batch_size = output_tensor.num_samples() / 2;\n+            const auto sample_size = output_tensor.k();\n+            const auto offset = batch_size * sample_size;\n+\n+            // Alias helpers to access the samples in the batch\n+            alias_tensor split(batch_size, sample_size);\n+            auto za = split(output_tensor);\n+            auto zb = split(output_tensor, offset);\n+\n+            // Normalize both batches independently across the batch dimension\n+            const double eps = 1e-4;\n+            resizable_tensor za_norm, means_a, invstds_a;\n+            resizable_tensor zb_norm, means_b, invstds_b;\n+            resizable_tensor rms, rvs, g, b;\n+            g.set_size(1, sample_size);\n+            g = 1;\n+            b.set_size(1, sample_size);\n+            b = 0;\n+            tt::batch_normalize(eps, za_norm, means_a, invstds_a, 1, rms, rvs, za, g, b);\n+            tt::batch_normalize(eps, zb_norm, means_b, invstds_b, 1, rms, rvs, zb, g, b);\n+\n+            // Compute the empirical cross-correlation matrix\n+            resizable_tensor eccm;\n+            eccm.set_size(sample_size, sample_size);\n+            tt::gemm(0, eccm, 1, za_norm, true, zb_norm, false);\n+            eccm /= batch_size;\n+\n+            // Compute the loss: MSE between eccm and the identity matrix.\n+            // Off-diagonal terms are weighed by lambda.\n+            const matrix<float> C = mat(eccm);\n+            const double diagonal_loss = sum(squared(diag(C) - 1));\n+            const double off_diag_loss = sum(squared(C - diagm(diag(C))));\n+            double loss = diagonal_loss + lambda * off_diag_loss;\n+\n+            // Loss gradient, which will be used as the input of the batch normalization gradient\n+            resizable_tensor grad_input;\n+            grad_input.copy_size(grad);\n+            auto grad_input_a = split(grad_input);\n+            auto grad_input_b = split(grad_input, offset);\n+\n+            // Compute the loss: notation from http://www.matrixcalculus.org/\n+            // A = za_norm\n+            // B = zb_norm\n+            // C = eccm\n+            // D = off_mask: a mask that keeps only the elements outside the diagonal\n+\n+            // diagonal term: sum((diag(A' * B) - vector(1)).^2)\n+            // --------------------------------------------\n+            // \t=> d/dA = 2 * B * diag(diag(A' * B) - vector(1)) = 2 * B * diag(diag(C) - vector(1))\n+            // \t=> d/dB = 2 * A * diag(diag(A' * B) - vector(1)) = 2 * A * diag(diag(C) - vector(1))\n+            resizable_tensor cdiag_1(diagm(diag(mat(eccm) - 1)));\n+            tt::gemm(0, grad_input_a, 2, zb_norm, false, cdiag_1, false);\n+            tt::gemm(0, grad_input_b, 2, za_norm, false, cdiag_1, false);\n+\n+            // off-diag term: sum(((A'* B) .* D).^2)\n+            // --------------------------------\n+            //  => d/dA = 2 * B * ((B' * A) .* (D .* D)') = 2 * B * (C .* (D .* D)) = 2 * B * (C .* D)\n+            //  => d/dB = 2 * A * ((A' * B) .* (D .* D))  = 2 * A * (C .* (D .* D)) = 2 * A * (C .* D)\n+            resizable_tensor off_mask(ones_matrix<float>(sample_size, sample_size) - identity_matrix<float>(sample_size));\n+            resizable_tensor off_diag(sample_size, sample_size);\n+            tt::multiply(false, off_diag, eccm, off_mask);\n+            tt::gemm(1, grad_input_a, lambda, zb_norm, false, off_diag, false);\n+            tt::gemm(1, grad_input_b, lambda, za_norm, false, off_diag, false);\n+\n+            // Compute the batch norm gradients, g and b grads are not used\n+            resizable_tensor g_grad, b_grad;\n+            g_grad.copy_size(g);\n+            b_grad.copy_size(b);\n+            auto gza = split(grad);\n+            auto gzb = split(grad, offset);\n+            tt::batch_normalize_gradient(eps, grad_input_a, means_a, invstds_a, za, g, gza, g_grad, b_grad);\n+            tt::batch_normalize_gradient(eps, grad_input_b, means_b, invstds_b, zb, g, gzb, g_grad, b_grad);\n+\n+            return loss;\n+        }\n+\n+        float get_lambda() const  { return lambda; }\n+\n+        friend void serialize(const loss_barlow_twins_& item, std::ostream& out)\n+        {\n+            serialize(\"loss_barlow_twins_\", out);\n+            serialize(item.lambda, out);\n+        }\n+\n+        friend void deserialize(loss_barlow_twins_& item, std::istream& in)\n+        {\n+            std::string version;\n+            deserialize(version, in);\n+            if (version == \"loss_barlow_twins_\")\n+            {\n+                deserialize(item.lambda, in);\n+            }\n+            else\n+            {\n+                throw serialization_error(\"Unexpected version found while deserializing dlib::loss_barlow_twins_.  Instead found \" + version);\n+            }\n+        }\n+\n+        friend std::ostream& operator<<(std::ostream& out, const loss_barlow_twins_& item)\n+        {\n+            out << \"loss_barlow_twins (lambda=\" << item.lambda << \")\";\n+            return out;\n+        }\n+\n+        friend void to_xml(const loss_barlow_twins_& item, std::ostream& out)\n+        {\n+            out << \"<loss_barlow_twins lambda='\" << item.lambda << \"'/>\";\n+        }\n+\n+    private:\n+        float lambda = 0.0051;\n+    };\n+\n+    template <typename SUBNET>\n+    using loss_barlow_twins = add_loss_layer<loss_barlow_twins_, SUBNET>;\n+\n }\n \n #endif // DLIB_DNn_LOSS_H_\ndiff --git a/dlib/dnn/loss_abstract.h b/dlib/dnn/loss_abstract.h\nindex c527eec6cc..8f8c0edf83 100644\n--- a/dlib/dnn/loss_abstract.h\n+++ b/dlib/dnn/loss_abstract.h\n@@ -2038,6 +2038,88 @@ namespace dlib\n \n // ----------------------------------------------------------------------------------------\n \n+    class loss_barlow_twins_\n+    {\n+    public:\n+\n+        /*!\n+            WHAT THIS OBJECT REPRESENTS\n+                This object implements the loss layer interface defined above by\n+                EXAMPLE_LOSS_LAYER_.  In particular, it implements the Barlow Twins loss\n+                layer presented in the paper:\n+                    Barlow Twins: Self-Supervised Learning via Redundancy Reduction\n+                    by Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, St\u00e9phane Deny\n+                    (https://arxiv.org/abs/2103.03230)\n+\n+                This means you use this loss to learn useful representations from data that\n+                has no label information.  Useful representations mean that can be used to\n+                train another downstream task, such as classification.\n+                In particular, this loss function applies the redundancy reduction principle\n+                to the representations learned by the network it sits on top of.\n+\n+                To be specific, this layer requires the sample_expansion_factor to be 2, and\n+                in each batch, the second half contains distorted versions of the first half.\n+                Let Z_A and Z_B be the first and second half of the batch that goes into this\n+                loss layer, respectively.  Z_A and Z_B have dimensions N rows and D columns,\n+                where N is half the batch size and D is the dimensionality of the output tensor.\n+                Each row in Z_B should contain a distorted version of the corresponding row\n+                in Z_A.  Then, this loss computes the empirical cross-correlation matrix between\n+                the batch-normalized versions of Z_A and Z_B:\n+\n+                    C = trans(bn(Z_A)) * bn(Z_B)\n+\n+                It then applies the redundancy reduction principle by trying to make C as\n+                close to the identity matrix as possible:\n+\n+                    L = squared(diag(C) - 1) + lambda * squared(off_diag(C))\n+\n+                where off_diag grabs all the elements that are not on the diagonal of C and\n+                lambda provides a trade-off between both terms in the loss function.  The C\n+                matrix has dimensions D x D: there are only D diagonal terms, but D * (D - 1)\n+                off-diagonal elements.  A reasonable value for lambda is 1 / D.\n+        !*/\n+\n+        loss_barlow_twins_(\n+        );\n+        /*!\n+            ensures\n+                - #get_lambda() == 0.0051\n+        !*/\n+\n+        loss_barlow_twins_(float lambda);\n+        /*!\n+            ensures\n+                - #get_lambda() == lambda\n+        !*/\n+\n+        float get_lambda() const;\n+        /*!\n+            ensures\n+                - returns the lambda value used by the loss function.  See the discussion\n+                  in WHAT THIS OBJECT REPRESENTS for details.\n+        !*/\n+\n+        template <\n+            typename SUBNET\n+        >\n+        double compute_loss_value_and_gradient (\n+            const tensor& input_tensor,\n+            SUBNET& sub\n+        ) const;\n+        /*!\n+            This function has the same interface as EXAMPLE_LOSS_LAYER_::compute_loss_value_and_gradient()\n+            except it has the additional calling requirements that:\n+                - sub.get_output().nr() == 1\n+                - sub.get_output().nc() == 1\n+                - sub.get_output().num_samples() == input_tensor.num_samples()\n+                - sub.sample_expansion_factor() == 2\n+        !*/\n+\n+    };\n+\n+    template <typename SUBNET>\n+    using loss_barlow_twins = add_loss_layer<loss_barlow_twins_, SUBNET>;\n+\n }\n \n #endif // DLIB_DNn_LOSS_ABSTRACT_H_\ndiff --git a/examples/CMakeLists.txt b/examples/CMakeLists.txt\nindex 6d5e479f57..3a67e4fe78 100644\n--- a/examples/CMakeLists.txt\n+++ b/examples/CMakeLists.txt\n@@ -156,6 +156,7 @@ if (NOT USING_OLD_VISUAL_STUDIO_COMPILER)\n    add_example(dnn_metric_learning_on_images_ex)\n    add_gui_example(dnn_dcgan_train_ex)\n    add_gui_example(dnn_yolo_train_ex)\n+   add_gui_example(dnn_self_supervised_learning_ex)\n endif()\n \n \ndiff --git a/examples/dnn_self_supervised_learning_ex.cpp b/examples/dnn_self_supervised_learning_ex.cpp\nnew file mode 100644\nindex 0000000000..110a6077bf\n--- /dev/null\n+++ b/examples/dnn_self_supervised_learning_ex.cpp\n@@ -0,0 +1,364 @@\n+// The contents of this file are in the public domain. See LICENSE_FOR_EXAMPLE_PROGRAMS.txt\n+/*\n+    This is an example illustrating the use of the deep learning tools from the dlib C++\n+    Library.  I'm assuming you have already read the dnn_introduction_ex.cpp, the\n+    dnn_introduction2_ex.cpp and the dnn_introduction3_ex.cpp examples.  In this example\n+    program we are going to show how one can train a neural network using an unsupervised\n+    loss function.  In particular, we will train the ResNet50 model from the paper\n+    \"Deep Residual Learning for Image Recognition\" by Kaiming He, Xiangyu Zhang, Shaoqing\n+    Ren, Jian Sun.\n+\n+    To train the unsupervised loss, we will use the self-supervised learning (SSL) method\n+    called Barlow Twins, introduced in this paper:\n+    \"Barlow Twins: Self-Supervised Learning via Redundancy Reduction\" by Jure Zbontar,\n+    Li Jing, Ishan Misra, Yann LeCun, St\u00e9phane Deny.\n+\n+    The paper contains a good explanation on how and why this works, but the main idea\n+    behind the Barlow Twins method is:\n+        - generate two distorted views of a batch of images: YA, YB\n+        - feed them to a deep neural network and obtain their representations and\n+          and batch normalize them: ZA, ZB\n+        - compute the empirical cross-correlation matrix between both feature\n+          representations as: C = trans(ZA) * ZB.\n+        - make C as close as possible to the identity matrix.\n+\n+    This removes the redundancy of the feature representations, by maximizing the\n+    encoded information about the images themselves, while minimizing the information\n+    about the transforms and data augmentations used to obtain the representations.\n+\n+    The original Barlow Twins paper uses the ImageNet dataset, but in this example we\n+    are using CIFAR-10, so we will follow the recommendations of this paper, instead:\n+    \"A Note on Connecting Barlow Twins with Negative-Sample-Free Contrastive Learning\"\n+    by Yao-Hung Hubert Tsai, Shaojie Bai, Louis-Philippe Morency, Ruslan Salakhutdinov,\n+    in which they experiment with Barlow Twins on CIFAR-10 and Tiny ImageNet.  Since\n+    the CIFAR-10 contains relatively small images, we will define a ResNet50 architecture\n+    that doesn't downsample the input in the first convolutional layer, and doesn't have\n+    a max pooling layer afterwards, like the paper does.\n+*/\n+\n+#include <dlib/dnn.h>\n+#include <dlib/data_io.h>\n+#include <dlib/cmd_line_parser.h>\n+#include <dlib/gui_widgets.h>\n+\n+using namespace std;\n+using namespace dlib;\n+\n+// A custom definition of ResNet50 with a downsampling factor of 8 instead of 32.\n+// It is essentially the original ResNet50, but without the max pooling and a\n+// convolutional layer with a stride of 1 instead of 2 at the input.\n+namespace resnet50\n+{\n+    using namespace dlib;\n+    template <template <typename> class BN>\n+    struct def\n+    {\n+        template <long N, int K, int S, typename SUBNET>\n+        using conv = add_layer<con_<N, K, K, S, S, K / 2, K / 2>, SUBNET>;\n+\n+        template<long N, int S, typename SUBNET>\n+        using bottleneck = BN<conv<4 * N, 1, 1, relu<BN<conv<N, 3, S, relu<BN<conv<N, 1, 1, SUBNET>>>>>>>>;\n+\n+        template <long N,  typename SUBNET>\n+        using residual = add_prev1<bottleneck<N, 1, tag1<SUBNET>>>;\n+\n+        template <typename SUBNET> using res_512 = relu<residual<512, SUBNET>>;\n+        template <typename SUBNET> using res_256 = relu<residual<256, SUBNET>>;\n+        template <typename SUBNET> using res_128 = relu<residual<128, SUBNET>>;\n+        template <typename SUBNET> using res_64  = relu<residual<64, SUBNET>>;\n+\n+        template <long N, int S, typename SUBNET>\n+        using transition = add_prev2<BN<conv<4 * N, 1, S, skip1<tag2<bottleneck<N, S, tag1<SUBNET>>>>>>>;\n+\n+        template <typename INPUT>\n+        using backbone = avg_pool_everything<\n+            repeat<2, res_512, transition<512, 2,\n+            repeat<5, res_256, transition<256, 2,\n+            repeat<3, res_128, transition<128, 2,\n+            repeat<2, res_64,  transition<64, 1,\n+            relu<BN<conv<64, 3, 1,INPUT>>>>>>>>>>>>;\n+    };\n+};\n+\n+// This model namespace contains the definitions for:\n+// - SSL model using the Barlow Twins loss, a projector head and an input_rgb_image_pair.\n+// - Classifier model using the loss_multiclass_log, a fc layer and an input_rgb_image.\n+namespace model\n+{\n+    template <typename SUBNET> using projector = fc<128, relu<bn_fc<fc<512, SUBNET>>>>;\n+    template <typename SUBNET> using classifier = fc<10, SUBNET>;\n+\n+    using train = loss_barlow_twins<projector<resnet50::def<bn_con>::backbone<input_rgb_image_pair>>>;\n+    using infer = loss_multiclass_log<classifier<resnet50::def<affine>::backbone<input_rgb_image>>>;\n+}\n+\n+rectangle make_random_cropping_rect(\n+    const matrix<rgb_pixel>& image,\n+    dlib::rand& rnd\n+)\n+{\n+    const double mins = 7. / 15.;\n+    const double maxs = 7. / 8.;\n+    const auto scale = rnd.get_double_in_range(mins, maxs);\n+    const auto size = scale * std::min(image.nr(), image.nc());\n+    const rectangle rect(size, size);\n+    const point offset(rnd.get_random_32bit_number() % (image.nc() - rect.width()),\n+                       rnd.get_random_32bit_number() % (image.nr() - rect.height()));\n+    return move_rect(rect, offset);\n+}\n+\n+matrix<rgb_pixel> augment(\n+    const matrix<rgb_pixel>& image,\n+    const bool prime,\n+    dlib::rand& rnd\n+)\n+{\n+    matrix<rgb_pixel> crop;\n+    // blur\n+    matrix<rgb_pixel> blurred;\n+    const double sigma = rnd.get_double_in_range(0.1, 1.1);\n+    if (!prime || (prime && rnd.get_random_double() < 0.1))\n+    {\n+        const auto rect = gaussian_blur(image, blurred, sigma);\n+        extract_image_chip(blurred, rect, crop);\n+        blurred = crop;\n+    }\n+    else\n+    {\n+        blurred = image;\n+    }\n+\n+    // randomly crop\n+    const auto rect = make_random_cropping_rect(image, rnd);\n+    extract_image_chip(blurred, chip_details(rect, chip_dims(32, 32)), crop);\n+\n+    // image left-right flip\n+    if (rnd.get_random_double() < 0.5)\n+        flip_image_left_right(crop);\n+\n+    // color augmentation\n+    if (rnd.get_random_double() < 0.8)\n+        disturb_colors(crop, rnd, 0.5, 0.5);\n+\n+    // grayscale\n+    if (rnd.get_random_double() < 0.2)\n+    {\n+        matrix<unsigned char> gray;\n+        assign_image(gray, crop);\n+        assign_image(crop, gray);\n+    }\n+\n+    // solarize\n+    if (prime && rnd.get_random_double() < 0.2)\n+    {\n+        for (auto& p : crop)\n+        {\n+            if (p.red > 128)\n+                p.red = 255 - p.red;\n+            if (p.green > 128)\n+                p.green = 255 - p.green;\n+            if (p.blue > 128)\n+                p.blue = 255 - p.blue;\n+        }\n+    }\n+    return crop;\n+}\n+\n+int main(const int argc, const char** argv)\n+try\n+{\n+    // The default settings are fine for the example already.\n+    command_line_parser parser;\n+    parser.add_option(\"batch\", \"set the mini batch size per GPU (default: 64)\", 1);\n+    parser.add_option(\"dims\", \"set the projector dimensions (default: 128)\", 1);\n+    parser.add_option(\"lambda\", \"penalize off-diagonal terms (default: 1/dims)\", 1);\n+    parser.add_option(\"learning-rate\", \"set the initial learning rate (default: 1e-3)\", 1);\n+    parser.add_option(\"min-learning-rate\", \"set the min learning rate (default: 1e-5)\", 1);\n+    parser.add_option(\"num-gpus\", \"number of GPUs (default: 1)\", 1);\n+    parser.set_group_name(\"Help Options\");\n+    parser.add_option(\"h\", \"alias for --help\");\n+    parser.add_option(\"help\", \"display this message and exit\");\n+    parser.parse(argc, argv);\n+\n+    if (parser.number_of_arguments() < 1 || parser.option(\"h\") || parser.option(\"help\"))\n+    {\n+        cout << \"This example needs the CIFAR-10 dataset to run.\" << endl;\n+        cout << \"You can get CIFAR-10 from https://www.cs.toronto.edu/~kriz/cifar.html\" << endl;\n+        cout << \"Download the binary version the dataset, decompress it, and put the 6\" << endl;\n+        cout << \"bin files in a folder.  Then give that folder as input to this program.\" << endl;\n+        parser.print_options();\n+        return EXIT_SUCCESS;\n+    }\n+\n+    const size_t num_gpus = get_option(parser, \"num-gpus\", 1);\n+    const size_t batch_size = get_option(parser, \"batch\", 64) * num_gpus;\n+    const long dims = get_option(parser, \"dims\", 128);\n+    const double lambda = get_option(parser, \"lambda\", 1.0 / dims);\n+    const double learning_rate = get_option(parser, \"learning-rate\", 1e-3);\n+    const double min_learning_rate = get_option(parser, \"min-learning-rate\", 1e-5);\n+\n+    // Load the CIFAR-10 dataset into memory.\n+    std::vector<matrix<rgb_pixel>> training_images, testing_images;\n+    std::vector<unsigned long> training_labels, testing_labels;\n+    load_cifar_10_dataset(parser[0], training_images, training_labels, testing_images, testing_labels);\n+\n+    // Initialize the model with the specified projector dimensions and lambda.  According to the\n+    // second paper, lambda = 1/dims works well on CIFAR-10.\n+    model::train net((loss_barlow_twins_(lambda)));\n+    layer<1>(net).layer_details().set_num_outputs(dims);\n+    disable_duplicative_biases(net);\n+    dlib::rand rnd;\n+    std::vector<int> gpus(num_gpus);\n+    std::iota(gpus.begin(), gpus.end(), 0);\n+\n+    // Train the feature extractor using the Barlow Twins method\n+    {\n+        dnn_trainer<model::train, adam> trainer(net, adam(1e-6, 0.9, 0.999), gpus);\n+        trainer.set_mini_batch_size(batch_size);\n+        trainer.set_learning_rate(learning_rate);\n+        trainer.set_min_learning_rate(min_learning_rate);\n+        trainer.set_iterations_without_progress_threshold(10000);\n+        trainer.set_synchronization_file(\"barlow_twins_sync\");\n+        trainer.be_verbose();\n+        cout << trainer << endl;\n+\n+        // During the training, we will compute the empirical cross-correlation matrix\n+        // between the features of both versions of the augmented images.  This matrix\n+        // should be getting close to the identity matrix as the training progresses.\n+        // Note that this step is already done in the loss layer, and it's not necessary\n+        // to do it here for the example to work.  However, it provides a nice\n+        // visualization of the training progress: the closer to the identity matrix,\n+        // the better.\n+        resizable_tensor eccm;\n+        eccm.set_size(dims, dims);\n+        // Some tensors needed to perform batch normalization\n+        resizable_tensor za_norm, zb_norm, means, invstds, rms, rvs, gamma, beta;\n+        const double eps = DEFAULT_BATCH_NORM_EPS;\n+        gamma.set_size(1, dims);\n+        beta.set_size(1, dims);\n+        image_window win;\n+\n+        std::vector<std::pair<matrix<rgb_pixel>, matrix<rgb_pixel>>> batch;\n+        while (trainer.get_learning_rate() >= trainer.get_min_learning_rate())\n+        {\n+            batch.clear();\n+            while (batch.size() < trainer.get_mini_batch_size())\n+            {\n+                const auto idx = rnd.get_random_32bit_number() % training_images.size();\n+                auto image = training_images[idx];\n+                batch.emplace_back(augment(image, false, rnd), augment(image, true, rnd));\n+            }\n+            trainer.train_one_step(batch);\n+\n+            // Compute the empirical cross-correlation matrix every 100 steps. Again,\n+            // this is not needed for the training to work, but it's nice to visualize.\n+            if (trainer.get_train_one_step_calls() % 100 == 0)\n+            {\n+                // Wait for threaded processing to stop in the trainer.\n+                trainer.get_net(force_flush_to_disk::no);\n+                // Get the output from the last fc layer\n+                const auto& out = net.subnet().get_output();\n+                // The trainer might have synchronized its state to the disk and cleaned\n+                // the network state. If that happens, the output will be empty, in\n+                // which case, we just skip the empirical cross-correlation matrix\n+                // computation.\n+                if (out.size() == 0)\n+                    continue;\n+                // Separate both augmented versions of the images\n+                alias_tensor split(out.num_samples() / 2, dims);\n+                auto za = split(out);\n+                auto zb = split(out, split.size());\n+                gamma = 1;\n+                beta = 0;\n+                // Perform batch normalization on each feature representation, independently.\n+                tt::batch_normalize(eps, za_norm, means, invstds, 1, rms, rvs, za, gamma, beta);\n+                tt::batch_normalize(eps, zb_norm, means, invstds, 1, rms, rvs, za, gamma, beta);\n+                // Compute the empirical cross-correlation matrix between the features and\n+                // visualize it.\n+                tt::gemm(0, eccm, 1, za_norm, true, zb_norm, false);\n+                eccm /= batch_size;\n+                win.set_image(abs(mat(eccm)) * 255);\n+                win.set_title(\"Barlow Twins step#: \" + to_string(trainer.get_train_one_step_calls()));\n+            }\n+        }\n+        trainer.get_net();\n+        net.clean();\n+        // After training, we can discard the projector head and just keep the backone\n+        // to train it or finetune it on other downstream tasks.\n+        serialize(\"resnet50_self_supervised_cifar_10.net\") << layer<5>(net);\n+    }\n+\n+    // To check the quality of the learned feature representations, we will train a linear\n+    // classififer on top of the frozen backbone.\n+    model::infer inet;\n+    // Assign the network, without the projector, which is only used for the self-supervised\n+    // training.\n+    layer<2>(inet) = layer<5>(net);\n+    // Freeze the backbone\n+    set_all_learning_rate_multipliers(layer<2>(inet), 0);\n+    // Train the network\n+    {\n+        dnn_trainer<model::infer, adam> trainer(inet, adam(1e-6, 0.9, 0.999), gpus);\n+        // Since this model doesn't train with pairs, just single images, we can increase\n+        // the batch size.\n+        trainer.set_mini_batch_size(2 * batch_size);\n+        trainer.set_learning_rate(learning_rate);\n+        trainer.set_min_learning_rate(min_learning_rate);\n+        trainer.set_iterations_without_progress_threshold(5000);\n+        trainer.set_synchronization_file(\"cifar_10_sync\");\n+        trainer.be_verbose();\n+        cout << trainer << endl;\n+\n+        std::vector<matrix<rgb_pixel>> images;\n+        std::vector<unsigned long> labels;\n+        while (trainer.get_learning_rate() >= trainer.get_min_learning_rate())\n+        {\n+            images.clear();\n+            labels.clear();\n+            while (images.size() < trainer.get_mini_batch_size())\n+            {\n+                const auto idx = rnd.get_random_32bit_number() % training_images.size();\n+                images.push_back(augment(training_images[idx], false, rnd));\n+                labels.push_back(training_labels[idx]);\n+            }\n+            trainer.train_one_step(images, labels);\n+        }\n+        trainer.get_net();\n+        inet.clean();\n+        serialize(\"resnet50_cifar_10.dnn\") << inet;\n+    }\n+\n+    // Finally, we can compute the accuracy of the model on the CIFAR-10 train and test images.\n+    auto compute_accuracy = [&inet, batch_size](\n+        const std::vector<matrix<rgb_pixel>>& images,\n+        const std::vector<unsigned long>& labels\n+    )\n+    {\n+        size_t num_right = 0;\n+        size_t num_wrong = 0;\n+        const auto preds = inet(images, batch_size * 2);\n+        for (size_t i = 0; i < labels.size(); ++i)\n+        {\n+            if (labels[i] == preds[i])\n+                ++num_right;\n+            else\n+                ++num_wrong;\n+        }\n+        cout << \"num right:  \" << num_right << endl;\n+        cout << \"num wrong:  \" << num_wrong << endl;\n+        cout << \"accuracy:   \" << num_right / static_cast<double>(num_right + num_wrong) << endl;\n+        cout << \"error rate: \" << num_wrong / static_cast<double>(num_right + num_wrong) << endl;\n+    };\n+\n+    // If everything works as expected, we should get accuracies that are between 87% and 90%.\n+    cout << \"training accuracy\" << endl;\n+    compute_accuracy(training_images, training_labels);\n+    cout << \"\\ntesting accuracy\" << endl;\n+    compute_accuracy(testing_images, testing_labels);\n+    return EXIT_SUCCESS;\n+}\n+catch (const exception& e)\n+{\n+    cout << e.what() << endl;\n+    return EXIT_FAILURE;\n+}\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. The `dnn_trainer` crashes on the 3rd iteration; run with `ENABLE_ASSERTS` and on CPU for debugging. Valgrind may help identify issues, as GDB didn't yield a trace.\n2. Fix pointer arithmetic crash by placing `job.labels[i].assign(lbegin+start, lbegin+stop);` inside an `if` check for non-empty labels.\n3. Change output type to `std::vector<std::pair<matrix<float,0,1>, matrix<float,0,1>>>` for embeddings traceability.\n4. Consider whether `input_rgb_image_pair` is necessary; it automates minibatch creation, reducing user error.\n5. For multi-GPU training, replace fixed-size tensor allocation with dynamic sizing based on the current number of samples: `alias_tensor split(out.num_samples()/2, dims);`.\n6. Propose adding a parameter to `input_rgb_image_pair` to control sample interleaving as a future feature."
      }
    ],
    "codediff_length": 40822
  },
  {
    "index": 70,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/dlib/CMakeLists.txt b/dlib/CMakeLists.txt\nindex 09ddfaffa4..b48dfee8c7 100644\n--- a/dlib/CMakeLists.txt\n+++ b/dlib/CMakeLists.txt\n@@ -8,6 +8,16 @@ SET(CMAKE_ALLOW_LOOSE_LOOP_CONSTRUCTS true)\n \n cmake_minimum_required(VERSION 2.4)\n \n+# default to a Release build (except if CMAKE_BUILD_TYPE is set)\n+include(release_build_by_default)\n+\n+project(dlib)\n+\n+set(CPACK_PACKAGE_VERSION_MAJOR \"18\")\n+set(CPACK_PACKAGE_VERSION_MINOR \"17\")\n+set(CPACK_PACKAGE_VERSION_PATCH \"99\")\n+set(VERSION ${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH})\n+\n set(CMAKE_LEGACY_CYGWIN_WIN32 0) # Remove when CMake >= 2.8.4 is required\n # Suppress cmake warnings about changes in new versions.\n if(COMMAND cmake_policy) \n@@ -45,7 +55,6 @@ if (NOT CMAKE_CXX_FLAGS_DEBUG MATCHES \"-DENABLE_ASSERTS\")\n       FORCE)\n endif ()\n \n-\n # Don't try to call add_library(dlib) and setup dlib's stuff if it has already\n # been done by some other part of the current cmake project.  We do this\n # because it avoids getting warnings/errors about cmake policy CMP0002.  This\n@@ -66,24 +75,33 @@ if (NOT TARGET dlib)\n    \"Disable this if you don't want to use a BLAS library\" )\n    set (DLIB_USE_LAPACK_STR\n    \"Disable this if you don't want to use a LAPACK library\" )\n-   set (DLIB_LINK_WITH_LIBPNG_STR\n+   set (DLIB_PNG_SUPPORT_STR\n    \"Disable this if you don't want to link against libpng\" )\n-   set (DLIB_LINK_WITH_LIBJPEG_STR\n+   set (DLIB_JPEG_SUPPORT_STR\n    \"Disable this if you don't want to link against libjpeg\" )\n    set (DLIB_LINK_WITH_SQLITE3_STR\n    \"Disable this if you don't want to link against sqlite3\" )\n-   #set (DLIB_LINK_WITH_FFTW_STR \"Disable this if you don't want to link against fftw\" )\n+   #set (DLIB_USE_FFTW_STR \"Disable this if you don't want to link against fftw\" )\n \n    option(DLIB_ISO_CPP_ONLY ${DLIB_ISO_CPP_ONLY_STR} OFF)\n    option(DLIB_NO_GUI_SUPPORT ${DLIB_NO_GUI_SUPPORT_STR} OFF)\n    option(DLIB_ENABLE_STACK_TRACE ${DLIB_ENABLE_STACK_TRACE_STR} OFF)\n+\n    option(DLIB_ENABLE_ASSERTS ${DLIB_ENABLE_ASSERTS_STR} OFF)\n+\n+   if(DLIB_ENABLE_ASSERTS)\n+       set (DLIB_DISABLE_ASSERTS false)\n+       set (ENABLE_ASSERTS true) # we need the CMake variable to properly configure config.h.in\n+   else()\n+       set (DLIB_DISABLE_ASSERTS true)\n+   endif()\n+\n    option(DLIB_USE_BLAS ${DLIB_USE_BLAS_STR} ON)\n    option(DLIB_USE_LAPACK ${DLIB_USE_LAPACK_STR} ON)\n-   option(DLIB_LINK_WITH_LIBPNG ${DLIB_LINK_WITH_LIBPNG_STR} ON)\n-   option(DLIB_LINK_WITH_LIBJPEG ${DLIB_LINK_WITH_LIBJPEG_STR} ON)\n+   option(DLIB_PNG_SUPPORT ${DLIB_PNG_SUPPORT_STR} ON)\n+   option(DLIB_JPEG_SUPPORT ${DLIB_JPEG_SUPPORT_STR} ON)\n    option(DLIB_LINK_WITH_SQLITE3 ${DLIB_LINK_WITH_SQLITE3_STR} ON)\n-   #option(DLIB_LINK_WITH_FFTW ${DLIB_LINK_WITH_FFTW_STR} ON)\n+   #option(DLIB_USE_FFTW ${DLIB_USE_FFTW_STR} ON)\n \n    set(source_files \n          base64/base64_kernel_1.cpp\n@@ -100,7 +118,10 @@ if (NOT TARGET dlib)\n          data_io/image_dataset_metadata.cpp)\n \n    if (DLIB_ISO_CPP_ONLY)\n-      add_library(dlib STATIC ${source_files} )\n+       add_library(dlib STATIC ${source_files} )\n+       if (UNIX AND NOT DLIB_IN_PROJECT_BUILD)\n+           add_library(dlib-shared SHARED ${source_files} )\n+       endif()\n    else()\n \n       set(source_files ${source_files}\n@@ -218,7 +239,7 @@ if (NOT TARGET dlib)\n \n       INCLUDE (CheckFunctionExists)\n \n-      if (DLIB_LINK_WITH_LIBPNG)\n+      if (DLIB_PNG_SUPPORT)\n          # try to find libpng \n          find_package(PNG QUIET)\n          # Make sure there isn't something wrong with the version of LIBPNG\n@@ -272,7 +293,7 @@ if (NOT TARGET dlib)\n             )\n       endif()\n \n-      if (DLIB_LINK_WITH_LIBJPEG)\n+      if (DLIB_JPEG_SUPPORT)\n          # try to find libjpeg \n          find_package(JPEG QUIET)\n          # Make sure there isn't something wrong with the version of libjpeg \n@@ -381,7 +402,7 @@ if (NOT TARGET dlib)\n \n \n \n-      if (DLIB_LINK_WITH_FFTW)\n+      if (DLIB_USE_FFTW)\n          find_library(fftw fftw3)\n          # make sure fftw3.h is in the include path\n          find_path(fftw_path fftw3.h)\n@@ -389,36 +410,96 @@ if (NOT TARGET dlib)\n             include_directories(${fftw_path})\n             set(dlib_needed_libraries ${dlib_needed_libraries} ${fftw} )\n          else()\n-            set(DLIB_LINK_WITH_FFTW OFF CACHE STRING ${DLIB_LINK_WITH_SQLITE3_STR} FORCE )\n+            set(DLIB_USE_FFTW OFF CACHE STRING ${DLIB_LINK_WITH_SQLITE3_STR} FORCE )\n          endif()\n          mark_as_advanced(fftw fftw_path)\n       endif()\n \n-\n       add_library(dlib STATIC ${source_files} )\n       target_link_libraries(dlib ${dlib_needed_libraries} )\n \n+      if (UNIX AND NOT DLIB_IN_PROJECT_BUILD)\n+          add_library(dlib-shared SHARED ${source_files} )\n+          target_link_libraries(dlib-shared ${dlib_needed_libraries} )\n+      endif()\n+\n    endif ()  ##### end of if NOT DLIB_ISO_CPP_ONLY ##########################################################\n \n+   # Install the library\n+   if (NOT DLIB_IN_PROJECT_BUILD)\n+       if(UNIX)\n+           set_target_properties(dlib-shared PROPERTIES\n+                                        OUTPUT_NAME dlib \n+                                        VERSION ${VERSION})\n+           install(TARGETS dlib dlib-shared\n+                   EXPORT dlib \n+                   RUNTIME DESTINATION bin # Windows (including cygwin) considers .dll to be runtime artifacts\n+                   LIBRARY DESTINATION lib\n+                   ARCHIVE DESTINATION lib)\n+       else()\n+           install(TARGETS dlib\n+                   EXPORT dlib \n+                   RUNTIME DESTINATION bin # Windows considers .dll to be runtime artifacts\n+                   LIBRARY DESTINATION lib\n+                   ARCHIVE DESTINATION lib)\n+       endif()\n+\n+       install(DIRECTORY ${CMAKE_SOURCE_DIR}/ DESTINATION include/dlib\n+               FILES_MATCHING PATTERN \"*.h\"\n+               REGEX \"${CMAKE_CURRENT_BINARY_DIR}\" EXCLUDE)\n+\n+\n+       configure_file(${CMAKE_SOURCE_DIR}/../dlib/config.h.in ${CMAKE_CURRENT_BINARY_DIR}/config.h)\n+       # overwrite config.h with the configured one\n+       install(FILES ${CMAKE_CURRENT_BINARY_DIR}/config.h DESTINATION include/dlib)\n+\n+       configure_file(${CMAKE_SOURCE_DIR}/../dlib/revision.h.in ${CMAKE_CURRENT_BINARY_DIR}/revision.h)\n+       install(FILES ${CMAKE_CURRENT_BINARY_DIR}/revision.h DESTINATION include/dlib)\n+\n+       install(FILES \"LICENSE.txt\" DESTINATION share/doc/dlib)\n+\n+       ## Config.cmake generation and installation\n+\n+       set(ConfigPackageLocation lib/cmake/dlib)\n+       install(EXPORT dlib\n+            NAMESPACE dlib::\n+            DESTINATION ${ConfigPackageLocation})\n+\n+       set(CONF_INSTALL_PATH \"\\${dlib_CMAKE_DIR}/../../../\")\n+       configure_file(dlibConfig.cmake.in \"${CMAKE_CURRENT_BINARY_DIR}/config/dlibConfig.cmake\" @ONLY)\n+\n+       include(CMakePackageConfigHelpers)\n+       write_basic_package_version_file(\n+           \"${CMAKE_CURRENT_BINARY_DIR}/config/dlibConfigVersion.cmake\"\n+           VERSION ${VERSION}\n+           COMPATIBILITY AnyNewerVersion\n+           )\n+\n+       install(FILES \n+                    \"${CMAKE_CURRENT_BINARY_DIR}/config/dlibConfig.cmake\" \n+                    \"${CMAKE_CURRENT_BINARY_DIR}/config/dlibConfigVersion.cmake\" \n+               DESTINATION ${ConfigPackageLocation})\n+   endif()\n+\n \n    #test for some things that really should be true about the compiler\n    include(TestForSTDNamespace)\n    include(TestForANSIStreamHeaders)\n \n \n-   if (DLIB_LINK_WITH_LIBPNG AND NOT DLIB_ISO_CPP_ONLY)\n+   if (DLIB_PNG_SUPPORT AND NOT DLIB_ISO_CPP_ONLY)\n       add_global_define(DLIB_PNG_SUPPORT)\n    else()\n       remove_global_define(DLIB_PNG_SUPPORT)\n    endif()\n \n-   if (DLIB_LINK_WITH_LIBJPEG AND NOT DLIB_ISO_CPP_ONLY)\n+   if (DLIB_JPEG_SUPPORT AND NOT DLIB_ISO_CPP_ONLY)\n       add_global_define(DLIB_JPEG_SUPPORT)\n    else()\n       remove_global_define(DLIB_JPEG_SUPPORT)\n    endif()\n \n-   if (DLIB_LINK_WITH_FFTW AND NOT DLIB_ISO_CPP_ONLY)\n+   if (DLIB_USE_FFTW AND NOT DLIB_ISO_CPP_ONLY)\n       add_global_define(DLIB_USE_FFTW)\n    else()\n       remove_global_define(DLIB_USE_FFTW)\ndiff --git a/dlib/cmake b/dlib/cmake\nindex d4a0bd2ed0..969ea59a4e 100644\n--- a/dlib/cmake\n+++ b/dlib/cmake\n@@ -1,4 +1,7 @@\n # This is a CMake file meant to be included via include()\n+# It will trigger a compilation of dlib *in the project* \n+# including it\n+set(DLIB_IN_PROJECT_BUILD true)\n \n cmake_minimum_required(VERSION 2.6.4)\n \ndiff --git a/dlib/config.h.in b/dlib/config.h.in\nnew file mode 100644\nindex 0000000000..45fbf3e5a2\n--- /dev/null\n+++ b/dlib/config.h.in\n@@ -0,0 +1,23 @@\n+\n+\n+// If you are compiling dlib as a shared library and installing it somewhere on your system\n+// then it is important that any programs that use dlib agree on the state of the\n+// DLIB_ASSERT statements (i.e. they are either always on or always off).  Therefore,\n+// uncomment one of the following lines to force all DLIB_ASSERTs to either always on or\n+// always off.  If you don't define one of these two macros then DLIB_ASSERT will toggle\n+// automatically depending on the state of certain other macros, which is not what you want\n+// when creating a shared library.\n+#cmakedefine ENABLE_ASSERTS       // asserts always enabled \n+#cmakedefine DLIB_DISABLE_ASSERTS // asserts always disabled \n+\n+#cmakedefine DLIB_ISO_CPP_ONLY\n+#cmakedefine DLIB_NO_GUI_SUPPORT\n+#cmakedefine DLIB_ENABLE_STACK_TRACE\n+\n+// You should also consider telling dlib to link against libjpeg, libpng, fftw, and a BLAS\n+// and LAPACK library.  To do this you need to uncomment the following #defines.\n+#cmakedefine DLIB_JPEG_SUPPORT\n+#cmakedefine DLIB_PNG_SUPPORT\n+#cmakedefine DLIB_USE_FFTW\n+#cmakedefine DLIB_USE_BLAS\n+#cmakedefine DLIB_USE_LAPACK\ndiff --git a/dlib/dlibConfig.cmake.in b/dlib/dlibConfig.cmake.in\nnew file mode 100644\nindex 0000000000..a2d2ec5965\n--- /dev/null\n+++ b/dlib/dlibConfig.cmake.in\n@@ -0,0 +1,39 @@\n+# ===================================================================================\n+#  The dlib CMake configuration file\n+#\n+#             ** File generated automatically, do not modify **\n+#\n+#  Usage from an external project:\n+#    In your CMakeLists.txt, add these lines:\n+#\n+#    FIND_PACKAGE(dlib REQUIRED)\n+#    TARGET_LINK_LIBRARIES(MY_TARGET_NAME ${dlib_LIBRARIES})\n+#\n+#    This file will define the following variables:\n+#      - dlib_LIBRARIES                : The list of all imported targets for dlib modules.\n+#      - dlib_INCLUDE_DIRS             : The dlib include directories.\n+#      - dlib_VERSION                  : The version of this dlib build.\n+#      - dlib_VERSION_MAJOR            : Major version part of this dlib revision.\n+#      - dlib_VERSION_MINOR            : Minor version part of this dlib revision.\n+#\n+# ===================================================================================\n+\n+\n+# Compute paths\n+get_filename_component(dlib_CMAKE_DIR \"${CMAKE_CURRENT_LIST_FILE}\" PATH)\n+\n+if(${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION} VERSION_LESS 2.8)\n+    get_filename_component(dlib_INSTALL_PATH \"@CONF_INSTALL_PATH@\" ABSOLUTE)\n+else()\n+    get_filename_component(dlib_INSTALL_PATH \"@CONF_INSTALL_PATH@\" REALPATH)\n+endif()\n+\n+set(dlib_INCLUDE_DIRS \"${dlib_INSTALL_PATH}/include\")\n+ \n+# Our library dependencies (contains definitions for IMPORTED targets)\n+if(NOT TARGET dlib-shared AND NOT dlib_BINARY_DIR)\n+    include(\"${dlib_CMAKE_DIR}/dlib.cmake\")\n+endif()\n+\n+find_library(dlib_LIBRARIES dlib HINTS ${dlib_INSTALL_PATH}/lib)\n+set(dlib_LIBRARIES ${dlib_LIBRARIES} \"@dlib_needed_libraries@\")\ndiff --git a/dlib/revision.h.in b/dlib/revision.h.in\nnew file mode 100644\nindex 0000000000..e6922c17c6\n--- /dev/null\n+++ b/dlib/revision.h.in\n@@ -0,0 +1,6 @@\n+#ifndef DLIB_REVISION_H\n+#define DLIB_MAJOR_VERSION  @CPACK_PACKAGE_VERSION_MAJOR@\n+#define DLIB_MINOR_VERSION  @CPACK_PACKAGE_VERSION_MINOR@\n+#define DLIB_PATCH_VERSION  @CPACK_PACKAGE_VERSION_PATCH@\n+#endif\n+\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "- **Issue: Missing `.dll` during install**: Ensure that `install(TARGETS dlib-shared RUNTIME DESTINATION bin)` is added to the CMakeLists.txt, so the DLL is correctly copied during installation.\n\n- **Configuration Modifications**: Update `dlib/config.h` to enforce DLIB_ASSERT macros based on the `DLIB_ENABLE_ASSERTS` option, regardless of the build type.\n\n- **Optimize Building**: Avoid double building by setting a variable (e.g., `DLIB_IN_PROJECT_BUILD`) to conditionally control shared library builds.\n\n- **Version Management**: Read version info dynamically from `revision.h` instead of hardcoding in CMake.\n\n- **Testing**: After applying changes, test on multiple platforms to ensure compatibility and that the `.dll` is correctly generated and installed."
      }
    ],
    "codediff_length": 11939
  },
  {
    "index": 71,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/dlib/invoke.h b/dlib/invoke.h\nnew file mode 100644\nindex 0000000000..4abca8a27b\n--- /dev/null\n+++ b/dlib/invoke.h\n@@ -0,0 +1,145 @@\n+// Copyright (C) 2016  Davis E. King (davis@dlib.net)\n+// License: Boost Software License   See LICENSE.txt for the full license.\n+#ifndef DLIB_INVOKE_Hh_\n+#define DLIB_INVOKE_Hh_\n+\n+#include <functional>\n+#include <type_traits>\n+#include \"utility.h\"\n+\n+namespace dlib\n+{\n+    // ----------------------------------------------------------------------------------------\n+    namespace detail {\n+        template< typename F, typename ... Args >\n+        auto INVOKE(F&& fn, Args&& ... args)\n+        -> typename std::enable_if<\n+                std::is_member_pointer<typename std::decay<F>::type>::value,\n+                decltype(std::mem_fn(fn)(std::forward<Args>(args)...))>::type\n+        {\n+            return std::mem_fn(fn)(std::forward<Args>(args)...) ;\n+        }\n+\n+        template< typename F, typename ... Args >\n+        auto INVOKE(F&& fn, Args&& ... args)\n+        -> typename std::enable_if<\n+                !std::is_member_pointer<typename std::decay<F>::type>::value,\n+                decltype(std::forward<F>(fn)(std::forward<Args>(args)...))>::type\n+        {\n+            return std::forward<F>(fn)(std::forward<Args>(args)...);\n+        }\n+    }\n+\n+    template< typename F, typename... Args>\n+    auto invoke(F && f, Args &&... args)\n+    /*!\n+        ensures\n+            - identical to std::invoke(std::forward<F>(f), std::forward<Args>(args)...)\n+            - works with C++11 onwards\n+    !*/\n+    -> decltype(detail::INVOKE(std::forward<F>( f ), std::forward<Args>( args )...))\n+    {\n+        return detail::INVOKE(std::forward<F>( f ), std::forward<Args>( args )...);\n+    }\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    namespace detail\n+    {\n+        template< typename AlwaysVoid, typename, typename...>\n+        struct invoke_traits\n+        {\n+            static constexpr bool value = false;\n+        };\n+\n+        template< typename F, typename... Args >\n+        struct invoke_traits< decltype( void(dlib::invoke(std::declval<F>(), std::declval<Args>()...)) ), F, Args...>\n+        {\n+            static constexpr bool value = true;\n+            using type = decltype( dlib::invoke(std::declval<F>(), std::declval<Args>()...) );\n+        };\n+    }\n+\n+    template< typename F, typename... Args >\n+    struct invoke_result : detail::invoke_traits< void, F, Args...> {};\n+    /*!\n+        ensures\n+            - identical to std::invoke_result<F, Args..>\n+            - works with C++11 onwards\n+    !*/\n+\n+    template< typename F, typename... Args >\n+    using invoke_result_t = typename invoke_result<F, Args...>::type;\n+    /*!\n+        ensures\n+            - identical to std::invoke_result_t<F, Args..>\n+            - works with C++11 onwards\n+    !*/\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    template< typename F, typename... Args >\n+    struct is_invocable : std::integral_constant<bool, detail::invoke_traits< void, F, Args...>::value> {};\n+    /*!\n+        ensures\n+            - identical to std::is_invocable<F, Args..>\n+            - works with C++11 onwards\n+    !*/\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    namespace detail\n+    {\n+        template<typename F, typename Tuple, std::size_t... I>\n+        auto apply_impl(F&& fn, Tuple&& tpl, index_sequence<I...>)\n+        -> decltype(dlib::invoke(std::forward<F>(fn),\n+                                 std::get<I>(std::forward<Tuple>(tpl))...))\n+        {\n+            return dlib::invoke(std::forward<F>(fn),\n+                                std::get<I>(std::forward<Tuple>(tpl))...);\n+        }\n+    }\n+\n+    template<typename F, typename Tuple>\n+    auto apply(F&& fn, Tuple&& tpl)\n+    /*!\n+        ensures\n+            - identical to std::apply(std::forward<F>(f), std::forward<Tuple>(tpl))\n+            - works with C++11 onwards\n+    !*/\n+    -> decltype(detail::apply_impl(std::forward<F>(fn),\n+                                   std::forward<Tuple>(tpl),\n+                                   make_index_sequence<std::tuple_size<typename std::remove_reference<Tuple>::type >::value>{}))\n+    {\n+        return detail::apply_impl(std::forward<F>(fn),\n+                                  std::forward<Tuple>(tpl),\n+                                  make_index_sequence<std::tuple_size<typename std::remove_reference<Tuple>::type >::value>{});\n+    }\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    namespace detail\n+    {\n+        template <class T, class Tuple, std::size_t... I>\n+        constexpr T make_from_tuple_impl( Tuple&& t, index_sequence<I...> )\n+        {\n+            return T(std::get<I>(std::forward<Tuple>(t))...);\n+        }\n+    }\n+\n+    template <class T, class Tuple>\n+    constexpr T make_from_tuple( Tuple&& t )\n+    /*!\n+        ensures\n+            - identical to std::make_from_tuple<T>(std::forward<Tuple>(t))\n+            - works with C++11 onwards\n+    !*/\n+    {\n+        return detail::make_from_tuple_impl<T>(std::forward<Tuple>(t),\n+                                               make_index_sequence<std::tuple_size<typename std::remove_reference<Tuple>::type >::value>{});\n+    }\n+\n+    // ----------------------------------------------------------------------------------------\n+}\n+\n+#endif //DLIB_INVOKE_Hh_\n\\ No newline at end of file\ndiff --git a/dlib/test/CMakeLists.txt b/dlib/test/CMakeLists.txt\nindex ea4cf7768f..47a71a1b22 100644\n--- a/dlib/test/CMakeLists.txt\n+++ b/dlib/test/CMakeLists.txt\n@@ -71,6 +71,7 @@ set (tests\n    hash_table.cpp\n    hog_image.cpp\n    image.cpp\n+   invoke.cpp\n    iosockstream.cpp\n    is_same_object.cpp\n    isotonic_regression.cpp\ndiff --git a/dlib/test/invoke.cpp b/dlib/test/invoke.cpp\nnew file mode 100644\nindex 0000000000..4d555c5a7b\n--- /dev/null\n+++ b/dlib/test/invoke.cpp\n@@ -0,0 +1,256 @@\n+// Copyright (C) 2008  Davis E. King (davis@dlib.net)\n+// License: Boost Software License   See LICENSE.txt for the full license.\n+#include <string>\n+#include <memory>\n+#include <array>\n+#include <tuple>\n+#include <utility>\n+#include <dlib/invoke.h>\n+#include \"tester.h\"\n+\n+namespace\n+{\n+    using namespace test;\n+    using namespace dlib;\n+\n+    logger dlog(\"test.invoke\");\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    static const std::string run1_str1 = \"hello there 1\";\n+    static const std::string run1_str2 = \"hello there 2\";\n+    static const std::string run1_str3 = \"hello there 3\";\n+    static const std::string run1_str4 = \"hello there 4\";\n+    static const std::string run1_str5 = \"hello there 5\";\n+\n+    void func_testargs(int i, std::string ref1, const std::string& ref2, const std::string& ref3, std::string& ref4)\n+    {\n+        DLIB_TEST(i > 0);\n+        DLIB_TEST(ref1 == run1_str1);\n+        DLIB_TEST(ref2 == run1_str2);\n+        DLIB_TEST(ref3 == run1_str3);\n+        DLIB_TEST(ref4 == run1_str4);\n+        ref4 = run1_str5;\n+    }\n+\n+    int func_return_addition(int i, int j)\n+    {\n+        return i + j;\n+    }\n+\n+    void test_functions()\n+    {\n+        static_assert(dlib::is_invocable<decltype(func_testargs), int, std::string, const std::string&, const std::string&, std::string&>::value, \"should be invocable!\");\n+        static_assert(dlib::is_invocable<decltype(func_testargs), int, std::string, std::string, const std::string&, std::string&>::value, \"should be invocable!\");\n+        static_assert(dlib::is_invocable<decltype(func_testargs), int, std::string, std::string, std::string, std::string&>::value, \"should be invocable!\");\n+        static_assert(dlib::is_invocable<decltype(func_testargs), int, std::string, std::string, std::string, std::reference_wrapper<std::string>>::value, \"should be invocable!\");\n+\n+        {\n+            std::string str = run1_str4;\n+            dlib::invoke(func_testargs, 1, run1_str1, run1_str2, std::cref(run1_str3), std::ref(str));\n+            DLIB_TEST(str == run1_str5);\n+        }\n+\n+        {\n+            std::string str = run1_str4;\n+            dlib::apply(func_testargs, std::make_tuple(1, run1_str1, run1_str2, std::cref(run1_str3), std::ref(str)));\n+            DLIB_TEST(str == run1_str5);\n+        }\n+\n+        {\n+            for (int i = -10 ; i <= 10 ; i++)\n+            {\n+                for (int j = -10 ; j <= 10 ; j++)\n+                {\n+                    DLIB_TEST(dlib::invoke(func_return_addition, i, j) == (i+j));\n+                    DLIB_TEST(dlib::apply(func_return_addition, std::make_tuple(i, j)) == (i+j));\n+                }\n+            }\n+        }\n+    }\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    void test_lambdas()\n+    {\n+        {\n+            std::string str = run1_str4;\n+            dlib::invoke([](int i, std::string ref1, const std::string& ref2, const std::string& ref3, std::string& ref4) {\n+                DLIB_TEST(i > 0);\n+                DLIB_TEST(ref1 == run1_str1);\n+                DLIB_TEST(ref2 == run1_str2);\n+                DLIB_TEST(ref3 == run1_str3);\n+                DLIB_TEST(ref4 == run1_str4);\n+                ref4 = run1_str5;\n+            }, 1, run1_str1, run1_str2, std::cref(run1_str3), std::ref(str));\n+            DLIB_TEST(str == run1_str5);\n+        }\n+\n+        {\n+            std::string str = run1_str4;\n+            dlib::apply([](int i, std::string ref1, const std::string& ref2, const std::string& ref3, std::string& ref4) {\n+                DLIB_TEST(i > 0);\n+                DLIB_TEST(ref1 == run1_str1);\n+                DLIB_TEST(ref2 == run1_str2);\n+                DLIB_TEST(ref3 == run1_str3);\n+                DLIB_TEST(ref4 == run1_str4);\n+                ref4 = run1_str5;\n+            }, std::make_tuple(1, run1_str1, run1_str2, std::cref(run1_str3), std::ref(str)));\n+            DLIB_TEST(str == run1_str5);\n+        }\n+\n+        {\n+            for (int i = -10 ; i <= 10 ; i++)\n+            {\n+                for (int j = -10 ; j <= 10 ; j++)\n+                {\n+                    DLIB_TEST(dlib::invoke([](int i, int j) {return i + j;}, i, j) == (i+j));\n+                    DLIB_TEST(dlib::apply([](int i, int j) {return i + j;}, std::make_tuple(i,j)) == (i+j));\n+                }\n+            }\n+        }\n+    }\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    struct example_struct\n+    {\n+        example_struct(int i_ = 0) : i(i_) {}\n+        example_struct(const example_struct&) = delete;\n+        example_struct& operator=(const example_struct&) = delete;\n+        example_struct(example_struct&& other) : i(other.i) {other.i = 0;}\n+        example_struct& operator=(example_struct&& other) {i = other.i; other.i = 0; return *this;}\n+\n+        int get_i() const {return i;}\n+\n+        int i = 0;\n+    };\n+\n+    void test_member_functions_and_data()\n+    {\n+        example_struct obj1(10);\n+        std::unique_ptr<example_struct> obj2(new example_struct(11));\n+        std::shared_ptr<example_struct> obj3(new example_struct(12));\n+\n+        DLIB_TEST(dlib::invoke(&example_struct::get_i,    obj1) == 10);\n+        DLIB_TEST(dlib::invoke(&example_struct::i,        obj1) == 10);\n+        DLIB_TEST(dlib::invoke(&example_struct::get_i,    &obj1) == 10);\n+        DLIB_TEST(dlib::invoke(&example_struct::i,        &obj1) == 10);\n+        DLIB_TEST(dlib::invoke(&example_struct::get_i,    obj2) == 11);\n+        DLIB_TEST(dlib::invoke(&example_struct::i,        obj2) == 11);\n+        DLIB_TEST(dlib::invoke(&example_struct::get_i,    obj3) == 12);\n+        DLIB_TEST(dlib::invoke(&example_struct::i,        obj3) == 12);\n+    }\n+\n+    // ----------------------------------------------------------------------------------------\n+    int return_int()\n+    {\n+        return 0;\n+    }\n+\n+    int& return_int_ref()\n+    {\n+        static int i = 0;\n+        return i;\n+    }\n+\n+    const int& return_int_const_ref()\n+    {\n+        static const int i = 0;\n+        return i;\n+    }\n+\n+    int* return_int_pointer()\n+    {\n+        static int i = 0;\n+        return &i;\n+    }\n+\n+    const int* return_int_const_pointer()\n+    {\n+        static const int i = 0;\n+        return &i;\n+    }\n+\n+    void test_return_types()\n+    {\n+        static_assert(std::is_same<int,         dlib::invoke_result_t<decltype(return_int)>>::value, \"bad type\");\n+        static_assert(std::is_same<int&,        dlib::invoke_result_t<decltype(return_int_ref)>>::value, \"bad type\");\n+        static_assert(std::is_same<const int&,  dlib::invoke_result_t<decltype(return_int_const_ref)>>::value, \"bad type\");\n+        static_assert(std::is_same<int*,        dlib::invoke_result_t<decltype(return_int_pointer)>>::value, \"bad type\");\n+        static_assert(std::is_same<const int*,  dlib::invoke_result_t<decltype(return_int_const_pointer)>>::value, \"bad type\");\n+\n+        static_assert(std::is_same<int, dlib::invoke_result_t<decltype(&example_struct::get_i), const example_struct&>>::value, \"bad type\");\n+        static_assert(std::is_same<int, dlib::invoke_result_t<decltype(&example_struct::get_i), example_struct&>>::value, \"bad type\");\n+        static_assert(std::is_same<int, dlib::invoke_result_t<decltype(&example_struct::get_i), const example_struct*>>::value, \"bad type\");\n+        static_assert(std::is_same<int, dlib::invoke_result_t<decltype(&example_struct::get_i), example_struct*>>::value, \"bad type\");\n+        static_assert(std::is_same<int, dlib::invoke_result_t<decltype(&example_struct::get_i), std::unique_ptr<example_struct>>>::value, \"bad type\");\n+        static_assert(std::is_same<int, dlib::invoke_result_t<decltype(&example_struct::get_i), std::shared_ptr<example_struct>>>::value, \"bad type\");\n+\n+        static_assert(std::is_same<const int&,  dlib::invoke_result_t<decltype(&example_struct::i), const example_struct&>>::value, \"bad type\");\n+        static_assert(std::is_same<int&,        dlib::invoke_result_t<decltype(&example_struct::i), example_struct&>>::value, \"bad type\");\n+        static_assert(std::is_same<const int&,  dlib::invoke_result_t<decltype(&example_struct::i), const example_struct*>>::value, \"bad type\");\n+        static_assert(std::is_same<int&,        dlib::invoke_result_t<decltype(&example_struct::i), example_struct*>>::value, \"bad type\");\n+        static_assert(std::is_same<int&,        dlib::invoke_result_t<decltype(&example_struct::i), std::unique_ptr<example_struct>>>::value, \"bad type\");\n+        static_assert(std::is_same<int&,        dlib::invoke_result_t<decltype(&example_struct::i), std::shared_ptr<example_struct>>>::value, \"bad type\");\n+\n+        auto lambda_func_return_int = []() -> int {return 0;};\n+        static_assert(std::is_same<int, dlib::invoke_result_t<decltype(lambda_func_return_int)>>::value, \"bad type\");\n+    }\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    void test_make_from_tuple()\n+    {\n+        struct multi_args_object\n+        {\n+            multi_args_object(int i_, int j_) : i(i_), j(j_) {}\n+            int i = 0;\n+            int j = 0;\n+        };\n+\n+        {\n+            auto obj = dlib::make_from_tuple<multi_args_object>(std::make_tuple(1, 2));\n+            static_assert(std::is_same<decltype(obj), multi_args_object>::value, \"bad type\");\n+            DLIB_TEST(obj.i == 1);\n+            DLIB_TEST(obj.j == 2);\n+        }\n+\n+        {\n+            std::array<int,2> a = {3, 4};\n+            auto obj = dlib::make_from_tuple<multi_args_object>(a);\n+            static_assert(std::is_same<decltype(obj), multi_args_object>::value, \"bad type\");\n+            DLIB_TEST(obj.i == 3);\n+            DLIB_TEST(obj.j == 4);\n+        }\n+\n+        {\n+            auto obj = dlib::make_from_tuple<multi_args_object>(std::make_pair(5, 6));\n+            static_assert(std::is_same<decltype(obj), multi_args_object>::value, \"bad type\");\n+            DLIB_TEST(obj.i == 5);\n+            DLIB_TEST(obj.j == 6);\n+        }\n+    }\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+\n+    class invoke_tester : public tester\n+    {\n+    public:\n+        invoke_tester(\n+        ) : tester(\"test_invoke\",\n+                   \"Runs tests on dlib::invoke and dlib::apply\")\n+        {}\n+\n+        void perform_test(\n+        )\n+        {\n+            test_functions();\n+            test_lambdas();\n+            test_member_functions_and_data();\n+            test_return_types();\n+            test_make_from_tuple();\n+        }\n+    } a;\n+}\ndiff --git a/dlib/utility.h b/dlib/utility.h\nnew file mode 100644\nindex 0000000000..78af92ed5f\n--- /dev/null\n+++ b/dlib/utility.h\n@@ -0,0 +1,42 @@\n+// Copyright (C) 2016  Davis E. King (davis@dlib.net)\n+// License: Boost Software License   See LICENSE.txt for the full license.\n+#ifndef DLIB_UTILITY_Hh_\n+#define DLIB_UTILITY_Hh_\n+\n+#include <cstddef>\n+\n+/*\n+    This header contains back-ports of C++14/17 functions and type traits\n+    found in <utility> header of the standard library.\n+ */\n+\n+namespace dlib\n+{\n+    template<std::size_t... Ints>\n+    struct index_sequence\n+    {\n+        using type = index_sequence;\n+        using value_type = std::size_t;\n+        static constexpr std::size_t size() noexcept {return sizeof...(Ints);}\n+    };\n+\n+    template<class Sequence1, class Sequence2>\n+    struct merge_and_renumber;\n+\n+    template<std::size_t... I1, std::size_t... I2>\n+    struct merge_and_renumber<index_sequence<I1...>, index_sequence<I2...>>\n+            : index_sequence < I1..., (sizeof...(I1) + I2)... > {};\n+\n+    template<std::size_t N>\n+    struct make_index_sequence\n+        : merge_and_renumber < typename make_index_sequence < N / 2 >::type,\n+          typename make_index_sequence < N - N / 2 >::type > {};\n+\n+    template<> struct make_index_sequence<0> : index_sequence<> {};\n+    template<> struct make_index_sequence<1> : index_sequence<0> {};\n+\n+    template<typename... Ts>\n+    using index_sequence_for = make_index_sequence<sizeof...(Ts)>;\n+}\n+\n+#endif //DLIB_UTILITY_Hh_\n\\ No newline at end of file\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Implement super macro guards to detect `std::invoke`, `std::invoke_result`, and `std::apply` specifically for MSVC. \n\n2. Rename invocable functions to prevent ambiguous calling errors when users define `using namespace std` and `using namespace dlib`.\n\n3. Consider adopting feature detection macros (`#ifdef`) to utilize standard implementations when available, particularly for GCC and Clang.\n\n4. Confirm that `dlib::invoke_result` and `dlib::is_invocable` align with standard behaviors, as discrepancies with MSVC have been noted.\n\n5. Update CI pipelines to build with `/Za` flag for C++ standards compliance, ensuring consistent behavior across compilers. \n\n6. Consider adding `std::make_from_tuple` to `dlib/invoke.h` for enhanced functionality."
      }
    ],
    "codediff_length": 18291
  },
  {
    "index": 72,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.github/workflows/build_cpp.yml b/.github/workflows/build_cpp.yml\nindex 28ee56f8c3..a0035ca09d 100644\n--- a/.github/workflows/build_cpp.yml\n+++ b/.github/workflows/build_cpp.yml\n@@ -30,7 +30,7 @@ defaults:\n     working-directory: dlib/test\n \n jobs:\n-  ubuntu-22-04-gcc-default-cmake-3-10-ffmpeg5:\n+  ubuntu-22-04-gcc-default-cmake-3-17-ffmpeg5:\n     runs-on: 'ubuntu-22.04'\n     steps:\n     - uses: actions/checkout@v2\n@@ -40,18 +40,18 @@ jobs:\n         sudo apt update\n         sudo apt install libwebp-dev make yasm\n         \n-    - name: Cache cmake 3.10.0\n+    - name: Cache cmake 3.17.0\n       uses: actions/cache@v3\n       id: cache-cmake-download\n       with:\n         # cache this folder:\n-        path: ~/cmake-3.10.0-Linux-x86_64\n-        key: cmake-3.10.0_try3\n+        path: ~/cmake-3.17.0-Linux-x86_64\n+        key: cmake-3.17.0_try3\n         \n     - run: |\n         # Get the minimum version of cmake dlib supports\n-        wget https://cmake.org/files/v3.10/cmake-3.10.0-Linux-x86_64.tar.gz\n-        tar -xf cmake-3.10.0-Linux-x86_64.tar.gz -C ~\n+        wget https://cmake.org/files/v3.17/cmake-3.17.0-Linux-x86_64.tar.gz\n+        tar -xf cmake-3.17.0-Linux-x86_64.tar.gz -C ~\n       if: steps.cache-cmake-download.outputs.cache-hit != 'true'\n \n     - name: Cache FFmpeg 5\n@@ -76,7 +76,7 @@ jobs:\n       run: |\n         mkdir build\n         cd build\n-        ~/cmake-3.10.0-Linux-x86_64/bin/cmake -DCMAKE_PREFIX_PATH=/home/runner/ffmpeg-n5.1.3_installation .. \n+        ~/cmake-3.17.0-Linux-x86_64/bin/cmake -DCMAKE_PREFIX_PATH=/home/runner/ffmpeg-n5.1.3_installation .. \n     \n     - name: Build just tests\n       run: |\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 79c938d677..ca00843f18 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-cmake_minimum_required(VERSION 3.10.0)\n+cmake_minimum_required(VERSION 3.17.0)\n \n project(dlib_project)\n \ndiff --git a/dlib/CMakeLists.txt b/dlib/CMakeLists.txt\nindex d1ac826ce3..04b5d92059 100644\n--- a/dlib/CMakeLists.txt\n+++ b/dlib/CMakeLists.txt\n@@ -4,7 +4,7 @@\n #\n \n \n-cmake_minimum_required(VERSION 3.10.0)\n+cmake_minimum_required(VERSION 3.17.0)\n \n set(CMAKE_DISABLE_SOURCE_CHANGES ON)\n set(CMAKE_DISABLE_IN_SOURCE_BUILD ON)\n@@ -13,7 +13,7 @@ if(POLICY CMP0077)\n    cmake_policy(SET CMP0077 NEW)\n endif()\n \n-project(dlib)\n+project(dlib LANGUAGES C CXX)\n \n set(CPACK_PACKAGE_NAME \"dlib\")\n set(CPACK_PACKAGE_VERSION_MAJOR \"20\")\n@@ -26,6 +26,7 @@ if (NOT TARGET dlib)\n    message(STATUS \"Compiling dlib version: ${VERSION}\")\n endif()\n \n+set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ${CMAKE_CURRENT_SOURCE_DIR}/cmake_utils)\n \n include(cmake_utils/set_compiler_specific_options.cmake)\n \n@@ -104,17 +105,6 @@ elseif(BUILD_SHARED_LIBS)\n    endif()\n endif()\n \n-\n-if (CMAKE_VERSION VERSION_LESS \"3.9.0\")\n-   # Set only because there are old target_link_libraries() statements in the\n-   # FindCUDA.cmake file that comes with CMake that error out if the new behavior\n-   # is used.  In newer versions of CMake we can instead set CUDA_LINK_LIBRARIES_KEYWORD which fixes this issue.\n-   cmake_policy(SET CMP0023 OLD)\n-else()\n-   set(CUDA_LINK_LIBRARIES_KEYWORD PUBLIC)\n-endif()\n-\n-\n macro (enable_preprocessor_switch option_name)\n    list(APPEND active_preprocessor_switches \"-D${option_name}\")\n endmacro()\n@@ -249,7 +239,6 @@ if (NOT TARGET dlib)\n       option(DLIB_USE_BLAS ${DLIB_USE_BLAS_STR} ON)\n       option(DLIB_USE_LAPACK ${DLIB_USE_LAPACK_STR} ON)\n       option(DLIB_USE_CUDA ${DLIB_USE_CUDA_STR} ON)\n-      set(DLIB_USE_CUDA_COMPUTE_CAPABILITIES 50 CACHE STRING ${DLIB_USE_CUDA_COMPUTE_CAPABILITIES_STR})\n       option(DLIB_PNG_SUPPORT ${DLIB_PNG_SUPPORT_STR} ON)\n       option(DLIB_GIF_SUPPORT ${DLIB_GIF_SUPPORT_STR} ON)\n       option(DLIB_WEBP_SUPPORT ${DLIB_WEBP_SUPPORT_STR} ON)\n@@ -649,178 +638,75 @@ if (NOT TARGET dlib)\n \n \n       if (DLIB_USE_CUDA)\n-         find_package(CUDA 7.5)\n-\n-         if (CUDA_VERSION VERSION_GREATER 9.1 AND CMAKE_VERSION VERSION_LESS 3.12.2)\n-            # This bit of weirdness is to work around a bug in cmake \n-            list(REMOVE_ITEM CUDA_CUBLAS_LIBRARIES \"CUDA_cublas_device_LIBRARY-NOTFOUND\")\n-         endif()\n-\n-\n-         if (CUDA_FOUND AND MSVC AND NOT CUDA_CUBLAS_LIBRARIES AND \"${CMAKE_SIZEOF_VOID_P}\" EQUAL \"4\")\n-            message(WARNING \"You have CUDA installed, but we can't use it unless you put visual studio in 64bit mode.\")\n-            set(CUDA_FOUND 0)\n-         endif()\n-\n-         if (NOT CUDA_CUBLAS_LIBRARIES)\n-            message(STATUS \"Found CUDA, but CMake was unable to find the cuBLAS libraries that should be part of every basic CUDA \"\n-               \"install. Your CUDA install is somehow broken or incomplete. Since cuBLAS is required for dlib to use CUDA we won't use CUDA.\")\n-            set(CUDA_FOUND 0)\n-         endif()\n-\n-         if (CUDA_FOUND)\n-\n-            # There is some bug in cmake that causes it to mess up the\n-            # -std=c++11 option if you let it propagate it to nvcc in some\n-            # cases.  So instead we disable this and manually include\n-            # things from CMAKE_CXX_FLAGS in the CUDA_NVCC_FLAGS list below.\n-            if (APPLE)\n-               set(CUDA_PROPAGATE_HOST_FLAGS OFF)\n-               # Grab all the -D flags from CMAKE_CXX_FLAGS so we can pass them\n-               # to nvcc.\n-               string(REGEX MATCHALL \"-D[^ ]*\" FLAGS_FOR_NVCC \"${CMAKE_CXX_FLAGS}\")\n-\n-               # Check if we are being built as part of a pybind11 module. \n-               if (COMMAND pybind11_add_module)\n-                  # Don't export unnecessary symbols.\n-                  list(APPEND FLAGS_FOR_NVCC \"-Xcompiler=-fvisibility=hidden\")\n-               endif()\n-            endif()\n-\n-            set(CUDA_HOST_COMPILATION_CPP ON)\n-            string(REPLACE \",\" \";\" DLIB_CUDA_COMPUTE_CAPABILITIES ${DLIB_USE_CUDA_COMPUTE_CAPABILITIES})\n-            foreach(CAP ${DLIB_CUDA_COMPUTE_CAPABILITIES})\n-                list(APPEND CUDA_NVCC_FLAGS \"-gencode arch=compute_${CAP},code=[sm_${CAP},compute_${CAP}]\")\n-            endforeach()\n-            # Note that we add __STRICT_ANSI__ to avoid freaking out nvcc with gcc specific\n-            # magic in the standard C++ header files (since nvcc uses gcc headers on linux).\n-            list(APPEND CUDA_NVCC_FLAGS \"-D__STRICT_ANSI__;-D_MWAITXINTRIN_H_INCLUDED;-D_FORCE_INLINES;${FLAGS_FOR_NVCC}\")\n-            list(APPEND CUDA_NVCC_FLAGS ${active_preprocessor_switches})\n-            if (NOT DLIB_IN_PROJECT_BUILD)\n-               LIST(APPEND CUDA_NVCC_FLAGS -DDLIB__CMAKE_GENERATED_A_CONFIG_H_FILE)\n-            endif()\n-            if (NOT MSVC)\n-               list(APPEND CUDA_NVCC_FLAGS \"-std=c++14\")\n-            endif()\n-            if (CMAKE_POSITION_INDEPENDENT_CODE)\n-               # sometimes this setting isn't propagated to NVCC, which then causes the\n-               # compile to fail.  So make sure it's propagated.\n-               if (NOT MSVC) # Visual studio doesn't have -fPIC so don't do it in that case.\n-                  list(APPEND CUDA_NVCC_FLAGS \"-Xcompiler -fPIC\")\n-               endif()\n+         find_package(CUDAToolkit)\n+      \n+         if (CUDAToolkit_FOUND AND CUDAToolkit_NVCC_EXECUTABLE)\n+            set(CMAKE_CUDA_COMPILER ${CUDAToolkit_NVCC_EXECUTABLE})\n+\n+            # Set USER_DID_NOT_SPECIFY_WHAT_CUDA_ARCH_TO_USE before calling\n+            # enable_language(CUDA) because enable_language() sets\n+            # CMAKE_CUDA_ARCHITECTURES to a default that isn't especially\n+            # helpful for most users in newer cmake versions.  E.g. it picks\n+            # the oldest supported arch the cuda toolkit you have can build for\n+            # which is often so old your GPU can't actually run the resulting\n+            # kernels.\n+            set(USER_DID_NOT_SPECIFY_WHAT_CUDA_ARCH_TO_USE FALSE)\n+            if (NOT DEFINED CMAKE_CUDA_ARCHITECTURES AND (NOT DEFINED ENV{CUDAARCHS} OR \"$ENV{CUDAARCHS}\" STREQUAL \"\"))\n+               set(USER_DID_NOT_SPECIFY_WHAT_CUDA_ARCH_TO_USE TRUE)\n             endif()\n \n-            include(cmake_utils/test_for_cudnn/find_cudnn.txt)\n+            enable_language(CUDA)\n \n-            if (cudnn AND cudnn_include AND NOT DEFINED cuda_test_compile_worked AND NOT DEFINED cudnn_test_compile_worked)\n-               # make sure cuda is really working by doing a test compile\n-               message(STATUS \"Building a CUDA test project to see if your compiler is compatible with CUDA...\")\n-\n-               set(CUDA_TEST_CMAKE_FLAGS \n-                  \"-DCMAKE_PREFIX_PATH=${CMAKE_PREFIX_PATH}\"\n-                  \"-DCMAKE_INCLUDE_PATH=${CMAKE_INCLUDE_PATH}\"\n-                  \"-DCMAKE_LIBRARY_PATH=${CMAKE_LIBRARY_PATH}\")\n-\n-               if (NOT MSVC) # see https://github.com/davisking/dlib/issues/363\n-                  list(APPEND CUDA_TEST_CMAKE_FLAGS \"-DCUDA_HOST_COMPILER=${CUDA_HOST_COMPILER}\")\n-               endif()\n-\n-               try_compile(cuda_test_compile_worked \n-                  ${PROJECT_BINARY_DIR}/cuda_test_build \n-                  ${PROJECT_SOURCE_DIR}/cmake_utils/test_for_cuda cuda_test\n-                  CMAKE_FLAGS ${CUDA_TEST_CMAKE_FLAGS}\n-                  OUTPUT_VARIABLE try_compile_output_message\n-                  )\n-               if (NOT cuda_test_compile_worked)\n-                  string(REPLACE \"\\n\" \"\\n   ***   \" try_compile_output_message \"${try_compile_output_message}\")\n-                  message(STATUS \"*****************************************************************************************************************\")\n-                  message(STATUS \"*** CUDA was found but your compiler failed to compile a simple CUDA program so dlib isn't going to use CUDA. \")\n-                  message(STATUS \"*** The output of the failed CUDA test compile is shown below: \")\n-                  message(STATUS \"*** \")\n-                  message(STATUS \"***   ${try_compile_output_message}\")\n-                  message(STATUS \"*****************************************************************************************************************\")\n+            # If the user didn't say what cuda arch they want to use try to pick something reasonable\n+            if(USER_DID_NOT_SPECIFY_WHAT_CUDA_ARCH_TO_USE)\n+               if (CMAKE_VERSION VERSION_GREATER_EQUAL 3.24)\n+                  # Auto-detect host GPU(s); safest default on modern CMake.\n+                  set(CMAKE_CUDA_ARCHITECTURES native)  # requires CMake \u2265 3.24\n                else()\n-                  message(STATUS \"Building a cuDNN test project to check if you have the right version of cuDNN installed...\")\n-                  try_compile(cudnn_test_compile_worked \n-                     ${PROJECT_BINARY_DIR}/cudnn_test_build \n-                     ${PROJECT_SOURCE_DIR}/cmake_utils/test_for_cudnn cudnn_test\n-                     CMAKE_FLAGS ${CUDA_TEST_CMAKE_FLAGS}\n-                     OUTPUT_VARIABLE try_compile_output_message\n-                     )\n-                  if (NOT cudnn_test_compile_worked)\n-                     string(REPLACE \"\\n\" \"\\n   ***   \" try_compile_output_message \"${try_compile_output_message}\")\n-                     message(STATUS \"*****************************************************************************************************\")\n-                     message(STATUS \"*** Found cuDNN, but we failed to compile the dlib/cmake_utils/test_for_cudnn project. \")\n-                     message(STATUS \"*** You either have an unsupported version of cuDNN or something is wrong with your cudDNN install.\")\n-                     message(STATUS \"*** Since a functional cuDNN is not found DLIB WILL NOT USE CUDA. \")\n-                     message(STATUS \"*** The output of the failed test_for_cudnn build is: \")\n-                     message(STATUS \"*** \")\n-                     message(STATUS \"***   ${try_compile_output_message}\")\n-                     message(STATUS \"*****************************************************************************************************\")\n+                  # Fallback by nvcc version to avoid asking for archs it doesn't know yet\n+                  if (CMAKE_CUDA_COMPILER_VERSION VERSION_LESS 11)\n+                     # CUDA 10.x and older\n+                     set(CMAKE_CUDA_ARCHITECTURES 52;60;61;70;75)\n+                  elseif (CMAKE_CUDA_COMPILER_VERSION VERSION_LESS 12)\n+                     # CUDA 11.x\n+                     set(CMAKE_CUDA_ARCHITECTURES 60;61;70;75;80;86)\n+                  else()\n+                     # CUDA 12.x+\n+                     # (Keep this conservative; add 89/90 only on toolkits that support them.)\n+                     set(CMAKE_CUDA_ARCHITECTURES 70;75;80;86;89;90)\n                   endif()\n                endif()\n             endif()\n \n-            # Find where cuSOLVER is since the FindCUDA cmake package doesn't\n-            # bother to look for it in older versions of cmake.\n-            if (NOT CUDA_cusolver_LIBRARY)\n-               get_filename_component(cuda_blas_path \"${CUDA_CUBLAS_LIBRARIES}\" DIRECTORY)\n-               find_library(CUDA_cusolver_LIBRARY cusolver HINTS ${cuda_blas_path})\n-               # CUDA 10.1 doesn't install symbolic links to libcusolver.so in\n-               # the usual place.  This is probably a bug in the cuda\n-               # installer.  In any case, If we haven't found cusolver yet go\n-               # look in the cuda install folder for it.  New versions of cmake\n-               # do this correctly, but older versions need help.\n-               if (NOT CUDA_cusolver_LIBRARY)\n-                  find_library(CUDA_cusolver_LIBRARY cusolver HINTS \n-                     /usr/local/cuda/lib64/\n-                     )\n-               endif()\n-               mark_as_advanced(CUDA_cusolver_LIBRARY)\n-            endif()\n-            # Also find OpenMP since cuSOLVER needs it.  Importantly, we only\n-            # look for one to link to if our use of BLAS, specifically the\n-            # Intel MKL, hasn't already decided what to use.  This is because\n-            # it makes the MKL bug out if you link to another openmp lib other\n-            # than Intel's when you use the MKL. I'm also not really sure when\n-            # explicit linking to openmp became unnecessary, but for\n-            # sufficiently older versions of cuda it was needed.  Then in\n-            # versions of cmake newer than 3.11 linking to openmp started to\n-            # mess up the switches passed to nvcc, so you can't just leave\n-            # these \"try to link to openmp\" statements here going forward.  Fun\n-            # times.\n-            if (CUDA_VERSION VERSION_LESS \"9.1\" AND NOT openmp_libraries AND NOT MSVC AND NOT XCODE AND NOT APPLE)\n-               find_package(OpenMP)\n-               if (OPENMP_FOUND)\n-                  set(openmp_libraries ${OpenMP_CXX_FLAGS}) \n-               else()\n-                  message(STATUS \"*** Didn't find OpenMP, which is required to use CUDA. ***\")\n-                  set(CUDA_FOUND 0)\n+            find_package(CUDNN)\n+\n+            if(CUDNN_FOUND)\n+               set(source_files ${source_files} \n+                  cuda/cuda_dlib.cu \n+                  cuda/cudnn_dlibapi.cpp\n+                  cuda/cublas_dlibapi.cpp\n+                  cuda/cusolver_dlibapi.cu\n+                  cuda/curand_dlibapi.cpp\n+                  cuda/cuda_data_ptr.cpp\n+                  cuda/gpu_data.cpp\n+                  )\n+               list (APPEND dlib_needed_private_libraries CUDA::cublas)\n+               list (APPEND dlib_needed_private_libraries ${CUDNN_LIBRARY_PATH})\n+               list (APPEND dlib_needed_private_libraries CUDA::curand)\n+               list (APPEND dlib_needed_private_libraries CUDA::cusolver)\n+               list (APPEND dlib_needed_private_libraries CUDA::cudart)\n+               if(openmp_libraries)\n+                  list (APPEND dlib_needed_private_libraries ${openmp_libraries})\n                endif()\n-            endif()\n-         endif()\n \n-         if (CUDA_FOUND AND cudnn AND cuda_test_compile_worked AND cudnn_test_compile_worked AND cudnn_include)\n-            set(source_files ${source_files} \n-               cuda/cuda_dlib.cu \n-               cuda/cudnn_dlibapi.cpp\n-               cuda/cublas_dlibapi.cpp\n-               cuda/cusolver_dlibapi.cu\n-               cuda/curand_dlibapi.cpp\n-               cuda/cuda_data_ptr.cpp\n-               cuda/gpu_data.cpp\n-               )\n-            list (APPEND dlib_needed_private_libraries ${CUDA_CUBLAS_LIBRARIES})\n-            list (APPEND dlib_needed_private_libraries ${cudnn})\n-            list (APPEND dlib_needed_private_libraries ${CUDA_curand_LIBRARY})\n-            list (APPEND dlib_needed_private_libraries ${CUDA_cusolver_LIBRARY})\n-            list (APPEND dlib_needed_private_libraries ${CUDA_CUDART_LIBRARY})\n-            if(openmp_libraries)\n-               list (APPEND dlib_needed_private_libraries ${openmp_libraries})\n-            endif()\n-\n-            include_directories(${cudnn_include})\n-            message(STATUS \"Enabling CUDA support for dlib.  DLIB WILL USE CUDA, compute capabilities: ${DLIB_CUDA_COMPUTE_CAPABILITIES}\")\n+               include_directories(${CUDAToolkit_INCLUDE_DIRS} ${CUDNN_INCLUDE_PATH})\n+               message(STATUS \"Enabling CUDA support for dlib.  DLIB WILL USE CUDA using cuda arch ${CMAKE_CUDA_ARCHITECTURES}.  If you don't want to use that arch set the CUDAARCHS env var or CMAKE_CUDA_ARCHITECTURES cmake variable.\")\n+            else()\n+                set(DLIB_USE_CUDA OFF CACHE STRING ${DLIB_USE_BLAS_STR} FORCE )\n+               toggle_preprocessor_switch(DLIB_USE_CUDA)\n+               message(STATUS \"DID NOT FIND CUDNN\")\n+               message(STATUS \"Disabling CUDA support for dlib.  DLIB WILL NOT USE CUDA\")\n+               endif()\n          else()\n             set(DLIB_USE_CUDA OFF CACHE STRING ${DLIB_USE_BLAS_STR} FORCE )\n             toggle_preprocessor_switch(DLIB_USE_CUDA)\n@@ -875,15 +761,8 @@ if (NOT TARGET dlib)\n          endif()\n       endif()\n \n-      # Tell CMake to build dlib via add_library()/cuda_add_library()\n-      if (DLIB_USE_CUDA)\n-         # The old cuda_add_library() command doesn't support CMake's newer dependency\n-         # stuff, so we have to set the include path manually still, which we do here.\n-         include_directories(${dlib_needed_public_includes})\n-         cuda_add_library(dlib ${source_files} )\n-      else()\n-         add_library(dlib ${source_files} )\n-      endif()\n+      add_library(dlib ${source_files})\n+\n \n    endif ()  ##### end of if NOT DLIB_ISO_CPP_ONLY ##########################################################\n \ndiff --git a/dlib/cmake_utils/FindCUDNN.cmake b/dlib/cmake_utils/FindCUDNN.cmake\nnew file mode 100644\nindex 0000000000..c5d88ae6ab\n--- /dev/null\n+++ b/dlib/cmake_utils/FindCUDNN.cmake\n@@ -0,0 +1,81 @@\n+# Find the CUDNN libraries\n+#\n+# The following variables are optionally searched for defaults\n+#  CUDNN_ROOT: Base directory where CUDNN is found\n+#  CUDNN_INCLUDE_DIR: Directory where CUDNN header is searched for\n+#  CUDNN_LIBRARY: Directory where CUDNN library is searched for\n+#  CUDNN_STATIC: Are we looking for a static library? (default: no)\n+#\n+# The following are set after configuration is done:\n+#  CUDNN_FOUND\n+#  CUDNN_INCLUDE_PATH\n+#  CUDNN_LIBRARY_PATH\n+#\n+\n+include(FindPackageHandleStandardArgs)\n+\n+set(CUDNN_ROOT $ENV{CUDNN_ROOT_DIR} CACHE PATH \"Folder containing NVIDIA cuDNN\")\n+if (DEFINED $ENV{CUDNN_ROOT_DIR})\n+  message(WARNING \"CUDNN_ROOT_DIR is deprecated. Please set CUDNN_ROOT instead.\")\n+endif()\n+list(APPEND CUDNN_ROOT $ENV{CUDNN_ROOT_DIR} ${CUDA_TOOLKIT_ROOT_DIR})\n+\n+# Compatible layer for CMake <3.12. CUDNN_ROOT will be accounted in for searching paths and libraries for CMake >=3.12.\n+list(APPEND CMAKE_PREFIX_PATH ${CUDNN_ROOT})\n+\n+set(CUDNN_INCLUDE_DIR $ENV{CUDNN_INCLUDE_DIR} CACHE PATH \"Folder containing NVIDIA cuDNN header files\")\n+\n+set(CUDA_VERSION \"${CUDAToolkit_VERSION_MAJOR}.${CUDAToolkit_VERSION_MINOR}\")\n+\n+find_path(CUDNN_INCLUDE_PATH cudnn.h\n+  HINTS ${CUDNN_INCLUDE_DIR} ENV CUDNN_INCLUDE_DIR  ENV CUDNN_HOME\n+  PATHS /usr/local /usr/local/cuda \"C:/Program Files/NVIDIA/CUDNN/*/include/${CUDA_VERSION}\" \"C:/Program Files/NVIDIA/CUDNN/*/include/*\" ENV CPATH\n+  PATH_SUFFIXES cuda/include cuda include)\n+\n+option(CUDNN_STATIC \"Look for static CUDNN\" OFF)\n+if (CUDNN_STATIC)\n+  set(CUDNN_LIBNAME \"libcudnn_static.a\")\n+else()\n+  set(CUDNN_LIBNAME \"cudnn\")\n+endif()\n+\n+set(CUDNN_LIBRARY $ENV{CUDNN_LIBRARY} CACHE PATH \"Path to the cudnn library file (e.g., libcudnn.so)\")\n+if (CUDNN_LIBRARY MATCHES \".*cudnn_static.a\" AND NOT CUDNN_STATIC)\n+  message(WARNING \"CUDNN_LIBRARY points to a static library (${CUDNN_LIBRARY}) but CUDNN_STATIC is OFF.\")\n+endif()\n+\n+find_library(CUDNN_LIBRARY_PATH ${CUDNN_LIBNAME}\n+  PATHS ${CUDNN_LIBRARY} /usr/local /usr/local/cuda  \"C:/Program Files/NVIDIA/CUDNN/*/lib/${CUDA_VERSION}/x64\" \"C:/Program Files/NVIDIA/CUDNN/*/lib/${CUDA_VERSION}\" \"C:/Program Files/NVIDIA/CUDNN/*/lib/*\" ENV LD_LIBRARY_PATH\n+  PATH_SUFFIXES lib lib64 cuda/lib cuda/lib64 lib/x64)\n+\n+find_package_handle_standard_args(CUDNN DEFAULT_MSG CUDNN_LIBRARY_PATH CUDNN_INCLUDE_PATH)\n+\n+if(CUDNN_FOUND)\n+  # Get cuDNN version\n+  if(EXISTS ${CUDNN_INCLUDE_PATH}/cudnn_version.h)\n+    file(READ ${CUDNN_INCLUDE_PATH}/cudnn_version.h CUDNN_HEADER_CONTENTS)\n+  else()\n+    file(READ ${CUDNN_INCLUDE_PATH}/cudnn.h CUDNN_HEADER_CONTENTS)\n+  endif()\n+  string(REGEX MATCH \"define CUDNN_MAJOR * +([0-9]+)\"\n+               CUDNN_VERSION_MAJOR \"${CUDNN_HEADER_CONTENTS}\")\n+  string(REGEX REPLACE \"define CUDNN_MAJOR * +([0-9]+)\" \"\\\\1\"\n+               CUDNN_VERSION_MAJOR \"${CUDNN_VERSION_MAJOR}\")\n+  string(REGEX MATCH \"define CUDNN_MINOR * +([0-9]+)\"\n+               CUDNN_VERSION_MINOR \"${CUDNN_HEADER_CONTENTS}\")\n+  string(REGEX REPLACE \"define CUDNN_MINOR * +([0-9]+)\" \"\\\\1\"\n+               CUDNN_VERSION_MINOR \"${CUDNN_VERSION_MINOR}\")\n+  string(REGEX MATCH \"define CUDNN_PATCHLEVEL * +([0-9]+)\"\n+               CUDNN_VERSION_PATCH \"${CUDNN_HEADER_CONTENTS}\")\n+  string(REGEX REPLACE \"define CUDNN_PATCHLEVEL * +([0-9]+)\" \"\\\\1\"\n+               CUDNN_VERSION_PATCH \"${CUDNN_VERSION_PATCH}\")\n+  # Assemble cuDNN version\n+  if(NOT CUDNN_VERSION_MAJOR)\n+    set(CUDNN_VERSION \"?\")\n+  else()\n+    set(CUDNN_VERSION\n+        \"${CUDNN_VERSION_MAJOR}.${CUDNN_VERSION_MINOR}.${CUDNN_VERSION_PATCH}\")\n+  endif()\n+endif()\n+\n+mark_as_advanced(CUDNN_ROOT CUDNN_INCLUDE_DIR CUDNN_LIBRARY CUDNN_VERSION)\ndiff --git a/dlib/cmake_utils/dlibConfig.cmake.in b/dlib/cmake_utils/dlibConfig.cmake.in\nindex 2667a2e718..4f7ea1ee28 100644\n--- a/dlib/cmake_utils/dlibConfig.cmake.in\n+++ b/dlib/cmake_utils/dlibConfig.cmake.in\n@@ -35,6 +35,10 @@ set(dlib_LIBRARIES dlib::dlib)\n set(dlib_LIBS      dlib::dlib)\n set(dlib_INCLUDE_DIRS \"@CMAKE_INSTALL_FULL_INCLUDEDIR@\" \"@dlib_needed_includes@\")\n \n+if (@DLIB_USE_CUDA@)\n+   find_package(CUDAToolkit)\n+endif()\n+\n mark_as_advanced(dlib_LIBRARIES)\n mark_as_advanced(dlib_LIBS)\n mark_as_advanced(dlib_INCLUDE_DIRS)\ndiff --git a/dlib/cmake_utils/test_for_cuda/CMakeLists.txt b/dlib/cmake_utils/test_for_cuda/CMakeLists.txt\ndeleted file mode 100644\nindex f5b3b95964..0000000000\n--- a/dlib/cmake_utils/test_for_cuda/CMakeLists.txt\n+++ /dev/null\n@@ -1,14 +0,0 @@\n-\n-cmake_minimum_required(VERSION 3.10.0)\n-project(cuda_test)\n-\n-include_directories(../../cuda)\n-add_definitions(-DDLIB_USE_CUDA)\n-\n-# Override the FindCUDA.cmake setting to avoid duplication of host flags if using a toolchain:\n-option(CUDA_PROPAGATE_HOST_FLAGS \"Propage C/CXX_FLAGS and friends to the host compiler via -Xcompile\" OFF)\n-find_package(CUDA 7.5 REQUIRED)\n-set(CUDA_HOST_COMPILATION_CPP ON)\n-list(APPEND CUDA_NVCC_FLAGS \"-arch=sm_50;-std=c++14;-D__STRICT_ANSI__;-D_MWAITXINTRIN_H_INCLUDED;-D_FORCE_INLINES\")\n-\n-cuda_add_library(cuda_test STATIC cuda_test.cu )\ndiff --git a/dlib/cmake_utils/test_for_cuda/cuda_test.cu b/dlib/cmake_utils/test_for_cuda/cuda_test.cu\ndeleted file mode 100644\nindex fb1ffe0dad..0000000000\n--- a/dlib/cmake_utils/test_for_cuda/cuda_test.cu\n+++ /dev/null\n@@ -1,21 +0,0 @@\n-// Copyright (C) 2015  Davis E. King (davis@dlib.net)\n-// License: Boost Software License   See LICENSE.txt for the full license.\n-\n-#include \"cuda_utils.h\"\n-#include \"cuda_dlib.h\"\n-\n-\n-// ------------------------------------------------------------------------------------\n-\n-__global__ void cuda_add_arrays(const float* a, const float* b, float* out, size_t n)\n-{\n-   out[0] += a[0]+b[0];\n-}\n-\n-void add_arrays()\n-{\n-   cuda_add_arrays<<<512,512>>>(0,0,0,0);\n-}\n-\n-// ------------------------------------------------------------------------------------\n-\ndiff --git a/dlib/cmake_utils/test_for_cudnn/CMakeLists.txt b/dlib/cmake_utils/test_for_cudnn/CMakeLists.txt\ndeleted file mode 100644\nindex 3d748eb562..0000000000\n--- a/dlib/cmake_utils/test_for_cudnn/CMakeLists.txt\n+++ /dev/null\n@@ -1,18 +0,0 @@\n-\r\n-cmake_minimum_required(VERSION 3.10.0)\r\n-project(cudnn_test)\r\n-\r\n-# Override the FindCUDA.cmake setting to avoid duplication of host flags if using a toolchain:\r\n-option(CUDA_PROPAGATE_HOST_FLAGS \"Propage C/CXX_FLAGS and friends to the host compiler via -Xcompile\" OFF)\r\n-find_package(CUDA 7.5 REQUIRED)\r\n-set(CUDA_HOST_COMPILATION_CPP ON)\r\n-list(APPEND CUDA_NVCC_FLAGS \"-arch=sm_50;-std=c++14;-D__STRICT_ANSI__\")\r\n-add_definitions(-DDLIB_USE_CUDA)\r\n-\r\n-include(find_cudnn.txt)\r\n-\r\n-if (cudnn_include AND cudnn)\r\n-   include_directories(${cudnn_include})\r\n-   cuda_add_library(cudnn_test STATIC ../../cuda/cudnn_dlibapi.cpp ${cudnn} )\r\n-   target_compile_features(cudnn_test PUBLIC cxx_std_14)\r\n-endif()\r\ndiff --git a/dlib/cmake_utils/test_for_cudnn/find_cudnn.txt b/dlib/cmake_utils/test_for_cudnn/find_cudnn.txt\ndeleted file mode 100644\nindex b38d5f26da..0000000000\n--- a/dlib/cmake_utils/test_for_cudnn/find_cudnn.txt\n+++ /dev/null\n@@ -1,24 +0,0 @@\n-\n-message(STATUS \"Looking for cuDNN install...\")\n-# Look for cudnn, we will look in the same place as other CUDA\n-# libraries and also a few other places as well.\n-find_path(cudnn_include cudnn.h\n-    HINTS ${CUDA_INCLUDE_DIRS} ENV CUDNN_INCLUDE_DIR  ENV CUDNN_HOME\n-    PATHS /usr/local /usr/local/cuda \"C:/Program Files/NVIDIA/CUDNN/*/include/${CUDA_VERSION}\" \"C:/Program Files/NVIDIA/CUDNN/*/include/*\" ENV CPATH\n-    PATH_SUFFIXES include\n-    )\n-get_filename_component(cudnn_hint_path \"${CUDA_CUBLAS_LIBRARIES}\" PATH)\n-find_library(cudnn cudnn\n-    HINTS ${cudnn_hint_path} ENV CUDNN_LIBRARY_DIR  ENV CUDNN_HOME \n-    PATHS /usr/local /usr/local/cuda \"C:/Program Files/NVIDIA/CUDNN/*/lib/${CUDA_VERSION}\" \"C:/Program Files/NVIDIA/CUDNN/*/lib/*\" ENV LD_LIBRARY_PATH\n-    PATH_SUFFIXES lib64 lib x64\n-    )\n-mark_as_advanced(cudnn cudnn_include)\n-\n-if (cudnn AND cudnn_include)\n-    message(STATUS \"Found cuDNN: \" ${cudnn})\n-else()\n-    message(STATUS \"*** cuDNN V5.0 OR GREATER NOT FOUND.                                                       ***\")\n-    message(STATUS \"*** Dlib requires cuDNN V5.0 OR GREATER.  Since cuDNN is not found DLIB WILL NOT USE CUDA. ***\")\n-    message(STATUS \"*** If you have cuDNN then set CMAKE_PREFIX_PATH to include cuDNN's folder.                ***\")\n-endif()\ndiff --git a/tools/python/dlib/__init__.py.in b/tools/python/dlib/__init__.py.in\nindex 4a289ed5e0..6aff592629 100644\n--- a/tools/python/dlib/__init__.py.in\n+++ b/tools/python/dlib/__init__.py.in\n@@ -8,13 +8,22 @@ def add_lib_to_dll_path(path):\n     \"\"\"\n     try:\n         import os\n-        os.add_dll_directory(os.path.join(os.path.dirname(path), '../../bin'))\n+\n+        # Work out where the various bin folders that hold nvidia's dlls are.\n+        lib_folder = os.path.dirname(path)\n+        dll_folder = lib_folder.replace(\"/lib/\", \"/bin/\")\n+\n+        if os.path.isdir(dll_folder):\n+            os.add_dll_directory(dll_folder)\n+        else:\n+            os.add_dll_directory(os.path.dirname(dll_folder))\n     except (AttributeError,KeyError,FileNotFoundError):\n         pass\n \n if '@DLIB_USE_CUDA@' == 'ON':\n-    add_lib_to_dll_path('@cudnn@')\n-    add_lib_to_dll_path('@CUDA_CUDART_LIBRARY@')\n+    add_lib_to_dll_path('@CUDNN_LIBRARY_PATH@')\n+    add_lib_to_dll_path('@CUDA_CUDART@')\n+\n \n from _dlib_pybind11 import *\n from _dlib_pybind11 import __version__, __time_compiled__\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Pkg-config Issues**: Current implementation of using CMake imported targets is incompatible with pkg-config. Consider dropping pkg-config support from Dlib to streamline the CMake update process.\n\n2. **CUDA Capabilities Warning**: The warning regarding CUDA compute capabilities indicates that setting it to \"all\" is problematic. Investigate adjustments to avoid this issue while maintaining functionality.\n\n3. **CMake Configuration**: Implement `find_package(CUDAToolkit)` and `find_package(CUDNN)` along with `cmake_dependent_option()` to simplify option handling without unnecessary toggling. \n\n4. **Linking Errors**: Review linking issues with `dlib::cuda::` symbols post-build; ensure all necessary CUDA sources are included before linking.\n\n5. **Code Modification**: Remove `cmake_dependent_option()` from within the `if(DLIB_USE_CUDA)` block to improve clarity and functionality."
      }
    ],
    "codediff_length": 28167
  },
  {
    "index": 73,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/dlib/image_processing/shape_predictor.h b/dlib/image_processing/shape_predictor.h\nindex 26e99ae26e..7446bd0e43 100644\n--- a/dlib/image_processing/shape_predictor.h\n+++ b/dlib/image_processing/shape_predictor.h\n@@ -80,7 +80,7 @@ namespace dlib\n                 i = 0;\n                 while (i < splits.size())\n                 {\n-                    if (feature_pixel_values[splits[i].idx1] - feature_pixel_values[splits[i].idx2] > splits[i].thresh)\n+                    if ((float)feature_pixel_values[splits[i].idx1] - (float)feature_pixel_values[splits[i].idx2] > splits[i].thresh)\n                         i = left_child(i);\n                     else\n                         i = right_child(i);\n@@ -235,7 +235,7 @@ namespace dlib\n \n     // ------------------------------------------------------------------------------------\n \n-        template <typename image_type>\n+        template <typename image_type, typename feature_type>\n         void extract_feature_pixel_values (\n             const image_type& img_,\n             const rectangle& rect,\n@@ -243,7 +243,7 @@ namespace dlib\n             const matrix<float,0,1>& reference_shape,\n             const std::vector<unsigned long>& reference_pixel_anchor_idx,\n             const std::vector<dlib::vector<float,2> >& reference_pixel_deltas,\n-            std::vector<float>& feature_pixel_values\n+            std::vector<feature_type>& feature_pixel_values\n         )\n         /*!\n             requires\n@@ -449,6 +449,7 @@ namespace dlib\n             _num_test_splits = 20;\n             _feature_pool_region_padding = 0;\n             _verbose = false;\n+            _num_threads = 0;\n         }\n \n         unsigned long get_cascade_depth (\n@@ -601,6 +602,15 @@ namespace dlib\n             _verbose = false;\n         }\n \n+        unsigned long get_num_threads (\n+        ) const { return _num_threads; }\n+        void set_num_threads (\n+                unsigned long num\n+        )\n+        {\n+            _num_threads = num;\n+        }\n+\n         template <typename image_array>\n         shape_predictor train (\n             const image_array& images,\n@@ -657,13 +667,17 @@ namespace dlib\n                 << \"\\n\\t you can't have a part that is always set to OBJECT_PART_NOT_PRESENT.\"\n             );\n \n+            // creating thread pool. if num_threads <= 1, trainer should work in caller thread\n+            thread_pool tp(_num_threads > 1 ? _num_threads : 0);\n \n-\n-\n+            // determining the type of features used for this type of images\n+            typedef typename std::remove_const<typename std::remove_reference<decltype(images[0])>::type>::type image_type;\n+            typedef typename image_traits<image_type>::pixel_type pixel_type;\n+            typedef typename pixel_traits<pixel_type>::basic_pixel_type feature_type;\n \n             rnd.set_seed(get_random_seed());\n \n-            std::vector<training_sample> samples;\n+            std::vector<training_sample<feature_type>> samples;\n             const matrix<float,0,1> initial_shape = populate_training_sample_shapes(objects, samples);\n             const std::vector<std::vector<dlib::vector<float,2> > > pixel_coordinates = randomly_sample_pixel_coordinates(initial_shape);\n \n@@ -684,17 +698,17 @@ namespace dlib\n \n                 // First compute the feature_pixel_values for each training sample at this\n                 // level of the cascade.\n-                for (unsigned long i = 0; i < samples.size(); ++i)\n+                parallel_for(tp, 0, samples.size(), [&](unsigned long i)\n                 {\n-                    extract_feature_pixel_values(images[samples[i].image_idx], samples[i].rect,\n-                        samples[i].current_shape, initial_shape, anchor_idx,\n-                        deltas, samples[i].feature_pixel_values);\n-                }\n+                    impl::extract_feature_pixel_values(images[samples[i].image_idx], samples[i].rect,\n+                                                 samples[i].current_shape, initial_shape, anchor_idx,\n+                                                 deltas, samples[i].feature_pixel_values);\n+                }, 1);\n \n                 // Now start building the trees at this cascade level.\n                 for (unsigned long i = 0; i < get_num_trees_per_cascade_level(); ++i)\n                 {\n-                    forests[cascade].push_back(make_regression_tree(samples, pixel_coordinates[cascade]));\n+                    forests[cascade].push_back(make_regression_tree(tp, samples, pixel_coordinates[cascade]));\n \n                     if (_verbose)\n                     {\n@@ -741,7 +755,8 @@ namespace dlib\n             }\n         }\n \n-        struct training_sample \n+        template<typename feature_type>\n+        struct training_sample\n         {\n             /*!\n \n@@ -756,15 +771,18 @@ namespace dlib\n                 - present == 0/1 mask saying which parts of target_shape are present.\n                 - rect == the position of the object in the image_idx-th image.  All shape\n                   coordinates are coded relative to this rectangle.\n+                - diff_shape == temporary value for holding difference between current\n+                  shape and target shape\n             !*/\n \n             unsigned long image_idx;\n             rectangle rect;\n-            matrix<float,0,1> target_shape; \n-            matrix<float,0,1> present; \n+            matrix<float,0,1> target_shape;\n+            matrix<float,0,1> present;\n \n-            matrix<float,0,1> current_shape;  \n-            std::vector<float> feature_pixel_values;\n+            matrix<float,0,1> current_shape;\n+            matrix<float,0,1> diff_shape;\n+            std::vector<feature_type> feature_pixel_values;\n \n             void swap(training_sample& item)\n             {\n@@ -773,12 +791,15 @@ namespace dlib\n                 target_shape.swap(item.target_shape);\n                 present.swap(item.present);\n                 current_shape.swap(item.current_shape);\n+                diff_shape.swap(item.diff_shape);\n                 feature_pixel_values.swap(item.feature_pixel_values);\n             }\n         };\n \n+        template<typename feature_type>\n         impl::regression_tree make_regression_tree (\n-            std::vector<training_sample>& samples,\n+            thread_pool& tp,\n+            std::vector<training_sample<feature_type>>& samples,\n             const std::vector<dlib::vector<float,2> >& pixel_coordinates\n         ) const\n         {\n@@ -791,19 +812,53 @@ namespace dlib\n             // walk the tree in breadth first order\n             const unsigned long num_split_nodes = static_cast<unsigned long>(std::pow(2.0, (double)get_tree_depth())-1);\n             std::vector<matrix<float,0,1> > sums(num_split_nodes*2+1);\n-            for (unsigned long i = 0; i < samples.size(); ++i)\n-                sums[0] += samples[i].target_shape - samples[i].current_shape;\n+            if (tp.num_threads_in_pool() > 1)\n+            {\n+                // Here we need to calculate shape differences and store sum of differences into sums[0]\n+                // to make it I am splitting of samples into blocks, each block will be processed by\n+                // separate thread, and the sum of differences of each block is stored into separate\n+                // place in block_sums\n+\n+                const unsigned long num_workers = std::max(1UL, tp.num_threads_in_pool());\n+                const unsigned long num =  samples.size();\n+                const unsigned long block_size = std::max(1UL, (num + num_workers - 1) / num_workers);\n+                std::vector<matrix<float,0,1> > block_sums(num_workers);\n+\n+                parallel_for(tp, 0, num_workers, [&](unsigned long block)\n+                {\n+                    const unsigned long block_begin = block * block_size;\n+                    const unsigned long block_end =  std::min(num, block_begin + block_size);\n+                    for (unsigned long i = block_begin; i < block_end; ++i)\n+                    {\n+                        samples[i].diff_shape = samples[i].target_shape - samples[i].current_shape;\n+                        block_sums[block] += samples[i].diff_shape;\n+                    }\n+                }, 1);\n \n-            for (unsigned long i = 0; i < num_split_nodes; ++i) \n+                // now calculate the total result from separate blocks\n+                for (unsigned long i = 0; i < block_sums.size(); ++i)\n+                    sums[0] += block_sums[i];\n+            }\n+            else\n+            {\n+                // synchronous implementation\n+                for (unsigned long i = 0; i < samples.size(); ++i)\n+                {\n+                    samples[i].diff_shape = samples[i].target_shape - samples[i].current_shape;\n+                    sums[0] += samples[i].diff_shape;\n+                }\n+            }\n+\n+            for (unsigned long i = 0; i < num_split_nodes; ++i)\n             {\n                 std::pair<unsigned long,unsigned long> range = parts.front();\n                 parts.pop_front();\n \n-                const impl::split_feature split = generate_split(samples, range.first,\n+                const impl::split_feature split = generate_split(tp, samples, range.first,\n                     range.second, pixel_coordinates, sums[i], sums[left_child(i)],\n                     sums[right_child(i)]);\n                 tree.splits.push_back(split);\n-                const unsigned long mid = partition_samples(split, samples, range.first, range.second); \n+                const unsigned long mid = partition_samples(split, samples, range.first, range.second);\n \n                 parts.push_back(std::make_pair(range.first, mid));\n                 parts.push_back(std::make_pair(mid, range.second));\n@@ -817,7 +872,7 @@ namespace dlib\n             {\n                 // Get the present counts for each dimension so we can divide each\n                 // dimension by the number of observations we have on it to find the mean\n-                // displacement in each leaf. \n+                // displacement in each leaf.\n                 present_counts = 0;\n                 for (unsigned long j = parts[i].first; j < parts[i].second; ++j)\n                     present_counts += samples[j].present;\n@@ -829,7 +884,7 @@ namespace dlib\n                     tree.leaf_values[i] = zeros_matrix(samples[0].target_shape);\n \n                 // now adjust the current shape based on these predictions\n-                for (unsigned long j = parts[i].first; j < parts[i].second; ++j)\n+                parallel_for(tp, parts[i].first, parts[i].second, [&](unsigned long j)\n                 {\n                     samples[j].current_shape += tree.leaf_values[i];\n                     // For parts that aren't present in the training data, we just make\n@@ -842,7 +897,7 @@ namespace dlib\n                         if (samples[j].present(k) == 0)\n                             samples[j].target_shape(k) = samples[j].current_shape(k);\n                     }\n-                }\n+                }, 1);\n             }\n \n             return tree;\n@@ -869,8 +924,10 @@ namespace dlib\n             return feat;\n         }\n \n+        template<typename feature_type>\n         impl::split_feature generate_split (\n-            const std::vector<training_sample>& samples,\n+            thread_pool& tp,\n+            const std::vector<training_sample<feature_type>>& samples,\n             unsigned long begin,\n             unsigned long end,\n             const std::vector<dlib::vector<float,2> >& pixel_coordinates,\n@@ -892,24 +949,33 @@ namespace dlib\n             std::vector<matrix<float,0,1> > left_sums(num_test_splits);\n             std::vector<unsigned long> left_cnt(num_test_splits);\n \n+            const unsigned long num_workers = std::max(1UL, tp.num_threads_in_pool());\n+            const unsigned long block_size = std::max(1UL, (num_test_splits + num_workers - 1) / num_workers);\n+\n             // now compute the sums of vectors that go left for each feature\n-            matrix<float,0,1> temp;\n-            for (unsigned long j = begin; j < end; ++j)\n+            parallel_for(tp, 0, num_workers, [&](unsigned long block)\n             {\n-                temp = samples[j].target_shape-samples[j].current_shape;\n-                for (unsigned long i = 0; i < num_test_splits; ++i)\n+                const unsigned long block_begin = block * block_size;\n+                const unsigned long block_end   = std::min(block_begin + block_size, num_test_splits);\n+\n+                for (unsigned long j = begin; j < end; ++j)\n                 {\n-                    if (samples[j].feature_pixel_values[feats[i].idx1] - samples[j].feature_pixel_values[feats[i].idx2] > feats[i].thresh)\n+                    for (unsigned long i = block_begin; i < block_end; ++i)\n                     {\n-                        left_sums[i] += temp;\n-                        ++left_cnt[i];\n+                        if ((float)samples[j].feature_pixel_values[feats[i].idx1] - (float)samples[j].feature_pixel_values[feats[i].idx2] > feats[i].thresh)\n+                        {\n+                            left_sums[i] += samples[j].diff_shape;\n+                            ++left_cnt[i];\n+                        }\n                     }\n                 }\n-            }\n+\n+            }, 1);\n \n             // now figure out which feature is the best\n             double best_score = -1;\n             unsigned long best_feat = 0;\n+            matrix<float,0,1> temp;\n             for (unsigned long i = 0; i < num_test_splits; ++i)\n             {\n                 // check how well the feature splits the space.\n@@ -940,9 +1006,10 @@ namespace dlib\n             return feats[best_feat];\n         }\n \n+        template<typename feature_type>\n         unsigned long partition_samples (\n             const impl::split_feature& split,\n-            std::vector<training_sample>& samples,\n+            std::vector<training_sample<feature_type>>& samples,\n             unsigned long begin,\n             unsigned long end\n         ) const\n@@ -954,7 +1021,7 @@ namespace dlib\n             unsigned long i = begin;\n             for (unsigned long j = begin; j < end; ++j)\n             {\n-                if (samples[j].feature_pixel_values[split.idx1] - samples[j].feature_pixel_values[split.idx2] > split.thresh)\n+                if ((float)samples[j].feature_pixel_values[split.idx1] - (float)samples[j].feature_pixel_values[split.idx2] > split.thresh)\n                 {\n                     samples[i].swap(samples[j]);\n                     ++i;\n@@ -965,9 +1032,10 @@ namespace dlib\n \n \n \n+        template<typename feature_type>\n         matrix<float,0,1> populate_training_sample_shapes(\n             const std::vector<std::vector<full_object_detection> >& objects,\n-            std::vector<training_sample>& samples\n+            std::vector<training_sample<feature_type>>& samples\n         ) const\n         {\n             samples.clear();\n@@ -978,7 +1046,7 @@ namespace dlib\n             {\n                 for (unsigned long j = 0; j < objects[i].size(); ++j)\n                 {\n-                    training_sample sample;\n+                    training_sample<feature_type> sample;\n                     sample.image_idx = i;\n                     sample.rect = objects[i][j].get_rect();\n                     object_to_shape(objects[i][j], sample.target_shape, sample.present);\n@@ -1095,6 +1163,7 @@ namespace dlib\n         unsigned long _num_test_splits;\n         double _feature_pool_region_padding;\n         bool _verbose;\n+        unsigned long _num_threads;\n     };\n \n // ----------------------------------------------------------------------------------------\ndiff --git a/dlib/image_processing/shape_predictor_abstract.h b/dlib/image_processing/shape_predictor_abstract.h\nindex a37117a9b8..cd3e21541e 100644\n--- a/dlib/image_processing/shape_predictor_abstract.h\n+++ b/dlib/image_processing/shape_predictor_abstract.h\n@@ -148,6 +148,7 @@ namespace dlib\n                 - #get_num_test_splits() == 20\n                 - #get_feature_pool_region_padding() == 0\n                 - #get_random_seed() == \"\"\n+                - #get_num_threads() == 0\n                 - This object will not be verbose\n         !*/\n \n@@ -367,6 +368,26 @@ namespace dlib\n                 - #get_num_test_splits() == num\n         !*/\n \n+        unsigned long get_num_threads (\n+        ) const;\n+        /*!\n+            ensures\n+                - When running training process, it is possible to make some parts of it parallel\n+                  using CPU threads with #parallel_for() extension and creating #thread_pool internally\n+                  When get_num_threads() == 0, trainer will not create threads and all processing will\n+                  be done in the calling thread\n+        !*/\n+\n+        void set_num_threads (\n+            unsigned long num\n+        );\n+        /*!\n+            requires\n+                - num >= 0\n+            ensures\n+                - #get_num_threads() == num\n+        !*/\n+\n         void be_verbose (\n         );\n         /*!\ndiff --git a/examples/train_shape_predictor_ex.cpp b/examples/train_shape_predictor_ex.cpp\nindex d0d3e1b282..bb3d85ddcd 100644\n--- a/examples/train_shape_predictor_ex.cpp\n+++ b/examples/train_shape_predictor_ex.cpp\n@@ -39,7 +39,7 @@ std::vector<std::vector<double> > get_interocular_distances (\n // ----------------------------------------------------------------------------------------\n \n int main(int argc, char** argv)\n-{  \n+{\n     try\n     {\n         // In this example we are going to train a shape_predictor based on the\n@@ -108,6 +108,9 @@ int main(int argc, char** argv)\n         trainer.set_nu(0.05);\n         trainer.set_tree_depth(2);\n \n+        // some parts of training process can be parellelized.\n+        // Trainer will use this count of threads when possible\n+        trainer.set_num_threads(2);\n \n         // Tell the trainer to print status messages to the console so we can\n         // see how long the training will take.\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Performance Issues**: Single-threaded performance is significantly slower\u2014reduce overhead to match or exceed prior performance. Optimize memory usage based on the lower RAM version mentioned.\n\n2. **C++11 Compatibility**: Ensure the code compiles without C++11 support temporarily, but prepare for a shift to C++11 by early 2017. Adjust CMake scripts for C++11 usage, monitoring for user impact.\n\n3. **Thread Configuration**: Improve `block_size` management in multi-threaded routines to enhance load balancing; consider a larger number of smaller blocks for better thread utilization.\n\n4. **Testing**: Continue validation with various datasets, particularly focusing on performance comparisons.\n\n5. **Documentation**: Clearly document changes in performance metrics between original and new implementations for user reference."
      }
    ],
    "codediff_length": 18027
  },
  {
    "index": 74,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/dlib/dnn/core.h b/dlib/dnn/core.h\nindex c091f9455c..f44d9a9136 100644\n--- a/dlib/dnn/core.h\n+++ b/dlib/dnn/core.h\n@@ -1000,6 +1000,12 @@ namespace dlib\n             subnetwork->update_parameters(solvers.pop(), learning_rate);\n         }\n \n+        template <typename solver_type>\n+        void update_parameters(std::vector<solver_type>& solvers, double learning_rate)\n+        {\n+            subnetwork->update_parameters(make_sstack(solvers), learning_rate);\n+        }\n+\n         const tensor& get_parameter_gradient(\n         ) const { return params_grad; }\n \ndiff --git a/dlib/dnn/layers_abstract.h b/dlib/dnn/layers_abstract.h\nindex 6c0ba73886..95801bea60 100644\n--- a/dlib/dnn/layers_abstract.h\n+++ b/dlib/dnn/layers_abstract.h\n@@ -2132,7 +2132,9 @@ namespace dlib\n         const tensor& get_layer_params() const;\n         tensor& get_layer_params();\n         /*!\n-            These functions are implemented as described in the EXAMPLE_COMPUTATIONAL_LAYER_ interface.\n+            These functions are implemented as described in the EXAMPLE_COMPUTATIONAL_LAYER_\n+            interface.  Note that this layer doesn't have any parameters, so the tensor\n+            returned by get_layer_params() is always empty.\n         !*/\n     };\n \ndiff --git a/examples/CMakeLists.txt b/examples/CMakeLists.txt\nindex 34e46ca048..46b197be5a 100644\n--- a/examples/CMakeLists.txt\n+++ b/examples/CMakeLists.txt\n@@ -154,6 +154,7 @@ if (NOT USING_OLD_VISUAL_STUDIO_COMPILER)\n    add_example(dnn_semantic_segmentation_train_ex)\n    add_example(dnn_instance_segmentation_train_ex)\n    add_example(dnn_metric_learning_on_images_ex)\n+   add_example(dnn_dcgan_train_ex)\n endif()\n \n \ndiff --git a/examples/dnn_dcgan_train_ex.cpp b/examples/dnn_dcgan_train_ex.cpp\nnew file mode 100644\nindex 0000000000..4f8f2789df\n--- /dev/null\n+++ b/examples/dnn_dcgan_train_ex.cpp\n@@ -0,0 +1,270 @@\n+// The contents of this file are in the public domain. See LICENSE_FOR_EXAMPLE_PROGRAMS.txt\n+/*\n+    This is an example illustrating the use of the deep learning tools from the dlib C++\n+    Library.  I'm assuming you have already read the dnn_introduction_ex.cpp, the\n+    dnn_introduction2_ex.cpp and the dnn_introduction3_ex.cpp examples.  In this example\n+    program we are going to show how one can train Generative Adversarial Networks (GANs).  In\n+    particular, we will train a Deep Convolutional Generative Adversarial Network (DCGAN) like\n+    the one introduced in this paper:\n+    \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\"\n+    by Alec Radford, Luke Metz, Soumith Chintala.\n+\n+    The main idea is that there are two neural networks training at the same time:\n+    - the generator is in charge of generating images that look as close as possible as the\n+      ones from the dataset.\n+    - the discriminator will decide whether an image is fake (created by the generator) or real\n+      (selected from the dataset).\n+\n+    Each training iteration alternates between training the discriminator and the generator.\n+    We first train the discriminator with real and fake images and then use the gradient from\n+    the discriminator to update the generator.\n+\n+    In this example, we are going to learn how to generate digits from the MNIST dataset, but\n+    the same code can be run using the Fashion MNIST datset:\n+    https://github.com/zalandoresearch/fashion-mnist\n+*/\n+\n+#include <algorithm>\n+#include <iostream>\n+\n+#include <dlib/data_io.h>\n+#include <dlib/dnn.h>\n+#include <dlib/gui_widgets.h>\n+#include <dlib/matrix.h>\n+\n+using namespace std;\n+using namespace dlib;\n+\n+// We start by defining a simple visitor to disable bias learning in a network.  By default,\n+// biases are initialized to 0, so setting the multipliers to 0 disables bias learning.\n+class visitor_no_bias\n+{\n+public:\n+    template <typename input_layer_type>\n+    void operator()(size_t , input_layer_type& ) const\n+    {\n+        // ignore other layers\n+    }\n+\n+    template <typename T, typename U, typename E>\n+    void operator()(size_t , add_layer<T, U, E>& l) const\n+    {\n+        set_bias_learning_rate_multiplier(l.layer_details(), 0);\n+        set_bias_weight_decay_multiplier(l.layer_details(), 0);\n+    }\n+};\n+\n+// Some helper definitions for the noise generation\n+const size_t noise_size = 100;\n+using noise_t = std::array<matrix<float, 1, 1>, noise_size>;\n+\n+noise_t make_noise(dlib::rand& rnd)\n+{\n+    noise_t noise;\n+    for (auto& n : noise)\n+    {\n+        n = rnd.get_random_gaussian();\n+    }\n+    return noise;\n+}\n+\n+// A convolution with custom padding\n+template<long num_filters, long kernel_size, int stride, int padding, typename SUBNET>\n+using conp = add_layer<con_<num_filters, kernel_size, kernel_size, stride, stride, padding, padding>, SUBNET>;\n+\n+// A transposed convolution to with custom padding\n+template<long num_filters, long kernel_size, int stride, int padding, typename SUBNET>\n+using contp = add_layer<cont_<num_filters, kernel_size, kernel_size, stride, stride, padding, padding>, SUBNET>;\n+\n+// The generator is made of a bunch of deconvolutional layers.  Its input is a 1 x 1 x k noise\n+// tensor, and the output is the generated image.  The loss layer does not matter for the\n+// training, we just stack a compatible one on top to be able to have a () operator on the\n+// generator.\n+using generator_type =\n+    loss_binary_log_per_pixel<\n+    sig<contp<1, 4, 2, 1,\n+    relu<bn_con<contp<64, 4, 2, 1,\n+    relu<bn_con<contp<128, 3, 2, 1,\n+    relu<bn_con<contp<256, 4, 1, 0,\n+    input<noise_t>\n+    >>>>>>>>>>>>;\n+\n+// Now, let's proceed to define the discriminator, whose role will be to decide whether an\n+// image is fake or not.\n+using discriminator_type =\n+    loss_binary_log<\n+    conp<1, 3, 1, 0,\n+    leaky_relu<bn_con<conp<256, 4, 2, 1,\n+    leaky_relu<bn_con<conp<128, 4, 2, 1,\n+    leaky_relu<conp<64, 4, 2, 1,\n+    input<matrix<unsigned char>>\n+    >>>>>>>>>>;\n+\n+// Some helper functions to generate and get the images from the generator\n+matrix<unsigned char> generate_image(generator_type& net, const noise_t& noise)\n+{\n+    const matrix<float> output = net(noise);\n+    matrix<unsigned char> image;\n+    assign_image(image, 255 * output);\n+    return image;\n+}\n+\n+std::vector<matrix<unsigned char>> get_generated_images(generator_type& net)\n+{\n+    std::vector<matrix<unsigned char>> images;\n+    const tensor& out = layer<1>(net).get_output();\n+    for (size_t n = 0; n < out.num_samples(); ++n)\n+    {\n+        matrix<float> output = image_plane(out, n);\n+        matrix<unsigned char> image;\n+        assign_image(image, 255 * output);\n+        images.push_back(std::move(image));\n+    }\n+    return images;\n+}\n+\n+int main(int argc, char** argv) try\n+{\n+    // This example is going to run on the MNIST dataset.\n+    if (argc != 2)\n+    {\n+        cout << \"This example needs the MNIST dataset to run!\" << endl;\n+        cout << \"You can get MNIST from http://yann.lecun.com/exdb/mnist/\" << endl;\n+        cout << \"Download the 4 files that comprise the dataset, decompress them, and\" << endl;\n+        cout << \"put them in a folder.  Then give that folder as input to this program.\" << endl;\n+        return EXIT_FAILURE;\n+    }\n+\n+    // MNIST is broken into two parts, a training set of 60000 images and a test set of 10000\n+    // images.  Each image is labeled so that we know what hand written digit is depicted.\n+    // These next statements load the dataset into memory.\n+    std::vector<matrix<unsigned char>> training_images;\n+    std::vector<unsigned long>         training_labels;\n+    std::vector<matrix<unsigned char>> testing_images;\n+    std::vector<unsigned long>         testing_labels;\n+    load_mnist_dataset(argv[1], training_images, training_labels, testing_images, testing_labels);\n+\n+    // Fix the random generator seeds for network initialization and noise\n+    srand(1234);\n+    dlib::rand rnd(std::rand());\n+\n+    // Instantiate both generator and discriminator\n+    generator_type generator;\n+    discriminator_type discriminator(\n+        leaky_relu_(0.2), leaky_relu_(0.2), leaky_relu_(0.2));\n+    // Remove the bias learning from the networks\n+    visit_layers(generator, visitor_no_bias());\n+    visit_layers(discriminator, visitor_no_bias());\n+    // Forward random noise so that we see the tensor size at each layer\n+    discriminator(generate_image(generator, make_noise(rnd)));\n+    cout << \"generator\" << endl;\n+    cout << generator << endl;\n+    cout << \"discriminator\" << endl;\n+    cout << discriminator << endl;\n+\n+    // The solvers for the generator and discriminator networks.  In this example, we are going to\n+    // train the networks manually, so we don't need to use a dnn_trainer.  Note that the\n+    // discriminator could be trained using a dnn_trainer, but not the generator, since its\n+    // training process is a bit particular.\n+    std::vector<adam> g_solvers(generator.num_computational_layers, adam(0, 0.5, 0.999));\n+    std::vector<adam> d_solvers(discriminator.num_computational_layers, adam(0, 0.5, 0.999));\n+    double learning_rate = 2e-4;\n+\n+    // Resume training from last sync file\n+    size_t iteration = 0;\n+    if (file_exists(\"dcgan_sync\"))\n+    {\n+        deserialize(\"dcgan_sync\") >> generator >> discriminator >> iteration;\n+    }\n+\n+    const size_t minibatch_size = 64;\n+    const std::vector<float> real_labels(minibatch_size, 1);\n+    const std::vector<float> fake_labels(minibatch_size, -1);\n+    dlib::image_window win;\n+    resizable_tensor real_samples_tensor, fake_samples_tensor, noises_tensor;\n+    while (iteration < 50000)\n+    {\n+        // Train the discriminator with real images\n+        std::vector<matrix<unsigned char>> real_samples;\n+        while (real_samples.size() < minibatch_size)\n+        {\n+            auto idx = rnd.get_random_32bit_number() % training_images.size();\n+            real_samples.push_back(training_images[idx]);\n+        }\n+        // The following lines are equivalent to calling train_one_step(real_samples, real_labels)\n+        discriminator.to_tensor(real_samples.begin(), real_samples.end(), real_samples_tensor);\n+        double d_loss = discriminator.compute_loss(real_samples_tensor, real_labels.begin());\n+        discriminator.subnet().back_propagate_error(real_samples_tensor);\n+        discriminator.subnet().update_parameters(d_solvers, learning_rate);\n+\n+        // Train the discriminator with fake images\n+        // 1. generate some random noise\n+        std::vector<noise_t> noises;\n+        while (noises.size() < minibatch_size)\n+        {\n+            noises.push_back(make_noise(rnd));\n+        }\n+        // 2. forward the noise through the generator\n+        generator.to_tensor(noises.begin(), noises.end(), noises_tensor);\n+        generator.subnet().forward(noises_tensor);\n+        // 3. get the generated images from the generator\n+        const auto fake_samples = get_generated_images(generator);\n+        // 4. finally train the discriminator and wait for the threading to stop.  The following\n+        // lines are equivalent to calling train_one_step(fake_samples, fake_labels)\n+        discriminator.to_tensor(fake_samples.begin(), fake_samples.end(), fake_samples_tensor);\n+        d_loss += discriminator.compute_loss(fake_samples_tensor, fake_labels.begin());\n+        discriminator.subnet().back_propagate_error(fake_samples_tensor);\n+        discriminator.subnet().update_parameters(d_solvers, learning_rate);\n+\n+        // Train the generator\n+        // This part is the essence of the Generative Adversarial Networks.  Until now, we have\n+        // just trained a binary classifier that the generator is not aware of.  But now, the\n+        // discriminator is going to give feedback to the generator on how it should update\n+        // itself to generate more realistic images.  The following lines perform the same\n+        // actions as train_one_step() except for the network update part.  They can also be\n+        // seen as test_one_step() plus the error back propagation.\n+\n+        // Forward the fake samples and compute the loss with real labels\n+        const auto g_loss = discriminator.compute_loss(fake_samples_tensor, real_labels.begin());\n+        // Back propagate the error to fill the final data gradient\n+        discriminator.subnet().back_propagate_error(fake_samples_tensor);\n+        // Get the gradient that will tell the generator how to update itself\n+        const tensor& d_grad = discriminator.subnet().get_final_data_gradient();\n+        generator.subnet().back_propagate_error(noises_tensor, d_grad);\n+        generator.subnet().update_parameters(g_solvers, learning_rate);\n+\n+        // At some point, we should see that the generated images start looking like samples from\n+        // the MNIST dataset\n+        if (++iteration % 1000 == 0)\n+        {\n+            serialize(\"dcgan_sync\") << generator << discriminator << iteration;\n+            std::cout <<\n+                \"step#: \" << iteration <<\n+                \"\\tdiscriminator loss: \" << d_loss <<\n+                \"\\tgenerator loss: \" << g_loss << '\\n';\n+            win.set_image(tile_images(fake_samples));\n+            win.set_title(\"DCGAN step#: \" + to_string(iteration));\n+        }\n+    }\n+\n+    // Once the training has finished, we don't need the discriminator any more. We just keep the\n+    // generator.\n+    generator.clean();\n+    serialize(\"dcgan_mnist.dnn\") << generator;\n+\n+    // To test the generator, we just forward some random noise through it and visualize the\n+    // output.\n+    while (!win.is_closed())\n+    {\n+        win.set_image(generate_image(generator, make_noise(rnd)));\n+        cout << \"Hit enter to generate a new image\";\n+        cin.get();\n+    }\n+\n+    return EXIT_SUCCESS;\n+}\n+catch(exception& e)\n+{\n+    cout << e.what() << endl;\n+    return EXIT_FAILURE;\n+}\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Convergence Issue**: Fixed pseudo-random seed improved convergence but inconsistency remains. Investigate and minimize coupling to `std::rand` and other random functions for better determinism.\n\n2. **Non-Determinism**: Recognize training non-determinism as inherent; consider using fixed `float` types to avoid implicit casting issues. \n\n3. **Windows Compatibility**: The `not` operator fails on Windows. Replace `not` with `!` for broader compatibility.\n\n4. **Implementation Suggestion**: Adopt the use of two `running_stats` objects (`g_loss`, `d_loss`) to track and compute mean losses for clearer performance representation during training.\n\n5. **Next Steps**: Review and test floating point handling, and ensure consistency across platforms."
      }
    ],
    "codediff_length": 13854
  },
  {
    "index": 75,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/dlib/python/numpy.h b/dlib/python/numpy.h\nindex 264460a7e8..2b5ab9d703 100644\n--- a/dlib/python/numpy.h\n+++ b/dlib/python/numpy.h\n@@ -7,12 +7,14 @@\n #include <dlib/error.h>\n #include <dlib/algs.h>\n #include <dlib/string.h>\n+#include <dlib/array.h>\n+#include <dlib/pixel.h>\n \n // ----------------------------------------------------------------------------------------\n \n template <typename T>\n void validate_numpy_array_type (\n-    boost::python::object& obj\n+    const boost::python::object& obj\n )\n {\n     using namespace boost::python;\n@@ -30,36 +32,83 @@ void validate_numpy_array_type (\n \n // ----------------------------------------------------------------------------------------\n \n+template <int dims>\n+void get_numpy_ndarray_shape (\n+    const boost::python::object& obj,\n+    long (&shape)[dims]\n+)\n+/*!\n+    ensures\n+        - stores the shape of the array into #shape.\n+        - the dimension of the given numpy array is not greater than #dims.\n+!*/\n+{\n+    Py_buffer pybuf;\n+    if (PyObject_GetBuffer(obj.ptr(), &pybuf, PyBUF_STRIDES ))\n+        throw dlib::error(\"Expected numpy.ndarray with shape set.\");\n+\n+    try\n+    {\n+\n+        if (pybuf.ndim > dims)\n+            throw dlib::error(\"Expected array with \" + dlib::cast_to_string(dims) + \" dimensions.\");\n+\n+        for (int i = 0; i < dims; ++i)\n+        {\n+            if (i < pybuf.ndim)\n+                shape[i] = pybuf.shape[i];\n+            else\n+                shape[i] = 1;\n+        }\n+    }\n+    catch(...)\n+    {\n+        PyBuffer_Release(&pybuf);\n+        throw;\n+    }\n+    PyBuffer_Release(&pybuf);\n+}\n+\n+// ----------------------------------------------------------------------------------------\n+\n template <typename T, int dims>\n void get_numpy_ndarray_parts (\n     boost::python::object& obj,\n     T*& data,\n+    dlib::array<T>& contig_buf,\n     long (&shape)[dims]\n )\n /*!\n     ensures\n         - extracts the pointer to the data from the given numpy ndarray.  Stores the shape\n           of the array into #shape.\n+        - the dimension of the given numpy array is not greater than #dims.\n+        - #shape[#dims-1] == pixel_traits<T>::num when #dims is greater than 2\n !*/\n {\n     Py_buffer pybuf;\n-    if (PyObject_GetBuffer(obj.ptr(), &pybuf, PyBUF_ND | PyBUF_WRITABLE ))\n-        throw dlib::error(\"Expected contiguous and writable numpy.ndarray.\");\n+    if (PyObject_GetBuffer(obj.ptr(), &pybuf, PyBUF_STRIDES | PyBUF_WRITABLE ))\n+        throw dlib::error(\"Expected writable numpy.ndarray with shape set.\");\n \n     try\n     {\n         validate_numpy_array_type<T>(obj);\n-        data = (T*)pybuf.buf;\n \n         if (pybuf.ndim > dims)\n             throw dlib::error(\"Expected array with \" + dlib::cast_to_string(dims) + \" dimensions.\");\n+        get_numpy_ndarray_shape(obj, shape);\n \n-        for (int i = 0; i < dims; ++i)\n+        if (dlib::pixel_traits<T>::num > 1 && dlib::pixel_traits<T>::num != shape[dims-1])\n+            throw dlib::error(\"Expected numpy.ndarray with \" + dlib::cast_to_string(dlib::pixel_traits<T>::num) + \" channels.\");\n+\n+        if (PyBuffer_IsContiguous(&pybuf, 'C'))\n+            data = (T*)pybuf.buf;\n+        else\n         {\n-            if (i < pybuf.ndim)\n-                shape[i] = pybuf.shape[i];\n-            else\n-                shape[i] = 1;\n+            contig_buf.resize(pybuf.len);\n+            if (PyBuffer_ToContiguous(&contig_buf[0], &pybuf, pybuf.len, 'C'))\n+                throw dlib::error(\"Can't copy numpy.ndarray to a contiguous buffer.\");\n+            data = &contig_buf[0];\n         }\n     }\n     catch(...)\n@@ -76,32 +125,40 @@ template <typename T, int dims>\n void get_numpy_ndarray_parts (\n     const boost::python::object& obj,\n     const T*& data,\n+    dlib::array<T>& contig_buf,\n     long (&shape)[dims]\n )\n /*!\n     ensures\n         - extracts the pointer to the data from the given numpy ndarray.  Stores the shape\n           of the array into #shape.\n+        - the dimension of the given numpy array is not greater than #dims.\n+        - #shape[#dims-1] == pixel_traits<T>::num when #dims is greater than 2\n !*/\n {\n     Py_buffer pybuf;\n-    if (PyObject_GetBuffer(obj.ptr(), &pybuf, PyBUF_ND ))\n-        throw dlib::error(\"Expected contiguous numpy.ndarray.\");\n+    if (PyObject_GetBuffer(obj.ptr(), &pybuf, PyBUF_STRIDES ))\n+        throw dlib::error(\"Expected numpy.ndarray with shape set.\");\n \n     try\n     {\n         validate_numpy_array_type<T>(obj);\n-        data = (const T*)pybuf.buf;\n \n         if (pybuf.ndim > dims)\n             throw dlib::error(\"Expected array with \" + dlib::cast_to_string(dims) + \" dimensions.\");\n+        get_numpy_ndarray_shape(obj, shape);\n \n-        for (int i = 0; i < dims; ++i)\n+        if (dlib::pixel_traits<T>::num > 1 && dlib::pixel_traits<T>::num != shape[dims-1])\n+            throw dlib::error(\"Expected numpy.ndarray with \" + dlib::cast_to_string(dlib::pixel_traits<T>::num) + \" channels.\");\n+\n+        if (PyBuffer_IsContiguous(&pybuf, 'C'))\n+            data = (const T*)pybuf.buf;\n+        else\n         {\n-            if (i < pybuf.ndim)\n-                shape[i] = pybuf.shape[i];\n-            else\n-                shape[i] = 1;\n+            contig_buf.resize(pybuf.len);\n+            if (PyBuffer_ToContiguous(&contig_buf[0], &pybuf, pybuf.len, 'C'))\n+                throw dlib::error(\"Can't copy numpy.ndarray to a contiguous buffer.\");\n+            data = &contig_buf[0];\n         }\n     }\n     catch(...)\ndiff --git a/dlib/python/numpy_image.h b/dlib/python/numpy_image.h\nindex 61e028a1cb..65a46e03b8 100644\n--- a/dlib/python/numpy_image.h\n+++ b/dlib/python/numpy_image.h\n@@ -6,6 +6,7 @@\n #include \"numpy.h\"\n #include <dlib/pixel.h>\n #include <dlib/matrix.h>\n+#include <dlib/array.h>\n \n \n // ----------------------------------------------------------------------------------------\n@@ -18,7 +19,7 @@ class numpy_gray_image\n     numpy_gray_image (boost::python::object& img) \n     {\n         long shape[2];\n-        get_numpy_ndarray_parts(img, _data, shape);\n+        get_numpy_ndarray_parts(img, _data, _contig_buf, shape);\n         _nr = shape[0];\n         _nc = shape[1];\n     }\n@@ -32,6 +33,7 @@ class numpy_gray_image\n private:\n \n     unsigned char* _data;\n+    dlib::array<unsigned char> _contig_buf;\n     long _nr;\n     long _nc;\n };\n@@ -51,7 +53,8 @@ inline bool is_gray_python_image (boost::python::object& img)\n {\n     try\n     {\n-        numpy_gray_image temp(img);\n+        long shape[2];\n+        get_numpy_ndarray_shape(img, shape);\n         return true;\n     }\n     catch (dlib::error&)\n@@ -70,7 +73,7 @@ class numpy_rgb_image\n     numpy_rgb_image (boost::python::object& img) \n     {\n         long shape[3];\n-        get_numpy_ndarray_parts(img, _data, shape);\n+        get_numpy_ndarray_parts(img, _data, _contig_buf, shape);\n         _nr = shape[0];\n         _nc = shape[1];\n         if (shape[2] != 3)\n@@ -87,6 +90,7 @@ class numpy_rgb_image\n private:\n \n     dlib::rgb_pixel* _data;\n+    dlib::array<dlib::rgb_pixel> _contig_buf;\n     long _nr;\n     long _nc;\n };\n@@ -107,8 +111,11 @@ inline bool is_rgb_python_image (boost::python::object& img)\n {\n     try\n     {\n-        numpy_rgb_image temp(img);\n-        return true;\n+        long shape[3];\n+        get_numpy_ndarray_shape(img, shape);\n+        if (shape[2] == 3)\n+            return true;\n+        return false;\n     }\n     catch (dlib::error&)\n     {\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Core Dump Issue**: Implement an additional check to prevent core dumps.\n2. **Pointer Returning**: Avoid returning pointers to stack-local objects. Instead, pass `dlib::array2d` by reference to manage valid pointer lifetimes.\n3. **Memory Management**: Evaluate memory management with `PyMem_Malloc`. If using it, consider calling `PyMem_Free` in `numpy_image` destructor to prevent memory leaks.\n4. **Data Initialization**: Replace `_data` with a `dlib::array` initialized properly; ensure `array2d` is a member of `numpy_image` to retain valid pointers.\n5. **Performance**: Address potential data copying in `numpy_*_image` construction by creating a dedicated function for array shape checking, despite increased complexity.\n6. **Testing**: Conduct comprehensive tests beyond the provided script to ensure functionality and stability."
      }
    ],
    "codediff_length": 7369
  },
  {
    "index": 76,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/BuildMacOSUniversalBinary.py b/BuildMacOSUniversalBinary.py\nnew file mode 100755\nindex 000000000000..ea6f83d07709\n--- /dev/null\n+++ b/BuildMacOSUniversalBinary.py\n@@ -0,0 +1,330 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+The current tooling supported in CMake, Homebrew, and Qt5 are insufficient for\n+creating macOS universal binaries automatically for applications like Dolphin\n+which have more complicated build requirements (like different libraries, build\n+flags and source files for each target architecture).\n+\n+So instead, this script manages the configuration and compilation of distinct\n+builds and project files for each target architecture and then merges the two\n+binaries into a single universal binary.\n+\n+Running this script will:\n+1) Generate Xcode project files for the ARM build (if project files don't\n+   already exist)\n+2) Generate Xcode project files for the x64 build (if project files don't\n+   already exist)\n+3) Build the ARM project for the selected build_target\n+4) Build the x64 project for the selected build_target\n+5) Generate universal .app packages combining the ARM and x64 packages\n+6) Use the lipo tool to combine the binary objects inside each of the\n+   packages into universal binaries\n+7) Code sign the final universal binaries using the specified\n+   codesign_identity\n+\"\"\"\n+\n+import argparse\n+import filecmp\n+import glob\n+import json\n+import multiprocessing\n+import os\n+import shutil\n+import subprocess\n+\n+# The config variables listed below are the defaults, but they can be\n+# overridden by command line arguments see parse_args(), or run:\n+# BuildMacOSUniversalBinary.py --help\n+DEFAULT_CONFIG = {\n+\n+    # Location of destination universal binary\n+    \"dst_app\": \"universal/\",\n+    # Build Target (dolphin-emu to just build the emulator and skip the tests)\n+    \"build_target\": \"ALL_BUILD\",\n+\n+    # Location for CMake to search for files (default is for homebrew)\n+    \"arm64_cmake_prefix\":  \"/opt/homebrew\",\n+    \"x86_64_cmake_prefix\": \"/usr/local\",\n+\n+    # Locations to qt5 directories for arm and x64 libraries\n+    # The default values of these paths are taken from the default\n+    # paths used for homebrew\n+    \"arm64_qt5_path\":  \"/opt/homebrew/opt/qt5\",\n+    \"x86_64_qt5_path\": \"/usr/local/opt/qt5\",\n+\n+    # Identity to use for code signing. \"-\" indicates that the app will not\n+    # be cryptographically signed/notarized but will instead just use a\n+    # SHA checksum to verify the integrity of the app. This doesn't\n+    # protect against malicious actors, but it does protect against\n+    # running corrupted binaries and allows for access to the extended\n+    # permisions needed for ARM builds\n+    \"codesign_identity\":  \"-\",\n+    # Entitlements file to use for code signing\n+    \"entitlements\": \"../Source/Core/DolphinQt/DolphinEmu.entitlements\",\n+\n+    # Minimum macOS version for each architecture slice\n+    \"arm64_mac_os_deployment_target\":  \"11.0.0\",\n+    \"x86_64_mac_os_deployment_target\": \"10.12.0\",\n+\n+    # CMake Generator to use for building\n+    \"generator\": \"Unix Makefiles\",\n+    \"build_type\": \"Release\",\n+\n+}\n+\n+# Architectures to build for. This is explicity left out of the command line\n+# config options for several reasons:\n+# 1) Adding new architectures will generally require more code changes\n+# 2) Single architecture builds should utilize the normal generated cmake\n+#    project files rather than this wrapper script\n+\n+ARCHITECTURES = [\"x86_64\", \"arm64\"]\n+\n+\n+def parse_args(conf=DEFAULT_CONFIG):\n+    \"\"\"\n+    Parses the command line arguments into a config dictionary.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser(\n+        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n+\n+    parser.add_argument(\n+        \"--target\",\n+        help=\"Build target in generated project files\",\n+        default=conf[\"build_target\"],\n+        dest=\"build_target\")\n+    parser.add_argument(\n+        \"-G\",\n+        help=\"CMake Generator to use for creating project files\",\n+        default=conf[\"generator\"],\n+        dest=\"generator\")\n+    parser.add_argument(\n+        \"--build_type\",\n+        help=\"CMake build type [Debug, Release, RelWithDebInfo, MinSizeRel]\",\n+        default=conf[\"build_type\"],\n+        dest=\"build_type\")\n+    parser.add_argument(\n+        \"--dst_app\",\n+        help=\"Directory where universal binary will be stored\",\n+        default=conf[\"dst_app\"])\n+\n+    parser.add_argument(\n+        \"--entitlements\",\n+        help=\"Path to .entitlements file for code signing\",\n+        default=conf[\"entitlements\"])\n+\n+    parser.add_argument(\n+        \"--codesign\",\n+        help=\"Code signing identity to use to sign the applications\",\n+        default=conf[\"codesign_identity\"],\n+        dest=\"codesign_identity\")\n+\n+    for arch in ARCHITECTURES:\n+        parser.add_argument(\n+             f\"--{arch}_cmake_prefix\",\n+             help=\"Folder for cmake to search for packages\",\n+             default=conf[arch+\"_cmake_prefix\"],\n+             dest=arch+\"_cmake_prefix\")\n+\n+        parser.add_argument(\n+             f\"--{arch}_qt5_path\",\n+             help=f\"Install path for {arch} qt5 libraries\",\n+             default=conf[arch+\"_qt5_path\"])\n+\n+        parser.add_argument(\n+             f\"--{arch}_mac_os_deployment_target\",\n+             help=f\"Deployment architecture for {arch} slice\",\n+             default=conf[arch+\"_mac_os_deployment_target\"])\n+\n+    return vars(parser.parse_args())\n+\n+\n+def lipo(path0, path1, dst):\n+    if subprocess.call([\"lipo\", \"-create\", \"-output\", dst, path0, path1]) != 0:\n+        print(f\"WARNING: {path0} and {path1} cannot be lipo'd\")\n+\n+        shutil.copy(path0, dst)\n+\n+\n+def recursive_merge_binaries(src0, src1, dst):\n+    \"\"\"\n+    Merges two build trees together for different architectures into a single\n+    universal binary.\n+\n+    The rules for merging are:\n+\n+    1) Files that exist in either src tree are copied into the dst tree\n+    2) Files that exist in both trees and are identical are copied over\n+       unmodified\n+    3) Files that exist in both trees and are non-identical are lipo'd\n+    4) Symlinks are created in the destination tree to mirror the hierarchy in\n+       the source trees\n+    \"\"\"\n+\n+    # Check that all files present in the folder are of the same type and that\n+    # links link to the same relative location\n+    for newpath0 in glob.glob(src0+\"/*\"):\n+        filename = os.path.basename(newpath0)\n+        newpath1 = os.path.join(src1, filename)\n+        if not os.path.exists(newpath1):\n+            continue\n+\n+        if os.path.islink(newpath0) and os.path.islink(newpath1):\n+            if os.path.relpath(newpath0, src0) == os.path.relpath(newpath1, src1):\n+                continue\n+\n+        if os.path.isdir(newpath0) and os.path.isdir(newpath1):\n+            continue\n+\n+        # isfile() can be true for links so check that both are not links\n+        # before checking if they are both files\n+        if (not os.path.islink(newpath0)) and (not os.path.islink(newpath1)):\n+            if os.path.isfile(newpath0) and os.path.isfile(newpath1):\n+                continue\n+\n+        raise Exception(f\"{newpath0} and {newpath1} cannot be \" +\n+                        \"merged into a universal binary because they are of \" +\n+                        \"incompatible types. Perhaps the installed libraries\" +\n+                        \" are from different versions for each architecture\")\n+\n+    for newpath0 in glob.glob(src0+\"/*\"):\n+        filename = os.path.basename(newpath0)\n+        newpath1 = os.path.join(src1, filename)\n+        new_dst_path = os.path.join(dst, filename)\n+        if os.path.islink(newpath0):\n+            # Symlinks will be fixed after files are resolved\n+            continue\n+\n+        if not os.path.exists(newpath1):\n+            if os.path.isdir(newpath0):\n+                shutil.copytree(newpath0, new_dst_path)\n+            else:\n+                shutil.copy(newpath0, new_dst_path)\n+\n+            continue\n+\n+        if os.path.isdir(newpath1):\n+            os.mkdir(new_dst_path)\n+            recursive_merge_binaries(newpath0, newpath1, new_dst_path)\n+            continue\n+\n+        if filecmp.cmp(newpath0, newpath1):\n+            shutil.copy(newpath0, new_dst_path)\n+        else:\n+            lipo(newpath0, newpath1, new_dst_path)\n+\n+    # Loop over files in src1 and copy missing things over to dst\n+    for newpath1 in glob.glob(src1+\"/*\"):\n+        filename = os.path.basename(newpath1)\n+        newpath0 = os.path.join(src0, filename)\n+        new_dst_path = os.path.join(dst, filename)\n+        if (not os.path.exists(newpath0)) and (not os.path.islink(newpath1)):\n+            if os.path.isdir(newpath1):\n+                shutil.copytree(newpath1, new_dst_path)\n+            else:\n+                shutil.copy(newpath1, new_dst_path)\n+\n+    # Fix up symlinks for path0\n+    for newpath0 in glob.glob(src0+\"/*\"):\n+        filename = os.path.basename(newpath0)\n+        new_dst_path = os.path.join(dst, filename)\n+        if os.path.islink(newpath0):\n+            relative_path = os.path.relpath(os.path.realpath(newpath0), src0)\n+            os.symlink(relative_path, new_dst_path)\n+    # Fix up symlinks for path1\n+    for newpath1 in glob.glob(src1+\"/*\"):\n+        filename = os.path.basename(newpath1)\n+        new_dst_path = os.path.join(dst, filename)\n+        newpath0 = os.path.join(src0, filename)\n+        if os.path.islink(newpath1) and not os.path.exists(newpath0):\n+            relative_path = os.path.relpath(os.path.realpath(newpath1), src1)\n+            os.symlink(relative_path, new_dst_path)\n+\n+\n+def build(config):\n+    \"\"\"\n+    Builds the project with the parameters specified in config.\n+    \"\"\"\n+\n+    print(\"Building config:\")\n+    print(json.dumps(config, indent=4))\n+\n+    # Configure and build single architecture builds for each architecture\n+    for arch in ARCHITECTURES:\n+        if not os.path.exists(arch):\n+            os.mkdir(arch)\n+\n+        env = os.environ.copy()\n+        env[\"Qt5_DIR\"] = config[arch+\"_qt5_path\"]\n+        env[\"CMAKE_OSX_ARCHITECTURES\"] = arch\n+        env[\"CMAKE_PREFIX_PATH\"] = config[arch+\"_cmake_prefix\"]\n+\n+        # Add the other architecture's prefix path to the ignore path so that\n+        # CMake doesn't try to pick up the wrong architecture's libraries when\n+        # cross compiling.\n+        ignore_path = \"\"\n+        for a in ARCHITECTURES:\n+            if a != arch:\n+                ignore_path = config[a+\"_cmake_prefix\"]\n+\n+        subprocess.check_call([\n+                \"cmake\", \"../../\", \"-G\", config[\"generator\"],\n+                \"-DCMAKE_BUILD_TYPE=\" + config[\"build_type\"],\n+                '-DCMAKE_CXX_FLAGS=\"-DMACOS_UNIVERSAL_BUILD=1\"',\n+                '-DCMAKE_C_FLAGS=\"-DMACOS_UNIVERSAL_BUILD=1\"',\n+                # System name needs to be specified for CMake to use\n+                # the specified CMAKE_SYSTEM_PROCESSOR\n+                \"-DCMAKE_SYSTEM_NAME=Darwin\",\n+                \"-DCMAKE_PREFIX_PATH=\"+config[arch+\"_cmake_prefix\"],\n+                \"-DCMAKE_SYSTEM_PROCESSOR=\"+arch,\n+                \"-DCMAKE_IGNORE_PATH=\"+ignore_path,\n+                \"-DCMAKE_OSX_DEPLOYMENT_TARGET=\"\n+                + config[arch+\"_mac_os_deployment_target\"],\n+                \"-DMACOS_CODE_SIGNING_IDENTITY=\"\n+                + config[\"codesign_identity\"],\n+                \"-DMACOS_CODE_SIGNING_IDENTITY_UPDATER=\"\n+                + config[\"codesign_identity\"],\n+                '-DMACOS_CODE_SIGNING=\"ON\"'\n+            ],\n+            env=env, cwd=arch)\n+\n+        threads = multiprocessing.cpu_count()\n+        subprocess.check_call([\"cmake\", \"--build\", \".\",\n+                               \"--config\", config[\"build_type\"],\n+                               \"--parallel\", f\"{threads}\"], cwd=arch)\n+\n+    dst_app = config[\"dst_app\"]\n+\n+    if os.path.exists(dst_app):\n+        shutil.rmtree(dst_app)\n+\n+    # Create and codesign the universal binary/\n+    os.mkdir(dst_app)\n+\n+    # Source binary trees to merge together\n+    src_app0 = ARCHITECTURES[0]+\"/Binaries/\"\n+    src_app1 = ARCHITECTURES[1]+\"/Binaries/\"\n+\n+    recursive_merge_binaries(src_app0, src_app1, dst_app)\n+    for path in glob.glob(dst_app+\"/*\"):\n+        if os.path.isdir(path) and os.path.splitext(path)[1] != \".app\":\n+            continue\n+\n+        subprocess.check_call([\n+            \"codesign\",\n+            \"-d\",\n+            \"--force\",\n+            \"-s\",\n+            config[\"codesign_identity\"],\n+            \"--options=runtime\",\n+            \"--entitlements\", config[\"entitlements\"],\n+            \"--deep\",\n+            \"--verbose=2\",\n+            path])\n+\n+\n+if __name__ == \"__main__\":\n+    conf = parse_args()\n+    build(conf)\n+    print(\"Built Universal Binary successfully!\")\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nindex e1565844e489..a480467b3ec6 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -2,13 +2,17 @@\n # General setup\n #\n cmake_minimum_required(VERSION 3.10)\n-set(CMAKE_OSX_ARCHITECTURES \"x86_64\")\n+\n # Minimum OS X version.\n # This is inserted into the Info.plist as well.\n \n-# MacOS prior to 10.12 did not fully support C++17, which is used to\n-# handle configuration options\n-set(CMAKE_OSX_DEPLOYMENT_TARGET \"10.12.0\" CACHE STRING \"\")\n+# MacOS prior to 10.14 did not support aligned alloc which is used to implement\n+# std::unique_ptr in the arm64 C++ standard library. x86_64 builds can override\n+# this to 10.12.0 using -DCMAKE_OSX_DEPLOYMENT_TARGET=\"10.12.0\" without issue.\n+# This is done in the universal binary building script to build a binary that \n+# runs on 10.12 on x86_64 computers, while still containing an arm64 slice.\n+\n+set(CMAKE_OSX_DEPLOYMENT_TARGET \"10.14.0\" CACHE STRING \"\")\n \n set(CMAKE_USER_MAKE_RULES_OVERRIDE \"CMake/FlagsOverride.cmake\")\n \n@@ -68,8 +72,12 @@ else()\n endif()\n \n if(APPLE)\n-  option(OSX_USE_DEFAULT_SEARCH_PATH \"Don't prioritize system library paths\" OFF)\n-  option(SKIP_POSTPROCESS_BUNDLE \"Skip postprocessing bundle for redistributability\" OFF)\n+  option(MACOS_USE_DEFAULT_SEARCH_PATH \"Don't prioritize system library paths\" OFF)\n+  option(SKIP_POSTPROCESS_BUNDLE \"Skip postprocessing bundle for redistributability\" OFF) \n+  # Enable adhoc code signing by default (otherwise makefile builds on ARM will not work)\n+  option(MACOS_CODE_SIGNING \"Enable codesigning\" ON)\n+  set(MACOS_CODE_SIGNING_IDENTITY \"-\" CACHE STRING \"The identity used for codesigning.\")\n+  set(MACOS_CODE_SIGNING_IDENTITY_UPDATER \"-\" CACHE STRING \"The identity used for codesigning, for the updater.\")\n endif()\n \n if(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n@@ -290,7 +298,7 @@ else()\n endif()\n \n if(CMAKE_SYSTEM_NAME MATCHES \"Darwin\")\n-  if(NOT OSX_USE_DEFAULT_SEARCH_PATH)\n+  if(NOT MACOS_USE_DEFAULT_SEARCH_PATH)\n     # Hack up the path to prioritize the path to built-in OS libraries to\n     # increase the chance of not depending on a bunch of copies of them\n     # installed by MacPorts, Fink, Homebrew, etc, and ending up copying\n@@ -306,9 +314,10 @@ if(CMAKE_SYSTEM_NAME MATCHES \"Darwin\")\n   set(CMAKE_XCODE_ATTRIBUTE_GCC_STRICT_ALIASING NO)\n \n   # Specify target CPUs.\n-  check_and_add_flag(HAVE_MSSSE3 -mssse3)\n-  check_and_add_flag(HAVE_ARCH_CORE2 -march=core2)\n-\n+  if(_ARCH_64 AND CMAKE_SYSTEM_PROCESSOR MATCHES \"x86_64|amd64|AMD64\")\n+    check_and_add_flag(HAVE_MSSSE3 -mssse3)\n+    check_and_add_flag(HAVE_ARCH_CORE2 -march=core2)\n+  endif()\n   # Linker flags.\n   # Drop unreachable code and data.\n   set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -Wl,-dead_strip,-dead_strip_dylibs\")\ndiff --git a/Externals/MoltenVK/libvulkan.dylib b/Externals/MoltenVK/libvulkan.dylib\nindex efb0db74b867..4eddd174d46f 100755\nBinary files a/Externals/MoltenVK/libvulkan.dylib and b/Externals/MoltenVK/libvulkan.dylib differ\ndiff --git a/Externals/MoltenVK/version.txt b/Externals/MoltenVK/version.txt\nindex 9f1cd7fc3dad..2454c57670bd 100644\n--- a/Externals/MoltenVK/version.txt\n+++ b/Externals/MoltenVK/version.txt\n@@ -1 +1 @@\n-MoltenVK from https://github.com/KhronosGroup/MoltenVK, commit b9b78def172074872bfbb1015ccf75eeec554ae2\n+MoltenVK from https://vulkan.lunarg.com/sdk/home#mac, version 1.2.170.0\n\\ No newline at end of file\ndiff --git a/Readme.md b/Readme.md\nindex 2093723871dc..4a16b75fc9e7 100644\n--- a/Readme.md\n+++ b/Readme.md\n@@ -65,6 +65,8 @@ missing packages yourself.\n \n ### macOS Build Steps:\n \n+A binary supporting a single architecture can be built using the following steps: \n+\n 1. `mkdir build`\n 2. `cd build`\n 3. `cmake ..`\n@@ -72,6 +74,18 @@ missing packages yourself.\n \n An application bundle will be created in `./Binaries`.\n \n+A script is also provided to build universal binaries supporting both x64 and ARM in the same\n+application bundle using the following steps:\n+\n+1. `mkdir build`\n+2. `cd build`\n+3. `python ../BuildMacOSUniversalBinary.py`\n+4. Universal binaries will be available in the `universal` folder\n+\n+Doing this is more complex as it requires installation of library dependencies for both x64 and ARM (or universal library\n+equivalents) and may require specifying additional arguments to point to relevant library locations. \n+Execute BuildMacOSUniversalBinary.py --help for more details.  \n+\n ### Linux Global Build Steps:\n \n To install to your system.\ndiff --git a/Source/Core/Common/Arm64Emitter.cpp b/Source/Core/Common/Arm64Emitter.cpp\nindex ab701d612faa..4d6feb222fda 100644\n--- a/Source/Core/Common/Arm64Emitter.cpp\n+++ b/Source/Core/Common/Arm64Emitter.cpp\n@@ -21,6 +21,9 @@\n #ifdef _WIN32\n #include <Windows.h>\n #endif\n+#ifdef __APPLE__\n+#include <libkern/OSCacheControl.h>\n+#endif\n \n namespace Arm64Gen\n {\n@@ -342,7 +345,7 @@ void ARM64XEmitter::FlushIcacheSection(u8* start, u8* end)\n   if (start == end)\n     return;\n \n-#if defined(IOS)\n+#if defined(IOS) || defined(__APPLE__)\n   // Header file says this is equivalent to: sys_icache_invalidate(start, end - start);\n   sys_cache_control(kCacheFunctionPrepareForExecution, start, end - start);\n #elif defined(WIN32)\ndiff --git a/Source/Core/Common/ArmCPUDetect.cpp b/Source/Core/Common/ArmCPUDetect.cpp\nindex a603ff03fd51..4100df9f822c 100644\n--- a/Source/Core/Common/ArmCPUDetect.cpp\n+++ b/Source/Core/Common/ArmCPUDetect.cpp\n@@ -8,7 +8,7 @@\n #include <string>\n #include <thread>\n \n-#ifndef _WIN32\n+#if !defined(_WIN32) && !defined(__APPLE__)\n #ifndef __FreeBSD__\n #include <asm/hwcap.h>\n #endif\n@@ -71,7 +71,17 @@ void CPUInfo::Detect()\n   vendor = CPUVendor::ARM;\n   bFlushToZero = true;\n \n-#ifdef _WIN32\n+#ifdef __APPLE__\n+  num_cores = std::thread::hardware_concurrency();\n+\n+  // M-series CPUs have all of these\n+  bFP = true;\n+  bASIMD = true;\n+  bAES = true;\n+  bSHA1 = true;\n+  bSHA2 = true;\n+  bCRC32 = true;\n+#elif defined(_WIN32)\n   num_cores = std::thread::hardware_concurrency();\n \n   // Windows does not provide any mechanism for querying the system registers on ARMv8, unlike Linux\ndiff --git a/Source/Core/Common/MemoryUtil.cpp b/Source/Core/Common/MemoryUtil.cpp\nindex 44a601502780..ce5182c9769f 100644\n--- a/Source/Core/Common/MemoryUtil.cpp\n+++ b/Source/Core/Common/MemoryUtil.cpp\n@@ -16,6 +16,7 @@\n #include <windows.h>\n #include \"Common/StringUtil.h\"\n #else\n+#include <pthread.h>\n #include <stdio.h>\n #include <sys/mman.h>\n #include <sys/types.h>\n@@ -38,9 +39,15 @@ void* AllocateExecutableMemory(size_t size)\n #if defined(_WIN32)\n   void* ptr = VirtualAlloc(nullptr, size, MEM_COMMIT, PAGE_EXECUTE_READWRITE);\n #else\n-  void* ptr =\n-      mmap(nullptr, size, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_ANON | MAP_PRIVATE, -1, 0);\n-\n+  int map_flags = MAP_ANON | MAP_PRIVATE;\n+#if defined(__APPLE__)\n+  // This check is in place to prepare for x86_64 MAP_JIT support. While MAP_JIT did exist\n+  // prior to 10.14, it had restrictions on the number of JIT allocations that were removed\n+  // in 10.14.\n+  if (__builtin_available(macOS 10.14, *))\n+    map_flags |= MAP_JIT;\n+#endif\n+  void* ptr = mmap(nullptr, size, PROT_READ | PROT_WRITE | PROT_EXEC, map_flags, -1, 0);\n   if (ptr == MAP_FAILED)\n     ptr = nullptr;\n #endif\n@@ -50,6 +57,79 @@ void* AllocateExecutableMemory(size_t size)\n \n   return ptr;\n }\n+// This function is used to provide a counter for the JITPageWrite*Execute*\n+// functions to enable nesting. The static variable is wrapped in a a function\n+// to allow those functions to be called inside of the constructor of a static\n+// variable portably.\n+//\n+// The variable is thread_local as the W^X mode is specific to each running thread.\n+static int& JITPageWriteNestCounter()\n+{\n+  static thread_local int nest_counter = 0;\n+  return nest_counter;\n+}\n+\n+// Certain platforms (Mac OS on ARM) enforce that a single thread can only have write or\n+// execute permissions to pages at any given point of time. The two below functions\n+// are used to toggle between having write permissions or execute permissions.\n+//\n+// The default state of these allocations in Dolphin is for them to be executable,\n+// but not writeable. So, functions that are updating these pages should wrap their\n+// writes like below:\n+\n+// JITPageWriteEnableExecuteDisable();\n+// PrepareInstructionStreamForJIT();\n+// JITPageWriteDisableExecuteEnable();\n+\n+// These functions can be nested, in which case execution will only be enabled\n+// after the call to the JITPageWriteDisableExecuteEnable from the top most\n+// nesting level. Example:\n+\n+// [JIT page is in execute mode for the thread]\n+// JITPageWriteEnableExecuteDisable();\n+//   [JIT page is in write mode for the thread]\n+//   JITPageWriteEnableExecuteDisable();\n+//     [JIT page is in write mode for the thread]\n+//   JITPageWriteDisableExecuteEnable();\n+//   [JIT page is in write mode for the thread]\n+// JITPageWriteDisableExecuteEnable();\n+// [JIT page is in execute mode for the thread]\n+\n+// Allows a thread to write to executable memory, but not execute the data.\n+void JITPageWriteEnableExecuteDisable()\n+{\n+#if defined(_M_ARM_64) && defined(__APPLE__)\n+  if (JITPageWriteNestCounter() == 0)\n+  {\n+    if (__builtin_available(macOS 11.0, *))\n+    {\n+      pthread_jit_write_protect_np(0);\n+    }\n+  }\n+#endif\n+  JITPageWriteNestCounter()++;\n+}\n+// Allows a thread to execute memory allocated for execution, but not write to it.\n+void JITPageWriteDisableExecuteEnable()\n+{\n+  JITPageWriteNestCounter()--;\n+\n+  // Sanity check the NestCounter to identify underflow\n+  // This can indicate the calls to JITPageWriteDisableExecuteEnable()\n+  // are not matched with previous calls to JITPageWriteEnableExecuteDisable()\n+  if (JITPageWriteNestCounter() < 0)\n+    PanicAlertFmt(\"JITPageWriteNestCounter() underflowed\");\n+\n+#if defined(_M_ARM_64) && defined(__APPLE__)\n+  if (JITPageWriteNestCounter() == 0)\n+  {\n+    if (__builtin_available(macOS 11.0, *))\n+    {\n+      pthread_jit_write_protect_np(1);\n+    }\n+  }\n+#endif\n+}\n \n void* AllocateMemoryPages(size_t size)\n {\n@@ -128,7 +208,10 @@ void WriteProtectMemory(void* ptr, size_t size, bool allowExecute)\n   DWORD oldValue;\n   if (!VirtualProtect(ptr, size, allowExecute ? PAGE_EXECUTE_READ : PAGE_READONLY, &oldValue))\n     PanicAlertFmt(\"WriteProtectMemory failed!\\nVirtualProtect: {}\", GetLastErrorString());\n-#else\n+#elif !(defined(_M_ARM_64) && defined(__APPLE__))\n+  // MacOS 11.2 on ARM does not allow for changing the access permissions of pages\n+  // that were marked executable, instead it uses the protections offered by MAP_JIT\n+  // for write protection.\n   if (mprotect(ptr, size, allowExecute ? (PROT_READ | PROT_EXEC) : PROT_READ) != 0)\n     PanicAlertFmt(\"WriteProtectMemory failed!\\nmprotect: {}\", LastStrerrorString());\n #endif\n@@ -140,7 +223,10 @@ void UnWriteProtectMemory(void* ptr, size_t size, bool allowExecute)\n   DWORD oldValue;\n   if (!VirtualProtect(ptr, size, allowExecute ? PAGE_EXECUTE_READWRITE : PAGE_READWRITE, &oldValue))\n     PanicAlertFmt(\"UnWriteProtectMemory failed!\\nVirtualProtect: {}\", GetLastErrorString());\n-#else\n+#elif !(defined(_M_ARM_64) && defined(__APPLE__))\n+  // MacOS 11.2 on ARM does not allow for changing the access permissions of pages\n+  // that were marked executable, instead it uses the protections offered by MAP_JIT\n+  // for write protection.\n   if (mprotect(ptr, size,\n                allowExecute ? (PROT_READ | PROT_WRITE | PROT_EXEC) : PROT_WRITE | PROT_READ) != 0)\n   {\ndiff --git a/Source/Core/Common/MemoryUtil.h b/Source/Core/Common/MemoryUtil.h\nindex 72eb4f68f9ab..f13c55dab457 100644\n--- a/Source/Core/Common/MemoryUtil.h\n+++ b/Source/Core/Common/MemoryUtil.h\n@@ -10,6 +10,23 @@\n namespace Common\n {\n void* AllocateExecutableMemory(size_t size);\n+\n+// These two functions control the executable/writable state of the W^X memory\n+// allocations. More detailed documentation about them is in the .cpp file.\n+// In general where applicable the ScopedJITPageWriteAndNoExecute wrapper\n+// should be used to prevent bugs from not pairing up the calls properly.\n+\n+// Allows a thread to write to executable memory, but not execute the data.\n+void JITPageWriteEnableExecuteDisable();\n+// Allows a thread to execute memory allocated for execution, but not write to it.\n+void JITPageWriteDisableExecuteEnable();\n+// RAII Wrapper around JITPageWrite*Execute*(). When this is in scope the thread can\n+// write to executable memory but not execute it.\n+struct ScopedJITPageWriteAndNoExecute\n+{\n+  ScopedJITPageWriteAndNoExecute() { JITPageWriteEnableExecuteDisable(); }\n+  ~ScopedJITPageWriteAndNoExecute() { JITPageWriteDisableExecuteEnable(); }\n+};\n void* AllocateMemoryPages(size_t size);\n void FreeMemoryPages(void* ptr, size_t size);\n void* AllocateAlignedMemory(size_t size, size_t alignment);\ndiff --git a/Source/Core/Core/DolphinAnalytics.cpp b/Source/Core/Core/DolphinAnalytics.cpp\nindex 07e541af2b9a..11071d0678e6 100644\n--- a/Source/Core/Core/DolphinAnalytics.cpp\n+++ b/Source/Core/Core/DolphinAnalytics.cpp\n@@ -289,11 +289,17 @@ void DolphinAnalytics::MakeBaseBuilder()\n       s64 minor_version;  // NSInteger minorVersion\n       s64 patch_version;  // NSInteger patchVersion\n     };\n-\n+    // Under arm64, we need to call objc_msgSend to recieve a struct.\n+    // On x86_64, we need to explicitly call objc_msgSend_stret for a struct.\n+#if _M_ARM_64\n+#define msgSend objc_msgSend\n+#else\n+#define msgSend objc_msgSend_stret\n+#endif\n     // NSOperatingSystemVersion version = [processInfo operatingSystemVersion]\n-    OSVersion version = reinterpret_cast<OSVersion (*)(id, SEL)>(objc_msgSend_stret)(\n+    OSVersion version = reinterpret_cast<OSVersion (*)(id, SEL)>(msgSend)(\n         processInfo, sel_getUid(\"operatingSystemVersion\"));\n-\n+#undef msgSend\n     builder.AddData(\"osx-ver-major\", version.major_version);\n     builder.AddData(\"osx-ver-minor\", version.minor_version);\n     builder.AddData(\"osx-ver-bugfix\", version.patch_version);\ndiff --git a/Source/Core/Core/MachineContext.h b/Source/Core/Core/MachineContext.h\nindex 1ae0a1cc48eb..afad4ba0eee8 100644\n--- a/Source/Core/Core/MachineContext.h\n+++ b/Source/Core/Core/MachineContext.h\n@@ -67,6 +67,12 @@ typedef x86_thread_state64_t SContext;\n #define CTX_R14 __r14\n #define CTX_R15 __r15\n #define CTX_RIP __rip\n+#elif _M_ARM_64\n+typedef arm_thread_state64_t SContext;\n+#define CTX_REG(x) __x[x]\n+#define CTX_LR __x[30]\n+#define CTX_SP __sp\n+#define CTX_PC __pc\n #else\n #error No context definition for architecture\n #endif\ndiff --git a/Source/Core/Core/MemTools.cpp b/Source/Core/Core/MemTools.cpp\nindex 7559b1b6bc70..e269252a4ae2 100644\n--- a/Source/Core/Core/MemTools.cpp\n+++ b/Source/Core/Core/MemTools.cpp\n@@ -25,6 +25,20 @@\n #include <unistd.h>  // Needed for _POSIX_VERSION\n #endif\n \n+#if defined(__APPLE__)\n+#ifdef _M_X86_64\n+#define THREAD_STATE64_COUNT x86_THREAD_STATE64_COUNT\n+#define THREAD_STATE64 x86_THREAD_STATE64\n+#define thread_state64_t x86_thread_state64_t\n+#elif defined(_M_ARM_64)\n+#define THREAD_STATE64_COUNT ARM_THREAD_STATE64_COUNT\n+#define THREAD_STATE64 ARM_THREAD_STATE64\n+#define thread_state64_t arm_thread_state64_t\n+#else\n+#error Unsupported architecture\n+#endif\n+#endif\n+\n namespace EMM\n {\n #ifdef _WIN32\n@@ -123,7 +137,7 @@ static void ExceptionThread(mach_port_t port)\n     int64_t code[2];\n     int flavor;\n     mach_msg_type_number_t old_stateCnt;\n-    natural_t old_state[x86_THREAD_STATE64_COUNT];\n+    natural_t old_state[THREAD_STATE64_COUNT];\n     mach_msg_trailer_t trailer;\n   } msg_in;\n \n@@ -134,7 +148,7 @@ static void ExceptionThread(mach_port_t port)\n     kern_return_t RetCode;\n     int flavor;\n     mach_msg_type_number_t new_stateCnt;\n-    natural_t new_state[x86_THREAD_STATE64_COUNT];\n+    natural_t new_state[THREAD_STATE64_COUNT];\n   } msg_out;\n #pragma pack()\n   memset(&msg_in, 0xee, sizeof(msg_in));\n@@ -165,13 +179,13 @@ static void ExceptionThread(mach_port_t port)\n       return;\n     }\n \n-    if (msg_in.flavor != x86_THREAD_STATE64)\n+    if (msg_in.flavor != THREAD_STATE64)\n     {\n-      PanicAlertFmt(\"unknown flavor {} (expected {})\", msg_in.flavor, x86_THREAD_STATE64);\n+      PanicAlertFmt(\"unknown flavor {} (expected {})\", msg_in.flavor, THREAD_STATE64);\n       return;\n     }\n \n-    x86_thread_state64_t* state = (x86_thread_state64_t*)msg_in.old_state;\n+    thread_state64_t* state = (thread_state64_t*)msg_in.old_state;\n \n     bool ok = JitInterface::HandleFault((uintptr_t)msg_in.code[1], state);\n \n@@ -184,9 +198,9 @@ static void ExceptionThread(mach_port_t port)\n     if (ok)\n     {\n       msg_out.RetCode = KERN_SUCCESS;\n-      msg_out.flavor = x86_THREAD_STATE64;\n-      msg_out.new_stateCnt = x86_THREAD_STATE64_COUNT;\n-      memcpy(msg_out.new_state, msg_in.old_state, x86_THREAD_STATE64_COUNT * sizeof(natural_t));\n+      msg_out.flavor = THREAD_STATE64;\n+      msg_out.new_stateCnt = THREAD_STATE64_COUNT;\n+      memcpy(msg_out.new_state, msg_in.old_state, THREAD_STATE64_COUNT * sizeof(natural_t));\n     }\n     else\n     {\n@@ -218,7 +232,7 @@ void InstallExceptionHandler()\n   // Debuggers set the task port, so we grab the thread port.\n   CheckKR(\"thread_set_exception_ports\",\n           thread_set_exception_ports(mach_thread_self(), EXC_MASK_BAD_ACCESS, port,\n-                                     EXCEPTION_STATE | MACH_EXCEPTION_CODES, x86_THREAD_STATE64));\n+                                     EXCEPTION_STATE | MACH_EXCEPTION_CODES, THREAD_STATE64));\n   // ...and get rid of our copy so that MACH_NOTIFY_NO_SENDERS works.\n   CheckKR(\"mach_port_mod_refs\",\n           mach_port_mod_refs(mach_task_self(), port, MACH_PORT_RIGHT_SEND, -1));\ndiff --git a/Source/Core/Core/PowerPC/JitArm64/Jit.cpp b/Source/Core/Core/PowerPC/JitArm64/Jit.cpp\nindex 2d838d7ba6ad..b606b071eae8 100644\n--- a/Source/Core/Core/PowerPC/JitArm64/Jit.cpp\n+++ b/Source/Core/Core/PowerPC/JitArm64/Jit.cpp\n@@ -73,6 +73,8 @@ void JitArm64::Init()\n \n bool JitArm64::HandleFault(uintptr_t access_address, SContext* ctx)\n {\n+  // Ifdef this since the exception handler runs on a separate thread on macOS (ARM)\n+#if !(defined(__APPLE__) && defined(_M_ARM_64))\n   // We can't handle any fault from other threads.\n   if (!Core::IsCPUThread())\n   {\n@@ -80,6 +82,7 @@ bool JitArm64::HandleFault(uintptr_t access_address, SContext* ctx)\n     DoBacktrace(access_address, ctx);\n     return false;\n   }\n+#endif\n \n   bool success = false;\n \n@@ -124,6 +127,7 @@ void JitArm64::ClearCache()\n   m_handler_to_loc.clear();\n \n   blocks.Clear();\n+  const Common::ScopedJITPageWriteAndNoExecute enable_jit_page_writes;\n   ClearCodeSpace();\n   farcode.ClearCodeSpace();\n   UpdateMemoryOptions();\n@@ -596,6 +600,7 @@ void JitArm64::Jit(u32)\n   {\n     ClearCache();\n   }\n+  const Common::ScopedJITPageWriteAndNoExecute enable_jit_page_writes;\n \n   std::size_t block_size = m_code_buffer.size();\n   const u32 em_address = PowerPC::ppcState.pc;\ndiff --git a/Source/Core/Core/PowerPC/JitArm64/JitArm64Cache.cpp b/Source/Core/Core/PowerPC/JitArm64/JitArm64Cache.cpp\nindex b9fd37ec24cc..73dc1af127ea 100644\n--- a/Source/Core/Core/PowerPC/JitArm64/JitArm64Cache.cpp\n+++ b/Source/Core/Core/PowerPC/JitArm64/JitArm64Cache.cpp\n@@ -59,11 +59,11 @@ void JitArm64BlockCache::WriteLinkBlock(Arm64Gen::ARM64XEmitter& emit,\n \n void JitArm64BlockCache::WriteLinkBlock(const JitBlock::LinkData& source, const JitBlock* dest)\n {\n+  const Common::ScopedJITPageWriteAndNoExecute enable_jit_page_writes;\n   u8* location = source.exitPtrs;\n   ARM64XEmitter emit(location);\n \n   WriteLinkBlock(emit, source, dest);\n-\n   emit.FlushIcache();\n }\n \n@@ -71,9 +71,8 @@ void JitArm64BlockCache::WriteDestroyBlock(const JitBlock& block)\n {\n   // Only clear the entry points as we might still be within this block.\n   ARM64XEmitter emit(block.checkedEntry);\n-\n+  const Common::ScopedJITPageWriteAndNoExecute enable_jit_page_writes;\n   while (emit.GetWritableCodePtr() <= block.normalEntry)\n     emit.BRK(0x123);\n-\n   emit.FlushIcache();\n }\ndiff --git a/Source/Core/Core/PowerPC/JitArm64/JitArm64_BackPatch.cpp b/Source/Core/Core/PowerPC/JitArm64/JitArm64_BackPatch.cpp\nindex 4f1aca8e602c..23236a524e9b 100644\n--- a/Source/Core/Core/PowerPC/JitArm64/JitArm64_BackPatch.cpp\n+++ b/Source/Core/Core/PowerPC/JitArm64/JitArm64_BackPatch.cpp\n@@ -289,6 +289,7 @@ bool JitArm64::HandleFastmemFault(uintptr_t access_address, SContext* ctx)\n   if ((const u8*)ctx->CTX_PC - fault_location > fastmem_area_length)\n     return false;\n \n+  const Common::ScopedJITPageWriteAndNoExecute enable_jit_page_writes;\n   ARM64XEmitter emitter((u8*)fault_location);\n \n   emitter.BL(slow_handler_iter->second.slowmem_code);\n@@ -300,6 +301,7 @@ bool JitArm64::HandleFastmemFault(uintptr_t access_address, SContext* ctx)\n   m_fault_to_handler.erase(slow_handler_iter);\n \n   emitter.FlushIcache();\n+\n   ctx->CTX_PC = reinterpret_cast<std::uintptr_t>(fault_location);\n   return true;\n }\ndiff --git a/Source/Core/Core/PowerPC/JitArm64/JitAsm.cpp b/Source/Core/Core/PowerPC/JitArm64/JitAsm.cpp\nindex 001607d5e4f8..d61280fe8ba9 100644\n--- a/Source/Core/Core/PowerPC/JitArm64/JitAsm.cpp\n+++ b/Source/Core/Core/PowerPC/JitArm64/JitAsm.cpp\n@@ -25,6 +25,8 @@ using namespace Arm64Gen;\n \n void JitArm64::GenerateAsm()\n {\n+  const Common::ScopedJITPageWriteAndNoExecute enable_jit_page_writes;\n+\n   // This value is all of the callee saved registers that we are required to save.\n   // According to the AACPS64 we need to save R19 ~ R30 and Q8 ~ Q15.\n   const u32 ALL_CALLEE_SAVED = 0x7FF80000;\ndiff --git a/Source/Core/Core/PowerPC/JitInterface.cpp b/Source/Core/Core/PowerPC/JitInterface.cpp\nindex e36b27314c82..adb12f2fa349 100644\n--- a/Source/Core/Core/PowerPC/JitInterface.cpp\n+++ b/Source/Core/Core/PowerPC/JitInterface.cpp\n@@ -71,9 +71,8 @@ CPUCoreBase* InitJitCore(PowerPC::CPUCore core)\n     break;\n \n   default:\n-    PanicAlertFmtT(\"The selected CPU emulation core ({0}) is not available. \"\n-                   \"Please select a different CPU emulation core in the settings.\",\n-                   core);\n+    // Under this case the caller overrides the CPU core to the default and logs that\n+    // it performed the override.\n     g_jit = nullptr;\n     return nullptr;\n   }\ndiff --git a/Source/Core/DolphinQt/CMakeLists.txt b/Source/Core/DolphinQt/CMakeLists.txt\nindex 288e313e3ffc..9ae47143177f 100644\n--- a/Source/Core/DolphinQt/CMakeLists.txt\n+++ b/Source/Core/DolphinQt/CMakeLists.txt\n@@ -473,6 +473,8 @@ if(APPLE)\n   set_target_properties(dolphin-emu PROPERTIES\n     MACOSX_BUNDLE true\n     MACOSX_BUNDLE_INFO_PLIST ${CMAKE_CURRENT_SOURCE_DIR}/Info.plist.in\n+    XCODE_ATTRIBUTE_CODE_SIGN_ENTITLEMENTS \"${CMAKE_CURRENT_SOURCE_DIR}/DolphinEmu.entitlements\"\n+    XCODE_ATTRIBUTE_OTHER_CODE_SIGN_FLAGS \"--deep --options=runtime\"\n     OUTPUT_NAME Dolphin\n     )\n \n@@ -516,6 +518,22 @@ if(APPLE)\n     POST_BUILD COMMAND\n     ${CMAKE_INSTALL_NAME_TOOL} -add_rpath \"@executable_path/../Frameworks/\"\n     $<TARGET_FILE:dolphin-emu>)\n+\n+  if(MACOS_CODE_SIGNING)\n+    # Code sign make file builds\n+    add_custom_command(TARGET dolphin-emu\n+      POST_BUILD COMMAND\n+      /usr/bin/codesign -f -s \"${MACOS_CODE_SIGNING_IDENTITY}\" --deep --options=runtime --entitlements \"${CMAKE_SOURCE_DIR}/Source/Core/DolphinQt/DolphinEmu.entitlements\" \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/Dolphin.app\" || true)\n+    \n+    # Code sign builds for build systems that do have release/debug variants (Xcode)\n+    add_custom_command(TARGET dolphin-emu\n+      POST_BUILD COMMAND\n+      /usr/bin/codesign -f -s \"${MACOS_CODE_SIGNING_IDENTITY}\" --deep --options=runtime --entitlements \"${CMAKE_SOURCE_DIR}/Source/Core/DolphinQt/DolphinEmu.entitlements\" \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY_DEBUG}/Dolphin.app\" || true)\n+      \n+    add_custom_command(TARGET dolphin-emu\n+      POST_BUILD COMMAND\n+      /usr/bin/codesign -f -s \"${MACOS_CODE_SIGNING_IDENTITY}\" --deep --options=runtime --entitlements \"${CMAKE_SOURCE_DIR}/Source/Core/DolphinQt/DolphinEmu.entitlements\" \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY_RELEASE}/Dolphin.app\" || true)\n+  endif()\n else()\n   install(TARGETS dolphin-emu RUNTIME DESTINATION ${bindir})\n endif()\ndiff --git a/Source/Core/DolphinQt/DolphinEmu.entitlements b/Source/Core/DolphinQt/DolphinEmu.entitlements\nnew file mode 100644\nindex 000000000000..50c57c58c12b\n--- /dev/null\n+++ b/Source/Core/DolphinQt/DolphinEmu.entitlements\n@@ -0,0 +1,17 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n+<plist version=\"1.0\">\n+<dict>\n+\t<key>com.apple.security.cs.allow-jit</key>\n+\t<true/>\n+\t<!-- Needed for GameCube microphone emulation -->\n+\t<key>com.apple.security.device.audio-input</key>\n+\t<true/>\n+\t<!-- TODO: It is likely this requirement is coming from Qt, but should confirm -->\n+  \t<key>com.apple.security.automation.apple-events</key>\n+  \t<true/>\n+\t<!-- This is needed to use adhoc signed linked libraries -->\n+ \t<key>com.apple.security.cs.disable-library-validation</key> \n+  \t<true/>\n+</dict>\n+</plist>\ndiff --git a/Source/Core/MacUpdater/CMakeLists.txt b/Source/Core/MacUpdater/CMakeLists.txt\nindex 725917e030f2..65e7d99a9227 100644\n--- a/Source/Core/MacUpdater/CMakeLists.txt\n+++ b/Source/Core/MacUpdater/CMakeLists.txt\n@@ -13,6 +13,8 @@ set(SOURCES\n add_executable(MacUpdater ${SOURCES})\n \n set(MacUpdater_NAME \"Dolphin Updater\")\n+set(MacUpdater_BIN_DIR ${CMAKE_BINARY_DIR}/Binaries)\n+set(MacUpdater_BUNDLE_PATH ${MacUpdater_BIN_DIR}/${MacUpdater_NAME}.app)\n \n set_target_properties(MacUpdater PROPERTIES\n   MACOSX_BUNDLE true\n@@ -53,8 +55,24 @@ foreach(sb ${STORYBOARDS})\n \n   add_custom_command(TARGET MacUpdater POST_BUILD\n                      COMMAND ${IBTOOL} --errors --warnings --notices --output-format human-readable-text\n-                                       --compile ${MacUpdater_BIN_DIR}/${MacUpdater_NAME}.app/Contents/Resources/${sb}c\n+                                       --compile ${MacUpdater_BUNDLE_PATH}/Contents/Resources/${sb}c\n                      ${CMAKE_CURRENT_SOURCE_DIR}/${sb}\n                      COMMENT \"Compiling Storyboard ${sb}...\")\n endforeach()\n \n+if(MACOS_CODE_SIGNING)\n+  if (MACOS_CODE_SIGNING_IDENTITY_UPDATER STREQUAL \"\")\n+    set(MACOS_CODE_SIGNING_IDENTITY_UPDATER \"${MACOS_CODE_SIGNING_IDENTITY}\")\n+  endif()\n+\n+  # Make file build code sign\n+  add_custom_command(TARGET MacUpdater POST_BUILD\n+    COMMAND test ${MacUpdater_BUNDLE_PATH} || /usr/bin/codesign -f -s \"${MACOS_CODE_SIGNING_IDENTITY_UPDATER}\" --deep --options runtime ${MacUpdater_BUNDLE_PATH})\n+  \n+  # Xcode build code sign\n+  add_custom_command(TARGET MacUpdater POST_BUILD\n+    COMMAND test \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY_DEBUG}/${MacUpdater_NAME}.app\" || /usr/bin/codesign -f -s \"${MACOS_CODE_SIGNING_IDENTITY_UPDATER}\" --deep --options runtime \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY_DEBUG}/${MacUpdater_NAME}.app\")\n+    \n+  add_custom_command(TARGET MacUpdater POST_BUILD\n+    COMMAND test \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY_RELEASE}/${MacUpdater_NAME}.app\" || /usr/bin/codesign -f -s \"${MACOS_CODE_SIGNING_IDENTITY_UPDATER}\" --deep --options runtime \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY_RELEASE}/${MacUpdater_NAME}.app\")\n+endif()\ndiff --git a/Source/Core/UICommon/AutoUpdate.cpp b/Source/Core/UICommon/AutoUpdate.cpp\nindex 0a5ad10c4074..5808d3ac2e03 100644\n--- a/Source/Core/UICommon/AutoUpdate.cpp\n+++ b/Source/Core/UICommon/AutoUpdate.cpp\n@@ -140,7 +140,11 @@ static std::string GetPlatformID()\n #if defined _WIN32\n   return \"win\";\n #elif defined __APPLE__\n+#if defined(MACOS_UNIVERSAL_BUILD)\n+  return \"macos-universal\";\n+#else\n   return \"macos\";\n+#endif\n #else\n   return \"unknown\";\n #endif\ndiff --git a/Source/Core/VideoCommon/VertexLoaderARM64.cpp b/Source/Core/VideoCommon/VertexLoaderARM64.cpp\nindex e546c42be8e7..afd2f0f21d91 100644\n--- a/Source/Core/VideoCommon/VertexLoaderARM64.cpp\n+++ b/Source/Core/VideoCommon/VertexLoaderARM64.cpp\n@@ -54,6 +54,7 @@ VertexLoaderARM64::VertexLoaderARM64(const TVtxDesc& vtx_desc, const VAT& vtx_at\n     : VertexLoaderBase(vtx_desc, vtx_att), m_float_emit(this)\n {\n   AllocCodeSpace(4096);\n+  const Common::ScopedJITPageWriteAndNoExecute enable_jit_page_writes;\n   ClearCodeSpace();\n   GenerateVertexLoader();\n   WriteProtect();\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Controller Input Issue**: SDL2 may not be properly recognizing the Switch Pro Controller via USB-C. Verify if both ARM and x64 versions of SDL2 are installed and detected in CMake.\n\n2. **Build Errors**:\n   - Ensure `CMake` is a universal binary; if it\u2019s not, install a universal version.\n   - Missing `libzstd`. Check if it\u2019s installed and linked correctly. Consider using vendored libraries to avoid conflicts.\n\n3. **Dual Core Crashes**: Problems observed with Dolphin hanging or crashing when Dual Core is enabled, possibly linked to concurrency issues on ARM64. Test by disabling Dual Core to stabilize performance.\n\n4. **CMake Configuration**: Clean build setup and re-run CMake. Specific path issues noted with FFmpeg and zstd; adjust search paths to avoid broken configurations.\n\n5. **Unit Test Failed**: Run unit tests to identify potential issues in the codebase, particularly around memory ordering in ARM64 architecture. Use `make unittests` to execute.\n\n6. **Dependency Management**: Confirm and install all required dependencies via Homebrew. Ensure paths for ARM and Intel versions of Homebrew do not overlap incorrectly."
      }
    ],
    "codediff_length": 40766
  },
  {
    "index": 77,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/Source/Core/DolphinQt/CMakeLists.txt b/Source/Core/DolphinQt/CMakeLists.txt\nindex fe7a42604e3c..537c87c936d3 100644\n--- a/Source/Core/DolphinQt/CMakeLists.txt\n+++ b/Source/Core/DolphinQt/CMakeLists.txt\n@@ -208,6 +208,8 @@ add_executable(dolphin-emu\n   Config/WiimoteControllersWidget.h\n   Debugger/BreakpointWidget.cpp\n   Debugger/BreakpointWidget.h\n+  Debugger/CodeDiffDialog.cpp\n+  Debugger/CodeDiffDialog.h\n   Debugger/CodeViewWidget.cpp\n   Debugger/CodeViewWidget.h\n   Debugger/CodeWidget.cpp\ndiff --git a/Source/Core/DolphinQt/Debugger/CodeDiffDialog.cpp b/Source/Core/DolphinQt/Debugger/CodeDiffDialog.cpp\nnew file mode 100644\nindex 000000000000..bb2fc03c1bb6\n--- /dev/null\n+++ b/Source/Core/DolphinQt/Debugger/CodeDiffDialog.cpp\n@@ -0,0 +1,517 @@\n+// Copyright 2022 Dolphin Emulator Project\r\n+// SPDX-License-Identifier: GPL-2.0-or-later\r\n+\r\n+#include \"DolphinQt/Debugger/CodeDiffDialog.h\"\r\n+\r\n+#include <algorithm>\r\n+#include <string>\r\n+#include <vector>\r\n+\r\n+#include <QHBoxLayout>\r\n+#include <QLabel>\r\n+#include <QMenu>\r\n+#include <QPushButton>\r\n+#include <QTableWidget>\r\n+#include <QVBoxLayout>\r\n+\r\n+#include \"Common/StringUtil.h\"\r\n+#include \"Core/Core.h\"\r\n+#include \"Core/Debugger/PPCDebugInterface.h\"\r\n+#include \"Core/HW/CPU.h\"\r\n+#include \"Core/PowerPC/JitInterface.h\"\r\n+#include \"Core/PowerPC/MMU.h\"\r\n+#include \"Core/PowerPC/PPCSymbolDB.h\"\r\n+#include \"Core/PowerPC/PowerPC.h\"\r\n+#include \"Core/PowerPC/Profiler.h\"\r\n+\r\n+#include \"DolphinQt/Debugger/CodeWidget.h\"\r\n+#include \"DolphinQt/Host.h\"\r\n+#include \"DolphinQt/QtUtils/ModalMessageBox.h\"\r\n+#include \"DolphinQt/Settings.h\"\r\n+\r\n+CodeDiffDialog::CodeDiffDialog(CodeWidget* parent) : QDialog(parent), m_code_widget(parent)\r\n+{\r\n+  setWindowTitle(tr(\"Code Diff Tool\"));\r\n+  CreateWidgets();\r\n+  auto& settings = Settings::GetQSettings();\r\n+  restoreGeometry(settings.value(QStringLiteral(\"diffdialog/geometry\")).toByteArray());\r\n+  ConnectWidgets();\r\n+}\r\n+\r\n+void CodeDiffDialog::reject()\r\n+{\r\n+  ClearData();\r\n+  auto& settings = Settings::GetQSettings();\r\n+  settings.setValue(QStringLiteral(\"diffdialog/geometry\"), saveGeometry());\r\n+  QDialog::reject();\r\n+}\r\n+\r\n+void CodeDiffDialog::CreateWidgets()\r\n+{\r\n+  auto* btns_layout = new QGridLayout;\r\n+  m_exclude_btn = new QPushButton(tr(\"Code did not get executed\"));\r\n+  m_include_btn = new QPushButton(tr(\"Code has been executed\"));\r\n+  m_record_btn = new QPushButton(tr(\"Start Recording\"));\r\n+  m_record_btn->setCheckable(true);\r\n+  m_record_btn->setStyleSheet(\r\n+      QStringLiteral(\"QPushButton:checked { background-color: rgb(150, 0, 0); border-style: solid; \"\r\n+                     \"border-width: 3px; border-color: rgb(150,0,0); color: rgb(255, 255, 255);}\"));\r\n+\r\n+  m_exclude_btn->setEnabled(false);\r\n+  m_include_btn->setEnabled(false);\r\n+\r\n+  btns_layout->addWidget(m_exclude_btn, 0, 0);\r\n+  btns_layout->addWidget(m_include_btn, 0, 1);\r\n+  btns_layout->addWidget(m_record_btn, 0, 2);\r\n+\r\n+  auto* labels_layout = new QHBoxLayout;\r\n+  m_exclude_size_label = new QLabel(tr(\"Excluded: 0\"));\r\n+  m_include_size_label = new QLabel(tr(\"Included: 0\"));\r\n+\r\n+  btns_layout->addWidget(m_exclude_size_label, 1, 0);\r\n+  btns_layout->addWidget(m_include_size_label, 1, 1);\r\n+\r\n+  m_matching_results_table = new QTableWidget();\r\n+  m_matching_results_table->setColumnCount(5);\r\n+  m_matching_results_table->setHorizontalHeaderLabels(\r\n+      {tr(\"Address\"), tr(\"Total Hits\"), tr(\"Hits\"), tr(\"Symbol\"), tr(\"Inspected\")});\r\n+  m_matching_results_table->setSelectionMode(QAbstractItemView::SingleSelection);\r\n+  m_matching_results_table->setSelectionBehavior(QAbstractItemView::SelectRows);\r\n+  m_matching_results_table->setSizePolicy(QSizePolicy::Expanding, QSizePolicy::Expanding);\r\n+  m_matching_results_table->setContextMenuPolicy(Qt::CustomContextMenu);\r\n+  m_matching_results_table->setColumnWidth(0, 60);\r\n+  m_matching_results_table->setColumnWidth(1, 60);\r\n+  m_matching_results_table->setColumnWidth(2, 4);\r\n+  m_matching_results_table->setColumnWidth(3, 210);\r\n+  m_matching_results_table->setColumnWidth(4, 65);\r\n+  m_reset_btn = new QPushButton(tr(\"Reset All\"));\r\n+  m_reset_btn->setSizePolicy(QSizePolicy::Fixed, QSizePolicy::Fixed);\r\n+  m_help_btn = new QPushButton(tr(\"Help\"));\r\n+  m_help_btn->setSizePolicy(QSizePolicy::Fixed, QSizePolicy::Fixed);\r\n+  auto* help_reset_layout = new QHBoxLayout;\r\n+  help_reset_layout->addWidget(m_reset_btn, 0, Qt::AlignLeft);\r\n+  help_reset_layout->addWidget(m_help_btn, 0, Qt::AlignRight);\r\n+\r\n+  auto* layout = new QVBoxLayout();\r\n+  layout->addLayout(btns_layout);\r\n+  layout->addLayout(labels_layout);\r\n+  layout->addWidget(m_matching_results_table);\r\n+  layout->addLayout(help_reset_layout);\r\n+\r\n+  setLayout(layout);\r\n+  resize(515, 400);\r\n+}\r\n+\r\n+void CodeDiffDialog::ConnectWidgets()\r\n+{\r\n+  connect(m_record_btn, &QPushButton::toggled, this, &CodeDiffDialog::OnRecord);\r\n+  connect(m_include_btn, &QPushButton::pressed, [this]() { Update(true); });\r\n+  connect(m_exclude_btn, &QPushButton::pressed, [this]() { Update(false); });\r\n+  connect(m_matching_results_table, &QTableWidget::itemClicked, [this]() { OnClickItem(); });\r\n+  connect(m_reset_btn, &QPushButton::pressed, this, &CodeDiffDialog::ClearData);\r\n+  connect(m_help_btn, &QPushButton::pressed, this, &CodeDiffDialog::InfoDisp);\r\n+  connect(m_matching_results_table, &CodeDiffDialog::customContextMenuRequested, this,\r\n+          &CodeDiffDialog::OnContextMenu);\r\n+}\r\n+\r\n+void CodeDiffDialog::OnClickItem()\r\n+{\r\n+  UpdateItem();\r\n+  auto address = m_matching_results_table->currentItem()->data(Qt::UserRole).toUInt();\r\n+  m_code_widget->SetAddress(address, CodeViewWidget::SetAddressUpdate::WithDetailedUpdate);\r\n+}\r\n+\r\n+void CodeDiffDialog::ClearData()\r\n+{\r\n+  if (m_record_btn->isChecked())\r\n+    m_record_btn->toggle();\r\n+  ClearBlockCache();\r\n+  m_matching_results_table->clear();\r\n+  m_matching_results_table->setRowCount(0);\r\n+  m_matching_results_table->setHorizontalHeaderLabels(\r\n+      {tr(\"Address\"), tr(\"Total Hits\"), tr(\"Hits\"), tr(\"Symbol\"), tr(\"Inspected\")});\r\n+  m_matching_results_table->setEditTriggers(QAbstractItemView::EditTrigger::NoEditTriggers);\r\n+  m_exclude_size_label->setText(tr(\"Excluded: %1\").arg(0));\r\n+  m_include_size_label->setText(tr(\"Included: %1\").arg(0));\r\n+  m_exclude_btn->setEnabled(false);\r\n+  m_include_btn->setEnabled(false);\r\n+  m_include_active = false;\r\n+  // Swap is used instead of clear for efficiency in the case of huge m_include/m_exclude\r\n+  std::vector<Diff>().swap(m_include);\r\n+  std::vector<Diff>().swap(m_exclude);\r\n+  JitInterface::SetProfilingState(JitInterface::ProfilingState::Disabled);\r\n+}\r\n+\r\n+void CodeDiffDialog::ClearBlockCache()\r\n+{\r\n+  Core::State old_state = Core::GetState();\r\n+\r\n+  if (old_state == Core::State::Running)\r\n+    Core::SetState(Core::State::Paused);\r\n+\r\n+  JitInterface::ClearCache();\r\n+\r\n+  if (old_state == Core::State::Running)\r\n+    Core::SetState(Core::State::Running);\r\n+}\r\n+\r\n+void CodeDiffDialog::OnRecord(bool enabled)\r\n+{\r\n+  if (m_failed_requirements)\r\n+  {\r\n+    m_failed_requirements = false;\r\n+    return;\r\n+  }\r\n+\r\n+  if (Core::GetState() == Core::State::Uninitialized)\r\n+  {\r\n+    ModalMessageBox::information(this, tr(\"Code Diff Tool\"),\r\n+                                 tr(\"Emulation must be started to record.\"));\r\n+    m_failed_requirements = true;\r\n+    m_record_btn->setChecked(false);\r\n+    return;\r\n+  }\r\n+\r\n+  if (g_symbolDB.IsEmpty())\r\n+  {\r\n+    ModalMessageBox::warning(\r\n+        this, tr(\"Code Diff Tool\"),\r\n+        tr(\"Symbol map not found.\\n\\nIf one does not exist, you can generate one from \"\r\n+           \"the Menu bar:\\nSymbols -> Generate Symbols From ->\\n\\tAddress | Signature \"\r\n+           \"Database | RSO Modules\"));\r\n+    m_failed_requirements = true;\r\n+    m_record_btn->setChecked(false);\r\n+    return;\r\n+  }\r\n+\r\n+  JitInterface::ProfilingState state;\r\n+\r\n+  if (enabled)\r\n+  {\r\n+    ClearBlockCache();\r\n+    m_record_btn->setText(tr(\"Stop Recording\"));\r\n+    state = JitInterface::ProfilingState::Enabled;\r\n+    m_exclude_btn->setEnabled(true);\r\n+    m_include_btn->setEnabled(true);\r\n+  }\r\n+  else\r\n+  {\r\n+    ClearBlockCache();\r\n+    m_record_btn->setText(tr(\"Start Recording\"));\r\n+    state = JitInterface::ProfilingState::Disabled;\r\n+    m_exclude_btn->setEnabled(false);\r\n+    m_include_btn->setEnabled(false);\r\n+  }\r\n+\r\n+  m_record_btn->update();\r\n+  JitInterface::SetProfilingState(state);\r\n+}\r\n+\r\n+void CodeDiffDialog::OnInclude()\r\n+{\r\n+  const auto recorded_symbols = CalculateSymbolsFromProfile();\r\n+\r\n+  if (recorded_symbols.empty())\r\n+    return;\r\n+\r\n+  if (m_include.empty() && m_exclude.empty())\r\n+  {\r\n+    m_include = recorded_symbols;\r\n+    m_include_active = true;\r\n+  }\r\n+  else if (m_include.empty())\r\n+  {\r\n+    // If include becomes empty after having items on it, don't refill it until after a reset.\r\n+    if (m_include_active)\r\n+      return;\r\n+\r\n+    // If we are building include for the first time and we have an exlcude list, then include =\r\n+    // recorded - excluded.\r\n+    m_include = recorded_symbols;\r\n+    RemoveMatchingSymbolsFromIncludes(m_exclude);\r\n+    m_include_active = true;\r\n+  }\r\n+  else\r\n+  {\r\n+    // If include already exists, keep items that are in both include and recorded. Exclude list\r\n+    // becomes irrelevant.\r\n+    RemoveMissingSymbolsFromIncludes(recorded_symbols);\r\n+  }\r\n+}\r\n+\r\n+void CodeDiffDialog::OnExclude()\r\n+{\r\n+  const auto recorded_symbols = CalculateSymbolsFromProfile();\r\n+  if (m_include.empty() && m_exclude.empty())\r\n+  {\r\n+    m_exclude = recorded_symbols;\r\n+  }\r\n+  else if (m_include.empty())\r\n+  {\r\n+    // If there is only an exclude list, update it.\r\n+    for (auto& iter : recorded_symbols)\r\n+    {\r\n+      auto pos = std::lower_bound(m_exclude.begin(), m_exclude.end(), iter.symbol);\r\n+\r\n+      if (pos == m_exclude.end() || pos->symbol != iter.symbol)\r\n+        m_exclude.insert(pos, iter);\r\n+    }\r\n+  }\r\n+  else\r\n+  {\r\n+    // If include already exists, the exclude list will have been used to trim it, so the exclude\r\n+    // list is now irrelevant, as anythng not on the include list is effectively excluded.\r\n+    // Exclude/subtract recorded items from the include list.\r\n+    RemoveMatchingSymbolsFromIncludes(recorded_symbols);\r\n+  }\r\n+}\r\n+\r\n+std::vector<Diff> CodeDiffDialog::CalculateSymbolsFromProfile()\r\n+{\r\n+  Profiler::ProfileStats prof_stats;\r\n+  auto& blockstats = prof_stats.block_stats;\r\n+  JitInterface::GetProfileResults(&prof_stats);\r\n+  std::vector<Diff> current;\r\n+  current.reserve(20000);\r\n+\r\n+  // Convert blockstats to smaller struct Diff. Exclude repeat functions via symbols.\r\n+  for (auto& iter : blockstats)\r\n+  {\r\n+    Diff tmp_diff;\r\n+    std::string symbol = g_symbolDB.GetDescription(iter.addr);\r\n+    if (!std::any_of(current.begin(), current.end(),\r\n+                     [&symbol](Diff& v) { return v.symbol == symbol; }))\r\n+    {\r\n+      tmp_diff.symbol = symbol;\r\n+      tmp_diff.addr = iter.addr;\r\n+      tmp_diff.hits = iter.run_count;\r\n+      tmp_diff.total_hits = iter.run_count;\r\n+      current.push_back(tmp_diff);\r\n+    }\r\n+  }\r\n+\r\n+  sort(current.begin(), current.end(),\r\n+       [](const Diff& v1, const Diff& v2) { return (v1.symbol < v2.symbol); });\r\n+\r\n+  return current;\r\n+}\r\n+\r\n+void CodeDiffDialog::RemoveMissingSymbolsFromIncludes(const std::vector<Diff>& symbol_diff)\r\n+{\r\n+  m_include.erase(std::remove_if(m_include.begin(), m_include.end(),\r\n+                                 [&](const Diff& v) {\r\n+                                   auto arg = std::none_of(\r\n+                                       symbol_diff.begin(), symbol_diff.end(), [&](const Diff& p) {\r\n+                                         return p.symbol == v.symbol || p.addr == v.addr;\r\n+                                       });\r\n+                                   return arg;\r\n+                                 }),\r\n+                  m_include.end());\r\n+  for (auto& original_includes : m_include)\r\n+  {\r\n+    auto pos = std::lower_bound(symbol_diff.begin(), symbol_diff.end(), original_includes.symbol);\r\n+    if (pos != symbol_diff.end() &&\r\n+        (pos->symbol == original_includes.symbol || pos->addr == original_includes.addr))\r\n+    {\r\n+      original_includes.total_hits += pos->hits;\r\n+      original_includes.hits = pos->hits;\r\n+    }\r\n+  }\r\n+}\r\n+\r\n+void CodeDiffDialog::RemoveMatchingSymbolsFromIncludes(const std::vector<Diff>& symbol_list)\r\n+{\r\n+  m_include.erase(std::remove_if(m_include.begin(), m_include.end(),\r\n+                                 [&](const Diff& i) {\r\n+                                   return std::any_of(\r\n+                                       symbol_list.begin(), symbol_list.end(), [&](const Diff& s) {\r\n+                                         return i.symbol == s.symbol || i.addr == s.addr;\r\n+                                       });\r\n+                                 }),\r\n+                  m_include.end());\r\n+}\r\n+\r\n+void CodeDiffDialog::Update(bool include)\r\n+{\r\n+  // Wrap everything in a pause\r\n+  Core::State old_state = Core::GetState();\r\n+  if (old_state == Core::State::Running)\r\n+    Core::SetState(Core::State::Paused);\r\n+\r\n+  // Main process\r\n+  if (include)\r\n+  {\r\n+    OnInclude();\r\n+  }\r\n+  else\r\n+  {\r\n+    OnExclude();\r\n+  }\r\n+\r\n+  const auto create_item = [](const QString string = {}, const u32 address = 0x00000000) {\r\n+    QTableWidgetItem* item = new QTableWidgetItem(string);\r\n+    item->setData(Qt::UserRole, address);\r\n+    item->setFlags(Qt::ItemIsEnabled | Qt::ItemIsSelectable);\r\n+    return item;\r\n+  };\r\n+\r\n+  int i = 0;\r\n+  m_matching_results_table->clear();\r\n+  m_matching_results_table->setRowCount(i);\r\n+  m_matching_results_table->setHorizontalHeaderLabels(\r\n+      {tr(\"Address\"), tr(\"Total Hits\"), tr(\"Hits\"), tr(\"Symbol\"), tr(\"Inspected\")});\r\n+\r\n+  for (auto& iter : m_include)\r\n+  {\r\n+    m_matching_results_table->setRowCount(i + 1);\r\n+\r\n+    QString fix_sym = QString::fromStdString(iter.symbol);\r\n+    fix_sym.replace(QStringLiteral(\"\\t\"), QStringLiteral(\"  \"));\r\n+\r\n+    m_matching_results_table->setItem(\r\n+        i, 0, create_item(QStringLiteral(\"%1\").arg(iter.addr, 1, 16), iter.addr));\r\n+    m_matching_results_table->setItem(\r\n+        i, 1, create_item(QStringLiteral(\"%1\").arg(iter.total_hits), iter.addr));\r\n+    m_matching_results_table->setItem(i, 2,\r\n+                                      create_item(QStringLiteral(\"%1\").arg(iter.hits), iter.addr));\r\n+    m_matching_results_table->setItem(i, 3,\r\n+                                      create_item(QStringLiteral(\"%1\").arg(fix_sym), iter.addr));\r\n+    m_matching_results_table->setItem(i, 4, create_item(QStringLiteral(\"\"), iter.addr));\r\n+    i++;\r\n+  }\r\n+\r\n+  // If we have ruled out all functions from being included.\r\n+  if (m_include_active && m_include.empty())\r\n+  {\r\n+    m_matching_results_table->setRowCount(1);\r\n+    m_matching_results_table->setItem(0, 3, create_item(tr(\"No possible functions left. Reset.\")));\r\n+  }\r\n+\r\n+  m_exclude_size_label->setText(tr(\"Excluded: %1\").arg(m_exclude.size()));\r\n+  m_include_size_label->setText(tr(\"Included: %1\").arg(m_include.size()));\r\n+\r\n+  JitInterface::ClearCache();\r\n+  if (old_state == Core::State::Running)\r\n+    Core::SetState(Core::State::Running);\r\n+}\r\n+\r\n+void CodeDiffDialog::InfoDisp()\r\n+{\r\n+  ModalMessageBox::information(\r\n+      this, tr(\"Code Diff Tool Help\"),\r\n+      tr(\"Used to find functions based on when they should be running.\\nSimilar to Cheat Engine \"\r\n+         \"Ultimap.\\n\"\r\n+         \"A symbol map must be loaded prior to use.\\n\"\r\n+         \"Include/Exclude lists will persist on ending/restarting emulation.\\nThese lists \"\r\n+         \"will not persist on Dolphin close.\"\r\n+         \"\\n\\n'Start Recording': \"\r\n+         \"keeps track of what functions run.\\n'Stop Recording': erases current \"\r\n+         \"recording without any change to the lists.\\n'Code did not get executed': click while \"\r\n+         \"recording, will add recorded functions to an exclude \"\r\n+         \"list, then reset the recording list.\\n'Code has been executed': click while recording, \"\r\n+         \"will add recorded function to an include list, then reset the recording list.\\n\\nAfter \"\r\n+         \"you use \"\r\n+         \"both exclude and include once, the exclude list will be subtracted from the include \"\r\n+         \"list \"\r\n+         \"and any includes left over will be displayed.\\nYou can continue to use \"\r\n+         \"'Code did not get executed'/'Code has been executed' to narrow down the \"\r\n+         \"results.\"));\r\n+  ModalMessageBox::information(\r\n+      this, tr(\"Code Diff Tool Help\"),\r\n+      tr(\"Example:\\n\"\r\n+         \"You want to find a function that runs when HP is modified.\\n1. Start recording and \"\r\n+         \"play the game without letting HP be modified, then press 'Code did not get \"\r\n+         \"executed'.\\n2. Immediately gain/lose HP and press 'Code has been executed'.\\n3. Repeat \"\r\n+         \"1 or 2 to \"\r\n+         \"narrow down the results.\\nIncludes (Code has been executed) should \"\r\n+         \"have short recordings focusing on what you want.\\n\\nPressing 'Code has been \"\r\n+         \"executed' twice will only keep functions that ran for both recordings. Hits will update \"\r\n+         \"to reflect the last recording's \"\r\n+         \"number of Hits. Total Hits will reflect the total number of \"\r\n+         \"times a function has been executed until the lists are cleared with Reset.\\n\\nRight \"\r\n+         \"click -> 'Set blr' will place a \"\r\n+         \"blr at the top of the symbol.\\n\"));\r\n+}\r\n+\r\n+void CodeDiffDialog::OnContextMenu()\r\n+{\r\n+  if (m_matching_results_table->currentItem() == nullptr)\r\n+    return;\r\n+  UpdateItem();\r\n+  QMenu* menu = new QMenu(this);\r\n+  menu->addAction(tr(\"&Go to start of function\"), this, &CodeDiffDialog::OnGoTop);\r\n+  menu->addAction(tr(\"Set &blr\"), this, &CodeDiffDialog::OnSetBLR);\r\n+  menu->addAction(tr(\"&Delete\"), this, &CodeDiffDialog::OnDelete);\r\n+  menu->exec(QCursor::pos());\r\n+}\r\n+\r\n+void CodeDiffDialog::OnGoTop()\r\n+{\r\n+  auto item = m_matching_results_table->currentItem();\r\n+  if (!item)\r\n+    return;\r\n+  Common::Symbol* symbol = g_symbolDB.GetSymbolFromAddr(item->data(Qt::UserRole).toUInt());\r\n+  if (!symbol)\r\n+    return;\r\n+  m_code_widget->SetAddress(symbol->address, CodeViewWidget::SetAddressUpdate::WithDetailedUpdate);\r\n+}\r\n+\r\n+void CodeDiffDialog::OnDelete()\r\n+{\r\n+  // Delete from include list and qtable widget\r\n+  auto item = m_matching_results_table->currentItem();\r\n+  if (!item)\r\n+    return;\r\n+  int row = m_matching_results_table->row(item);\r\n+  if (row == -1)\r\n+    return;\r\n+  // TODO: If/when sorting is ever added, .erase needs to find item position instead; leaving as is\r\n+  // for performance\r\n+  if (!m_include.empty())\r\n+  {\r\n+    m_include.erase(m_include.begin() + row);\r\n+  }\r\n+  m_matching_results_table->removeRow(row);\r\n+}\r\n+\r\n+void CodeDiffDialog::OnSetBLR()\r\n+{\r\n+  auto item = m_matching_results_table->currentItem();\r\n+  if (!item)\r\n+    return;\r\n+\r\n+  Common::Symbol* symbol = g_symbolDB.GetSymbolFromAddr(item->data(Qt::UserRole).toUInt());\r\n+  if (!symbol)\r\n+    return;\r\n+  PowerPC::debug_interface.SetPatch(symbol->address, 0x4E800020);\r\n+\r\n+  int row = item->row();\r\n+  m_matching_results_table->item(row, 0)->setForeground(QBrush(Qt::red));\r\n+  m_matching_results_table->item(row, 1)->setForeground(QBrush(Qt::red));\r\n+  m_matching_results_table->item(row, 2)->setForeground(QBrush(Qt::red));\r\n+  m_matching_results_table->item(row, 3)->setForeground(QBrush(Qt::red));\r\n+  m_matching_results_table->item(row, 4)->setForeground(QBrush(Qt::red));\r\n+  m_matching_results_table->item(row, 4)->setText(QStringLiteral(\"X\"));\r\n+\r\n+  m_code_widget->Update();\r\n+}\r\n+\r\n+void CodeDiffDialog::UpdateItem()\r\n+{\r\n+  QTableWidgetItem* item = m_matching_results_table->currentItem();\r\n+  if (!item)\r\n+    return;\r\n+\r\n+  int row = m_matching_results_table->row(item);\r\n+  if (row == -1)\r\n+    return;\r\n+  uint address = item->data(Qt::UserRole).toUInt();\r\n+\r\n+  auto symbolName = g_symbolDB.GetDescription(address);\r\n+  if (symbolName == \" --- \")\r\n+    return;\r\n+\r\n+  QString newName =\r\n+      QString::fromStdString(symbolName).replace(QStringLiteral(\"\\t\"), QStringLiteral(\"  \"));\r\n+  m_matching_results_table->item(row, 3)->setText(newName);\r\n+}\r\ndiff --git a/Source/Core/DolphinQt/Debugger/CodeDiffDialog.h b/Source/Core/DolphinQt/Debugger/CodeDiffDialog.h\nnew file mode 100644\nindex 000000000000..33b1d4e108ad\n--- /dev/null\n+++ b/Source/Core/DolphinQt/Debugger/CodeDiffDialog.h\n@@ -0,0 +1,71 @@\n+// Copyright 2022 Dolphin Emulator Project\r\n+// SPDX-License-Identifier: GPL-2.0-or-later\r\n+\r\n+#pragma once\r\n+\r\n+#include <QDialog>\r\n+#include <string>\r\n+#include <vector>\r\n+#include \"Common/CommonTypes.h\"\r\n+\r\n+class CodeWidget;\r\n+class QLabel;\r\n+class QPushButton;\r\n+class QTableWidget;\r\n+\r\n+struct Diff\r\n+{\r\n+  u32 addr;\r\n+  std::string symbol;\r\n+  u32 hits;\r\n+  u32 total_hits;\r\n+\r\n+  bool operator<(const std::string& val) const { return symbol < val; }\r\n+};\r\n+\r\n+class CodeDiffDialog : public QDialog\r\n+{\r\n+  Q_OBJECT\r\n+\r\n+public:\r\n+  explicit CodeDiffDialog(CodeWidget* parent);\r\n+  void reject() override;\r\n+\r\n+private:\r\n+  void CreateWidgets();\r\n+  void ConnectWidgets();\r\n+  void ClearData();\r\n+  void ClearBlockCache();\r\n+  void OnClickItem();\r\n+  void OnRecord(bool enabled);\r\n+  std::vector<Diff> CalculateSymbolsFromProfile();\r\n+  void OnInclude();\r\n+  void OnExclude();\r\n+  void RemoveMissingSymbolsFromIncludes(const std::vector<Diff>& symbol_diff);\r\n+  void RemoveMatchingSymbolsFromIncludes(const std::vector<Diff>& symbol_list);\r\n+  void Update(bool include);\r\n+  void InfoDisp();\r\n+\r\n+  void OnContextMenu();\r\n+\r\n+  void OnGoTop();\r\n+  void OnDelete();\r\n+  void OnSetBLR();\r\n+\r\n+  void UpdateItem();\r\n+\r\n+  QTableWidget* m_matching_results_table;\r\n+  QLabel* m_exclude_size_label;\r\n+  QLabel* m_include_size_label;\r\n+  QPushButton* m_exclude_btn;\r\n+  QPushButton* m_include_btn;\r\n+  QPushButton* m_record_btn;\r\n+  QPushButton* m_reset_btn;\r\n+  QPushButton* m_help_btn;\r\n+  CodeWidget* m_code_widget;\r\n+\r\n+  std::vector<Diff> m_exclude;\r\n+  std::vector<Diff> m_include;\r\n+  bool m_failed_requirements = false;\r\n+  bool m_include_active = false;\r\n+};\r\ndiff --git a/Source/Core/DolphinQt/Debugger/CodeWidget.cpp b/Source/Core/DolphinQt/Debugger/CodeWidget.cpp\nindex 67dd73c04b19..3be5a75776b7 100644\n--- a/Source/Core/DolphinQt/Debugger/CodeWidget.cpp\n+++ b/Source/Core/DolphinQt/Debugger/CodeWidget.cpp\n@@ -9,6 +9,7 @@\n #include <QGroupBox>\n #include <QLineEdit>\n #include <QListWidget>\n+#include <QPushButton>\n #include <QSplitter>\n #include <QTableWidget>\n #include <QWidget>\n@@ -95,6 +96,7 @@ void CodeWidget::CreateWidgets()\n \n   m_search_address = new QLineEdit;\n   m_search_symbols = new QLineEdit;\n+  m_code_diff = new QPushButton(tr(\"Diff\"));\n   m_code_view = new CodeViewWidget;\n \n   m_search_address->setPlaceholderText(tr(\"Search Address\"));\n@@ -146,6 +148,7 @@ void CodeWidget::CreateWidgets()\n \n   layout->addWidget(m_search_address, 0, 0);\n   layout->addWidget(m_search_symbols, 0, 1);\n+  layout->addWidget(m_code_diff, 0, 2);\n   layout->addWidget(m_code_splitter, 1, 0, -1, -1);\n \n   QWidget* widget = new QWidget(this);\n@@ -158,6 +161,7 @@ void CodeWidget::ConnectWidgets()\n   connect(m_search_address, &QLineEdit::textChanged, this, &CodeWidget::OnSearchAddress);\n   connect(m_search_address, &QLineEdit::returnPressed, this, &CodeWidget::OnSearchAddress);\n   connect(m_search_symbols, &QLineEdit::textChanged, this, &CodeWidget::OnSearchSymbols);\n+  connect(m_code_diff, &QPushButton::pressed, this, &CodeWidget::OnDiff);\n \n   connect(m_symbols_list, &QListWidget::itemPressed, this, &CodeWidget::OnSelectSymbol);\n   connect(m_callstack_list, &QListWidget::itemPressed, this, &CodeWidget::OnSelectCallstack);\n@@ -176,6 +180,16 @@ void CodeWidget::ConnectWidgets()\n   connect(m_code_view, &CodeViewWidget::ShowMemory, this, &CodeWidget::ShowMemory);\n }\n \n+void CodeWidget::OnDiff()\n+{\n+  if (!m_diff_dialog)\n+    m_diff_dialog = new CodeDiffDialog(this);\n+  m_diff_dialog->setWindowFlag(Qt::WindowMinimizeButtonHint);\n+  m_diff_dialog->show();\n+  m_diff_dialog->raise();\n+  m_diff_dialog->activateWindow();\n+}\n+\n void CodeWidget::OnSearchAddress()\n {\n   bool good = true;\ndiff --git a/Source/Core/DolphinQt/Debugger/CodeWidget.h b/Source/Core/DolphinQt/Debugger/CodeWidget.h\nindex c269902189a9..fcf67d89a657 100644\n--- a/Source/Core/DolphinQt/Debugger/CodeWidget.h\n+++ b/Source/Core/DolphinQt/Debugger/CodeWidget.h\n@@ -7,6 +7,7 @@\n #include <QString>\n \n #include \"Common/CommonTypes.h\"\n+#include \"DolphinQt/Debugger/CodeDiffDialog.h\"\n #include \"DolphinQt/Debugger/CodeViewWidget.h\"\n \n class QCloseEvent;\n@@ -14,6 +15,7 @@ class QLineEdit;\n class QShowEvent;\n class QSplitter;\n class QListWidget;\n+class QPushButton;\n class QTableWidget;\n \n namespace Common\n@@ -35,6 +37,7 @@ class CodeWidget : public QDockWidget\n   void ShowPC();\n   void SetPC();\n \n+  void OnDiff();\n   void ToggleBreakpoint();\n   void AddBreakpoint();\n   void SetAddress(u32 address, CodeViewWidget::SetAddressUpdate update);\n@@ -63,8 +66,10 @@ class CodeWidget : public QDockWidget\n   void closeEvent(QCloseEvent*) override;\n   void showEvent(QShowEvent* event) override;\n \n+  CodeDiffDialog* m_diff_dialog = nullptr;\n   QLineEdit* m_search_address;\n   QLineEdit* m_search_symbols;\n+  QPushButton* m_code_diff;\n \n   QListWidget* m_callstack_list;\n   QListWidget* m_symbols_list;\ndiff --git a/Source/Core/DolphinQt/DolphinQt.vcxproj b/Source/Core/DolphinQt/DolphinQt.vcxproj\nindex 636cc514b66a..acfb18540181 100644\n--- a/Source/Core/DolphinQt/DolphinQt.vcxproj\n+++ b/Source/Core/DolphinQt/DolphinQt.vcxproj\n@@ -124,6 +124,7 @@\n     <ClCompile Include=\"Config\\WiimoteControllersWidget.cpp\" />\n     <ClCompile Include=\"ConvertDialog.cpp\" />\n     <ClCompile Include=\"Debugger\\BreakpointWidget.cpp\" />\n+    <ClCompile Include=\"Debugger\\CodeDiffDialog.cpp\" />\n     <ClCompile Include=\"Debugger\\CodeViewWidget.cpp\" />\n     <ClCompile Include=\"Debugger\\CodeWidget.cpp\" />\n     <ClCompile Include=\"Debugger\\JITWidget.cpp\" />\n@@ -308,6 +309,7 @@\n     <QtMoc Include=\"Config\\WiimoteControllersWidget.h\" />\n     <QtMoc Include=\"ConvertDialog.h\" />\n     <QtMoc Include=\"Debugger\\BreakpointWidget.h\" />\n+    <QtMoc Include=\"Debugger\\CodeDiffDialog.h\" />\n     <QtMoc Include=\"Debugger\\CodeViewWidget.h\" />\n     <QtMoc Include=\"Debugger\\CodeWidget.h\" />\n     <QtMoc Include=\"Debugger\\JITWidget.h\" />\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "### Review Summary\n\n1. **UI/UX Improvements Required**:\n   - Implement labels for the Included/Excluded values consistently. (`m_exclude_size_label`, `m_include_size_label` should show numbers with accompanying text).\n   - Redesign button placement for better intuitiveness; consider adding a dedicated Start, Pause/Resume, and Stop button for recording.\n   - Disable buttons when not applicable to prevent user error.\n\n2. **Add Functionality**:\n   - Introduce a \"Filter our routine(s) where callcount is not\" button.\n   - Implement a clear distinction between the recording and filtering sections, potentially using `QGroupBox`.\n\n3. **Fixes Required**:\n   - Clear definition of the \"Reset All\" functionality.\n   - Fix crashes on renaming functions in table headers\u2014shouldn't cause a crash if the symbol no longer exists.\n   - Ensure toggling \"blr\" correctly reverts previous actions, as it doesn't currently function as expected.\n\n4. **Refactoring Suggestions**:\n   - Transition from `QListWidget` to `QTableWidget` to support headers and sorting capabilities; this will help clarify the table's structure and visibility.\n\nNext steps:\n- Address identified UI/UX improvements and additional functionality before merging."
      }
    ],
    "codediff_length": 26294
  },
  {
    "index": 78,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/README.rst b/README.rst\nindex ffb7b8df..cd56057d 100644\n--- a/README.rst\n+++ b/README.rst\n@@ -78,7 +78,7 @@ Full Python API\n \n * ``AnnoyIndex(f, metric)`` returns a new index that's read-write and stores vector of ``f`` dimensions. Metric can be ``\"angular\"``, ``\"euclidean\"``, ``\"manhattan\"``, ``\"hamming\"``, or ``\"dot\"``.\n * ``a.add_item(i, v)`` adds item ``i`` (any nonnegative integer) with vector ``v``. Note that it will allocate memory for ``max(i)+1`` items.\n-* ``a.build(n_trees)`` builds a forest of ``n_trees`` trees. More trees gives higher precision when querying. After calling ``build``, no more items can be added.\n+* ``a.build(n_trees, n_jobs=-1)`` builds a forest of ``n_trees`` trees. More trees gives higher precision when querying. After calling ``build``, no more items can be added. ``n_jobs`` specifies the number of threads used to build the trees. ``n_jobs=-1`` uses all available CPU cores.\n * ``a.save(fn, prefault=False)`` saves the index to disk and loads it (see next function). After saving, no more items can be added.\n * ``a.load(fn, prefault=False)`` loads (mmaps) an index from disk. If `prefault` is set to `True`, it will pre-read the entire file into memory (using mmap with `MAP_POPULATE`). Default is `False`.\n * ``a.unload()`` unloads.\ndiff --git a/README_GO.rst b/README_GO.rst\nindex 2f2c1ca8..35ebfd07 100644\n--- a/README_GO.rst\n+++ b/README_GO.rst\n@@ -58,7 +58,7 @@ Right now it only accepts integers as identifiers for items. Note that it will a\n Full Go API\n ---------------\n \n-See annoygomodule.h. Generally the same as Python API except some arguments are not optional. \n+See annoygomodule.h. Generally the same as Python API except some arguments are not optional. Go binding does not support multithreaded build.\n \n Tests\n -------\ndiff --git a/README_Lua.md b/README_Lua.md\nindex b24a567f..cab0583a 100644\n--- a/README_Lua.md\n+++ b/README_Lua.md\n@@ -64,7 +64,7 @@ end\n Full Lua API\n ------------\n \n-Lua API closely resembles Python API, see main README.\n+Lua API closely resembles Python API, see main README. Lua binding does not support multithreaded build.\n \n \n Tests\ndiff --git a/examples/precision_test.cpp b/examples/precision_test.cpp\nindex 2c006487..2c9bb907 100644\n--- a/examples/precision_test.cpp\n+++ b/examples/precision_test.cpp\n@@ -25,7 +25,7 @@ int precision(int f=40, int n=1000000){\n \n \t//******************************************************\n \t//Building the tree\n-\tAnnoyIndex<int, double, Angular, Kiss32Random> t = AnnoyIndex<int, double, Angular, Kiss32Random>(f);\n+\tAnnoyIndex<int, double, Angular, Kiss32Random, AnnoyIndexMultiThreadedBuildPolicy> t = AnnoyIndex<int, double, Angular, Kiss32Random, AnnoyIndexMultiThreadedBuildPolicy>(f);\n \n \tstd::cout << \"Building index ... be patient !!\" << std::endl;\n \tstd::cout << \"\\\"Trees that are slow to grow bear the best fruit\\\" (Moliere)\" << std::endl;\ndiff --git a/examples/s_compile_cpp.sh b/examples/s_compile_cpp.sh\nindex 687a6082..b1dd341d 100755\n--- a/examples/s_compile_cpp.sh\n+++ b/examples/s_compile_cpp.sh\n@@ -2,6 +2,6 @@\n \n \n echo \"compiling precision example...\"\n-cmd=\"g++ precision_test.cpp -o precision_test -std=c++11\"\n+cmd=\"g++ precision_test.cpp -DANNOYLIB_MULTITHREADED_BUILD -o precision_test -std=c++14 -pthread\"\n eval $cmd\n echo \"Done\"\ndiff --git a/setup.py b/setup.py\nindex 147483ee..7d46d619 100644\n--- a/setup.py\n+++ b/setup.py\n@@ -19,6 +19,7 @@\n import codecs\n import os\n import platform\n+import sys\n \n readme_note = \"\"\"\\\n .. note::\n@@ -49,10 +50,19 @@\n if os.name != 'nt':\n     extra_compile_args += ['-O3', '-ffast-math', '-fno-associative-math']\n \n+# Add multithreaded build flag for all platforms using Python 3 and\n+# for non-Windows Python 2 platforms\n+python_major_version = sys.version_info[0]\n+if python_major_version == 3 or (python_major_version == 2 and os.name != 'nt'):\n+    extra_compile_args += ['-DANNOYLIB_MULTITHREADED_BUILD']\n+\n+    if os.name != 'nt':\n+        extra_compile_args += ['-std=c++14']\n+\n # #349: something with OS X Mojave causes libstd not to be found\n if platform.system() == 'Darwin':\n-    extra_compile_args += ['-std=c++11', '-mmacosx-version-min=10.9']\n-    extra_link_args += ['-stdlib=libc++', '-mmacosx-version-min=10.9']\n+    extra_compile_args += ['-mmacosx-version-min=10.12']\n+    extra_link_args += ['-stdlib=libc++', '-mmacosx-version-min=10.12']\n \n # Manual configuration, you're on your own here.\n manual_compiler_args = os.environ.get('ANNOY_COMPILER_ARGS', None)\ndiff --git a/src/annoygomodule.h b/src/annoygomodule.h\nindex 005ed065..a25574e1 100644\n--- a/src/annoygomodule.h\n+++ b/src/annoygomodule.h\n@@ -17,7 +17,7 @@ class AnnoyIndex {\n     ptr->add_item(item, w);\n   };\n   void build(int q) {\n-    ptr->build(q);\n+    ptr->build(q, 1);\n   };\n   bool save(const char* filename, bool prefault) {\n     return ptr->save(filename, prefault);\n@@ -69,7 +69,7 @@ class AnnoyIndexAngular : public AnnoyIndex\n {\n  public:\n   AnnoyIndexAngular(int f) {\n-    ptr = new ::AnnoyIndex<int32_t, float, ::Angular, ::Kiss64Random>(f);\n+    ptr = new ::AnnoyIndex<int32_t, float, ::Angular, ::Kiss64Random, AnnoyIndexSingleThreadedBuildPolicy>(f);\n     this->f = f;\n   }\n };\n@@ -77,7 +77,7 @@ class AnnoyIndexAngular : public AnnoyIndex\n class AnnoyIndexEuclidean : public AnnoyIndex {\n  public:\n   AnnoyIndexEuclidean(int f) {\n-    ptr = new ::AnnoyIndex<int32_t, float, ::Euclidean, ::Kiss64Random>(f);\n+    ptr = new ::AnnoyIndex<int32_t, float, ::Euclidean, ::Kiss64Random, AnnoyIndexSingleThreadedBuildPolicy>(f);\n     this->f = f;\n   }\n };\n@@ -85,7 +85,7 @@ class AnnoyIndexEuclidean : public AnnoyIndex {\n class AnnoyIndexManhattan : public AnnoyIndex {\n  public:\n   AnnoyIndexManhattan(int f) {\n-    ptr = new ::AnnoyIndex<int32_t, float, ::Manhattan, ::Kiss64Random>(f);\n+    ptr = new ::AnnoyIndex<int32_t, float, ::Manhattan, ::Kiss64Random, AnnoyIndexSingleThreadedBuildPolicy>(f);\n     this->f = f;\n   }\n };\ndiff --git a/src/annoylib.h b/src/annoylib.h\nindex 517a6d9b..3fcf89fa 100644\n--- a/src/annoylib.h\n+++ b/src/annoylib.h\n@@ -58,6 +58,12 @@ typedef signed __int64    int64_t;\n #include <queue>\n #include <limits>\n \n+#ifdef ANNOYLIB_MULTITHREADED_BUILD\n+#include <thread>\n+#include <mutex>\n+#include <shared_mutex>\n+#endif\n+\n #ifdef _MSC_VER\n // Needed for Visual Studio to disable runtime checks for mempcy\n #pragma runtime_checks(\"s\", off)\n@@ -104,7 +110,6 @@ inline void set_error_from_string(char **error, const char* msg) {\n #ifndef _MSC_VER\n #define popcount __builtin_popcountll\n #else // See #293, #358\n-#define isnan(x) _isnan(x)\n #define popcount cole_popcount\n #endif\n \n@@ -594,8 +599,8 @@ struct DotProduct : Angular {\n     // Step one: compute the norm of each vector and store that in its extra dimension (f-1)\n     for (S i = 0; i < node_count; i++) {\n       Node* node = get_node_ptr<S, Node>(nodes, _s, i);\n-      T norm = sqrt(dot(node->v, node->v, f));\n-      if (isnan(norm)) norm = 0;\n+      T d = dot(node->v, node->v, f);\n+      T norm = d < 0 ? 0 : sqrt(d);\n       node->dot_factor = norm;\n     }\n \n@@ -612,9 +617,8 @@ struct DotProduct : Angular {\n     for (S i = 0; i < node_count; i++) {\n       Node* node = get_node_ptr<S, Node>(nodes, _s, i);\n       T node_norm = node->dot_factor;\n-\n-      T dot_factor = sqrt(pow(max_norm, static_cast<T>(2.0)) - pow(node_norm, static_cast<T>(2.0)));\n-      if (isnan(dot_factor)) dot_factor = 0;\n+      T squared_norm_diff = pow(max_norm, static_cast<T>(2.0)) - pow(node_norm, static_cast<T>(2.0));\n+      T dot_factor = squared_norm_diff < 0 ? 0 : sqrt(squared_norm_diff);\n \n       node->dot_factor = dot_factor;\n     }\n@@ -817,7 +821,7 @@ class AnnoyIndexInterface {\n   // Note that the methods with an **error argument will allocate memory and write the pointer to that string if error is non-NULL\n   virtual ~AnnoyIndexInterface() {};\n   virtual bool add_item(S item, const T* w, char** error=NULL) = 0;\n-  virtual bool build(int q, char** error=NULL) = 0;\n+  virtual bool build(int q, int n_threads=-1, char** error=NULL) = 0;\n   virtual bool unbuild(char** error=NULL) = 0;\n   virtual bool save(const char* filename, bool prefault=false, char** error=NULL) = 0;\n   virtual void unload() = 0;\n@@ -833,7 +837,7 @@ class AnnoyIndexInterface {\n   virtual bool on_disk_build(const char* filename, char** error=NULL) = 0;\n };\n \n-template<typename S, typename T, typename Distance, typename Random>\n+template<typename S, typename T, typename Distance, typename Random, class ThreadedBuildPolicy>\n   class AnnoyIndex : public AnnoyIndexInterface<S, T> {\n   /*\n    * We use random projection to build a forest of binary trees of all items.\n@@ -850,12 +854,13 @@ template<typename S, typename T, typename Distance, typename Random>\n   const int _f;\n   size_t _s;\n   S _n_items;\n-  Random _random;\n   void* _nodes; // Could either be mmapped, or point to a memory buffer that we reallocate\n   S _n_nodes;\n   S _nodes_size;\n   vector<S> _roots;\n   S _K;\n+  bool _is_seeded;\n+  int _seed;\n   bool _loaded;\n   bool _verbose;\n   int _fd;\n@@ -863,7 +868,7 @@ template<typename S, typename T, typename Distance, typename Random>\n   bool _built;\n public:\n \n-   AnnoyIndex(int f) : _f(f), _random() {\n+   AnnoyIndex(int f) : _f(f) {\n     _s = offsetof(Node, v) + _f * sizeof(T); // Size of each node\n     _verbose = false;\n     _built = false;\n@@ -929,7 +934,7 @@ template<typename S, typename T, typename Distance, typename Random>\n     return true;\n   }\n     \n-  bool build(int q, char** error=NULL) {\n+  bool build(int q, int n_threads=-1, char** error=NULL) {\n     if (_loaded) {\n       set_error_from_string(error, \"You can't build a loaded index\");\n       return false;\n@@ -943,21 +948,8 @@ template<typename S, typename T, typename Distance, typename Random>\n     D::template preprocess<T, S, Node>(_nodes, _s, _n_items, _f);\n \n     _n_nodes = _n_items;\n-    while (1) {\n-      if (q == -1 && _n_nodes >= _n_items * 2)\n-        break;\n-      if (q != -1 && _roots.size() >= (size_t)q)\n-        break;\n-      if (_verbose) showUpdate(\"pass %zd...\\n\", _roots.size());\n \n-      vector<S> indices;\n-      for (S i = 0; i < _n_items; i++) {\n-        if (_get(i)->n_descendants >= 1) // Issue #223\n-          indices.push_back(i);\n-      }\n-\n-      _roots.push_back(_make_tree(indices, true));\n-    }\n+    ThreadedBuildPolicy::template build<S, T>(this, q, n_threads);\n \n     // Also, copy the roots into the last segment of the array\n     // This way we can load them faster without reading the whole file\n@@ -1035,6 +1027,7 @@ template<typename S, typename T, typename Distance, typename Random>\n     _n_nodes = 0;\n     _nodes_size = 0;\n     _on_disk = false;\n+    _is_seeded = false;\n     _roots.clear();\n   }\n \n@@ -1142,29 +1135,82 @@ template<typename S, typename T, typename Distance, typename Random>\n   }\n \n   void set_seed(int seed) {\n+    _is_seeded = true;\n+    _seed = seed;\n+  }\n+\n+  void thread_build(int q, int thread_idx, ThreadedBuildPolicy& threaded_build_policy) {\n+    Random _random;\n+    // Each thread needs its own seed, otherwise each thread would be building the same tree(s)\n+    int seed = _is_seeded ? _seed + thread_idx : thread_idx;\n     _random.set_seed(seed);\n+\n+    vector<S> thread_roots;\n+    while (1) {\n+      if (q == -1) {\n+        threaded_build_policy.lock_n_nodes();\n+        if (_n_nodes >= 2 * _n_items) {\n+          threaded_build_policy.unlock_n_nodes();\n+          break;\n+        }\n+        threaded_build_policy.unlock_n_nodes();\n+      } else {\n+        if (thread_roots.size() >= (size_t)q) {\n+          break;\n+        }\n+      }\n+\n+      if (_verbose) showUpdate(\"pass %zd...\\n\", thread_roots.size());\n+\n+      vector<S> indices;\n+      threaded_build_policy.lock_shared_nodes();\n+      for (S i = 0; i < _n_items; i++) {\n+        if (_get(i)->n_descendants >= 1) { // Issue #223\n+          indices.push_back(i);\n+        }\n+      }\n+      threaded_build_policy.unlock_shared_nodes();\n+\n+      thread_roots.push_back(_make_tree(indices, true, _random, threaded_build_policy));\n+    }\n+\n+    threaded_build_policy.lock_roots();\n+    _roots.insert(_roots.end(), thread_roots.begin(), thread_roots.end());\n+    threaded_build_policy.unlock_roots();\n   }\n \n protected:\n+  void _reallocate_nodes(S n) {\n+    const double reallocation_factor = 1.3;\n+    S new_nodes_size = std::max(n, (S) ((_nodes_size + 1) * reallocation_factor));\n+    void *old = _nodes;\n+    \n+    if (_on_disk) {\n+      if (!remap_memory_and_truncate(&_nodes, _fd, \n+          static_cast<size_t>(_s) * static_cast<size_t>(_nodes_size), \n+          static_cast<size_t>(_s) * static_cast<size_t>(new_nodes_size)) && \n+          _verbose)\n+          showUpdate(\"File truncation error\\n\");\n+    } else {\n+      _nodes = realloc(_nodes, _s * new_nodes_size);\n+      memset((char *) _nodes + (_nodes_size * _s) / sizeof(char), 0, (new_nodes_size - _nodes_size) * _s);\n+    }\n+    \n+    _nodes_size = new_nodes_size;\n+    if (_verbose) showUpdate(\"Reallocating to %d nodes: old_address=%p, new_address=%p\\n\", new_nodes_size, old, _nodes);\n+  }\n+\n+  void _allocate_size(S n, ThreadedBuildPolicy& threaded_build_policy) {\n+    if (n > _nodes_size) {\n+      threaded_build_policy.lock_nodes();\n+      _reallocate_nodes(n);\n+      threaded_build_policy.unlock_nodes();\n+    }\n+  }\n+\n   void _allocate_size(S n) {\n     if (n > _nodes_size) {\n-      const double reallocation_factor = 1.3;\n-      S new_nodes_size = std::max(n, (S) ((_nodes_size + 1) * reallocation_factor));\n-      void *old = _nodes;\n-      \n-      if (_on_disk) {\n-        if (!remap_memory_and_truncate(&_nodes, _fd, \n-            static_cast<size_t>(_s) * static_cast<size_t>(_nodes_size), \n-            static_cast<size_t>(_s) * static_cast<size_t>(new_nodes_size)) && \n-            _verbose)\n-            showUpdate(\"File truncation error\\n\");\n-      } else {\n-        _nodes = realloc(_nodes, _s * new_nodes_size);\n-        memset((char *) _nodes + (_nodes_size * _s) / sizeof(char), 0, (new_nodes_size - _nodes_size) * _s);\n-      }\n-      \n-      _nodes_size = new_nodes_size;\n-      if (_verbose) showUpdate(\"Reallocating to %d nodes: old_address=%p, new_address=%p\\n\", new_nodes_size, old, _nodes);\n+      _reallocate_nodes(n);\n     }\n   }\n \n@@ -1179,7 +1225,7 @@ template<typename S, typename T, typename Distance, typename Random>\n     return std::max(f, 1-f);\n   }\n \n-  S _make_tree(const vector<S>& indices, bool is_root) {\n+  S _make_tree(const vector<S>& indices, bool is_root, Random& _random, ThreadedBuildPolicy& threaded_build_policy) {\n     // The basic rule is that if we have <= _K items, then it's a leaf node, otherwise it's a split node.\n     // There's some regrettable complications caused by the problem that root nodes have to be \"special\":\n     // 1. We identify root nodes by the arguable logic that _n_items == n->n_descendants, regardless of how many descendants they actually have\n@@ -1189,8 +1235,12 @@ template<typename S, typename T, typename Distance, typename Random>\n       return indices[0];\n \n     if (indices.size() <= (size_t)_K && (!is_root || (size_t)_n_items <= (size_t)_K || indices.size() == 1)) {\n-      _allocate_size(_n_nodes + 1);\n+      threaded_build_policy.lock_n_nodes();\n+      _allocate_size(_n_nodes + 1, threaded_build_policy);\n       S item = _n_nodes++;\n+      threaded_build_policy.unlock_n_nodes();\n+\n+      threaded_build_policy.lock_shared_nodes();\n       Node* m = _get(item);\n       m->n_descendants = is_root ? _n_items : (S)indices.size();\n \n@@ -1200,9 +1250,12 @@ template<typename S, typename T, typename Distance, typename Random>\n       // Only copy when necessary to avoid crash in MSVC 9. #293\n       if (!indices.empty())\n         memcpy(m->children, &indices[0], indices.size() * sizeof(S));\n+\n+      threaded_build_policy.unlock_shared_nodes();\n       return item;\n     }\n \n+    threaded_build_policy.lock_shared_nodes();\n     vector<Node*> children;\n     for (size_t i = 0; i < indices.size(); i++) {\n       S j = indices[i];\n@@ -1233,6 +1286,7 @@ template<typename S, typename T, typename Distance, typename Random>\n       if (_split_imbalance(children_indices[0], children_indices[1]) < 0.95)\n         break;\n     }\n+    threaded_build_policy.unlock_shared_nodes();\n \n     // If we didn't find a hyperplane, just randomize sides as a last option\n     while (_split_imbalance(children_indices[0], children_indices[1]) > 0.99) {\n@@ -1259,13 +1313,17 @@ template<typename S, typename T, typename Distance, typename Random>\n     m->n_descendants = is_root ? _n_items : (S)indices.size();\n     for (int side = 0; side < 2; side++) {\n       // run _make_tree for the smallest child first (for cache locality)\n-      m->children[side^flip] = _make_tree(children_indices[side^flip], false);\n+      m->children[side^flip] = _make_tree(children_indices[side^flip], false, _random, threaded_build_policy);\n     }\n \n-\n-    _allocate_size(_n_nodes + 1);\n+    threaded_build_policy.lock_n_nodes();\n+    _allocate_size(_n_nodes + 1, threaded_build_policy);\n     S item = _n_nodes++;\n+    threaded_build_policy.unlock_n_nodes();\n+\n+    threaded_build_policy.lock_shared_nodes();\n     memcpy(_get(item), m, _s);\n+    threaded_build_policy.unlock_shared_nodes();\n \n     return item;\n   }\n@@ -1330,5 +1388,92 @@ template<typename S, typename T, typename Distance, typename Random>\n   }\n };\n \n+class AnnoyIndexSingleThreadedBuildPolicy {\n+public:\n+  template<typename S, typename T, typename D, typename Random>\n+  static void build(AnnoyIndex<S, T, D, Random, AnnoyIndexSingleThreadedBuildPolicy>* annoy, int q, int n_threads) {\n+    AnnoyIndexSingleThreadedBuildPolicy threaded_build_policy;\n+    annoy->thread_build(q, 0, threaded_build_policy);\n+  }\n+\n+  void lock_n_nodes() {}\n+  void unlock_n_nodes() {}\n+\n+  void lock_nodes() {}\n+  void unlock_nodes() {}\n+\n+  void lock_shared_nodes() {}\n+  void unlock_shared_nodes() {}\n+\n+  void lock_roots() {}\n+  void unlock_roots() {}\n+};\n+\n+#ifdef ANNOYLIB_MULTITHREADED_BUILD\n+class AnnoyIndexMultiThreadedBuildPolicy {\n+private:\n+  std::shared_timed_mutex nodes_mutex;\n+  std::mutex n_nodes_mutex;\n+  std::mutex roots_mutex;\n+\n+public:\n+  template<typename S, typename T, typename D, typename Random>\n+  static void build(AnnoyIndex<S, T, D, Random, AnnoyIndexMultiThreadedBuildPolicy>* annoy, int q, int n_threads) {\n+    AnnoyIndexMultiThreadedBuildPolicy threaded_build_policy;\n+    if (n_threads == -1) {\n+      // If the hardware_concurrency() value is not well defined or not computable, it returns 0.\n+      // We guard against this by using at least 1 thread.\n+      n_threads = std::max(1, (int)std::thread::hardware_concurrency());\n+    }\n+\n+    vector<std::thread> threads(n_threads);\n+\n+    for (int thread_idx = 0; thread_idx < n_threads; thread_idx++) {\n+      int trees_per_thread = q == -1 ? -1 : (int)floor((q + thread_idx) / n_threads);\n+\n+      threads[thread_idx] = std::thread(\n+        &AnnoyIndex<S, T, D, Random, AnnoyIndexMultiThreadedBuildPolicy>::thread_build,\n+        annoy,\n+        trees_per_thread,\n+        thread_idx,\n+        std::ref(threaded_build_policy)\n+      );\n+    }\n+\n+    for (auto& thread : threads) {\n+      thread.join();\n+    }\n+  }\n+\n+  void lock_n_nodes() {\n+    n_nodes_mutex.lock();\n+  }\n+  void unlock_n_nodes() {\n+    n_nodes_mutex.unlock();\n+  }\n+\n+  void lock_nodes() {\n+    nodes_mutex.lock();\n+  }\n+  void unlock_nodes() {\n+    nodes_mutex.unlock();\n+  }\n+\n+  void lock_shared_nodes() {\n+    nodes_mutex.lock_shared();\n+  }\n+  void unlock_shared_nodes() {\n+    nodes_mutex.unlock_shared();\n+  }\n+\n+  void lock_roots() {\n+    roots_mutex.lock();\n+  }\n+  void unlock_roots() {\n+    roots_mutex.unlock();\n+  }\n+};\n+#endif\n+\n #endif\n // vim: tabstop=2 shiftwidth=2\ndiff --git a/src/annoyluamodule.cc b/src/annoyluamodule.cc\nindex 76fec7c9..c383424c 100644\n--- a/src/annoyluamodule.cc\n+++ b/src/annoyluamodule.cc\n@@ -33,7 +33,7 @@ class LuaAnnoy {\n public:\n   typedef int32_t AnnoyS;\n   typedef float AnnoyT;\n-  typedef AnnoyIndex<AnnoyS, AnnoyT, Distance, Kiss64Random> Impl;\n+  typedef AnnoyIndex<AnnoyS, AnnoyT, Distance, Kiss64Random, AnnoyIndexSingleThreadedBuildPolicy> Impl;\n   typedef LuaAnnoy<Distance> ThisClass;\n \n   class LuaArrayProxy {\n@@ -118,9 +118,10 @@ class LuaAnnoy {\n   }\n \n   static int build(lua_State* L) {\n+    int nargs = lua_gettop(L);\n     Impl* self = getAnnoy(L, 1);\n     int n_trees = luaL_checkinteger(L, 2);\n-    self->build(n_trees);\n+    self->build(n_trees, 1);\n     lua_pushboolean(L, true);\n     return 1;\n   }\ndiff --git a/src/annoymodule.cc b/src/annoymodule.cc\nindex f15a0cc6..572b713e 100644\n--- a/src/annoymodule.cc\n+++ b/src/annoymodule.cc\n@@ -54,6 +54,11 @@ typedef signed __int32    int32_t;\n     #define PyInt_FromLong PyLong_FromLong \n #endif\n \n+#ifdef ANNOYLIB_MULTITHREADED_BUILD\n+  typedef AnnoyIndexMultiThreadedBuildPolicy AnnoyIndexThreadedBuildPolicy;\n+#else\n+  typedef AnnoyIndexSingleThreadedBuildPolicy AnnoyIndexThreadedBuildPolicy;\n+#endif\n \n template class AnnoyIndexInterface<int32_t, float>;\n \n@@ -63,7 +68,7 @@ class HammingWrapper : public AnnoyIndexInterface<int32_t, float> {\n   // This is questionable from a performance point of view. Should reconsider this solution.\n private:\n   int32_t _f_external, _f_internal;\n-  AnnoyIndex<int32_t, uint64_t, Hamming, Kiss64Random> _index;\n+  AnnoyIndex<int32_t, uint64_t, Hamming, Kiss64Random, AnnoyIndexThreadedBuildPolicy> _index;\n   void _pack(const float* src, uint64_t* dst) const {\n     for (int32_t i = 0; i < _f_internal; i++) {\n       dst[i] = 0;\n@@ -84,7 +89,7 @@ class HammingWrapper : public AnnoyIndexInterface<int32_t, float> {\n     _pack(w, &w_internal[0]);\n     return _index.add_item(item, &w_internal[0], error);\n   };\n-  bool build(int q, char** error) { return _index.build(q, error); };\n+  bool build(int q, int n_threads, char** error) { return _index.build(q, n_threads, error); };\n   bool unbuild(char** error) { return _index.unbuild(error); };\n   bool save(const char* filename, bool prefault, char** error) { return _index.save(filename, prefault, error); };\n   void unload() { _index.unload(); };\n@@ -145,17 +150,17 @@ py_an_new(PyTypeObject *type, PyObject *args, PyObject *kwargs) {\n     // This keeps coming up, see #368 etc\n     PyErr_WarnEx(PyExc_FutureWarning, \"The default argument for metric will be removed \"\n \t\t \"in future version of Annoy. Please pass metric='angular' explicitly.\", 1);\n-    self->ptr = new AnnoyIndex<int32_t, float, Angular, Kiss64Random>(self->f);\n+    self->ptr = new AnnoyIndex<int32_t, float, Angular, Kiss64Random, AnnoyIndexThreadedBuildPolicy>(self->f);\n   } else if (!strcmp(metric, \"angular\")) {\n-   self->ptr = new AnnoyIndex<int32_t, float, Angular, Kiss64Random>(self->f);\n+   self->ptr = new AnnoyIndex<int32_t, float, Angular, Kiss64Random, AnnoyIndexThreadedBuildPolicy>(self->f);\n   } else if (!strcmp(metric, \"euclidean\")) {\n-    self->ptr = new AnnoyIndex<int32_t, float, Euclidean, Kiss64Random>(self->f);\n+    self->ptr = new AnnoyIndex<int32_t, float, Euclidean, Kiss64Random, AnnoyIndexThreadedBuildPolicy>(self->f);\n   } else if (!strcmp(metric, \"manhattan\")) {\n-    self->ptr = new AnnoyIndex<int32_t, float, Manhattan, Kiss64Random>(self->f);\n+    self->ptr = new AnnoyIndex<int32_t, float, Manhattan, Kiss64Random, AnnoyIndexThreadedBuildPolicy>(self->f);\n   } else if (!strcmp(metric, \"hamming\")) {\n     self->ptr = new HammingWrapper(self->f);\n   } else if (!strcmp(metric, \"dot\")) {\n-    self->ptr = new AnnoyIndex<int32_t, float, DotProduct, Kiss64Random>(self->f);\n+    self->ptr = new AnnoyIndex<int32_t, float, DotProduct, Kiss64Random, AnnoyIndexThreadedBuildPolicy>(self->f);\n   } else {\n     PyErr_SetString(PyExc_ValueError, \"No such metric\");\n     return NULL;\n@@ -408,16 +413,17 @@ py_an_on_disk_build(py_annoy *self, PyObject *args, PyObject *kwargs) {\n static PyObject *\n py_an_build(py_annoy *self, PyObject *args, PyObject *kwargs) {\n   int q;\n+  int n_jobs = -1;\n   if (!self->ptr) \n     return NULL;\n-  static char const * kwlist[] = {\"n_trees\", NULL};\n-  if (!PyArg_ParseTupleAndKeywords(args, kwargs, \"i\", (char**)kwlist, &q))\n+  static char const * kwlist[] = {\"n_trees\", \"n_jobs\", NULL};\n+  if (!PyArg_ParseTupleAndKeywords(args, kwargs, \"i|i\", (char**)kwlist, &q, &n_jobs))\n     return NULL;\n \n   bool res;\n   char* error;\n   Py_BEGIN_ALLOW_THREADS;\n-  res = self->ptr->build(q, &error);\n+  res = self->ptr->build(q, n_jobs, &error);\n   Py_END_ALLOW_THREADS;\n   if (!res) {\n     PyErr_SetString(PyExc_Exception, error);\n@@ -527,7 +533,7 @@ static PyMethodDef AnnoyMethods[] = {\n   {\"get_item_vector\",(PyCFunction)py_an_get_item_vector, METH_VARARGS, \"Returns the vector for item `i` that was previously added.\"},\n   {\"add_item\",(PyCFunction)py_an_add_item, METH_VARARGS | METH_KEYWORDS, \"Adds item `i` (any nonnegative integer) with vector `v`.\\n\\nNote that it will allocate memory for `max(i)+1` items.\"},\n   {\"on_disk_build\",(PyCFunction)py_an_on_disk_build, METH_VARARGS | METH_KEYWORDS, \"Build will be performed with storage on disk instead of RAM.\"},\n-  {\"build\",(PyCFunction)py_an_build, METH_VARARGS | METH_KEYWORDS, \"Builds a forest of `n_trees` trees.\\n\\nMore trees give higher precision when querying. After calling `build`,\\nno more items can be added.\"},\n+  {\"build\",(PyCFunction)py_an_build, METH_VARARGS | METH_KEYWORDS, \"Builds a forest of `n_trees` trees.\\n\\nMore trees give higher precision when querying. After calling `build`,\\nno more items can be added. `n_jobs` specifies the number of threads used to build the trees. `n_jobs=-1` uses all available CPU cores.\"},\n   {\"unbuild\",(PyCFunction)py_an_unbuild, METH_NOARGS, \"Unbuilds the tree in order to allows adding new items.\\n\\nbuild() has to be called again afterwards in order to\\nrun queries.\"},\n   {\"unload\",(PyCFunction)py_an_unload, METH_NOARGS, \"Unloads an index from disk.\"},\n   {\"get_distance\",(PyCFunction)py_an_get_distance, METH_VARARGS, \"Returns the distance between items `i` and `j`.\"},\ndiff --git a/test/multithreaded_build_test.py b/test/multithreaded_build_test.py\nnew file mode 100644\nindex 00000000..0fc9f24f\n--- /dev/null\n+++ b/test/multithreaded_build_test.py\n@@ -0,0 +1,26 @@\n+import numpy\n+import unittest\n+from annoy import AnnoyIndex\n+\n+\n+class MultithreadedBuildTest(unittest.TestCase):\n+    def _test_building_with_threads(self, n_jobs):\n+        n, f = 10000, 10\n+        n_trees = 31\n+        i = AnnoyIndex(f, 'euclidean')\n+        for j in range(n):\n+            i.add_item(j, numpy.random.normal(size=f))\n+        self.assertTrue(i.build(n_trees, n_jobs=n_jobs))\n+        self.assertEqual(n_trees, i.get_n_trees())\n+\n+    def test_one_thread(self):\n+        self._test_building_with_threads(1)\n+\n+    def test_two_threads(self):\n+        self._test_building_with_threads(2)\n+\n+    def test_four_threads(self):\n+        self._test_building_with_threads(4)\n+    \n+    def test_eight_threads(self):\n+        self._test_building_with_threads(8)\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "**Technical Feedback:**\n\n1. **Missing Flags:** Add `-std=c++11` for Lua and Go extension compilations.\n2. **Mutex Library Issue:** Windows Python 2.7 lacks C++ thread/mutex support. Consider alternative multithreading solutions for Windows compatibility.\n3. **CI Failures:** Erik, please investigate Go and Lua build failures related to the standard flag.\n4. **OSX Performance:** Improve performance by modifying locking logic to minimize excessive lock operations in index-building loops.\n5. **Docker CPU Utilization:** Investigate multi-core usage; the model should leverage all available CPU resources when set to `n_jobs = -1`. \n\nNext steps include implementing the flag additions and adjusting locking mechanisms."
      }
    ],
    "codediff_length": 26873
  },
  {
    "index": 79,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.gitignore b/.gitignore\nindex 6f46c1ef..034cf394 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -5,15 +5,23 @@\n build/\n dist/\n .vscode/\n+.vs/\n+x64/\n *.pdb\n+annoy.vc*\n \n MANIFEST\n *.py[cod]\n *.idea\n \n # testing\n+*.hdf5\n+fashion-mnist*\n+1.ann\n blah.ann\n t.ann\n x.tree\n test.tree\n foo.idx\n+precision.tree\n+glove*\ndiff --git a/README.rst b/README.rst\nindex b71f0afe..020404dc 100644\n--- a/README.rst\n+++ b/README.rst\n@@ -77,7 +77,7 @@ Full Python API\n \n * ``AnnoyIndex(f, metric='angular')`` returns a new index that's read-write and stores vector of ``f`` dimensions. Metric can be ``\"angular\"``, ``\"euclidean\"``, ``\"manhattan\"``, or ``\"hamming\"``.\n * ``a.add_item(i, v)`` adds item ``i`` (any nonnegative integer) with vector ``v``. Note that it will allocate memory for ``max(i)+1`` items.\n-* ``a.build(n_trees)`` builds a forest of ``n_trees`` trees. More trees gives higher precision when querying. After calling ``build``, no more items can be added.\n+* ``a.build(n_trees, n_threads)`` builds a forest of ``n_trees`` trees, with ``n_threads`` threads in parallel. More trees gives higher precision when querying. After calling ``build``, no more items can be added.\n * ``a.save(fn)`` saves the index to disk.\n * ``a.load(fn)`` loads (mmaps) an index from disk.\n * ``a.unload()`` unloads.\ndiff --git a/examples/precision_test b/examples/precision_test\nnew file mode 100644\nindex 00000000..b49ec0d1\nBinary files /dev/null and b/examples/precision_test differ\ndiff --git a/examples/precision_test.cpp b/examples/precision_test.cpp\nindex 13ee1540..b3bfa335 100644\n--- a/examples/precision_test.cpp\n+++ b/examples/precision_test.cpp\n@@ -14,6 +14,7 @@\n #include <chrono>\n #include <algorithm>\n #include <map>\n+#include <random>\n \n \n \n@@ -47,7 +48,7 @@ int precision(int f=40, int n=1000000){\n \tstd::cout << std::endl;\n \tstd::cout << \"Building index num_trees = 2 * num_features ...\";\n \tt_start = std::chrono::high_resolution_clock::now();\n-\tt.build(2 * f);\n+\tt.build(2 * f, 2);\n \tt_end = std::chrono::high_resolution_clock::now();\n \tauto duration = std::chrono::duration_cast<std::chrono::seconds>( t_end - t_start ).count();\n \tstd::cout << \" Done in \"<< duration << \" secs.\" << std::endl;\n@@ -155,7 +156,7 @@ int main(int argc, char **argv) {\n \n \t\tfeedback(f,n);\n \n-\t\tprecision(40, 1000000);\n+\t\tprecision(f, n);\n \t}\n \telse if(argc == 3){\n \ndiff --git a/examples/s_compile_cpp.sh b/examples/s_compile_cpp.sh\nindex 687a6082..9a496392 100755\n--- a/examples/s_compile_cpp.sh\n+++ b/examples/s_compile_cpp.sh\n@@ -2,6 +2,6 @@\n \n \n echo \"compiling precision example...\"\n-cmd=\"g++ precision_test.cpp -o precision_test -std=c++11\"\n+cmd=\"g++ precision_test.cpp -o precision_test -std=c++11 -pthread\"\n eval $cmd\n echo \"Done\"\ndiff --git a/setup.py b/setup.py\nindex 7c4b8e22..d6a3694b 100644\n--- a/setup.py\n+++ b/setup.py\n@@ -47,9 +47,9 @@\n     cputune = ['-mcpu=native',]\n \n if os.name != 'nt':\n-    compile_args = ['-O3', '-ffast-math', '-fno-associative-math']\n+    compile_args = ['-std=c++11', '-O3', '-ffast-math', '-fno-associative-math']\n else:\n-    compile_args = []\n+    compile_args = [\"/fp:fast\"]\n     cputune = []\n \n setup(name='annoy',\ndiff --git a/src/annoygomodule.h b/src/annoygomodule.h\nindex fdcc10c3..99dc1257 100644\n--- a/src/annoygomodule.h\n+++ b/src/annoygomodule.h\n@@ -16,8 +16,8 @@ class AnnoyIndex {\n   void addItem(int item, const float* w) {\n     ptr->add_item(item, w);\n   };\n-  void build(int q) {\n-    ptr->build(q);\n+  void build(int q, int n_threads=1) {\n+    ptr->build(q, n_threads);\n   };\n   bool save(const char* filename) {\n     return ptr->save(filename);\ndiff --git a/src/annoylib.h b/src/annoylib.h\nindex f13d9229..5ba236cc 100644\n--- a/src/annoylib.h\n+++ b/src/annoylib.h\n@@ -48,6 +48,8 @@ typedef signed __int32    int32_t;\n #include <algorithm>\n #include <queue>\n #include <limits>\n+#include <thread>\n+#include <mutex>\n \n #ifdef _MSC_VER\n // Needed for Visual Studio to disable runtime checks for mempcy\n@@ -98,6 +100,9 @@ using std::string;\n using std::pair;\n using std::numeric_limits;\n using std::make_pair;\n+using std::mutex;\n+\n+\n \n namespace {\n \n@@ -511,7 +516,7 @@ class AnnoyIndexInterface {\n  public:\n   virtual ~AnnoyIndexInterface() {};\n   virtual void add_item(S item, const T* w) = 0;\n-  virtual void build(int q) = 0;\n+  virtual void build(int q, int n_threads = 1) = 0;\n   virtual void unbuild() = 0;\n   virtual bool save(const char* filename) = 0;\n   virtual void unload() = 0;\n@@ -523,6 +528,7 @@ class AnnoyIndexInterface {\n   virtual void verbose(bool v) = 0;\n   virtual void get_item(S item, T* v) = 0;\n   virtual void set_seed(int q) = 0;\n+  virtual void build_tree_threaded(int q, vector<S> *_roots) = 0;\n };\n \n template<typename S, typename T, typename Distance, typename Random>\n@@ -551,6 +557,8 @@ template<typename S, typename T, typename Distance, typename Random>\n   bool _loaded;\n   bool _verbose;\n   int _fd;\n+  mutex _node_mutex;\n+  mutex _roots_mutex;\n public:\n \n   AnnoyIndex(int f) : _f(f), _random() {\n@@ -588,28 +596,53 @@ template<typename S, typename T, typename Distance, typename Random>\n       _n_items = item + 1;\n   }\n \n-  void build(int q) {\n-    if (_loaded) {\n-      // TODO: throw exception\n-      showUpdate(\"You can't build a loaded index\\n\");\n-      return;\n-    }\n-    _n_nodes = _n_items;\n+  void build_tree_threaded(int num_trees, vector<S>* _roots) {\n+    // just for this thread\n+    vector<S> _roots_thread;\n     while (1) {\n-      if (q == -1 && _n_nodes >= _n_items * 2)\n+      // user doesn't specify number of trees,\n+      // just fully develop one tree?\n+      if (num_trees == -1 && _n_nodes >= _n_items * 2)\n         break;\n-      if (q != -1 && _roots.size() >= (size_t)q)\n+      // quit when we have all trees built for this thread\n+      if (num_trees != -1 && _roots->size() >= (size_t)num_trees)\n         break;\n-      if (_verbose) showUpdate(\"pass %zd...\\n\", _roots.size());\n+      if (_verbose) showUpdate(\"pass %zd...\\n\", _roots->size());\n \n       vector<S> indices;\n       for (S i = 0; i < _n_items; i++) {\n-\tif (_get(i)->n_descendants >= 1) // Issue #223\n+        if (_get(i)->n_descendants >= 1) // Issue #223\n           indices.push_back(i);\n       }\n+      S tree = _make_tree(indices, true);\n+      _roots_thread.push_back(tree);\n+      // push to our shared roots vector\n+\t  _roots_mutex.lock();\n+      _roots->insert(_roots->end(), _roots_thread.begin(), _roots_thread.end());\n+      printf(\"num roots %i\", _roots->size());\n+\t  _roots_mutex.unlock();\n+    }\n+  }\n \n-      _roots.push_back(_make_tree(indices, true));\n+  void build(int q, int n_threads = 1) {\n+    if (_loaded) {\n+      // TODO: throw exception\n+      showUpdate(\"You can't build a loaded index\\n\");\n+      return;\n+    }\n+    _n_nodes = _n_items;\n+\n+    vector<std::thread> threads;\n+\n+    for (int i = 0; i < n_threads; i++) {\n+      threads.push_back(std::thread(&AnnoyIndexInterface<S, T>::build_tree_threaded, this, q, &_roots));\n     }\n+\n+    // rejoin\n+    for (auto &t : threads) {\n+      t.join();\n+    }\n+\n     // Also, copy the roots into the last segment of the array\n     // This way we can load them faster without reading the whole file\n     _allocate_size(_n_nodes + (S)_roots.size());\n@@ -754,8 +787,10 @@ template<typename S, typename T, typename Distance, typename Random>\n       return indices[0];\n \n     if (indices.size() <= (size_t)_K) {\n+\t  _node_mutex.lock();\n       _allocate_size(_n_nodes + 1);\n       S item = _n_nodes++;\n+\t  _node_mutex.unlock();\n       Node* m = _get(item);\n       m->n_descendants = (S)indices.size();\n \n@@ -813,8 +848,10 @@ template<typename S, typename T, typename Distance, typename Random>\n       // run _make_tree for the smallest child first (for cache locality)\n       m->children[side^flip] = _make_tree(children_indices[side^flip], false);\n \n+\t_node_mutex.lock();\n     _allocate_size(_n_nodes + 1);\n     S item = _n_nodes++;\n+\t_node_mutex.unlock();\n     memcpy(_get(item), m, _s);\n     free(m);\n \n@@ -880,4 +917,4 @@ template<typename S, typename T, typename Distance, typename Random>\n };\n \n #endif\n-// vim: tabstop=2 shiftwidth=2\n+// vim: tabstop=2 shiftwidth=2\n\\ No newline at end of file\ndiff --git a/src/annoyluamodule.cc b/src/annoyluamodule.cc\nindex ad10a2b3..3956d2ff 100644\n--- a/src/annoyluamodule.cc\n+++ b/src/annoyluamodule.cc\n@@ -117,10 +117,10 @@ class LuaAnnoy {\n     return 0;\n   }\n \n-  static int build(lua_State* L) {\n+  static int build(lua_State* L, int n_threads) {\n     Impl* self = getAnnoy(L, 1);\n     int n_trees = luaL_checkinteger(L, 2);\n-    self->build(n_trees);\n+    self->build(n_trees, n_threads);\n     lua_pushboolean(L, true);\n     return 1;\n   }\ndiff --git a/src/annoymodule.cc b/src/annoymodule.cc\nindex ac465f48..1846f1f5 100644\n--- a/src/annoymodule.cc\n+++ b/src/annoymodule.cc\n@@ -66,7 +66,10 @@ class HammingWrapper : public AnnoyIndexInterface<int32_t, float> {\n     _pack(w, &w_internal[0]);\n     _index.add_item(item, &w_internal[0]);\n   };\n-  void build(int q) { _index.build(q); };\n+  // TODO:\n+  // support threading for building index\n+  void build_tree_threaded(int num_trees, vector<int32_t> *_roots) {};\n+  void build(int q, int n_threads) { _index.build(q, 1); };\n   void unbuild() { _index.unbuild(); };\n   bool save(const char* filename) { return _index.save(filename); };\n   void unload() { _index.unload(); };\n@@ -354,14 +357,15 @@ py_an_add_item(py_annoy *self, PyObject *args, PyObject* kwargs) {\n static PyObject *\n py_an_build(py_annoy *self, PyObject *args, PyObject *kwargs) {\n   int q;\n+  int n_threads;\n   if (!self->ptr) \n     return NULL;\n-  static char const * kwlist[] = {\"n_trees\", NULL};\n-  if (!PyArg_ParseTupleAndKeywords(args, kwargs, \"i\", (char**)kwlist, &q))\n+  static char const * kwlist[] = {\"n_trees\", \"n_threads\", NULL};\n+  if (!PyArg_ParseTupleAndKeywords(args, kwargs, \"i|i\", (char**)kwlist, &q, &n_threads))\n     return NULL;\n \n   Py_BEGIN_ALLOW_THREADS;\n-  self->ptr->build(q);\n+  self->ptr->build(q, n_threads);\n   Py_END_ALLOW_THREADS;\n \n   Py_RETURN_TRUE;\n@@ -454,7 +458,7 @@ static PyMethodDef AnnoyMethods[] = {\n   {\"get_nns_by_vector\",(PyCFunction)py_an_get_nns_by_vector, METH_VARARGS | METH_KEYWORDS, \"Returns the `n` closest items to vector `vector`.\\n\\n:param search_k: the query will inspect up to `search_k` nodes.\\n`search_k` gives you a run-time tradeoff between better accuracy and speed.\\n`search_k` defaults to `n_trees * n` if not provided.\\n\\n:param include_distances: If `True`, this function will return a\\n2 element tuple of lists. The first list contains the `n` closest items.\\nThe second list contains the corresponding distances.\"},\n   {\"get_item_vector\",(PyCFunction)py_an_get_item_vector, METH_VARARGS, \"Returns the vector for item `i` that was previously added.\"},\n   {\"add_item\",(PyCFunction)py_an_add_item, METH_VARARGS | METH_KEYWORDS, \"Adds item `i` (any nonnegative integer) with vector `v`.\\n\\nNote that it will allocate memory for `max(i)+1` items.\"},\n-  {\"build\",(PyCFunction)py_an_build, METH_VARARGS | METH_KEYWORDS, \"Builds a forest of `n_trees` trees.\\n\\nMore trees give higher precision when querying. After calling `build`,\\nno more items can be added.\"},\n+  {\"build\",(PyCFunction)py_an_build, METH_VARARGS | METH_KEYWORDS, \"Builds a forest of `n_trees` trees.\\n\\nMore trees give higher precision when querying. After calling `build`,\\nno more items can be added.\\n\\n`n_threads`: number of threads to build index\"},\n   {\"unbuild\",(PyCFunction)py_an_unbuild, METH_NOARGS, \"Unbuilds the tree in order to allows adding new items.\\n\\nbuild() has to be called again afterwards in order to\\nrun queries.\"},\n   {\"unload\",(PyCFunction)py_an_unload, METH_NOARGS, \"Unloads an index from disk.\"},\n   {\"get_distance\",(PyCFunction)py_an_get_distance, METH_VARARGS, \"Returns the distance between items `i` and `j`.\"},\ndiff --git a/tox.ini b/tox.ini\nindex 74bff80d..6509c043 100644\n--- a/tox.ini\n+++ b/tox.ini\n@@ -16,8 +16,8 @@ setenv =\n whitelist_externals=*\n commands =\n   mkdir -p {env:GOPATH:}/src/annoyindex\n-  wget https://storage.googleapis.com/golang/go1.5.linux-amd64.tar.gz\n-  sudo tar -C /usr/local -xzf go1.5.linux-amd64.tar.gz\n+  wget https://storage.googleapis.com/golang/go1.9.linux-amd64.tar.gz\n+  sudo tar -C /usr/local -xzf go1.9.linux-amd64.tar.gz\n   sudo add-apt-repository -y ppa:rosmo/swig3.0.7\n   sudo apt-get update -qq\n   sudo apt-get install -y swig3.0\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "- Change thread assignment to allow threads to continue processing instead of terminating after completing their tasks for efficiency.\n- Resolve compilation errors for Lua and Go by adding a `-std=c++11` flag in `tox.ini`.\n- Introduce a separate counter to track `_roots.size()` using GCC atomic builtins for thread safety.\n- Investigate flaky Python tests on Windows that are crashing or failing; ensure proper test discovery with `nosetests`.\n- Fix unclear error messages in failing tests, particularly for accuracy tests.\n- Perform additional cleanup in the code after integrating the recent changes.\n- Recommended to close the PR temporarily for further learning in C++."
      }
    ],
    "codediff_length": 12330
  },
  {
    "index": 80,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/README.rst b/README.rst\nindex 914be3f8..7e2ae03a 100644\n--- a/README.rst\n+++ b/README.rst\n@@ -31,11 +31,13 @@ Summary of features\n -------------------\n \n * Euclidean distance (squared) or cosine similarity (using the squared distance of the normalized vectors)\n-* Works better if you don't have too many dimensions (like <100) but seems to perform surprisingly well even up to 1,000 dimensions\n-* Small memory usage\n+* Works better if you don't have too many dimensions (like <100) but seems to perform surprisingly well even up to 1,000 dimensions; works pretty fine with dimension up to 4000. \n+* Small memory usage in searching because memory map is used\n * Lets you share memory between multiple processes\n-* Index creation is separate from lookup (in particular you can not add more items once the tree has been created)\n+* Index creation is separate from lookup\n * Native Python support\n+* Support dynamic index add. ( will support delete and update in the future)\n+* Each sample contains a field label for filtering results -- i.e. search query can contain a list of target labels to search for.\n \n Code example\n ____________\n@@ -48,7 +50,7 @@ ____________\n       v = []\n       for z in xrange(f):\n           v.append(random.gauss(0, 1))\n-      t.add_item(i, v)\n+      t.add_item(i, v, 1)  # add items with label 1\n \n   t.build(10) # 10 trees\n   t.save('test.tree')\n@@ -57,7 +59,7 @@ ____________\n \n   u = AnnoyIndex(f)\n   u.load('test.tree') # super fast, will just mmap the file\n-  print(u.get_nns_by_item(0, 1000)) # will find the 1000 nearest neighbors\n+  print(u.get_nns_by_item(0, 1000, [1,2], 10000)) # will find the 1000 nearest neighbors, accurate search from top 10000 candidates with label 1 or 2\n \n \n Right now it only accepts integers as identifiers for items. Note that it will allocate memory for max(id)+1 items because it assumes your items are numbered 0 \u2026 n-1. If you need other id's, you will have to keep track of a map yourself.\ndiff --git a/examples/precision_test.py b/examples/precision_test.py\nindex 18842a5e..cce9d404 100644\n--- a/examples/precision_test.py\n+++ b/examples/precision_test.py\n@@ -9,13 +9,13 @@\n     xrange = range\n \n \n-def precision(f=40, n=1000000):\n+def precision(f=40, n=1000):\n     t = AnnoyIndex(f)\n     for i in xrange(n):\n         v = []\n         for z in xrange(f):\n             v.append(random.gauss(0, 1))\n-        t.add_item(i, v)\n+        t.add_item(i, v, 1)\n \n     t.build(2 * f)\n     t.save('test.tree')\n@@ -30,10 +30,10 @@ def precision(f=40, n=1000000):\n         j = random.randrange(0, n)\n         print('finding nbs for', j)\n         \n-        closest = set(t.get_nns_by_item(j, n)[:k])\n+        closest = set(t.get_nns_by_item(j, n, [1], j* 100)[:k])\n         for limit in limits:\n             t0 = time.time()\n-            toplist = t.get_nns_by_item(j, limit)\n+            toplist = t.get_nns_by_item(j, limit, [1], j* 100)\n             T = time.time() - t0\n             \n             found = len(closest.intersection(toplist))\ndiff --git a/examples/simple_test.py b/examples/simple_test.py\nindex 33cf74d1..0001bbe2 100644\n--- a/examples/simple_test.py\n+++ b/examples/simple_test.py\n@@ -1,10 +1,10 @@\n from annoy import AnnoyIndex\n \n a = AnnoyIndex(3)\n-a.add_item(0, [1, 0, 0])\n-a.add_item(1, [0, 1, 0])\n-a.add_item(2, [0, 0, 1])\n+a.add_item(0, [1, 0, 0], 1)\n+a.add_item(1, [0, 1, 0], 1)\n+a.add_item(2, [0, 0, 1], 1)\n a.build(-1)\n \n-print(a.get_nns_by_item(0, 100))\n-print(a.get_nns_by_vector([1.0, 0.5, 0.5], 100))\n+print(a.get_nns_by_item(1, 100, [2], 10))\n+print(a.get_nns_by_vector([1.0, 0.5, 0.5], 100, [], 1000))\ndiff --git a/src/annoylib.h b/src/annoylib.h\nindex caa28732..5ff60c11 100644\n--- a/src/annoylib.h\n+++ b/src/annoylib.h\n@@ -34,6 +34,7 @@\n #include <string.h>\n #include <math.h>\n #include <vector>\n+#include <map>\n #include <queue>\n #include <limits>\n #include <boost/version.hpp>\n@@ -126,6 +127,8 @@ struct Angular {\n      * more memory to be able to fit the vector outside\n      */\n     S n_descendants;\n+    S label;\n+    S parent;\n     S children[2]; // Will possibly store more than 2\n     T v[1]; // We let this one overflow intentionally. Need to allocate at least 1 to make GCC happy\n   };\n@@ -167,6 +170,8 @@ template<typename S, typename T>\n struct Euclidean {\n   struct __attribute__((__packed__)) node {\n     S n_descendants;\n+    S label;\n+    S parent;\n     T a; // need an extra constant term to determine the offset of the plane\n     S children[2];\n     T v[1];\n@@ -190,6 +195,29 @@ struct Euclidean {\n     else\n       return random->flip();\n   }\n+  static inline void create_split(const vector<node*>& nodes, int f, Randomness<T>* random, node* n) {\n+    // See http://en.wikipedia.org/wiki/Bertrand_paradox_(probability)\n+    // We want to sample a random hyperplane out of all hyperplanes that cut the convex hull.\n+    // The probability of each angle is in proportion to the extent of the projection.\n+    // This is good because it means we try to split in the longest direction.\n+    // Doing this using Metropolis-Hastings sampling using 10 steps\n+      for (int z = 0; z < f; z++)\n+        n->v[z] = random->gaussian();\n+      normalize(n->v, f);\n+      // Project the nodes onto the vector and calculate max and min\n+      T min = INFINITY, max = -INFINITY;\n+      for (size_t i = 0; i < nodes.size(); i++) {\n+        T dot = 0;\n+        for (int z = 0; z < f; z++)\n+          dot += nodes[i]->v[z] * n->v[z];\n+        if (dot > max)\n+          max = dot;\n+        if (dot < min)\n+          min = dot;\n+      }\n+      n->a = (max + min) / 2.0;// use the middle for random split\n+  }\n+/*\n   static inline void create_split(const vector<node*>& nodes, int f, Randomness<T>* random, node* n) {\n     // See http://en.wikipedia.org/wiki/Bertrand_paradox_(probability)\n     // We want to sample a random hyperplane out of all hyperplanes that cut the convex hull.\n@@ -221,6 +249,7 @@ struct Euclidean {\n     }\n     free(v);\n   }\n+*/\n };\n \n template<typename S, typename T, typename Distance>\n@@ -244,6 +273,10 @@ class AnnoyIndex {\n   S _K;\n   bool _loaded;\n   bool _verbose;\n+  bool _appended;\n+  std::map<S, S> _group_id_map;\n+  size_t _scanned ;  \n+  size_t _last_scanned;\n public:\n   AnnoyIndex(int f) : _random() {\n     _f = f;\n@@ -255,6 +288,9 @@ class AnnoyIndex {\n     _nodes = NULL;\n     _loaded = false;\n     _verbose = false;\n+    _appended = false;\n+    _scanned = 0;\n+    _last_scanned = 0;\n \n     _K = (sizeof(T) * f + sizeof(S) * 2) / sizeof(S);\n   }\n@@ -266,10 +302,74 @@ class AnnoyIndex {\n     }\n   }\n \n-  void add_item(S item, const T* w) {\n+  S set_K(S K) {\n+    if (K < _K) {\n+      _K = K;\n+    }\n+    return _K;\n+  }\n+  //update the label of an item\n+  S update_label(S item_id, S label) {\n+    if (item_id >= _n_items || item_id < 0) {\n+      return -1;\n+    }\n+    typename Distance::node* m = _get(item_id);  \n+    if (m != NULL) {\n+       m->label = label;\n+    }\n+    return 1;\n+  }\n+\n+  //add one item to existing built index, return the item id \n+  S add_item_to_index(const T* w, S label) {\n+    S item = _n_items;\n+    _n_items += 1; \n+    _allocate_size(_n_nodes + 1);\n+    \n+    //first, move the non-leaf node stored at (item) position to the end of array; \n+    memcpy(_get(_n_nodes), _get(item), _s);\n+    typename Distance::node* nd = _get(_n_nodes);\n+    if (nd->parent != 0) {\n+      typename Distance::node* nparent = _get(nd->parent);\n+      if (nparent->children[0] == item) {\n+         nparent->children[0] = _n_nodes;\n+      } else if (nparent->children[1] == item) {\n+         nparent->children[1] = _n_nodes;\n+      }\n+    }\n+    if (nd->n_descendants > _K) {\n+      S c0 = nd->children[0];\n+      typename Distance::node* nc0 = _get(c0);\n+      nc0->parent = _n_nodes;\n+\n+      S c1 = nd->children[1];\n+      typename Distance::node* nc1 = _get(c1);\n+      nc1->parent = _n_nodes;\n+    }\n+\n+    // if it is root, move root, \n+    for (size_t r = 0; r < _roots.size(); r ++ ) {\n+      if (_roots[r] == item) {\n+          _roots[r] = _n_nodes;\n+      }\n+    }\n+    _n_nodes += 1;\n+\n+    //store it\n+    add_item(item, w, label); \n+    \n+    //put it in the trees\n+    for (size_t r = 0; r < _roots.size(); r ++ ) {\n+      S new_root = _add_item_to_tree(item, _roots[r]);      \n+      _roots[r] = new_root;\n+    }\n+    return item;\n+  }\n+\n+  void add_item(S item, const T* w, S label) {\n     _allocate_size(item + 1);\n     typename Distance::node* n = _get(item);\n-\n+    n->label = label;\n     n->children[0] = 0;\n     n->children[1] = 0;\n     n->n_descendants = 1;\n@@ -298,23 +398,22 @@ class AnnoyIndex {\n     }\n     // Also, copy the roots into the last segment of the array\n     // This way we can load them faster without reading the whole file\n-    _allocate_size(_n_nodes + (S)_roots.size());\n-    for (size_t i = 0; i < _roots.size(); i++)\n-      memcpy(_get(_n_nodes + (S)i), _get(_roots[i]), _s);\n-    _n_nodes += _roots.size();\n-\n     if (_verbose) showUpdate(\"has %d nodes\\n\", _n_nodes);\n   }\n \n+\n   bool save(const string& filename) {\n     FILE *f = fopen(filename.c_str(), \"w\");\n     if (f == NULL)\n       return false;\n+    if (! _appended) {\n+      _append_roots_at_tail();\n+    }\n \n     fwrite(_nodes, _s, _n_nodes, f);\n \n     fclose(f);\n-\n+     \n     free(_nodes);\n     _n_items = 0;\n     _n_nodes = 0;\n@@ -334,41 +433,60 @@ class AnnoyIndex {\n   }\n \n   void unload() {\n-    off_t size = _n_nodes * _s;\n+    off_t size = _nodes_size * _s;\n     munmap(_nodes, size);\n     reinitialize();\n     if (_verbose) showUpdate(\"unloaded\\n\");\n   }\n \n-  bool load(const string& filename) {\n+  bool load_memory(const string& filename) {\n     int fd = open(filename.c_str(), O_RDONLY, (mode_t)0400);\n+    if (fd == -1) {\n+      return false;\n+    }\n+    off_t size = lseek(fd, 0, SEEK_END);\n+    lseek(fd, 0, SEEK_SET);\n+    _n_nodes = (S)(size / _s);\n+    _allocate_size(_n_nodes);\n+    int fr = read(fd, _nodes, size);\n+    if (fr == -1) {\n+      printf(\"error in reading the file %s \\n\", filename.c_str());\n+    }\n+    printf(\"file contains %d nodes \\n\", _n_nodes);\n+    _appended = true;\n+    _remove_roots_at_tail();\n+    if (_roots.size() == 0) \n+      return false;\n+    _loaded = true;\n+    _n_items = _get(_roots[0])->n_descendants;\n+    \n+    if (_verbose) showUpdate(\"found %lu roots with degree %d\\n\", _roots.size(), _n_items);\n+    return true;\n+  }\n+\n+\n+  bool load(const string& filename) {\n+    int fd = open(filename.c_str(), O_RDWR, (mode_t)0400);\n     if (fd == -1)\n       return false;\n     off_t size = lseek(fd, 0, SEEK_END);\n #ifdef MAP_POPULATE\n     _nodes = (typename Distance::node*)mmap(\n-        0, size, PROT_READ, MAP_SHARED | MAP_POPULATE, fd, 0);\n+        0, size, PROT_READ|PROT_WRITE, MAP_SHARED | MAP_POPULATE, fd, 0);\n #else\n     _nodes = (typename Distance::node*)mmap(\n-        0, size, PROT_READ, MAP_SHARED, fd, 0);\n+        0, size, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);\n #endif\n \n     _n_nodes = (S)(size / _s);\n-\n-    // Find the roots by scanning the end of the file and taking the nodes with most descendants\n-    S m = -1;\n-    for (S i = _n_nodes - 1; i >= 0; i--) {\n-      S k = _get(i)->n_descendants;\n-      if (m == -1 || k == m) {\n-        _roots.push_back(i);\n-        m = k;\n-      } else {\n-        break;\n-      }\n-    }\n+    _appended = true;\n+    _remove_roots_at_tail();\n+    if (_roots.size() == 0) \n+      return false;\n     _loaded = true;\n-    _n_items = m;\n-    if (_verbose) showUpdate(\"found %lu roots with degree %d\\n\", _roots.size(), m);\n+    _n_items = _get(_roots[0])->n_descendants;\n+    \n+    if (_verbose) showUpdate(\"found %lu roots with degree %d\\n\", _roots.size(), _n_items);\n     return true;\n   }\n \n@@ -378,14 +496,63 @@ class AnnoyIndex {\n     return Distance::distance(x, y, _f);\n   }\n \n-  void get_nns_by_item(S item, size_t n, vector<S>* result) {\n+  void get_nns_by_item(S item, size_t n, vector<pair<T, S> >* result, vector<S>& label_set, size_t tn = -1) {\n+    const typename Distance::node* m = _get(item);\n+    _get_all_nns(m->v, n, result, label_set, tn);\n+  }\n+\n+\n+  void get_nns_by_vector(const T* w, size_t n, vector<pair<T, S> >* result, vector<S> & label_set, size_t tn = -1) {\n+    _get_all_nns(w, n, result, label_set, tn);\n+  }\n+ \n+  void get_all_groups(T dist_threshold, S search_tree_count ) {\n+     _scanned = 0;\n+     for (size_t i = 0; i < _roots.size() && i < search_tree_count; i++) {\n+      _get_all_groups( _roots[i], dist_threshold);\n+    }\n+  }\n+\n+  void get_nns_group_by_item(S item, size_t n, vector<vector<S> >* group_results_ptr, vector<S>& label_set, size_t tn, T dist_threshold) {\n     const typename Distance::node* m = _get(item);\n-    _get_all_nns(m->v, n, result);\n+    get_nns_group_by_vector(m->v, n, group_results_ptr, label_set, tn, dist_threshold);\n   }\n \n-  void get_nns_by_vector(const T* w, size_t n, vector<S>* result) {\n-    _get_all_nns(w, n, result);\n+  void get_nns_group_by_vector(const T* v, size_t n, vector<vector<S> >* group_results_ptr, vector<S>& label_set, size_t tn, T dist_threshold) {\n+    vector<pair<T, S> > nns_dist;\n+    vector<vector<S> >& group_results = *group_results_ptr;\n+    _get_all_nns( v, n, &nns_dist, label_set, tn); \n+    \n+    for (size_t i = 0; i < nns_dist.size(); i ++ ) {\n+     //insert into groups \n+     S item = nns_dist[i].second;\n+     T* vw = _get(item)->v;\n+     bool found = false;\n+     for (size_t j = 0; j < group_results.size(); j ++ ) {\n+        for (size_t k = 0; k < group_results[j].size(); k ++ ) {\n+           T distance = Distance::distance(vw, _get(group_results[j][k])->v, _f);\n+           if (distance < dist_threshold) {\n+             group_results[j].push_back(item);\n+             found = true; \n+             break;\n+           }\n+        }\n+        if (found) break;\n+     } \n+     //a new group\n+     if (! found) {\n+       vector<S> g;\n+       g.push_back(item); \n+       group_results.push_back(g);\n+     }\n+    }\n+    return ; \n+  }\n+  S set_item_size(S n) {\n+      _allocate_size(n);\n+    return n;\n   }\n+\n   S get_n_items() {\n     return _n_items;\n   }\n@@ -394,13 +561,51 @@ class AnnoyIndex {\n   }\n \n protected:\n+  void _append_roots_at_tail() {\n+    if (_appended) {\n+       return ;\n+    }\n+    _allocate_size(_n_nodes + (S)_roots.size());\n+    for (size_t i = 0; i < _roots.size(); i++)\n+      memcpy(_get(_n_nodes + (S)i), _get(_roots[i]), _s);\n+\n+    // a root's n_descendants would point to the actual node\n+    S total_size = _n_nodes + _roots.size();\n+    for (size_t i = 0; i < _roots.size(); i++) {\n+      typename Distance::node* nd = _get(_n_nodes + (S) i );\n+      nd->n_descendants = _roots[i] + total_size; \n+    }\n+    _n_nodes += _roots.size();\n+    _appended = true;\n+  }\n+\n+  void _remove_roots_at_tail() {\n+    if (!_appended) {\n+       return ;\n+    }\n+    // Find the roots by scanning the end of the file and taking the nodes with most descendants\n+    for (S i = _n_nodes - 1; i >= 0; i--) {\n+      S k1 = _get(i)->n_descendants; // k1 would be the original root + total_size, rather than the duplicated root at the end of the array \n+      if (k1 >=  _n_nodes) {\n+         _roots.push_back(k1 - _n_nodes);\n+      } else {\n+        break;\n+      }\n+    }\n+    _nodes_size = _n_nodes;\n+    _n_nodes -= (S)_roots.size(); //reclaim the space used by duplicated roots\n+    _appended = false;\n+  }\n+  \n   void _allocate_size(S n) {\n     if (n > _nodes_size) {\n       S new_nodes_size = (_nodes_size + 1) * 2;\n-      if (n > new_nodes_size)\n+      if (n > new_nodes_size) \n         new_nodes_size = n;\n+      \n       _nodes = realloc(_nodes, _s * new_nodes_size);\n       memset((char *)_nodes + (_nodes_size * _s)/sizeof(char), 0, (new_nodes_size - _nodes_size) * _s);\n+      \n       _nodes_size = new_nodes_size;\n     }\n   }\n@@ -409,12 +614,13 @@ class AnnoyIndex {\n     return (typename Distance::node*)((char *)_nodes + (_s * i)/sizeof(char));\n   }\n \n-  S _make_tree(const vector<S >& indices) {\n+  S _make_tree(const vector<S >& indices, S item = -1) {\n     if (indices.size() == 1)\n       return indices[0];\n-\n-    _allocate_size(_n_nodes + 1);\n-    S item = _n_nodes++;\n+    if (item == -1) {\n+      _allocate_size(_n_nodes + 1);\n+      item = _n_nodes++;\n+    }\n     typename Distance::node* m = _get(item);\n     m->n_descendants = (S)indices.size();\n \n@@ -486,6 +692,8 @@ class AnnoyIndex {\n \n     S children_0 = _make_tree(children_indices[0]);\n     S children_1 = _make_tree(children_indices[1]);\n+    _get(children_0)->parent = item;\n+    _get(children_1)->parent = item;\n \n     // We need to fetch m again because it might have been reallocated\n     m = _get(item);\n@@ -495,43 +703,116 @@ class AnnoyIndex {\n     return item;\n   }\n \n-  void _get_nns(const T* v, S i, vector<S>* result, S limit) {\n-    const typename Distance::node* n = _get(i);\n-\n-    if (n->n_descendants == 0) {\n-      // unknown item, nothing to do...\n-    } else if (n->n_descendants == 1) {\n-      result->push_back(i);\n-    } else if (n->n_descendants <= _K) {\n-      const S* dst = n->children;\n-      result->insert(result->end(), n->children, &dst[n->descendants]);\n-    } else {\n-      bool side = Distance::side(n, v, _f, &_random);\n-\n-      _get_nns(v, n->children[side], result, limit);\n-      if (result->size() < (size_t)limit)\n-        _get_nns(v, n->children[!side], result, limit);\n+  S _add_item_to_tree(S item, S root) {\n+     typename Distance::node* nr = _get(root);\n+     typename Distance::node* ni = _get(item);\n+     if (nr->n_descendants == 1) {\n+       vector<S> children;\n+       children.push_back(item);\n+       children.push_back(root);\n+       S new_node = _make_tree(children);   \n+       return new_node;\n+     } else if (nr->n_descendants < _K - 1) {\n+       nr->children[nr->n_descendants] = item;\n+       nr->n_descendants += 1; \n+       return root;\n+     } else if (nr->n_descendants == _K) {\n+       vector<S> children;\n+       for (size_t kk = 0; kk < nr->n_descendants; kk ++ ) {\n+          children.push_back(nr->children[kk]);\n+       }\n+       children.push_back(item);\n+       nr->n_descendants += 1; \n+       _make_tree(children, root);\n+       return root;\n+     } else  { //non-leaf node\n+         nr = _get(root); \n+         ni = _get(item);\n+         \n+         bool side = Distance::side(nr, ni->v, _f, &_random);\n+         S child = nr->children[side];\n+         S new_child = _add_item_to_tree(item, child);\n+         nr->children[side] = new_child;\n+         nr->n_descendants += 1;\n+         return root;\n+     }\n+          \n+  }\n+  //ggg\n+  void _get_all_groups(S root, T dist_threshold) {\n+    const typename Distance::node* nd = _get(root);\n+    if (nd->n_descendants == 1) { \n+      _scanned += 1;\n+      if (_scanned > _last_scanned + 1000) {\n+         fprintf(stderr, \"\\r%d items scanned for dedup.\", _scanned);\n+         _last_scanned = _scanned;\n+      }\n+      return;\n+    } else if (nd->n_descendants <= _K) {\n+       for (size_t x = 0; x < nd->n_descendants; x ++ ) {\n+          S x_idx = nd->children[x];\n+          T* v_x = _get(x_idx)->v;\n+          for (size_t y = 0; y < x ; y ++ ) {\n+             S y_idx = nd->children[y];\n+             T* v_y = _get(y_idx)->v;\n+             T distance = Distance::distance(v_x, v_y, _f);\n+             if (distance < dist_threshold) { \n+               printf(\"%d\\t%d\\t%3.3f\\n\", x_idx, y_idx, distance);\n+             }\n+          }\n+       }\n+       _scanned += nd->n_descendants;\n+       if (_scanned > _last_scanned + 1000) {\n+         fprintf(stderr, \"\\r%d items scanned for dedup.\", _scanned);\n+         _last_scanned = _scanned;\n+       }\n+    } else { \n+       _get_all_groups(nd->children[1], dist_threshold);\n+       _get_all_groups(nd->children[0], dist_threshold);\n     }\n   }\n \n-  void _get_all_nns(const T* v, size_t n, vector<S>* result) {\n+ \n+  void _get_all_nns(const T* v, size_t n, vector<pair<T, S> >* result, vector<S>& label_set, size_t tn) {\n     std::priority_queue<pair<T, S> > q;\n-\n+    std::map<S, bool> r; // retrieved items map\n+    std::map<S, bool> cset; // category set map\n+    size_t c = 0;  //retrieved count\n+    for(size_t i = 0; i < label_set.size(); i ++) {\n+      cset.insert(make_pair(label_set[i], true));\n+    }\n     for (size_t i = 0; i < _roots.size(); i++) {\n       q.push(make_pair(numeric_limits<T>::infinity(), _roots[i]));\n     }\n+    if (tn == -1) {\n+      tn = n * _roots.size();\n+    }\n \n-    vector<S> nns;\n-    while (nns.size() < n * _roots.size() && !q.empty()) {\n+    vector<pair<T, S> > nns_dist;\n+    while (nns_dist.size() < tn && !q.empty()) {\n       const pair<T, S>& top = q.top();\n       S i = top.second;\n       const typename Distance::node* nd = _get(top.second);\n       q.pop();\n       if (nd->n_descendants == 1) {\n-        nns.push_back(i);\n+        if (r.find(i) == r.end())\n+        {\n+            if (cset.size() == 0 || cset.find(nd->label) != cset.end()) {\n+               nns_dist.push_back(make_pair(Distance::distance(v, _get(i)->v, _f), i));\n+               r.insert(make_pair(i, true));\n+            }\n+        }\n       } else if (nd->n_descendants <= _K) {\n \tconst S* dst = nd->children;\n-\tnns.insert(nns.end(), nd->children, &dst[nd->n_descendants]);\n+        for (size_t kk = 0; kk < nd->n_descendants; kk ++ ) {\n+          int w = nd->children[kk];\n+          if (r.find(w) == r.end()) {\n+            if (cset.size() == 0 || cset.find(_get(w)->label) != cset.end()) {\n+              nns_dist.push_back(make_pair(Distance::distance(v, _get(w)->v, _f), w));\n+              r.insert(make_pair(w, true));\n+            }\n+          }\n+        }\n       } else {\n         T margin = Distance::margin(nd, v, _f);\n         q.push(make_pair(+margin, nd->children[1]));\n@@ -539,22 +820,10 @@ class AnnoyIndex {\n       }\n     }\n \n-    sort(nns.begin(), nns.end());\n-    vector<pair<T, S> > nns_dist;\n-    S last = -1;\n-    for (size_t i = 0; i < nns.size(); i++) {\n-      S j = nns[i];\n-      if (j == last)\n-        continue;\n-      last = j;\n-      nns_dist.push_back(make_pair(Distance::distance(v, _get(j)->v, _f), j));\n-    }\n-\n     sort(nns_dist.begin(), nns_dist.end());\n     for (size_t i = 0; i < nns_dist.size() && result->size() < n; i++) {\n-      result->push_back(nns_dist[i].second);\n+      result->push_back(nns_dist[i]);\n     }\n   }\n };\n-\n #endif\ndiff --git a/src/annoymodule.cc b/src/annoymodule.cc\nindex 7a8380b1..76ae09eb 100644\n--- a/src/annoymodule.cc\n+++ b/src/annoymodule.cc\n@@ -32,32 +32,108 @@ template<typename S, typename T, typename Distance>\n class AnnoyIndexPython : public AnnoyIndex<S, T, Distance > {\n public:\n   AnnoyIndexPython(int f): AnnoyIndex<S, T, Distance>(f) {}\n-  void add_item_py(S item, const python::list& v) {\n+  void add_item_py(S item, const python::list& v, size_t label) {\n     vector<T> w;\n     for (int z = 0; z < this->_f; z++)\n       w.push_back(python::extract<T>(v[z]));\n \n-    this->add_item(item, &w[0]);\n+    this->add_item(item, &w[0], label);\n   }\n-  python::list get_nns_by_item_py(S item, size_t n) {\n-    vector<S> result;\n-    this->get_nns_by_item(item, n, &result);\n+  S set_K_py(S K) { \n+    return this->set_K(K); \n+  }\n+  S set_item_size_py(size_t size) { \n+    return this->set_item_size(size); \n+  }\n+  S add_item_to_index_py(const python::list& v, size_t label) {\n+    vector<T> w;\n+    for (int z = 0; z < this->_f; z++)\n+      w.push_back(python::extract<T>(v[z]));\n+    return this->add_item_to_index(&w[0], label);\n+  }\n+\n+  S update_label_py(S item, size_t label) {\n+    return this->update_label(item, label);\n+  }\n+\n+  void get_all_groups_py(T dist_threshold, S search_tree_count) {\n+    this->get_all_groups(dist_threshold, search_tree_count);\n+    return;\n+  }\n+\n+  python::list get_nns_by_item_py(S item, size_t n, python::list c, size_t tn) {\n+    size_t c_size = boost::python::len(c);\n+    vector<S> w(c_size);\n+    for (int z = 0; z < c_size; z++)\n+      w[z] = python::extract<S>(c[z]);\n+    vector<pair<T, S> > result;\n+    this->get_nns_by_item(item, n, &result, w, tn);\n     python::list l;\n-    for (size_t i = 0; i < result.size(); i++)\n-      l.append(result[i]);\n+    for (size_t i = 0; i < result.size(); i++) {\n+      python::list t;\n+      t.append(result[i].first);\n+      t.append(result[i].second);\n+      l.append(t);\n+    }\n     return l;\n   }\n-  python::list get_nns_by_vector_py(python::list v, size_t n) {\n+\n+  python::list get_nns_group_by_item_py(S item, size_t n, python::list c, size_t tn, T dist_threshold) {\n+    size_t c_size = boost::python::len(c);\n+    vector<S> cs(c_size);\n+    vector<vector<S> > group_result;\n+    this->get_nns_group_by_item(item, n, &group_result, cs, tn, dist_threshold);\n+    python::list l;\n+    for (size_t i = 0; i < group_result.size(); i++) {\n+      python::list a;\n+      for (size_t j = 0; j < group_result[i].size(); j ++ ) { \n+        a.append(group_result[i][j]); \n+      }\n+      l.append(a);\n+    }\n+    return l;\n+  }\n+\n+  python::list get_nns_group_by_vector_py(python::list v, size_t n, python::list c, size_t tn, T dist_threshold) {\n+    size_t c_size = boost::python::len(c);\n+    vector<S> cs(c_size);\n+    for (int z = 0; z < c_size; z++)\n+      cs[z] = python::extract<S>(c[z]);\n     vector<T> w(this->_f);\n     for (int z = 0; z < this->_f; z++)\n       w[z] = python::extract<T>(v[z]);\n-    vector<S> result;\n-    this->get_nns_by_vector(&w[0], n, &result);\n+    vector<vector<S> > group_result;\n+    this->get_nns_group_by_vector(&w[0], n, &group_result, cs, tn, dist_threshold);\n     python::list l;\n-    for (size_t i = 0; i < result.size(); i++)\n-      l.append(result[i]);\n+    for (size_t i = 0; i < group_result.size(); i++) {\n+      python::list a;\n+      for (size_t j = 0; j < group_result[i].size(); j ++ ) { \n+        a.append(group_result[i][j]); \n+      }\n+      l.append(a);\n+    }\n     return l;\n   }\n+  python::list get_nns_by_vector_py(python::list v, size_t n, python::list c, size_t tn) {\n+    size_t c_size = boost::python::len(c);\n+    vector<S> cs(c_size);\n+    for (int z = 0; z < c_size; z++)\n+      cs[z] = python::extract<S>(c[z]);\n+    vector<T> w(this->_f);\n+    for (int z = 0; z < this->_f; z++)\n+      w[z] = python::extract<T>(v[z]);\n+    vector<pair<T, S> > result;\n+    this->get_nns_by_vector(&w[0], n, &result, cs, tn);\n+    python::list l;\n+    for (size_t i = 0; i < result.size(); i++) {\n+      python::list t;\n+      t.append(result[i].first);\n+      t.append(result[i].second);\n+      l.append(t);\n+    }\n+    return l;\n+  }\n+\n   python::list get_item_vector_py(S item) {\n     const typename Distance::node* m = this->_get(item);\n     const T* v = m->v;\n@@ -67,6 +143,7 @@ class AnnoyIndexPython : public AnnoyIndex<S, T, Distance > {\n     }\n     return l;\n   }\n+\n   void save_py(const string& filename) {\n     if (!this->save(filename))\n       throw ErrnoException();\n@@ -75,21 +152,34 @@ class AnnoyIndexPython : public AnnoyIndex<S, T, Distance > {\n     if (!this->load(filename))\n       throw ErrnoException();\n   }\n+  void load_memory_py(const string& filename) {\n+    if (!this->load_memory(filename))\n+      throw ErrnoException();\n+  }\n };\n \n template<typename C>\n void expose_methods(python::class_<C> c) {\n   c.def(\"add_item\",          &C::add_item_py)\n+    .def(\"add_item_to_index\", &C::add_item_to_index_py)\n+    .def(\"set_item_size\",     &C::set_item_size)\n+    .def(\"set_K\",    \t      &C::set_K_py)\n+    .def(\"update_label\",      &C::update_label_py)\n     .def(\"build\",             &C::build)\n     .def(\"save\",              &C::save_py)\n     .def(\"load\",              &C::load_py)\n+    .def(\"load_memory\",       &C::load_memory_py)\n     .def(\"unload\",            &C::unload)\n     .def(\"get_distance\",      &C::get_distance)\n+    .def(\"get_all_groups\",    &C::get_all_groups_py)\n     .def(\"get_nns_by_item\",   &C::get_nns_by_item_py)\n+    .def(\"get_nns_group_by_item\",     &C::get_nns_group_by_item_py)\n+    .def(\"get_nns_group_by_vector\",     &C::get_nns_group_by_vector_py)\n     .def(\"get_nns_by_vector\", &C::get_nns_by_vector_py)\n     .def(\"get_item_vector\",   &C::get_item_vector_py)\n     .def(\"get_n_items\",       &C::get_n_items)\n     .def(\"verbose\",           &C::verbose);\n+\n }\n \n BOOST_PYTHON_MODULE(annoylib)\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. The implementation breaks backwards compatibility; consider removing or reworking the \"parent\" field to resolve unit test failures. \n\n2. Remove unrelated commits from the PR to maintain clarity.\n\n3. Assess the use of LMDB for backend storage to manage large indexes, as it provides transaction support and could alleviate memory issues while avoiding redundancy in memory-mapping code.\n\n4. Explore incremental addition to the index after build() and before save() to address memory management without significant changes.\n\n5. For running unit tests, use the command `nosetests`. \n\nNext steps: Focus on the \"parent\" field resolution and LMDB research."
      }
    ],
    "codediff_length": 28086
  },
  {
    "index": 81,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/search.cpp b/src/search.cpp\nindex eda7f2f771a..6d1a66e5f86 100644\n--- a/src/search.cpp\n+++ b/src/search.cpp\n@@ -62,9 +62,9 @@ namespace {\n   enum NodeType { NonPV, PV };\n \n   // Razor and futility margins\n-  constexpr int RazorMargin = 600;\n+  constexpr int RazorMargin = 661;\n   Value futility_margin(Depth d, bool improving) {\n-    return Value((175 - 50 * improving) * d / ONE_PLY);\n+    return Value((168 - 51 * improving) * d / ONE_PLY);\n   }\n \n   // Reductions lookup table, initialized at startup\n@@ -72,7 +72,7 @@ namespace {\n \n   Depth reduction(bool i, Depth d, int mn) {\n     int r = Reductions[d / ONE_PLY] * Reductions[mn];\n-    return ((r + 512) / 1024 + (!i && r > 1024)) * ONE_PLY;\n+    return ((r + 520) / 1024 + (!i && r > 999)) * ONE_PLY;\n   }\n \n   constexpr int futility_move_count(bool improving, int depth) {\n@@ -82,7 +82,7 @@ namespace {\n   // History and stats update bonus, based on depth\n   int stat_bonus(Depth depth) {\n     int d = depth / ONE_PLY;\n-    return d > 17 ? 0 : 29 * d * d + 138 * d - 134;\n+    return d > 17 ? -8 : 22 * d * d + 151 * d - 140;\n   }\n \n   // Add a small random component to draw evaluations to avoid 3fold-blindness\n@@ -191,7 +191,7 @@ namespace {\n void Search::init() {\n \n   for (int i = 1; i < MAX_MOVES; ++i)\n-      Reductions[i] = int(22.9 * std::log(i));\n+      Reductions[i] = int(23.4 * std::log(i));\n }\n \n \n@@ -409,15 +409,15 @@ void Thread::search() {\n           selDepth = 0;\n \n           // Reset aspiration window starting size\n-          if (rootDepth >= 5 * ONE_PLY)\n+          if (rootDepth >= 4 * ONE_PLY)\n           {\n               Value previousScore = rootMoves[pvIdx].previousScore;\n-              delta = Value(20);\n+              delta = Value(23);\n               alpha = std::max(previousScore - delta,-VALUE_INFINITE);\n               beta  = std::min(previousScore + delta, VALUE_INFINITE);\n \n               // Adjust contempt based on root move's previousScore (dynamic contempt)\n-              int dct = ct + 88 * previousScore / (abs(previousScore) + 200);\n+              int dct = ct + 86 * previousScore / (abs(previousScore) + 176);\n \n               contempt = (us == WHITE ?  make_score(dct, dct / 2)\n                                       : -make_score(dct, dct / 2));\n@@ -512,12 +512,12 @@ void Thread::search() {\n           && !Threads.stop\n           && !mainThread->stopOnPonderhit)\n       {\n-          double fallingEval = (314 + 9 * (mainThread->previousScore - bestValue)) / 581.0;\n+          double fallingEval = (354 + 10 * (mainThread->previousScore - bestValue)) / 692.0;\n           fallingEval = clamp(fallingEval, 0.5, 1.5);\n \n           // If the bestMove is stable over several iterations, reduce time accordingly\n-          timeReduction = lastBestMoveDepth + 10 * ONE_PLY < completedDepth ? 1.95 : 1.0;\n-          double reduction = (1.25 + mainThread->previousTimeReduction) / (2.25 * timeReduction);\n+          timeReduction = lastBestMoveDepth + 9 * ONE_PLY < completedDepth ? 1.97 : 0.98;\n+          double reduction = (1.36 + mainThread->previousTimeReduction) / (2.29 * timeReduction);\n \n           // Use part of the gained time from a previous stable move for the current move\n           for (Thread* th : Threads)\n@@ -796,9 +796,9 @@ namespace {\n     // Step 9. Null move search with verification search (~40 Elo)\n     if (   !PvNode\n         && (ss-1)->currentMove != MOVE_NULL\n-        && (ss-1)->statScore < 23200\n+        && (ss-1)->statScore < 22661\n         &&  eval >= beta\n-        &&  ss->staticEval >= beta - 36 * depth / ONE_PLY + 225\n+        &&  ss->staticEval >= beta - 33 * depth / ONE_PLY + 299\n         && !excludedMove\n         &&  pos.non_pawn_material(us)\n         && (ss->ply >= thisThread->nmpMinPly || us != thisThread->nmpColor))\n@@ -806,7 +806,7 @@ namespace {\n         assert(eval - beta >= 0);\n \n         // Null move dynamic reduction based on depth and value\n-        Depth R = ((823 + 67 * depth / ONE_PLY) / 256 + std::min(int(eval - beta) / 200, 3)) * ONE_PLY;\n+        Depth R = ((835 + 70 * depth / ONE_PLY) / 256 + std::min(int(eval - beta) / 185, 3)) * ONE_PLY;\n \n         ss->currentMove = MOVE_NULL;\n         ss->continuationHistory = &thisThread->continuationHistory[NO_PIECE][0];\n@@ -823,7 +823,7 @@ namespace {\n             if (nullValue >= VALUE_MATE_IN_MAX_PLY)\n                 nullValue = beta;\n \n-            if (thisThread->nmpMinPly || (abs(beta) < VALUE_KNOWN_WIN && depth < 12 * ONE_PLY))\n+            if (thisThread->nmpMinPly || (abs(beta) < VALUE_KNOWN_WIN && depth < 13 * ONE_PLY))\n                 return nullValue;\n \n             assert(!thisThread->nmpMinPly); // Recursive verification is not allowed\n@@ -849,7 +849,7 @@ namespace {\n         &&  depth >= 5 * ONE_PLY\n         &&  abs(beta) < VALUE_MATE_IN_MAX_PLY)\n     {\n-        Value raisedBeta = std::min(beta + 216 - 48 * improving, VALUE_INFINITE);\n+        Value raisedBeta = std::min(beta + 191 - 46 * improving, VALUE_INFINITE);\n         MovePicker mp(pos, ttMove, raisedBeta - ss->staticEval, &thisThread->captureHistory);\n         int probCutCount = 0;\n \n@@ -881,7 +881,7 @@ namespace {\n     }\n \n     // Step 11. Internal iterative deepening (~2 Elo)\n-    if (depth >= 8 * ONE_PLY && !ttMove)\n+    if (depth >= 7 * ONE_PLY && !ttMove)\n     {\n         search<NT>(pos, ss, alpha, beta, depth - 7 * ONE_PLY, cutNode);\n \n@@ -955,7 +955,7 @@ namespace {\n       // then that move is singular and should be extended. To verify this we do\n       // a reduced search on all the other moves but the ttMove and if the\n       // result is lower than ttValue minus a margin then we will extend the ttMove.\n-      if (    depth >= 8 * ONE_PLY\n+      if (    depth >= 6 * ONE_PLY\n           &&  move == ttMove\n           && !rootNode\n           && !excludedMove // Avoid recursive singular search\n@@ -976,7 +976,7 @@ namespace {\n               extension = ONE_PLY;\n               singularLMR++;\n \n-              if (value < singularBeta - std::min(3 * depth / ONE_PLY, 39))\n+              if (value < singularBeta - std::min(4 * depth / ONE_PLY, 36))\n                   singularLMR++;\n           }\n \n@@ -1036,15 +1036,15 @@ namespace {\n               lmrDepth /= ONE_PLY;\n \n               // Countermoves based pruning (~20 Elo)\n-              if (   lmrDepth < 3 + ((ss-1)->statScore > 0 || (ss-1)->moveCount == 1)\n+              if (   lmrDepth < 4 + ((ss-1)->statScore > 0 || (ss-1)->moveCount == 1)\n                   && (*contHist[0])[movedPiece][to_sq(move)] < CounterMovePruneThreshold\n                   && (*contHist[1])[movedPiece][to_sq(move)] < CounterMovePruneThreshold)\n                   continue;\n \n               // Futility pruning: parent node (~2 Elo)\n-              if (   lmrDepth < 7\n+              if (   lmrDepth < 6\n                   && !inCheck\n-                  && ss->staticEval + 256 + 200 * lmrDepth <= alpha)\n+                  && ss->staticEval + 250 + 211 * lmrDepth <= alpha)\n                   continue;\n \n               // Prune moves with negative SEE (~10 Elo)\n@@ -1052,7 +1052,7 @@ namespace {\n                   continue;\n           }\n           else if (  (!givesCheck || !extension)\n-                   && !pos.see_ge(move, -PawnValueEg * (depth / ONE_PLY))) // (~20 Elo)\n+                   && !pos.see_ge(move, Value(-199) * (depth / ONE_PLY))) // (~20 Elo)\n                   continue;\n       }\n \n@@ -1119,7 +1119,7 @@ namespace {\n                              + (*contHist[0])[movedPiece][to_sq(move)]\n                              + (*contHist[1])[movedPiece][to_sq(move)]\n                              + (*contHist[3])[movedPiece][to_sq(move)]\n-                             - 4000;\n+                             - 4729;\n \n               // Reset statScore to zero if negative and most stats shows >= 0\n               if (    ss->statScore < 0\n@@ -1129,10 +1129,10 @@ namespace {\n                   ss->statScore = 0;\n \n               // Decrease/increase reduction by comparing opponent's stat score (~10 Elo)\n-              if (ss->statScore >= 0 && (ss-1)->statScore < 0)\n+              if (ss->statScore >= -99 && (ss-1)->statScore < -116)\n                   r -= ONE_PLY;\n \n-              else if ((ss-1)->statScore >= 0 && ss->statScore < 0)\n+              else if ((ss-1)->statScore >= -117 && ss->statScore < -144)\n                   r += ONE_PLY;\n \n               // Decrease/increase reduction for moves with a good/bad history (~30 Elo)\n@@ -1402,7 +1402,7 @@ namespace {\n         if (PvNode && bestValue > alpha)\n             alpha = bestValue;\n \n-        futilityBase = bestValue + 128;\n+        futilityBase = bestValue + 153;\n     }\n \n     const PieceToHistory* contHist[] = { (ss-1)->continuationHistory, (ss-2)->continuationHistory,\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Run STC tests at [0, 4]. If it passes, accept the patch. If it fails, re-run LTC at [0, 4] to assess the validity of the previous LTC results.\n2. Consider increasing STC to 15 or 20 seconds based on the second LTC results.\n3. Assess and document current resource usage for tuning parameters to inform decisions on STC and LTC scaling.\n4. Evaluate if parameters should vary with search depth.\n5. Engage in discussion about the rationale for differing testing intensities for +5 elo versus +1 elo patches. \n6. Establish parameters for standardization in test runs for consistency."
      }
    ],
    "codediff_length": 8734
  },
  {
    "index": 82,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/Makefile b/src/Makefile\nindex cec623f5217..d247c3cb4f8 100644\n--- a/src/Makefile\n+++ b/src/Makefile\n@@ -448,7 +448,7 @@ endif\n ifeq ($(COMP),gcc)\n \tcomp=gcc\n \tCXX=g++\n-\tCXXFLAGS += -pedantic -Wextra -Wshadow -Wmissing-declarations\n+\tCXXFLAGS += -pedantic -Wextra -Wshadow -Wmissing-declarations -Wstack-usage=128000\n \n \tifeq ($(arch),$(filter $(arch),armv7 armv8 riscv64))\n \t\tifeq ($(OS),Android)\n@@ -631,6 +631,19 @@ ifneq ($(comp),mingw)\n \t\tifneq ($(KERNEL),Haiku)\n \t\t\tifneq ($(COMP),ndk)\n \t\t\t\tLDFLAGS += -lpthread\n+\n+\t\t\t\tadd_lrt = yes\n+\t\t\t\tifeq ($(target_windows),yes)\n+\t\t\t\t\tadd_lrt = no\n+\t\t\t\tendif\n+\n+\t\t\t\tifeq ($(KERNEL),Darwin)\n+\t\t\t\t\tadd_lrt = no\n+\t\t\t\tendif\n+\t\t\t\t\n+\t\t\t\tifeq ($(add_lrt),yes)\n+\t\t\t\t\tLDFLAGS += -lrt\n+\t\t\t\tendif\n \t\t\tendif\n \t\tendif\n \tendif\n@@ -641,6 +654,7 @@ ifeq ($(debug),no)\n \tCXXFLAGS += -DNDEBUG\n else\n \tCXXFLAGS += -g\n+\tCXXFLAGS += -D_GLIBCXX_ASSERTIONS -D_GLIBCXX_DEBUG\n endif\n \n ### 3.2.2 Debugging with undefined behavior sanitizers\ndiff --git a/src/engine.cpp b/src/engine.cpp\nindex a4c0bb1ebeb..7f5171794da 100644\n--- a/src/engine.cpp\n+++ b/src/engine.cpp\n@@ -33,6 +33,7 @@\n #include \"misc.h\"\n #include \"nnue/network.h\"\n #include \"nnue/nnue_common.h\"\n+#include \"nnue/nnue_misc.h\"\n #include \"numa.h\"\n #include \"perft.h\"\n #include \"position.h\"\n@@ -57,11 +58,13 @@ Engine::Engine(std::optional<std::string> path) :\n     threads(),\n     networks(\n       numaContext,\n-      NN::Networks(\n-        NN::NetworkBig({EvalFileDefaultNameBig, \"None\", \"\"}, NN::EmbeddedNNUEType::BIG),\n-        NN::NetworkSmall({EvalFileDefaultNameSmall, \"None\", \"\"}, NN::EmbeddedNNUEType::SMALL))) {\n-    pos.set(StartFEN, false, &states->back());\n+      std::make_unique<NN::Networks>(  // requires heap alloc due to sizeof\n+        std::make_unique<NN::NetworkBig>(NN::EvalFile{EvalFileDefaultNameBig, \"None\", \"\"},\n+                                         NN::EmbeddedNNUEType::BIG),\n+        std::make_unique<NN::NetworkSmall>(NN::EvalFile{EvalFileDefaultNameSmall, \"None\", \"\"},\n+                                           NN::EmbeddedNNUEType::SMALL))) {\n \n+    pos.set(StartFEN, false, &states->back());\n \n     options.add(  //\n       \"Debug Log File\", Option(\"\", [](const Option& o) {\n@@ -254,6 +257,27 @@ void Engine::set_ponderhit(bool b) { threads.main_manager()->ponder = b; }\n void Engine::verify_networks() const {\n     networks->big.verify(options[\"EvalFile\"], onVerifyNetworks);\n     networks->small.verify(options[\"EvalFileSmall\"], onVerifyNetworks);\n+\n+    auto statuses = networks.get_status_and_errors();\n+    for (size_t i = 0; i < statuses.size(); ++i) {\n+        const auto [status, error] = statuses[i];\n+        std::string message = \"Network replica \" + std::to_string(i+1) + \": \";\n+        if (status == SystemWideSharedConstantAllocationStatus::NoAllocation) {\n+            message += \"No allocation.\";\n+        } else if (status == SystemWideSharedConstantAllocationStatus::LocalMemory) {\n+            message += \"Local memory.\";\n+        } else if (status == SystemWideSharedConstantAllocationStatus::SharedMemory) {\n+            message += \"Shared memory.\";\n+        } else {\n+            message += \"Unknown status.\";\n+        }\n+\n+        if (error.has_value()) {\n+            message += \" \" + *error;\n+        }\n+            \n+        onVerifyNetworks(message);\n+    }\n }\n \n void Engine::load_networks() {\ndiff --git a/src/engine.h b/src/engine.h\nindex d26844f4ce4..7315b88815f 100644\n--- a/src/engine.h\n+++ b/src/engine.h\n@@ -115,10 +115,10 @@ class Engine {\n     Position     pos;\n     StateListPtr states;\n \n-    OptionsMap                               options;\n-    ThreadPool                               threads;\n-    TranspositionTable                       tt;\n-    LazyNumaReplicated<Eval::NNUE::Networks> networks;\n+    OptionsMap                                         options;\n+    ThreadPool                                         threads;\n+    TranspositionTable                                 tt;\n+    LazyNumaReplicatedSystemWide<Eval::NNUE::Networks> networks;\n \n     Search::SearchManager::UpdateContext  updateContext;\n     std::function<void(std::string_view)> onVerifyNetworks;\ndiff --git a/src/main.cpp b/src/main.cpp\nindex e262f387576..13992d9fe8c 100644\n--- a/src/main.cpp\n+++ b/src/main.cpp\n@@ -17,28 +17,74 @@\n */\n \n #include <iostream>\n+#include <memory>\n \n #include \"bitboard.h\"\n #include \"misc.h\"\n #include \"position.h\"\n+#include \"tune.h\"\n #include \"types.h\"\n #include \"uci.h\"\n-#include \"tune.h\"\n+\n+#include \"shm.h\"\n+\n+#if defined(SHM_CLEANUP)\n+    #include <cstdlib>\n+    #include <cstdio>\n+\n+    #include <signal.h>\n+\n+    #include \"shm_linux.h\"\n+#endif\n+\n+namespace Stockfish {\n+namespace Eval {\n+namespace NNUE {\n+struct Networks;\n+}\n+}\n+}\n \n using namespace Stockfish;\n \n+namespace {\n+#if defined(SHM_CLEANUP)\n+\n+void register_cleanup() {\n+    // hack to invoke atexit\n+    int signals[] = {SIGHUP,  SIGINT,  SIGQUIT, SIGILL, SIGABRT, SIGFPE,\n+                     SIGSEGV, SIGTERM, SIGBUS,  SIGSYS, SIGXCPU, SIGXFSZ};\n+\n+    struct sigaction sa;\n+    sa.sa_handler = [](int sig) { std::exit(128 + sig); };\n+    sigemptyset(&sa.sa_mask);\n+    sa.sa_flags = 0;\n+\n+    for (int sig : signals)\n+        if (sigaction(sig, &sa, nullptr) == -1)\n+            std::perror(\"sigaction\");\n+\n+    // Cleanup function to ensure shared memory is unlinked on exit\n+    std::atexit([]() { shm::SharedMemory<Eval::NNUE::Networks>::cleanup_all_instances(); });\n+}\n+#else\n+void register_cleanup() {}\n+#endif\n+}\n+\n int main(int argc, char* argv[]) {\n+    register_cleanup();\n \n     std::cout << engine_info() << std::endl;\n \n     Bitboards::init();\n     Position::init();\n \n-    UCIEngine uci(argc, argv);\n+    auto uci = std::make_unique<UCIEngine>(argc, argv);\n \n-    Tune::init(uci.engine_options());\n+    Tune::init(uci->engine_options());\n \n-    uci.loop();\n+    uci->loop();\n \n     return 0;\n }\ndiff --git a/src/memory.cpp b/src/memory.cpp\nindex 92cb650f26f..f4aa8fc2656 100644\n--- a/src/memory.cpp\n+++ b/src/memory.cpp\n@@ -55,12 +55,6 @@\n // the calls at compile time), try to load them at runtime. To do this we need\n // first to define the corresponding function pointers.\n \n-extern \"C\" {\n-using OpenProcessToken_t      = bool (*)(HANDLE, DWORD, PHANDLE);\n-using LookupPrivilegeValueA_t = bool (*)(LPCSTR, LPCSTR, PLUID);\n-using AdjustTokenPrivileges_t =\n-  bool (*)(HANDLE, BOOL, PTOKEN_PRIVILEGES, DWORD, PTOKEN_PRIVILEGES, PDWORD);\n-}\n #endif\n \n \n@@ -106,77 +100,14 @@ void std_aligned_free(void* ptr) {\n \n static void* aligned_large_pages_alloc_windows([[maybe_unused]] size_t allocSize) {\n \n-    #if !defined(_WIN64)\n-    return nullptr;\n-    #else\n-\n-    HANDLE hProcessToken{};\n-    LUID   luid{};\n-    void*  mem = nullptr;\n-\n-    const size_t largePageSize = GetLargePageMinimum();\n-    if (!largePageSize)\n-        return nullptr;\n-\n-    // Dynamically link OpenProcessToken, LookupPrivilegeValue and AdjustTokenPrivileges\n-\n-    HMODULE hAdvapi32 = GetModuleHandle(TEXT(\"advapi32.dll\"));\n-\n-    if (!hAdvapi32)\n-        hAdvapi32 = LoadLibrary(TEXT(\"advapi32.dll\"));\n-\n-    auto OpenProcessToken_f =\n-      OpenProcessToken_t((void (*)()) GetProcAddress(hAdvapi32, \"OpenProcessToken\"));\n-    if (!OpenProcessToken_f)\n-        return nullptr;\n-    auto LookupPrivilegeValueA_f =\n-      LookupPrivilegeValueA_t((void (*)()) GetProcAddress(hAdvapi32, \"LookupPrivilegeValueA\"));\n-    if (!LookupPrivilegeValueA_f)\n-        return nullptr;\n-    auto AdjustTokenPrivileges_f =\n-      AdjustTokenPrivileges_t((void (*)()) GetProcAddress(hAdvapi32, \"AdjustTokenPrivileges\"));\n-    if (!AdjustTokenPrivileges_f)\n-        return nullptr;\n-\n-    // We need SeLockMemoryPrivilege, so try to enable it for the process\n-\n-    if (!OpenProcessToken_f(  // OpenProcessToken()\n-          GetCurrentProcess(), TOKEN_ADJUST_PRIVILEGES | TOKEN_QUERY, &hProcessToken))\n-        return nullptr;\n-\n-    if (LookupPrivilegeValueA_f(nullptr, \"SeLockMemoryPrivilege\", &luid))\n-    {\n-        TOKEN_PRIVILEGES tp{};\n-        TOKEN_PRIVILEGES prevTp{};\n-        DWORD            prevTpLen = 0;\n-\n-        tp.PrivilegeCount           = 1;\n-        tp.Privileges[0].Luid       = luid;\n-        tp.Privileges[0].Attributes = SE_PRIVILEGE_ENABLED;\n-\n-        // Try to enable SeLockMemoryPrivilege. Note that even if AdjustTokenPrivileges()\n-        // succeeds, we still need to query GetLastError() to ensure that the privileges\n-        // were actually obtained.\n-\n-        if (AdjustTokenPrivileges_f(hProcessToken, FALSE, &tp, sizeof(TOKEN_PRIVILEGES), &prevTp,\n-                                    &prevTpLen)\n-            && GetLastError() == ERROR_SUCCESS)\n-        {\n-            // Round up size to full pages and allocate\n-            allocSize = (allocSize + largePageSize - 1) & ~size_t(largePageSize - 1);\n-            mem       = VirtualAlloc(nullptr, allocSize, MEM_RESERVE | MEM_COMMIT | MEM_LARGE_PAGES,\n-                                     PAGE_READWRITE);\n-\n-            // Privilege no longer needed, restore previous state\n-            AdjustTokenPrivileges_f(hProcessToken, FALSE, &prevTp, 0, nullptr, nullptr);\n-        }\n-    }\n-\n-    CloseHandle(hProcessToken);\n-\n-    return mem;\n-\n-    #endif\n+    return windows_try_with_large_page_priviliges(\n+      [&](size_t largePageSize) {\n+          // Round up size to full pages and allocate\n+          allocSize = (allocSize + largePageSize - 1) & ~size_t(largePageSize - 1);\n+          return VirtualAlloc(nullptr, allocSize, MEM_RESERVE | MEM_COMMIT | MEM_LARGE_PAGES,\n+                              PAGE_READWRITE);\n+      },\n+      []() { return (void*) nullptr; });\n }\n \n void* aligned_large_pages_alloc(size_t allocSize) {\ndiff --git a/src/memory.h b/src/memory.h\nindex e4a59fec5e0..b9be6f170dc 100644\n--- a/src/memory.h\n+++ b/src/memory.h\n@@ -29,6 +29,29 @@\n \n #include \"types.h\"\n \n+#if defined(_WIN64)\n+\n+    #if _WIN32_WINNT < 0x0601\n+        #undef _WIN32_WINNT\n+        #define _WIN32_WINNT 0x0601  // Force to include needed API prototypes\n+    #endif\n+\n+    #if !defined(NOMINMAX)\n+        #define NOMINMAX\n+    #endif\n+    #include <windows.h>\n+\n+    #include <psapi.h>\n+\n+extern \"C\" {\n+using OpenProcessToken_t      = bool (*)(HANDLE, DWORD, PHANDLE);\n+using LookupPrivilegeValueA_t = bool (*)(LPCSTR, LPCSTR, PLUID);\n+using AdjustTokenPrivileges_t =\n+  bool (*)(HANDLE, BOOL, PTOKEN_PRIVILEGES, DWORD, PTOKEN_PRIVILEGES, PDWORD);\n+}\n+#endif\n+\n+\n namespace Stockfish {\n \n void* std_aligned_alloc(size_t alignment, size_t size);\n@@ -211,6 +234,81 @@ T* align_ptr_up(T* ptr) {\n       reinterpret_cast<char*>((ptrint + (Alignment - 1)) / Alignment * Alignment));\n }\n \n+#if defined(_WIN32)\n+\n+template<typename FuncYesT, typename FuncNoT>\n+auto windows_try_with_large_page_priviliges([[maybe_unused]] FuncYesT&& fyes, FuncNoT&& fno) {\n+\n+    #if !defined(_WIN64)\n+    return fno();\n+    #else\n+\n+    HANDLE hProcessToken{};\n+    LUID   luid{};\n+\n+    const size_t largePageSize = GetLargePageMinimum();\n+    if (!largePageSize)\n+        return fno();\n+\n+    // Dynamically link OpenProcessToken, LookupPrivilegeValue and AdjustTokenPrivileges\n+\n+    HMODULE hAdvapi32 = GetModuleHandle(TEXT(\"advapi32.dll\"));\n+\n+    if (!hAdvapi32)\n+        hAdvapi32 = LoadLibrary(TEXT(\"advapi32.dll\"));\n+\n+    auto OpenProcessToken_f =\n+      OpenProcessToken_t((void (*)()) GetProcAddress(hAdvapi32, \"OpenProcessToken\"));\n+    if (!OpenProcessToken_f)\n+        return fno();\n+    auto LookupPrivilegeValueA_f =\n+      LookupPrivilegeValueA_t((void (*)()) GetProcAddress(hAdvapi32, \"LookupPrivilegeValueA\"));\n+    if (!LookupPrivilegeValueA_f)\n+        return fno();\n+    auto AdjustTokenPrivileges_f =\n+      AdjustTokenPrivileges_t((void (*)()) GetProcAddress(hAdvapi32, \"AdjustTokenPrivileges\"));\n+    if (!AdjustTokenPrivileges_f)\n+        return fno();\n+\n+    // We need SeLockMemoryPrivilege, so try to enable it for the process\n+\n+    if (!OpenProcessToken_f(  // OpenProcessToken()\n+          GetCurrentProcess(), TOKEN_ADJUST_PRIVILEGES | TOKEN_QUERY, &hProcessToken))\n+        return fno();\n+\n+    if (!LookupPrivilegeValueA_f(nullptr, \"SeLockMemoryPrivilege\", &luid))\n+        return fno();\n+\n+    TOKEN_PRIVILEGES tp{};\n+    TOKEN_PRIVILEGES prevTp{};\n+    DWORD            prevTpLen = 0;\n+\n+    tp.PrivilegeCount           = 1;\n+    tp.Privileges[0].Luid       = luid;\n+    tp.Privileges[0].Attributes = SE_PRIVILEGE_ENABLED;\n+\n+    // Try to enable SeLockMemoryPrivilege. Note that even if AdjustTokenPrivileges()\n+    // succeeds, we still need to query GetLastError() to ensure that the privileges\n+    // were actually obtained.\n+\n+    if (!AdjustTokenPrivileges_f(hProcessToken, FALSE, &tp, sizeof(TOKEN_PRIVILEGES), &prevTp,\n+                                 &prevTpLen)\n+        || GetLastError() != ERROR_SUCCESS)\n+        return fno();\n+\n+    auto&& ret = fyes(largePageSize);\n+\n+    // Privilege no longer needed, restore previous state\n+    AdjustTokenPrivileges_f(hProcessToken, FALSE, &prevTp, 0, nullptr, nullptr);\n+\n+    CloseHandle(hProcessToken);\n+\n+    return std::forward<decltype(ret)>(ret);\n+\n+    #endif\n+}\n+\n+#endif\n \n }  // namespace Stockfish\n \ndiff --git a/src/misc.h b/src/misc.h\nindex 756433290ee..b1707e74217 100644\n--- a/src/misc.h\n+++ b/src/misc.h\n@@ -23,11 +23,15 @@\n #include <array>\n #include <cassert>\n #include <chrono>\n-#include <cstddef>\n #include <cstdint>\n #include <cstdio>\n+#include <exception>  // IWYU pragma: keep\n+// IWYU pragma: no_include <__exception/terminate.h>\n+#include <functional>\n #include <iosfwd>\n #include <optional>\n+#include <cstring>\n+#include <memory>\n #include <string>\n #include <string_view>\n #include <vector>\n@@ -291,6 +295,94 @@ inline uint64_t mul_hi64(uint64_t a, uint64_t b) {\n }\n \n \n+template<typename T>\n+inline void hash_combine(std::size_t& seed, const T& v) {\n+    std::hash<T> hasher;\n+    seed ^= hasher(v) + 0x9e3779b9 + (seed << 6) + (seed >> 2);\n+}\n+\n+template<>\n+inline void hash_combine(std::size_t& seed, const std::size_t& v) {\n+    seed ^= v + 0x9e3779b9 + (seed << 6) + (seed >> 2);\n+}\n+\n+template<typename T>\n+inline std::size_t get_raw_data_hash(const T& value) {\n+    return std::hash<std::string_view>{}(\n+      std::string_view(reinterpret_cast<const char*>(&value), sizeof(value)));\n+}\n+\n+template<std::size_t Capacity>\n+class FixedString {\n+   public:\n+    FixedString() :\n+        length_(0) {\n+        data_[0] = '\\0';\n+    }\n+\n+    FixedString(const char* str) {\n+        size_t len = std::strlen(str);\n+        if (len > Capacity)\n+            std::terminate();\n+        std::memcpy(data_, str, len);\n+        length_        = len;\n+        data_[length_] = '\\0';\n+    }\n+\n+    FixedString(const std::string& str) {\n+        if (str.size() > Capacity)\n+            std::terminate();\n+        std::memcpy(data_, str.data(), str.size());\n+        length_        = str.size();\n+        data_[length_] = '\\0';\n+    }\n+\n+    std::size_t size() const { return length_; }\n+    std::size_t capacity() const { return Capacity; }\n+\n+    const char* c_str() const { return data_; }\n+    const char* data() const { return data_; }\n+\n+    char& operator[](std::size_t i) { return data_[i]; }\n+\n+    const char& operator[](std::size_t i) const { return data_[i]; }\n+\n+    FixedString& operator+=(const char* str) {\n+        size_t len = std::strlen(str);\n+        if (length_ + len > Capacity)\n+            std::terminate();\n+        std::memcpy(data_ + length_, str, len);\n+        length_ += len;\n+        data_[length_] = '\\0';\n+        return *this;\n+    }\n+\n+    FixedString& operator+=(const FixedString& other) { return (*this += other.c_str()); }\n+\n+    operator std::string() const { return std::string(data_, length_); }\n+\n+    operator std::string_view() const { return std::string_view(data_, length_); }\n+\n+    template<typename T>\n+    bool operator==(const T& other) const noexcept {\n+        return (std::string_view) (*this) == other;\n+    }\n+\n+    template<typename T>\n+    bool operator!=(const T& other) const noexcept {\n+        return (std::string_view) (*this) != other;\n+    }\n+\n+    void clear() {\n+        length_  = 0;\n+        data_[0] = '\\0';\n+    }\n+\n+   private:\n+    char        data_[Capacity + 1];  // +1 for null terminator\n+    std::size_t length_;\n+};\n+\n struct CommandLine {\n    public:\n     CommandLine(int _argc, char** _argv) :\n@@ -335,4 +427,11 @@ void move_to_front(std::vector<T>& vec, Predicate pred) {\n \n }  // namespace Stockfish\n \n+template<std::size_t N>\n+struct std::hash<Stockfish::FixedString<N>> {\n+    std::size_t operator()(const Stockfish::FixedString<N>& fstr) const noexcept {\n+        return std::hash<std::string_view>{}((std::string_view) fstr);\n+    }\n+};\n+\n #endif  // #ifndef MISC_H_INCLUDED\ndiff --git a/src/nnue/layers/affine_transform.h b/src/nnue/layers/affine_transform.h\nindex b4440c1e3fb..7ead09327e5 100644\n--- a/src/nnue/layers/affine_transform.h\n+++ b/src/nnue/layers/affine_transform.h\n@@ -181,6 +181,15 @@ class AffineTransform {\n \n         return !stream.fail();\n     }\n+\n+    std::size_t get_content_hash() const {\n+        std::size_t h = 0;\n+        hash_combine(h, get_raw_data_hash(biases));\n+        hash_combine(h, get_raw_data_hash(weights));\n+        hash_combine(h, get_hash_value(0));\n+        return h;\n+    }\n+\n     // Forward propagation\n     void propagate(const InputType* input, OutputType* output) const {\n \ndiff --git a/src/nnue/layers/affine_transform_sparse_input.h b/src/nnue/layers/affine_transform_sparse_input.h\nindex 069210304b1..985a74f66e5 100644\n--- a/src/nnue/layers/affine_transform_sparse_input.h\n+++ b/src/nnue/layers/affine_transform_sparse_input.h\n@@ -239,6 +239,15 @@ class AffineTransformSparseInput {\n \n         return !stream.fail();\n     }\n+\n+    std::size_t get_content_hash() const {\n+        std::size_t h = 0;\n+        hash_combine(h, get_raw_data_hash(biases));\n+        hash_combine(h, get_raw_data_hash(weights));\n+        hash_combine(h, get_hash_value(0));\n+        return h;\n+    }\n+\n     // Forward propagation\n     void propagate(const InputType* input, OutputType* output) const {\n \ndiff --git a/src/nnue/layers/clipped_relu.h b/src/nnue/layers/clipped_relu.h\nindex 2ad5a86a12c..a8679d14d72 100644\n--- a/src/nnue/layers/clipped_relu.h\n+++ b/src/nnue/layers/clipped_relu.h\n@@ -58,6 +58,12 @@ class ClippedReLU {\n     // Write network parameters\n     bool write_parameters(std::ostream&) const { return true; }\n \n+    std::size_t get_content_hash() const {\n+        std::size_t h = 0;\n+        hash_combine(h, get_hash_value(0));\n+        return h;\n+    }\n+\n     // Forward propagation\n     void propagate(const InputType* input, OutputType* output) const {\n \ndiff --git a/src/nnue/layers/sqr_clipped_relu.h b/src/nnue/layers/sqr_clipped_relu.h\nindex d14f1e0aba3..4218c0fe259 100644\n--- a/src/nnue/layers/sqr_clipped_relu.h\n+++ b/src/nnue/layers/sqr_clipped_relu.h\n@@ -58,6 +58,12 @@ class SqrClippedReLU {\n     // Write network parameters\n     bool write_parameters(std::ostream&) const { return true; }\n \n+    std::size_t get_content_hash() const {\n+        std::size_t h = 0;\n+        hash_combine(h, get_hash_value(0));\n+        return h;\n+    }\n+\n     // Forward propagation\n     void propagate(const InputType* input, OutputType* output) const {\n \ndiff --git a/src/nnue/network.cpp b/src/nnue/network.cpp\nindex 957dc7bffcc..f0391bebbff 100644\n--- a/src/nnue/network.cpp\n+++ b/src/nnue/network.cpp\n@@ -21,7 +21,6 @@\n #include <cstdlib>\n #include <fstream>\n #include <iostream>\n-#include <memory>\n #include <optional>\n #include <type_traits>\n #include <vector>\n@@ -30,7 +29,6 @@\n #include \"../incbin/incbin.h\"\n \n #include \"../evaluate.h\"\n-#include \"../memory.h\"\n #include \"../misc.h\"\n #include \"../position.h\"\n #include \"../types.h\"\n@@ -101,7 +99,7 @@ bool read_parameters(std::istream& stream, T& reference) {\n \n // Write evaluation function parameters\n template<typename T>\n-bool write_parameters(std::ostream& stream, T& reference) {\n+bool write_parameters(std::ostream& stream, const T& reference) {\n \n     write_little_endian<std::uint32_t>(stream, T::get_hash_value());\n     return reference.write_parameters(stream);\n@@ -109,43 +107,6 @@ bool write_parameters(std::ostream& stream, T& reference) {\n \n }  // namespace Detail\n \n-template<typename Arch, typename Transformer>\n-Network<Arch, Transformer>::Network(const Network<Arch, Transformer>& other) :\n-    evalFile(other.evalFile),\n-    embeddedType(other.embeddedType) {\n-\n-    if (other.featureTransformer)\n-        featureTransformer = make_unique_large_page<Transformer>(*other.featureTransformer);\n-\n-    network = make_unique_aligned<Arch[]>(LayerStacks);\n-\n-    if (!other.network)\n-        return;\n-\n-    for (std::size_t i = 0; i < LayerStacks; ++i)\n-        network[i] = other.network[i];\n-}\n-\n-template<typename Arch, typename Transformer>\n-Network<Arch, Transformer>&\n-Network<Arch, Transformer>::operator=(const Network<Arch, Transformer>& other) {\n-    evalFile     = other.evalFile;\n-    embeddedType = other.embeddedType;\n-\n-    if (other.featureTransformer)\n-        featureTransformer = make_unique_large_page<Transformer>(*other.featureTransformer);\n-\n-    network = make_unique_aligned<Arch[]>(LayerStacks);\n-\n-    if (!other.network)\n-        return *this;\n-\n-    for (std::size_t i = 0; i < LayerStacks; ++i)\n-        network[i] = other.network[i];\n-\n-    return *this;\n-}\n-\n template<typename Arch, typename Transformer>\n void Network<Arch, Transformer>::load(const std::string& rootDirectory, std::string evalfilePath) {\n #if defined(DEFAULT_NNUE_DIRECTORY)\n@@ -160,14 +121,14 @@ void Network<Arch, Transformer>::load(const std::string& rootDirectory, std::str\n \n     for (const auto& directory : dirs)\n     {\n-        if (evalFile.current != evalfilePath)\n+        if (std::string(evalFile.current) != evalfilePath)\n         {\n             if (directory != \"<internal>\")\n             {\n                 load_user_net(directory, evalfilePath);\n             }\n \n-            if (directory == \"<internal>\" && evalfilePath == evalFile.defaultName)\n+            if (directory == \"<internal>\" && evalfilePath == std::string(evalFile.defaultName))\n             {\n                 load_internal();\n             }\n@@ -185,7 +146,7 @@ bool Network<Arch, Transformer>::save(const std::optional<std::string>& filename\n         actualFilename = filename.value();\n     else\n     {\n-        if (evalFile.current != evalFile.defaultName)\n+        if (std::string(evalFile.current) != std::string(evalFile.defaultName))\n         {\n             msg = \"Failed to export a net. \"\n                   \"A non-embedded net can only be saved if the filename is specified\";\n@@ -222,7 +183,7 @@ Network<Arch, Transformer>::evaluate(const Position&                         pos\n \n     const int  bucket = (pos.count<ALL_PIECES>() - 1) / 4;\n     const auto psqt =\n-      featureTransformer->transform(pos, accumulatorStack, cache, transformedFeatures, bucket);\n+      featureTransformer.transform(pos, accumulatorStack, cache, transformedFeatures, bucket);\n     const auto positional = network[bucket].propagate(transformedFeatures);\n     return {static_cast<Value>(psqt / OutputScale), static_cast<Value>(positional / OutputScale)};\n }\n@@ -234,7 +195,7 @@ void Network<Arch, Transformer>::verify(std::string\n     if (evalfilePath.empty())\n         evalfilePath = evalFile.defaultName;\n \n-    if (evalFile.current != evalfilePath)\n+    if (std::string(evalFile.current) != evalfilePath)\n     {\n         if (f)\n         {\n@@ -245,7 +206,7 @@ void Network<Arch, Transformer>::verify(std::string\n                                \"including the directory name, to the network file.\";\n             std::string msg4 = \"The default net can be downloaded from: \"\n                                \"https://tests.stockfishchess.org/api/nn/\"\n-                             + evalFile.defaultName;\n+                             + std::string(evalFile.defaultName);\n             std::string msg5 = \"The engine will be terminated now.\";\n \n             std::string msg = \"ERROR: \" + msg1 + '\\n' + \"ERROR: \" + msg2 + '\\n' + \"ERROR: \" + msg3\n@@ -259,9 +220,9 @@ void Network<Arch, Transformer>::verify(std::string\n \n     if (f)\n     {\n-        size_t size = sizeof(*featureTransformer) + sizeof(Arch) * LayerStacks;\n+        size_t size = sizeof(featureTransformer) + sizeof(Arch) * LayerStacks;\n         f(\"NNUE evaluation using \" + evalfilePath + \" (\" + std::to_string(size / (1024 * 1024))\n-          + \"MiB, (\" + std::to_string(featureTransformer->InputDimensions) + \", \"\n+          + \"MiB, (\" + std::to_string(featureTransformer.InputDimensions) + \", \"\n           + std::to_string(network[0].TransformedFeatureDimensions) + \", \"\n           + std::to_string(network[0].FC_0_OUTPUTS) + \", \" + std::to_string(network[0].FC_1_OUTPUTS)\n           + \", 1))\");\n@@ -287,7 +248,7 @@ Network<Arch, Transformer>::trace_evaluate(const Position&\n     for (IndexType bucket = 0; bucket < LayerStacks; ++bucket)\n     {\n         const auto materialist =\n-          featureTransformer->transform(pos, accumulatorStack, cache, transformedFeatures, bucket);\n+          featureTransformer.transform(pos, accumulatorStack, cache, transformedFeatures, bucket);\n         const auto positional = network[bucket].propagate(transformedFeatures);\n \n         t.psqt[bucket]       = static_cast<Value>(materialist / OutputScale);\n@@ -341,8 +302,7 @@ void Network<Arch, Transformer>::load_internal() {\n \n template<typename Arch, typename Transformer>\n void Network<Arch, Transformer>::initialize() {\n-    featureTransformer = make_unique_large_page<Transformer>();\n-    network            = make_unique_aligned<Arch[]>(LayerStacks);\n+    initialized = true;\n }\n \n \n@@ -366,6 +326,20 @@ std::optional<std::string> Network<Arch, Transformer>::load(std::istream& stream\n }\n \n \n+template<typename Arch, typename Transformer>\n+std::size_t Network<Arch, Transformer>::get_content_hash() const {\n+    if (!initialized)\n+        return 0;\n+\n+    std::size_t h = 0;\n+    hash_combine(h, featureTransformer);\n+    for (IndexType i = 0; i < LayerStacks; ++i)\n+        hash_combine(h, network[i]);\n+    hash_combine(h, evalFile);\n+    hash_combine(h, static_cast<int>(embeddedType));\n+    return h;\n+}\n+\n // Read network header\n template<typename Arch, typename Transformer>\n bool Network<Arch, Transformer>::read_header(std::istream&  stream,\n@@ -399,13 +373,13 @@ bool Network<Arch, Transformer>::write_header(std::ostream&      stream,\n \n template<typename Arch, typename Transformer>\n bool Network<Arch, Transformer>::read_parameters(std::istream& stream,\n-                                                 std::string&  netDescription) const {\n+                                                 std::string&  netDescription) {\n     std::uint32_t hashValue;\n     if (!read_header(stream, &hashValue, &netDescription))\n         return false;\n     if (hashValue != Network::hash)\n         return false;\n-    if (!Detail::read_parameters(stream, *featureTransformer))\n+    if (!Detail::read_parameters(stream, featureTransformer))\n         return false;\n     for (std::size_t i = 0; i < LayerStacks; ++i)\n     {\n@@ -421,7 +395,7 @@ bool Network<Arch, Transformer>::write_parameters(std::ostream&      stream,\n                                                   const std::string& netDescription) const {\n     if (!write_header(stream, Network::hash, netDescription))\n         return false;\n-    if (!Detail::write_parameters(stream, *featureTransformer))\n+    if (!Detail::write_parameters(stream, featureTransformer))\n         return false;\n     for (std::size_t i = 0; i < LayerStacks; ++i)\n     {\ndiff --git a/src/nnue/network.h b/src/nnue/network.h\nindex c9358823bdb..6426252ec21 100644\n--- a/src/nnue/network.h\n+++ b/src/nnue/network.h\n@@ -19,16 +19,18 @@\n #ifndef NETWORK_H_INCLUDED\n #define NETWORK_H_INCLUDED\n \n+#include <cstddef>\n #include <cstdint>\n #include <functional>\n #include <iostream>\n+#include <memory>\n #include <optional>\n #include <string>\n #include <string_view>\n #include <tuple>\n #include <utility>\n \n-#include \"../memory.h\"\n+#include \"../misc.h\"\n #include \"../types.h\"\n #include \"nnue_accumulator.h\"\n #include \"nnue_architecture.h\"\n@@ -49,6 +51,7 @@ enum class EmbeddedNNUEType {\n \n using NetworkOutput = std::tuple<Value, Value>;\n \n+// The network must be trivial, i.e. the memory must be in-line. This is required to allow sharing the network via shared memory.\n template<typename Arch, typename Transformer>\n class Network {\n     static constexpr IndexType FTDimensions = Arch::TransformedFeatureDimensions;\n@@ -58,15 +61,17 @@ class Network {\n         evalFile(file),\n         embeddedType(type) {}\n \n-    Network(const Network& other);\n-    Network(Network&& other) = default;\n+    Network(const Network& other) = default;\n+    Network(Network&& other)      = default;\n \n-    Network& operator=(const Network& other);\n-    Network& operator=(Network&& other) = default;\n+    Network& operator=(const Network& other) = default;\n+    Network& operator=(Network&& other)      = default;\n \n     void load(const std::string& rootDirectory, std::string evalfilePath);\n     bool save(const std::optional<std::string>& filename) const;\n \n+    std::size_t get_content_hash() const;\n+\n     NetworkOutput evaluate(const Position&                         pos,\n                            AccumulatorStack&                       accumulatorStack,\n                            AccumulatorCaches::Cache<FTDimensions>* cache) const;\n@@ -89,18 +94,20 @@ class Network {\n     bool read_header(std::istream&, std::uint32_t*, std::string*) const;\n     bool write_header(std::ostream&, std::uint32_t, const std::string&) const;\n \n-    bool read_parameters(std::istream&, std::string&) const;\n+    bool read_parameters(std::istream&, std::string&);\n     bool write_parameters(std::ostream&, const std::string&) const;\n \n     // Input feature converter\n-    LargePagePtr<Transformer> featureTransformer;\n+    Transformer featureTransformer;\n \n     // Evaluation function\n-    AlignedPtr<Arch[]> network;\n+    Arch network[LayerStacks];\n \n     EvalFile         evalFile;\n     EmbeddedNNUEType embeddedType;\n \n+    bool initialized = false;\n+\n     // Hash value of evaluation function structure\n     static constexpr std::uint32_t hash = Transformer::get_hash_value() ^ Arch::get_hash_value();\n \n@@ -123,9 +130,9 @@ using NetworkSmall = Network<SmallNetworkArchitecture, SmallFeatureTransformer>;\n \n \n struct Networks {\n-    Networks(NetworkBig&& nB, NetworkSmall&& nS) :\n-        big(std::move(nB)),\n-        small(std::move(nS)) {}\n+    Networks(std::unique_ptr<NetworkBig>&& nB, std::unique_ptr<NetworkSmall>&& nS) :\n+        big(std::move(*nB)),\n+        small(std::move(*nS)) {}\n \n     NetworkBig   big;\n     NetworkSmall small;\n@@ -134,4 +141,22 @@ struct Networks {\n \n }  // namespace Stockfish\n \n+template<typename ArchT, typename FeatureTransformerT>\n+struct std::hash<Stockfish::Eval::NNUE::Network<ArchT, FeatureTransformerT>> {\n+    std::size_t operator()(\n+      const Stockfish::Eval::NNUE::Network<ArchT, FeatureTransformerT>& network) const noexcept {\n+        return network.get_content_hash();\n+    }\n+};\n+\n+template<>\n+struct std::hash<Stockfish::Eval::NNUE::Networks> {\n+    std::size_t operator()(const Stockfish::Eval::NNUE::Networks& networks) const noexcept {\n+        std::size_t h = 0;\n+        Stockfish::hash_combine(h, networks.big);\n+        Stockfish::hash_combine(h, networks.small);\n+        return h;\n+    }\n+};\n+\n #endif\ndiff --git a/src/nnue/nnue_accumulator.h b/src/nnue/nnue_accumulator.h\nindex 10aadc91776..8ddba67deb6 100644\n--- a/src/nnue/nnue_accumulator.h\n+++ b/src/nnue/nnue_accumulator.h\n@@ -88,7 +88,7 @@ struct AccumulatorCaches {\n         void clear(const Network& network) {\n             for (auto& entries1D : entries)\n                 for (auto& entry : entries1D)\n-                    entry.clear(network.featureTransformer->biases);\n+                    entry.clear(network.featureTransformer.biases);\n         }\n \n         std::array<Entry, COLOR_NB>& operator[](Square sq) { return entries[sq]; }\ndiff --git a/src/nnue/nnue_architecture.h b/src/nnue/nnue_architecture.h\nindex c020ce05b38..5965f24aa38 100644\n--- a/src/nnue/nnue_architecture.h\n+++ b/src/nnue/nnue_architecture.h\n@@ -97,7 +97,7 @@ struct NetworkArchitecture {\n             && fc_2.write_parameters(stream);\n     }\n \n-    std::int32_t propagate(const TransformedFeatureType* transformedFeatures) {\n+    std::int32_t propagate(const TransformedFeatureType* transformedFeatures) const {\n         struct alignas(CacheLineSize) Buffer {\n             alignas(CacheLineSize) typename decltype(fc_0)::OutputBuffer fc_0_out;\n             alignas(CacheLineSize) typename decltype(ac_sqr_0)::OutputType\n@@ -136,8 +136,28 @@ struct NetworkArchitecture {\n \n         return outputValue;\n     }\n+\n+    std::size_t get_content_hash() const {\n+        std::size_t h = 0;\n+        hash_combine(h, fc_0.get_content_hash());\n+        hash_combine(h, ac_sqr_0.get_content_hash());\n+        hash_combine(h, ac_0.get_content_hash());\n+        hash_combine(h, fc_1.get_content_hash());\n+        hash_combine(h, ac_1.get_content_hash());\n+        hash_combine(h, fc_2.get_content_hash());\n+        hash_combine(h, get_hash_value());\n+        return h;\n+    }\n };\n \n }  // namespace Stockfish::Eval::NNUE\n \n+template<Stockfish::Eval::NNUE::IndexType L1, int L2, int L3>\n+struct std::hash<Stockfish::Eval::NNUE::NetworkArchitecture<L1, L2, L3>> {\n+    std::size_t\n+    operator()(const Stockfish::Eval::NNUE::NetworkArchitecture<L1, L2, L3>& arch) const noexcept {\n+        return arch.get_content_hash();\n+    }\n+};\n+\n #endif  // #ifndef NNUE_ARCHITECTURE_H_INCLUDED\ndiff --git a/src/nnue/nnue_common.h b/src/nnue/nnue_common.h\nindex 550bcaad41b..3617a85eb28 100644\n--- a/src/nnue/nnue_common.h\n+++ b/src/nnue/nnue_common.h\n@@ -258,8 +258,8 @@ inline void write_leb_128(std::ostream& stream, const IntType* values, std::size\n         }\n     };\n \n-    auto write = [&](std::uint8_t byte) {\n-        buf[buf_pos++] = byte;\n+    auto write = [&](std::uint8_t b) {\n+        buf[buf_pos++] = b;\n         if (buf_pos == BUF_SIZE)\n             flush();\n     };\ndiff --git a/src/nnue/nnue_feature_transformer.h b/src/nnue/nnue_feature_transformer.h\nindex 37634cbc6b7..3439bc43c66 100644\n--- a/src/nnue/nnue_feature_transformer.h\n+++ b/src/nnue/nnue_feature_transformer.h\n@@ -157,20 +157,28 @@ class FeatureTransformer {\n     }\n \n     // Write network parameters\n-    bool write_parameters(std::ostream& stream) {\n+    bool write_parameters(std::ostream& stream) const {\n+        std::unique_ptr<FeatureTransformer> copy = std::make_unique<FeatureTransformer>(*this);\n \n-        unpermute_weights();\n-        scale_weights(false);\n+        copy->unpermute_weights();\n+        copy->scale_weights(false);\n \n-        write_leb_128<BiasType>(stream, biases, HalfDimensions);\n-        write_leb_128<WeightType>(stream, weights, HalfDimensions * InputDimensions);\n-        write_leb_128<PSQTWeightType>(stream, psqtWeights, PSQTBuckets * InputDimensions);\n+        write_leb_128<BiasType>(stream, copy->biases, HalfDimensions);\n+        write_leb_128<WeightType>(stream, copy->weights, HalfDimensions * InputDimensions);\n+        write_leb_128<PSQTWeightType>(stream, copy->psqtWeights, PSQTBuckets * InputDimensions);\n \n-        permute_weights();\n-        scale_weights(true);\n         return !stream.fail();\n     }\n \n+    std::size_t get_content_hash() const {\n+        std::size_t h = 0;\n+        hash_combine(h, get_raw_data_hash(biases));\n+        hash_combine(h, get_raw_data_hash(weights));\n+        hash_combine(h, get_raw_data_hash(psqtWeights));\n+        hash_combine(h, get_hash_value());\n+        return h;\n+    }\n+\n     // Convert input features\n     std::int32_t transform(const Position&                           pos,\n                            AccumulatorStack&                         accumulatorStack,\n@@ -309,4 +317,14 @@ class FeatureTransformer {\n \n }  // namespace Stockfish::Eval::NNUE\n \n+\n+template<Stockfish::Eval::NNUE::IndexType TransformedFeatureDimensions>\n+struct std::hash<Stockfish::Eval::NNUE::FeatureTransformer<TransformedFeatureDimensions>> {\n+    std::size_t\n+    operator()(const Stockfish::Eval::NNUE::FeatureTransformer<TransformedFeatureDimensions>& ft)\n+      const noexcept {\n+        return ft.get_content_hash();\n+    }\n+};\n+\n #endif  // #ifndef NNUE_FEATURE_TRANSFORMER_H_INCLUDED\ndiff --git a/src/nnue/nnue_misc.h b/src/nnue/nnue_misc.h\nindex 02212160a12..7ecfd58a2f6 100644\n--- a/src/nnue/nnue_misc.h\n+++ b/src/nnue/nnue_misc.h\n@@ -20,8 +20,10 @@\n #define NNUE_MISC_H_INCLUDED\n \n #include <cstddef>\n+#include <memory>\n #include <string>\n \n+#include \"../misc.h\"\n #include \"../types.h\"\n #include \"nnue_architecture.h\"\n \n@@ -31,17 +33,17 @@ class Position;\n \n namespace Eval::NNUE {\n \n+// EvalFile uses fixed string types because it's part of the network structure which must be trivial.\n struct EvalFile {\n     // Default net name, will use one of the EvalFileDefaultName* macros defined\n     // in evaluate.h\n-    std::string defaultName;\n+    FixedString<256> defaultName;\n     // Selected net name, either via uci option or default\n-    std::string current;\n+    FixedString<256> current;\n     // Net description extracted from the net file\n-    std::string netDescription;\n+    FixedString<256> netDescription;\n };\n \n-\n struct NnueEvalTrace {\n     static_assert(LayerStacks == PSQTBuckets);\n \n@@ -58,4 +60,15 @@ std::string trace(Position& pos, const Networks& networks, AccumulatorCaches& ca\n }  // namespace Stockfish::Eval::NNUE\n }  // namespace Stockfish\n \n+template<>\n+struct std::hash<Stockfish::Eval::NNUE::EvalFile> {\n+    std::size_t operator()(const Stockfish::Eval::NNUE::EvalFile& evalFile) const noexcept {\n+        std::size_t h = 0;\n+        Stockfish::hash_combine(h, evalFile.defaultName);\n+        Stockfish::hash_combine(h, evalFile.current);\n+        Stockfish::hash_combine(h, evalFile.netDescription);\n+        return h;\n+    }\n+};\n+\n #endif  // #ifndef NNUE_MISC_H_INCLUDED\ndiff --git a/src/numa.h b/src/numa.h\nindex 5cadbc726fc..b1ff0f708ac 100644\n--- a/src/numa.h\n+++ b/src/numa.h\n@@ -37,7 +37,7 @@\n #include <vector>\n #include <cstring>\n \n-#include \"memory.h\"\n+#include \"shm.h\"\n \n // We support linux very well, but we explicitly do NOT support Android,\n // because there is no affected systems, not worth maintaining.\n@@ -945,10 +945,11 @@ class NumaConfig {\n         th.join();\n     }\n \n-   private:\n     std::vector<std::set<CpuIndex>> nodes;\n     std::map<CpuIndex, NumaIndex>   nodeByCpu;\n-    CpuIndex                        highestCpuIndex;\n+\n+   private:\n+    CpuIndex highestCpuIndex;\n \n     bool customAffinity;\n \n@@ -1263,6 +1264,138 @@ class LazyNumaReplicated: public NumaReplicatedBase {\n     }\n };\n \n+// Utilizes shared memory.\n+template<typename T>\n+class LazyNumaReplicatedSystemWide: public NumaReplicatedBase {\n+   public:\n+    using ReplicatorFuncType = std::function<T(const T&)>;\n+\n+    LazyNumaReplicatedSystemWide(NumaReplicationContext& ctx) :\n+        NumaReplicatedBase(ctx) {\n+        prepare_replicate_from(std::make_unique<T>());\n+    }\n+\n+    LazyNumaReplicatedSystemWide(NumaReplicationContext& ctx, std::unique_ptr<T>&& source) :\n+        NumaReplicatedBase(ctx) {\n+        prepare_replicate_from(std::move(source));\n+    }\n+\n+    LazyNumaReplicatedSystemWide(const LazyNumaReplicatedSystemWide&) = delete;\n+    LazyNumaReplicatedSystemWide(LazyNumaReplicatedSystemWide&& other) noexcept :\n+        NumaReplicatedBase(std::move(other)),\n+        instances(std::exchange(other.instances, {})) {}\n+\n+    LazyNumaReplicatedSystemWide& operator=(const LazyNumaReplicatedSystemWide&) = delete;\n+    LazyNumaReplicatedSystemWide& operator=(LazyNumaReplicatedSystemWide&& other) noexcept {\n+        NumaReplicatedBase::operator=(*this, std::move(other));\n+        instances = std::exchange(other.instances, {});\n+\n+        return *this;\n+    }\n+\n+    LazyNumaReplicatedSystemWide& operator=(std::unique_ptr<T>&& source) {\n+        prepare_replicate_from(std::move(source));\n+\n+        return *this;\n+    }\n+\n+    ~LazyNumaReplicatedSystemWide() override = default;\n+\n+    const T& operator[](NumaReplicatedAccessToken token) const {\n+        assert(token.get_numa_index() < instances.size());\n+        ensure_present(token.get_numa_index());\n+        return *(instances[token.get_numa_index()]);\n+    }\n+\n+    const T& operator*() const { return *(instances[0]); }\n+\n+    const T* operator->() const { return &*instances[0]; }\n+\n+    std::vector<std::pair<SystemWideSharedConstantAllocationStatus, std::optional<std::string>>> get_status_and_errors() const {\n+        std::vector<std::pair<SystemWideSharedConstantAllocationStatus, std::optional<std::string>>> status;\n+        status.reserve(instances.size());\n+\n+        for (const auto& instance : instances) {\n+            status.emplace_back(instance.get_status(), instance.get_error_message());\n+        }\n+\n+        return status;\n+    }\n+\n+    template<typename FuncT>\n+    void modify_and_replicate(FuncT&& f) {\n+        auto source = std::make_unique<T>(*instances[0]);\n+        std::forward<FuncT>(f)(*source);\n+        prepare_replicate_from(std::move(source));\n+    }\n+\n+    void on_numa_config_changed() override {\n+        // Use the first one as the source. It doesn't matter which one we use,\n+        // because they all must be identical, but the first one is guaranteed to exist.\n+        auto source = std::make_unique<T>(*instances[0]);\n+        prepare_replicate_from(std::move(source));\n+    }\n+\n+   private:\n+    mutable std::vector<SystemWideSharedConstant<T>> instances;\n+    mutable std::mutex                               mutex;\n+\n+    std::size_t get_discriminator(NumaIndex idx) const {\n+        const NumaConfig& cfg     = get_numa_config();\n+        const NumaConfig& cfg_sys = NumaConfig::from_system(false);\n+        // as a descriminator, locate the hardware/system numadomain this cpuindex belongs to\n+        CpuIndex    cpu     = *cfg.nodes[idx].begin();  // get a CpuIndex from NumaIndex\n+        NumaIndex   sys_idx = cfg_sys.is_cpu_assigned(cpu) ? cfg_sys.nodeByCpu.at(cpu) : 0;\n+        std::string s       = cfg_sys.to_string() + \"$\" + std::to_string(sys_idx);\n+        return std::hash<std::string>{}(s);\n+    }\n+\n+    void ensure_present(NumaIndex idx) const {\n+        assert(idx < instances.size());\n+\n+        if (instances[idx] != nullptr)\n+            return;\n+\n+        assert(idx != 0);\n+\n+        std::unique_lock<std::mutex> lock(mutex);\n+        // Check again for races.\n+        if (instances[idx] != nullptr)\n+            return;\n+\n+        const NumaConfig& cfg = get_numa_config();\n+        cfg.execute_on_numa_node(idx, [this, idx]() {\n+            instances[idx] = SystemWideSharedConstant<T>(*instances[0], get_discriminator(idx));\n+        });\n+    }\n+\n+    void prepare_replicate_from(std::unique_ptr<T>&& source) {\n+        instances.clear();\n+\n+        const NumaConfig& cfg = get_numa_config();\n+        // We just need to make sure the first instance is there.\n+        // Note that we cannot move here as we need to reallocate the data\n+        // on the correct NUMA node.\n+        // Even in the case of a single NUMA node we have to copy since it's shared memory.\n+        if (cfg.requires_memory_replication())\n+        {\n+            assert(cfg.num_numa_nodes() > 0);\n+\n+            cfg.execute_on_numa_node(0, [this, &source]() {\n+                instances.emplace_back(SystemWideSharedConstant<T>(*source, get_discriminator(0)));\n+            });\n+\n+            // Prepare others for lazy init.\n+            instances.resize(cfg.num_numa_nodes());\n+        }\n+        else\n+        {\n+            assert(cfg.num_numa_nodes() == 1);\n+            instances.emplace_back(SystemWideSharedConstant<T>(*source, get_discriminator(0)));\n+        }\n+    }\n+};\n+\n class NumaReplicationContext {\n    public:\n     NumaReplicationContext(NumaConfig&& cfg) :\ndiff --git a/src/search.h b/src/search.h\nindex 07fc743173f..74c70919543 100644\n--- a/src/search.h\n+++ b/src/search.h\n@@ -134,19 +134,19 @@ struct LimitsType {\n // The UCI stores the uci options, thread pool, and transposition table.\n // This struct is used to easily forward data to the Search::Worker class.\n struct SharedState {\n-    SharedState(const OptionsMap&                               optionsMap,\n-                ThreadPool&                                     threadPool,\n-                TranspositionTable&                             transpositionTable,\n-                const LazyNumaReplicated<Eval::NNUE::Networks>& nets) :\n+    SharedState(const OptionsMap&                                         optionsMap,\n+                ThreadPool&                                               threadPool,\n+                TranspositionTable&                                       transpositionTable,\n+                const LazyNumaReplicatedSystemWide<Eval::NNUE::Networks>& nets) :\n         options(optionsMap),\n         threads(threadPool),\n         tt(transpositionTable),\n         networks(nets) {}\n \n-    const OptionsMap&                               options;\n-    ThreadPool&                                     threads;\n-    TranspositionTable&                             tt;\n-    const LazyNumaReplicated<Eval::NNUE::Networks>& networks;\n+    const OptionsMap&                                         options;\n+    ThreadPool&                                               threads;\n+    TranspositionTable&                                       tt;\n+    const LazyNumaReplicatedSystemWide<Eval::NNUE::Networks>& networks;\n };\n \n class Worker;\n@@ -350,10 +350,10 @@ class Worker {\n \n     Tablebases::Config tbConfig;\n \n-    const OptionsMap&                               options;\n-    ThreadPool&                                     threads;\n-    TranspositionTable&                             tt;\n-    const LazyNumaReplicated<Eval::NNUE::Networks>& networks;\n+    const OptionsMap&                                         options;\n+    ThreadPool&                                               threads;\n+    TranspositionTable&                                       tt;\n+    const LazyNumaReplicatedSystemWide<Eval::NNUE::Networks>& networks;\n \n     // Used by NNUE\n     Eval::NNUE::AccumulatorStack  accumulatorStack;\ndiff --git a/src/shm.h b/src/shm.h\nnew file mode 100644\nindex 00000000000..e3b8c96edab\n--- /dev/null\n+++ b/src/shm.h\n@@ -0,0 +1,646 @@\n+/*\n+  Stockfish, a UCI chess playing engine derived from Glaurung 2.1\n+  Copyright (C) 2004-2025 The Stockfish developers (see AUTHORS file)\n+\n+  Stockfish is free software: you can redistribute it and/or modify\n+  it under the terms of the GNU General Public License as published by\n+  the Free Software Foundation, either version 3 of the License, or\n+  (at your option) any later version.\n+\n+  Stockfish is distributed in the hope that it will be useful,\n+  but WITHOUT ANY WARRANTY; without even the implied warranty of\n+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+  GNU General Public License for more details.\n+\n+  You should have received a copy of the GNU General Public License\n+  along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+*/\n+\n+#ifndef SHM_H_INCLUDED\n+#define SHM_H_INCLUDED\n+\n+#include <algorithm>\n+#include <cstddef>\n+#include <cstdint>\n+#include <cstring>\n+#include <functional>\n+#include <iomanip>\n+#include <iostream>\n+#include <memory>\n+#include <new>\n+#include <optional>\n+#include <sstream>\n+#include <string>\n+#include <type_traits>\n+#include <utility>\n+#include <variant>\n+\n+#if !defined(_WIN32) && !defined(__ANDROID__)\n+    #include \"shm_linux.h\"\n+    #define SHM_CLEANUP\n+#endif\n+\n+#if defined(__ANDROID__)\n+    #include <limits.h>\n+    #define SF_MAX_SEM_NAME_LEN NAME_MAX\n+#endif\n+\n+#include \"types.h\"\n+\n+#include \"memory.h\"\n+\n+#if defined(_WIN32)\n+\n+    #if _WIN32_WINNT < 0x0601\n+        #undef _WIN32_WINNT\n+        #define _WIN32_WINNT 0x0601  // Force to include needed API prototypes\n+    #endif\n+\n+    #if !defined(NOMINMAX)\n+        #define NOMINMAX\n+    #endif\n+    #include <windows.h>\n+#else\n+    #include <cstring>\n+    #include <fcntl.h>\n+    #include <pthread.h>\n+    #include <semaphore.h>\n+    #include <sys/mman.h>\n+    #include <sys/stat.h>\n+    #include <unistd.h>\n+#endif\n+\n+\n+#if defined(__APPLE__)\n+    #include <mach-o/dyld.h>\n+    #include <sys/syslimits.h>\n+\n+#elif defined(__sun)\n+    #include <stdlib.h>\n+\n+#elif defined(__FreeBSD__)\n+    #include <sys/sysctl.h>\n+    #include <sys/types.h>\n+    #include <unistd.h>\n+\n+#elif defined(__NetBSD__) || defined(__DragonFly__) || defined(__linux__)\n+    #include <limits.h>\n+    #include <unistd.h>\n+#endif\n+\n+\n+namespace Stockfish {\n+\n+// argv[0] CANNOT be used because we need to identify the executable.\n+// argv[0] contains the command used to invoke it, which does not involve the full path.\n+// Just using a path is not fully resilient either, as the executable could\n+// have changed if it wasn't locked by the OS. Ideally we would hash the executable\n+// but it's not really that important at this point.\n+\n+inline std::string getExecutablePathHash() {\n+    char executable_path[4096] = {0};\n+    int  path_length           = 0;\n+\n+#if defined(_WIN32)\n+    path_length = GetModuleFileNameA(NULL, executable_path, sizeof(executable_path));\n+\n+#elif defined(__APPLE__)\n+    uint32_t size = sizeof(executable_path);\n+    if (_NSGetExecutablePath(executable_path, &size) == 0)\n+    {\n+        path_length = static_cast<int>(std::strlen(executable_path));\n+    }\n+\n+#elif defined(__sun)  // Solaris\n+    const char* path = getexecname();\n+    if (path)\n+    {\n+        std::strncpy(executable_path, path, sizeof(executable_path) - 1);\n+        path_length = static_cast<int>(std::strlen(executable_path));\n+    }\n+\n+#elif defined(__FreeBSD__)\n+    size_t size   = sizeof(executable_path);\n+    int    mib[4] = {CTL_KERN, KERN_PROC, KERN_PROC_PATHNAME, -1};\n+    if (sysctl(mib, 4, executable_path, &size, NULL, 0) == 0)\n+    {\n+        path_length = static_cast<int>(std::strlen(executable_path));\n+    }\n+\n+#elif defined(__NetBSD__) || defined(__DragonFly__)\n+    ssize_t len = readlink(\"/proc/curproc/exe\", executable_path, sizeof(executable_path) - 1);\n+    if (len != -1)\n+    {\n+        executable_path[len] = '\\0';\n+        path_length          = static_cast<int>(len);\n+    }\n+\n+#elif defined(__linux__)\n+    ssize_t len = readlink(\"/proc/self/exe\", executable_path, sizeof(executable_path) - 1);\n+    if (len != -1)\n+    {\n+        executable_path[len] = '\\0';\n+        path_length          = static_cast<int>(len);\n+    }\n+\n+#endif\n+\n+    if (path_length <= 0)\n+    {\n+        return \"\";  // fallback\n+    }\n+\n+    return std::string(executable_path, path_length);\n+}\n+\n+enum class SystemWideSharedConstantAllocationStatus {\n+    NoAllocation,\n+    LocalMemory,\n+    SharedMemory\n+};\n+\n+#if defined(_WIN32)\n+\n+inline std::string GetLastErrorAsString(DWORD error) {\n+    //Get the error message ID, if any.\n+    DWORD errorMessageID = error;\n+    if (errorMessageID == 0)\n+    {\n+        return std::string();  //No error message has been recorded\n+    }\n+\n+    LPSTR messageBuffer = nullptr;\n+\n+    //Ask Win32 to give us the string version of that message ID.\n+    //The parameters we pass in, tell Win32 to create the buffer that holds the message for us (because we don't yet know how long the message string will be).\n+    size_t size = FormatMessageA(FORMAT_MESSAGE_ALLOCATE_BUFFER | FORMAT_MESSAGE_FROM_SYSTEM\n+                                   | FORMAT_MESSAGE_IGNORE_INSERTS,\n+                                 NULL, errorMessageID, MAKELANGID(LANG_NEUTRAL, SUBLANG_DEFAULT),\n+                                 (LPSTR) &messageBuffer, 0, NULL);\n+\n+    //Copy the error message into a std::string.\n+    std::string message(messageBuffer, size);\n+\n+    //Free the Win32's string's buffer.\n+    LocalFree(messageBuffer);\n+\n+    return message;\n+}\n+\n+// Utilizes shared memory to store the value. It is deduplicated system-wide (for the single user).\n+template<typename T>\n+class SharedMemoryBackend {\n+   public:\n+    enum class Status {\n+        Success,\n+        LargePageAllocationError,\n+        FileMappingError,\n+        MapViewError,\n+        MutexCreateError,\n+        MutexWaitError,\n+        MutexReleaseError,\n+        NotInitialized\n+    };\n+\n+    static constexpr DWORD IS_INITIALIZED_VALUE = 1;\n+\n+    SharedMemoryBackend() :\n+        status(Status::NotInitialized) {}\n+\n+    SharedMemoryBackend(const std::string& shm_name, const T& value) :\n+        status(Status::NotInitialized) {\n+\n+        initialize(shm_name, value);\n+    }\n+\n+    bool is_valid() const { return status == Status::Success; }\n+\n+    std::optional<std::string> get_error_message() const {\n+        switch (status)\n+        {\n+        case Status::Success :\n+            return std::nullopt;\n+        case Status::LargePageAllocationError :\n+            return \"Failed to allocate large page memory\";\n+        case Status::FileMappingError :\n+            return \"Failed to create file mapping: \" + last_error_message;\n+        case Status::MapViewError :\n+            return \"Failed to map view: \" + last_error_message;\n+        case Status::MutexCreateError :\n+            return \"Failed to create mutex: \" + last_error_message;\n+        case Status::MutexWaitError :\n+            return \"Failed to wait on mutex: \" + last_error_message;\n+        case Status::MutexReleaseError :\n+            return \"Failed to release mutex: \" + last_error_message;\n+        case Status::NotInitialized :\n+            return \"Not initialized\";\n+        default :\n+            return \"Unknown error\";\n+        }\n+    }\n+\n+    void* get() const { return is_valid() ? pMap : nullptr; }\n+\n+    ~SharedMemoryBackend() { cleanup(); }\n+\n+    SharedMemoryBackend(const SharedMemoryBackend&)            = delete;\n+    SharedMemoryBackend& operator=(const SharedMemoryBackend&) = delete;\n+\n+    SharedMemoryBackend(SharedMemoryBackend&& other) noexcept :\n+        pMap(other.pMap),\n+        hMapFile(other.hMapFile),\n+        status(other.status),\n+        last_error_message(std::move(other.last_error_message)) {\n+\n+        other.pMap     = nullptr;\n+        other.hMapFile = 0;\n+        other.status   = Status::NotInitialized;\n+    }\n+\n+    SharedMemoryBackend& operator=(SharedMemoryBackend&& other) noexcept {\n+        if (this != &other)\n+        {\n+            cleanup();\n+            pMap               = other.pMap;\n+            hMapFile           = other.hMapFile;\n+            status             = other.status;\n+            last_error_message = std::move(other.last_error_message);\n+\n+            other.pMap     = nullptr;\n+            other.hMapFile = 0;\n+            other.status   = Status::NotInitialized;\n+        }\n+        return *this;\n+    }\n+    \n+    SystemWideSharedConstantAllocationStatus get_status() const {\n+        return \n+            status == Status::Success \n+            ? SystemWideSharedConstantAllocationStatus::SharedMemory \n+            : SystemWideSharedConstantAllocationStatus::NoAllocation;\n+    }\n+\n+   private:\n+    void initialize(const std::string& shm_name, const T& value) {\n+        const size_t total_size = sizeof(T) + sizeof(IS_INITIALIZED_VALUE);\n+\n+        // Try allocating with large pages first.\n+        hMapFile = windows_try_with_large_page_priviliges(\n+            [&](size_t largePageSize) {\n+                const size_t total_size_aligned =\n+                  (total_size + largePageSize - 1) / largePageSize * largePageSize;\n+                \n+#if defined(_WIN64)\n+                DWORD total_size_low = total_size_aligned & 0xFFFFFFFFu;\n+                DWORD total_size_high = total_size_aligned >> 32u;\n+#else\n+                DWORD total_size_low = total_size_aligned;\n+                DWORD total_size_high = 0;\n+#endif\n+\n+                return CreateFileMappingA(\n+                    INVALID_HANDLE_VALUE, NULL, PAGE_READWRITE | SEC_COMMIT | SEC_LARGE_PAGES,\n+                    total_size_high,\n+                    total_size_low, \n+                    shm_name.c_str()\n+                );\n+            },\n+            []() { return (void*) nullptr; });\n+\n+        // Fallback to normal allocation if no large pages available.\n+        if (!hMapFile)\n+        {\n+            hMapFile = CreateFileMappingA(INVALID_HANDLE_VALUE, NULL, PAGE_READWRITE, 0,\n+                                          static_cast<DWORD>(total_size), shm_name.c_str());\n+        }\n+\n+        if (!hMapFile)\n+        {\n+            const DWORD err    = GetLastError();\n+            last_error_message = GetLastErrorAsString(err);\n+            status             = Status::FileMappingError;\n+            return;\n+        }\n+\n+        pMap = MapViewOfFile(hMapFile, FILE_MAP_ALL_ACCESS, 0, 0, total_size);\n+        if (!pMap)\n+        {\n+            const DWORD err    = GetLastError();\n+            last_error_message = GetLastErrorAsString(err);\n+            status             = Status::MapViewError;\n+            cleanup_partial();\n+            return;\n+        }\n+\n+        // Use named mutex to ensure only one initializer\n+        std::string mutex_name = shm_name + \"$mutex\";\n+        HANDLE      hMutex     = CreateMutexA(NULL, FALSE, mutex_name.c_str());\n+        if (!hMutex)\n+        {\n+            const DWORD err    = GetLastError();\n+            last_error_message = GetLastErrorAsString(err);\n+            status             = Status::MutexCreateError;\n+            cleanup_partial();\n+            return;\n+        }\n+\n+        DWORD wait_result = WaitForSingleObject(hMutex, INFINITE);\n+        if (wait_result != WAIT_OBJECT_0)\n+        {\n+            const DWORD err    = GetLastError();\n+            last_error_message = GetLastErrorAsString(err);\n+            status             = Status::MutexWaitError;\n+            CloseHandle(hMutex);\n+            cleanup_partial();\n+            return;\n+        }\n+\n+        // Crucially, we place the object first to ensure alignment.\n+        volatile DWORD* is_initialized =\n+          std::launder(reinterpret_cast<DWORD*>(reinterpret_cast<char*>(pMap) + sizeof(T)));\n+        T* object = std::launder(reinterpret_cast<T*>(pMap));\n+\n+        if (*is_initialized != IS_INITIALIZED_VALUE)\n+        {\n+            // First time initialization, message for debug purposes\n+            new (object) T{value};\n+            *is_initialized = IS_INITIALIZED_VALUE;\n+        }\n+\n+        BOOL release_result = ReleaseMutex(hMutex);\n+        CloseHandle(hMutex);\n+\n+        if (!release_result)\n+        {\n+            const DWORD err    = GetLastError();\n+            last_error_message = GetLastErrorAsString(err);\n+            status             = Status::MutexReleaseError;\n+            cleanup_partial();\n+            return;\n+        }\n+\n+        status = Status::Success;\n+    }\n+\n+    void cleanup_partial() {\n+        if (pMap != nullptr)\n+        {\n+            UnmapViewOfFile(pMap);\n+            pMap = nullptr;\n+        }\n+        if (hMapFile)\n+        {\n+            CloseHandle(hMapFile);\n+            hMapFile = 0;\n+        }\n+    }\n+\n+    void cleanup() {\n+        if (pMap != nullptr)\n+        {\n+            UnmapViewOfFile(pMap);\n+            pMap = nullptr;\n+        }\n+        if (hMapFile)\n+        {\n+            CloseHandle(hMapFile);\n+            hMapFile = 0;\n+        }\n+    }\n+\n+    void*       pMap     = nullptr;\n+    HANDLE      hMapFile = 0;\n+    Status      status   = Status::NotInitialized;\n+    std::string last_error_message;\n+};\n+\n+#elif !defined(__ANDROID__)\n+\n+template<typename T>\n+class SharedMemoryBackend {\n+   public:\n+    SharedMemoryBackend() {}\n+\n+    SharedMemoryBackend(const std::string& shm_name, const T& value) :\n+        shm1(shm::create_shared<T>(shm_name, value)) {}\n+\n+    void* get() const {\n+        const T* ptr = &shm1->get();\n+        return reinterpret_cast<void*>(const_cast<T*>(ptr));\n+    }\n+\n+    bool is_valid() const { return shm1 && shm1->is_open() && shm1->is_initialized(); }\n+    \n+    SystemWideSharedConstantAllocationStatus get_status() const {\n+        return \n+            is_valid() \n+            ? SystemWideSharedConstantAllocationStatus::SharedMemory \n+            : SystemWideSharedConstantAllocationStatus::NoAllocation;\n+    }\n+\n+    std::optional<std::string> get_error_message() const {\n+        if (!shm1)\n+            return \"Shared memory not initialized\";\n+\n+        if (!shm1->is_open())\n+            return \"Shared memory is not open\";\n+\n+        if (!shm1->is_initialized())\n+            return \"Not initialized\";\n+\n+        return std::nullopt;\n+    }\n+\n+   private:\n+    std::optional<shm::SharedMemory<T>> shm1;\n+};\n+\n+#else\n+\n+// For systems that don't have shared memory, or support is troublesome.\n+// The way fallback is done is that we need a dummy backend.\n+\n+template<typename T>\n+class SharedMemoryBackend {\n+   public:\n+    SharedMemoryBackend() {}\n+\n+    SharedMemoryBackend(const std::string& shm_name, const T& value) {}\n+\n+    void* get() const {\n+        return nullptr;\n+    }\n+\n+    bool is_valid() const { return false; }\n+    \n+    SystemWideSharedConstantAllocationStatus get_status() const {\n+        return SystemWideSharedConstantAllocationStatus::NoAllocation;\n+    }\n+\n+    std::optional<std::string> get_error_message() const {\n+        return \"Dummy SharedMemoryBackend\";\n+    }\n+};\n+\n+#endif\n+\n+template<typename T>\n+struct SharedMemoryBackendFallback {\n+    SharedMemoryBackendFallback() = default;\n+\n+    SharedMemoryBackendFallback(const std::string&, const T& value) :\n+        fallback_object(make_unique_large_page<T>(value)) {}\n+\n+    void* get() const { return fallback_object.get(); }\n+\n+    SharedMemoryBackendFallback(const SharedMemoryBackendFallback&)            = delete;\n+    SharedMemoryBackendFallback& operator=(const SharedMemoryBackendFallback&) = delete;\n+\n+    SharedMemoryBackendFallback(SharedMemoryBackendFallback&& other) noexcept :\n+        fallback_object(std::move(other.fallback_object)) {}\n+\n+    SharedMemoryBackendFallback& operator=(SharedMemoryBackendFallback&& other) noexcept {\n+        fallback_object = std::move(other.fallback_object);\n+        return *this;\n+    }\n+    \n+    SystemWideSharedConstantAllocationStatus get_status() const {\n+        return \n+            fallback_object == nullptr \n+            ? SystemWideSharedConstantAllocationStatus::NoAllocation \n+            : SystemWideSharedConstantAllocationStatus::LocalMemory;\n+    }\n+\n+    std::optional<std::string> get_error_message() const {\n+        if (fallback_object == nullptr)\n+            return \"Not initialized\";\n+\n+        return \"Shared memory not supported by the OS. Local allocation fallback.\";\n+    }\n+\n+   private:\n+    LargePagePtr<T> fallback_object;\n+};\n+\n+// Platform-independent wrapper\n+template<typename T>\n+struct SystemWideSharedConstant {\n+   private:\n+    static std::string createHashString(const std::string& input) {\n+        size_t hash = std::hash<std::string>{}(input);\n+\n+        std::stringstream ss;\n+        ss << std::hex << std::setfill('0') << hash;\n+\n+        return ss.str();\n+    }\n+\n+   public:\n+    // We can't run the destructor because it may be in a completely different process.\n+    // The object stored must also be obviously in-line but we can't check for that, other than some basic checks that cover most cases.\n+    static_assert(std::is_trivially_destructible_v<T>);\n+    static_assert(std::is_trivially_move_constructible_v<T>);\n+    static_assert(std::is_trivially_copy_constructible_v<T>);\n+\n+    SystemWideSharedConstant() = default;\n+\n+\n+    // Content is addressed by its hash. An additional discriminator can be added to account for differences\n+    // that are not present in the content, for example NUMA node allocation.\n+    SystemWideSharedConstant(const T& value, std::size_t discriminator = 0) {\n+        std::size_t content_hash    = std::hash<T>{}(value);\n+        std::size_t executable_hash = std::hash<std::string>{}(getExecutablePathHash());\n+\n+        std::string shm_name = std::string(\"Local\\\\\") + std::to_string(content_hash) + \"$\"\n+                             + std::to_string(executable_hash) + \"$\"\n+                             + std::to_string(discriminator);\n+\n+#if !defined(_WIN32)\n+        // POSIX shared memory names must start with a slash\n+        shm_name = \"/\" + createHashString(shm_name);\n+\n+        // hash name and make sure it is not longer than SF_MAX_SEM_NAME_LEN\n+        if (shm_name.size() > SF_MAX_SEM_NAME_LEN) {\n+            shm_name = shm_name.substr(0, SF_MAX_SEM_NAME_LEN - 1);\n+        }\n+#endif\n+\n+        SharedMemoryBackend<T> shm_backend(shm_name, value);\n+\n+        if (shm_backend.is_valid()) {\n+            backend = std::move(shm_backend);\n+        } else {\n+            backend = SharedMemoryBackendFallback<T>(shm_name, value);\n+        }\n+    }\n+\n+    SystemWideSharedConstant(const SystemWideSharedConstant&)            = delete;\n+    SystemWideSharedConstant& operator=(const SystemWideSharedConstant&) = delete;\n+\n+    SystemWideSharedConstant(SystemWideSharedConstant&& other) noexcept :\n+        backend(std::move(other.backend)) {}\n+\n+    SystemWideSharedConstant& operator=(SystemWideSharedConstant&& other) noexcept {\n+        backend = std::move(other.backend);\n+        return *this;\n+    }\n+\n+    const T& operator*() const { return *std::launder(reinterpret_cast<const T*>(get_ptr())); }\n+\n+    bool operator==(std::nullptr_t) const noexcept { return get_ptr() == nullptr; }\n+\n+    bool operator!=(std::nullptr_t) const noexcept { return get_ptr() != nullptr; }\n+\n+    SystemWideSharedConstantAllocationStatus get_status() const {\n+        return std::visit(\n+          [](const auto& end) -> SystemWideSharedConstantAllocationStatus {\n+              if constexpr (std::is_same_v<std::decay_t<decltype(end)>, std::monostate>)\n+              {\n+                  return SystemWideSharedConstantAllocationStatus::NoAllocation;\n+              }\n+              else\n+              {\n+                  return end.get_status();\n+              }\n+          },\n+          backend);\n+    }\n+\n+    std::optional<std::string> get_error_message() const {\n+        return std::visit(\n+          [](const auto& end) -> std::optional<std::string> {\n+              if constexpr (std::is_same_v<std::decay_t<decltype(end)>, std::monostate>)\n+              {\n+                  return std::nullopt;\n+              }\n+              else\n+              {\n+                  return end.get_error_message();\n+              }\n+          },\n+          backend);\n+    }\n+\n+   private:\n+    auto get_ptr() const {\n+        return std::visit(\n+          [](const auto& end) -> void* {\n+              if constexpr (std::is_same_v<std::decay_t<decltype(end)>, std::monostate>)\n+              {\n+                  return nullptr;\n+              }\n+              else\n+              {\n+                  return end.get();\n+              }\n+          },\n+          backend);\n+    }\n+\n+    std::variant<std::monostate, SharedMemoryBackend<T>, SharedMemoryBackendFallback<T>> backend;\n+};\n+\n+\n+}  // namespace Stockfish\n+\n+#endif  // #ifndef SHM_H_INCLUDED\ndiff --git a/src/shm_linux.h b/src/shm_linux.h\nnew file mode 100644\nindex 00000000000..6d4ea9a7553\n--- /dev/null\n+++ b/src/shm_linux.h\n@@ -0,0 +1,417 @@\n+/*\n+  Stockfish, a UCI chess playing engine derived from Glaurung 2.1\n+  Copyright (C) 2004-2025 The Stockfish developers (see AUTHORS file)\n+\n+  Stockfish is free software: you can redistribute it and/or modify\n+  it under the terms of the GNU General Public License as published by\n+  the Free Software Foundation, either version 3 of the License, or\n+  (at your option) any later version.\n+\n+  Stockfish is distributed in the hope that it will be useful,\n+  but WITHOUT ANY WARRANTY; without even the implied warranty of\n+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+  GNU General Public License for more details.\n+\n+  You should have received a copy of the GNU General Public License\n+  along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+*/\n+\n+#ifndef SHM_LINUX_H_INCLUDED\n+#define SHM_LINUX_H_INCLUDED\n+\n+#include <atomic>\n+#include <cassert>\n+#include <cstdlib>\n+#include <cstring>\n+#include <mutex>\n+#include <new>\n+#include <optional>\n+#include <string>\n+#include <thread>\n+#include <type_traits>\n+#include <unordered_set>\n+\n+#include <fcntl.h>\n+#include <semaphore.h>\n+#include <signal.h>\n+#include <sys/mman.h>\n+#include <sys/stat.h>\n+#include <unistd.h>\n+\n+#if defined(__NetBSD__) || defined(__DragonFly__) || defined(__linux__)\n+    #include <limits.h>\n+    #define SF_MAX_SEM_NAME_LEN NAME_MAX\n+#elif defined(__APPLE__)\n+    #define SF_MAX_SEM_NAME_LEN 31\n+#else\n+    #define SF_MAX_SEM_NAME_LEN 255\n+#endif\n+\n+\n+namespace Stockfish {\n+\n+namespace shm {\n+\n+namespace detail {\n+// Header placed after the data\n+struct ShmHeader {\n+    static constexpr uint32_t SHM_MAGIC = 0xDEADBEEF;\n+\n+    std::atomic<uint32_t> ref_count{0};\n+    std::atomic<bool>     initialized{false};\n+    uint32_t              magic = SHM_MAGIC;\n+};\n+\n+class SharedMemoryBase {\n+   public:\n+    virtual ~SharedMemoryBase()                      = default;\n+    virtual void               close() noexcept      = 0;\n+    virtual const std::string& name() const noexcept = 0;\n+};\n+\n+// Static registry for cleanup\n+class SharedMemoryRegistry {\n+   private:\n+    static std::mutex                            registry_mutex_;\n+    static std::unordered_set<SharedMemoryBase*> active_instances_;\n+\n+   public:\n+    static void register_instance(SharedMemoryBase* instance) {\n+        std::lock_guard<std::mutex> lock(registry_mutex_);\n+        active_instances_.insert(instance);\n+    }\n+\n+    static void unregister_instance(SharedMemoryBase* instance) {\n+        std::lock_guard<std::mutex> lock(registry_mutex_);\n+        active_instances_.erase(instance);\n+    }\n+\n+    static void cleanup_all() noexcept {\n+        std::lock_guard<std::mutex> lock(registry_mutex_);\n+        for (auto* instance : active_instances_)\n+            instance->close();\n+\n+        active_instances_.clear();\n+    }\n+};\n+\n+inline int portable_fallocate(int fd, off_t offset, off_t length) {\n+#ifdef __APPLE__\n+    fstore_t store = {F_ALLOCATECONTIG, F_PEOFPOSMODE, offset, length, 0};\n+    int      ret   = fcntl(fd, F_PREALLOCATE, &store);\n+    if (ret == -1)\n+    {\n+        store.fst_flags = F_ALLOCATEALL;\n+        ret             = fcntl(fd, F_PREALLOCATE, &store);\n+    }\n+    if (ret != -1)\n+    {\n+        ret = ftruncate(fd, offset + length);\n+    }\n+    return ret;\n+#else\n+    return posix_fallocate(fd, offset, length);\n+#endif\n+}\n+\n+inline std::mutex                            SharedMemoryRegistry::registry_mutex_;\n+inline std::unordered_set<SharedMemoryBase*> SharedMemoryRegistry::active_instances_;\n+\n+}  // namespace detail\n+\n+template<typename T>\n+class SharedMemory: public detail::SharedMemoryBase {\n+    static_assert(std::is_trivially_copyable_v<T>, \"T must be trivially copyable\");\n+    static_assert(!std::is_pointer_v<T>, \"T cannot be a pointer type\");\n+\n+   private:\n+    std::string        name_;\n+    int                fd_         = -1;\n+    void*              mapped_ptr_ = nullptr;\n+    T*                 data_ptr_   = nullptr;\n+    detail::ShmHeader* header_ptr_ = nullptr;\n+    sem_t*             sem_        = nullptr;\n+    size_t             total_size_ = 0;\n+\n+    static constexpr size_t calculate_total_size() noexcept {\n+        return sizeof(T) + sizeof(detail::ShmHeader);\n+    }\n+\n+    std::string get_semaphore_name() const {\n+        auto name = \"/\" + name_ + \"_mutex\";\n+        assert(name.size() < SF_MAX_SEM_NAME_LEN - 4 && \"Semaphore name too long\");\n+        return name;\n+    }\n+\n+   public:\n+    explicit SharedMemory(const std::string& name) noexcept :\n+        name_(name),\n+        total_size_(calculate_total_size()) {}\n+\n+    ~SharedMemory() noexcept {\n+        detail::SharedMemoryRegistry::unregister_instance(this);\n+        close();\n+    }\n+\n+    // Non-copyable but movable\n+    SharedMemory(const SharedMemory&)            = delete;\n+    SharedMemory& operator=(const SharedMemory&) = delete;\n+\n+    SharedMemory(SharedMemory&& other) noexcept :\n+        name_(std::move(other.name_)),\n+        fd_(other.fd_),\n+        mapped_ptr_(other.mapped_ptr_),\n+        data_ptr_(other.data_ptr_),\n+        header_ptr_(other.header_ptr_),\n+        sem_(other.sem_),\n+        total_size_(other.total_size_) {\n+\n+        // Update registry\n+        detail::SharedMemoryRegistry::unregister_instance(&other);\n+        detail::SharedMemoryRegistry::register_instance(this);\n+\n+        other.reset();\n+    }\n+\n+    SharedMemory& operator=(SharedMemory&& other) noexcept {\n+        if (this != &other)\n+        {\n+            detail::SharedMemoryRegistry::unregister_instance(this);\n+            close();\n+\n+            name_       = std::move(other.name_);\n+            fd_         = other.fd_;\n+            mapped_ptr_ = other.mapped_ptr_;\n+            data_ptr_   = other.data_ptr_;\n+            header_ptr_ = other.header_ptr_;\n+            sem_        = other.sem_;\n+            total_size_ = other.total_size_;\n+\n+            detail::SharedMemoryRegistry::unregister_instance(&other);\n+            detail::SharedMemoryRegistry::register_instance(this);\n+\n+            other.reset();\n+        }\n+        return *this;\n+    }\n+\n+    // Create or open shared memory region\n+    [[nodiscard]] bool open(const T& initial_value) noexcept {\n+        if (is_open())\n+            return false;\n+\n+        std::string sem_name = get_semaphore_name();\n+        sem_                 = sem_open(sem_name.c_str(), O_CREAT, 0666, 1);\n+\n+        if (sem_ == SEM_FAILED)\n+        {\n+            sem_ = nullptr;\n+            return false;\n+        }\n+\n+        // Try to create new shared memory\n+        fd_ = shm_open(name_.c_str(), O_CREAT | O_EXCL | O_RDWR, 0666);\n+        if (fd_ != -1)\n+        {\n+            if (!setup_new_region(initial_value))\n+            {\n+                close();\n+                shm_unlink(name_.c_str());\n+                return false;\n+            }\n+            detail::SharedMemoryRegistry::register_instance(this);\n+            return true;\n+        }\n+\n+        // If creation failed, try to open existing\n+        fd_ = shm_open(name_.c_str(), O_RDWR, 0666);\n+        if (fd_ == -1)\n+        {\n+            cleanup_semaphore();\n+            return false;\n+        }\n+\n+        bool success = setup_existing_region();\n+        if (success)\n+        {\n+            detail::SharedMemoryRegistry::register_instance(this);\n+        }\n+        else\n+        {\n+            cleanup_semaphore();\n+        }\n+        return success;\n+    }\n+\n+    void close() noexcept override {\n+        if (mapped_ptr_ != nullptr)\n+        {\n+            if (header_ptr_ != nullptr)\n+            {\n+                auto old_count = header_ptr_->ref_count.fetch_sub(1, std::memory_order_acq_rel);\n+\n+                // remove shm\n+                if (old_count == 1)\n+                {\n+                    shm_unlink(name_.c_str());\n+                    sem_unlink(get_semaphore_name().c_str());\n+                }\n+            }\n+\n+            munmap(mapped_ptr_, total_size_);\n+\n+            mapped_ptr_ = nullptr;\n+            data_ptr_   = nullptr;\n+            header_ptr_ = nullptr;\n+        }\n+\n+        if (fd_ != -1)\n+        {\n+            ::close(fd_);\n+        }\n+\n+        cleanup_semaphore();\n+        reset();\n+    }\n+\n+    const std::string& name() const noexcept override { return name_; }\n+\n+    [[nodiscard]] bool is_open() const noexcept {\n+        return fd_ != -1 && mapped_ptr_ != nullptr && data_ptr_ != nullptr;\n+    }\n+\n+    [[nodiscard]] const T& get() const noexcept { return *data_ptr_; }\n+\n+    [[nodiscard]] const T* operator->() const noexcept { return data_ptr_; }\n+\n+    [[nodiscard]] const T& operator*() const noexcept { return *data_ptr_; }\n+\n+    [[nodiscard]] uint32_t ref_count() const noexcept {\n+        return header_ptr_ ? header_ptr_->ref_count.load(std::memory_order_acquire) : 0;\n+    }\n+\n+    [[nodiscard]] bool is_initialized() const noexcept {\n+        return header_ptr_ ? header_ptr_->initialized.load(std::memory_order_acquire) : false;\n+    }\n+\n+    // Static cleanup method for atexit\n+    static void cleanup_all_instances() noexcept { detail::SharedMemoryRegistry::cleanup_all(); }\n+\n+   private:\n+    void reset() noexcept {\n+        fd_         = -1;\n+        mapped_ptr_ = nullptr;\n+        data_ptr_   = nullptr;\n+        header_ptr_ = nullptr;\n+        sem_        = nullptr;\n+    }\n+\n+    void cleanup_semaphore() noexcept {\n+        if (sem_ && sem_ != SEM_FAILED)\n+        {\n+            sem_close(sem_);\n+            sem_ = nullptr;\n+        }\n+    }\n+\n+    [[nodiscard]] bool setup_new_region(const T& initial_value) noexcept {\n+        // Wait on semaphore to ensure exclusive access during initialization\n+        if (sem_wait(sem_) == -1)\n+        {\n+            return false;\n+        }\n+\n+        // Set the size of the shared memory region\n+        if (ftruncate(fd_, static_cast<off_t>(total_size_)) == -1)\n+        {\n+            sem_post(sem_);\n+            return false;\n+        }\n+\n+        int r = detail::portable_fallocate(fd_, 0, static_cast<off_t>(total_size_));\n+        if (r != 0)\n+        {\n+            sem_post(sem_);\n+            return false;\n+        }\n+\n+        // Map the memory\n+        auto flags  = PROT_READ | PROT_WRITE;\n+        mapped_ptr_ = mmap(nullptr, total_size_, flags, MAP_SHARED, fd_, 0);\n+\n+        if (mapped_ptr_ == MAP_FAILED)\n+        {\n+            mapped_ptr_ = nullptr;\n+            sem_post(sem_);\n+            return false;\n+        }\n+\n+        // Set up pointers - data first, header immediately after\n+        data_ptr_ = static_cast<T*>(mapped_ptr_);\n+        header_ptr_ =\n+          reinterpret_cast<detail::ShmHeader*>(static_cast<char*>(mapped_ptr_) + sizeof(T));\n+\n+        new (header_ptr_) detail::ShmHeader{};\n+        new (data_ptr_) T{initial_value};\n+\n+        // Initialize header\n+        header_ptr_->ref_count.store(1, std::memory_order_release);\n+        header_ptr_->initialized.store(true, std::memory_order_release);\n+\n+        if (sem_post(sem_) == -1)\n+            return false;\n+\n+        return true;\n+    }\n+\n+    [[nodiscard]] bool setup_existing_region() noexcept {\n+        // Wait on semaphore to ensure proper initialization\n+        if (sem_wait(sem_) == -1)\n+            return false;\n+\n+        // Map the memory\n+        auto flags  = PROT_READ | PROT_WRITE;\n+        mapped_ptr_ = mmap(nullptr, total_size_, flags, MAP_SHARED, fd_, 0);\n+\n+        if (mapped_ptr_ == MAP_FAILED)\n+        {\n+            mapped_ptr_ = nullptr;\n+            sem_post(sem_);\n+            return false;\n+        }\n+\n+        data_ptr_   = static_cast<T*>(mapped_ptr_);\n+        header_ptr_ = std::launder(\n+          reinterpret_cast<detail::ShmHeader*>(static_cast<char*>(mapped_ptr_) + sizeof(T)));\n+\n+        assert(header_ptr_->initialized.load(std::memory_order_acquire));\n+\n+        if (header_ptr_->magic != detail::ShmHeader::SHM_MAGIC)\n+        {\n+            sem_post(sem_);\n+            return false;\n+        }\n+\n+        header_ptr_->ref_count.fetch_add(1, std::memory_order_acq_rel);\n+\n+        if (sem_post(sem_) == -1)\n+            return false;\n+\n+        return true;\n+    }\n+};\n+\n+// Convenience function to create shared memory\n+template<typename T>\n+[[nodiscard]] std::optional<SharedMemory<T>> create_shared(const std::string& name,\n+                                                           const T& initial_value) noexcept {\n+    SharedMemory<T> shm(name);\n+    if (shm.open(initial_value))\n+        return shm;  // copy elision is guaranteed here\n+    return std::nullopt;\n+}\n+\n+}  // namespace shm\n+}  // namespace Stockfish\n+\n+#endif  // #ifndef SHM_LINUX_H_INCLUDED\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Single Core Regression**: Test if the regression issue is fixed by running extended speedup commands. Large pages may still be a factor.\n\n2. **SHM File Adapter**: Implement an OS-specific adapter for `shm_open`. On macOS, consider a hash for names exceeding `NAME_MAX`.\n\n3. **Instance Spawning Fix**: Confirm the fix for rapid instance spawning issues with proper content hashing.\n\n4. **NUMA Testing**: Plan for NUMA testing and explore multiple SHM files mapped to different processes in NUMA domains.\n\n5. **Huge Pages on Linux**: Investigate filesystem quirks with huge pages for SHM. Ensure that admin privileges are still not necessary for large pages on Windows.\n\n6. **File Descriptor Sharing**: Assess the use of `memfd_create()` for shared memory across processes and the method of transferring descriptors. \n\n7. **Code Maintenance**: Consider refactoring system-dependent code to improve maintainability. "
      }
    ],
    "codediff_length": 79862
  },
  {
    "index": 83,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/search.cpp b/src/search.cpp\nindex b68c8b7859a..d8086dc0737 100644\n--- a/src/search.cpp\n+++ b/src/search.cpp\n@@ -45,10 +45,11 @@ namespace Search {\n namespace Tablebases {\n \n   int Cardinality;\n-  bool RootInTB;\n-  bool UseRule50;\n   Depth ProbeDepth;\n-  Value Score;\n+  WDLScore DrawScore;\n+  WDLScore RootWDL;\n+  int RootPosDTZ;\n+  bool CanProbeDTZ;\n }\n \n namespace TB = Tablebases;\n@@ -150,6 +151,7 @@ namespace {\n   void update_pv(Move* pv, Move move, Move* childPv);\n   void update_continuation_histories(Stack* ss, Piece pc, Square to, int bonus);\n   void update_stats(const Position& pos, Stack* ss, Move move, Move* quiets, int quietsCnt, int bonus);\n+  Value probe_tb(Position& pos, Stack* ss, Value alpha, Value beta, Depth* depth, TTEntry* tte);\n \n   // perft() is our utility to verify move generation. All the leaf nodes up\n   // to the given depth are generated and counted, and the sum is returned.\n@@ -243,6 +245,25 @@ void MainThread::search() {\n   DrawValue[ us] = VALUE_DRAW - Value(contempt);\n   DrawValue[~us] = VALUE_DRAW + Value(contempt);\n \n+  // Set TB probing parameters\n+  TB::DrawScore = Options[\"Syzygy50MoveRule\"] ? TB::WDLCursedWin : TB::WDLDraw;\n+  TB::ProbeDepth = Options[\"SyzygyProbeDepth\"] * ONE_PLY;\n+  TB::Cardinality = Options[\"SyzygyProbeLimit\"];\n+\n+  if (TB::Cardinality > TB::MaxCardinality)\n+  {\n+      TB::Cardinality = TB::MaxCardinality;\n+      TB::ProbeDepth = DEPTH_ZERO; // Hack!\n+  }\n+\n+  // Enable probing of DTZ only when WDL is not enough\n+  TB::CanProbeDTZ =   TB::RootPosDTZ != TB::DTZ_NONE // Only if root is in TB\n+                   && TB::DrawScore != TB::WDLDraw   // Only if rule50 is enabled\n+                   && TB::RootPosDTZ;                 // Not a draw\n+\n+  TB::RootWDL = TB::CanProbeDTZ ? TB::dtz_to_wdl(TB::RootPosDTZ, rootPos.rule50_count())\n+                                : TB::WDLScoreNone;\n+\n   if (rootMoves.empty())\n   {\n       rootMoves.emplace_back(MOVE_NONE);\n@@ -303,16 +324,50 @@ void MainThread::search() {\n       }\n   }\n \n-  previousScore = bestThread->rootMoves[0].score;\n+  RootMove& bestMove = bestThread->rootMoves[0];\n+  previousScore = bestMove.score;\n+\n+  // When starting from a DTZ position ensure we return DTZ optimal move or a\n+  // mate. We don't need DTZ post-processing for draw positions or after a rule50\n+  // zeroing move because WDL will do the job.\n+  if (TB::CanProbeDTZ && abs(bestMove.score) < VALUE_MATE_IN_MAX_PLY)\n+  {\n+      auto bestWdl = -TB::dtz_to_wdl(bestMove.dtz, rootPos.rule50_count());\n+\n+      // Force a DTZ best move if we don't preserve the WDL score or if we are\n+      // winning but we don't follow the shortest path to zero, the latter\n+      // condition is to avoid a possible draw by repetition.\n+      // When losing we don't enforce anything so to lose with naturalness :-)\n+      if (    bestWdl < TB::RootWDL\n+          || (TB::RootWDL > TB::DrawScore && TB::RootPosDTZ != bestMove.dtz))\n+      {\n+          auto it = std::find_if(rootMoves.begin(), rootMoves.end(), [&](const RootMove& rm) {\n+                                 return TB::RootPosDTZ == rm.dtz; });\n+\n+          assert(it != rootMoves.end());\n+\n+          bestMove.pv.clear();\n+          bestMove.pv.push_back(it->pv[0]);\n+      }\n+\n+      static_assert(int(PawnValueEg) * 120 < VALUE_MATE_IN_MAX_PLY, \"DTZ overflow\");\n+\n+      // Signal the GUI we are in TB and codify DTZ count into output score\n+      if (abs(TB::RootPosDTZ) + rootPos.rule50_count() > 100)\n+          bestMove.score = VALUE_DRAW; // Cursed win / blessed loss\n+      else\n+          bestMove.score = TB::RootPosDTZ > 0 ?  PawnValueEg * (120 - TB::RootPosDTZ / 2)\n+                                              : -PawnValueEg * (120 + TB::RootPosDTZ / 2);\n+  }\n \n   // Send new PV when needed\n-  if (bestThread != this)\n+  if (bestThread != this || TB::RootPosDTZ != TB::DTZ_NONE)\n       sync_cout << UCI::pv(bestThread->rootPos, bestThread->completedDepth, -VALUE_INFINITE, VALUE_INFINITE) << sync_endl;\n \n-  sync_cout << \"bestmove \" << UCI::move(bestThread->rootMoves[0].pv[0], rootPos.is_chess960());\n+  sync_cout << \"bestmove \" << UCI::move(bestMove.pv[0], rootPos.is_chess960());\n \n   if (bestThread->rootMoves[0].pv.size() > 1 || bestThread->rootMoves[0].extract_ponder_from_tt(rootPos))\n-      std::cout << \" ponder \" << UCI::move(bestThread->rootMoves[0].pv[1], rootPos.is_chess960());\n+      std::cout << \" ponder \" << UCI::move(bestMove.pv[1], rootPos.is_chess960());\n \n   std::cout << sync_endl;\n }\n@@ -330,6 +385,7 @@ void Thread::search() {\n   MainThread* mainThread = (this == Threads.main() ? Threads.main() : nullptr);\n \n   std::memset(ss-4, 0, 7 * sizeof(Stack));\n+  ss->tbCardinality = TB::Cardinality;\n   for (int i = 4; i > 0; i--)\n      (ss-i)->contHistory = &this->contHistory[NO_PIECE][0]; // Use as sentinel\n \n@@ -587,6 +643,7 @@ namespace {\n     ss->currentMove = (ss+1)->excludedMove = bestMove = MOVE_NONE;\n     ss->contHistory = &thisThread->contHistory[NO_PIECE][0];\n     (ss+2)->killers[0] = (ss+2)->killers[1] = MOVE_NONE;\n+    (ss+1)->tbCardinality = ss->tbCardinality;\n     Square prevSq = to_sq((ss-1)->currentMove);\n \n     // Step 4. Transposition table lookup. We don't want the score of a partial\n@@ -631,34 +688,18 @@ namespace {\n     }\n \n     // Step 4a. Tablebase probe\n-    if (!rootNode && TB::Cardinality)\n+    if (!rootNode && ss->tbCardinality)\n     {\n         int piecesCount = pos.count<ALL_PIECES>();\n \n-        if (    piecesCount <= TB::Cardinality\n-            && (piecesCount <  TB::Cardinality || depth >= TB::ProbeDepth)\n-            &&  pos.rule50_count() == 0\n+        if (    piecesCount <= ss->tbCardinality\n+            && (piecesCount <  ss->tbCardinality || depth >= TB::ProbeDepth)\n             && !pos.can_castle(ANY_CASTLING))\n         {\n-            TB::ProbeState err;\n-            TB::WDLScore v = Tablebases::probe_wdl(pos, &err);\n-\n-            if (err != TB::ProbeState::FAIL)\n-            {\n-                thisThread->tbHits.fetch_add(1, std::memory_order_relaxed);\n-\n-                int drawScore = TB::UseRule50 ? 1 : 0;\n-\n-                value =  v < -drawScore ? -VALUE_MATE + MAX_PLY + ss->ply\n-                       : v >  drawScore ?  VALUE_MATE - MAX_PLY - ss->ply\n-                                        :  VALUE_DRAW + 2 * v * drawScore;\n-\n-                tte->save(posKey, value_to_tt(value, ss->ply), BOUND_EXACT,\n-                          std::min(DEPTH_MAX - ONE_PLY, depth + 6 * ONE_PLY),\n-                          MOVE_NONE, VALUE_NONE, TT.generation());\n+            value = probe_tb(pos, ss, alpha, beta, &depth, tte);\n \n+            if (value != VALUE_NONE)\n                 return value;\n-            }\n         }\n     }\n \n@@ -1457,6 +1498,92 @@ namespace {\n     return best;\n   }\n \n+\n+  // probe_tb() is called by search after TT probe to look up the position in\n+  // tablebases, if it is found we return immediately or continue the search\n+  // eventually with reduced depth according to the case.\n+\n+  Value probe_tb(Position& pos, Stack* ss, Value alpha, Value beta, Depth* depth, TTEntry* tte) {\n+\n+    TB::ProbeState err;\n+    TB::WDLScore wdl;\n+    bool tbHit = false, farFromRoot = false, reduceDepth = true;\n+\n+    Thread* thisThread = pos.this_thread();\n+    thisThread->tbHits.fetch_add(1, std::memory_order_relaxed);\n+\n+    // If rootPos is in TB we probe DTZ to differentiate between a win/loss and\n+    // a cursed/blessed draw. This is critical because WDL is reliable only if\n+    // rule50 counter is zero and search alone would detect it only at ply 101.\n+    if (TB::CanProbeDTZ && (ss-1)->ply == 1)\n+    {\n+        tbHit = true;\n+        RootMove& rm = *std::find(thisThread->rootMoves.begin(), thisThread->rootMoves.end(),\n+                                  (ss-1)->currentMove);\n+        wdl = TB::dtz_to_wdl(rm.dtz, thisThread->rootPos.rule50_count());\n+\n+        // Search at reduced depth moves that don't preserve the score\n+        reduceDepth = -wdl < TB::RootWDL;\n+    }\n+    else\n+    {\n+        wdl = Tablebases::probe_wdl(pos, &err);\n+\n+        // Win or loss scores are reliable only if we are probing after a\n+        // rule50 reset move. Instead draw scores are reliable in any case.\n+        if (   err != TB::ProbeState::FAIL\n+            && (pos.rule50_count() == 0 || abs(wdl) <= TB::DrawScore))\n+        {\n+            tbHit = true;\n+\n+            // It is far if ply >= (RootDepth - LMR) / 3, so that at a\n+            // given ply, nodes with high LMR are considered farther\n+            // from root than nodes near the PV line.\n+            farFromRoot = ss->ply - *depth / (2 * ONE_PLY) >= 0;\n+\n+            // Don't save in TT and don't reduce if root is in TB\n+            if (TB::RootPosDTZ != TB::DTZ_NONE)\n+                farFromRoot = reduceDepth = false;\n+        }\n+    }\n+\n+    if (tbHit)\n+    {\n+        Value value =  wdl >  TB::DrawScore ?  VALUE_MATE - MAX_PLY - ss->ply\n+                     : wdl < -TB::DrawScore ? -VALUE_MATE + MAX_PLY + ss->ply\n+                                            :  VALUE_DRAW + 2 * wdl;\n+\n+        Bound bound =  wdl >  TB::DrawScore ? BOUND_LOWER\n+                     : wdl < -TB::DrawScore ? BOUND_UPPER : BOUND_EXACT;\n+\n+        // Use TB scores as lower/upper bounds, a draw score is BOUND_EXACT\n+        // and is always considered even if value is within (alpha, beta)\n+        if (   (value >= beta  && bound == BOUND_LOWER)\n+            || (value <= alpha && bound == BOUND_UPPER)\n+            ||  bound == BOUND_EXACT)\n+        {\n+            // When in midgame or is a draw save in TT and return...\n+            if (bound == BOUND_EXACT || farFromRoot)\n+            {\n+                Key posKey = pos.key() ^ Key(ss->excludedMove);\n+                tte->save(posKey, value_to_tt(value, ss->ply), bound,\n+                          std::min(DEPTH_MAX - ONE_PLY, *depth + 6 * ONE_PLY),\n+                          MOVE_NONE, VALUE_NONE, TT.generation());\n+                return value;\n+            }\n+            // ...otherwise search win/loss with a reduced depth after a WDL\n+            // look-up or after a DTZ look-up if it is a not-improving move.\n+            else if (reduceDepth)\n+                *depth = std::max(*depth / 2, ONE_PLY);\n+\n+            // Don't probe in the win/loss sub-tree (draws cut-off immediately)\n+            ss->tbCardinality = 0;\n+        }\n+    }\n+\n+    return VALUE_NONE;\n+  }\n+\n } // namespace\n \n   // check_time() is used to print debug info and, more importantly, to detect\n@@ -1504,7 +1631,7 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n   size_t PVIdx = pos.this_thread()->PVIdx;\n   size_t multiPV = std::min((size_t)Options[\"MultiPV\"], rootMoves.size());\n   uint64_t nodesSearched = Threads.nodes_searched();\n-  uint64_t tbHits = Threads.tb_hits() + (TB::RootInTB ? rootMoves.size() : 0);\n+  uint64_t tbHits = Threads.tb_hits();\n \n   for (size_t i = 0; i < multiPV; ++i)\n   {\n@@ -1516,9 +1643,6 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n       Depth d = updated ? depth : depth - ONE_PLY;\n       Value v = updated ? rootMoves[i].score : rootMoves[i].previousScore;\n \n-      bool tb = TB::RootInTB && abs(v) < VALUE_MATE - MAX_PLY;\n-      v = tb ? TB::Score : v;\n-\n       if (ss.rdbuf()->in_avail()) // Not at first line\n           ss << \"\\n\";\n \n@@ -1528,7 +1652,7 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n          << \" multipv \"  << i + 1\n          << \" score \"    << UCI::value(v);\n \n-      if (!tb && i == PVIdx)\n+      if (i == PVIdx)\n           ss << (v >= beta ? \" lowerbound\" : v <= alpha ? \" upperbound\" : \"\");\n \n       ss << \" nodes \"    << nodesSearched\n@@ -1577,43 +1701,3 @@ bool RootMove::extract_ponder_from_tt(Position& pos) {\n     pos.undo_move(pv[0]);\n     return pv.size() > 1;\n }\n-\n-void Tablebases::filter_root_moves(Position& pos, Search::RootMoves& rootMoves) {\n-\n-    RootInTB = false;\n-    UseRule50 = Options[\"Syzygy50MoveRule\"];\n-    ProbeDepth = Options[\"SyzygyProbeDepth\"] * ONE_PLY;\n-    Cardinality = Options[\"SyzygyProbeLimit\"];\n-\n-    // Skip TB probing when no TB found: !TBLargest -> !TB::Cardinality\n-    if (Cardinality > MaxCardinality)\n-    {\n-        Cardinality = MaxCardinality;\n-        ProbeDepth = DEPTH_ZERO;\n-    }\n-\n-    if (Cardinality < popcount(pos.pieces()) || pos.can_castle(ANY_CASTLING))\n-        return;\n-\n-    // If the current root position is in the tablebases, then RootMoves\n-    // contains only moves that preserve the draw or the win.\n-    RootInTB = root_probe(pos, rootMoves, TB::Score);\n-\n-    if (RootInTB)\n-        Cardinality = 0; // Do not probe tablebases during the search\n-\n-    else // If DTZ tables are missing, use WDL tables as a fallback\n-    {\n-        // Filter out moves that do not preserve the draw or the win.\n-        RootInTB = root_probe_wdl(pos, rootMoves, TB::Score);\n-\n-        // Only probe during search if winning\n-        if (RootInTB && TB::Score <= VALUE_DRAW)\n-            Cardinality = 0;\n-    }\n-\n-    if (RootInTB && !UseRule50)\n-        TB::Score =  TB::Score > VALUE_DRAW ?  VALUE_MATE - MAX_PLY - 1\n-                   : TB::Score < VALUE_DRAW ? -VALUE_MATE + MAX_PLY + 1\n-                                            :  VALUE_DRAW;\n-}\ndiff --git a/src/search.h b/src/search.h\nindex 694dd643892..9587edb6510 100644\n--- a/src/search.h\n+++ b/src/search.h\n@@ -49,6 +49,7 @@ struct Stack {\n   Value staticEval;\n   int statScore;\n   int moveCount;\n+  int tbCardinality;\n };\n \n \n@@ -69,6 +70,7 @@ struct RootMove {\n   Value score = -VALUE_INFINITE;\n   Value previousScore = -VALUE_INFINITE;\n   int selDepth = 0;\n+  int dtz;\n   std::vector<Move> pv;\n };\n \ndiff --git a/src/syzygy/tbprobe.cpp b/src/syzygy/tbprobe.cpp\nindex 4aff3b2da4b..378173d2260 100644\n--- a/src/syzygy/tbprobe.cpp\n+++ b/src/syzygy/tbprobe.cpp\n@@ -208,14 +208,6 @@ int MapKK[10][SQUARE_NB]; // [MapA1D1D4][SQUARE_NB]\n bool pawns_comp(Square i, Square j) { return MapPawns[i] < MapPawns[j]; }\n int off_A1H8(Square sq) { return int(rank_of(sq)) - file_of(sq); }\n \n-const Value WDL_to_value[] = {\n-   -VALUE_MATE + MAX_PLY + 1,\n-    VALUE_DRAW - 2,\n-    VALUE_DRAW,\n-    VALUE_DRAW + 2,\n-    VALUE_MATE - MAX_PLY - 1\n-};\n-\n const std::string PieceToChar = \" PNBRQK  pnbrqk\";\n \n int Binomial[6][SQUARE_NB];    // [k][n] k elements from a set of n elements\n@@ -1200,7 +1192,7 @@ T probe_table(const Position& pos, ProbeState* result, WDLScore wdl = WDLDraw) {\n // where the best move is an ep-move (even if losing). So in all these cases set\n // the state to ZEROING_BEST_MOVE.\n template<bool CheckZeroingMoves = false>\n-WDLScore search(Position& pos, ProbeState* result) {\n+WDLScore search_wdl(Position& pos, ProbeState* result) {\n \n     WDLScore value, bestValue = WDLLoss;\n     StateInfo st;\n@@ -1208,17 +1200,17 @@ WDLScore search(Position& pos, ProbeState* result) {\n     auto moveList = MoveList<LEGAL>(pos);\n     size_t totalCount = moveList.size(), moveCount = 0;\n \n-    for (const Move& move : moveList)\n+    for (const auto& m : moveList)\n     {\n-        if (   !pos.capture(move)\n-            && (!CheckZeroingMoves || type_of(pos.moved_piece(move)) != PAWN))\n+        if (   !pos.capture(m)\n+            && (!CheckZeroingMoves || type_of(pos.moved_piece(m)) != PAWN))\n             continue;\n \n         moveCount++;\n \n-        pos.do_move(move, st);\n-        value = -search(pos, result);\n-        pos.undo_move(move);\n+        pos.do_move(m, st);\n+        value = -search_wdl(pos, result);\n+        pos.undo_move(m);\n \n         if (*result == FAIL)\n             return WDLDraw;\n@@ -1261,8 +1253,60 @@ WDLScore search(Position& pos, ProbeState* result) {\n     return *result = OK, value;\n }\n \n+// Do a 1-ply search probing DTZ values of resulting positions and reporting\n+// back the minimum DTZ already converted to the point of view of previous ply.\n+// If rootMoves is passed then set the corresponding RootMove dtz field.\n+int search_dtz(Position& pos, ProbeState* result, WDLScore wdl, Search::RootMoves* rootMoves) {\n+\n+  StateInfo st;\n+  int minDTZ = 0xFFFF;\n+\n+  for (const auto& m : MoveList<LEGAL>(pos))\n+  {\n+      bool zeroing = pos.capture(m) || type_of(pos.moved_piece(m)) == PAWN;\n+\n+      pos.do_move(m, st);\n+\n+      // For zeroing moves we want the dtz of the move _before_ doing it,\n+      // otherwise we will get the dtz of the next move sequence. Search the\n+      // position after the move to get the score sign (because even in a\n+      // winning position we could make a losing capture or going for a draw).\n+      int dtz = zeroing ? -dtz_before_zeroing(search_wdl(pos, result))\n+                        : -probe_dtz(pos, result);\n+\n+      pos.undo_move(m);\n+\n+      if (*result == FAIL)\n+          return 0;\n+\n+      // Convert result from 1-ply search. Zeroing moves are already accounted\n+      // by dtz_before_zeroing() that returns the DTZ of the previous move.\n+      if (!zeroing)\n+          dtz += sign_of(dtz);\n+\n+      // Skip the draws and if we are winning only pick positive dtz\n+      if (dtz < minDTZ && sign_of(dtz) == sign_of(wdl))\n+          minDTZ = dtz;\n+\n+      if (rootMoves)\n+          std::find(rootMoves->begin(), rootMoves->end(), m)->dtz = dtz;\n+  }\n+\n+  // Special handle a mate position, when there are no legal moves, in this\n+  // case return value is somewhat arbitrary, so stick to the original TB code\n+  // that returns -1 in this case.\n+  return minDTZ == 0xFFFF ? -1 : minDTZ;\n+}\n+\n } // namespace\n \n+WDLScore Tablebases::dtz_to_wdl(int dtz, int r50) {\n+\n+  bool cursed = abs(dtz) + r50 > 100;\n+  return  dtz > 0 ? (cursed ? WDLCursedWin   : WDLWin)\n+        : dtz < 0 ? (cursed ? WDLBlessedLoss : WDLLoss) : WDLDraw;\n+}\n+\n void Tablebases::init(const std::string& paths) {\n \n     EntryTable.clear();\n@@ -1406,7 +1450,7 @@ void Tablebases::init(const std::string& paths) {\n WDLScore Tablebases::probe_wdl(Position& pos, ProbeState* result) {\n \n     *result = OK;\n-    return search(pos, result);\n+    return search_wdl(pos, result);\n }\n \n // Probe the DTZ table for a particular position.\n@@ -1437,7 +1481,7 @@ WDLScore Tablebases::probe_wdl(Position& pos, ProbeState* result) {\n int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n \n     *result = OK;\n-    WDLScore wdl = search<true>(pos, result);\n+    WDLScore wdl = search_wdl<true>(pos, result);\n \n     if (*result == FAIL || wdl == WDLDraw) // DTZ tables don't store draws\n         return 0;\n@@ -1457,246 +1501,25 @@ int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n \n     // DTZ stores results for the other side, so we need to do a 1-ply search and\n     // find the winning move that minimizes DTZ.\n-    StateInfo st;\n-    int minDTZ = 0xFFFF;\n-\n-    for (const Move& move : MoveList<LEGAL>(pos))\n-    {\n-        bool zeroing = pos.capture(move) || type_of(pos.moved_piece(move)) == PAWN;\n-\n-        pos.do_move(move, st);\n-\n-        // For zeroing moves we want the dtz of the move _before_ doing it,\n-        // otherwise we will get the dtz of the next move sequence. Search the\n-        // position after the move to get the score sign (because even in a\n-        // winning position we could make a losing capture or going for a draw).\n-        dtz = zeroing ? -dtz_before_zeroing(search(pos, result))\n-                      : -probe_dtz(pos, result);\n-\n-        pos.undo_move(move);\n-\n-        if (*result == FAIL)\n-            return 0;\n-\n-        // Convert result from 1-ply search. Zeroing moves are already accounted\n-        // by dtz_before_zeroing() that returns the DTZ of the previous move.\n-        if (!zeroing)\n-            dtz += sign_of(dtz);\n-\n-        // Skip the draws and if we are winning only pick positive dtz\n-        if (dtz < minDTZ && sign_of(dtz) == sign_of(wdl))\n-            minDTZ = dtz;\n-    }\n-\n-    // Special handle a mate position, when there are no legal moves, in this\n-    // case return value is somewhat arbitrary, so stick to the original TB code\n-    // that returns -1 in this case.\n-    return minDTZ == 0xFFFF ? -1 : minDTZ;\n-}\n-\n-// Check whether there has been at least one repetition of positions\n-// since the last capture or pawn move.\n-static int has_repeated(StateInfo *st)\n-{\n-    while (1) {\n-        int i = 4, e = std::min(st->rule50, st->pliesFromNull);\n-\n-        if (e < i)\n-            return 0;\n-\n-        StateInfo *stp = st->previous->previous;\n-\n-        do {\n-            stp = stp->previous->previous;\n-\n-            if (stp->key == st->key)\n-                return 1;\n-\n-            i += 2;\n-        } while (i <= e);\n-\n-        st = st->previous;\n-    }\n-}\n-\n-// Use the DTZ tables to filter out moves that don't preserve the win or draw.\n-// If the position is lost, but DTZ is fairly high, only keep moves that\n-// maximise DTZ.\n-//\n-// A return value false indicates that not all probes were successful and that\n-// no moves were filtered out.\n-bool Tablebases::root_probe(Position& pos, Search::RootMoves& rootMoves, Value& score)\n-{\n-    assert(rootMoves.size());\n-\n-    ProbeState result;\n-    int dtz = probe_dtz(pos, &result);\n-\n-    if (result == FAIL)\n-        return false;\n-\n-    StateInfo st;\n-\n-    // Probe each move\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        Move move = rootMoves[i].pv[0];\n-        pos.do_move(move, st);\n-        int v = 0;\n-\n-        if (pos.checkers() && dtz > 0) {\n-            ExtMove s[MAX_MOVES];\n-\n-            if (generate<LEGAL>(pos, s) == s)\n-                v = 1;\n-        }\n-\n-        if (!v) {\n-            if (st.rule50 != 0) {\n-                v = -probe_dtz(pos, &result);\n-\n-                if (v > 0)\n-                    ++v;\n-                else if (v < 0)\n-                    --v;\n-            } else {\n-                v = -probe_wdl(pos, &result);\n-                v = dtz_before_zeroing(WDLScore(v));\n-            }\n-        }\n-\n-        pos.undo_move(move);\n-\n-        if (result == FAIL)\n-            return false;\n-\n-        rootMoves[i].score = (Value)v;\n-    }\n-\n-    // Obtain 50-move counter for the root position.\n-    // In Stockfish there seems to be no clean way, so we do it like this:\n-    int cnt50 = st.previous ? st.previous->rule50 : 0;\n-\n-    // Use 50-move counter to determine whether the root position is\n-    // won, lost or drawn.\n-    WDLScore wdl = WDLDraw;\n-\n-    if (dtz > 0)\n-        wdl = (dtz + cnt50 <= 100) ? WDLWin : WDLCursedWin;\n-    else if (dtz < 0)\n-        wdl = (-dtz + cnt50 <= 100) ? WDLLoss : WDLBlessedLoss;\n-\n-    // Determine the score to report to the user.\n-    score = WDL_to_value[wdl + 2];\n-\n-    // If the position is winning or losing, but too few moves left, adjust the\n-    // score to show how close it is to winning or losing.\n-    // NOTE: int(PawnValueEg) is used as scaling factor in score_to_uci().\n-    if (wdl == WDLCursedWin && dtz <= 100)\n-        score = (Value)(((200 - dtz - cnt50) * int(PawnValueEg)) / 200);\n-    else if (wdl == WDLBlessedLoss && dtz >= -100)\n-        score = -(Value)(((200 + dtz - cnt50) * int(PawnValueEg)) / 200);\n-\n-    // Now be a bit smart about filtering out moves.\n-    size_t j = 0;\n-\n-    if (dtz > 0) { // winning (or 50-move rule draw)\n-        int best = 0xffff;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v > 0 && v < best)\n-                best = v;\n-        }\n-\n-        int max = best;\n-\n-        // If the current phase has not seen repetitions, then try all moves\n-        // that stay safely within the 50-move budget, if there are any.\n-        if (!has_repeated(st.previous) && best + cnt50 <= 99)\n-            max = 99 - cnt50;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v > 0 && v <= max)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    } else if (dtz < 0) { // losing (or 50-move rule draw)\n-        int best = 0;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v < best)\n-                best = v;\n-        }\n-\n-        // Try all moves, unless we approach or have a 50-move rule draw.\n-        if (-best * 2 + cnt50 < 100)\n-            return true;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            if (rootMoves[i].score == best)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    } else { // drawing\n-        // Try all moves that preserve the draw.\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            if (rootMoves[i].score == 0)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    }\n-\n-    rootMoves.resize(j, Search::RootMove(MOVE_NONE));\n-\n-    return true;\n+    return search_dtz(pos, result, wdl, nullptr);\n }\n \n-// Use the WDL tables to filter out moves that don't preserve the win or draw.\n-// This is a fallback for the case that some or all DTZ tables are missing.\n-//\n-// A return value false indicates that not all probes were successful and that\n-// no moves were filtered out.\n-bool Tablebases::root_probe_wdl(Position& pos, Search::RootMoves& rootMoves, Value& score)\n-{\n-    ProbeState result;\n-\n-    WDLScore wdl = Tablebases::probe_wdl(pos, &result);\n-\n-    if (result == FAIL)\n-        return false;\n-\n-    score = WDL_to_value[wdl + 2];\n-\n-    StateInfo st;\n-\n-    int best = WDLLoss;\n+// Call probe_dtz() for each root move and store the result\n+void Tablebases::dtz_score(Position& pos, Search::RootMoves& rootMoves) {\n \n-    // Probe each move\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        Move move = rootMoves[i].pv[0];\n-        pos.do_move(move, st);\n-        WDLScore v = -Tablebases::probe_wdl(pos, &result);\n-        pos.undo_move(move);\n+  ProbeState result;\n+  RootPosDTZ = DTZ_NONE;\n \n-        if (result == FAIL)\n-            return false;\n-\n-        rootMoves[i].score = (Value)v;\n-\n-        if (v > best)\n-            best = v;\n-    }\n-\n-    size_t j = 0;\n-\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        if (rootMoves[i].score == best)\n-            rootMoves[j++] = rootMoves[i];\n-    }\n+  if (   pos.count<ALL_PIECES>() > MaxCardinality\n+      || pos.can_castle(ANY_CASTLING)\n+      || rootMoves.empty())\n+      return;\n \n-    rootMoves.resize(j, Search::RootMove(MOVE_NONE));\n+  // Return value of probe_dtz() can be off by 1, so use search_dtz() for RootPosDTZ\n+  int dtz = Tablebases::probe_dtz(pos, &result);\n+  if (result != FAIL)\n+      dtz = search_dtz(pos, &result, dtz_to_wdl(dtz, pos.rule50_count()), &rootMoves);\n \n-    return true;\n+  if (result != FAIL)\n+      RootPosDTZ = dtz;\n }\ndiff --git a/src/syzygy/tbprobe.h b/src/syzygy/tbprobe.h\nindex f44674b215f..597080244f9 100644\n--- a/src/syzygy/tbprobe.h\n+++ b/src/syzygy/tbprobe.h\n@@ -26,6 +26,8 @@\n \n namespace Tablebases {\n \n+const int DTZ_NONE = 999;\n+\n enum WDLScore {\n     WDLLoss        = -2, // Loss\n     WDLBlessedLoss = -1, // Loss, but draw under 50-move rule\n@@ -45,13 +47,15 @@ enum ProbeState {\n };\n \n extern int MaxCardinality;\n+extern int RootPosDTZ;\n+extern WDLScore RootWDL;\n+extern bool CanProbeDTZ;\n \n void init(const std::string& paths);\n WDLScore probe_wdl(Position& pos, ProbeState* result);\n int probe_dtz(Position& pos, ProbeState* result);\n-bool root_probe(Position& pos, Search::RootMoves& rootMoves, Value& score);\n-bool root_probe_wdl(Position& pos, Search::RootMoves& rootMoves, Value& score);\n-void filter_root_moves(Position& pos, Search::RootMoves& rootMoves);\n+void dtz_score(Position& pos, Search::RootMoves& rootMoves);\n+WDLScore dtz_to_wdl(int dtz, int r50);\n \n inline std::ostream& operator<<(std::ostream& os, const WDLScore v) {\n \ndiff --git a/src/thread.cpp b/src/thread.cpp\nindex d095aefeb6a..f02c3fd5afe 100644\n--- a/src/thread.cpp\n+++ b/src/thread.cpp\n@@ -163,8 +163,7 @@ void ThreadPool::start_thinking(Position& pos, StateListPtr& states,\n           || std::count(limits.searchmoves.begin(), limits.searchmoves.end(), m))\n           rootMoves.emplace_back(m);\n \n-  if (!rootMoves.empty())\n-      Tablebases::filter_root_moves(pos, rootMoves);\n+  Tablebases::dtz_score(pos, rootMoves);\n \n   // After ownership transfer 'states' becomes empty, so if we stop the search\n   // and call 'go' again without setting a new position states.get() == NULL.\ndiff --git a/src/types.h b/src/types.h\nindex acca8743a48..4f88eec387e 100644\n--- a/src/types.h\n+++ b/src/types.h\n@@ -180,8 +180,8 @@ enum Value : int {\n   VALUE_INFINITE  = 32001,\n   VALUE_NONE      = 32002,\n \n-  VALUE_MATE_IN_MAX_PLY  =  VALUE_MATE - 2 * MAX_PLY,\n-  VALUE_MATED_IN_MAX_PLY = -VALUE_MATE + 2 * MAX_PLY,\n+  VALUE_MATE_IN_MAX_PLY  =  VALUE_MATE - MAX_PLY,\n+  VALUE_MATED_IN_MAX_PLY = -VALUE_MATE + MAX_PLY,\n \n   PawnValueMg   = 171,   PawnValueEg   = 240,\n   KnightValueMg = 764,   KnightValueEg = 848,\ndiff --git a/src/uci.cpp b/src/uci.cpp\nindex fc66f0b5321..8ec5916024d 100644\n--- a/src/uci.cpp\n+++ b/src/uci.cpp\n@@ -142,8 +142,8 @@ namespace {\n \n   void bench(Position& pos, istream& args, StateListPtr& states) {\n \n-    string token;\n-    uint64_t num, nodes = 0, cnt = 1;\n+    string token, tbh;\n+    uint64_t num, nodes = 0, tbHits = 0, cnt = 1;\n \n     vector<string> list = setup_bench(pos, args);\n     num = count_if(list.begin(), list.end(), [](string s) { return s.find(\"go \") == 0; });\n@@ -160,7 +160,8 @@ namespace {\n             cerr << \"\\nPosition: \" << cnt++ << '/' << num << endl;\n             go(pos, is, states);\n             Threads.main()->wait_for_search_finished();\n-            nodes += Threads.nodes_searched();\n+            nodes  += Threads.nodes_searched();\n+            tbHits += Threads.tb_hits();\n         }\n         else if (token == \"setoption\")  setoption(is);\n         else if (token == \"position\")   position(pos, is, states);\n@@ -174,7 +175,8 @@ namespace {\n     cerr << \"\\n===========================\"\n          << \"\\nTotal time (ms) : \" << elapsed\n          << \"\\nNodes searched  : \" << nodes\n-         << \"\\nNodes/second    : \" << 1000 * nodes / elapsed << endl;\n+         << \"\\nNodes/second    : \" << 1000 * nodes / elapsed\n+         << \"\\nTB hits         : \" << tbHits << endl;\n   }\n \n } // namespace\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Bug/Logic Issue**: Ensure the engine detects draw by repetition after every non-DTZ-decreasing move. Playing non-optimal moves may revert to a previously repeated state, risking a draw.\n\n2. **Implementation Suggestion**: Add a UCI option \"NaturalTB\" (default true) to toggle behavior between traditional and natural modes. In \"Natural\", return to a DTZ-optimal move after repetitions.\n\n3. **Performance Concern**: Validate the impact of the changes on ELO performance and TB accuracy over longer search times.\n\n4. **Next Steps**: Focus on implementing the DTZ tracking for optimal move selection without complicating the existing code. Test the changes against scenarios to ensure proper handling of draw conditions."
      }
    ],
    "codediff_length": 30121
  },
  {
    "index": 84,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/Makefile b/src/Makefile\nindex 660b41e7edb..e6de514e568 100644\n--- a/src/Makefile\n+++ b/src/Makefile\n@@ -806,7 +806,7 @@ help:\n \t@echo \"help                    > Display architecture details\"\n \t@echo \"profile-build           > standard build with profile-guided optimization\"\n \t@echo \"build                   > skip profile-guided optimization\"\n-\t@echo \"net                     > Download the default nnue net\"\n+\t@echo \"net                     > Download the default nnue nets\"\n \t@echo \"strip                   > Strip executable\"\n \t@echo \"install                 > Install executable\"\n \t@echo \"clean                   > Clean up\"\n@@ -922,16 +922,7 @@ profileclean:\n \t@rm -f stockfish.res\n \t@rm -f ./-lstdc++.res\n \n-# set up shell variables for the net stuff\n-netvariables:\n-\t$(eval nnuenet := $(shell grep EvalFileDefaultName evaluate.h | grep define | sed 's/.*\\(nn-[a-z0-9]\\{12\\}.nnue\\).*/\\1/'))\n-\t$(eval nnuedownloadurl1 := https://tests.stockfishchess.org/api/nn/$(nnuenet))\n-\t$(eval nnuedownloadurl2 := https://github.com/official-stockfish/networks/raw/master/$(nnuenet))\n-\t$(eval curl_or_wget := $(shell if hash curl 2>/dev/null; then echo \"curl -skL\"; elif hash wget 2>/dev/null; then echo \"wget -qO-\"; fi))\n-\t$(eval shasum_command := $(shell if hash shasum 2>/dev/null; then echo \"shasum -a 256 \"; elif hash sha256sum 2>/dev/null; then echo \"sha256sum \"; fi))\n-\n-# evaluation network (nnue)\n-net: netvariables\n+define fetch_network\n \t@echo \"Default net: $(nnuenet)\"\n \t@if [ \"x$(curl_or_wget)\" = \"x\" ]; then \\\n \t\techo \"Neither curl nor wget is installed. Install one of these tools unless the net has been downloaded manually\"; \\\n@@ -966,7 +957,24 @@ net: netvariables\n \t\tif [ \"$(nnuenet)\" = \"nn-\"`$(shasum_command) $(nnuenet) | cut -c1-12`\".nnue\" ]; then \\\n \t\t\techo \"Network validated\"; break; \\\n \t\tfi; \\\n-\tfi; \\\n+\tfi;\n+endef\n+\n+# set up shell variables for the net stuff\n+define netvariables\n+$(eval nnuenet := $(shell grep $(1) evaluate.h | grep define | sed 's/.*\\(nn-[a-z0-9]\\{12\\}.nnue\\).*/\\1/'))\n+$(eval nnuedownloadurl1 := https://tests.stockfishchess.org/api/nn/$(nnuenet))\n+$(eval nnuedownloadurl2 := https://github.com/official-stockfish/networks/raw/master/$(nnuenet))\n+$(eval curl_or_wget := $(shell if hash curl 2>/dev/null; then echo \"curl -skL\"; elif hash wget 2>/dev/null; then echo \"wget -qO-\"; fi))\n+$(eval shasum_command := $(shell if hash shasum 2>/dev/null; then echo \"shasum -a 256 \"; elif hash sha256sum 2>/dev/null; then echo \"sha256sum \"; fi))\n+endef\n+\n+# evaluation network (nnue)\n+net:\n+\t$(call netvariables, EvalFileDefaultNameBig)\n+\t$(call fetch_network)\n+\t$(call netvariables, EvalFileDefaultNameSmall)\n+\t$(call fetch_network)\n \n format:\n \t$(CLANG-FORMAT) -i $(SRCS) $(HEADERS) -style=file\ndiff --git a/src/evaluate.cpp b/src/evaluate.cpp\nindex bda7132a1ff..deeb9e673d0 100644\n--- a/src/evaluate.cpp\n+++ b/src/evaluate.cpp\n@@ -23,6 +23,7 @@\n #include <cmath>\n #include <cstdlib>\n #include <fstream>\n+#include <initializer_list>\n #include <iomanip>\n #include <iostream>\n #include <sstream>\n@@ -31,6 +32,7 @@\n #include \"incbin/incbin.h\"\n #include \"misc.h\"\n #include \"nnue/evaluate_nnue.h\"\n+#include \"nnue/nnue_architecture.h\"\n #include \"position.h\"\n #include \"thread.h\"\n #include \"types.h\"\n@@ -44,11 +46,15 @@\n //     const unsigned int         gEmbeddedNNUESize;    // the size of the embedded file\n // Note that this does not work in Microsoft Visual Studio.\n #if !defined(_MSC_VER) && !defined(NNUE_EMBEDDING_OFF)\n-INCBIN(EmbeddedNNUE, EvalFileDefaultName);\n+INCBIN(EmbeddedNNUEBig, EvalFileDefaultNameBig);\n+INCBIN(EmbeddedNNUESmall, EvalFileDefaultNameSmall);\n #else\n-const unsigned char        gEmbeddedNNUEData[1] = {0x0};\n-const unsigned char* const gEmbeddedNNUEEnd     = &gEmbeddedNNUEData[1];\n-const unsigned int         gEmbeddedNNUESize    = 1;\n+const unsigned char        gEmbeddedNNUEBigData[1]   = {0x0};\n+const unsigned char* const gEmbeddedNNUEBigEnd       = &gEmbeddedNNUEBigData[1];\n+const unsigned int         gEmbeddedNNUEBigSize      = 1;\n+const unsigned char        gEmbeddedNNUESmallData[1] = {0x0};\n+const unsigned char* const gEmbeddedNNUESmallEnd     = &gEmbeddedNNUESmallData[1];\n+const unsigned int         gEmbeddedNNUESmallSize    = 1;\n #endif\n \n \n@@ -56,7 +62,9 @@ namespace Stockfish {\n \n namespace Eval {\n \n-std::string currentEvalFileName = \"None\";\n+std::string       currentEvalFileName[2] = {\"None\", \"None\"};\n+const std::string EvFiles[2]             = {\"EvalFile\", \"EvalFileSmall\"};\n+const std::string EvFileNames[2]         = {EvalFileDefaultNameBig, EvalFileDefaultNameSmall};\n \n // Tries to load a NNUE network at startup time, or when the engine\n // receives a UCI command \"setoption name EvalFile value nn-[a-z0-9]{12}.nnue\"\n@@ -67,84 +75,96 @@ std::string currentEvalFileName = \"None\";\n // variable to have the engine search in a special directory in their distro.\n void NNUE::init() {\n \n-    std::string eval_file = std::string(Options[\"EvalFile\"]);\n-    if (eval_file.empty())\n-        eval_file = EvalFileDefaultName;\n+    for (NetSize netSize : {Big, Small})\n+    {\n+        // change after fishtest supports EvalFileSmall\n+        std::string eval_file =\n+          std::string(netSize == Small ? EvalFileDefaultNameSmall : Options[EvFiles[netSize]]);\n+        if (eval_file.empty())\n+            eval_file = EvFileNames[netSize];\n \n #if defined(DEFAULT_NNUE_DIRECTORY)\n-    std::vector<std::string> dirs = {\"<internal>\", \"\", CommandLine::binaryDirectory,\n-                                     stringify(DEFAULT_NNUE_DIRECTORY)};\n+        std::vector<std::string> dirs = {\"<internal>\", \"\", CommandLine::binaryDirectory,\n+                                         stringify(DEFAULT_NNUE_DIRECTORY)};\n #else\n-    std::vector<std::string> dirs = {\"<internal>\", \"\", CommandLine::binaryDirectory};\n+        std::vector<std::string> dirs = {\"<internal>\", \"\", CommandLine::binaryDirectory};\n #endif\n \n-    for (const std::string& directory : dirs)\n-        if (currentEvalFileName != eval_file)\n+        for (const std::string& directory : dirs)\n         {\n-            if (directory != \"<internal>\")\n-            {\n-                std::ifstream stream(directory + eval_file, std::ios::binary);\n-                if (NNUE::load_eval(eval_file, stream))\n-                    currentEvalFileName = eval_file;\n-            }\n-\n-            if (directory == \"<internal>\" && eval_file == EvalFileDefaultName)\n+            if (currentEvalFileName[netSize] != eval_file)\n             {\n-                // C++ way to prepare a buffer for a memory stream\n-                class MemoryBuffer: public std::basic_streambuf<char> {\n-                   public:\n-                    MemoryBuffer(char* p, size_t n) {\n-                        setg(p, p, p + n);\n-                        setp(p, p + n);\n-                    }\n-                };\n-\n-                MemoryBuffer buffer(\n-                  const_cast<char*>(reinterpret_cast<const char*>(gEmbeddedNNUEData)),\n-                  size_t(gEmbeddedNNUESize));\n-                (void) gEmbeddedNNUEEnd;  // Silence warning on unused variable\n-\n-                std::istream stream(&buffer);\n-                if (NNUE::load_eval(eval_file, stream))\n-                    currentEvalFileName = eval_file;\n+                if (directory != \"<internal>\")\n+                {\n+                    std::ifstream stream(directory + eval_file, std::ios::binary);\n+                    if (NNUE::load_eval(eval_file, stream, netSize))\n+                        currentEvalFileName[netSize] = eval_file;\n+                }\n+\n+                if (directory == \"<internal>\" && eval_file == EvFileNames[netSize])\n+                {\n+                    // C++ way to prepare a buffer for a memory stream\n+                    class MemoryBuffer: public std::basic_streambuf<char> {\n+                       public:\n+                        MemoryBuffer(char* p, size_t n) {\n+                            setg(p, p, p + n);\n+                            setp(p, p + n);\n+                        }\n+                    };\n+\n+                    MemoryBuffer buffer(\n+                      const_cast<char*>(reinterpret_cast<const char*>(\n+                        netSize == Small ? gEmbeddedNNUESmallData : gEmbeddedNNUEBigData)),\n+                      size_t(netSize == Small ? gEmbeddedNNUESmallSize : gEmbeddedNNUEBigSize));\n+                    (void) gEmbeddedNNUEBigEnd;  // Silence warning on unused variable\n+                    (void) gEmbeddedNNUESmallEnd;\n+\n+                    std::istream stream(&buffer);\n+                    if (NNUE::load_eval(eval_file, stream, netSize))\n+                        currentEvalFileName[netSize] = eval_file;\n+                }\n             }\n         }\n+    }\n }\n \n // Verifies that the last net used was loaded successfully\n void NNUE::verify() {\n \n-    std::string eval_file = std::string(Options[\"EvalFile\"]);\n-    if (eval_file.empty())\n-        eval_file = EvalFileDefaultName;\n-\n-    if (currentEvalFileName != eval_file)\n+    for (NetSize netSize : {Big, Small})\n     {\n+        // change after fishtest supports EvalFileSmall\n+        std::string eval_file =\n+          std::string(netSize == Small ? EvalFileDefaultNameSmall : Options[EvFiles[netSize]]);\n+        if (eval_file.empty())\n+            eval_file = EvFileNames[netSize];\n \n-        std::string msg1 =\n-          \"Network evaluation parameters compatible with the engine must be available.\";\n-        std::string msg2 = \"The network file \" + eval_file + \" was not loaded successfully.\";\n-        std::string msg3 = \"The UCI option EvalFile might need to specify the full path, \"\n-                           \"including the directory name, to the network file.\";\n-        std::string msg4 = \"The default net can be downloaded from: \"\n-                           \"https://tests.stockfishchess.org/api/nn/\"\n-                         + std::string(EvalFileDefaultName);\n-        std::string msg5 = \"The engine will be terminated now.\";\n-\n-        sync_cout << \"info string ERROR: \" << msg1 << sync_endl;\n-        sync_cout << \"info string ERROR: \" << msg2 << sync_endl;\n-        sync_cout << \"info string ERROR: \" << msg3 << sync_endl;\n-        sync_cout << \"info string ERROR: \" << msg4 << sync_endl;\n-        sync_cout << \"info string ERROR: \" << msg5 << sync_endl;\n-\n-        exit(EXIT_FAILURE);\n-    }\n+        if (currentEvalFileName[netSize] != eval_file)\n+        {\n+            std::string msg1 =\n+              \"Network evaluation parameters compatible with the engine must be available.\";\n+            std::string msg2 = \"The network file \" + eval_file + \" was not loaded successfully.\";\n+            std::string msg3 = \"The UCI option EvalFile might need to specify the full path, \"\n+                               \"including the directory name, to the network file.\";\n+            std::string msg4 = \"The default net can be downloaded from: \"\n+                               \"https://tests.stockfishchess.org/api/nn/\"\n+                             + std::string(EvFileNames[netSize]);\n+            std::string msg5 = \"The engine will be terminated now.\";\n+\n+            sync_cout << \"info string ERROR: \" << msg1 << sync_endl;\n+            sync_cout << \"info string ERROR: \" << msg2 << sync_endl;\n+            sync_cout << \"info string ERROR: \" << msg3 << sync_endl;\n+            sync_cout << \"info string ERROR: \" << msg4 << sync_endl;\n+            sync_cout << \"info string ERROR: \" << msg5 << sync_endl;\n+\n+            exit(EXIT_FAILURE);\n+        }\n \n-    sync_cout << \"info string NNUE evaluation using \" << eval_file << sync_endl;\n+        sync_cout << \"info string NNUE evaluation using \" << eval_file << sync_endl;\n+    }\n }\n }\n \n-\n // Returns a static, purely materialistic evaluation of the position from\n // the point of view of the given color. It can be divided by PawnValue to get\n // an approximation of the material advantage on the board in terms of pawns.\n@@ -163,18 +183,19 @@ Value Eval::evaluate(const Position& pos) {\n     int   v;\n     Color stm        = pos.side_to_move();\n     int   shuffling  = pos.rule50_count();\n-    int   simpleEval = simple_eval(pos, stm) + (int(pos.key() & 7) - 3);\n-\n-    bool lazy = std::abs(simpleEval) >= RookValue + KnightValue + 16 * shuffling * shuffling\n-                                          + std::abs(pos.this_thread()->bestValue)\n-                                          + std::abs(pos.this_thread()->rootSimpleEval);\n+    int   simpleEval = simple_eval(pos, stm);\n \n+    bool lazy = std::abs(simpleEval) > 2300;\n     if (lazy)\n         v = simpleEval;\n     else\n     {\n-        int   nnueComplexity;\n-        Value nnue = NNUE::evaluate(pos, true, &nnueComplexity);\n+        bool smallNet = std::abs(simpleEval) > 1100;\n+\n+        int nnueComplexity;\n+\n+        Value nnue = smallNet ? NNUE::evaluate<NNUE::Small>(pos, true, &nnueComplexity)\n+                              : NNUE::evaluate<NNUE::Big>(pos, true, &nnueComplexity);\n \n         int optimism = pos.this_thread()->optimism[stm];\n \n@@ -217,7 +238,7 @@ std::string Eval::trace(Position& pos) {\n     ss << std::showpoint << std::showpos << std::fixed << std::setprecision(2) << std::setw(15);\n \n     Value v;\n-    v = NNUE::evaluate(pos, false);\n+    v = NNUE::evaluate<NNUE::Big>(pos, false);\n     v = pos.side_to_move() == WHITE ? v : -v;\n     ss << \"NNUE evaluation        \" << 0.01 * UCI::to_cp(v) << \" (white side)\\n\";\n \ndiff --git a/src/evaluate.h b/src/evaluate.h\nindex 0a7ec61a3cf..3ead6b763dc 100644\n--- a/src/evaluate.h\n+++ b/src/evaluate.h\n@@ -34,12 +34,13 @@ std::string trace(Position& pos);\n int   simple_eval(const Position& pos, Color c);\n Value evaluate(const Position& pos);\n \n-extern std::string currentEvalFileName;\n+extern std::string currentEvalFileName[2];\n \n // The default net name MUST follow the format nn-[SHA256 first 12 digits].nnue\n // for the build process (profile-build and fishtest) to work. Do not change the\n // name of the macro, as it is used in the Makefile.\n-#define EvalFileDefaultName \"nn-b1e55edbea57.nnue\"\n+#define EvalFileDefaultNameBig \"nn-b1e55edbea57.nnue\"\n+#define EvalFileDefaultNameSmall \"nn-c01dc0ffeede.nnue\"\n \n namespace NNUE {\n \ndiff --git a/src/nnue/evaluate_nnue.cpp b/src/nnue/evaluate_nnue.cpp\nindex 14e2fec15a4..004e28dfb41 100644\n--- a/src/nnue/evaluate_nnue.cpp\n+++ b/src/nnue/evaluate_nnue.cpp\n@@ -40,14 +40,18 @@\n namespace Stockfish::Eval::NNUE {\n \n // Input feature converter\n-LargePagePtr<FeatureTransformer> featureTransformer;\n+LargePagePtr<FeatureTransformer<TransformedFeatureDimensionsBig, &StateInfo::accumulatorBig>>\n+  featureTransformerBig;\n+LargePagePtr<FeatureTransformer<TransformedFeatureDimensionsSmall, &StateInfo::accumulatorSmall>>\n+  featureTransformerSmall;\n \n // Evaluation function\n-AlignedPtr<Network> network[LayerStacks];\n+AlignedPtr<Network<TransformedFeatureDimensionsBig, L2Big, L3Big>>       networkBig[LayerStacks];\n+AlignedPtr<Network<TransformedFeatureDimensionsSmall, L2Small, L3Small>> networkSmall[LayerStacks];\n \n-// Evaluation function file name\n-std::string fileName;\n-std::string netDescription;\n+// Evaluation function file names\n+std::string fileName[2];\n+std::string netDescription[2];\n \n namespace Detail {\n \n@@ -91,11 +95,20 @@ bool write_parameters(std::ostream& stream, const T& reference) {\n \n \n // Initialize the evaluation function parameters\n-static void initialize() {\n+static void initialize(NetSize netSize) {\n \n-    Detail::initialize(featureTransformer);\n-    for (std::size_t i = 0; i < LayerStacks; ++i)\n-        Detail::initialize(network[i]);\n+    if (netSize == Small)\n+    {\n+        Detail::initialize(featureTransformerSmall);\n+        for (std::size_t i = 0; i < LayerStacks; ++i)\n+            Detail::initialize(networkSmall[i]);\n+    }\n+    else\n+    {\n+        Detail::initialize(featureTransformerBig);\n+        for (std::size_t i = 0; i < LayerStacks; ++i)\n+            Detail::initialize(networkBig[i]);\n+    }\n }\n \n // Read network header\n@@ -122,39 +135,57 @@ static bool write_header(std::ostream& stream, std::uint32_t hashValue, const st\n }\n \n // Read network parameters\n-static bool read_parameters(std::istream& stream) {\n+static bool read_parameters(std::istream& stream, NetSize netSize) {\n \n     std::uint32_t hashValue;\n-    if (!read_header(stream, &hashValue, &netDescription))\n+    if (!read_header(stream, &hashValue, &netDescription[netSize]))\n+        return false;\n+    if (hashValue != HashValue[netSize])\n         return false;\n-    if (hashValue != HashValue)\n+    if (netSize == Big && !Detail::read_parameters(stream, *featureTransformerBig))\n         return false;\n-    if (!Detail::read_parameters(stream, *featureTransformer))\n+    if (netSize == Small && !Detail::read_parameters(stream, *featureTransformerSmall))\n         return false;\n     for (std::size_t i = 0; i < LayerStacks; ++i)\n-        if (!Detail::read_parameters(stream, *(network[i])))\n+    {\n+        if (netSize == Big && !Detail::read_parameters(stream, *(networkBig[i])))\n             return false;\n+        if (netSize == Small && !Detail::read_parameters(stream, *(networkSmall[i])))\n+            return false;\n+    }\n     return stream && stream.peek() == std::ios::traits_type::eof();\n }\n \n // Write network parameters\n-static bool write_parameters(std::ostream& stream) {\n+static bool write_parameters(std::ostream& stream, NetSize netSize) {\n \n-    if (!write_header(stream, HashValue, netDescription))\n+    if (!write_header(stream, HashValue[netSize], netDescription[netSize]))\n         return false;\n-    if (!Detail::write_parameters(stream, *featureTransformer))\n+    if (netSize == Big && !Detail::write_parameters(stream, *featureTransformerBig))\n+        return false;\n+    if (netSize == Small && !Detail::write_parameters(stream, *featureTransformerSmall))\n         return false;\n     for (std::size_t i = 0; i < LayerStacks; ++i)\n-        if (!Detail::write_parameters(stream, *(network[i])))\n+    {\n+        if (netSize == Big && !Detail::write_parameters(stream, *(networkBig[i])))\n+            return false;\n+        if (netSize == Small && !Detail::write_parameters(stream, *(networkSmall[i])))\n             return false;\n+    }\n     return bool(stream);\n }\n \n void hint_common_parent_position(const Position& pos) {\n-    featureTransformer->hint_common_access(pos);\n+\n+    int simpleEval = simple_eval(pos, pos.side_to_move());\n+    if (abs(simpleEval) > 1100)\n+        featureTransformerSmall->hint_common_access(pos);\n+    else\n+        featureTransformerBig->hint_common_access(pos);\n }\n \n // Evaluation function. Perform differential calculation.\n+template<NetSize Net_Size>\n Value evaluate(const Position& pos, bool adjusted, int* complexity) {\n \n     // We manually align the arrays on the stack because with gcc < 9.3\n@@ -165,19 +196,28 @@ Value evaluate(const Position& pos, bool adjusted, int* complexity) {\n \n #if defined(ALIGNAS_ON_STACK_VARIABLES_BROKEN)\n     TransformedFeatureType\n-      transformedFeaturesUnaligned[FeatureTransformer::BufferSize\n-                                   + alignment / sizeof(TransformedFeatureType)];\n+      transformedFeaturesUnaligned[FeatureTransformer < Small ? TransformedFeatureDimensionsSmall\n+                                                              : TransformedFeatureDimensionsBig,\n+                                   nullptr\n+                                     > ::BufferSize + alignment / sizeof(TransformedFeatureType)];\n \n     auto* transformedFeatures = align_ptr_up<alignment>(&transformedFeaturesUnaligned[0]);\n #else\n-    alignas(alignment) TransformedFeatureType transformedFeatures[FeatureTransformer::BufferSize];\n+\n+    alignas(alignment) TransformedFeatureType\n+      transformedFeatures[FeatureTransformer < Net_Size == Small ? TransformedFeatureDimensionsSmall\n+                                                                 : TransformedFeatureDimensionsBig,\n+                          nullptr > ::BufferSize];\n #endif\n \n     ASSERT_ALIGNED(transformedFeatures, alignment);\n \n     const int  bucket     = (pos.count<ALL_PIECES>() - 1) / 4;\n-    const auto psqt       = featureTransformer->transform(pos, transformedFeatures, bucket);\n-    const auto positional = network[bucket]->propagate(transformedFeatures);\n+    const auto psqt       = Net_Size == Small\n+                            ? featureTransformerSmall->transform(pos, transformedFeatures, bucket)\n+                            : featureTransformerBig->transform(pos, transformedFeatures, bucket);\n+    const auto positional = Net_Size == Small ? networkSmall[bucket]->propagate(transformedFeatures)\n+                                              : networkBig[bucket]->propagate(transformedFeatures);\n \n     if (complexity)\n         *complexity = std::abs(psqt - positional) / OutputScale;\n@@ -190,6 +230,9 @@ Value evaluate(const Position& pos, bool adjusted, int* complexity) {\n         return static_cast<Value>((psqt + positional) / OutputScale);\n }\n \n+template Value evaluate<Big>(const Position& pos, bool adjusted, int* complexity);\n+template Value evaluate<Small>(const Position& pos, bool adjusted, int* complexity);\n+\n struct NnueEvalTrace {\n     static_assert(LayerStacks == PSQTBuckets);\n \n@@ -205,13 +248,14 @@ static NnueEvalTrace trace_evaluate(const Position& pos) {\n     constexpr uint64_t alignment = CacheLineSize;\n \n #if defined(ALIGNAS_ON_STACK_VARIABLES_BROKEN)\n-    TransformedFeatureType\n-      transformedFeaturesUnaligned[FeatureTransformer::BufferSize\n-                                   + alignment / sizeof(TransformedFeatureType)];\n+    TransformedFeatureType transformedFeaturesUnaligned\n+      [FeatureTransformer<TransformedFeatureDimensionsBig, nullptr>::BufferSize\n+       + alignment / sizeof(TransformedFeatureType)];\n \n     auto* transformedFeatures = align_ptr_up<alignment>(&transformedFeaturesUnaligned[0]);\n #else\n-    alignas(alignment) TransformedFeatureType transformedFeatures[FeatureTransformer::BufferSize];\n+    alignas(alignment) TransformedFeatureType\n+      transformedFeatures[FeatureTransformer<TransformedFeatureDimensionsBig, nullptr>::BufferSize];\n #endif\n \n     ASSERT_ALIGNED(transformedFeatures, alignment);\n@@ -220,8 +264,8 @@ static NnueEvalTrace trace_evaluate(const Position& pos) {\n     t.correctBucket = (pos.count<ALL_PIECES>() - 1) / 4;\n     for (IndexType bucket = 0; bucket < LayerStacks; ++bucket)\n     {\n-        const auto materialist = featureTransformer->transform(pos, transformedFeatures, bucket);\n-        const auto positional  = network[bucket]->propagate(transformedFeatures);\n+        const auto materialist = featureTransformerBig->transform(pos, transformedFeatures, bucket);\n+        const auto positional  = networkBig[bucket]->propagate(transformedFeatures);\n \n         t.psqt[bucket]       = static_cast<Value>(materialist / OutputScale);\n         t.positional[bucket] = static_cast<Value>(positional / OutputScale);\n@@ -310,7 +354,7 @@ std::string trace(Position& pos) {\n \n     // We estimate the value of each piece by doing a differential evaluation from\n     // the current base eval, simulating the removal of the piece from its square.\n-    Value base = evaluate(pos);\n+    Value base = evaluate<NNUE::Big>(pos);\n     base       = pos.side_to_move() == WHITE ? base : -base;\n \n     for (File f = FILE_A; f <= FILE_H; ++f)\n@@ -325,16 +369,16 @@ std::string trace(Position& pos) {\n                 auto st = pos.state();\n \n                 pos.remove_piece(sq);\n-                st->accumulator.computed[WHITE] = false;\n-                st->accumulator.computed[BLACK] = false;\n+                st->accumulatorBig.computed[WHITE] = false;\n+                st->accumulatorBig.computed[BLACK] = false;\n \n-                Value eval = evaluate(pos);\n+                Value eval = evaluate<NNUE::Big>(pos);\n                 eval       = pos.side_to_move() == WHITE ? eval : -eval;\n                 v          = base - eval;\n \n                 pos.put_piece(pc, sq);\n-                st->accumulator.computed[WHITE] = false;\n-                st->accumulator.computed[BLACK] = false;\n+                st->accumulatorBig.computed[WHITE] = false;\n+                st->accumulatorBig.computed[BLACK] = false;\n             }\n \n             writeSquare(f, r, pc, v);\n@@ -379,24 +423,24 @@ std::string trace(Position& pos) {\n \n \n // Load eval, from a file stream or a memory stream\n-bool load_eval(std::string name, std::istream& stream) {\n+bool load_eval(const std::string name, std::istream& stream, NetSize netSize) {\n \n-    initialize();\n-    fileName = name;\n-    return read_parameters(stream);\n+    initialize(netSize);\n+    fileName[netSize] = name;\n+    return read_parameters(stream, netSize);\n }\n \n // Save eval, to a file stream or a memory stream\n-bool save_eval(std::ostream& stream) {\n+bool save_eval(std::ostream& stream, NetSize netSize) {\n \n-    if (fileName.empty())\n+    if (fileName[netSize].empty())\n         return false;\n \n-    return write_parameters(stream);\n+    return write_parameters(stream, netSize);\n }\n \n // Save eval, to a file given by its name\n-bool save_eval(const std::optional<std::string>& filename) {\n+bool save_eval(const std::optional<std::string>& filename, NetSize netSize) {\n \n     std::string actualFilename;\n     std::string msg;\n@@ -405,7 +449,8 @@ bool save_eval(const std::optional<std::string>& filename) {\n         actualFilename = filename.value();\n     else\n     {\n-        if (currentEvalFileName != EvalFileDefaultName)\n+        if (currentEvalFileName[netSize]\n+            != (netSize == Small ? EvalFileDefaultNameSmall : EvalFileDefaultNameBig))\n         {\n             msg = \"Failed to export a net. \"\n                   \"A non-embedded net can only be saved if the filename is specified\";\n@@ -413,11 +458,11 @@ bool save_eval(const std::optional<std::string>& filename) {\n             sync_cout << msg << sync_endl;\n             return false;\n         }\n-        actualFilename = EvalFileDefaultName;\n+        actualFilename = (netSize == Small ? EvalFileDefaultNameSmall : EvalFileDefaultNameBig);\n     }\n \n     std::ofstream stream(actualFilename, std::ios_base::binary);\n-    bool          saved = save_eval(stream);\n+    bool          saved = save_eval(stream, netSize);\n \n     msg = saved ? \"Network saved successfully to \" + actualFilename : \"Failed to export a net\";\n \ndiff --git a/src/nnue/evaluate_nnue.h b/src/nnue/evaluate_nnue.h\nindex f80aa398bba..fabfb5693f9 100644\n--- a/src/nnue/evaluate_nnue.h\n+++ b/src/nnue/evaluate_nnue.h\n@@ -39,9 +39,11 @@ class Position;\n namespace Stockfish::Eval::NNUE {\n \n // Hash value of evaluation function structure\n-constexpr std::uint32_t HashValue =\n-  FeatureTransformer::get_hash_value() ^ Network::get_hash_value();\n-\n+constexpr std::uint32_t HashValue[2] = {\n+  FeatureTransformer<TransformedFeatureDimensionsBig, nullptr>::get_hash_value()\n+    ^ Network<TransformedFeatureDimensionsBig, L2Big, L3Big>::get_hash_value(),\n+  FeatureTransformer<TransformedFeatureDimensionsSmall, nullptr>::get_hash_value()\n+    ^ Network<TransformedFeatureDimensionsSmall, L2Small, L3Small>::get_hash_value()};\n \n // Deleter for automating release of memory area\n template<typename T>\n@@ -67,12 +69,13 @@ template<typename T>\n using LargePagePtr = std::unique_ptr<T, LargePageDeleter<T>>;\n \n std::string trace(Position& pos);\n-Value       evaluate(const Position& pos, bool adjusted = false, int* complexity = nullptr);\n-void        hint_common_parent_position(const Position& pos);\n+template<NetSize Net_Size>\n+Value evaluate(const Position& pos, bool adjusted = false, int* complexity = nullptr);\n+void  hint_common_parent_position(const Position& pos);\n \n-bool load_eval(std::string name, std::istream& stream);\n-bool save_eval(std::ostream& stream);\n-bool save_eval(const std::optional<std::string>& filename);\n+bool load_eval(const std::string name, std::istream& stream, NetSize netSize);\n+bool save_eval(std::ostream& stream, NetSize netSize);\n+bool save_eval(const std::optional<std::string>& filename, NetSize netSize);\n \n }  // namespace Stockfish::Eval::NNUE\n \ndiff --git a/src/nnue/nnue_accumulator.h b/src/nnue/nnue_accumulator.h\nindex f6d705243ef..0b05d00da28 100644\n--- a/src/nnue/nnue_accumulator.h\n+++ b/src/nnue/nnue_accumulator.h\n@@ -29,8 +29,9 @@\n namespace Stockfish::Eval::NNUE {\n \n // Class that holds the result of affine transformation of input features\n+template<IndexType Size>\n struct alignas(CacheLineSize) Accumulator {\n-    std::int16_t accumulation[2][TransformedFeatureDimensions];\n+    std::int16_t accumulation[2][Size];\n     std::int32_t psqtAccumulation[2][PSQTBuckets];\n     bool         computed[2];\n };\ndiff --git a/src/nnue/nnue_architecture.h b/src/nnue/nnue_architecture.h\nindex 92445704296..949f2d8687f 100644\n--- a/src/nnue/nnue_architecture.h\n+++ b/src/nnue/nnue_architecture.h\n@@ -37,14 +37,28 @@ namespace Stockfish::Eval::NNUE {\n // Input features used in evaluation function\n using FeatureSet = Features::HalfKAv2_hm;\n \n+enum NetSize {\n+    Big,\n+    Small\n+};\n+\n // Number of input feature dimensions after conversion\n-constexpr IndexType TransformedFeatureDimensions = 2560;\n-constexpr IndexType PSQTBuckets                  = 8;\n-constexpr IndexType LayerStacks                  = 8;\n+constexpr IndexType TransformedFeatureDimensionsBig = 2560;\n+constexpr int       L2Big                           = 15;\n+constexpr int       L3Big                           = 32;\n+\n+constexpr IndexType TransformedFeatureDimensionsSmall = 128;\n+constexpr int       L2Small                           = 15;\n+constexpr int       L3Small                           = 32;\n+\n+constexpr IndexType PSQTBuckets = 8;\n+constexpr IndexType LayerStacks = 8;\n \n+template<IndexType L1, int L2, int L3>\n struct Network {\n-    static constexpr int FC_0_OUTPUTS = 15;\n-    static constexpr int FC_1_OUTPUTS = 32;\n+    static constexpr IndexType TransformedFeatureDimensions = L1;\n+    static constexpr int       FC_0_OUTPUTS                 = L2;\n+    static constexpr int       FC_1_OUTPUTS                 = L3;\n \n     Layers::AffineTransformSparseInput<TransformedFeatureDimensions, FC_0_OUTPUTS + 1> fc_0;\n     Layers::SqrClippedReLU<FC_0_OUTPUTS + 1>                                           ac_sqr_0;\n@@ -84,13 +98,13 @@ struct Network {\n \n     std::int32_t propagate(const TransformedFeatureType* transformedFeatures) {\n         struct alignas(CacheLineSize) Buffer {\n-            alignas(CacheLineSize) decltype(fc_0)::OutputBuffer fc_0_out;\n-            alignas(CacheLineSize) decltype(ac_sqr_0)::OutputType\n+            alignas(CacheLineSize) typename decltype(fc_0)::OutputBuffer fc_0_out;\n+            alignas(CacheLineSize) typename decltype(ac_sqr_0)::OutputType\n               ac_sqr_0_out[ceil_to_multiple<IndexType>(FC_0_OUTPUTS * 2, 32)];\n-            alignas(CacheLineSize) decltype(ac_0)::OutputBuffer ac_0_out;\n-            alignas(CacheLineSize) decltype(fc_1)::OutputBuffer fc_1_out;\n-            alignas(CacheLineSize) decltype(ac_1)::OutputBuffer ac_1_out;\n-            alignas(CacheLineSize) decltype(fc_2)::OutputBuffer fc_2_out;\n+            alignas(CacheLineSize) typename decltype(ac_0)::OutputBuffer ac_0_out;\n+            alignas(CacheLineSize) typename decltype(fc_1)::OutputBuffer fc_1_out;\n+            alignas(CacheLineSize) typename decltype(ac_1)::OutputBuffer ac_1_out;\n+            alignas(CacheLineSize) typename decltype(fc_2)::OutputBuffer fc_2_out;\n \n             Buffer() { std::memset(this, 0, sizeof(*this)); }\n         };\n@@ -108,7 +122,7 @@ struct Network {\n         ac_sqr_0.propagate(buffer.fc_0_out, buffer.ac_sqr_0_out);\n         ac_0.propagate(buffer.fc_0_out, buffer.ac_0_out);\n         std::memcpy(buffer.ac_sqr_0_out + FC_0_OUTPUTS, buffer.ac_0_out,\n-                    FC_0_OUTPUTS * sizeof(decltype(ac_0)::OutputType));\n+                    FC_0_OUTPUTS * sizeof(typename decltype(ac_0)::OutputType));\n         fc_1.propagate(buffer.ac_sqr_0_out, buffer.fc_1_out);\n         ac_1.propagate(buffer.fc_1_out, buffer.ac_1_out);\n         fc_2.propagate(buffer.ac_1_out, buffer.fc_2_out);\ndiff --git a/src/nnue/nnue_feature_transformer.h b/src/nnue/nnue_feature_transformer.h\nindex 2008cf25f1d..9a162ac9853 100644\n--- a/src/nnue/nnue_feature_transformer.h\n+++ b/src/nnue/nnue_feature_transformer.h\n@@ -186,11 +186,6 @@ static constexpr int BestRegisterCount() {\n \n     return 1;\n }\n-\n-static constexpr int NumRegs =\n-  BestRegisterCount<vec_t, WeightType, TransformedFeatureDimensions, NumRegistersSIMD>();\n-static constexpr int NumPsqtRegs =\n-  BestRegisterCount<psqt_vec_t, PSQTWeightType, PSQTBuckets, NumRegistersSIMD>();\n     #if defined(__GNUC__)\n         #pragma GCC diagnostic pop\n     #endif\n@@ -198,6 +193,8 @@ static constexpr int NumPsqtRegs =\n \n \n // Input feature converter\n+template<IndexType                                 TransformedFeatureDimensions,\n+         Accumulator<TransformedFeatureDimensions> StateInfo::*accPtr>\n class FeatureTransformer {\n \n    private:\n@@ -205,6 +202,11 @@ class FeatureTransformer {\n     static constexpr IndexType HalfDimensions = TransformedFeatureDimensions;\n \n #ifdef VECTOR\n+    static constexpr int NumRegs =\n+      BestRegisterCount<vec_t, WeightType, TransformedFeatureDimensions, NumRegistersSIMD>();\n+    static constexpr int NumPsqtRegs =\n+      BestRegisterCount<psqt_vec_t, PSQTWeightType, PSQTBuckets, NumRegistersSIMD>();\n+\n     static constexpr IndexType TileHeight     = NumRegs * sizeof(vec_t) / 2;\n     static constexpr IndexType PsqtTileHeight = NumPsqtRegs * sizeof(psqt_vec_t) / 4;\n     static_assert(HalfDimensions % TileHeight == 0, \"TileHeight must divide HalfDimensions\");\n@@ -253,8 +255,8 @@ class FeatureTransformer {\n         update_accumulator<BLACK>(pos);\n \n         const Color perspectives[2]  = {pos.side_to_move(), ~pos.side_to_move()};\n-        const auto& accumulation     = pos.state()->accumulator.accumulation;\n-        const auto& psqtAccumulation = pos.state()->accumulator.psqtAccumulation;\n+        const auto& accumulation     = (pos.state()->*accPtr).accumulation;\n+        const auto& psqtAccumulation = (pos.state()->*accPtr).psqtAccumulation;\n \n         const auto psqt =\n           (psqtAccumulation[perspectives[0]][bucket] - psqtAccumulation[perspectives[1]][bucket])\n@@ -323,7 +325,7 @@ class FeatureTransformer {\n         // of the estimated gain in terms of features to be added/subtracted.\n         StateInfo *st = pos.state(), *next = nullptr;\n         int        gain = FeatureSet::refresh_cost(pos);\n-        while (st->previous && !st->accumulator.computed[Perspective])\n+        while (st->previous && !(st->*accPtr).computed[Perspective])\n         {\n             // This governs when a full feature refresh is needed and how many\n             // updates are better than just one full refresh.\n@@ -381,7 +383,7 @@ class FeatureTransformer {\n \n             for (; i >= 0; --i)\n             {\n-                states_to_update[i]->accumulator.computed[Perspective] = true;\n+                (states_to_update[i]->*accPtr).computed[Perspective] = true;\n \n                 const StateInfo* end_state = i == 0 ? computed_st : states_to_update[i - 1];\n \n@@ -402,9 +404,9 @@ class FeatureTransformer {\n             assert(states_to_update[0]);\n \n             auto accIn =\n-              reinterpret_cast<const vec_t*>(&st->accumulator.accumulation[Perspective][0]);\n+              reinterpret_cast<const vec_t*>(&(st->*accPtr).accumulation[Perspective][0]);\n             auto accOut = reinterpret_cast<vec_t*>(\n-              &states_to_update[0]->accumulator.accumulation[Perspective][0]);\n+              &(states_to_update[0]->*accPtr).accumulation[Perspective][0]);\n \n             const IndexType offsetR0 = HalfDimensions * removed[0][0];\n             auto            columnR0 = reinterpret_cast<const vec_t*>(&weights[offsetR0]);\n@@ -428,10 +430,10 @@ class FeatureTransformer {\n                                            vec_add_16(columnR0[k], columnR1[k]));\n             }\n \n-            auto accPsqtIn = reinterpret_cast<const psqt_vec_t*>(\n-              &st->accumulator.psqtAccumulation[Perspective][0]);\n+            auto accPsqtIn =\n+              reinterpret_cast<const psqt_vec_t*>(&(st->*accPtr).psqtAccumulation[Perspective][0]);\n             auto accPsqtOut = reinterpret_cast<psqt_vec_t*>(\n-              &states_to_update[0]->accumulator.psqtAccumulation[Perspective][0]);\n+              &(states_to_update[0]->*accPtr).psqtAccumulation[Perspective][0]);\n \n             const IndexType offsetPsqtR0 = PSQTBuckets * removed[0][0];\n             auto columnPsqtR0 = reinterpret_cast<const psqt_vec_t*>(&psqtWeights[offsetPsqtR0]);\n@@ -463,7 +465,7 @@ class FeatureTransformer {\n             {\n                 // Load accumulator\n                 auto accTileIn = reinterpret_cast<const vec_t*>(\n-                  &st->accumulator.accumulation[Perspective][j * TileHeight]);\n+                  &(st->*accPtr).accumulation[Perspective][j * TileHeight]);\n                 for (IndexType k = 0; k < NumRegs; ++k)\n                     acc[k] = vec_load(&accTileIn[k]);\n \n@@ -489,7 +491,7 @@ class FeatureTransformer {\n \n                     // Store accumulator\n                     auto accTileOut = reinterpret_cast<vec_t*>(\n-                      &states_to_update[i]->accumulator.accumulation[Perspective][j * TileHeight]);\n+                      &(states_to_update[i]->*accPtr).accumulation[Perspective][j * TileHeight]);\n                     for (IndexType k = 0; k < NumRegs; ++k)\n                         vec_store(&accTileOut[k], acc[k]);\n                 }\n@@ -499,7 +501,7 @@ class FeatureTransformer {\n             {\n                 // Load accumulator\n                 auto accTilePsqtIn = reinterpret_cast<const psqt_vec_t*>(\n-                  &st->accumulator.psqtAccumulation[Perspective][j * PsqtTileHeight]);\n+                  &(st->*accPtr).psqtAccumulation[Perspective][j * PsqtTileHeight]);\n                 for (std::size_t k = 0; k < NumPsqtRegs; ++k)\n                     psqt[k] = vec_load_psqt(&accTilePsqtIn[k]);\n \n@@ -525,8 +527,8 @@ class FeatureTransformer {\n \n                     // Store accumulator\n                     auto accTilePsqtOut = reinterpret_cast<psqt_vec_t*>(\n-                      &states_to_update[i]\n-                         ->accumulator.psqtAccumulation[Perspective][j * PsqtTileHeight]);\n+                      &(states_to_update[i]->*accPtr)\n+                         .psqtAccumulation[Perspective][j * PsqtTileHeight]);\n                     for (std::size_t k = 0; k < NumPsqtRegs; ++k)\n                         vec_store_psqt(&accTilePsqtOut[k], psqt[k]);\n                 }\n@@ -535,13 +537,12 @@ class FeatureTransformer {\n #else\n         for (IndexType i = 0; states_to_update[i]; ++i)\n         {\n-            std::memcpy(states_to_update[i]->accumulator.accumulation[Perspective],\n-                        st->accumulator.accumulation[Perspective],\n-                        HalfDimensions * sizeof(BiasType));\n+            std::memcpy((states_to_update[i]->*accPtr).accumulation[Perspective],\n+                        (st->*accPtr).accumulation[Perspective], HalfDimensions * sizeof(BiasType));\n \n             for (std::size_t k = 0; k < PSQTBuckets; ++k)\n-                states_to_update[i]->accumulator.psqtAccumulation[Perspective][k] =\n-                  st->accumulator.psqtAccumulation[Perspective][k];\n+                (states_to_update[i]->*accPtr).psqtAccumulation[Perspective][k] =\n+                  (st->*accPtr).psqtAccumulation[Perspective][k];\n \n             st = states_to_update[i];\n \n@@ -551,10 +552,10 @@ class FeatureTransformer {\n                 const IndexType offset = HalfDimensions * index;\n \n                 for (IndexType j = 0; j < HalfDimensions; ++j)\n-                    st->accumulator.accumulation[Perspective][j] -= weights[offset + j];\n+                    (st->*accPtr).accumulation[Perspective][j] -= weights[offset + j];\n \n                 for (std::size_t k = 0; k < PSQTBuckets; ++k)\n-                    st->accumulator.psqtAccumulation[Perspective][k] -=\n+                    (st->*accPtr).psqtAccumulation[Perspective][k] -=\n                       psqtWeights[index * PSQTBuckets + k];\n             }\n \n@@ -564,10 +565,10 @@ class FeatureTransformer {\n                 const IndexType offset = HalfDimensions * index;\n \n                 for (IndexType j = 0; j < HalfDimensions; ++j)\n-                    st->accumulator.accumulation[Perspective][j] += weights[offset + j];\n+                    (st->*accPtr).accumulation[Perspective][j] += weights[offset + j];\n \n                 for (std::size_t k = 0; k < PSQTBuckets; ++k)\n-                    st->accumulator.psqtAccumulation[Perspective][k] +=\n+                    (st->*accPtr).psqtAccumulation[Perspective][k] +=\n                       psqtWeights[index * PSQTBuckets + k];\n             }\n         }\n@@ -586,7 +587,7 @@ class FeatureTransformer {\n         // Refresh the accumulator\n         // Could be extracted to a separate function because it's done in 2 places,\n         // but it's unclear if compilers would correctly handle register allocation.\n-        auto& accumulator                 = pos.state()->accumulator;\n+        auto& accumulator                 = pos.state()->*accPtr;\n         accumulator.computed[Perspective] = true;\n         FeatureSet::IndexList active;\n         FeatureSet::append_active_indices<Perspective>(pos, active);\n@@ -663,12 +664,12 @@ class FeatureTransformer {\n         // Look for a usable accumulator of an earlier position. We keep track\n         // of the estimated gain in terms of features to be added/subtracted.\n         // Fast early exit.\n-        if (pos.state()->accumulator.computed[Perspective])\n+        if ((pos.state()->*accPtr).computed[Perspective])\n             return;\n \n         auto [oldest_st, _] = try_find_computed_accumulator<Perspective>(pos);\n \n-        if (oldest_st->accumulator.computed[Perspective])\n+        if ((oldest_st->*accPtr).computed[Perspective])\n         {\n             // Only update current position accumulator to minimize work.\n             StateInfo* states_to_update[2] = {pos.state(), nullptr};\n@@ -685,7 +686,7 @@ class FeatureTransformer {\n \n         auto [oldest_st, next] = try_find_computed_accumulator<Perspective>(pos);\n \n-        if (oldest_st->accumulator.computed[Perspective])\n+        if ((oldest_st->*accPtr).computed[Perspective])\n         {\n             if (next == nullptr)\n                 return;\ndiff --git a/src/position.cpp b/src/position.cpp\nindex 4fba3c234b7..ddc31888422 100644\n--- a/src/position.cpp\n+++ b/src/position.cpp\n@@ -684,10 +684,10 @@ void Position::do_move(Move m, StateInfo& newSt, bool givesCheck) {\n     ++st->pliesFromNull;\n \n     // Used by NNUE\n-    st->accumulator.computed[WHITE] = false;\n-    st->accumulator.computed[BLACK] = false;\n-    auto& dp                        = st->dirtyPiece;\n-    dp.dirty_num                    = 1;\n+    st->accumulatorBig.computed[WHITE]     = st->accumulatorBig.computed[BLACK] =\n+      st->accumulatorSmall.computed[WHITE] = st->accumulatorSmall.computed[BLACK] = false;\n+    auto& dp                                                                      = st->dirtyPiece;\n+    dp.dirty_num                                                                  = 1;\n \n     Color  us       = sideToMove;\n     Color  them     = ~us;\n@@ -964,15 +964,15 @@ void Position::do_null_move(StateInfo& newSt) {\n     assert(!checkers());\n     assert(&newSt != st);\n \n-    std::memcpy(&newSt, st, offsetof(StateInfo, accumulator));\n+    std::memcpy(&newSt, st, offsetof(StateInfo, accumulatorBig));\n \n     newSt.previous = st;\n     st             = &newSt;\n \n-    st->dirtyPiece.dirty_num        = 0;\n-    st->dirtyPiece.piece[0]         = NO_PIECE;  // Avoid checks in UpdateAccumulator()\n-    st->accumulator.computed[WHITE] = false;\n-    st->accumulator.computed[BLACK] = false;\n+    st->dirtyPiece.dirty_num               = 0;\n+    st->dirtyPiece.piece[0]                = NO_PIECE;  // Avoid checks in UpdateAccumulator()\n+    st->accumulatorBig.computed[WHITE]     = st->accumulatorBig.computed[BLACK] =\n+      st->accumulatorSmall.computed[WHITE] = st->accumulatorSmall.computed[BLACK] = false;\n \n     if (st->epSquare != SQ_NONE)\n     {\ndiff --git a/src/position.h b/src/position.h\nindex 7e0c3eefd77..34b53f4a558 100644\n--- a/src/position.h\n+++ b/src/position.h\n@@ -27,6 +27,7 @@\n \n #include \"bitboard.h\"\n #include \"nnue/nnue_accumulator.h\"\n+#include \"nnue/nnue_architecture.h\"\n #include \"types.h\"\n \n namespace Stockfish {\n@@ -57,8 +58,9 @@ struct StateInfo {\n     int        repetition;\n \n     // Used by NNUE\n-    Eval::NNUE::Accumulator accumulator;\n-    DirtyPiece              dirtyPiece;\n+    Eval::NNUE::Accumulator<Eval::NNUE::TransformedFeatureDimensionsBig>   accumulatorBig;\n+    Eval::NNUE::Accumulator<Eval::NNUE::TransformedFeatureDimensionsSmall> accumulatorSmall;\n+    DirtyPiece                                                             dirtyPiece;\n };\n \n \ndiff --git a/src/uci.cpp b/src/uci.cpp\nindex 8e93eee6dc5..be902277984 100644\n--- a/src/uci.cpp\n+++ b/src/uci.cpp\n@@ -37,6 +37,7 @@\n #include \"misc.h\"\n #include \"movegen.h\"\n #include \"nnue/evaluate_nnue.h\"\n+#include \"nnue/nnue_architecture.h\"\n #include \"position.h\"\n #include \"search.h\"\n #include \"thread.h\"\n@@ -320,7 +321,7 @@ void UCI::loop(int argc, char* argv[]) {\n             std::string                f;\n             if (is >> std::skipws >> f)\n                 filename = f;\n-            Eval::NNUE::save_eval(filename);\n+            Eval::NNUE::save_eval(filename, Eval::NNUE::Big);\n         }\n         else if (token == \"--help\" || token == \"help\" || token == \"--license\" || token == \"license\")\n             sync_cout\ndiff --git a/src/ucioption.cpp b/src/ucioption.cpp\nindex 087882f11b8..f8cbcc53077 100644\n--- a/src/ucioption.cpp\n+++ b/src/ucioption.cpp\n@@ -82,7 +82,9 @@ void init(OptionsMap& o) {\n     o[\"SyzygyProbeDepth\"] << Option(1, 1, 100);\n     o[\"Syzygy50MoveRule\"] << Option(true);\n     o[\"SyzygyProbeLimit\"] << Option(7, 0, 7);\n-    o[\"EvalFile\"] << Option(EvalFileDefaultName, on_eval_file);\n+    o[\"EvalFile\"] << Option(EvalFileDefaultNameBig, on_eval_file);\n+    // Enable this after fishtest workers support EvalFileSmall\n+    // o[\"EvalFileSmall\"] << Option(EvalFileDefaultNameSmall, on_eval_file);\n }\n \n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Implement a proper accumulator interface with virtual methods is suggested, but may be unnecessary for the initial PR; consider better solutions.\n\n2. Rename variables `big` and `small` for clarity as they conflict with boolean usage. Propose more intuitive names like `net0` and `net1`.\n\n3. The `simple_eval()` function was moved back to the eval namespace; maintain consistency unless there's a strong rationale for separating it.\n\n4. Small net name not declared in the binary; ensure it's correctly implemented to allow functionality.\n\n5. Consider handling multiple networks by modifying `EvalFile` to check headers, enhancing training integration, and user flexibility, while managing detection consistency in UCI options.\n\n6. Address issues with Fishtest and worker problems; confirm with relevant team members for broader integration challenges."
      }
    ],
    "codediff_length": 46275
  },
  {
    "index": 85,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/script/make_release.py b/script/make_release.py\nnew file mode 100644\nindex 00000000000..0d964de67d5\n--- /dev/null\n+++ b/script/make_release.py\n@@ -0,0 +1,466 @@\n+#!/usr/bin/env python3\n+\n+# For usage example use:\n+#   python3 ./make_release.py --help\n+\n+import subprocess\n+import threading\n+import os\n+import sys\n+import re\n+import shutil\n+import uuid\n+import stat\n+import concurrent.futures\n+import argparse\n+import logging\n+import platform\n+import traceback\n+from zipfile import ZipFile\n+\n+def get_logger():\n+    logger = logging.getLogger('make_release')\n+    logger.setLevel(logging.DEBUG)\n+    handler = logging.StreamHandler()\n+    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', '%H:%M:%S')\n+    handler.setFormatter(formatter)\n+    logger.addHandler(handler)\n+    return logger\n+\n+parser = argparse.ArgumentParser(description='Stockfish release maker', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n+parser.add_argument('--sde', default=None, type=str,\n+                    help='Absolute path to Intel SDE application. If not specified it will not be used. If specified it will be used as a fallback for architectures that fail to compile.')\n+parser.add_argument('--concurrency', default=1, type=int,\n+                    help='The maximum number of jobs to run concurrently.')\n+parser.add_argument('--repository', default='https://github.com/official-stockfish/Stockfish.git', type=str,\n+                    help='The path to the repository to clone.')\n+parser.add_argument('--clone-dir', default='cloned', type=str,\n+                    help='The directory to clone the repository to.')\n+parser.add_argument('--out-dir', default='out', type=str,\n+                    help='The directory that shall contain the resulting binaries.')\n+parser.add_argument('--build-type', default='profile-build', type=str,\n+                    help='The build type to use in make.')\n+parser.add_argument('--prefix', default='', type=str,\n+                    help='The string put in the binary name after stockfish- but before -arch. For example \"win\" or \"linux\". Will be ommited if empty.')\n+parser.add_argument('--verbose', default=False, action='store_true',\n+                    help='Keep output of running programs.')\n+parser.add_argument('--keep-logs', default=False, action='store_true',\n+                    help='Whether to keep logs in the output directory. Incompatible with --verbose.')\n+parser.add_argument('--bench', default=None, type=int,\n+                    help='If specified the bench of resulting binaries will be verified and must match this value.')\n+parser.add_argument('--max-num-workers', default=None, type=int,\n+                    help='Sometimes too many compilation processes running in parallel can cause issues. If this is specified it will limit the number of parallel arch builds to this number. Remaining threads specified by concurrency will be used for make jobs.')\n+parser.add_argument('--compiler', default=None, type=str,\n+                    help='If specified this will be passed as COMP to the make script.')\n+parser.add_argument('--clone-depth', default=25, type=int,\n+                    help='The number of commits to clone history of. For retrieving bench more than one might be needed. Default is setup such that it should work for all normal cases.')\n+parser.add_argument('--max-tries', default=1, type=int,\n+                    help='How many times a build for a single target can be attempted. Builds fail sometimes for weird reasons.')\n+parser.add_argument('archs', nargs='*', default=None, type=str,\n+                    help='A list of architectures to compile. If not provided then most sensible archs will be built.')\n+\n+args = parser.parse_args()\n+\n+if args.verbose and args.keep_logs:\n+    parser.error('--verbose and --keep-logs are currently not compatible.')\n+\n+SDE_PATH = args.sde\n+NUM_THREADS = args.concurrency\n+CLONE_DIR = args.clone_dir\n+CLONE_DEPTH = args.clone_depth\n+OUT_DIR = args.out_dir\n+REPO = args.repository\n+BUILD_TYPE = args.build_type\n+ARCHS = args.archs\n+STDOUT = None if args.verbose else subprocess.DEVNULL\n+STDERR = subprocess.STDOUT\n+PREFIX = args.prefix\n+IS_WINDOWS = 'windows' in platform.system().lower()\n+EXE_SUFFIX = '.exe' if IS_WINDOWS else ''\n+ZIP_SUFFIX = '.zip'\n+EXPECTED_BENCH = args.bench\n+MAX_NUM_WORKERS = NUM_THREADS if args.max_num_workers is None else args.max_num_workers\n+MAX_TRIES = args.max_tries\n+COMPILER = args.compiler\n+LOGGER = get_logger()\n+\n+def remove_readonly(func, path, _):\n+    '''\n+    Clear the readonly bit and reattempt the removal\n+    '''\n+    os.chmod(path, stat.S_IWRITE)\n+    func(path)\n+\n+def clone_stockfish(destination_dir, repository, branch='master', clone_depth=1):\n+    '''\n+    Clone, with depth 1, the specified `branch` from the `repository`.\n+    The repository is cloned to the `destination_dir`.\n+    '''\n+    LOGGER.info('Cloning branch {} from repository {} into {}' \\\n+                .format(branch, repository, destination_dir))\n+\n+    command = ['git', 'clone', '--branch', branch, '--depth', str(clone_depth), repository, destination_dir]\n+    LOGGER.info('Cloning command is: {}'.format(' '.join(command)))\n+\n+    subprocess.run( \\\n+        command, \\\n+        encoding='utf-8', stdout=STDOUT, stderr=STDERR)\n+\n+    LOGGER.info('Cloning finished.')\n+\n+def download_net(repo_dir):\n+    LOGGER.info('Executing `make net`.')\n+    ret = subprocess.run(['make', 'net'], cwd=os.path.join(repo_dir, 'src'))\n+    if ret.returncode != 0:\n+        LOGGER.error('Failed to download the net.')\n+        raise Exception('Failed to download the net')\n+    else:\n+        LOGGER.info('Sucessfully downloaded the net.')\n+\n+class DummyContextManager():\n+    '''\n+    Useful for \"conditional\" `with` statements.\n+    '''\n+\n+    def __enter__(self):\n+        return None\n+\n+    def __exit__(self, exc_type, exc_value, traceback):\n+        return False\n+\n+class TemporaryDirectory():\n+    '''\n+    Maintains a temporary directory with a unique name.\n+    '''\n+\n+    def __init__(self, prefix='', add_uuid=True):\n+        self.path = prefix\n+        if add_uuid:\n+            self.path += str(uuid.uuid4())\n+        os.mkdir(self.path)\n+        LOGGER.info('Created temporary directory {}'.format(self.path))\n+\n+    def __enter__(self):\n+        return self\n+\n+    def __exit__(self, exc_type, exc_value, traceback):\n+        shutil.rmtree(self.path, onerror=remove_readonly)\n+        LOGGER.info('Removed temporary directory {}'.format(self.path))\n+\n+def get_bench_from_git_history(repo_dir):\n+    command = ['git', '--git-dir', os.path.join(repo_dir, '.git'), 'log']\n+    completed_process = subprocess.run(command, encoding='utf-8', stdout=subprocess.PIPE, universal_newlines=True)\n+    output = completed_process.stdout\n+    try:\n+        m = re.search('[Bb]ench[ :]+(\\\\d*)', output)\n+        return int(m.group(1))\n+    except:\n+        return None\n+\n+def pack_binary_with_source(dest_dir, repo_dir, src_file, dest_filename):\n+    '''\n+    Takes the src_file (expected to be stockfish's binary) and\n+    the `repo_dir` and produces a .zip archive with them both.\n+    The archive is put into `dest_dir` and has the following structure:\n+    `artifact_name` is the stem of `dest_filename`\n+    - `dest_dir`\n+        - `artifact_name`+ZIP_SUFFIX\n+            - `artifact_name`\n+                - `Stockfish`\n+                    - `src`\n+                    - rest of the repo, without .git\n+                - `artifact_name`+EXE_SUFFIX\n+    '''\n+\n+    artifact_name = os.path.splitext(dest_filename)[0]\n+    archive_filename = artifact_name + ZIP_SUFFIX\n+    archive_path = os.path.join(dest_dir, archive_filename)\n+\n+    LOGGER.info('Creating archive {}.'.format(archive_path))\n+\n+    with ZipFile(archive_path, 'w') as archive:\n+        # Write the stockfish binary, AUTHORS, Top CPU Contributors.txt,\n+        # and Copying.txt files to the main directory.\n+        main_level_files = [\n+            (src_file, dest_filename),\n+            (os.path.join(repo_dir, 'AUTHORS'), 'AUTHORS'),\n+            (os.path.join(repo_dir, 'Copying.txt'), 'Copying.txt'),\n+            (os.path.join(repo_dir, 'Top CPU Contributors.txt'), 'Top CPU Contributors.txt')\n+        ]\n+        for path_from, name in main_level_files:\n+            archive.write(path_from, os.path.join(artifact_name, name))\n+\n+        # Write the source directory, excluding .git and *.nnue.\n+        for path, subdirs, files in os.walk(repo_dir, followlinks=False):\n+            if '.git' in path:\n+                continue\n+\n+            for filename in files:\n+                if filename.endswith('.nnue'):\n+                    continue\n+\n+                full_path = os.path.join(path, filename)\n+                rel_path = os.path.relpath(full_path, repo_dir)\n+                internal_path = os.path.join(artifact_name, 'Stockfish', rel_path)\n+\n+                archive.write(full_path, internal_path)\n+\n+    success = True\n+    with ZipFile(archive_path, 'r') as archive:\n+        if archive.testzip() is not None:\n+            success = False\n+\n+    if not success:\n+        os.remove(archive_path)\n+        raise Exception('The CRC check for {} failed.'.format(archive_path))\n+\n+    LOGGER.info('Created archive {}.'.format(archive_path))\n+\n+def run_bench(stockfish):\n+    command = [stockfish, 'bench']\n+    if SDE_PATH:\n+        command = [SDE_PATH, '--'] + command\n+\n+    proc = subprocess.run(command, stderr=subprocess.PIPE, stdout=subprocess.DEVNULL, universal_newlines=True)\n+    return int([line for line in proc.stderr.splitlines() if 'Nodes searched' in line][0].split(':')[1].strip())\n+\n+def compile_target(\n+    *,\n+    repo_dir,\n+    out_dir,\n+    build_type='profile-build',\n+    arch='x86-64-modern',\n+    prefix='',\n+    expected_bench=None,\n+    num_threads=1,\n+    compiler=None):\n+    '''\n+    This function performs the following:\n+    1. Copies the contents of `repo_dir` into a temporary directory.\n+    2. Runs `make clean` in that temporary directory + ./src/\n+    3. Runs `make `build_type`` for the specified `arch`.\n+       NOTE: If SDE_PATH is not empty then SDE_PATH is set for all make commands.\n+    4. Copies the resulting executable file into `out_dir` with a given `prefix`\n+    '''\n+    assert num_threads >= 1\n+\n+    if prefix != '':\n+        prefix = '-' + prefix\n+\n+    if args.keep_logs:\n+        # If the user wants to keep logs a file is created and stdout redirected to it.\n+        # Otherwise we use the dummy context manager and stdout is not redirected.\n+        logfile_name = os.path.join(out_dir, 'stockfish{}-{}-{}.log'.format(prefix, build_type, arch))\n+        LOGGER.info('{}: Creating log file at {}.'.format(arch, logfile_name))\n+\n+        logfile = open(logfile_name, 'w')\n+        stdout = logfile\n+    else:\n+        logfile = DummyContextManager()\n+        stdout = STDOUT\n+\n+    with logfile:\n+        with TemporaryDirectory('./stockfish-{}-{}-'.format(build_type, arch)) as copy_dir:\n+            src_dir = os.path.join(copy_dir.path, 'src')\n+\n+            LOGGER.info('{}: Copying original files from {} to {}'.format(arch, repo_dir, copy_dir.path))\n+\n+            shutil.copytree(os.path.join(repo_dir, 'src'), os.path.join(copy_dir.path, 'src'))\n+\n+            LOGGER.info('{}: Running `make clean`'.format(arch))\n+\n+            subprocess.run( \\\n+                ['make', 'clean'], \\\n+                cwd=src_dir, stdout=stdout, stderr=STDERR)\n+\n+            # We form the make command used to build stockfish.\n+            # If SDE_PATH is given the only thing that needs to be done is\n+            # it needs to be passed to the make script.\n+            # There is no downside to always running under SDE if provided.\n+            make_command = ['make', build_type, 'ARCH={}'.format(arch)]\n+            if SDE_PATH:\n+                make_command += ['SDE_PATH=\\'{}\\''.format(SDE_PATH)]\n+            if compiler:\n+                make_command += ['COMP={}'.format(compiler)]\n+            if num_threads > 1:\n+                make_command += ['-j{}'.format(num_threads)]\n+\n+            make_command_log = ' '.join(make_command)\n+            LOGGER.info('{}: Running `{}`' \\\n+                .format(arch, make_command_log))\n+\n+            ret = subprocess.run(make_command, cwd=src_dir, stdout=stdout, stderr=STDERR)\n+\n+            # This will also detect profile-builds that failed due to illegal instructions\n+            # but it requires user input on windows (closing the error dialog)\n+            # unless ran under msys or equivalent.\n+            # A proper solution would query the ISA, for example using gcc, but\n+            # normally for such cases SDE_PATH will be specified.\n+            if ret.returncode != 0:\n+                LOGGER.error('{}: Error running `{}`. Exit code: {}' \\\n+                            .format(arch, make_command_log, ret.returncode))\n+                raise Exception('Make script failed')\n+            else:\n+                src_file = os.path.join(src_dir, 'stockfish' + EXE_SUFFIX)\n+\n+                LOGGER.info('{}: Finished build of {}.'.format(arch, src_file))\n+                LOGGER.info('{}: Running `make strip`.'.format(arch))\n+\n+                make_strip_command = ['make', 'strip']\n+                if compiler:\n+                    make_strip_command += ['COMP={}'.format(compiler)]\n+                subprocess.run(make_strip_command, cwd=src_dir, stdout=stdout, stderr=STDERR)\n+\n+                LOGGER.info('{}: Verifying bench.'.format(arch))\n+\n+                bench = run_bench(src_file)\n+                if bench == expected_bench:\n+                    LOGGER.info('{}: Correct bench: {}'.format(arch, bench))\n+                    LOGGER.info('{}: Producing the release archive.'.format(arch))\n+                    dest_filename = 'stockfish{}-{}{}'.format(prefix, arch, EXE_SUFFIX)\n+                    pack_binary_with_source(out_dir, repo_dir, src_file, dest_filename)\n+                else:\n+                    LOGGER.error('{}: Invalid bench. Expected {}, got {}.'.format(arch, expected_bench, bench))\n+                    raise Exception('Invalid bench')\n+\n+def get_possible_targets(repo_dir):\n+    '''\n+    Parse the output of `make help` and extract the available targets\n+    '''\n+    p = subprocess.run(['make', 'help'], cwd=os.path.join(repo_dir, 'src'),\n+                       encoding='utf-8', stdout=subprocess.PIPE, universal_newlines=True)\n+\n+    targets = []\n+    read_targets = False\n+\n+    for line in p.stdout.splitlines():\n+        if 'Supported compilers:' in line:\n+            read_targets = False\n+        if read_targets and len(line.split()) > 1:\n+            targets.append(line.split()[0])\n+        if 'Supported archs:' in line:\n+            read_targets = True\n+\n+    targets = [target for target in targets if \"apple\" not in target if \"arm\" not in target if \"ppc\" not in target]\n+\n+    return targets\n+\n+def main():\n+    if os.path.exists(CLONE_DIR):\n+        # We can't rely on ignoring errors for this, because\n+        # then we also ignore write protection errors...\n+        # So we have to take this race condition.\n+        shutil.rmtree(CLONE_DIR, onerror=remove_readonly)\n+\n+    with TemporaryDirectory(CLONE_DIR, False):\n+        try:\n+            os.mkdir(OUT_DIR)\n+        except FileExistsError as e:\n+            LOGGER.warning('Directory {} already exists.'.format(OUT_DIR))\n+\n+        clone_stockfish(CLONE_DIR, REPO, clone_depth=CLONE_DEPTH)\n+        download_net(CLONE_DIR)\n+\n+        expected_bench = EXPECTED_BENCH if EXPECTED_BENCH is not None else get_bench_from_git_history(CLONE_DIR)\n+        if expected_bench is None:\n+            LOGGER.error('Could not retrieve bench from git history. Exiting.')\n+            return\n+        else:\n+            LOGGER.info('Expected bench is {}.'.format(expected_bench))\n+\n+        archs = ARCHS if ARCHS else get_possible_targets(CLONE_DIR)\n+\n+        if not archs:\n+            LOGGER.info('No archs specified. Exiting.')\n+            return\n+\n+        num_tries = dict()\n+        successfully_completed = dict()\n+        for arch in archs:\n+            num_tries[arch] = 0\n+            successfully_completed[arch] = False\n+\n+        # Compute how many threads each worker can use\n+        # Try to find as equal distribution as possible\n+        num_workers = min([NUM_THREADS, len(archs), MAX_NUM_WORKERS])\n+        num_threads_per_worker = [1] * num_workers\n+        for i in range(NUM_THREADS - num_workers):\n+            num_threads_per_worker[i % num_workers] += 1\n+        num_workers_by_thread_id = dict()\n+        lock = threading.Lock()\n+\n+        def run_task(arch):\n+            try:\n+                with lock:\n+                    thread_id = threading.get_ident()\n+                    if not thread_id in num_workers_by_thread_id:\n+                        # On thread discovery get the next available thread count\n+                        # We expect this to be entered at most NUM_WORKERS times\n+                        assert len(num_threads_per_worker) > 0\n+                        num_workers_by_thread_id[thread_id] = num_threads_per_worker[0]\n+                        num_threads_per_worker.pop(0)\n+                    num_threads = num_workers_by_thread_id[thread_id]\n+\n+                compile_target(\n+                    repo_dir=CLONE_DIR,\n+                    out_dir=OUT_DIR,\n+                    build_type=BUILD_TYPE,\n+                    arch=arch,\n+                    prefix=PREFIX,\n+                    expected_bench=expected_bench,\n+                    num_threads=num_threads,\n+                    compiler=COMPILER)\n+\n+                return True\n+\n+            except Exception as e:\n+                LOGGER.error('Exception: {}'.format(e))\n+                traceback.print_exc()\n+                return False\n+\n+        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n+            tasks = dict()\n+            for arch in archs:\n+                LOGGER.info('Scheduling ARCH={}. Try 1 out of {}'.format(arch, MAX_TRIES))\n+                num_tries[arch] += 1\n+                future = executor.submit(run_task, arch)\n+                tasks[future] = arch\n+\n+            for future in concurrent.futures.as_completed(tasks):\n+                arch = tasks[future]\n+                success = future.result()\n+                if success:\n+                    # If the build was successful then note it. We're done with this target\n+                    LOGGER.info('Sucessfully finished building {}'.format(arch))\n+                    successfully_completed[arch] = True\n+                else:\n+                    # If the build was not succesfull we retry, unless max number of tries was reached.\n+                    LOGGER.info('Failed building {} in an attempt {} out of {}'.format(arch, num_tries[arch], MAX_TRIES))\n+                    if num_tries[arch] < MAX_TRIES:\n+                        LOGGER.info('Scheduling ARCH={}. Try {} out of {}'.format(arch, num_tries[arch]+1, MAX_TRIES))\n+                        num_tries[arch] += 1\n+                        future = executor.submit(run_task, arch)\n+                        tasks[future] = arch\n+\n+    num_successful = list(successfully_completed.values()).count(True)\n+    num_failed = len(successfully_completed) - num_successful\n+    msg = 'Finished all tasks. {} successful, {} failed.'.format(num_successful, num_failed)\n+    if num_failed == 0:\n+        LOGGER.info(msg)\n+    else:\n+        LOGGER.info(msg)\n+\n+    for arch, success in sorted(successfully_completed.items(), key=lambda x: -int(x[1])):\n+        msg = '{}: {} after {} tries.'.format(arch, 'Success' if success else 'Failed', num_tries[arch])\n+        if success:\n+            LOGGER.info(msg)\n+        else:\n+            LOGGER.error(msg)\n+\n+    if num_failed == 0:\n+        return 0\n+    else:\n+        return 1\n+\n+if __name__ == '__main__':\n+    sys.exit(main())\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Bugs/Errors**: \n   - Fix the error message regarding `--verbose and --keep-logs` - change \"incompabile\" to \"incompatible\". \n   - Address `NameError: name 'make_command_log' is not defined` in `compile_target`.\n\n2. **Implementation Suggestions**:\n   - Use `pathlib` instead of `os` for path operations (Python 3.4+).\n   - Consider adding the `--make-jobs` argument to facilitate better thread distribution during builds.\n   - When setting default architectures, use `DEFAULT_ARCHS = make_targets()`.\n\n3. **Security/Performance Concerns**: \n   - Ensure that sensitive paths aren't logged when using subprocess.\n\n4. **Next Steps**:\n   - Investigate the execution environment differences on Windows.\n   - Implement zipping of binaries and source code as per the suggested enhancements.\n   - Limit Git clone depth to 25 to ensure necessary history for benchmarking while avoiding excessive history."
      }
    ],
    "codediff_length": 19941
  },
  {
    "index": 86,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/search.cpp b/src/search.cpp\nindex 7873e7dc552..793b5bbcae3 100644\n--- a/src/search.cpp\n+++ b/src/search.cpp\n@@ -45,10 +45,8 @@ namespace Search {\n namespace Tablebases {\n \n   int Cardinality;\n-  bool RootInTB;\n-  bool UseRule50;\n   Depth ProbeDepth;\n-  Value Score;\n+  WDLScore DrawScore;\n }\n \n namespace TB = Tablebases;\n@@ -150,6 +148,7 @@ namespace {\n   void update_pv(Move* pv, Move move, Move* childPv);\n   void update_continuation_histories(Stack* ss, Piece pc, Square to, int bonus);\n   void update_stats(const Position& pos, Stack* ss, Move move, Move* quiets, int quietsCnt, int bonus);\n+  Value probe_tb(Position& pos, Stack* ss, Value alpha, Value beta, Depth* depth, TTEntry* tte);\n \n   // perft() is our utility to verify move generation. All the leaf nodes up\n   // to the given depth are generated and counted, and the sum is returned.\n@@ -243,6 +242,18 @@ void MainThread::search() {\n   DrawValue[ us] = VALUE_DRAW - Value(contempt);\n   DrawValue[~us] = VALUE_DRAW + Value(contempt);\n \n+  // Set TB probing parameters\n+  TB::DrawScore = Options[\"Syzygy50MoveRule\"] ? TB::WDLCursedWin : TB::WDLDraw;\n+  TB::ProbeDepth = Options[\"SyzygyProbeDepth\"] * ONE_PLY;\n+  TB::Cardinality = Options[\"SyzygyProbeLimit\"];\n+\n+  // Skip TB probing when no TB found: !TBLargest -> !TB::Cardinality\n+  if (TB::Cardinality > TB::MaxCardinality)\n+  {\n+      TB::Cardinality = TB::MaxCardinality;\n+      TB::ProbeDepth = DEPTH_ZERO; // Hack!\n+  }\n+\n   if (rootMoves.empty())\n   {\n       rootMoves.emplace_back(MOVE_NONE);\n@@ -330,6 +341,7 @@ void Thread::search() {\n   MainThread* mainThread = (this == Threads.main() ? Threads.main() : nullptr);\n \n   std::memset(ss-4, 0, 7 * sizeof(Stack));\n+  ss->tbCardinality = TB::Cardinality;\n   for (int i = 4; i > 0; i--)\n      (ss-i)->contHistory = &this->contHistory[NO_PIECE][0]; // Use as sentinel\n \n@@ -587,6 +599,7 @@ namespace {\n     ss->currentMove = (ss+1)->excludedMove = bestMove = MOVE_NONE;\n     ss->contHistory = &thisThread->contHistory[NO_PIECE][0];\n     (ss+2)->killers[0] = (ss+2)->killers[1] = MOVE_NONE;\n+    (ss+1)->tbCardinality = ss->tbCardinality;\n     Square prevSq = to_sq((ss-1)->currentMove);\n \n     // Step 4. Transposition table lookup. We don't want the score of a partial\n@@ -631,34 +644,18 @@ namespace {\n     }\n \n     // Step 4a. Tablebase probe\n-    if (!rootNode && TB::Cardinality)\n+    if (!rootNode && ss->tbCardinality)\n     {\n         int piecesCount = pos.count<ALL_PIECES>();\n \n-        if (    piecesCount <= TB::Cardinality\n-            && (piecesCount <  TB::Cardinality || depth >= TB::ProbeDepth)\n-            &&  pos.rule50_count() == 0\n+        if (    piecesCount <= ss->tbCardinality\n+            && (piecesCount <  ss->tbCardinality || depth >= TB::ProbeDepth)\n             && !pos.can_castle(ANY_CASTLING))\n         {\n-            TB::ProbeState err;\n-            TB::WDLScore v = Tablebases::probe_wdl(pos, &err);\n-\n-            if (err != TB::ProbeState::FAIL)\n-            {\n-                thisThread->tbHits.fetch_add(1, std::memory_order_relaxed);\n-\n-                int drawScore = TB::UseRule50 ? 1 : 0;\n-\n-                value =  v < -drawScore ? -VALUE_MATE + MAX_PLY + ss->ply\n-                       : v >  drawScore ?  VALUE_MATE - MAX_PLY - ss->ply\n-                                        :  VALUE_DRAW + 2 * v * drawScore;\n-\n-                tte->save(posKey, value_to_tt(value, ss->ply), BOUND_EXACT,\n-                          std::min(DEPTH_MAX - ONE_PLY, depth + 6 * ONE_PLY),\n-                          MOVE_NONE, VALUE_NONE, TT.generation());\n+            value = probe_tb(pos, ss, alpha, beta, &depth, tte);\n \n+            if (value != VALUE_NONE)\n                 return value;\n-            }\n         }\n     }\n \n@@ -1454,6 +1451,91 @@ namespace {\n     return best;\n   }\n \n+\n+  // probe_tb() is called by search after TT probe to look up the position in\n+  // tablebases, if it is found we return immediately or continue the search\n+  // eventually with reduced depth according to the case.\n+\n+  Value probe_tb(Position& pos, Stack* ss, Value alpha, Value beta, Depth* depth, TTEntry* tte) {\n+\n+    Key posKey = pos.key() ^ Key(ss->excludedMove);\n+    Thread* thisThread = pos.this_thread();\n+\n+    TB::ProbeState err;\n+    TB::WDLScore wdl = Tablebases::probe_wdl(pos, &err);\n+\n+    thisThread->tbHits.fetch_add(1, std::memory_order_relaxed);\n+\n+    if (err == TB::ProbeState::FAIL)\n+    {}\n+    // Win or loss scores are reliable only if we are probing after a\n+    // rule50 reset move. Instead draw scores are reliable in any case.\n+    else if (pos.rule50_count() == 0 || abs(wdl) <= TB::DrawScore)\n+    {\n+        Value value =  wdl >  TB::DrawScore ?  VALUE_MATE - MAX_PLY - ss->ply\n+                     : wdl < -TB::DrawScore ? -VALUE_MATE + MAX_PLY + ss->ply\n+                                            :  VALUE_DRAW + 2 * wdl;\n+\n+        Bound b =  wdl >  TB::DrawScore ? BOUND_LOWER\n+                 : wdl < -TB::DrawScore ? BOUND_UPPER : BOUND_EXACT;\n+\n+        // Use TB scores as lower/upper bounds, a draw score is BOUND_EXACT\n+        // and is always considered even if value is within (alpha, beta)\n+        if (   (value >= beta  && b == BOUND_LOWER)\n+            || (value <= alpha && b == BOUND_UPPER)\n+            ||  b == BOUND_EXACT)\n+        {\n+            // It is far if ply >= (RootDepth - LMR) / 3, so that at a\n+            // given ply, nodes with high LMR are considered farther\n+            // from root than nodes near the PV line.\n+            bool farFromRoot = ss->ply - *depth / (2 * ONE_PLY) >= 0;\n+\n+            // When in midgame or is a draw save in TT and return\n+            if (farFromRoot || b == BOUND_EXACT)\n+            {\n+                tte->save(posKey, value_to_tt(value, ss->ply), b,\n+                          std::min(DEPTH_MAX - ONE_PLY, *depth + 6 * ONE_PLY),\n+                          MOVE_NONE, VALUE_NONE, TT.generation());\n+                return value;\n+            }\n+\n+            // When in endgame proceed with a reduced search\n+            *depth = std::max(*depth / 2, ONE_PLY);\n+            ss->tbCardinality = 0;\n+        }\n+    }\n+    // If rootPos is in TB and we can't rely on WDL score, then we have\n+    // to use the big artillery to differentiate between a win/loss and\n+    // a cursed/blessed draw. This is critical because search alone will\n+    // detect it only at ply 101...too late.\n+    else if (   (ss-1)->ply == 1\n+             && pos.rule50_count() > 0\n+             && TB::DrawScore == TB::WDLCursedWin)\n+    {\n+        assert(abs(wdl) > TB::DrawScore);\n+        assert(!pos.captured_piece()); // Root is in TB\n+\n+        int dtz = Tablebases::probe_dtz(pos, &err);\n+\n+        assert(dtz != 0 || err == TB::ProbeState::FAIL);\n+\n+        // If it is a draw under 50-move rule save in TT and return\n+        if (   err != TB::ProbeState::FAIL\n+            && abs(dtz) + pos.rule50_count() > 100)\n+        {\n+            wdl = dtz > 0 ? TB::WDLCursedWin : TB::WDLBlessedLoss;\n+            Value value = VALUE_DRAW + 2 * wdl;\n+\n+            tte->save(posKey, value_to_tt(value, ss->ply), BOUND_EXACT,\n+                      std::min(DEPTH_MAX - ONE_PLY, *depth + 6 * ONE_PLY),\n+                      MOVE_NONE, VALUE_NONE, TT.generation());\n+            return value;\n+        }\n+    }\n+    return VALUE_NONE;\n+  }\n+\n+\n } // namespace\n \n   // check_time() is used to print debug info and, more importantly, to detect\n@@ -1501,7 +1583,7 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n   size_t PVIdx = pos.this_thread()->PVIdx;\n   size_t multiPV = std::min((size_t)Options[\"MultiPV\"], rootMoves.size());\n   uint64_t nodesSearched = Threads.nodes_searched();\n-  uint64_t tbHits = Threads.tb_hits() + (TB::RootInTB ? rootMoves.size() : 0);\n+  uint64_t tbHits = Threads.tb_hits();\n \n   for (size_t i = 0; i < multiPV; ++i)\n   {\n@@ -1513,9 +1595,6 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n       Depth d = updated ? depth : depth - ONE_PLY;\n       Value v = updated ? rootMoves[i].score : rootMoves[i].previousScore;\n \n-      bool tb = TB::RootInTB && abs(v) < VALUE_MATE - MAX_PLY;\n-      v = tb ? TB::Score : v;\n-\n       if (ss.rdbuf()->in_avail()) // Not at first line\n           ss << \"\\n\";\n \n@@ -1525,7 +1604,7 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n          << \" multipv \"  << i + 1\n          << \" score \"    << UCI::value(v);\n \n-      if (!tb && i == PVIdx)\n+      if (i == PVIdx)\n           ss << (v >= beta ? \" lowerbound\" : v <= alpha ? \" upperbound\" : \"\");\n \n       ss << \" nodes \"    << nodesSearched\n@@ -1574,43 +1653,3 @@ bool RootMove::extract_ponder_from_tt(Position& pos) {\n     pos.undo_move(pv[0]);\n     return pv.size() > 1;\n }\n-\n-void Tablebases::filter_root_moves(Position& pos, Search::RootMoves& rootMoves) {\n-\n-    RootInTB = false;\n-    UseRule50 = Options[\"Syzygy50MoveRule\"];\n-    ProbeDepth = Options[\"SyzygyProbeDepth\"] * ONE_PLY;\n-    Cardinality = Options[\"SyzygyProbeLimit\"];\n-\n-    // Skip TB probing when no TB found: !TBLargest -> !TB::Cardinality\n-    if (Cardinality > MaxCardinality)\n-    {\n-        Cardinality = MaxCardinality;\n-        ProbeDepth = DEPTH_ZERO;\n-    }\n-\n-    if (Cardinality < popcount(pos.pieces()) || pos.can_castle(ANY_CASTLING))\n-        return;\n-\n-    // If the current root position is in the tablebases, then RootMoves\n-    // contains only moves that preserve the draw or the win.\n-    RootInTB = root_probe(pos, rootMoves, TB::Score);\n-\n-    if (RootInTB)\n-        Cardinality = 0; // Do not probe tablebases during the search\n-\n-    else // If DTZ tables are missing, use WDL tables as a fallback\n-    {\n-        // Filter out moves that do not preserve the draw or the win.\n-        RootInTB = root_probe_wdl(pos, rootMoves, TB::Score);\n-\n-        // Only probe during search if winning\n-        if (RootInTB && TB::Score <= VALUE_DRAW)\n-            Cardinality = 0;\n-    }\n-\n-    if (RootInTB && !UseRule50)\n-        TB::Score =  TB::Score > VALUE_DRAW ?  VALUE_MATE - MAX_PLY - 1\n-                   : TB::Score < VALUE_DRAW ? -VALUE_MATE + MAX_PLY + 1\n-                                            :  VALUE_DRAW;\n-}\ndiff --git a/src/search.h b/src/search.h\nindex 694dd643892..c3eb17c11f7 100644\n--- a/src/search.h\n+++ b/src/search.h\n@@ -49,6 +49,7 @@ struct Stack {\n   Value staticEval;\n   int statScore;\n   int moveCount;\n+  int tbCardinality;\n };\n \n \ndiff --git a/src/syzygy/tbprobe.cpp b/src/syzygy/tbprobe.cpp\nindex 4aff3b2da4b..377bfcea4a0 100644\n--- a/src/syzygy/tbprobe.cpp\n+++ b/src/syzygy/tbprobe.cpp\n@@ -29,6 +29,7 @@\n #include <type_traits>\n \n #include \"../bitboard.h\"\n+#include \"../misc.h\"\n #include \"../movegen.h\"\n #include \"../position.h\"\n #include \"../search.h\"\n@@ -204,6 +205,9 @@ int MapB1H1H7[SQUARE_NB];\n int MapA1D1D4[SQUARE_NB];\n int MapKK[10][SQUARE_NB]; // [MapA1D1D4][SQUARE_NB]\n \n+typedef std::pair<Key, std::pair<int, ProbeState>> CacheEntry;\n+HashTable<CacheEntry, 32768> DTZCache;\n+\n // Comparison function to sort leading pawns in ascending MapPawns[] order\n bool pawns_comp(Square i, Square j) { return MapPawns[i] < MapPawns[j]; }\n int off_A1H8(Square sq) { return int(rank_of(sq)) - file_of(sq); }\n@@ -1436,24 +1440,35 @@ WDLScore Tablebases::probe_wdl(Position& pos, ProbeState* result) {\n // then do not accept moves leading to dtz + 50-move-counter == 100.\n int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n \n+    Key key = pos.key();\n+    CacheEntry* e = DTZCache[key];\n+    auto& p = e->second;\n+\n+    if (e->first == key)\n+        return *result = p.second, p.first;\n+\n+    e->first = key;\n+\n     *result = OK;\n     WDLScore wdl = search<true>(pos, result);\n+    p.second = *result;\n \n     if (*result == FAIL || wdl == WDLDraw) // DTZ tables don't store draws\n-        return 0;\n+        return p.first = 0;\n \n     // DTZ stores a 'don't care' value in this case, or even a plain wrong\n     // one as in case the best move is a losing ep, so it cannot be probed.\n     if (*result == ZEROING_BEST_MOVE)\n-        return dtz_before_zeroing(wdl);\n+        return p.first = dtz_before_zeroing(wdl);\n \n     int dtz = probe_table<DTZEntry>(pos, result, wdl);\n+    p.second = *result;\n \n     if (*result == FAIL)\n-        return 0;\n+        return p.first = 0;\n \n     if (*result != CHANGE_STM)\n-        return (dtz + 100 * (wdl == WDLBlessedLoss || wdl == WDLCursedWin)) * sign_of(wdl);\n+        return p.first = (dtz + 100 * (wdl == WDLBlessedLoss || wdl == WDLCursedWin)) * sign_of(wdl);\n \n     // DTZ stores results for the other side, so we need to do a 1-ply search and\n     // find the winning move that minimizes DTZ.\n@@ -1472,11 +1487,11 @@ int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n         // winning position we could make a losing capture or going for a draw).\n         dtz = zeroing ? -dtz_before_zeroing(search(pos, result))\n                       : -probe_dtz(pos, result);\n-\n+        p.second = *result;\n         pos.undo_move(move);\n \n         if (*result == FAIL)\n-            return 0;\n+            return p.first = 0;\n \n         // Convert result from 1-ply search. Zeroing moves are already accounted\n         // by dtz_before_zeroing() that returns the DTZ of the previous move.\n@@ -1491,212 +1506,5 @@ int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n     // Special handle a mate position, when there are no legal moves, in this\n     // case return value is somewhat arbitrary, so stick to the original TB code\n     // that returns -1 in this case.\n-    return minDTZ == 0xFFFF ? -1 : minDTZ;\n-}\n-\n-// Check whether there has been at least one repetition of positions\n-// since the last capture or pawn move.\n-static int has_repeated(StateInfo *st)\n-{\n-    while (1) {\n-        int i = 4, e = std::min(st->rule50, st->pliesFromNull);\n-\n-        if (e < i)\n-            return 0;\n-\n-        StateInfo *stp = st->previous->previous;\n-\n-        do {\n-            stp = stp->previous->previous;\n-\n-            if (stp->key == st->key)\n-                return 1;\n-\n-            i += 2;\n-        } while (i <= e);\n-\n-        st = st->previous;\n-    }\n-}\n-\n-// Use the DTZ tables to filter out moves that don't preserve the win or draw.\n-// If the position is lost, but DTZ is fairly high, only keep moves that\n-// maximise DTZ.\n-//\n-// A return value false indicates that not all probes were successful and that\n-// no moves were filtered out.\n-bool Tablebases::root_probe(Position& pos, Search::RootMoves& rootMoves, Value& score)\n-{\n-    assert(rootMoves.size());\n-\n-    ProbeState result;\n-    int dtz = probe_dtz(pos, &result);\n-\n-    if (result == FAIL)\n-        return false;\n-\n-    StateInfo st;\n-\n-    // Probe each move\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        Move move = rootMoves[i].pv[0];\n-        pos.do_move(move, st);\n-        int v = 0;\n-\n-        if (pos.checkers() && dtz > 0) {\n-            ExtMove s[MAX_MOVES];\n-\n-            if (generate<LEGAL>(pos, s) == s)\n-                v = 1;\n-        }\n-\n-        if (!v) {\n-            if (st.rule50 != 0) {\n-                v = -probe_dtz(pos, &result);\n-\n-                if (v > 0)\n-                    ++v;\n-                else if (v < 0)\n-                    --v;\n-            } else {\n-                v = -probe_wdl(pos, &result);\n-                v = dtz_before_zeroing(WDLScore(v));\n-            }\n-        }\n-\n-        pos.undo_move(move);\n-\n-        if (result == FAIL)\n-            return false;\n-\n-        rootMoves[i].score = (Value)v;\n-    }\n-\n-    // Obtain 50-move counter for the root position.\n-    // In Stockfish there seems to be no clean way, so we do it like this:\n-    int cnt50 = st.previous ? st.previous->rule50 : 0;\n-\n-    // Use 50-move counter to determine whether the root position is\n-    // won, lost or drawn.\n-    WDLScore wdl = WDLDraw;\n-\n-    if (dtz > 0)\n-        wdl = (dtz + cnt50 <= 100) ? WDLWin : WDLCursedWin;\n-    else if (dtz < 0)\n-        wdl = (-dtz + cnt50 <= 100) ? WDLLoss : WDLBlessedLoss;\n-\n-    // Determine the score to report to the user.\n-    score = WDL_to_value[wdl + 2];\n-\n-    // If the position is winning or losing, but too few moves left, adjust the\n-    // score to show how close it is to winning or losing.\n-    // NOTE: int(PawnValueEg) is used as scaling factor in score_to_uci().\n-    if (wdl == WDLCursedWin && dtz <= 100)\n-        score = (Value)(((200 - dtz - cnt50) * int(PawnValueEg)) / 200);\n-    else if (wdl == WDLBlessedLoss && dtz >= -100)\n-        score = -(Value)(((200 + dtz - cnt50) * int(PawnValueEg)) / 200);\n-\n-    // Now be a bit smart about filtering out moves.\n-    size_t j = 0;\n-\n-    if (dtz > 0) { // winning (or 50-move rule draw)\n-        int best = 0xffff;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v > 0 && v < best)\n-                best = v;\n-        }\n-\n-        int max = best;\n-\n-        // If the current phase has not seen repetitions, then try all moves\n-        // that stay safely within the 50-move budget, if there are any.\n-        if (!has_repeated(st.previous) && best + cnt50 <= 99)\n-            max = 99 - cnt50;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v > 0 && v <= max)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    } else if (dtz < 0) { // losing (or 50-move rule draw)\n-        int best = 0;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v < best)\n-                best = v;\n-        }\n-\n-        // Try all moves, unless we approach or have a 50-move rule draw.\n-        if (-best * 2 + cnt50 < 100)\n-            return true;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            if (rootMoves[i].score == best)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    } else { // drawing\n-        // Try all moves that preserve the draw.\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            if (rootMoves[i].score == 0)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    }\n-\n-    rootMoves.resize(j, Search::RootMove(MOVE_NONE));\n-\n-    return true;\n-}\n-\n-// Use the WDL tables to filter out moves that don't preserve the win or draw.\n-// This is a fallback for the case that some or all DTZ tables are missing.\n-//\n-// A return value false indicates that not all probes were successful and that\n-// no moves were filtered out.\n-bool Tablebases::root_probe_wdl(Position& pos, Search::RootMoves& rootMoves, Value& score)\n-{\n-    ProbeState result;\n-\n-    WDLScore wdl = Tablebases::probe_wdl(pos, &result);\n-\n-    if (result == FAIL)\n-        return false;\n-\n-    score = WDL_to_value[wdl + 2];\n-\n-    StateInfo st;\n-\n-    int best = WDLLoss;\n-\n-    // Probe each move\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        Move move = rootMoves[i].pv[0];\n-        pos.do_move(move, st);\n-        WDLScore v = -Tablebases::probe_wdl(pos, &result);\n-        pos.undo_move(move);\n-\n-        if (result == FAIL)\n-            return false;\n-\n-        rootMoves[i].score = (Value)v;\n-\n-        if (v > best)\n-            best = v;\n-    }\n-\n-    size_t j = 0;\n-\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        if (rootMoves[i].score == best)\n-            rootMoves[j++] = rootMoves[i];\n-    }\n-\n-    rootMoves.resize(j, Search::RootMove(MOVE_NONE));\n-\n-    return true;\n+    return p.first = (minDTZ == 0xFFFF ? -1 : minDTZ);\n }\ndiff --git a/src/syzygy/tbprobe.h b/src/syzygy/tbprobe.h\nindex f44674b215f..3bdf85c1fcc 100644\n--- a/src/syzygy/tbprobe.h\n+++ b/src/syzygy/tbprobe.h\n@@ -49,9 +49,6 @@ extern int MaxCardinality;\n void init(const std::string& paths);\n WDLScore probe_wdl(Position& pos, ProbeState* result);\n int probe_dtz(Position& pos, ProbeState* result);\n-bool root_probe(Position& pos, Search::RootMoves& rootMoves, Value& score);\n-bool root_probe_wdl(Position& pos, Search::RootMoves& rootMoves, Value& score);\n-void filter_root_moves(Position& pos, Search::RootMoves& rootMoves);\n \n inline std::ostream& operator<<(std::ostream& os, const WDLScore v) {\n \ndiff --git a/src/thread.cpp b/src/thread.cpp\nindex d095aefeb6a..c2a96db7ec5 100644\n--- a/src/thread.cpp\n+++ b/src/thread.cpp\n@@ -163,9 +163,6 @@ void ThreadPool::start_thinking(Position& pos, StateListPtr& states,\n           || std::count(limits.searchmoves.begin(), limits.searchmoves.end(), m))\n           rootMoves.emplace_back(m);\n \n-  if (!rootMoves.empty())\n-      Tablebases::filter_root_moves(pos, rootMoves);\n-\n   // After ownership transfer 'states' becomes empty, so if we stop the search\n   // and call 'go' again without setting a new position states.get() == NULL.\n   assert(states.get() || setupStates.get());\ndiff --git a/src/uci.cpp b/src/uci.cpp\nindex fc66f0b5321..8ec5916024d 100644\n--- a/src/uci.cpp\n+++ b/src/uci.cpp\n@@ -142,8 +142,8 @@ namespace {\n \n   void bench(Position& pos, istream& args, StateListPtr& states) {\n \n-    string token;\n-    uint64_t num, nodes = 0, cnt = 1;\n+    string token, tbh;\n+    uint64_t num, nodes = 0, tbHits = 0, cnt = 1;\n \n     vector<string> list = setup_bench(pos, args);\n     num = count_if(list.begin(), list.end(), [](string s) { return s.find(\"go \") == 0; });\n@@ -160,7 +160,8 @@ namespace {\n             cerr << \"\\nPosition: \" << cnt++ << '/' << num << endl;\n             go(pos, is, states);\n             Threads.main()->wait_for_search_finished();\n-            nodes += Threads.nodes_searched();\n+            nodes  += Threads.nodes_searched();\n+            tbHits += Threads.tb_hits();\n         }\n         else if (token == \"setoption\")  setoption(is);\n         else if (token == \"position\")   position(pos, is, states);\n@@ -174,7 +175,8 @@ namespace {\n     cerr << \"\\n===========================\"\n          << \"\\nTotal time (ms) : \" << elapsed\n          << \"\\nNodes searched  : \" << nodes\n-         << \"\\nNodes/second    : \" << 1000 * nodes / elapsed << endl;\n+         << \"\\nNodes/second    : \" << 1000 * nodes / elapsed\n+         << \"\\nTB hits         : \" << tbHits << endl;\n   }\n \n } // namespace\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Verify testing setup for `cutechess-cli`:\n   ```\n   ./cutechess-cli -repeat -rounds 10000 -tournament gauntlet -pgnout results.pgn -srand 1942127704 -resign movecount=3 score=400 -draw movenumber=34 movecount=8 score=20 -concurrency 30 -openings file=2moves_v1.pgn format=pgn order=random plies=16 -engine name=master cmd=stockfish.master -engine name=ntb cmd=stockfish.ntb -each proto=uci tc=10.00+0.10 option.Threads=1 option.SyzygyPath=/dev/shm/syzygy/3-4-5/ option.Hash=4\n   ```\n\n2. Do not use early adjudication; ensure conversion of TB wins is tested.\n\n3. For fair testing, use SF master version from around August 22 to match `natural2`.\n\n4. Include DTZ tables in the same directory for proper functioning.\n\n5. Prefer time control of +0.10 over +0.01 to avoid time losses encountered in short tests. \n\n6. Investigate and provide extraordinary proof if optimization truly yields a notable Elo gain; isolate and test the core concept separately."
      }
    ],
    "codediff_length": 22161
  },
  {
    "index": 87,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/search.cpp b/src/search.cpp\nindex 07c18012739..a294b36a674 100644\n--- a/src/search.cpp\n+++ b/src/search.cpp\n@@ -46,9 +46,10 @@ namespace Tablebases {\n \n   int Cardinality;\n   bool RootInTB;\n-  bool UseRule50;\n   Depth ProbeDepth;\n-  Value Score;\n+  WDLScore DrawScore;\n+  WDLScore RootWDL;\n+  int RootDTZ;\n }\n \n namespace TB = Tablebases;\n@@ -150,6 +151,7 @@ namespace {\n   void update_pv(Move* pv, Move move, Move* childPv);\n   void update_continuation_histories(Stack* ss, Piece pc, Square to, int bonus);\n   void update_stats(const Position& pos, Stack* ss, Move move, Move* quiets, int quietsCnt, int bonus);\n+  Value probe_tb(Position& pos, Stack* ss, Value alpha, Value beta, Depth* depth, TTEntry* tte);\n \n   // perft() is our utility to verify move generation. All the leaf nodes up\n   // to the given depth are generated and counted, and the sum is returned.\n@@ -180,6 +182,20 @@ namespace {\n } // namespace\n \n \n+/// Sort root moves in descending order, when root is in TB score according to\n+/// TB knwoledge.\n+\n+bool RootMove::operator<(const RootMove& m) const {\n+\n+  bool useDTZ = m.dtz != dtz && TB::RootDTZ > 0;\n+\n+  return  m.wdl != wdl     ? m.wdl < wdl\n+        : useDTZ           ? m.dtz > dtz\n+        : m.score != score ? m.score < score\n+                           : m.previousScore < previousScore;\n+}\n+\n+\n /// Search::init() is called during startup to initialize various lookup tables\n \n void Search::init() {\n@@ -243,6 +259,17 @@ void MainThread::search() {\n   DrawValue[ us] = VALUE_DRAW - Value(contempt);\n   DrawValue[~us] = VALUE_DRAW + Value(contempt);\n \n+  // Set TB probing parameters\n+  TB::DrawScore = Options[\"Syzygy50MoveRule\"] ? TB::WDLCursedWin : TB::WDLDraw;\n+  TB::ProbeDepth = Options[\"SyzygyProbeDepth\"] * ONE_PLY;\n+  TB::Cardinality = Options[\"SyzygyProbeLimit\"];\n+\n+  if (TB::Cardinality > TB::MaxCardinality)\n+  {\n+      TB::Cardinality = TB::MaxCardinality;\n+      TB::ProbeDepth = DEPTH_ZERO; // Hack!\n+  }\n+\n   if (rootMoves.empty())\n   {\n       rootMoves.emplace_back(MOVE_NONE);\n@@ -291,22 +318,18 @@ void MainThread::search() {\n       && !Skill(Options[\"Skill Level\"]).enabled()\n       &&  rootMoves[0].pv[0] != MOVE_NONE)\n   {\n+      // Select the thread with the best score, always if it is a mate\n       for (Thread* th : Threads)\n-      {\n-          Depth depthDiff = th->completedDepth - bestThread->completedDepth;\n-          Value scoreDiff = th->rootMoves[0].score - bestThread->rootMoves[0].score;\n-\n-          // Select the thread with the best score, always if it is a mate\n-          if (    scoreDiff > 0\n-              && (depthDiff >= 0 || th->rootMoves[0].score >= VALUE_MATE_IN_MAX_PLY))\n+          if (   bestThread->rootMoves[0] < th->rootMoves[0]\n+              && (   th->completedDepth >= bestThread->completedDepth\n+                  || th->rootMoves[0].score >= VALUE_MATE_IN_MAX_PLY))\n               bestThread = th;\n-      }\n   }\n \n   previousScore = bestThread->rootMoves[0].score;\n \n   // Send new PV when needed\n-  if (bestThread != this)\n+  if (bestThread != this || TB::RootInTB)\n       sync_cout << UCI::pv(bestThread->rootPos, bestThread->completedDepth, -VALUE_INFINITE, VALUE_INFINITE) << sync_endl;\n \n   sync_cout << \"bestmove \" << UCI::move(bestThread->rootMoves[0].pv[0], rootPos.is_chess960());\n@@ -330,6 +353,7 @@ void Thread::search() {\n   MainThread* mainThread = (this == Threads.main() ? Threads.main() : nullptr);\n \n   std::memset(ss-4, 0, 7 * sizeof(Stack));\n+  ss->tbCardinality = TB::Cardinality;\n   for (int i = 4; i > 0; i--)\n      (ss-i)->contHistory = &this->contHistory[NO_PIECE][0]; // Use as sentinel\n \n@@ -397,6 +421,13 @@ void Thread::search() {\n           {\n               bestValue = ::search<PV>(rootPos, ss, alpha, beta, rootDepth, false, false);\n \n+              // If we are in mate territory stop using DTZ to score moves\n+              if (   TB::RootInTB\n+                  && abs(bestValue) > VALUE_MATE_IN_MAX_PLY\n+                  && bestValue > alpha && bestValue < beta)\n+                  for (RootMove& rm : rootMoves)\n+                      rm.dtz = 0;\n+\n               // Bring the best move to the front. It is critical that sorting\n               // is done with a stable algorithm because all the values but the\n               // first and eventually the new best one are set to -VALUE_INFINITE\n@@ -407,10 +438,17 @@ void Thread::search() {\n \n               // If search has been stopped, we break immediately. Sorting and\n               // writing PV back to TT is safe because RootMoves is still\n-              // valid, although it refers to the previous iteration.\n+              // valid, although it refers to the previous iteration. Instead\n+              // bestValue cannot be trusted.\n               if (Threads.stop)\n                   break;\n \n+              // If DTZ sorting overrides score sorting, it could happen that\n+              // first root move does not have always the best score. So ensure\n+              // it to avoid any possible artifact.\n+              if (TB::RootInTB)\n+                  rootMoves[PVIdx].score = bestValue;\n+\n               // When failing high/low give some update (without cluttering\n               // the UI) before a re-search.\n               if (   mainThread\n@@ -587,6 +625,7 @@ namespace {\n     ss->currentMove = (ss+1)->excludedMove = bestMove = MOVE_NONE;\n     ss->contHistory = &thisThread->contHistory[NO_PIECE][0];\n     (ss+2)->killers[0] = (ss+2)->killers[1] = MOVE_NONE;\n+    (ss+1)->tbCardinality = ss->tbCardinality;\n     Square prevSq = to_sq((ss-1)->currentMove);\n \n     // Step 4. Transposition table lookup. We don't want the score of a partial\n@@ -631,34 +670,18 @@ namespace {\n     }\n \n     // Step 4a. Tablebase probe\n-    if (!rootNode && TB::Cardinality)\n+    if (!rootNode && ss->tbCardinality)\n     {\n         int piecesCount = pos.count<ALL_PIECES>();\n \n-        if (    piecesCount <= TB::Cardinality\n-            && (piecesCount <  TB::Cardinality || depth >= TB::ProbeDepth)\n-            &&  pos.rule50_count() == 0\n+        if (    piecesCount <= ss->tbCardinality\n+            && (piecesCount <  ss->tbCardinality || depth >= TB::ProbeDepth)\n             && !pos.can_castle(ANY_CASTLING))\n         {\n-            TB::ProbeState err;\n-            TB::WDLScore v = Tablebases::probe_wdl(pos, &err);\n-\n-            if (err != TB::ProbeState::FAIL)\n-            {\n-                thisThread->tbHits.fetch_add(1, std::memory_order_relaxed);\n-\n-                int drawScore = TB::UseRule50 ? 1 : 0;\n-\n-                value =  v < -drawScore ? -VALUE_MATE + MAX_PLY + ss->ply + 1\n-                       : v >  drawScore ?  VALUE_MATE - MAX_PLY - ss->ply - 1\n-                                        :  VALUE_DRAW + 2 * v * drawScore;\n-\n-                tte->save(posKey, value_to_tt(value, ss->ply), BOUND_EXACT,\n-                          std::min(DEPTH_MAX - ONE_PLY, depth + 6 * ONE_PLY),\n-                          MOVE_NONE, VALUE_NONE, TT.generation());\n+            value = probe_tb(pos, ss, alpha, beta, &depth, tte);\n \n+            if (value != VALUE_NONE)\n                 return value;\n-            }\n         }\n     }\n \n@@ -1456,6 +1479,75 @@ namespace {\n     return best;\n   }\n \n+\n+  // probe_tb() is called by search after TT probe to look up the position in\n+  // tablebases, if it is found we return immediately or continue the search\n+  // eventually with reduced depth according to the case.\n+\n+  Value probe_tb(Position& pos, Stack* ss, Value alpha, Value beta, Depth* depth, TTEntry* tte) {\n+\n+    TB::ProbeState err = TB::ProbeState::FAIL;\n+    TB::WDLScore wdl;\n+    bool farFromRoot = false, reduceDepth = true;\n+\n+    Thread* thisThread = pos.this_thread();\n+    thisThread->tbHits.fetch_add(1, std::memory_order_relaxed);\n+\n+    // If root is in TB then reduce all moves that don't preserve the score\n+    if (TB::RootInTB && (ss-1)->ply == 0)\n+    {\n+        err = TB::ProbeState::OK;\n+        RootMove& rm = *std::find(thisThread->rootMoves.begin(),\n+                                  thisThread->rootMoves.end(), (ss-1)->currentMove);\n+        wdl = TB::WDLScore(-rm.wdl);\n+        reduceDepth = -wdl < TB::RootWDL;\n+    }\n+    else\n+        wdl = Tablebases::probe_wdl(pos, &err);\n+\n+    // Win or loss scores are reliable only if we are probing after a\n+    // rule50 reset move. Instead draw scores are reliable in any case.\n+    if (err != TB::ProbeState::FAIL)\n+    {\n+        // It is far if ply >= (RootDepth - LMR) / 3, so that at a given ply\n+        // nodes with high LMR are considered farther from root than nodes\n+        // near the PV line.\n+        farFromRoot = ss->ply - *depth / (2 * ONE_PLY) >= 0;\n+\n+        Value value =  wdl >  TB::DrawScore ?  VALUE_MATE - MAX_PLY - ss->ply\n+                     : wdl < -TB::DrawScore ? -VALUE_MATE + MAX_PLY + ss->ply\n+                                            :  VALUE_DRAW + 2 * wdl;\n+\n+        Bound bound =  wdl >  TB::DrawScore ? BOUND_LOWER\n+                     : wdl < -TB::DrawScore ? BOUND_UPPER : BOUND_EXACT;\n+\n+        // Use TB scores as lower/upper bounds, a draw score is BOUND_EXACT\n+        // and is always considered even if value is within (alpha, beta)\n+        if (   (value >= beta  && bound == BOUND_LOWER)\n+            || (value <= alpha && bound == BOUND_UPPER)\n+            ||  bound == BOUND_EXACT)\n+        {\n+            // When in midgame or is a draw save in TT and return...\n+            if (bound == BOUND_EXACT || farFromRoot)\n+            {\n+                Key posKey = pos.key() ^ Key(ss->excludedMove);\n+                tte->save(posKey, value_to_tt(value, ss->ply), bound,\n+                          std::min(DEPTH_MAX - ONE_PLY, *depth + 6 * ONE_PLY),\n+                          MOVE_NONE, VALUE_NONE, TT.generation());\n+                return value;\n+            }\n+            // ...otherwise search win/loss eventually with a reduced depth\n+            else if (reduceDepth)\n+                *depth = std::max(*depth / 2, ONE_PLY);\n+\n+            // Don't probe in the win/loss sub-tree (draws cut-off immediately)\n+            ss->tbCardinality = 0;\n+        }\n+    }\n+\n+    return VALUE_NONE;\n+  }\n+\n } // namespace\n \n   // check_time() is used to print debug info and, more importantly, to detect\n@@ -1503,7 +1595,7 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n   size_t PVIdx = pos.this_thread()->PVIdx;\n   size_t multiPV = std::min((size_t)Options[\"MultiPV\"], rootMoves.size());\n   uint64_t nodesSearched = Threads.nodes_searched();\n-  uint64_t tbHits = Threads.tb_hits() + (TB::RootInTB ? rootMoves.size() : 0);\n+  uint64_t tbHits = Threads.tb_hits();\n \n   for (size_t i = 0; i < multiPV; ++i)\n   {\n@@ -1514,9 +1606,23 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n \n       Depth d = updated ? depth : depth - ONE_PLY;\n       Value v = updated ? rootMoves[i].score : rootMoves[i].previousScore;\n+      string bound = v >= beta ? \" lowerbound\" : v <= alpha ? \" upperbound\" : \"\";\n+\n+      // Signal the GUI we are in TB and codify DTZ info into output score\n+      if (TB::RootInTB && abs(v) < VALUE_MATE_IN_MAX_PLY)\n+      {\n+          if (   TB::DrawScore != TB::WDLDraw // Rule50 enabled\n+              && (   rootMoves[i].wdl == TB::WDLBlessedLoss\n+                  || rootMoves[i].wdl == TB::WDLCursedWin))\n+              v = int(rootMoves[i].wdl) * PawnValueEg / 10;\n+          else\n+          {\n+              static_assert(int(PawnValueEg) * 120 < VALUE_MATE_IN_MAX_PLY, \"DTZ overflow\");\n \n-      bool tb = TB::RootInTB && abs(v) < VALUE_MATE - MAX_PLY;\n-      v = tb ? TB::Score : v;\n+              auto s = PawnValueEg * (120 - abs(rootMoves[i].dtz) / 2);\n+              v = int(rootMoves[i].wdl / 2) * std::max(s, PawnValueEg * 10);\n+          }\n+      }\n \n       if (ss.rdbuf()->in_avail()) // Not at first line\n           ss << \"\\n\";\n@@ -1527,8 +1633,8 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n          << \" multipv \"  << i + 1\n          << \" score \"    << UCI::value(v);\n \n-      if (!tb && i == PVIdx)\n-          ss << (v >= beta ? \" lowerbound\" : v <= alpha ? \" upperbound\" : \"\");\n+      if (i == PVIdx)\n+          ss << bound;\n \n       ss << \" nodes \"    << nodesSearched\n          << \" nps \"      << nodesSearched * 1000 / elapsed;\n@@ -1576,43 +1682,3 @@ bool RootMove::extract_ponder_from_tt(Position& pos) {\n     pos.undo_move(pv[0]);\n     return pv.size() > 1;\n }\n-\n-void Tablebases::filter_root_moves(Position& pos, Search::RootMoves& rootMoves) {\n-\n-    RootInTB = false;\n-    UseRule50 = Options[\"Syzygy50MoveRule\"];\n-    ProbeDepth = Options[\"SyzygyProbeDepth\"] * ONE_PLY;\n-    Cardinality = Options[\"SyzygyProbeLimit\"];\n-\n-    // Skip TB probing when no TB found: !TBLargest -> !TB::Cardinality\n-    if (Cardinality > MaxCardinality)\n-    {\n-        Cardinality = MaxCardinality;\n-        ProbeDepth = DEPTH_ZERO;\n-    }\n-\n-    if (Cardinality < popcount(pos.pieces()) || pos.can_castle(ANY_CASTLING))\n-        return;\n-\n-    // If the current root position is in the tablebases, then RootMoves\n-    // contains only moves that preserve the draw or the win.\n-    RootInTB = root_probe(pos, rootMoves, TB::Score);\n-\n-    if (RootInTB)\n-        Cardinality = 0; // Do not probe tablebases during the search\n-\n-    else // If DTZ tables are missing, use WDL tables as a fallback\n-    {\n-        // Filter out moves that do not preserve the draw or the win.\n-        RootInTB = root_probe_wdl(pos, rootMoves, TB::Score);\n-\n-        // Only probe during search if winning\n-        if (RootInTB && TB::Score <= VALUE_DRAW)\n-            Cardinality = 0;\n-    }\n-\n-    if (RootInTB && !UseRule50)\n-        TB::Score =  TB::Score > VALUE_DRAW ?  VALUE_MATE - MAX_PLY - 1\n-                   : TB::Score < VALUE_DRAW ? -VALUE_MATE + MAX_PLY + 1\n-                                            :  VALUE_DRAW;\n-}\ndiff --git a/src/search.h b/src/search.h\nindex 694dd643892..0e2adc2272f 100644\n--- a/src/search.h\n+++ b/src/search.h\n@@ -49,6 +49,7 @@ struct Stack {\n   Value staticEval;\n   int statScore;\n   int moveCount;\n+  int tbCardinality;\n };\n \n \n@@ -61,14 +62,13 @@ struct RootMove {\n   explicit RootMove(Move m) : pv(1, m) {}\n   bool extract_ponder_from_tt(Position& pos);\n   bool operator==(const Move& m) const { return pv[0] == m; }\n-  bool operator<(const RootMove& m) const { // Sort in descending order\n-    return m.score != score ? m.score < score\n-                            : m.previousScore < previousScore;\n-  }\n+  bool operator<(const RootMove& m) const;\n \n   Value score = -VALUE_INFINITE;\n   Value previousScore = -VALUE_INFINITE;\n   int selDepth = 0;\n+  int dtz = 0;\n+  int wdl = 0;\n   std::vector<Move> pv;\n };\n \ndiff --git a/src/syzygy/tbprobe.cpp b/src/syzygy/tbprobe.cpp\nindex 4aff3b2da4b..24a501e5e02 100644\n--- a/src/syzygy/tbprobe.cpp\n+++ b/src/syzygy/tbprobe.cpp\n@@ -61,6 +61,18 @@ inline WDLScore operator-(WDLScore d) { return WDLScore(-int(d)); }\n inline Square operator^=(Square& s, int i) { return s = Square(int(s) ^ i); }\n inline Square operator^(Square s, int i) { return Square(int(s) ^ i); }\n \n+// Return the sign of a number (-1, 0, 1)\n+template <typename T> int sign_of(T val) {\n+    return (T(0) < val) - (val < T(0));\n+}\n+\n+// Convert from a DTZ to a WDL score, knowing rule50 counter\n+WDLScore dtz_to_wdl(int dtz, int r50) {\n+    bool cursed = abs(dtz) + r50 > 100;\n+    return  dtz > 0 ? (cursed ? WDLCursedWin   : WDLWin)\n+          : dtz < 0 ? (cursed ? WDLBlessedLoss : WDLLoss) : WDLDraw;\n+}\n+\n // DTZ tables don't store valid scores for moves that reset the rule50 counter\n // like captures and pawn moves but we can easily recover the correct dtz of the\n // previous move if we know the position's WDL score.\n@@ -71,11 +83,6 @@ int dtz_before_zeroing(WDLScore wdl) {\n            wdl == WDLLoss        ? -1   : 0;\n }\n \n-// Return the sign of a number (-1, 0, 1)\n-template <typename T> int sign_of(T val) {\n-    return (T(0) < val) - (val < T(0));\n-}\n-\n // Numbers in little endian used by sparseIndex[] to point into blockLength[]\n struct SparseEntry {\n     char block[4];   // Number of block\n@@ -208,14 +215,6 @@ int MapKK[10][SQUARE_NB]; // [MapA1D1D4][SQUARE_NB]\n bool pawns_comp(Square i, Square j) { return MapPawns[i] < MapPawns[j]; }\n int off_A1H8(Square sq) { return int(rank_of(sq)) - file_of(sq); }\n \n-const Value WDL_to_value[] = {\n-   -VALUE_MATE + MAX_PLY + 1,\n-    VALUE_DRAW - 2,\n-    VALUE_DRAW,\n-    VALUE_DRAW + 2,\n-    VALUE_MATE - MAX_PLY - 1\n-};\n-\n const std::string PieceToChar = \" PNBRQK  pnbrqk\";\n \n int Binomial[6][SQUARE_NB];    // [k][n] k elements from a set of n elements\n@@ -1200,7 +1199,7 @@ T probe_table(const Position& pos, ProbeState* result, WDLScore wdl = WDLDraw) {\n // where the best move is an ep-move (even if losing). So in all these cases set\n // the state to ZEROING_BEST_MOVE.\n template<bool CheckZeroingMoves = false>\n-WDLScore search(Position& pos, ProbeState* result) {\n+WDLScore search_wdl(Position& pos, ProbeState* result) {\n \n     WDLScore value, bestValue = WDLLoss;\n     StateInfo st;\n@@ -1208,17 +1207,17 @@ WDLScore search(Position& pos, ProbeState* result) {\n     auto moveList = MoveList<LEGAL>(pos);\n     size_t totalCount = moveList.size(), moveCount = 0;\n \n-    for (const Move& move : moveList)\n+    for (const auto& m : moveList)\n     {\n-        if (   !pos.capture(move)\n-            && (!CheckZeroingMoves || type_of(pos.moved_piece(move)) != PAWN))\n+        if (   !pos.capture(m)\n+            && (!CheckZeroingMoves || type_of(pos.moved_piece(m)) != PAWN))\n             continue;\n \n         moveCount++;\n \n-        pos.do_move(move, st);\n-        value = -search(pos, result);\n-        pos.undo_move(move);\n+        pos.do_move(m, st);\n+        value = -search_wdl(pos, result);\n+        pos.undo_move(m);\n \n         if (*result == FAIL)\n             return WDLDraw;\n@@ -1261,6 +1260,61 @@ WDLScore search(Position& pos, ProbeState* result) {\n     return *result = OK, value;\n }\n \n+// Do a 1-ply search probing DTZ values of resulting positions and reporting\n+// back the minimum DTZ already converted to the point of view of previous ply.\n+// If rootMoves is passed then set the corresponding RootMove dtz field.\n+int search_dtz(Position& pos, ProbeState* result, int r50, Search::RootMoves* rootMoves) {\n+\n+    StateInfo st;\n+    WDLScore wdl = WDLLoss;\n+    int minDTZ = 0xFFFF;\n+\n+    for (const auto& m : MoveList<LEGAL>(pos))\n+    {\n+        bool zeroing = pos.capture(m) || type_of(pos.moved_piece(m)) == PAWN;\n+\n+        pos.do_move(m, st);\n+\n+        // For zeroing moves we want the dtz of the move _before_ doing it,\n+        // otherwise we will get the dtz of the next move sequence. Search the\n+        // position after the move to get the score sign (because even in a\n+        // winning position we could make a losing capture or going for a draw).\n+        int dtz = zeroing ? -dtz_before_zeroing(search_wdl(pos, result))\n+                          : -probe_dtz(pos, result);\n+\n+        pos.undo_move(m);\n+\n+        if (*result == FAIL)\n+            return 0;\n+\n+        // Convert result from 1-ply search. Zeroing moves are already accounted\n+        // by dtz_before_zeroing() that returns the DTZ of the previous move.\n+        if (!zeroing)\n+            dtz += sign_of(dtz);\n+\n+        if (dtz_to_wdl(dtz, r50) > wdl)\n+        {\n+            wdl = dtz_to_wdl(dtz, r50);\n+            minDTZ = dtz;\n+        }\n+        // Skip the draws and if we are winning only pick positive dtz\n+        else if (dtz < minDTZ && sign_of(dtz) == sign_of(wdl))\n+            minDTZ = dtz;\n+\n+        if (rootMoves)\n+        {\n+            auto it = std::find(rootMoves->begin(), rootMoves->end(), m);\n+            it->dtz = dtz;\n+            it->wdl = dtz_to_wdl(dtz, r50);\n+        }\n+    }\n+\n+    // Special handle a mate position, when there are no legal moves, in this\n+    // case return value is somewhat arbitrary, so stick to the original TB code\n+    // that returns -1 in this case.\n+    return minDTZ == 0xFFFF ? -1 : minDTZ;\n+}\n+\n } // namespace\n \n void Tablebases::init(const std::string& paths) {\n@@ -1406,7 +1460,7 @@ void Tablebases::init(const std::string& paths) {\n WDLScore Tablebases::probe_wdl(Position& pos, ProbeState* result) {\n \n     *result = OK;\n-    return search(pos, result);\n+    return search_wdl(pos, result);\n }\n \n // Probe the DTZ table for a particular position.\n@@ -1437,7 +1491,7 @@ WDLScore Tablebases::probe_wdl(Position& pos, ProbeState* result) {\n int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n \n     *result = OK;\n-    WDLScore wdl = search<true>(pos, result);\n+    WDLScore wdl = search_wdl<true>(pos, result);\n \n     if (*result == FAIL || wdl == WDLDraw) // DTZ tables don't store draws\n         return 0;\n@@ -1457,246 +1511,26 @@ int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n \n     // DTZ stores results for the other side, so we need to do a 1-ply search and\n     // find the winning move that minimizes DTZ.\n-    StateInfo st;\n-    int minDTZ = 0xFFFF;\n-\n-    for (const Move& move : MoveList<LEGAL>(pos))\n-    {\n-        bool zeroing = pos.capture(move) || type_of(pos.moved_piece(move)) == PAWN;\n-\n-        pos.do_move(move, st);\n-\n-        // For zeroing moves we want the dtz of the move _before_ doing it,\n-        // otherwise we will get the dtz of the next move sequence. Search the\n-        // position after the move to get the score sign (because even in a\n-        // winning position we could make a losing capture or going for a draw).\n-        dtz = zeroing ? -dtz_before_zeroing(search(pos, result))\n-                      : -probe_dtz(pos, result);\n-\n-        pos.undo_move(move);\n-\n-        if (*result == FAIL)\n-            return 0;\n-\n-        // Convert result from 1-ply search. Zeroing moves are already accounted\n-        // by dtz_before_zeroing() that returns the DTZ of the previous move.\n-        if (!zeroing)\n-            dtz += sign_of(dtz);\n-\n-        // Skip the draws and if we are winning only pick positive dtz\n-        if (dtz < minDTZ && sign_of(dtz) == sign_of(wdl))\n-            minDTZ = dtz;\n-    }\n-\n-    // Special handle a mate position, when there are no legal moves, in this\n-    // case return value is somewhat arbitrary, so stick to the original TB code\n-    // that returns -1 in this case.\n-    return minDTZ == 0xFFFF ? -1 : minDTZ;\n+    return search_dtz(pos, result, pos.rule50_count(), nullptr);\n }\n \n-// Check whether there has been at least one repetition of positions\n-// since the last capture or pawn move.\n-static int has_repeated(StateInfo *st)\n-{\n-    while (1) {\n-        int i = 4, e = std::min(st->rule50, st->pliesFromNull);\n-\n-        if (e < i)\n-            return 0;\n-\n-        StateInfo *stp = st->previous->previous;\n-\n-        do {\n-            stp = stp->previous->previous;\n-\n-            if (stp->key == st->key)\n-                return 1;\n-\n-            i += 2;\n-        } while (i <= e);\n-\n-        st = st->previous;\n-    }\n-}\n-\n-// Use the DTZ tables to filter out moves that don't preserve the win or draw.\n-// If the position is lost, but DTZ is fairly high, only keep moves that\n-// maximise DTZ.\n-//\n-// A return value false indicates that not all probes were successful and that\n-// no moves were filtered out.\n-bool Tablebases::root_probe(Position& pos, Search::RootMoves& rootMoves, Value& score)\n-{\n-    assert(rootMoves.size());\n-\n-    ProbeState result;\n-    int dtz = probe_dtz(pos, &result);\n-\n-    if (result == FAIL)\n-        return false;\n-\n-    StateInfo st;\n-\n-    // Probe each move\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        Move move = rootMoves[i].pv[0];\n-        pos.do_move(move, st);\n-        int v = 0;\n-\n-        if (pos.checkers() && dtz > 0) {\n-            ExtMove s[MAX_MOVES];\n-\n-            if (generate<LEGAL>(pos, s) == s)\n-                v = 1;\n-        }\n-\n-        if (!v) {\n-            if (st.rule50 != 0) {\n-                v = -probe_dtz(pos, &result);\n-\n-                if (v > 0)\n-                    ++v;\n-                else if (v < 0)\n-                    --v;\n-            } else {\n-                v = -probe_wdl(pos, &result);\n-                v = dtz_before_zeroing(WDLScore(v));\n-            }\n-        }\n-\n-        pos.undo_move(move);\n-\n-        if (result == FAIL)\n-            return false;\n-\n-        rootMoves[i].score = (Value)v;\n-    }\n-\n-    // Obtain 50-move counter for the root position.\n-    // In Stockfish there seems to be no clean way, so we do it like this:\n-    int cnt50 = st.previous ? st.previous->rule50 : 0;\n-\n-    // Use 50-move counter to determine whether the root position is\n-    // won, lost or drawn.\n-    WDLScore wdl = WDLDraw;\n-\n-    if (dtz > 0)\n-        wdl = (dtz + cnt50 <= 100) ? WDLWin : WDLCursedWin;\n-    else if (dtz < 0)\n-        wdl = (-dtz + cnt50 <= 100) ? WDLLoss : WDLBlessedLoss;\n-\n-    // Determine the score to report to the user.\n-    score = WDL_to_value[wdl + 2];\n-\n-    // If the position is winning or losing, but too few moves left, adjust the\n-    // score to show how close it is to winning or losing.\n-    // NOTE: int(PawnValueEg) is used as scaling factor in score_to_uci().\n-    if (wdl == WDLCursedWin && dtz <= 100)\n-        score = (Value)(((200 - dtz - cnt50) * int(PawnValueEg)) / 200);\n-    else if (wdl == WDLBlessedLoss && dtz >= -100)\n-        score = -(Value)(((200 + dtz - cnt50) * int(PawnValueEg)) / 200);\n-\n-    // Now be a bit smart about filtering out moves.\n-    size_t j = 0;\n+// Probe DTZ tables for each root move and store the result\n+void Tablebases::dtz_score(Position& pos, Search::RootMoves& rootMoves) {\n \n-    if (dtz > 0) { // winning (or 50-move rule draw)\n-        int best = 0xffff;\n+    ProbeState result = OK;\n+    RootInTB = false;\n \n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v > 0 && v < best)\n-                best = v;\n-        }\n-\n-        int max = best;\n-\n-        // If the current phase has not seen repetitions, then try all moves\n-        // that stay safely within the 50-move budget, if there are any.\n-        if (!has_repeated(st.previous) && best + cnt50 <= 99)\n-            max = 99 - cnt50;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v > 0 && v <= max)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    } else if (dtz < 0) { // losing (or 50-move rule draw)\n-        int best = 0;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v < best)\n-                best = v;\n-        }\n-\n-        // Try all moves, unless we approach or have a 50-move rule draw.\n-        if (-best * 2 + cnt50 < 100)\n-            return true;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            if (rootMoves[i].score == best)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    } else { // drawing\n-        // Try all moves that preserve the draw.\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            if (rootMoves[i].score == 0)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    }\n-\n-    rootMoves.resize(j, Search::RootMove(MOVE_NONE));\n-\n-    return true;\n-}\n-\n-// Use the WDL tables to filter out moves that don't preserve the win or draw.\n-// This is a fallback for the case that some or all DTZ tables are missing.\n-//\n-// A return value false indicates that not all probes were successful and that\n-// no moves were filtered out.\n-bool Tablebases::root_probe_wdl(Position& pos, Search::RootMoves& rootMoves, Value& score)\n-{\n-    ProbeState result;\n-\n-    WDLScore wdl = Tablebases::probe_wdl(pos, &result);\n+    if (   pos.count<ALL_PIECES>() > MaxCardinality\n+        || pos.can_castle(ANY_CASTLING)\n+        || rootMoves.empty())\n+        return;\n \n+    // Value of probe_dtz() can be off by 1, so use search_dtz() for RootPosDTZ\n+    int dtz = search_dtz(pos, &result, pos.rule50_count(), &rootMoves);\n     if (result == FAIL)\n-        return false;\n-\n-    score = WDL_to_value[wdl + 2];\n-\n-    StateInfo st;\n-\n-    int best = WDLLoss;\n-\n-    // Probe each move\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        Move move = rootMoves[i].pv[0];\n-        pos.do_move(move, st);\n-        WDLScore v = -Tablebases::probe_wdl(pos, &result);\n-        pos.undo_move(move);\n-\n-        if (result == FAIL)\n-            return false;\n-\n-        rootMoves[i].score = (Value)v;\n-\n-        if (v > best)\n-            best = v;\n-    }\n-\n-    size_t j = 0;\n-\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        if (rootMoves[i].score == best)\n-            rootMoves[j++] = rootMoves[i];\n-    }\n-\n-    rootMoves.resize(j, Search::RootMove(MOVE_NONE));\n+        return;\n \n-    return true;\n+    RootDTZ = dtz;\n+    RootWDL = dtz_to_wdl(dtz, pos.rule50_count());\n+    RootInTB = true;\n }\ndiff --git a/src/syzygy/tbprobe.h b/src/syzygy/tbprobe.h\nindex f44674b215f..df9c1656e57 100644\n--- a/src/syzygy/tbprobe.h\n+++ b/src/syzygy/tbprobe.h\n@@ -45,13 +45,14 @@ enum ProbeState {\n };\n \n extern int MaxCardinality;\n+extern bool RootInTB;\n+extern WDLScore RootWDL;\n+extern int RootDTZ;\n \n void init(const std::string& paths);\n WDLScore probe_wdl(Position& pos, ProbeState* result);\n int probe_dtz(Position& pos, ProbeState* result);\n-bool root_probe(Position& pos, Search::RootMoves& rootMoves, Value& score);\n-bool root_probe_wdl(Position& pos, Search::RootMoves& rootMoves, Value& score);\n-void filter_root_moves(Position& pos, Search::RootMoves& rootMoves);\n+void dtz_score(Position& pos, Search::RootMoves& rootMoves);\n \n inline std::ostream& operator<<(std::ostream& os, const WDLScore v) {\n \ndiff --git a/src/thread.cpp b/src/thread.cpp\nindex eb360869b53..09e6ae6245d 100644\n--- a/src/thread.cpp\n+++ b/src/thread.cpp\n@@ -163,8 +163,8 @@ void ThreadPool::start_thinking(Position& pos, StateListPtr& states,\n           || std::count(limits.searchmoves.begin(), limits.searchmoves.end(), m))\n           rootMoves.emplace_back(m);\n \n-  if (!rootMoves.empty())\n-      Tablebases::filter_root_moves(pos, rootMoves);\n+  // If root position is in TB then probe rootMoves for DTZ info\n+  Tablebases::dtz_score(pos, rootMoves);\n \n   // After ownership transfer 'states' becomes empty, so if we stop the search\n   // and call 'go' again without setting a new position states.get() == NULL.\ndiff --git a/src/types.h b/src/types.h\nindex acca8743a48..4f88eec387e 100644\n--- a/src/types.h\n+++ b/src/types.h\n@@ -180,8 +180,8 @@ enum Value : int {\n   VALUE_INFINITE  = 32001,\n   VALUE_NONE      = 32002,\n \n-  VALUE_MATE_IN_MAX_PLY  =  VALUE_MATE - 2 * MAX_PLY,\n-  VALUE_MATED_IN_MAX_PLY = -VALUE_MATE + 2 * MAX_PLY,\n+  VALUE_MATE_IN_MAX_PLY  =  VALUE_MATE - MAX_PLY,\n+  VALUE_MATED_IN_MAX_PLY = -VALUE_MATE + MAX_PLY,\n \n   PawnValueMg   = 171,   PawnValueEg   = 240,\n   KnightValueMg = 764,   KnightValueEg = 848,\ndiff --git a/src/uci.cpp b/src/uci.cpp\nindex fc66f0b5321..ab672646b88 100644\n--- a/src/uci.cpp\n+++ b/src/uci.cpp\n@@ -143,7 +143,7 @@ namespace {\n   void bench(Position& pos, istream& args, StateListPtr& states) {\n \n     string token;\n-    uint64_t num, nodes = 0, cnt = 1;\n+    uint64_t num, nodes = 0, tbHits = 0, cnt = 1;\n \n     vector<string> list = setup_bench(pos, args);\n     num = count_if(list.begin(), list.end(), [](string s) { return s.find(\"go \") == 0; });\n@@ -160,7 +160,8 @@ namespace {\n             cerr << \"\\nPosition: \" << cnt++ << '/' << num << endl;\n             go(pos, is, states);\n             Threads.main()->wait_for_search_finished();\n-            nodes += Threads.nodes_searched();\n+            nodes  += Threads.nodes_searched();\n+            tbHits += Threads.tb_hits();\n         }\n         else if (token == \"setoption\")  setoption(is);\n         else if (token == \"position\")   position(pos, is, states);\n@@ -174,7 +175,8 @@ namespace {\n     cerr << \"\\n===========================\"\n          << \"\\nTotal time (ms) : \" << elapsed\n          << \"\\nNodes searched  : \" << nodes\n-         << \"\\nNodes/second    : \" << 1000 * nodes / elapsed << endl;\n+         << \"\\nNodes/second    : \" << 1000 * nodes / elapsed\n+         << \"\\nTB hits         : \" << tbHits << endl;\n   }\n \n } // namespace\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. The implementation incorrectly relies on DTZ-shortest moves throughout the search, potentially leading to repetition draws. Remove the reliance on DTZ when a mate is found to avoid this risk.\n\n2. Calls to `pos.is_draw(1)` in DTZ probing are unnecessary and can be removed since the implementation consistently selects DTZ-optimal moves.\n\n3. Consider using a rank value instead of raw WDL and DTZ values to simplify root move comparison and enhance flexibility in ranking.\n\n4. Split the PR into smaller patches focusing on individual issues for clarity and easier review. This assists with understanding the changes and any regressions.\n\n5. Investigate separating WDL information from position value to prevent unintended scoring overlaps."
      }
    ],
    "codediff_length": 32262
  },
  {
    "index": 88,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/timeman.cpp b/src/timeman.cpp\nindex 0848be420c0..588bd0bd5a9 100644\n--- a/src/timeman.cpp\n+++ b/src/timeman.cpp\n@@ -28,58 +28,10 @@\n \n TimeManagement Time; // Our global time management object\n \n-namespace {\n-\n-  enum TimeType { OptimumTime, MaxTime };\n-\n-  constexpr int MoveHorizon   = 50;   // Plan time management at most this many moves ahead\n-  constexpr double MaxRatio   = 7.3;  // When in trouble, we can step over reserved time with this ratio\n-  constexpr double StealRatio = 0.34; // However we must not steal time from remaining moves over this ratio\n-\n-\n-  // move_importance() is a skew-logistic function based on naive statistical\n-  // analysis of \"how many games are still undecided after n half-moves\". Game\n-  // is considered \"undecided\" as long as neither side has >275cp advantage.\n-  // Data was extracted from the CCRL game database with some simple filtering criteria.\n-\n-  double move_importance(int ply) {\n-\n-    constexpr double XScale = 6.85;\n-    constexpr double XShift = 64.5;\n-    constexpr double Skew   = 0.171;\n-\n-    return pow((1 + exp((ply - XShift) / XScale)), -Skew) + DBL_MIN; // Ensure non-zero\n-  }\n-\n-  template<TimeType T>\n-  TimePoint remaining(TimePoint myTime, int movesToGo, int ply, TimePoint slowMover) {\n-\n-    constexpr double TMaxRatio   = (T == OptimumTime ? 1.0 : MaxRatio);\n-    constexpr double TStealRatio = (T == OptimumTime ? 0.0 : StealRatio);\n-\n-    double moveImportance = (move_importance(ply) * slowMover) / 100.0;\n-    double otherMovesImportance = 0.0;\n-\n-    for (int i = 1; i < movesToGo; ++i)\n-        otherMovesImportance += move_importance(ply + 2 * i);\n-\n-    double ratio1 = (TMaxRatio * moveImportance) / (TMaxRatio * moveImportance + otherMovesImportance);\n-    double ratio2 = (moveImportance + TStealRatio * otherMovesImportance) / (moveImportance + otherMovesImportance);\n-\n-    return TimePoint(myTime * std::min(ratio1, ratio2)); // Intel C++ asks for an explicit cast\n-  }\n-\n-} // namespace\n-\n-\n-/// init() is called at the beginning of the search and calculates the allowed\n-/// thinking time out of the time control and current game ply. We support four\n-/// different kinds of time controls, passed in 'limits':\n-///\n-///  inc == 0 && movestogo == 0 means: x basetime  [sudden death!]\n-///  inc == 0 && movestogo != 0 means: x moves in y minutes\n-///  inc >  0 && movestogo == 0 means: x basetime + z increment\n-///  inc >  0 && movestogo != 0 means: x moves in y minutes + z increment\n+/// init() is called at the beginning of the search and calculates the bounds\n+/// of time allowed for the current game ply.  We currently support:\n+//      1) x basetime (+z increment)\n+//      2) x moves in y seconds (+z increment)\n \n void TimeManagement::init(Search::LimitsType& limits, Color us, int ply) {\n \n@@ -87,7 +39,10 @@ void TimeManagement::init(Search::LimitsType& limits, Color us, int ply) {\n   TimePoint moveOverhead    = Options[\"Move Overhead\"];\n   TimePoint slowMover       = Options[\"Slow Mover\"];\n   TimePoint npmsec          = Options[\"nodestime\"];\n-  TimePoint hypMyTime;\n+\n+  // opt_scale is a percentage of available time to use for the current move.\n+  // max_scale is a multiplier applied to optimumTime.\n+  double opt_scale, max_scale;\n \n   // If we have to play in 'nodes as time' mode, then convert from time\n   // to nodes, and use resulting values in time management formulas.\n@@ -105,29 +60,42 @@ void TimeManagement::init(Search::LimitsType& limits, Color us, int ply) {\n   }\n \n   startTime = limits.startTime;\n-  optimumTime = maximumTime = std::max(limits.time[us], minThinkingTime);\n \n-  const int maxMTG = limits.movestogo ? std::min(limits.movestogo, MoveHorizon) : MoveHorizon;\n+  //Maximum move horizon of 50 moves\n+  int mtg = limits.movestogo ? std::min(limits.movestogo, 50) : 50;\n \n-  // We calculate optimum time usage for different hypothetical \"moves to go\" values\n-  // and choose the minimum of calculated search time values. Usually the greatest\n-  // hypMTG gives the minimum values.\n-  for (int hypMTG = 1; hypMTG <= maxMTG; ++hypMTG)\n-  {\n-      // Calculate thinking time for hypothetical \"moves to go\"-value\n-      hypMyTime =  limits.time[us]\n-                 + limits.inc[us] * (hypMTG - 1)\n-                 - moveOverhead * (2 + std::min(hypMTG, 40));\n+  // Adjust moveOverhead if there are tiny increments\n+  moveOverhead = std::max(10, std::min<int>(limits.inc[us] / 2, moveOverhead));\n+\n+  // Make sure timeLeft is > 0 since we may use it as a divisor\n+  TimePoint timeLeft =  std::max(TimePoint(1),\n+      limits.time[us] + limits.inc[us] * (mtg - 1) - moveOverhead * (2 + mtg));\n \n-      hypMyTime = std::max(hypMyTime, TimePoint(0));\n+  // A user may scale time usage by setting UCI option \"Slow Mover\"\n+  // We presume this will lower elo or even cause time losses. User beware.\n+  timeLeft = slowMover * timeLeft / 100;\n \n-      TimePoint t1 = minThinkingTime + remaining<OptimumTime>(hypMyTime, hypMTG, ply, slowMover);\n-      TimePoint t2 = minThinkingTime + remaining<MaxTime    >(hypMyTime, hypMTG, ply, slowMover);\n+  // x basetime (+ z increment)\n+  // If there is a healthy increment, timeLeft can exceed actual available\n+  // game time for the current move, so also cap to 20% of available game time.\n+  if (limits.movestogo == 0)\n+  {\n+      opt_scale = std::min(0.007 + std::pow(ply + 3.0, 0.5) / 250.0,\n+                           0.2 * limits.time[us] / double(timeLeft));\n+      max_scale = 4 + std::pow(ply + 3, 0.3);\n+  }\n \n-      optimumTime = std::min(t1, optimumTime);\n-      maximumTime = std::min(t2, maximumTime);\n+  // x moves in y seconds (+ z increment)\n+  else\n+  {\n+      opt_scale = std::min((0.8 + ply / 128.0) / mtg,\n+                            0.8 * limits.time[us] / double(timeLeft));\n+      max_scale = std::min(6.3, 1.5 + 0.11 * mtg);\n   }\n \n+  optimumTime = std::max(minThinkingTime, opt_scale * timeLeft);\n+  maximumTime = std::min(0.9 * limits.time[us] - moveOverhead, max_scale * optimumTime);\n+\n   if (Options[\"Ponder\"])\n       optimumTime += optimumTime / 4;\n }\ndiff --git a/src/ucioption.cpp b/src/ucioption.cpp\nindex 26fcf30227a..ad576fda2d1 100644\n--- a/src/ucioption.cpp\n+++ b/src/ucioption.cpp\n@@ -69,8 +69,8 @@ void init(OptionsMap& o) {\n   o[\"MultiPV\"]               << Option(1, 1, 500);\n   o[\"Skill Level\"]           << Option(20, 0, 20);\n   o[\"Move Overhead\"]         << Option(30, 0, 5000);\n-  o[\"Minimum Thinking Time\"] << Option(20, 0, 5000);\n-  o[\"Slow Mover\"]            << Option(84, 10, 1000);\n+  o[\"Minimum Thinking Time\"] << Option( 0, 0, 5000);\n+  o[\"Slow Mover\"]            << Option(100, 10, 1000);\n   o[\"nodestime\"]             << Option(0, 0, 10000);\n   o[\"UCI_Chess960\"]          << Option(false);\n   o[\"UCI_AnalyseMode\"]       << Option(false);\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "### Actionable Feedback:\n\n1. **MinThinkingTime**: Change the default from 30 to 0. It should be user-configurable without impacting performance for fast games.\n\n2. **MoveOverhead**: Keep the default at 30ms; adjust to `std::max(10, std::min(incr / 2, moveOverhead))` to ensure it adapts reasonably to time controls. \n\n3. **Time Management Algorithm**: It should automatically determine optimal timing without needing a non-zero default for MinThinkingTime.\n\n4. **Testing**: Test added handler for configurations like x moves in y seconds (+z increment) and confirm extension to various time controls is effective.\n\n5. **Confirmation Needed**: Validate if proposed values for minThinkingTime and moveOverhead are acceptable to proceed with commits."
      }
    ],
    "codediff_length": 6775
  },
  {
    "index": 89,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/bitboard.h b/src/bitboard.h\nindex c9f199eee01..f14997bde04 100644\n--- a/src/bitboard.h\n+++ b/src/bitboard.h\n@@ -126,7 +126,7 @@ inline Bitboard& operator^=(Bitboard& b, Square s) {\n   return b ^= SquareBB[s];\n }\n \n-inline bool more_than_one(Bitboard b) {\n+constexpr bool more_than_one(Bitboard b) {\n   return b & (b - 1);\n }\n \n@@ -154,7 +154,7 @@ inline Bitboard file_bb(Square s) {\n /// shift() moves a bitboard one step along direction D. Mainly for pawns\n \n template<Square D>\n-inline Bitboard shift(Bitboard b) {\n+constexpr Bitboard shift(Bitboard b) {\n   return  D == NORTH      ?  b             << 8 : D == SOUTH      ?  b             >> 8\n         : D == NORTH_EAST ? (b & ~FileHBB) << 9 : D == SOUTH_EAST ? (b & ~FileHBB) >> 7\n         : D == NORTH_WEST ? (b & ~FileABB) << 7 : D == SOUTH_WEST ? (b & ~FileABB) >> 9\n@@ -228,12 +228,12 @@ inline bool aligned(Square s1, Square s2, Square s3) {\n /// distance() functions return the distance between x and y, defined as the\n /// number of steps for a king in x to reach y. Works with squares, ranks, files.\n \n-template<typename T> inline int distance(T x, T y) { return x < y ? y - x : x - y; }\n+template<typename T> constexpr int distance(T x, T y) { return x < y ? y - x : x - y; }\n template<> inline int distance<Square>(Square x, Square y) { return SquareDistance[x][y]; }\n \n template<typename T1, typename T2> inline int distance(T2 x, T2 y);\n-template<> inline int distance<File>(Square x, Square y) { return distance(file_of(x), file_of(y)); }\n-template<> inline int distance<Rank>(Square x, Square y) { return distance(rank_of(x), rank_of(y)); }\n+template<> constexpr int distance<File>(Square x, Square y) { return distance(file_of(x), file_of(y)); }\n+template<> constexpr int distance<Rank>(Square x, Square y) { return distance(rank_of(x), rank_of(y)); }\n \n \n /// attacks_bb() returns a bitboard representing all the squares attacked by a\ndiff --git a/src/movegen.h b/src/movegen.h\nindex 825605704c9..daee502d8cc 100644\n--- a/src/movegen.h\n+++ b/src/movegen.h\n@@ -45,7 +45,7 @@ struct ExtMove {\n \n   // Inhibit unwanted implicit conversions to Move\n   // with an ambiguity that yields to a compile error.\n-  operator float() const;\n+  operator float() const = delete;\n };\n \n inline bool operator<(const ExtMove& f, const ExtMove& s) {\ndiff --git a/src/types.h b/src/types.h\nindex acca8743a48..eef1fde288b 100644\n--- a/src/types.h\n+++ b/src/types.h\n@@ -146,7 +146,7 @@ enum CastlingRight {\n };\n \n template<Color C, CastlingSide S> struct MakeCastling {\n-  static const CastlingRight\n+  static constexpr CastlingRight\n   right = C == WHITE ? S == QUEEN_SIDE ? WHITE_OOO : WHITE_OO\n                      : S == QUEEN_SIDE ? BLACK_OOO : BLACK_OO;\n };\n@@ -261,7 +261,7 @@ enum Rank : int {\n /// care to avoid left-shifting a signed int to avoid undefined behavior.\n enum Score : int { SCORE_ZERO };\n \n-inline Score make_score(int mg, int eg) {\n+constexpr Score make_score(int mg, int eg) {\n   return Score((int)((unsigned int)eg << 16) + mg);\n }\n \n@@ -269,32 +269,30 @@ inline Score make_score(int mg, int eg) {\n /// according to the standard a simple cast to short is implementation defined\n /// and so is a right shift of a signed integer.\n inline Value eg_value(Score s) {\n-\n-  union { uint16_t u; int16_t s; } eg = { uint16_t(unsigned(s + 0x8000) >> 16) };\n-  return Value(eg.s);\n+\tunion { uint16_t u; int16_t s; } eg = { uint16_t(unsigned(s + 0x8000) >> 16) };\n+\treturn Value(eg.s);\n }\n \n inline Value mg_value(Score s) {\n-\n   union { uint16_t u; int16_t s; } mg = { uint16_t(unsigned(s)) };\n   return Value(mg.s);\n }\n \n #define ENABLE_BASE_OPERATORS_ON(T)                             \\\n-inline T operator+(T d1, T d2) { return T(int(d1) + int(d2)); } \\\n-inline T operator-(T d1, T d2) { return T(int(d1) - int(d2)); } \\\n-inline T operator-(T d) { return T(-int(d)); }                  \\\n+constexpr T operator+(T d1, T d2) { return T(int(d1) + int(d2)); } \\\n+constexpr T operator-(T d1, T d2) { return T(int(d1) - int(d2)); } \\\n+constexpr T operator-(T d) { return T(-int(d)); }                  \\\n inline T& operator+=(T& d1, T d2) { return d1 = d1 + d2; }      \\\n inline T& operator-=(T& d1, T d2) { return d1 = d1 - d2; }      \\\n \n #define ENABLE_FULL_OPERATORS_ON(T)                             \\\n ENABLE_BASE_OPERATORS_ON(T)                                     \\\n-inline T operator*(int i, T d) { return T(i * int(d)); }        \\\n-inline T operator*(T d, int i) { return T(int(d) * i); }        \\\n+constexpr T operator*(int i, T d) { return T(i * int(d)); }        \\\n+constexpr T operator*(T d, int i) { return T(int(d) * i); }        \\\n inline T& operator++(T& d) { return d = T(int(d) + 1); }        \\\n inline T& operator--(T& d) { return d = T(int(d) - 1); }        \\\n-inline T operator/(T d, int i) { return T(int(d) / i); }        \\\n-inline int operator/(T d1, T d2) { return int(d1) / int(d2); }  \\\n+constexpr T operator/(T d, int i) { return T(int(d) / i); }        \\\n+constexpr int operator/(T d1, T d2) { return int(d1) / int(d2); }  \\\n inline T& operator*=(T& d, int i) { return d = T(int(d) * i); } \\\n inline T& operator/=(T& d, int i) { return d = T(int(d) / i); }\n \n@@ -313,14 +311,14 @@ ENABLE_BASE_OPERATORS_ON(Score)\n #undef ENABLE_BASE_OPERATORS_ON\n \n /// Additional operators to add integers to a Value\n-inline Value operator+(Value v, int i) { return Value(int(v) + i); }\n-inline Value operator-(Value v, int i) { return Value(int(v) - i); }\n+constexpr Value operator+(Value v, int i) { return Value(int(v) + i); }\n+constexpr Value operator-(Value v, int i) { return Value(int(v) - i); }\n inline Value& operator+=(Value& v, int i) { return v = v + i; }\n inline Value& operator-=(Value& v, int i) { return v = v - i; }\n \n /// Only declared but not defined. We don't want to multiply two scores due to\n /// a very high risk of overflow. So user should explicitly convert to integer.\n-inline Score operator*(Score s1, Score s2);\n+Score operator*(Score s1, Score s2) = delete;\n \n /// Division of a Score must be handled separately for each term\n inline Score operator/(Score s, int i) {\n@@ -328,6 +326,11 @@ inline Score operator/(Score s, int i) {\n }\n \n /// Multiplication of a Score by an integer. We check for overflow in debug mode.\n+#ifdef NDEBUG\n+constexpr Score operator*(Score s, int i) {\n+\treturn Score(int(s) * i);\n+}\n+#else\n inline Score operator*(Score s, int i) {\n \n   Score result = Score(int(s) * i);\n@@ -338,40 +341,41 @@ inline Score operator*(Score s, int i) {\n \n   return result;\n }\n+#endif\n \n-inline Color operator~(Color c) {\n+constexpr Color operator~(Color c) {\n   return Color(c ^ BLACK); // Toggle color\n }\n \n-inline Square operator~(Square s) {\n+constexpr Square operator~(Square s) {\n   return Square(s ^ SQ_A8); // Vertical flip SQ_A1 -> SQ_A8\n }\n \n-inline Piece operator~(Piece pc) {\n+constexpr Piece operator~(Piece pc) {\n   return Piece(pc ^ 8); // Swap color of piece B_KNIGHT -> W_KNIGHT\n }\n \n-inline CastlingRight operator|(Color c, CastlingSide s) {\n+constexpr CastlingRight operator|(Color c, CastlingSide s) {\n   return CastlingRight(WHITE_OO << ((s == QUEEN_SIDE) + 2 * c));\n }\n \n-inline Value mate_in(int ply) {\n+constexpr Value mate_in(int ply) {\n   return VALUE_MATE - ply;\n }\n \n-inline Value mated_in(int ply) {\n+constexpr Value mated_in(int ply) {\n   return -VALUE_MATE + ply;\n }\n \n-inline Square make_square(File f, Rank r) {\n+constexpr Square make_square(File f, Rank r) {\n   return Square((r << 3) + f);\n }\n \n-inline Piece make_piece(Color c, PieceType pt) {\n+constexpr Piece make_piece(Color c, PieceType pt) {\n   return Piece((c << 3) + pt);\n }\n \n-inline PieceType type_of(Piece pc) {\n+constexpr PieceType type_of(Piece pc) {\n   return PieceType(pc & 7);\n }\n \n@@ -380,27 +384,27 @@ inline Color color_of(Piece pc) {\n   return Color(pc >> 3);\n }\n \n-inline bool is_ok(Square s) {\n+constexpr bool is_ok(Square s) {\n   return s >= SQ_A1 && s <= SQ_H8;\n }\n \n-inline File file_of(Square s) {\n+constexpr File file_of(Square s) {\n   return File(s & 7);\n }\n \n-inline Rank rank_of(Square s) {\n+constexpr Rank rank_of(Square s) {\n   return Rank(s >> 3);\n }\n \n-inline Square relative_square(Color c, Square s) {\n+constexpr Square relative_square(Color c, Square s) {\n   return Square(s ^ (c * 56));\n }\n \n-inline Rank relative_rank(Color c, Rank r) {\n+constexpr Rank relative_rank(Color c, Rank r) {\n   return Rank(r ^ (c * 7));\n }\n \n-inline Rank relative_rank(Color c, Square s) {\n+constexpr Rank relative_rank(Color c, Square s) {\n   return relative_rank(c, rank_of(s));\n }\n \n@@ -409,27 +413,27 @@ inline bool opposite_colors(Square s1, Square s2) {\n   return ((s >> 3) ^ s) & 1;\n }\n \n-inline Square pawn_push(Color c) {\n+constexpr Square pawn_push(Color c) {\n   return c == WHITE ? NORTH : SOUTH;\n }\n \n-inline Square from_sq(Move m) {\n+constexpr Square from_sq(Move m) {\n   return Square((m >> 6) & 0x3F);\n }\n \n-inline Square to_sq(Move m) {\n+constexpr Square to_sq(Move m) {\n   return Square(m & 0x3F);\n }\n \n-inline int from_to(Move m) {\n+constexpr int from_to(Move m) {\n  return m & 0xFFF;\n }\n \n-inline MoveType type_of(Move m) {\n+constexpr MoveType type_of(Move m) {\n   return MoveType(m & (3 << 14));\n }\n \n-inline PieceType promotion_type(Move m) {\n+constexpr PieceType promotion_type(Move m) {\n   return PieceType(((m >> 12) & 3) + KNIGHT);\n }\n \n@@ -438,11 +442,11 @@ inline Move make_move(Square from, Square to) {\n }\n \n template<MoveType T>\n-inline Move make(Square from, Square to, PieceType pt = KNIGHT) {\n+constexpr Move make(Square from, Square to, PieceType pt = KNIGHT) {\n   return Move(T + ((pt - KNIGHT) << 12) + (from << 6) + to);\n }\n \n-inline bool is_ok(Move m) {\n+constexpr bool is_ok(Move m) {\n   return from_sq(m) != to_sq(m); // Catch MOVE_NULL and MOVE_NONE\n }\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Inconsistency with `constexpr` Specifier**: The function `tte.value()` is incorrectly marked as `constexpr` since it returns a heap value\u2014this violates the standard, as it cannot be evaluated at compile-time with any argument values. Consider refactoring or removing the `constexpr` specifier.\n\n2. **Performance Optimization**: The `make_score()` function's optimizations appear effective. Ensure that similar optimizations are reviewed across other key functions. Adding `constexpr` for constants guarantees their evaluation at compile-time, which is beneficial; apply this where applicable.\n\n3. **Inline Specifications**: Reassess the use of `inline` with `constexpr` functions, as the latter implicates inlining since C++17. Removing `inline` from constexpr declarations can streamline code without negatively impacting performance.\n\n4. **Compiler Differences**: Note discrepancies between GCC and Clang optimizations. Additional testing across compilers is advised to corroborate performance benefits and optimization fidelity.\n\n5. **Next Steps**: Integrate changes based on the above observations and conduct performance benchmarking to confirm improvements."
      }
    ],
    "codediff_length": 9726
  },
  {
    "index": 90,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/endgame.cpp b/src/endgame.cpp\nindex ca17f6ac8fc..696e60a318e 100644\n--- a/src/endgame.cpp\n+++ b/src/endgame.cpp\n@@ -100,11 +100,8 @@ Endgames::Endgames() {\n   add<KQKR>(\"KQKR\");\n \n   add<KNPK>(\"KNPK\");\n-  add<KNPKB>(\"KNPKB\");\n   add<KRPKR>(\"KRPKR\");\n   add<KRPKB>(\"KRPKB\");\n-  add<KBPKB>(\"KBPKB\");\n-  add<KBPKN>(\"KBPKN\");\n   add<KBPPKB>(\"KBPPKB\");\n   add<KRPPKRP>(\"KRPPKRP\");\n }\n@@ -606,58 +603,6 @@ ScaleFactor Endgame<KPsK>::operator()(const Position& pos) const {\n   return SCALE_FACTOR_NONE;\n }\n \n-\n-/// KBP vs KB. There are two rules: if the defending king is somewhere along the\n-/// path of the pawn, and the square of the king is not of the same color as the\n-/// stronger side's bishop, it's a draw. If the two bishops have opposite color,\n-/// it's almost always a draw.\n-template<>\n-ScaleFactor Endgame<KBPKB>::operator()(const Position& pos) const {\n-\n-  assert(verify_material(pos, strongSide, BishopValueMg, 1));\n-  assert(verify_material(pos, weakSide,   BishopValueMg, 0));\n-\n-  Square pawnSq = pos.square<PAWN>(strongSide);\n-  Square strongBishopSq = pos.square<BISHOP>(strongSide);\n-  Square weakBishopSq = pos.square<BISHOP>(weakSide);\n-  Square weakKingSq = pos.square<KING>(weakSide);\n-\n-  // Case 1: Defending king blocks the pawn, and cannot be driven away\n-  if (   file_of(weakKingSq) == file_of(pawnSq)\n-      && relative_rank(strongSide, pawnSq) < relative_rank(strongSide, weakKingSq)\n-      && (   opposite_colors(weakKingSq, strongBishopSq)\n-          || relative_rank(strongSide, weakKingSq) <= RANK_6))\n-      return SCALE_FACTOR_DRAW;\n-\n-  // Case 2: Opposite colored bishops\n-  if (opposite_colors(strongBishopSq, weakBishopSq))\n-  {\n-      // We assume that the position is drawn in the following three situations:\n-      //\n-      //   a. The pawn is on rank 5 or further back.\n-      //   b. The defending king is somewhere in the pawn's path.\n-      //   c. The defending bishop attacks some square along the pawn's path,\n-      //      and is at least three squares away from the pawn.\n-      //\n-      // These rules are probably not perfect, but in practice they work\n-      // reasonably well.\n-\n-      if (relative_rank(strongSide, pawnSq) <= RANK_5)\n-          return SCALE_FACTOR_DRAW;\n-\n-      Bitboard path = forward_file_bb(strongSide, pawnSq);\n-\n-      if (path & pos.pieces(weakSide, KING))\n-          return SCALE_FACTOR_DRAW;\n-\n-      if (  (pos.attacks_from<BISHOP>(weakBishopSq) & path)\n-          && distance(weakBishopSq, pawnSq) >= 3)\n-          return SCALE_FACTOR_DRAW;\n-  }\n-  return SCALE_FACTOR_NONE;\n-}\n-\n-\n /// KBPP vs KB. It detects a few basic draws with opposite-colored bishops\n template<>\n ScaleFactor Endgame<KBPPKB>::operator()(const Position& pos) const {\n@@ -726,30 +671,6 @@ ScaleFactor Endgame<KBPPKB>::operator()(const Position& pos) const {\n   }\n }\n \n-\n-/// KBP vs KN. There is a single rule: If the defending king is somewhere along\n-/// the path of the pawn, and the square of the king is not of the same color as\n-/// the stronger side's bishop, it's a draw.\n-template<>\n-ScaleFactor Endgame<KBPKN>::operator()(const Position& pos) const {\n-\n-  assert(verify_material(pos, strongSide, BishopValueMg, 1));\n-  assert(verify_material(pos, weakSide, KnightValueMg, 0));\n-\n-  Square pawnSq = pos.square<PAWN>(strongSide);\n-  Square strongBishopSq = pos.square<BISHOP>(strongSide);\n-  Square weakKingSq = pos.square<KING>(weakSide);\n-\n-  if (   file_of(weakKingSq) == file_of(pawnSq)\n-      && relative_rank(strongSide, pawnSq) < relative_rank(strongSide, weakKingSq)\n-      && (   opposite_colors(weakKingSq, strongBishopSq)\n-          || relative_rank(strongSide, weakKingSq) <= RANK_6))\n-      return SCALE_FACTOR_DRAW;\n-\n-  return SCALE_FACTOR_NONE;\n-}\n-\n-\n /// KNP vs K. There is a single rule: if the pawn is a rook pawn on the 7th rank\n /// and the defending king prevents the pawn from advancing, the position is drawn.\n template<>\n@@ -768,25 +689,6 @@ ScaleFactor Endgame<KNPK>::operator()(const Position& pos) const {\n   return SCALE_FACTOR_NONE;\n }\n \n-\n-/// KNP vs KB. If knight can block bishop from taking pawn, it's a win.\n-/// Otherwise the position is drawn.\n-template<>\n-ScaleFactor Endgame<KNPKB>::operator()(const Position& pos) const {\n-\n-  Square pawnSq = pos.square<PAWN>(strongSide);\n-  Square bishopSq = pos.square<BISHOP>(weakSide);\n-  Square weakKingSq = pos.square<KING>(weakSide);\n-\n-  // King needs to get close to promoting pawn to prevent knight from blocking.\n-  // Rules for this are very tricky, so just approximate.\n-  if (forward_file_bb(strongSide, pawnSq) & pos.attacks_from<BISHOP>(bishopSq))\n-      return ScaleFactor(distance(weakKingSq, pawnSq));\n-\n-  return SCALE_FACTOR_NONE;\n-}\n-\n-\n /// KP vs KP. This is done by removing the weakest side's pawn and probing the\n /// KP vs K bitbase: If the weakest side has a draw without the pawn, it probably\n /// has at least a draw with the pawn as well. The exception is when the stronger\ndiff --git a/src/endgame.h b/src/endgame.h\nindex 3d61207c419..00259922734 100644\n--- a/src/endgame.h\n+++ b/src/endgame.h\n@@ -53,11 +53,8 @@ enum EndgameCode {\n   KRPKB,   // KRP vs KB\n   KRPPKRP, // KRPP vs KRP\n   KPsK,    // K and pawns vs K\n-  KBPKB,   // KBP vs KB\n   KBPPKB,  // KBPP vs KB\n-  KBPKN,   // KBP vs KN\n   KNPK,    // KNP vs K\n-  KNPKB,   // KNP vs KB\n   KPKP     // KP vs KP\n };\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "**Feedback Summary:**\n\n1. **KBPKN Function:** Consider retaining the function as it encodes necessary endgame knowledge despite limited utility in practical scenarios.\n\n2. **KBPKB Function:** Do not delete case 1; it provides necessary draw evaluations. Case 2's removal is acceptable due to existing scaling factors.\n\n3. **KNPKB Function:** Either remove or improve; currently exhibits suboptimal scoring performance. Without a method to verify improvement, removal might be more practical.\n\n4. **Scalability Testing:** Propose developing heuristics for minor piece endgames and inputting them into `evaluate_scale_factor`. Use statistical analysis (A/N, B/N, C/N) for validating heuristic efficiency. \n\n5. **Database Utilization:** Establish an endgame database to enhance evaluation quality; adjust parameters in `material.cpp` for more nuanced scoring on KRKB."
      }
    ],
    "codediff_length": 5362
  },
  {
    "index": 91,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/search.cpp b/src/search.cpp\nindex 54a9ec878c4..e5112707049 100644\n--- a/src/search.cpp\n+++ b/src/search.cpp\n@@ -1090,11 +1090,12 @@ namespace {\n       if (   !SpNode\n           &&  Threads.size() >= 2\n           &&  depth >= Threads.minimumSplitDepth\n+          &&  thisThread->splitPointsSize < MAX_SPLITPOINTS_PER_THREAD\n           &&  (   !thisThread->activeSplitPoint\n                || !thisThread->activeSplitPoint->allSlavesSearching\n-               || (   Threads.size() > MAX_SLAVES_PER_SPLITPOINT\n-                   && thisThread->activeSplitPoint->slavesMask.count() == MAX_SLAVES_PER_SPLITPOINT))\n-          &&  thisThread->splitPointsSize < MAX_SPLITPOINTS_PER_THREAD)\n+               // Try to split again if previous split was limited due to\n+               // hit max_slaves_per_splitpoint.\n+               || thisThread->can_split_again()))\n       {\n           assert(bestValue > -VALUE_INFINITE && bestValue < beta);\n \n@@ -1649,7 +1650,7 @@ void Thread::idle_loop() {\n \n               if (   sp\n                   && sp->allSlavesSearching\n-                  && sp->slavesMask.count() < MAX_SLAVES_PER_SPLITPOINT\n+                  && sp->slavesMask.count() < Threads.max_slaves_per_splitpoint(sp->depth)\n                   && can_join(sp))\n               {\n                   assert(this != th);\n@@ -1678,7 +1679,7 @@ void Thread::idle_loop() {\n               sp->spinlock.acquire();\n \n               if (   sp->allSlavesSearching\n-                  && sp->slavesMask.count() < MAX_SLAVES_PER_SPLITPOINT)\n+                  && sp->slavesMask.count() < Threads.max_slaves_per_splitpoint(sp->depth))\n               {\n                   spinlock.acquire();\n \ndiff --git a/src/thread.cpp b/src/thread.cpp\nindex e2881c4ee78..03b24cd54f9 100644\n--- a/src/thread.cpp\n+++ b/src/thread.cpp\n@@ -102,6 +102,13 @@ bool Thread::cutoff_occurred() const {\n }\n \n \n+bool Thread::can_split_again() const {\n+\n+  SplitPoint* sp = activeSplitPoint;\n+  size_t oldMax = Threads.max_slaves_per_splitpoint(sp->depth);\n+ \n+  return (Threads.size() > oldMax && sp->slavesMask.count() == oldMax);\n+}\n // Thread::can_join() checks whether the thread is available to join the split\n // point 'sp'. An obvious requirement is that thread must be idle. With more than\n // two threads, this is not sufficient: If the thread is the master of some split\n@@ -145,7 +152,6 @@ void Thread::split(Position& pos, Stack* ss, Value alpha, Value beta, Value* bes\n   SplitPoint& sp = splitPoints[splitPointsSize];\n \n   sp.spinlock.acquire(); // No contention here until we don't increment splitPointsSize\n-  spinlock.acquire();\n \n   sp.master = this;\n   sp.parentSplitPoint = activeSplitPoint;\n@@ -168,12 +174,11 @@ void Thread::split(Position& pos, Stack* ss, Value alpha, Value beta, Value* bes\n   ++splitPointsSize;\n   activeSplitPoint = &sp;\n   activePosition = nullptr;\n-  spinlock.release();\n \n   // Try to allocate available threads\n   Thread* slave;\n \n-  while (    sp.slavesMask.count() < MAX_SLAVES_PER_SPLITPOINT\n+  while (    sp.slavesMask.count() < Threads.max_slaves_per_splitpoint(depth)\n          && (slave = Threads.available_slave(&sp)) != nullptr)\n   {\n      slave->spinlock.acquire();\n@@ -196,7 +201,6 @@ void Thread::split(Position& pos, Stack* ss, Value alpha, Value beta, Value* bes\n \n   Thread::idle_loop(); // Force a call to base class idle_loop()\n \n-  sp.spinlock.acquire();\n   spinlock.acquire();\n \n   // In the helpful master concept, a master can help only a sub-tree of its\n@@ -218,7 +222,6 @@ void Thread::split(Position& pos, Stack* ss, Value alpha, Value beta, Value* bes\n   *bestValue = sp.bestValue;\n \n   spinlock.release();\n-  sp.spinlock.release();\n }\n \n \n@@ -296,6 +299,13 @@ void ThreadPool::init() {\n   read_uci_options();\n }\n \n+size_t ThreadPool::max_slaves_per_splitpoint(Depth depth)\n+{\n+\n+  return std::min((1 + depth / (2 * ONE_PLY)), MAX_SLAVES_PER_SPLITPOINT); \n+}\n+\n+\n \n // ThreadPool::exit() terminates the threads before the program exits. Cannot be\n // done in d'tor because threads must be terminated before freeing us.\ndiff --git a/src/thread.h b/src/thread.h\nindex e880b01c6fc..627f3948d55 100644\n--- a/src/thread.h\n+++ b/src/thread.h\n@@ -38,7 +38,7 @@ struct Thread;\n \n const size_t MAX_THREADS = 128;\n const size_t MAX_SPLITPOINTS_PER_THREAD = 8;\n-const size_t MAX_SLAVES_PER_SPLITPOINT = 4;\n+const int    MAX_SLAVES_PER_SPLITPOINT = 7;\n \n class Spinlock {\n \n@@ -114,6 +114,7 @@ struct Thread : public ThreadBase {\n   virtual void idle_loop();\n   bool cutoff_occurred() const;\n   bool can_join(const SplitPoint* sp) const;\n+  bool can_split_again() const;\n \n   void split(Position& pos, Search::Stack* ss, Value alpha, Value beta, Value* bestValue, Move* bestMove,\n              Depth depth, int moveCount, MovePicker* movePicker, int nodeType, bool cutNode);\n@@ -163,7 +164,7 @@ struct ThreadPool : public std::vector<Thread*> {\n   void read_uci_options();\n   Thread* available_slave(const SplitPoint* sp) const;\n   void start_thinking(const Position&, const Search::LimitsType&, Search::StateStackPtr&);\n-\n+  size_t  max_slaves_per_splitpoint(Depth depth);\n   Depth minimumSplitDepth;\n   TimerThread* timer;\n };\ndiff --git a/src/ucioption.cpp b/src/ucioption.cpp\nindex 828d138fd21..c2d04ad0d3a 100644\n--- a/src/ucioption.cpp\n+++ b/src/ucioption.cpp\n@@ -58,7 +58,7 @@ void init(OptionsMap& o) {\n \n   o[\"Write Debug Log\"]       << Option(false, on_logger);\n   o[\"Contempt\"]              << Option(0, -100, 100);\n-  o[\"Min Split Depth\"]       << Option(5, 0, 12, on_threads);\n+  o[\"Min Split Depth\"]       << Option(2, 0, 12, on_threads);\n   o[\"Threads\"]               << Option(1, 1, MAX_THREADS, on_threads);\n   o[\"Hash\"]                  << Option(16, 1, MaxHashMB, on_hash_size);\n   o[\"Clear Hash\"]            << Option(on_clear_hash);\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Performance Concerns**: Patch improves ELO at 7 cores and below but shows degraded performance on CoffeeOne-23 cores. Suggest using \"Min Split Depth = 5\" to reduce overhead from spinlocks and shared variables on high-core machines.\n\n2. **Default Configuration**: Set \"Min Split Depth\" to 2 for typical users (95% use <= 8 cores) but keep a manual option for fine-tuning.\n\n3. **Implementation Issue**: The recent `minsplitdepth2_fix2` branch causes hangs due to `slavesMask` not being volatile, risking race conditions. Recommend making `slavesMask` volatile to ensure memory consistency across threads.\n\n4. **Testing**: Before committing changes, isolate tests for \"Min Split Depth\" and \"max slaves per split point\" without speculative lock removals to confirm their individual impacts. \n\n5. **Code Review**: Remove speculative locks until the original hang scenario is understood and documented. Suggest future redesign of SMP to adopt C++11 atomics."
      }
    ],
    "codediff_length": 5788
  },
  {
    "index": 92,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/movepick.cpp b/src/movepick.cpp\nindex 1ec56c2f700..95e60003f00 100644\n--- a/src/movepick.cpp\n+++ b/src/movepick.cpp\n@@ -115,7 +115,7 @@ MovePicker::MovePicker(const Position& p, Move ttm, Value th)\n   ttMove =   ttm\n           && pos.pseudo_legal(ttm)\n           && pos.capture(ttm)\n-          && pos.see(ttm) > threshold ? ttm : MOVE_NONE;\n+          && pos.see_ge(ttm, threshold + 1)? ttm : MOVE_NONE;\n \n   stage += (ttMove == MOVE_NONE);\n }\n@@ -201,7 +201,7 @@ Move MovePicker::next_move() {\n           move = pick_best(cur++, endMoves);\n           if (move != ttMove)\n           {\n-              if (pos.see_sign(move) >= VALUE_ZERO)\n+              if (pos.see_ge(move, VALUE_ZERO))\n                   return move;\n \n               // Losing capture, move it to the beginning of the array\n@@ -295,7 +295,7 @@ Move MovePicker::next_move() {\n       {\n           move = pick_best(cur++, endMoves);\n           if (   move != ttMove\n-              && pos.see(move) > threshold)\n+              && pos.see_ge(move, threshold + 1))\n               return move;\n       }\n       break;\ndiff --git a/src/position.cpp b/src/position.cpp\nindex 9fe5f893c9d..445eedad0f1 100644\n--- a/src/position.cpp\n+++ b/src/position.cpp\n@@ -954,105 +954,91 @@ Key Position::key_after(Move m) const {\n   return k ^ Zobrist::psq[pc][to] ^ Zobrist::psq[pc][from];\n }\n \n+/// Position::see_ge (Static Exchange Evaluation Greater or Equal) tests if the SEE value of move is\n+/// greater or equal to the given value\n+bool Position::see_ge(Move m, Value v) const {\n \n-/// Position::see() is a static exchange evaluator: It tries to estimate the\n-/// material gain or loss resulting from a move.\n-\n-Value Position::see_sign(Move m) const {\n+  // We'll use an algorithm similar to alpha-beta pruning with a null window\n \n   assert(is_ok(m));\n \n-  // Early return if SEE cannot be negative because captured piece value\n-  // is not less then capturing one. Note that king moves always return\n-  // here because king midgame value is set to 0.\n-  if (PieceValue[MG][moved_piece(m)] <= PieceValue[MG][piece_on(to_sq(m))])\n-      return VALUE_KNOWN_WIN;\n-\n-  return see(m);\n-}\n+  // Castling moves are implemented as king capturing the rook so cannot\n+  // be handled correctly. Simply assume the SEE value is VALUE_ZERO that is always correct\n+  // unless in the rare case the rook ends up under attack.\n+  if (type_of(m) == CASTLING)\n+    return VALUE_ZERO >= v;\n \n-Value Position::see(Move m) const {\n+  Square from = from_sq(m), to = to_sq(m);\n \n-  Square from, to;\n-  Bitboard occupied, attackers, stmAttackers;\n-  Value swapList[32];\n-  int slIndex = 1;\n-  PieceType nextVictim;\n-  Color stm;\n+  PieceType nextVictim = type_of(piece_on(from));\n \n-  assert(is_ok(m));\n+  // We'll first consider a move by the opponent\n+  Color stm = ~color_of(piece_on(from));\n \n-  from = from_sq(m);\n-  to = to_sq(m);\n-  swapList[0] = PieceValue[MG][piece_on(to)];\n-  stm = color_of(piece_on(from));\n-  occupied = pieces() ^ from;\n+  // the sum of the values of the pieces taken by us minus the corresponding sum of the opponent\n+  Value balance;\n \n-  // Castling moves are implemented as king capturing the rook so cannot\n-  // be handled correctly. Simply return VALUE_ZERO that is always correct\n-  // unless in the rare case the rook ends up under attack.\n-  if (type_of(m) == CASTLING)\n-      return VALUE_ZERO;\n+  Bitboard occupied;\n \n   if (type_of(m) == ENPASSANT)\n   {\n-      occupied ^= to - pawn_push(stm); // Remove the captured pawn\n-      swapList[0] = PieceValue[MG][PAWN];\n+      occupied = SquareBB[to - pawn_push(~stm)]; // Remove the captured pawn\n+      balance = PieceValue[MG][PAWN];\n+  }\n+  else\n+  {\n+      balance = PieceValue[MG][piece_on(to)];\n+      occupied = 0;\n   }\n \n-  // Find all attackers to the destination square, with the moving piece\n-  // removed, but possibly an X-ray attacker added behind it.\n-  attackers = attackers_to(to, occupied) & occupied;\n+  if (balance < v)\n+    return false;\n \n-  // If the opponent has no attackers we are finished\n-  stm = ~stm;\n-  stmAttackers = attackers & pieces(stm);\n-  occupied ^= to; // For the case when captured piece is a pinner\n+  if (nextVictim == KING)\n+    return true;\n \n-  // Don't allow pinned pieces to attack pieces except the king as long all\n-  // pinners are on their original square.\n-  if (!(st->pinnersForKing[stm] & ~occupied))\n-      stmAttackers &= ~st->blockersForKing[stm];\n+  balance -= PieceValue[MG][nextVictim];\n \n-  if (!stmAttackers)\n-        return swapList[0];\n+  if (balance >= v)\n+    return true;\n \n-  // The destination square is defended, which makes things rather more\n-  // difficult to compute. We proceed by building up a \"swap list\" containing\n-  // the material gain or loss at each stop in a sequence of captures to the\n-  // destination square, where the sides alternately capture, and always\n-  // capture with the least valuable piece. After each capture, we look for\n-  // new X-ray attacks from behind the capturing piece.\n-  nextVictim = type_of(piece_on(from));\n+  // true if the opponent is to move and false if we are to move\n+  bool relativeStm = true;\n+  Bitboard stmAttackers;\n \n-  do {\n-      assert(slIndex < 32);\n+  occupied ^= pieces() ^ from ^ to;\n \n-      // Add the new entry to the swap list\n-      swapList[slIndex] = -swapList[slIndex - 1] + PieceValue[MG][nextVictim];\n+  // Find all attackers to the destination square, with the moving piece\n+  // removed, but possibly an X-ray attacker added behind it.\n+  Bitboard attackers = attackers_to(to, occupied) & occupied;\n \n-      // Locate and remove the next least valuable attacker\n-      nextVictim = min_attacker<PAWN>(byTypeBB, to, stmAttackers, occupied, attackers);\n-      stm = ~stm;\n+  while (true)\n+  {\n       stmAttackers = attackers & pieces(stm);\n \n-      // Don't allow pinned pieces to attack pieces except the king\n-      if (   nextVictim != KING\n-          && !(st->pinnersForKing[stm] & ~occupied))\n+      // Don't allow pinned pieces to attack pieces except the king as long all\n+      // pinners are on their original square.\n+      if (!(st->pinnersForKing[stm] & ~occupied))\n           stmAttackers &= ~st->blockersForKing[stm];\n \n-      ++slIndex;\n+      if (!stmAttackers)\n+          return relativeStm;\n \n-  } while (stmAttackers && (nextVictim != KING || (--slIndex, false))); // Stop before a king capture\n+      // Locate and remove the next least valuable attacker\n+      nextVictim = min_attacker<PAWN>(byTypeBB, to, stmAttackers, occupied, attackers);\n \n-  // Having built the swap list, we negamax through it to find the best\n-  // achievable score from the point of view of the side to move.\n-  while (--slIndex)\n-      swapList[slIndex - 1] = std::min(-swapList[slIndex], swapList[slIndex - 1]);\n+      if (nextVictim == KING)\n+          return relativeStm == bool(attackers & pieces(~stm));\n \n-  return swapList[0];\n-}\n+      balance = relativeStm ? balance + PieceValue[MG][nextVictim] : balance - PieceValue[MG][nextVictim];\n+      relativeStm = !relativeStm;\n+\n+      if (relativeStm == (balance >= v))\n+          return relativeStm;\n \n+      stm = ~stm;\n+  }\n+}\n \n /// Position::is_draw() tests whether the position is drawn by 50-move rule\n /// or by repetition. It does not detect stalemates.\ndiff --git a/src/position.h b/src/position.h\nindex 9830619eac8..8db7c5f03f7 100644\n--- a/src/position.h\n+++ b/src/position.h\n@@ -133,8 +133,7 @@ class Position {\n   void undo_null_move();\n \n   // Static Exchange Evaluation\n-  Value see(Move m) const;\n-  Value see_sign(Move m) const;\n+  bool see_ge(Move m, Value value) const;\n \n   // Accessing hash keys\n   Key key() const;\n@@ -375,6 +374,7 @@ inline Thread* Position::this_thread() const {\n   return thisThread;\n }\n \n+\n inline void Position::put_piece(Piece pc, Square s) {\n \n   board[s] = pc;\ndiff --git a/src/search.cpp b/src/search.cpp\nindex 64cdb325ebc..eae3468074d 100644\n--- a/src/search.cpp\n+++ b/src/search.cpp\n@@ -889,7 +889,7 @@ namespace {\n       // Step 12. Extend checks\n       if (    givesCheck\n           && !moveCountPruning\n-          &&  pos.see_sign(move) >= VALUE_ZERO)\n+          &&  pos.see_ge(move, VALUE_ZERO))\n           extension = ONE_PLY;\n \n       // Singular extension search. If all moves but one fail low on a search of\n@@ -946,11 +946,11 @@ namespace {\n \n               // Prune moves with negative SEE\n               if (   lmrDepth < 8\n-                  && pos.see_sign(move) < Value(-35 * lmrDepth * lmrDepth))\n+                  && !pos.see_ge(move, Value(-35 * lmrDepth * lmrDepth)))\n                   continue;\n           }\n           else if (   depth < 7 * ONE_PLY\n-                   && pos.see_sign(move) < Value(-35 * depth / ONE_PLY * depth / ONE_PLY))\n+                   && !pos.see_ge(move, Value(-35 * depth / ONE_PLY * depth / ONE_PLY)))\n                   continue;\n       }\n \n@@ -992,7 +992,7 @@ namespace {\n               // because the destination square is empty.\n               else if (   type_of(move) == NORMAL\n                        && type_of(pos.piece_on(to_sq(move))) != PAWN\n-                       && pos.see(make_move(to_sq(move), from_sq(move))) < VALUE_ZERO)\n+                       && !pos.see_ge(make_move(to_sq(move), from_sq(move)),  VALUE_ZERO))\n                   r -= 2 * ONE_PLY;\n \n               // Decrease/increase reduction for moves with a good/bad history\n@@ -1302,7 +1302,7 @@ namespace {\n               continue;\n           }\n \n-          if (futilityBase <= alpha && pos.see(move) <= VALUE_ZERO)\n+          if (futilityBase <= alpha && !pos.see_ge(move, VALUE_ZERO + 1))\n           {\n               bestValue = std::max(bestValue, futilityBase);\n               continue;\n@@ -1317,7 +1317,7 @@ namespace {\n       // Don't search moves with negative SEE values\n       if (  (!InCheck || evasionPrunable)\n           &&  type_of(move) != PROMOTION\n-          &&  pos.see_sign(move) < VALUE_ZERO)\n+          &&  !pos.see_ge(move, VALUE_ZERO))\n           continue;\n \n       // Speculative prefetch as early as possible\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Implement syntactic sugar for `see_ge()` to enhance readability without modifying `movepicker.cpp` and `search.cpp`:\n   - `see(m) > A` => `see_ge(m, A + 1)`\n   - `see(m) >= A` => `see_ge(m, A)`\n   - `see(m) < A` => `!(see_ge(m, A))`\n   - `see(m) <= A` => `!(see_ge(m, A + 1)`\n\n2. Consider returning `balance` from functions instead of boolean for potential future SEE calculations.\n\n3. Avoid operator overloading if it complicates understanding, as it could lead to incorrect usage and subtle performance issues.\n\n4. Explore implementing lightweight helper functions (`see_g()`, `see_l()`, etc.) to improve efficiency.\n\n5. Prioritize performance over readability in critical sections; minor improvements can significantly affect overall speed."
      }
    ],
    "codediff_length": 10048
  },
  {
    "index": 93,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/evaluate.cpp b/src/evaluate.cpp\nindex bbca9964f43..44a0669f9c0 100644\n--- a/src/evaluate.cpp\n+++ b/src/evaluate.cpp\n@@ -126,19 +126,19 @@ namespace {\n   // friendly pieces.\n   const Score MobilityBonus[][32] = {\n     {}, {},\n-    { S(-68,-49), S(-46,-33), S(-3,-12), S( 5, -4), S( 9, 11), S(15, 16), // Knights\n-      S( 23, 27), S( 33, 28), S(37, 29) },\n-    { S(-49,-44), S(-23,-16), S(16,  1), S(29, 16), S(40, 25), S(51, 34), // Bishops\n-      S( 55, 43), S( 61, 49), S(64, 51), S(68, 52), S(73, 55), S(75, 60),\n-      S( 80, 65), S( 86, 66) },\n-    { S(-50,-57), S(-28,-22), S(-11, 7), S(-1, 29), S( 0, 39), S( 1, 46), // Rooks\n-      S( 10, 66), S( 16, 79), S(22, 86), S(23,103), S(30,109), S(33,111),\n-      S( 37,115), S( 38,119), S(48,124) },\n-    { S(-43,-30), S(-27,-15), S( 1, -5), S( 2, -3), S(14, 10), S(18, 24), // Queens\n-      S( 20, 27), S( 33, 37), S(33, 38), S(34, 43), S(40, 46), S(43, 56),\n-      S( 46, 61), S( 52, 63), S(52, 63), S(57, 65), S(60, 70), S(61, 74),\n-      S( 67, 80), S( 76, 82), S(77, 88), S(82, 94), S(86, 95), S(90, 96),\n-      S( 94, 99), S( 96,100), S(99,111), S(99,112) }\n+    { S(-70,-52), S(-52,-37), S( -7,-17), S(  0, -6), S(  8,  5), S( 16,  9), // Knights\n+      S( 23, 20), S( 31, 21), S( 36, 22) },\n+    { S(-49,-44), S(-22,-13), S( 16,  0), S( 27, 11), S( 38, 19), S( 52, 34), // Bishops\n+      S( 56, 44), S( 65, 47), S( 67, 51), S( 73, 56), S( 81, 59), S( 83, 69),\n+      S( 95, 72), S(100, 75) },\n+    { S(-49,-57), S(-22,-14), S(-10, 18), S( -5, 39), S( -4, 50), S( -2, 58), // Rooks\n+      S(  6, 78), S( 11, 86), S( 17, 92), S( 19,103), S( 26,111), S( 27,115),\n+      S( 36,119), S( 41,121), S( 50,122) },\n+    { S(-41,-24), S(-26, -8), S(  0,  6), S(  2, 14), S( 12, 27), S( 21, 40), // Queens\n+      S( 22, 45), S( 37, 55), S( 40, 57), S( 43, 63), S( 50, 68), S( 52, 74),\n+      S( 56, 80), S( 66, 84), S( 68, 85), S( 69, 88), S( 71, 92), S( 72, 94),\n+      S( 80, 96), S( 89, 98), S( 94,101), S(102,113), S(106,114), S(107,116),\n+      S(112,125), S(113,127), S(117,137), S(122,143) }\n   };\n \n   // Outpost[knight/bishop][supported by pawn] contains bonuses for knights and\n@@ -172,8 +172,8 @@ namespace {\n \n   // PassedFile[File] contains a bonus according to the file of a passed pawn.\n   const Score PassedFile[] = {\n-    S( 14,  13), S( 2,  5), S(-3, -4), S(-19, -14),\n-    S(-19, -14), S(-3, -4), S( 2,  5), S( 14,  13)\n+    S( 12,  10), S( 3,  10), S( 1, -8), S(-27, -12),\n+    S(-27, -12), S( 1, -8),  S( 3, 10), S( 12,  10)\n   };\n \n   const Score ThreatenedByHangingPawn = S(40, 60);\n@@ -414,7 +414,8 @@ namespace {\n         {\n             // ...and then remove squares not supported by another enemy piece\n             b &=  ei.attackedBy[Them][PAWN]   | ei.attackedBy[Them][KNIGHT]\n-                | ei.attackedBy[Them][BISHOP] | ei.attackedBy[Them][ROOK];\n+                | ei.attackedBy[Them][BISHOP] | ei.attackedBy[Them][ROOK]\n+                | ei.attackedBy[Them][KING];\n \n             if (b)\n                 attackUnits += QueenContactCheck * popcount<Max15>(b);\ndiff --git a/src/evaluate.h b/src/evaluate.h\nindex 450f2535f0d..28e9075114a 100644\n--- a/src/evaluate.h\n+++ b/src/evaluate.h\n@@ -28,7 +28,7 @@ class Position;\n \n namespace Eval {\n \n-const Value Tempo = Value(17); // Must be visible to search\n+const Value Tempo = Value(20); // Must be visible to search\n \n void init();\n std::string trace(const Position& pos);\ndiff --git a/src/material.cpp b/src/material.cpp\nindex 7e2331277d5..bf0d060fde3 100644\n--- a/src/material.cpp\n+++ b/src/material.cpp\n@@ -31,28 +31,28 @@ namespace {\n   // Polynomial material imbalance parameters\n \n   //                      pair  pawn knight bishop rook queen\n-  const int Linear[6] = { 1756, -164, -1067, -160,  234, -137 };\n+  const int Linear[6] = { 1667, -168, -1027, -166,  238, -138 };\n \n   const int QuadraticOurs[][PIECE_TYPE_NB] = {\n     //            OUR PIECES\n     // pair pawn knight bishop rook queen\n     {   0                               }, // Bishop pair\n-    {  39,    2                         }, // Pawn\n-    {  35,  271,  -4                    }, // Knight      OUR PIECES\n-    {   0,  105,   4,    0              }, // Bishop\n-    { -27,   -2,  46,   100,  -141      }, // Rook\n-    {-177,   25, 129,   142,  -137,   0 }  // Queen\n+    {  40,    2                         }, // Pawn\n+    {  32,  255,  -3                    }, // Knight      OUR PIECES\n+    {   0,  104,   4,    0              }, // Bishop\n+    { -26,   -2,  47,   105,  -149      }, // Rook\n+    {-185,   24, 122,   137,  -134,   0 }  // Queen\n   };\n \n   const int QuadraticTheirs[][PIECE_TYPE_NB] = {\n     //           THEIR PIECES\n     // pair pawn knight bishop rook queen\n     {   0                               }, // Bishop pair\n-    {  37,    0                         }, // Pawn\n-    {  10,   62,   0                    }, // Knight      OUR PIECES\n-    {  57,   64,  39,     0             }, // Bishop\n-    {  50,   40,  23,   -22,    0       }, // Rook\n-    {  98,  105, -39,   141,  274,    0 }  // Queen\n+    {  36,    0                         }, // Pawn\n+    {   9,   63,   0                    }, // Knight      OUR PIECES\n+    {  59,   65,  42,     0             }, // Bishop\n+    {  46,   39,  24,   -24,    0       }, // Rook\n+    { 101,  100, -37,   141,  268,    0 }  // Queen\n   };\n \n   // Endgame evaluation and scaling functions are accessed directly and not through\ndiff --git a/src/search.cpp b/src/search.cpp\nindex 4988dc8e676..60f6133c53f 100644\n--- a/src/search.cpp\n+++ b/src/search.cpp\n@@ -66,7 +66,7 @@ namespace {\n   enum NodeType { Root, PV, NonPV };\n \n   // Razoring and futility margin based on depth\n-  Value razor_margin(Depth d) { return Value(512 + 32 * d); }\n+  int razor_margin[4] = {483, 570, 603, 554};\n   Value futility_margin(Depth d) { return Value(200 * d); }\n \n   // Futility and reductions lookup tables, initialized at startup\n@@ -155,7 +155,7 @@ namespace {\n \n void Search::init() {\n \n-  const double K[][2] = {{ 0.83, 2.25 }, { 0.50, 3.00 }};\n+  const double K[][2] = {{ 0.799, 2.281 }, { 0.484, 3.023 }};\n \n   for (int pv = 0; pv <= 1; ++pv)\n       for (int imp = 0; imp <= 1; ++imp)\n@@ -377,7 +377,7 @@ namespace {\n             // Reset aspiration window starting size\n             if (depth >= 5 * ONE_PLY)\n             {\n-                delta = Value(16);\n+                delta = Value(18);\n                 alpha = std::max(RootMoves[PVIdx].previousScore - delta,-VALUE_INFINITE);\n                 beta  = std::min(RootMoves[PVIdx].previousScore + delta, VALUE_INFINITE);\n             }\n@@ -433,7 +433,7 @@ namespace {\n                 else\n                     break;\n \n-                delta += delta / 2;\n+                delta += delta / 4 + 5;\n \n                 assert(alpha >= -VALUE_INFINITE && beta <= VALUE_INFINITE);\n             }\n@@ -673,14 +673,14 @@ namespace {\n     // Step 6. Razoring (skipped when in check)\n     if (   !PvNode\n         &&  depth < 4 * ONE_PLY\n-        &&  eval + razor_margin(depth) <= alpha\n+        &&  eval + razor_margin[depth] <= alpha\n         &&  ttMove == MOVE_NONE)\n     {\n         if (   depth <= ONE_PLY\n-            && eval + razor_margin(3 * ONE_PLY) <= alpha)\n+            && eval + razor_margin[3 * ONE_PLY] <= alpha)\n             return qsearch<NonPV, false>(pos, ss, alpha, beta, DEPTH_ZERO);\n \n-        Value ralpha = alpha - razor_margin(depth);\n+        Value ralpha = alpha - razor_margin[depth];\n         Value v = qsearch<NonPV, false>(pos, ss, ralpha, ralpha+1, DEPTH_ZERO);\n         if (v <= ralpha)\n             return v;\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Merge the current patch for ELO gain, but separate the time management patch for independent testing.\n2. Fix Stockfish (SF) to disable time management when in fixed time per move mode.\n3. Test with `tempo = 17` at `40+0.4` using SPRT with thresholds [0, 4]. \n4. Ensure compliance with union patch guidelines, limiting to a maximum of 2 patches per union and avoiding mixing time management with parameter tweaks.\n5. Consider a large SPSA session (e.g., 100,000 games) starting with patch values for further testing.\n6. Propose an ELO measurement with VLTC of 120 seconds+ over 2000 games; aim for at least +1.5 ELO before final merge decisions."
      }
    ],
    "codediff_length": 7573
  },
  {
    "index": 94,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/nnue/layers/affine_transform.h b/src/nnue/layers/affine_transform.h\nindex 9a3b778e6bb..80b2be19f43 100644\n--- a/src/nnue/layers/affine_transform.h\n+++ b/src/nnue/layers/affine_transform.h\n@@ -33,7 +33,7 @@ namespace Stockfish::Eval::NNUE::Layers {\n     // Input/output type\n     using InputType = typename PreviousLayer::OutputType;\n     using OutputType = std::int32_t;\n-    static_assert(std::is_same<InputType, std::uint8_t>::value, \"\");\n+    static_assert(std::is_same<InputType, std::int8_t>::value, \"\");\n \n     // Number of input/output dimensions\n     static constexpr IndexType InputDimensions =\ndiff --git a/src/nnue/layers/clipped_relu.h b/src/nnue/layers/clipped_relu.h\nindex 65455df4944..a42706101e7 100644\n--- a/src/nnue/layers/clipped_relu.h\n+++ b/src/nnue/layers/clipped_relu.h\n@@ -31,7 +31,7 @@ namespace Stockfish::Eval::NNUE::Layers {\n    public:\n     // Input/output type\n     using InputType = typename PreviousLayer::OutputType;\n-    using OutputType = std::uint8_t;\n+    using OutputType = std::int8_t;\n     static_assert(std::is_same<InputType, std::int32_t>::value, \"\");\n \n     // Number of input/output dimensions\n@@ -65,120 +65,21 @@ namespace Stockfish::Eval::NNUE::Layers {\n     }\n \n     // Forward propagation\n-    const OutputType* propagate(\n-        const TransformedFeatureType* transformedFeatures, char* buffer) const {\n-      const auto input = previousLayer.propagate(\n-          transformedFeatures, buffer + SelfBufferSize);\n+    const OutputType* propagate(const TransformedFeatureType* features, char* buffer) const {\n+    \n+      const auto input  = previousLayer.propagate(features, buffer + SelfBufferSize);\n       const auto output = reinterpret_cast<OutputType*>(buffer);\n \n-  #if defined(USE_AVX2)\n-      if constexpr (InputDimensions % SimdWidth == 0) {\n-        constexpr IndexType NumChunks = InputDimensions / SimdWidth;\n-        const __m256i Zero = _mm256_setzero_si256();\n-        const __m256i Offsets = _mm256_set_epi32(7, 3, 6, 2, 5, 1, 4, 0);\n-        const auto in = reinterpret_cast<const __m256i*>(input);\n-        const auto out = reinterpret_cast<__m256i*>(output);\n-        for (IndexType i = 0; i < NumChunks; ++i) {\n-          const __m256i words0 = _mm256_srai_epi16(_mm256_packs_epi32(\n-              _mm256_load_si256(&in[i * 4 + 0]),\n-              _mm256_load_si256(&in[i * 4 + 1])), WeightScaleBits);\n-          const __m256i words1 = _mm256_srai_epi16(_mm256_packs_epi32(\n-              _mm256_load_si256(&in[i * 4 + 2]),\n-              _mm256_load_si256(&in[i * 4 + 3])), WeightScaleBits);\n-          _mm256_store_si256(&out[i], _mm256_permutevar8x32_epi32(_mm256_max_epi8(\n-              _mm256_packs_epi16(words0, words1), Zero), Offsets));\n-        }\n-      } else {\n-        constexpr IndexType NumChunks = InputDimensions / (SimdWidth / 2);\n-        const __m128i Zero = _mm_setzero_si128();\n-        const auto in = reinterpret_cast<const __m128i*>(input);\n-        const auto out = reinterpret_cast<__m128i*>(output);\n-        for (IndexType i = 0; i < NumChunks; ++i) {\n-          const __m128i words0 = _mm_srai_epi16(_mm_packs_epi32(\n-              _mm_load_si128(&in[i * 4 + 0]),\n-              _mm_load_si128(&in[i * 4 + 1])), WeightScaleBits);\n-          const __m128i words1 = _mm_srai_epi16(_mm_packs_epi32(\n-              _mm_load_si128(&in[i * 4 + 2]),\n-              _mm_load_si128(&in[i * 4 + 3])), WeightScaleBits);\n-          const __m128i packedbytes = _mm_packs_epi16(words0, words1);\n-          _mm_store_si128(&out[i], _mm_max_epi8(packedbytes, Zero));\n-        }\n-      }\n-      constexpr IndexType Start =\n-        InputDimensions % SimdWidth == 0\n-        ? InputDimensions / SimdWidth * SimdWidth\n-        : InputDimensions / (SimdWidth / 2) * (SimdWidth / 2);\n-\n-  #elif defined(USE_SSE2)\n-      constexpr IndexType NumChunks = InputDimensions / SimdWidth;\n-\n-  #ifdef USE_SSE41\n-      const __m128i Zero = _mm_setzero_si128();\n-  #else\n-      const __m128i k0x80s = _mm_set1_epi8(-128);\n-  #endif\n-\n-      const auto in = reinterpret_cast<const __m128i*>(input);\n-      const auto out = reinterpret_cast<__m128i*>(output);\n-      for (IndexType i = 0; i < NumChunks; ++i) {\n-        const __m128i words0 = _mm_srai_epi16(_mm_packs_epi32(\n-            _mm_load_si128(&in[i * 4 + 0]),\n-            _mm_load_si128(&in[i * 4 + 1])), WeightScaleBits);\n-        const __m128i words1 = _mm_srai_epi16(_mm_packs_epi32(\n-            _mm_load_si128(&in[i * 4 + 2]),\n-            _mm_load_si128(&in[i * 4 + 3])), WeightScaleBits);\n-        const __m128i packedbytes = _mm_packs_epi16(words0, words1);\n-        _mm_store_si128(&out[i],\n-\n-  #ifdef USE_SSE41\n-          _mm_max_epi8(packedbytes, Zero)\n-  #else\n-          _mm_subs_epi8(_mm_adds_epi8(packedbytes, k0x80s), k0x80s)\n-  #endif\n-\n-        );\n-      }\n-      constexpr IndexType Start = NumChunks * SimdWidth;\n-\n-  #elif defined(USE_MMX)\n-      constexpr IndexType NumChunks = InputDimensions / SimdWidth;\n-      const __m64 k0x80s = _mm_set1_pi8(-128);\n-      const auto in = reinterpret_cast<const __m64*>(input);\n-      const auto out = reinterpret_cast<__m64*>(output);\n-      for (IndexType i = 0; i < NumChunks; ++i) {\n-        const __m64 words0 = _mm_srai_pi16(\n-            _mm_packs_pi32(in[i * 4 + 0], in[i * 4 + 1]),\n-            WeightScaleBits);\n-        const __m64 words1 = _mm_srai_pi16(\n-            _mm_packs_pi32(in[i * 4 + 2], in[i * 4 + 3]),\n-            WeightScaleBits);\n-        const __m64 packedbytes = _mm_packs_pi16(words0, words1);\n-        out[i] = _mm_subs_pi8(_mm_adds_pi8(packedbytes, k0x80s), k0x80s);\n-      }\n-      _mm_empty();\n-      constexpr IndexType Start = NumChunks * SimdWidth;\n-\n-  #elif defined(USE_NEON)\n-      constexpr IndexType NumChunks = InputDimensions / (SimdWidth / 2);\n-      const int8x8_t Zero = {0};\n-      const auto in = reinterpret_cast<const int32x4_t*>(input);\n-      const auto out = reinterpret_cast<int8x8_t*>(output);\n-      for (IndexType i = 0; i < NumChunks; ++i) {\n-        int16x8_t shifted;\n-        const auto pack = reinterpret_cast<int16x4_t*>(&shifted);\n-        pack[0] = vqshrn_n_s32(in[i * 2 + 0], WeightScaleBits);\n-        pack[1] = vqshrn_n_s32(in[i * 2 + 1], WeightScaleBits);\n-        out[i] = vmax_s8(vqmovn_s16(shifted), Zero);\n-      }\n-      constexpr IndexType Start = NumChunks * (SimdWidth / 2);\n-  #else\n-      constexpr IndexType Start = 0;\n-  #endif\n-\n-      for (IndexType i = Start; i < InputDimensions; ++i) {\n-        output[i] = static_cast<OutputType>(\n-            std::max(0, std::min(127, input[i] >> WeightScaleBits)));\n+      // We implement a clipped ReLu of the input, keeping the output in the 0..127 range\n+      for (IndexType i = 0; i < InputDimensions; ++i)\n+      {\n+          int x = (input[i] >> WeightScaleBits);\n+          if (x < 0)   x = 0;\n+          if (x > 127) x = 127;\n+\n+          output[i] = x;\n       }\n+\n       return output;\n     }\n \ndiff --git a/src/nnue/nnue_common.h b/src/nnue/nnue_common.h\nindex 75ac7862791..53e03aa81a1 100644\n--- a/src/nnue/nnue_common.h\n+++ b/src/nnue/nnue_common.h\n@@ -74,7 +74,7 @@ namespace Stockfish::Eval::NNUE {\n   constexpr std::size_t MaxSimdWidth = 32;\n \n   // Type of input feature after conversion\n-  using TransformedFeatureType = std::uint8_t;\n+  using TransformedFeatureType = std::int8_t;\n   using IndexType = std::uint32_t;\n \n   // Round n up to be a multiple of base\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "The PR introduces a performance regression of approximately 0.5% with MMX and SSE4.1 targets across multiple tests. The benchmarks show significant slowdowns, specifically with clang 12 and gcc 10.2, which resulted in up to a 2.2% performance drop. \n\nRecommended actions:\n1. Review recent changes for unintended consequences, especially with MMX and SSE4.1 implementations.\n2. Optimize the vectorization strategy used in the code to mitigate slowdowns with autovectorization on different compilers.\n3. Ensure thorough testing of the implementation across various compilers (GCC, Clang, ICC) to validate performance.\n4. Consider merging only after confirming no major regressions persist and that any optimizations result in tangible speed improvements."
      }
    ],
    "codediff_length": 7412
  },
  {
    "index": 95,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/README.md b/README.md\nindex 79db8170257..39dbecd30c0 100644\n--- a/README.md\n+++ b/README.md\n@@ -265,10 +265,6 @@ targets with corresponding descriptions.\n     make build ARCH=x86-64-modern\n ```\n \n-When not using the Makefile to compile (for instance, with Microsoft MSVC) you\n-need to manually set/unset some switches in the compiler command line; see\n-file *types.h* for a quick reference.\n-\n When reporting an issue or a bug, please tell us which Stockfish version\n and which compiler you used to create your executable. This information\n can be found by typing the following command in a console:\ndiff --git a/appveyor.yml b/appveyor.yml\ndeleted file mode 100644\nindex ab6084090a4..00000000000\n--- a/appveyor.yml\n+++ /dev/null\n@@ -1,88 +0,0 @@\n-version: 1.0.{build}\n-clone_depth: 50\n-\n-branches:\n-  only:\n-    - master\n-\n-# Operating system (build VM template)\n-os: Visual Studio 2019\n-\n-# Build platform, i.e. x86, x64, AnyCPU. This setting is optional.\n-platform:\n-  - x86\n-  - x64\n-\n-# build Configuration, i.e. Debug, Release, etc.\n-configuration:\n-  - Debug\n-  - Release\n-\n-matrix:\n-  # The build fail immediately once one of the job fails\n-  fast_finish: true\n-\n-# Scripts that are called at very beginning, before repo cloning\n-init:\n-  - cmake --version\n-  - msbuild /version\n-\n-before_build:\n-  - ps: |\n-      # Get sources\n-      $src = get-childitem -Path *.cpp -Recurse | select -ExpandProperty FullName\n-      $src = $src -join ' '\n-      $src = $src.Replace(\"\\\", \"/\")\n-\n-      # Build CMakeLists.txt\n-      $t = 'cmake_minimum_required(VERSION 3.17)',\n-           'project(Stockfish)',\n-           'set(CMAKE_CXX_STANDARD 17)',\n-           'set(CMAKE_CXX_STANDARD_REQUIRED ON)',\n-           'set (CMAKE_CXX_EXTENSIONS OFF)',\n-           'set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_SOURCE_DIR}/src)',\n-           'set(source_files', $src, ')',\n-           'add_executable(stockfish ${source_files})'\n-\n-      # Write CMakeLists.txt withouth BOM\n-      $MyPath = (Get-Item -Path \".\" -Verbose).FullName + '\\CMakeLists.txt'\n-      $Utf8NoBomEncoding = New-Object System.Text.UTF8Encoding $False\n-      [System.IO.File]::WriteAllLines($MyPath, $t, $Utf8NoBomEncoding)\n-\n-      # Obtain bench reference from git log\n-      $b = git log HEAD | sls \"\\b[Bb]ench[ :]+[0-9]{7}\" | select -first 1\n-      $bench = $b -match '\\D+(\\d+)' | % { $matches[1] }\n-      Write-Host \"Reference bench:\" $bench\n-      $g = \"Visual Studio 16 2019\"\n-      If (${env:PLATFORM} -eq 'x64') { $a = \"x64\" }\n-      If (${env:PLATFORM} -eq 'x86') { $a = \"Win32\" }\n-      cmake -G \"${g}\" -A ${a} .\n-      Write-Host \"Generated files for: \" $g $a\n-\n-build_script:\n-  - cmake --build . --config %CONFIGURATION% -- /verbosity:minimal\n-  - ps: |\n-      # Download default NNUE net from fishtest\n-      $nnuenet = Get-Content -Path src\\evaluate.h | Select-String -CaseSensitive -Pattern \"EvalFileDefaultName\" | Select-String -CaseSensitive -Pattern \"nn-[a-z0-9]{12}.nnue\"\n-      $dummy = $nnuenet -match \"(?<nnuenet>nn-[a-z0-9]{12}.nnue)\"\n-      $nnuenet = $Matches.nnuenet\n-      Write-Host \"Default net:\" $nnuenet\n-      $nnuedownloadurl = \"https://tests.stockfishchess.org/api/nn/$nnuenet\"\n-      $nnuefilepath = \"src\\${env:CONFIGURATION}\\$nnuenet\"\n-      if (Test-Path -Path $nnuefilepath) {\n-            Write-Host \"Already available.\"\n-      } else {\n-            Write-Host \"Downloading $nnuedownloadurl to $nnuefilepath\"\n-            Invoke-WebRequest -Uri $nnuedownloadurl -OutFile $nnuefilepath\n-      }\n-\n-before_test:\n-  - cd src/%CONFIGURATION%\n-  - stockfish bench 2> out.txt >NUL\n-  - ps: |\n-      # Verify bench number\n-      $s = (gc \"./out.txt\" | out-string)\n-      $r = ($s -match 'Nodes searched \\D+(\\d+)' | % { $matches[1] })\n-      Write-Host \"Engine bench:\" $r\n-      Write-Host \"Reference bench:\" $bench\n-      If ($r -ne $bench) { exit 1 }\ndiff --git a/src/Makefile b/src/Makefile\nindex bf3c3560bbd..f9e6632f217 100644\n--- a/src/Makefile\n+++ b/src/Makefile\n@@ -372,12 +372,6 @@ ifeq ($(COMP),mingw)\n \tLDFLAGS += -static\n endif\n \n-ifeq ($(COMP),icc)\n-\tcomp=icc\n-\tCXX=icpc\n-\tCXXFLAGS += -diag-disable 1476,10120 -Wcheck -Wabi -Wdeprecated -strict-ansi\n-endif\n-\n ifeq ($(COMP),clang)\n \tcomp=clang\n \tCXX=clang++\n@@ -426,10 +420,7 @@ ifeq ($(COMP),ndk)\n \tLDFLAGS += -static-libstdc++ -pie -lm -latomic\n endif\n \n-ifeq ($(comp),icc)\n-\tprofile_make = icc-profile-make\n-\tprofile_use = icc-profile-use\n-else ifeq ($(comp),clang)\n+ifeq ($(comp),clang)\n \tprofile_make = clang-profile-make\n \tprofile_use = clang-profile-use\n else\n@@ -495,7 +486,7 @@ ifeq ($(optimize),yes)\n \t\tendif\n \tendif\n \n-\tifeq ($(comp),$(filter $(comp),gcc clang icc))\n+\tifeq ($(comp),$(filter $(comp),gcc clang))\n \t\tifeq ($(KERNEL),Darwin)\n \t\t\tCXXFLAGS += -mdynamic-no-pic\n \t\tendif\n@@ -524,8 +515,6 @@ endif\n ifeq ($(popcnt),yes)\n \tifeq ($(arch),$(filter $(arch),ppc64 armv7 armv8 arm64))\n \t\tCXXFLAGS += -DUSE_POPCNT\n-\telse ifeq ($(comp),icc)\n-\t\tCXXFLAGS += -msse3 -DUSE_POPCNT\n \telse\n \t\tCXXFLAGS += -msse3 -mpopcnt -DUSE_POPCNT\n \tendif\n@@ -708,7 +697,6 @@ help:\n \t@echo \"gcc                     > Gnu compiler (default)\"\n \t@echo \"mingw                   > Gnu compiler with MinGW under Windows\"\n \t@echo \"clang                   > LLVM Clang compiler\"\n-\t@echo \"icc                     > Intel compiler\"\n \t@echo \"ndk                     > Google NDK to cross-compile for Android\"\n \t@echo \"\"\n \t@echo \"Simple examples. If you don't know what to do, you likely want to run: \"\n@@ -733,7 +721,7 @@ endif\n \n \n .PHONY: help build profile-build strip install clean net objclean profileclean \\\n-        config-sanity icc-profile-use icc-profile-make gcc-profile-use gcc-profile-make \\\n+        config-sanity gcc-profile-use gcc-profile-make \\\n         clang-profile-use clang-profile-make\n \n build: net config-sanity\n@@ -863,7 +851,7 @@ config-sanity: net\n \t@test \"$(vnni256)\" = \"yes\" || test \"$(vnni256)\" = \"no\"\n \t@test \"$(vnni512)\" = \"yes\" || test \"$(vnni512)\" = \"no\"\n \t@test \"$(neon)\" = \"yes\" || test \"$(neon)\" = \"no\"\n-\t@test \"$(comp)\" = \"gcc\" || test \"$(comp)\" = \"icc\" || test \"$(comp)\" = \"mingw\" || test \"$(comp)\" = \"clang\" \\\n+\t@test \"$(comp)\" = \"gcc\" || test \"$(comp)\" = \"mingw\" || test \"$(comp)\" = \"clang\" \\\n \t|| test \"$(comp)\" = \"armv7a-linux-androideabi16-clang\"  || test \"$(comp)\" = \"aarch64-linux-android21-clang\"\n \n $(EXE): $(OBJS)\n@@ -895,17 +883,6 @@ gcc-profile-use:\n \tEXTRALDFLAGS='-lgcov' \\\n \tall\n \n-icc-profile-make:\n-\t@mkdir -p profdir\n-\t$(MAKE) ARCH=$(ARCH) COMP=$(COMP) \\\n-\tEXTRACXXFLAGS='-prof-gen=srcpos -prof_dir ./profdir' \\\n-\tall\n-\n-icc-profile-use:\n-\t$(MAKE) ARCH=$(ARCH) COMP=$(COMP) \\\n-\tEXTRACXXFLAGS='-prof_use -prof_dir ./profdir' \\\n-\tall\n-\n .depend:\n \t-@$(CXX) $(DEPENDFLAGS) -MM $(SRCS) > $@ 2> /dev/null\n \ndiff --git a/src/bitboard.h b/src/bitboard.h\nindex b29f3e24fa1..0e664ea7106 100644\n--- a/src/bitboard.h\n+++ b/src/bitboard.h\n@@ -341,10 +341,6 @@ inline int popcount(Bitboard b) {\n   union { Bitboard bb; uint16_t u[4]; } v = { b };\n   return PopCnt16[v.u[0]] + PopCnt16[v.u[1]] + PopCnt16[v.u[2]] + PopCnt16[v.u[3]];\n \n-#elif defined(_MSC_VER) || defined(__INTEL_COMPILER)\n-\n-  return (int)_mm_popcnt_u64(b);\n-\n #else // Assumed gcc or compatible compiler\n \n   return __builtin_popcountll(b);\n@@ -355,7 +351,7 @@ inline int popcount(Bitboard b) {\n \n /// lsb() and msb() return the least/most significant bit in a non-zero bitboard\n \n-#if defined(__GNUC__)  // GCC, Clang, ICC\n+#if defined(__GNUC__)  // GCC, Clang\n \n inline Square lsb(Bitboard b) {\n   assert(b);\n@@ -367,55 +363,7 @@ inline Square msb(Bitboard b) {\n   return Square(63 ^ __builtin_clzll(b));\n }\n \n-#elif defined(_MSC_VER)  // MSVC\n-\n-#ifdef _WIN64  // MSVC, WIN64\n-\n-inline Square lsb(Bitboard b) {\n-  assert(b);\n-  unsigned long idx;\n-  _BitScanForward64(&idx, b);\n-  return (Square) idx;\n-}\n-\n-inline Square msb(Bitboard b) {\n-  assert(b);\n-  unsigned long idx;\n-  _BitScanReverse64(&idx, b);\n-  return (Square) idx;\n-}\n-\n-#else  // MSVC, WIN32\n-\n-inline Square lsb(Bitboard b) {\n-  assert(b);\n-  unsigned long idx;\n-\n-  if (b & 0xffffffff) {\n-      _BitScanForward(&idx, int32_t(b));\n-      return Square(idx);\n-  } else {\n-      _BitScanForward(&idx, int32_t(b >> 32));\n-      return Square(idx + 32);\n-  }\n-}\n-\n-inline Square msb(Bitboard b) {\n-  assert(b);\n-  unsigned long idx;\n-\n-  if (b >> 32) {\n-      _BitScanReverse(&idx, int32_t(b >> 32));\n-      return Square(idx + 32);\n-  } else {\n-      _BitScanReverse(&idx, int32_t(b));\n-      return Square(idx);\n-  }\n-}\n-\n-#endif\n-\n-#else  // Compiler is neither GCC nor MSVC compatible\n+#else  // Compiler is not compatible\n \n #error \"Compiler not supported.\"\n \ndiff --git a/src/evaluate.cpp b/src/evaluate.cpp\nindex f9754795603..389bae906b3 100644\n--- a/src/evaluate.cpp\n+++ b/src/evaluate.cpp\n@@ -45,7 +45,7 @@\n //     const unsigned char *const gEmbeddedNNUEEnd;     // a marker to the end\n //     const unsigned int         gEmbeddedNNUESize;    // the size of the embedded file\n // Note that this does not work in Microsoft Visual Studio.\n-#if !defined(_MSC_VER) && !defined(NNUE_EMBEDDING_OFF)\n+#if !defined(NNUE_EMBEDDING_OFF)\n   INCBIN(EmbeddedNNUE, EvalFileDefaultName);\n #else\n   const unsigned char        gEmbeddedNNUEData[1] = {0x0};\ndiff --git a/src/misc.cpp b/src/misc.cpp\nindex 9e7b7e37b8c..ee6f4e6b601 100644\n--- a/src/misc.cpp\n+++ b/src/misc.cpp\n@@ -171,9 +171,7 @@ std::string compiler_info() {\n \n /// Predefined macros hell:\n ///\n-/// __GNUC__           Compiler is gcc, Clang or Intel on Linux\n-/// __INTEL_COMPILER   Compiler is Intel\n-/// _MSC_VER           Compiler is MSVC or Intel on Windows\n+/// __GNUC__           Compiler is GCC or Clang on Linux\n /// _WIN32             Building on Windows (any)\n /// _WIN64             Building on Windows 64 bit\n \n@@ -182,16 +180,6 @@ std::string compiler_info() {\n   #ifdef __clang__\n      compiler += \"clang++ \";\n      compiler += make_version_string(__clang_major__, __clang_minor__, __clang_patchlevel__);\n-  #elif __INTEL_COMPILER\n-     compiler += \"Intel compiler \";\n-     compiler += \"(version \";\n-     compiler += stringify(__INTEL_COMPILER) \" update \" stringify(__INTEL_COMPILER_UPDATE);\n-     compiler += \")\";\n-  #elif _MSC_VER\n-     compiler += \"MSVC \";\n-     compiler += \"(version \";\n-     compiler += stringify(_MSC_FULL_VER) \".\" stringify(_MSC_BUILD);\n-     compiler += \")\";\n   #elif defined(__e2k__) && defined(__LCC__)\n     #define dot_ver2(n) \\\n       compiler += (char)'.'; \\\n@@ -327,18 +315,7 @@ void prefetch(void*) {}\n #else\n \n void prefetch(void* addr) {\n-\n-#  if defined(__INTEL_COMPILER)\n-   // This hack prevents prefetches from being optimized away by\n-   // Intel compiler. Both MSVC and gcc seem not be affected by this.\n-   __asm__ (\"\");\n-#  endif\n-\n-#  if defined(__INTEL_COMPILER) || defined(_MSC_VER)\n-  _mm_prefetch((char*)addr, _MM_HINT_T0);\n-#  else\n   __builtin_prefetch(addr);\n-#  endif\n }\n \n #endif\n@@ -614,13 +591,6 @@ void init(int argc, char* argv[]) {\n \n #ifdef _WIN32\n     pathSeparator = \"\\\\\";\n-  #ifdef _MSC_VER\n-    // Under windows argv[0] may not have the extension. Also _get_pgmptr() had\n-    // issues in some windows 10 versions, so check returned values carefully.\n-    char* pgmptr = nullptr;\n-    if (!_get_pgmptr(&pgmptr) && pgmptr != nullptr && *pgmptr)\n-        argv0 = pgmptr;\n-  #endif\n #else\n     pathSeparator = \"/\";\n #endif\ndiff --git a/src/nnue/layers/affine_transform.h b/src/nnue/layers/affine_transform.h\nindex 9a3b778e6bb..80b2be19f43 100644\n--- a/src/nnue/layers/affine_transform.h\n+++ b/src/nnue/layers/affine_transform.h\n@@ -33,7 +33,7 @@ namespace Stockfish::Eval::NNUE::Layers {\n     // Input/output type\n     using InputType = typename PreviousLayer::OutputType;\n     using OutputType = std::int32_t;\n-    static_assert(std::is_same<InputType, std::uint8_t>::value, \"\");\n+    static_assert(std::is_same<InputType, std::int8_t>::value, \"\");\n \n     // Number of input/output dimensions\n     static constexpr IndexType InputDimensions =\ndiff --git a/src/nnue/layers/clipped_relu.h b/src/nnue/layers/clipped_relu.h\nindex 65455df4944..30e7721a67f 100644\n--- a/src/nnue/layers/clipped_relu.h\n+++ b/src/nnue/layers/clipped_relu.h\n@@ -31,7 +31,7 @@ namespace Stockfish::Eval::NNUE::Layers {\n    public:\n     // Input/output type\n     using InputType = typename PreviousLayer::OutputType;\n-    using OutputType = std::uint8_t;\n+    using OutputType = std::int8_t;\n     static_assert(std::is_same<InputType, std::int32_t>::value, \"\");\n \n     // Number of input/output dimensions\n@@ -71,114 +71,16 @@ namespace Stockfish::Eval::NNUE::Layers {\n           transformedFeatures, buffer + SelfBufferSize);\n       const auto output = reinterpret_cast<OutputType*>(buffer);\n \n-  #if defined(USE_AVX2)\n-      if constexpr (InputDimensions % SimdWidth == 0) {\n-        constexpr IndexType NumChunks = InputDimensions / SimdWidth;\n-        const __m256i Zero = _mm256_setzero_si256();\n-        const __m256i Offsets = _mm256_set_epi32(7, 3, 6, 2, 5, 1, 4, 0);\n-        const auto in = reinterpret_cast<const __m256i*>(input);\n-        const auto out = reinterpret_cast<__m256i*>(output);\n-        for (IndexType i = 0; i < NumChunks; ++i) {\n-          const __m256i words0 = _mm256_srai_epi16(_mm256_packs_epi32(\n-              _mm256_load_si256(&in[i * 4 + 0]),\n-              _mm256_load_si256(&in[i * 4 + 1])), WeightScaleBits);\n-          const __m256i words1 = _mm256_srai_epi16(_mm256_packs_epi32(\n-              _mm256_load_si256(&in[i * 4 + 2]),\n-              _mm256_load_si256(&in[i * 4 + 3])), WeightScaleBits);\n-          _mm256_store_si256(&out[i], _mm256_permutevar8x32_epi32(_mm256_max_epi8(\n-              _mm256_packs_epi16(words0, words1), Zero), Offsets));\n-        }\n-      } else {\n-        constexpr IndexType NumChunks = InputDimensions / (SimdWidth / 2);\n-        const __m128i Zero = _mm_setzero_si128();\n-        const auto in = reinterpret_cast<const __m128i*>(input);\n-        const auto out = reinterpret_cast<__m128i*>(output);\n-        for (IndexType i = 0; i < NumChunks; ++i) {\n-          const __m128i words0 = _mm_srai_epi16(_mm_packs_epi32(\n-              _mm_load_si128(&in[i * 4 + 0]),\n-              _mm_load_si128(&in[i * 4 + 1])), WeightScaleBits);\n-          const __m128i words1 = _mm_srai_epi16(_mm_packs_epi32(\n-              _mm_load_si128(&in[i * 4 + 2]),\n-              _mm_load_si128(&in[i * 4 + 3])), WeightScaleBits);\n-          const __m128i packedbytes = _mm_packs_epi16(words0, words1);\n-          _mm_store_si128(&out[i], _mm_max_epi8(packedbytes, Zero));\n-        }\n-      }\n-      constexpr IndexType Start =\n-        InputDimensions % SimdWidth == 0\n-        ? InputDimensions / SimdWidth * SimdWidth\n-        : InputDimensions / (SimdWidth / 2) * (SimdWidth / 2);\n-\n-  #elif defined(USE_SSE2)\n-      constexpr IndexType NumChunks = InputDimensions / SimdWidth;\n-\n-  #ifdef USE_SSE41\n-      const __m128i Zero = _mm_setzero_si128();\n-  #else\n-      const __m128i k0x80s = _mm_set1_epi8(-128);\n-  #endif\n-\n-      const auto in = reinterpret_cast<const __m128i*>(input);\n-      const auto out = reinterpret_cast<__m128i*>(output);\n-      for (IndexType i = 0; i < NumChunks; ++i) {\n-        const __m128i words0 = _mm_srai_epi16(_mm_packs_epi32(\n-            _mm_load_si128(&in[i * 4 + 0]),\n-            _mm_load_si128(&in[i * 4 + 1])), WeightScaleBits);\n-        const __m128i words1 = _mm_srai_epi16(_mm_packs_epi32(\n-            _mm_load_si128(&in[i * 4 + 2]),\n-            _mm_load_si128(&in[i * 4 + 3])), WeightScaleBits);\n-        const __m128i packedbytes = _mm_packs_epi16(words0, words1);\n-        _mm_store_si128(&out[i],\n-\n-  #ifdef USE_SSE41\n-          _mm_max_epi8(packedbytes, Zero)\n-  #else\n-          _mm_subs_epi8(_mm_adds_epi8(packedbytes, k0x80s), k0x80s)\n-  #endif\n-\n-        );\n-      }\n-      constexpr IndexType Start = NumChunks * SimdWidth;\n-\n-  #elif defined(USE_MMX)\n-      constexpr IndexType NumChunks = InputDimensions / SimdWidth;\n-      const __m64 k0x80s = _mm_set1_pi8(-128);\n-      const auto in = reinterpret_cast<const __m64*>(input);\n-      const auto out = reinterpret_cast<__m64*>(output);\n-      for (IndexType i = 0; i < NumChunks; ++i) {\n-        const __m64 words0 = _mm_srai_pi16(\n-            _mm_packs_pi32(in[i * 4 + 0], in[i * 4 + 1]),\n-            WeightScaleBits);\n-        const __m64 words1 = _mm_srai_pi16(\n-            _mm_packs_pi32(in[i * 4 + 2], in[i * 4 + 3]),\n-            WeightScaleBits);\n-        const __m64 packedbytes = _mm_packs_pi16(words0, words1);\n-        out[i] = _mm_subs_pi8(_mm_adds_pi8(packedbytes, k0x80s), k0x80s);\n-      }\n-      _mm_empty();\n-      constexpr IndexType Start = NumChunks * SimdWidth;\n-\n-  #elif defined(USE_NEON)\n-      constexpr IndexType NumChunks = InputDimensions / (SimdWidth / 2);\n-      const int8x8_t Zero = {0};\n-      const auto in = reinterpret_cast<const int32x4_t*>(input);\n-      const auto out = reinterpret_cast<int8x8_t*>(output);\n-      for (IndexType i = 0; i < NumChunks; ++i) {\n-        int16x8_t shifted;\n-        const auto pack = reinterpret_cast<int16x4_t*>(&shifted);\n-        pack[0] = vqshrn_n_s32(in[i * 2 + 0], WeightScaleBits);\n-        pack[1] = vqshrn_n_s32(in[i * 2 + 1], WeightScaleBits);\n-        out[i] = vmax_s8(vqmovn_s16(shifted), Zero);\n-      }\n-      constexpr IndexType Start = NumChunks * (SimdWidth / 2);\n-  #else\n-      constexpr IndexType Start = 0;\n-  #endif\n-\n-      for (IndexType i = Start; i < InputDimensions; ++i) {\n-        output[i] = static_cast<OutputType>(\n-            std::max(0, std::min(127, input[i] >> WeightScaleBits)));\n+      // We implement a clipped ReLu of the input, keeping the output in the 0..127 range\n+      for (IndexType i = 0; i < InputDimensions; ++i)\n+      {\n+          int x = (input[i] >> WeightScaleBits);\n+          if (x < 0)   x = 0;\n+          if (x > 127) x = 127;\n+\n+          output[i] = x;\n       }\n+\n       return output;\n     }\n \ndiff --git a/src/nnue/nnue_common.h b/src/nnue/nnue_common.h\nindex 75ac7862791..53e03aa81a1 100644\n--- a/src/nnue/nnue_common.h\n+++ b/src/nnue/nnue_common.h\n@@ -74,7 +74,7 @@ namespace Stockfish::Eval::NNUE {\n   constexpr std::size_t MaxSimdWidth = 32;\n \n   // Type of input feature after conversion\n-  using TransformedFeatureType = std::uint8_t;\n+  using TransformedFeatureType = std::int8_t;\n   using IndexType = std::uint32_t;\n \n   // Round n up to be a multiple of base\ndiff --git a/src/types.h b/src/types.h\nindex 0bd4a1c4090..4465ee6f2d0 100644\n--- a/src/types.h\n+++ b/src/types.h\n@@ -42,18 +42,9 @@\n #include <cstdlib>\n #include <algorithm>\n \n-#if defined(_MSC_VER)\n-// Disable some silly and noisy warning from MSVC compiler\n-#pragma warning(disable: 4127) // Conditional expression is constant\n-#pragma warning(disable: 4146) // Unary minus operator applied to unsigned type\n-#pragma warning(disable: 4800) // Forcing value to bool 'true' or 'false'\n-#endif\n-\n /// Predefined macros hell:\n ///\n-/// __GNUC__           Compiler is gcc, Clang or Intel on Linux\n-/// __INTEL_COMPILER   Compiler is Intel\n-/// _MSC_VER           Compiler is MSVC or Intel on Windows\n+/// __GNUC__           Compiler is GCC or Clang on Linux\n /// _WIN32             Building on Windows (any)\n /// _WIN64             Building on Windows 64 bit\n \n@@ -63,19 +54,6 @@\n \n #define ASSERT_ALIGNED(ptr, alignment) assert(reinterpret_cast<uintptr_t>(ptr) % alignment == 0)\n \n-#if defined(_WIN64) && defined(_MSC_VER) // No Makefile used\n-#  include <intrin.h> // Microsoft header for _BitScanForward64()\n-#  define IS_64BIT\n-#endif\n-\n-#if defined(USE_POPCNT) && (defined(__INTEL_COMPILER) || defined(_MSC_VER))\n-#  include <nmmintrin.h> // Intel and Microsoft header for _mm_popcnt_u64()\n-#endif\n-\n-#if !defined(NO_PREFETCH) && (defined(__INTEL_COMPILER) || defined(_MSC_VER))\n-#  include <xmmintrin.h> // Intel and Microsoft header for _mm_prefetch()\n-#endif\n-\n #if defined(USE_PEXT)\n #  include <immintrin.h> // Header for _pext_u64() intrinsic\n #  define pext(b, m) _pext_u64(b, m)\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Confirm if Intel intrinsic instructions (_pext_u64, _mm_popcnt_u64, _mm_prefetch) should be removed from the codebase.\n2. Assess benchmark test results from the \"purify_cpp\" branch for performance against the original code; evaluate compiler optimization effectiveness.\n3. Simplification concerns include trusting the compiler for prefetching and thread management; additional optimization may only be necessary if current compiler performance proves inadequate.\n4. Retain manual optimizations for PEXT, loader prefetch, thread affinity, and large pages based on your performance tests.\n5. Clarify preferred granularity for code cleanup (function/file/folder).\n6. Identify supported compilers and versions for benchmarking.\n7. Address potential performance regressions due to removing manual optimizations; further justify any proposed code removals."
      }
    ],
    "codediff_length": 19888
  },
  {
    "index": 96,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/misc.h b/src/misc.h\nindex b63e613fc80..94fed78f4d6 100644\n--- a/src/misc.h\n+++ b/src/misc.h\n@@ -39,6 +39,10 @@ void dbg_hit_on(bool c, bool b);\n void dbg_mean_of(int v);\n void dbg_print();\n \n+template <typename T> int sign_of(T val) {\n+  return (T(0) < val) - (val < T(0));\n+}\n+\n typedef std::chrono::milliseconds::rep TimePoint; // A value in milliseconds\n \n inline TimePoint now() {\ndiff --git a/src/search.cpp b/src/search.cpp\nindex eb8aea24a13..70e03e690ce 100644\n--- a/src/search.cpp\n+++ b/src/search.cpp\n@@ -45,10 +45,11 @@ namespace Search {\n namespace Tablebases {\n \n   int Cardinality;\n-  bool RootInTB;\n-  bool UseRule50;\n   Depth ProbeDepth;\n-  Value Score;\n+  WDLScore DrawScore;\n+  WDLScore RootWDL;\n+  int RootPosDTZ;\n+  bool CanProbeDTZ;\n }\n \n namespace TB = Tablebases;\n@@ -150,6 +151,7 @@ namespace {\n   void update_pv(Move* pv, Move move, Move* childPv);\n   void update_continuation_histories(Stack* ss, Piece pc, Square to, int bonus);\n   void update_stats(const Position& pos, Stack* ss, Move move, Move* quiets, int quietsCnt, int bonus);\n+  Value probe_tb(Position& pos, Stack* ss, Value alpha, Value beta, Depth* depth, TTEntry* tte);\n \n   // perft() is our utility to verify move generation. All the leaf nodes up\n   // to the given depth are generated and counted, and the sum is returned.\n@@ -243,6 +245,23 @@ void MainThread::search() {\n   DrawValue[ us] = VALUE_DRAW - Value(contempt);\n   DrawValue[~us] = VALUE_DRAW + Value(contempt);\n \n+  // Set TB probing parameters\n+  TB::DrawScore = Options[\"Syzygy50MoveRule\"] ? TB::WDLCursedWin : TB::WDLDraw;\n+  TB::ProbeDepth = Options[\"SyzygyProbeDepth\"] * ONE_PLY;\n+  TB::Cardinality = Options[\"SyzygyProbeLimit\"];\n+\n+  if (TB::Cardinality > TB::MaxCardinality)\n+  {\n+      TB::Cardinality = TB::MaxCardinality;\n+      TB::ProbeDepth = DEPTH_ZERO; // Hack!\n+  }\n+\n+  // Enable probing of DTZ only when WDL is not enough\n+  TB::CanProbeDTZ =   TB::RootPosDTZ != TB::DTZ_NONE // Only if root is in TB\n+                   && TB::RootPosDTZ != 0;           // Not a draw\n+\n+  TB::RootWDL = TB::CanProbeDTZ ? TB::dtz_to_wdl(TB::RootPosDTZ, rootPos.rule50_count())\n+                                : TB::WDLScoreNone;\n   if (rootMoves.empty())\n   {\n       rootMoves.emplace_back(MOVE_NONE);\n@@ -303,16 +322,59 @@ void MainThread::search() {\n       }\n   }\n \n-  previousScore = bestThread->rootMoves[0].score;\n+  RootMove& bestMove = bestThread->rootMoves[0];\n+  previousScore = bestMove.score;\n+\n+  // When starting from a DTZ position ensure we return DTZ optimal move or a\n+  // mate. We don't need DTZ post-processing for draw positions because WDL will\n+  // do the job.\n+  if (TB::CanProbeDTZ && abs(bestMove.score) < VALUE_MATE_IN_MAX_PLY)\n+  {\n+      TB::WDLScore wdl = TB::dtz_to_wdl(bestMove.dtz, rootPos.rule50_count());\n+\n+      assert(wdl <= TB::RootWDL);\n+\n+      // Force a DTZ best move if we don't preserve the WDL score or if we are\n+      // winning but we don't follow the shortest path to zero, the latter\n+      // condition is to avoid a possible draw by repetition.\n+      // When losing we don't enforce anything so to lose with naturalness :-)\n+      if (    wdl < TB::RootWDL\n+          || (TB::RootWDL > TB::DrawScore && TB::RootPosDTZ != bestMove.dtz))\n+      {\n+          auto it = std::find_if(rootMoves.begin(), rootMoves.end(), [&](const RootMove& rm) {\n+                                 return TB::RootPosDTZ == rm.dtz; });\n+\n+          assert(it != rootMoves.end());\n+\n+          // Don't follow (silly) captures but trust the search if win is preserved\n+          if (wdl < TB::RootWDL || !rootPos.capture(it->pv[0]))\n+          {\n+              bestMove.pv.clear();\n+              bestMove.pv.push_back(it->pv[0]);\n+          }\n+      }\n+\n+      static_assert(int(PawnValueEg) * 120 < VALUE_MATE_IN_MAX_PLY, \"DTZ overflow\");\n+\n+      // Signal the GUI we are in TB and codify DTZ count into output score\n+      if (   TB::DrawScore != TB::WDLDraw // Rule50 enabled\n+          && (TB::RootWDL == TB::WDLBlessedLoss || TB::RootWDL == TB::WDLCursedWin))\n+          bestMove.score = sign_of(TB::RootPosDTZ) * PawnValueEg / 10;\n+      else\n+      {\n+          auto s = PawnValueEg * (120 - abs(TB::RootPosDTZ) / 2);\n+          bestMove.score = sign_of(TB::RootPosDTZ) * std::max(s, PawnValueEg * 10);\n+      }\n+  }\n \n   // Send new PV when needed\n-  if (bestThread != this)\n+  if (bestThread != this || TB::RootPosDTZ != TB::DTZ_NONE)\n       sync_cout << UCI::pv(bestThread->rootPos, bestThread->completedDepth, -VALUE_INFINITE, VALUE_INFINITE) << sync_endl;\n \n-  sync_cout << \"bestmove \" << UCI::move(bestThread->rootMoves[0].pv[0], rootPos.is_chess960());\n+  sync_cout << \"bestmove \" << UCI::move(bestMove.pv[0], rootPos.is_chess960());\n \n   if (bestThread->rootMoves[0].pv.size() > 1 || bestThread->rootMoves[0].extract_ponder_from_tt(rootPos))\n-      std::cout << \" ponder \" << UCI::move(bestThread->rootMoves[0].pv[1], rootPos.is_chess960());\n+      std::cout << \" ponder \" << UCI::move(bestMove.pv[1], rootPos.is_chess960());\n \n   std::cout << sync_endl;\n }\n@@ -330,6 +392,7 @@ void Thread::search() {\n   MainThread* mainThread = (this == Threads.main() ? Threads.main() : nullptr);\n \n   std::memset(ss-4, 0, 7 * sizeof(Stack));\n+  ss->tbCardinality = TB::Cardinality;\n   for (int i = 4; i > 0; i--)\n      (ss-i)->contHistory = &this->contHistory[NO_PIECE][0]; // Use as sentinel\n \n@@ -587,6 +650,7 @@ namespace {\n     ss->currentMove = (ss+1)->excludedMove = bestMove = MOVE_NONE;\n     ss->contHistory = &thisThread->contHistory[NO_PIECE][0];\n     (ss+2)->killers[0] = (ss+2)->killers[1] = MOVE_NONE;\n+    (ss+1)->tbCardinality = ss->tbCardinality;\n     Square prevSq = to_sq((ss-1)->currentMove);\n \n     // Step 4. Transposition table lookup. We don't want the score of a partial\n@@ -631,34 +695,18 @@ namespace {\n     }\n \n     // Step 4a. Tablebase probe\n-    if (!rootNode && TB::Cardinality)\n+    if (!rootNode && ss->tbCardinality)\n     {\n         int piecesCount = pos.count<ALL_PIECES>();\n \n-        if (    piecesCount <= TB::Cardinality\n-            && (piecesCount <  TB::Cardinality || depth >= TB::ProbeDepth)\n-            &&  pos.rule50_count() == 0\n+        if (    piecesCount <= ss->tbCardinality\n+            && (piecesCount <  ss->tbCardinality || depth >= TB::ProbeDepth)\n             && !pos.can_castle(ANY_CASTLING))\n         {\n-            TB::ProbeState err;\n-            TB::WDLScore v = Tablebases::probe_wdl(pos, &err);\n-\n-            if (err != TB::ProbeState::FAIL)\n-            {\n-                thisThread->tbHits.fetch_add(1, std::memory_order_relaxed);\n-\n-                int drawScore = TB::UseRule50 ? 1 : 0;\n-\n-                value =  v < -drawScore ? -VALUE_MATE + MAX_PLY + ss->ply + 1\n-                       : v >  drawScore ?  VALUE_MATE - MAX_PLY - ss->ply - 1\n-                                        :  VALUE_DRAW + 2 * v * drawScore;\n-\n-                tte->save(posKey, value_to_tt(value, ss->ply), BOUND_EXACT,\n-                          std::min(DEPTH_MAX - ONE_PLY, depth + 6 * ONE_PLY),\n-                          MOVE_NONE, VALUE_NONE, TT.generation());\n+            value = probe_tb(pos, ss, alpha, beta, &depth, tte);\n \n+            if (value != VALUE_NONE)\n                 return value;\n-            }\n         }\n     }\n \n@@ -1456,6 +1504,92 @@ namespace {\n     return best;\n   }\n \n+\n+  // probe_tb() is called by search after TT probe to look up the position in\n+  // tablebases, if it is found we return immediately or continue the search\n+  // eventually with reduced depth according to the case.\n+\n+  Value probe_tb(Position& pos, Stack* ss, Value alpha, Value beta, Depth* depth, TTEntry* tte) {\n+\n+    TB::ProbeState err;\n+    TB::WDLScore wdl;\n+    bool tbHit = false, farFromRoot = false, reduceDepth = true;\n+\n+    Thread* thisThread = pos.this_thread();\n+    thisThread->tbHits.fetch_add(1, std::memory_order_relaxed);\n+\n+    // If rootPos is in TB we probe DTZ to differentiate between a win/loss and\n+    // a cursed/blessed draw. This is critical because WDL is reliable only if\n+    // rule50 counter is zero and search alone would detect it only at ply 100.\n+    if (TB::CanProbeDTZ && (ss-1)->ply == 0)\n+    {\n+        tbHit = true;\n+        RootMove& rm = *std::find(thisThread->rootMoves.begin(),\n+                                  thisThread->rootMoves.end(), (ss-1)->currentMove);\n+\n+        wdl = TB::WDLScore(-TB::dtz_to_wdl(rm.dtz, thisThread->rootPos.rule50_count()));\n+\n+        // Search at reduced depth moves that don't preserve the score\n+        reduceDepth = -wdl < TB::RootWDL;\n+    }\n+    else\n+    {\n+        wdl = Tablebases::probe_wdl(pos, &err);\n+\n+        // Win or loss scores are reliable only if we are probing after a\n+        // rule50 reset move. Instead draw scores are reliable in any case.\n+        if (   err != TB::ProbeState::FAIL\n+            && (pos.rule50_count() == 0 || abs(wdl) <= TB::DrawScore))\n+        {\n+            tbHit = true;\n+\n+            // It is far if ply >= (RootDepth - LMR) / 3, so that at a given ply\n+            // nodes with high LMR are considered farther from root than nodes\n+            // near the PV line.\n+            farFromRoot = ss->ply - *depth / (2 * ONE_PLY) >= 0;\n+\n+            // Don't save in TT and don't reduce if root is in TB\n+            if (TB::RootPosDTZ != TB::DTZ_NONE)\n+                farFromRoot = reduceDepth = false;\n+        }\n+    }\n+\n+    if (tbHit)\n+    {\n+        Value value =  wdl >  TB::DrawScore ?  VALUE_MATE - MAX_PLY - ss->ply\n+                     : wdl < -TB::DrawScore ? -VALUE_MATE + MAX_PLY + ss->ply\n+                                            :  VALUE_DRAW + 2 * wdl;\n+\n+        Bound bound =  wdl >  TB::DrawScore ? BOUND_LOWER\n+                     : wdl < -TB::DrawScore ? BOUND_UPPER : BOUND_EXACT;\n+\n+        // Use TB scores as lower/upper bounds, a draw score is BOUND_EXACT\n+        // and is always considered even if value is within (alpha, beta)\n+        if (   (value >= beta  && bound == BOUND_LOWER)\n+            || (value <= alpha && bound == BOUND_UPPER)\n+            ||  bound == BOUND_EXACT)\n+        {\n+            // When in midgame or is a draw save in TT and return...\n+            if (bound == BOUND_EXACT || farFromRoot)\n+            {\n+                Key posKey = pos.key() ^ Key(ss->excludedMove);\n+                tte->save(posKey, value_to_tt(value, ss->ply), bound,\n+                          std::min(DEPTH_MAX - ONE_PLY, *depth + 6 * ONE_PLY),\n+                          MOVE_NONE, VALUE_NONE, TT.generation());\n+                return value;\n+            }\n+            // ...otherwise search win/loss eventually with with a reduced depth\n+            else if (reduceDepth)\n+                *depth = std::max(*depth / 2, ONE_PLY);\n+\n+            // Don't probe in the win/loss sub-tree (draws cut-off immediately)\n+            ss->tbCardinality = 0;\n+        }\n+    }\n+\n+    return VALUE_NONE;\n+  }\n+\n } // namespace\n \n   // check_time() is used to print debug info and, more importantly, to detect\n@@ -1503,7 +1637,7 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n   size_t PVIdx = pos.this_thread()->PVIdx;\n   size_t multiPV = std::min((size_t)Options[\"MultiPV\"], rootMoves.size());\n   uint64_t nodesSearched = Threads.nodes_searched();\n-  uint64_t tbHits = Threads.tb_hits() + (TB::RootInTB ? rootMoves.size() : 0);\n+  uint64_t tbHits = Threads.tb_hits();\n \n   for (size_t i = 0; i < multiPV; ++i)\n   {\n@@ -1515,9 +1649,6 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n       Depth d = updated ? depth : depth - ONE_PLY;\n       Value v = updated ? rootMoves[i].score : rootMoves[i].previousScore;\n \n-      bool tb = TB::RootInTB && abs(v) < VALUE_MATE - MAX_PLY;\n-      v = tb ? TB::Score : v;\n-\n       if (ss.rdbuf()->in_avail()) // Not at first line\n           ss << \"\\n\";\n \n@@ -1527,7 +1658,7 @@ string UCI::pv(const Position& pos, Depth depth, Value alpha, Value beta) {\n          << \" multipv \"  << i + 1\n          << \" score \"    << UCI::value(v);\n \n-      if (!tb && i == PVIdx)\n+      if (i == PVIdx)\n           ss << (v >= beta ? \" lowerbound\" : v <= alpha ? \" upperbound\" : \"\");\n \n       ss << \" nodes \"    << nodesSearched\n@@ -1576,43 +1707,3 @@ bool RootMove::extract_ponder_from_tt(Position& pos) {\n     pos.undo_move(pv[0]);\n     return pv.size() > 1;\n }\n-\n-void Tablebases::filter_root_moves(Position& pos, Search::RootMoves& rootMoves) {\n-\n-    RootInTB = false;\n-    UseRule50 = Options[\"Syzygy50MoveRule\"];\n-    ProbeDepth = Options[\"SyzygyProbeDepth\"] * ONE_PLY;\n-    Cardinality = Options[\"SyzygyProbeLimit\"];\n-\n-    // Skip TB probing when no TB found: !TBLargest -> !TB::Cardinality\n-    if (Cardinality > MaxCardinality)\n-    {\n-        Cardinality = MaxCardinality;\n-        ProbeDepth = DEPTH_ZERO;\n-    }\n-\n-    if (Cardinality < popcount(pos.pieces()) || pos.can_castle(ANY_CASTLING))\n-        return;\n-\n-    // If the current root position is in the tablebases, then RootMoves\n-    // contains only moves that preserve the draw or the win.\n-    RootInTB = root_probe(pos, rootMoves, TB::Score);\n-\n-    if (RootInTB)\n-        Cardinality = 0; // Do not probe tablebases during the search\n-\n-    else // If DTZ tables are missing, use WDL tables as a fallback\n-    {\n-        // Filter out moves that do not preserve the draw or the win.\n-        RootInTB = root_probe_wdl(pos, rootMoves, TB::Score);\n-\n-        // Only probe during search if winning\n-        if (RootInTB && TB::Score <= VALUE_DRAW)\n-            Cardinality = 0;\n-    }\n-\n-    if (RootInTB && !UseRule50)\n-        TB::Score =  TB::Score > VALUE_DRAW ?  VALUE_MATE - MAX_PLY - 1\n-                   : TB::Score < VALUE_DRAW ? -VALUE_MATE + MAX_PLY + 1\n-                                            :  VALUE_DRAW;\n-}\ndiff --git a/src/search.h b/src/search.h\nindex 694dd643892..9587edb6510 100644\n--- a/src/search.h\n+++ b/src/search.h\n@@ -49,6 +49,7 @@ struct Stack {\n   Value staticEval;\n   int statScore;\n   int moveCount;\n+  int tbCardinality;\n };\n \n \n@@ -69,6 +70,7 @@ struct RootMove {\n   Value score = -VALUE_INFINITE;\n   Value previousScore = -VALUE_INFINITE;\n   int selDepth = 0;\n+  int dtz;\n   std::vector<Move> pv;\n };\n \ndiff --git a/src/syzygy/tbprobe.cpp b/src/syzygy/tbprobe.cpp\nindex 4aff3b2da4b..0e13af463f1 100644\n--- a/src/syzygy/tbprobe.cpp\n+++ b/src/syzygy/tbprobe.cpp\n@@ -29,6 +29,7 @@\n #include <type_traits>\n \n #include \"../bitboard.h\"\n+#include \"../misc.h\"\n #include \"../movegen.h\"\n #include \"../position.h\"\n #include \"../search.h\"\n@@ -71,11 +72,6 @@ int dtz_before_zeroing(WDLScore wdl) {\n            wdl == WDLLoss        ? -1   : 0;\n }\n \n-// Return the sign of a number (-1, 0, 1)\n-template <typename T> int sign_of(T val) {\n-    return (T(0) < val) - (val < T(0));\n-}\n-\n // Numbers in little endian used by sparseIndex[] to point into blockLength[]\n struct SparseEntry {\n     char block[4];   // Number of block\n@@ -208,14 +204,6 @@ int MapKK[10][SQUARE_NB]; // [MapA1D1D4][SQUARE_NB]\n bool pawns_comp(Square i, Square j) { return MapPawns[i] < MapPawns[j]; }\n int off_A1H8(Square sq) { return int(rank_of(sq)) - file_of(sq); }\n \n-const Value WDL_to_value[] = {\n-   -VALUE_MATE + MAX_PLY + 1,\n-    VALUE_DRAW - 2,\n-    VALUE_DRAW,\n-    VALUE_DRAW + 2,\n-    VALUE_MATE - MAX_PLY - 1\n-};\n-\n const std::string PieceToChar = \" PNBRQK  pnbrqk\";\n \n int Binomial[6][SQUARE_NB];    // [k][n] k elements from a set of n elements\n@@ -1200,7 +1188,7 @@ T probe_table(const Position& pos, ProbeState* result, WDLScore wdl = WDLDraw) {\n // where the best move is an ep-move (even if losing). So in all these cases set\n // the state to ZEROING_BEST_MOVE.\n template<bool CheckZeroingMoves = false>\n-WDLScore search(Position& pos, ProbeState* result) {\n+WDLScore search_wdl(Position& pos, ProbeState* result) {\n \n     WDLScore value, bestValue = WDLLoss;\n     StateInfo st;\n@@ -1208,17 +1196,17 @@ WDLScore search(Position& pos, ProbeState* result) {\n     auto moveList = MoveList<LEGAL>(pos);\n     size_t totalCount = moveList.size(), moveCount = 0;\n \n-    for (const Move& move : moveList)\n+    for (const auto& m : moveList)\n     {\n-        if (   !pos.capture(move)\n-            && (!CheckZeroingMoves || type_of(pos.moved_piece(move)) != PAWN))\n+        if (   !pos.capture(m)\n+            && (!CheckZeroingMoves || type_of(pos.moved_piece(m)) != PAWN))\n             continue;\n \n         moveCount++;\n \n-        pos.do_move(move, st);\n-        value = -search(pos, result);\n-        pos.undo_move(move);\n+        pos.do_move(m, st);\n+        value = -search_wdl(pos, result);\n+        pos.undo_move(m);\n \n         if (*result == FAIL)\n             return WDLDraw;\n@@ -1261,8 +1249,69 @@ WDLScore search(Position& pos, ProbeState* result) {\n     return *result = OK, value;\n }\n \n+// Do a 1-ply search probing DTZ values of resulting positions and reporting\n+// back the minimum DTZ already converted to the point of view of previous ply.\n+// If rootMoves is passed then set the corresponding RootMove dtz field.\n+int search_dtz(Position& pos, ProbeState* result, int r50, Search::RootMoves* rootMoves) {\n+\n+    StateInfo st;\n+    WDLScore wdl = WDLLoss;\n+    int minDTZ = 0xFFFF;\n+\n+    for (const auto& m : MoveList<LEGAL>(pos))\n+    {\n+        bool zeroing = pos.capture(m) || type_of(pos.moved_piece(m)) == PAWN;\n+\n+        pos.do_move(m, st);\n+\n+        // For zeroing moves we want the dtz of the move _before_ doing it,\n+        // otherwise we will get the dtz of the next move sequence. Search the\n+        // position after the move to get the score sign (because even in a\n+        // winning position we could make a losing capture or going for a draw).\n+        int dtz = zeroing ? -dtz_before_zeroing(search_wdl(pos, result))\n+                          : -probe_dtz(pos, result);\n+\n+        if (pos.is_draw(1))\n+            dtz = 0; // Draw by 3-fold repetition\n+\n+        pos.undo_move(m);\n+\n+        if (*result == FAIL)\n+            return 0;\n+\n+        // Convert result from 1-ply search. Zeroing moves are already accounted\n+        // by dtz_before_zeroing() that returns the DTZ of the previous move.\n+        if (!zeroing)\n+            dtz += sign_of(dtz);\n+\n+        if (dtz_to_wdl(dtz, r50) > wdl)\n+        {\n+            wdl = dtz_to_wdl(dtz, r50);\n+            minDTZ = dtz;\n+        }\n+        // Skip the draws and if we are winning only pick positive dtz\n+        else if (dtz < minDTZ && sign_of(dtz) == sign_of(wdl))\n+            minDTZ = dtz;\n+\n+        if (rootMoves)\n+            std::find(rootMoves->begin(), rootMoves->end(), m)->dtz = dtz;\n+    }\n+\n+    // Special handle a mate position, when there are no legal moves, in this\n+    // case return value is somewhat arbitrary, so stick to the original TB code\n+    // that returns -1 in this case.\n+    return minDTZ == 0xFFFF ? -1 : minDTZ;\n+}\n+\n } // namespace\n \n+WDLScore Tablebases::dtz_to_wdl(int dtz, int r50) {\n+\n+    bool cursed = abs(dtz) + r50 > 100;\n+    return  dtz > 0 ? (cursed ? WDLCursedWin   : WDLWin)\n+          : dtz < 0 ? (cursed ? WDLBlessedLoss : WDLLoss) : WDLDraw;\n+}\n+\n void Tablebases::init(const std::string& paths) {\n \n     EntryTable.clear();\n@@ -1406,7 +1455,7 @@ void Tablebases::init(const std::string& paths) {\n WDLScore Tablebases::probe_wdl(Position& pos, ProbeState* result) {\n \n     *result = OK;\n-    return search(pos, result);\n+    return search_wdl(pos, result);\n }\n \n // Probe the DTZ table for a particular position.\n@@ -1437,7 +1486,7 @@ WDLScore Tablebases::probe_wdl(Position& pos, ProbeState* result) {\n int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n \n     *result = OK;\n-    WDLScore wdl = search<true>(pos, result);\n+    WDLScore wdl = search_wdl<true>(pos, result);\n \n     if (*result == FAIL || wdl == WDLDraw) // DTZ tables don't store draws\n         return 0;\n@@ -1457,246 +1506,25 @@ int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n \n     // DTZ stores results for the other side, so we need to do a 1-ply search and\n     // find the winning move that minimizes DTZ.\n-    StateInfo st;\n-    int minDTZ = 0xFFFF;\n-\n-    for (const Move& move : MoveList<LEGAL>(pos))\n-    {\n-        bool zeroing = pos.capture(move) || type_of(pos.moved_piece(move)) == PAWN;\n-\n-        pos.do_move(move, st);\n-\n-        // For zeroing moves we want the dtz of the move _before_ doing it,\n-        // otherwise we will get the dtz of the next move sequence. Search the\n-        // position after the move to get the score sign (because even in a\n-        // winning position we could make a losing capture or going for a draw).\n-        dtz = zeroing ? -dtz_before_zeroing(search(pos, result))\n-                      : -probe_dtz(pos, result);\n-\n-        pos.undo_move(move);\n-\n-        if (*result == FAIL)\n-            return 0;\n-\n-        // Convert result from 1-ply search. Zeroing moves are already accounted\n-        // by dtz_before_zeroing() that returns the DTZ of the previous move.\n-        if (!zeroing)\n-            dtz += sign_of(dtz);\n-\n-        // Skip the draws and if we are winning only pick positive dtz\n-        if (dtz < minDTZ && sign_of(dtz) == sign_of(wdl))\n-            minDTZ = dtz;\n-    }\n-\n-    // Special handle a mate position, when there are no legal moves, in this\n-    // case return value is somewhat arbitrary, so stick to the original TB code\n-    // that returns -1 in this case.\n-    return minDTZ == 0xFFFF ? -1 : minDTZ;\n+    return search_dtz(pos, result, pos.rule50_count(), nullptr);\n }\n \n-// Check whether there has been at least one repetition of positions\n-// since the last capture or pawn move.\n-static int has_repeated(StateInfo *st)\n-{\n-    while (1) {\n-        int i = 4, e = std::min(st->rule50, st->pliesFromNull);\n-\n-        if (e < i)\n-            return 0;\n-\n-        StateInfo *stp = st->previous->previous;\n-\n-        do {\n-            stp = stp->previous->previous;\n-\n-            if (stp->key == st->key)\n-                return 1;\n-\n-            i += 2;\n-        } while (i <= e);\n-\n-        st = st->previous;\n-    }\n-}\n-\n-// Use the DTZ tables to filter out moves that don't preserve the win or draw.\n-// If the position is lost, but DTZ is fairly high, only keep moves that\n-// maximise DTZ.\n-//\n-// A return value false indicates that not all probes were successful and that\n-// no moves were filtered out.\n-bool Tablebases::root_probe(Position& pos, Search::RootMoves& rootMoves, Value& score)\n-{\n-    assert(rootMoves.size());\n+// Probe DTZ tables for each root move and store the result\n+void Tablebases::dtz_score(Position& pos, Search::RootMoves& rootMoves) {\n \n     ProbeState result;\n-    int dtz = probe_dtz(pos, &result);\n-\n-    if (result == FAIL)\n-        return false;\n-\n-    StateInfo st;\n-\n-    // Probe each move\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        Move move = rootMoves[i].pv[0];\n-        pos.do_move(move, st);\n-        int v = 0;\n-\n-        if (pos.checkers() && dtz > 0) {\n-            ExtMove s[MAX_MOVES];\n+    RootPosDTZ = DTZ_NONE;\n \n-            if (generate<LEGAL>(pos, s) == s)\n-                v = 1;\n-        }\n-\n-        if (!v) {\n-            if (st.rule50 != 0) {\n-                v = -probe_dtz(pos, &result);\n-\n-                if (v > 0)\n-                    ++v;\n-                else if (v < 0)\n-                    --v;\n-            } else {\n-                v = -probe_wdl(pos, &result);\n-                v = dtz_before_zeroing(WDLScore(v));\n-            }\n-        }\n-\n-        pos.undo_move(move);\n-\n-        if (result == FAIL)\n-            return false;\n-\n-        rootMoves[i].score = (Value)v;\n-    }\n-\n-    // Obtain 50-move counter for the root position.\n-    // In Stockfish there seems to be no clean way, so we do it like this:\n-    int cnt50 = st.previous ? st.previous->rule50 : 0;\n-\n-    // Use 50-move counter to determine whether the root position is\n-    // won, lost or drawn.\n-    WDLScore wdl = WDLDraw;\n-\n-    if (dtz > 0)\n-        wdl = (dtz + cnt50 <= 100) ? WDLWin : WDLCursedWin;\n-    else if (dtz < 0)\n-        wdl = (-dtz + cnt50 <= 100) ? WDLLoss : WDLBlessedLoss;\n-\n-    // Determine the score to report to the user.\n-    score = WDL_to_value[wdl + 2];\n-\n-    // If the position is winning or losing, but too few moves left, adjust the\n-    // score to show how close it is to winning or losing.\n-    // NOTE: int(PawnValueEg) is used as scaling factor in score_to_uci().\n-    if (wdl == WDLCursedWin && dtz <= 100)\n-        score = (Value)(((200 - dtz - cnt50) * int(PawnValueEg)) / 200);\n-    else if (wdl == WDLBlessedLoss && dtz >= -100)\n-        score = -(Value)(((200 + dtz - cnt50) * int(PawnValueEg)) / 200);\n-\n-    // Now be a bit smart about filtering out moves.\n-    size_t j = 0;\n-\n-    if (dtz > 0) { // winning (or 50-move rule draw)\n-        int best = 0xffff;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v > 0 && v < best)\n-                best = v;\n-        }\n-\n-        int max = best;\n-\n-        // If the current phase has not seen repetitions, then try all moves\n-        // that stay safely within the 50-move budget, if there are any.\n-        if (!has_repeated(st.previous) && best + cnt50 <= 99)\n-            max = 99 - cnt50;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v > 0 && v <= max)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    } else if (dtz < 0) { // losing (or 50-move rule draw)\n-        int best = 0;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            int v = rootMoves[i].score;\n-\n-            if (v < best)\n-                best = v;\n-        }\n-\n-        // Try all moves, unless we approach or have a 50-move rule draw.\n-        if (-best * 2 + cnt50 < 100)\n-            return true;\n-\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            if (rootMoves[i].score == best)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    } else { // drawing\n-        // Try all moves that preserve the draw.\n-        for (size_t i = 0; i < rootMoves.size(); ++i) {\n-            if (rootMoves[i].score == 0)\n-                rootMoves[j++] = rootMoves[i];\n-        }\n-    }\n-\n-    rootMoves.resize(j, Search::RootMove(MOVE_NONE));\n-\n-    return true;\n-}\n-\n-// Use the WDL tables to filter out moves that don't preserve the win or draw.\n-// This is a fallback for the case that some or all DTZ tables are missing.\n-//\n-// A return value false indicates that not all probes were successful and that\n-// no moves were filtered out.\n-bool Tablebases::root_probe_wdl(Position& pos, Search::RootMoves& rootMoves, Value& score)\n-{\n-    ProbeState result;\n-\n-    WDLScore wdl = Tablebases::probe_wdl(pos, &result);\n-\n-    if (result == FAIL)\n-        return false;\n-\n-    score = WDL_to_value[wdl + 2];\n-\n-    StateInfo st;\n-\n-    int best = WDLLoss;\n-\n-    // Probe each move\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        Move move = rootMoves[i].pv[0];\n-        pos.do_move(move, st);\n-        WDLScore v = -Tablebases::probe_wdl(pos, &result);\n-        pos.undo_move(move);\n-\n-        if (result == FAIL)\n-            return false;\n-\n-        rootMoves[i].score = (Value)v;\n-\n-        if (v > best)\n-            best = v;\n-    }\n-\n-    size_t j = 0;\n-\n-    for (size_t i = 0; i < rootMoves.size(); ++i) {\n-        if (rootMoves[i].score == best)\n-            rootMoves[j++] = rootMoves[i];\n-    }\n+    if (   pos.count<ALL_PIECES>() > MaxCardinality\n+        || pos.can_castle(ANY_CASTLING)\n+        || rootMoves.empty())\n+        return;\n \n-    rootMoves.resize(j, Search::RootMove(MOVE_NONE));\n+    // Value of probe_dtz() can be off by 1, so use search_dtz() for RootPosDTZ\n+    int dtz = Tablebases::probe_dtz(pos, &result);\n+    if (result != FAIL)\n+        dtz = search_dtz(pos, &result, pos.rule50_count(), &rootMoves);\n \n-    return true;\n+    if (result != FAIL)\n+        RootPosDTZ = dtz;\n }\ndiff --git a/src/syzygy/tbprobe.h b/src/syzygy/tbprobe.h\nindex f44674b215f..597080244f9 100644\n--- a/src/syzygy/tbprobe.h\n+++ b/src/syzygy/tbprobe.h\n@@ -26,6 +26,8 @@\n \n namespace Tablebases {\n \n+const int DTZ_NONE = 999;\n+\n enum WDLScore {\n     WDLLoss        = -2, // Loss\n     WDLBlessedLoss = -1, // Loss, but draw under 50-move rule\n@@ -45,13 +47,15 @@ enum ProbeState {\n };\n \n extern int MaxCardinality;\n+extern int RootPosDTZ;\n+extern WDLScore RootWDL;\n+extern bool CanProbeDTZ;\n \n void init(const std::string& paths);\n WDLScore probe_wdl(Position& pos, ProbeState* result);\n int probe_dtz(Position& pos, ProbeState* result);\n-bool root_probe(Position& pos, Search::RootMoves& rootMoves, Value& score);\n-bool root_probe_wdl(Position& pos, Search::RootMoves& rootMoves, Value& score);\n-void filter_root_moves(Position& pos, Search::RootMoves& rootMoves);\n+void dtz_score(Position& pos, Search::RootMoves& rootMoves);\n+WDLScore dtz_to_wdl(int dtz, int r50);\n \n inline std::ostream& operator<<(std::ostream& os, const WDLScore v) {\n \ndiff --git a/src/thread.cpp b/src/thread.cpp\nindex eb360869b53..3b1a0bd7422 100644\n--- a/src/thread.cpp\n+++ b/src/thread.cpp\n@@ -163,8 +163,7 @@ void ThreadPool::start_thinking(Position& pos, StateListPtr& states,\n           || std::count(limits.searchmoves.begin(), limits.searchmoves.end(), m))\n           rootMoves.emplace_back(m);\n \n-  if (!rootMoves.empty())\n-      Tablebases::filter_root_moves(pos, rootMoves);\n+  Tablebases::dtz_score(pos, rootMoves); // If root is in TB, DTZ probe rootMoves\n \n   // After ownership transfer 'states' becomes empty, so if we stop the search\n   // and call 'go' again without setting a new position states.get() == NULL.\ndiff --git a/src/types.h b/src/types.h\nindex acca8743a48..4f88eec387e 100644\n--- a/src/types.h\n+++ b/src/types.h\n@@ -180,8 +180,8 @@ enum Value : int {\n   VALUE_INFINITE  = 32001,\n   VALUE_NONE      = 32002,\n \n-  VALUE_MATE_IN_MAX_PLY  =  VALUE_MATE - 2 * MAX_PLY,\n-  VALUE_MATED_IN_MAX_PLY = -VALUE_MATE + 2 * MAX_PLY,\n+  VALUE_MATE_IN_MAX_PLY  =  VALUE_MATE - MAX_PLY,\n+  VALUE_MATED_IN_MAX_PLY = -VALUE_MATE + MAX_PLY,\n \n   PawnValueMg   = 171,   PawnValueEg   = 240,\n   KnightValueMg = 764,   KnightValueEg = 848,\ndiff --git a/src/uci.cpp b/src/uci.cpp\nindex fc66f0b5321..8ec5916024d 100644\n--- a/src/uci.cpp\n+++ b/src/uci.cpp\n@@ -142,8 +142,8 @@ namespace {\n \n   void bench(Position& pos, istream& args, StateListPtr& states) {\n \n-    string token;\n-    uint64_t num, nodes = 0, cnt = 1;\n+    string token, tbh;\n+    uint64_t num, nodes = 0, tbHits = 0, cnt = 1;\n \n     vector<string> list = setup_bench(pos, args);\n     num = count_if(list.begin(), list.end(), [](string s) { return s.find(\"go \") == 0; });\n@@ -160,7 +160,8 @@ namespace {\n             cerr << \"\\nPosition: \" << cnt++ << '/' << num << endl;\n             go(pos, is, states);\n             Threads.main()->wait_for_search_finished();\n-            nodes += Threads.nodes_searched();\n+            nodes  += Threads.nodes_searched();\n+            tbHits += Threads.tb_hits();\n         }\n         else if (token == \"setoption\")  setoption(is);\n         else if (token == \"position\")   position(pos, is, states);\n@@ -174,7 +175,8 @@ namespace {\n     cerr << \"\\n===========================\"\n          << \"\\nTotal time (ms) : \" << elapsed\n          << \"\\nNodes searched  : \" << nodes\n-         << \"\\nNodes/second    : \" << 1000 * nodes / elapsed << endl;\n+         << \"\\nNodes/second    : \" << 1000 * nodes / elapsed\n+         << \"\\nTB hits         : \" << tbHits << endl;\n   }\n \n } // namespace\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Bugs**: Current master code fails to convert some wins. Need to investigate specific positions where this occurs.\n  \n2. **Implementation Suggestions**:\n   - Test with 6-men tablebases to identify potential hidden bugs. Focus on ensuring that wins convert, draws preserve, and no silly sacrifices occur.\n   - Consider integrating a check to prevent repetition draws as proposed by Ronald, potentially reducing the problem of opponents repeating positions.\n   - Simplify logic - current master unnecessarily complicates code without clear improvement in addressing theoretical concerns.\n\n3. **Score Reporting**: Suggest adopting option 3 for score reporting consistency: provide a searchable PV and override the score to notify the user about being in a tablebase.\n\n4. **Next Steps**: Test and verify NTB implementation behaves as expected before further discussions on presentation of tablebase information."
      }
    ],
    "codediff_length": 31539
  },
  {
    "index": 97,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/search.cpp b/src/search.cpp\nindex e36c69593e3..7ace4649365 100644\n--- a/src/search.cpp\n+++ b/src/search.cpp\n@@ -652,6 +652,10 @@ namespace {\n             TB::ProbeState err;\n             TB::WDLScore wdl = Tablebases::probe_wdl(pos, &err);\n \n+            // Force time check on the next occasion\n+            if (thisThread == Threads.main())\n+                static_cast<MainThread*>(thisThread)->callsCnt = 0;\n+\n             if (err != TB::ProbeState::FAIL)\n             {\n                 thisThread->tbHits.fetch_add(1, std::memory_order_relaxed);\n@@ -1531,13 +1535,13 @@ namespace {\n \n } // namespace\n \n+\n /// MainThread::check_time() is used to print debug info and, more importantly,\n /// to detect when we are out of available time and thus stop the search.\n \n-void MainThread::check_time() {\n-\n+bool MainThread::check_time() {\n   if (--callsCnt > 0)\n-      return;\n+      return false;\n \n   // When using nodes, ensure checking rate is not lower than 0.1% of nodes\n   callsCnt = Limits.nodes ? std::min(1024, int(Limits.nodes / 1024)) : 1024;\n@@ -1555,12 +1559,16 @@ void MainThread::check_time() {\n \n   // We should not stop pondering until told so by the GUI\n   if (Threads.ponder)\n-      return;\n+      return false;\n \n   if (   (Limits.use_time_management() && elapsed > Time.maximum() - 10)\n       || (Limits.movetime && elapsed >= Limits.movetime)\n-      || (Limits.nodes && Threads.nodes_searched() >= (uint64_t)Limits.nodes))\n+      || (Limits.nodes && Threads.nodes_searched() >= (uint64_t)Limits.nodes)) {\n       Threads.stop = true;\n+      return true;\n+  }\n+\n+  return false;\n }\n \n \n@@ -1649,7 +1657,8 @@ bool RootMove::extract_ponder_from_tt(Position& pos) {\n     return pv.size() > 1;\n }\n \n-void Tablebases::rank_root_moves(Position& pos, Search::RootMoves& rootMoves) {\n+void Tablebases::rank_root_moves(Position& pos, Search::RootMoves& rootMoves,\n+                                 MainThread* main) {\n \n     RootInTB = false;\n     UseRule50 = bool(Options[\"Syzygy50MoveRule\"]);\n@@ -1668,13 +1677,13 @@ void Tablebases::rank_root_moves(Position& pos, Search::RootMoves& rootMoves) {\n     if (Cardinality >= popcount(pos.pieces()) && !pos.can_castle(ANY_CASTLING))\n     {\n         // Rank moves using DTZ tables\n-        RootInTB = root_probe(pos, rootMoves);\n+        RootInTB = root_probe(pos, rootMoves, main);\n \n         if (!RootInTB)\n         {\n             // DTZ tables are missing; try to rank moves using WDL tables\n             dtz_available = false;\n-            RootInTB = root_probe_wdl(pos, rootMoves);\n+            RootInTB = root_probe_wdl(pos, rootMoves, main);\n         }\n     }\n \ndiff --git a/src/syzygy/tbprobe.cpp b/src/syzygy/tbprobe.cpp\nindex dc7c523ae79..31273d21d6a 100644\n--- a/src/syzygy/tbprobe.cpp\n+++ b/src/syzygy/tbprobe.cpp\n@@ -1467,7 +1467,8 @@ int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n // Use the DTZ tables to rank root moves.\n //\n // A return value false indicates that not all probes were successful.\n-bool Tablebases::root_probe(Position& pos, Search::RootMoves& rootMoves) {\n+bool Tablebases::root_probe(Position& pos, Search::RootMoves& rootMoves,\n+                            MainThread* main) {\n \n     ProbeState result;\n     StateInfo st;\n@@ -1526,6 +1527,11 @@ bool Tablebases::root_probe(Position& pos, Search::RootMoves& rootMoves) {\n                    : r == 0     ? VALUE_DRAW\n                    : r > -bound ? Value((std::min(-3, r + 800) * int(PawnValueEg)) / 200)\n                    :             -VALUE_MATE + MAX_PLY + 1;\n+\n+        // Force time check\n+        main->callsCnt = 0;\n+        if (main->check_time())\n+            return false;\n     }\n \n     return true;\n@@ -1536,7 +1542,8 @@ bool Tablebases::root_probe(Position& pos, Search::RootMoves& rootMoves) {\n // This is a fallback for the case that some or all DTZ tables are missing.\n //\n // A return value false indicates that not all probes were successful.\n-bool Tablebases::root_probe_wdl(Position& pos, Search::RootMoves& rootMoves) {\n+bool Tablebases::root_probe_wdl(Position& pos, Search::RootMoves& rootMoves,\n+                                MainThread* main) {\n \n     static const int WDL_to_rank[] = { -1000, -899, 0, 899, 1000 };\n \n@@ -1563,6 +1570,11 @@ bool Tablebases::root_probe_wdl(Position& pos, Search::RootMoves& rootMoves) {\n             wdl =  wdl > WDLDraw ? WDLWin\n                  : wdl < WDLDraw ? WDLLoss : WDLDraw;\n         m.tbScore = WDL_to_value[wdl + 2];\n+\n+        // Force time check\n+        main->callsCnt = 0;\n+        if (main->check_time())\n+            return false;\n     }\n \n     return true;\ndiff --git a/src/syzygy/tbprobe.h b/src/syzygy/tbprobe.h\nindex 572265b5244..620a57e27fa 100644\n--- a/src/syzygy/tbprobe.h\n+++ b/src/syzygy/tbprobe.h\n@@ -23,6 +23,7 @@\n #include <ostream>\n \n #include \"../search.h\"\n+#include \"../thread.h\"\n \n namespace Tablebases {\n \n@@ -49,9 +50,12 @@ extern int MaxCardinality;\n void init(const std::string& paths);\n WDLScore probe_wdl(Position& pos, ProbeState* result);\n int probe_dtz(Position& pos, ProbeState* result);\n-bool root_probe(Position& pos, Search::RootMoves& rootMoves);\n-bool root_probe_wdl(Position& pos, Search::RootMoves& rootMoves);\n-void rank_root_moves(Position& pos, Search::RootMoves& rootMoves);\n+bool root_probe(Position& pos, Search::RootMoves& rootMoves,\n+                MainThread* main);\n+bool root_probe_wdl(Position& pos, Search::RootMoves& rootMoves,\n+                    MainThread* main);\n+void rank_root_moves(Position& pos, Search::RootMoves& rootMoves,\n+                     MainThread* main);\n \n inline std::ostream& operator<<(std::ostream& os, const WDLScore v) {\n \ndiff --git a/src/thread.cpp b/src/thread.cpp\nindex ed7c5f336fe..1445908ff7a 100644\n--- a/src/thread.cpp\n+++ b/src/thread.cpp\n@@ -173,7 +173,7 @@ void ThreadPool::start_thinking(Position& pos, StateListPtr& states,\n           rootMoves.emplace_back(m);\n \n   if (!rootMoves.empty())\n-      Tablebases::rank_root_moves(pos, rootMoves);\n+      Tablebases::rank_root_moves(pos, rootMoves, main());\n \n   // After ownership transfer 'states' becomes empty, so if we stop the search\n   // and call 'go' again without setting a new position states.get() == NULL.\ndiff --git a/src/thread.h b/src/thread.h\nindex 74d6e761798..c808c4321ab 100644\n--- a/src/thread.h\n+++ b/src/thread.h\n@@ -83,7 +83,7 @@ struct MainThread : public Thread {\n   using Thread::Thread;\n \n   void search() override;\n-  void check_time();\n+  bool check_time();\n \n   double bestMoveChanges, previousTimeReduction;\n   Value previousScore;\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Consider making frequent time checks an optional UCI setting, especially for users with slower HDDs. This will allow users to optimize performance without affecting SSD users. \n\n2. Modify the program to automatically enable move overhead tuning if a rotational drive is detected, validated with OS-specific checks. This should ensure it doesn\u2019t break by default.\n\n3. The current time check defaults to 1024 nodes; performance on SSDs should not regress.\n\n4. Initiate non-regression tests focusing on multithreading scenarios (at least 7 threads). Ensure the presence of timely checks during EGTB probing. \n\n5. Explore implementing a dedicated IO thread for probing to minimize blocking search threads."
      }
    ],
    "codediff_length": 6554
  },
  {
    "index": 98,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/syzygy/tbprobe.cpp b/src/syzygy/tbprobe.cpp\nindex 722679fd948..9b00bac2c66 100644\n--- a/src/syzygy/tbprobe.cpp\n+++ b/src/syzygy/tbprobe.cpp\n@@ -20,7 +20,7 @@\n #include <algorithm>\n #include <atomic>\n #include <cstdint>\n-#include <cstring>   // For std::memset\n+#include <cstring>   // For std::memset and std::memcpy\n #include <deque>\n #include <fstream>\n #include <iostream>\n@@ -54,6 +54,10 @@ int Tablebases::MaxCardinality;\n \n namespace {\n \n+constexpr int TBPIECES = 6; // Max number of supported pieces\n+\n+enum TBType { WDL, DTZ }; // Used as template parameter\n+\n // Each table has a set of flags: all of them refer to DTZ tables, the last one to WDL tables\n enum TBFlag { STM = 1, Mapped = 2, WinPlies = 4, LossPlies = 8, SingleValue = 128 };\n \n@@ -102,8 +106,6 @@ struct LR {\n \n static_assert(sizeof(LR) == 3, \"LR tree entry must be 3 bytes\");\n \n-constexpr int TBPIECES = 6;\n-\n struct PairsData {\n     int flags;\n     size_t sizeofBlock;            // Block size in bytes\n@@ -123,81 +125,81 @@ struct PairsData {\n     Piece pieces[TBPIECES];        // Position pieces: the order of pieces defines the groups\n     uint64_t groupIdx[TBPIECES+1]; // Start index used for the encoding of the group's pieces\n     int groupLen[TBPIECES+1];      // Number of pieces in a given group: KRKN -> (3, 1)\n+    uint16_t map_idx[4];           // WDLWin, WDLLoss, WDLCursedWin, WDLBlessedLoss (used in DTZ)\n };\n \n-// Helper struct to avoid manually defining entry copy constructor as we\n-// should because the default one is not compatible with std::atomic_bool.\n-struct Atomic {\n-    Atomic() = default;\n-    Atomic(const Atomic& e) { ready = e.ready.load(); } // MSVC 2013 wants assignment within body\n-    std::atomic_bool ready;\n-};\n-\n-// We define types for the different parts of the WDLEntry and DTZEntry with\n-// corresponding specializations for pieces or pawns.\n-\n-struct WDLEntryPiece {\n-    PairsData* precomp;\n-};\n+template<TBType Type>\n+struct TBEntry {\n+    typedef typename std::conditional<Type == WDL, WDLScore, int>::type Result;\n \n-struct WDLEntryPawn {\n-    uint8_t pawnCount[2];     // [Lead color / other color]\n-    WDLEntryPiece file[2][4]; // [wtm / btm][FILE_A..FILE_D]\n-};\n-\n-struct DTZEntryPiece {\n-    PairsData* precomp;\n-    uint16_t map_idx[4]; // WDLWin, WDLLoss, WDLCursedWin, WDLBlessedLoss\n-    uint8_t* map;\n-};\n-\n-struct DTZEntryPawn {\n-    uint8_t pawnCount[2];\n-    DTZEntryPiece file[4];\n-    uint8_t* map;\n-};\n+    static constexpr int Sides = Type == WDL ? 2 : 1;\n \n-struct TBEntry : public Atomic {\n+    std::atomic_bool ready;\n     void* baseAddress;\n+    uint8_t* map;\n     uint64_t mapping;\n     Key key;\n     Key key2;\n     int pieceCount;\n     bool hasPawns;\n     bool hasUniquePieces;\n-};\n+    uint8_t pawnCount[2]; // [Lead color / other color]\n+    PairsData items[Sides][4]; // [wtm / btm][FILE_A..FILE_D or 0]\n \n-// Now the main types: WDLEntry and DTZEntry\n-struct WDLEntry : public TBEntry {\n-    WDLEntry(const std::string& code);\n-   ~WDLEntry();\n-    union {\n-        WDLEntryPiece pieceTable[2]; // [wtm / btm]\n-        WDLEntryPawn  pawnTable;\n-    };\n-};\n+    PairsData* get(int stm, int f) {\n+        return &items[stm % Sides][hasPawns ? f : 0];\n+    }\n \n-struct DTZEntry : public TBEntry {\n-    DTZEntry(const WDLEntry& wdl);\n-   ~DTZEntry();\n-    union {\n-        DTZEntryPiece pieceTable;\n-        DTZEntryPawn  pawnTable;\n-    };\n+    TBEntry() : ready(false), baseAddress(nullptr) {}\n+    explicit TBEntry(const std::string& code);\n+    explicit TBEntry(const TBEntry<WDL>& wdl);\n+    ~TBEntry();\n };\n \n-typedef decltype(WDLEntry::pieceTable) WDLPieceTable;\n-typedef decltype(DTZEntry::pieceTable) DTZPieceTable;\n-typedef decltype(WDLEntry::pawnTable ) WDLPawnTable;\n-typedef decltype(DTZEntry::pawnTable ) DTZPawnTable;\n+template<>\n+TBEntry<WDL>::TBEntry(const std::string& code) : TBEntry() {\n+\n+    StateInfo st;\n+    Position pos;\n+\n+    key = pos.set(code, WHITE, &st).material_key();\n+    pieceCount = popcount(pos.pieces());\n+    hasPawns = pos.pieces(PAWN);\n+\n+    hasUniquePieces = false;\n+    for (Color c = WHITE; c <= BLACK; ++c)\n+        for (PieceType pt = PAWN; pt < KING; ++pt)\n+            if (popcount(pos.pieces(c, pt)) == 1)\n+                hasUniquePieces = true;\n+\n+    if (hasPawns) {\n+        // Set the leading color. In case both sides have pawns the leading color\n+        // is the side with less pawns because this leads to better compression.\n+        bool c =   !pos.count<PAWN>(BLACK)\n+                || (   pos.count<PAWN>(WHITE)\n+                    && pos.count<PAWN>(BLACK) >= pos.count<PAWN>(WHITE));\n \n-auto item(WDLPieceTable& e, int stm, int  ) -> decltype(e[stm])& { return e[stm]; }\n-auto item(DTZPieceTable& e, int    , int  ) -> decltype(e)& { return e; }\n-auto item(WDLPawnTable&  e, int stm, int f) -> decltype(e.file[stm][f])& { return e.file[stm][f]; }\n-auto item(DTZPawnTable&  e, int    , int f) -> decltype(e.file[f])& { return e.file[f]; }\n+        pawnCount[0] = pos.count<PAWN>(c ? WHITE : BLACK);\n+        pawnCount[1] = pos.count<PAWN>(c ? BLACK : WHITE);\n+    }\n \n-template<typename E> struct Ret { typedef int type; };\n-template<> struct Ret<WDLEntry> { typedef WDLScore type; };\n+    key2 = pos.set(code, BLACK, &st).material_key();\n+}\n+\n+template<>\n+TBEntry<DTZ>::TBEntry(const TBEntry<WDL>& wdl) : TBEntry() {\n+\n+    key = wdl.key;\n+    key2 = wdl.key2;\n+    pieceCount = wdl.pieceCount;\n+    hasPawns = wdl.hasPawns;\n+    hasUniquePieces = wdl.hasUniquePieces;\n+\n+    if (hasPawns) {\n+        pawnCount[0] = wdl.pawnCount[0];\n+        pawnCount[1] = wdl.pawnCount[1];\n+    }\n+}\n \n int MapPawns[SQUARE_NB];\n int MapB1H1H7[SQUARE_NB];\n@@ -252,7 +254,7 @@ template<typename T, int LE> T number(void* addr)\n \n class HashTable {\n \n-    typedef std::pair<WDLEntry*, DTZEntry*> EntryPair;\n+    typedef std::pair<TBEntry<WDL>*, TBEntry<DTZ>*> EntryPair;\n     typedef std::pair<Key, EntryPair> Entry;\n \n     static constexpr int TBHASHBITS = 10;\n@@ -260,15 +262,13 @@ class HashTable {\n \n     Entry hashTable[1 << TBHASHBITS][HSHMAX];\n \n-    std::deque<WDLEntry> wdlTable;\n-    std::deque<DTZEntry> dtzTable;\n+    std::deque<TBEntry<WDL>> wdlTable;\n+    std::deque<TBEntry<DTZ>> dtzTable;\n \n-    void insert(Key key, WDLEntry* wdl, DTZEntry* dtz) {\n-        Entry* entry = hashTable[key >> (64 - TBHASHBITS)];\n-\n-        for (int i = 0; i < HSHMAX; ++i, ++entry)\n-            if (!entry->second.first || entry->first == key) {\n-                *entry = std::make_pair(key, std::make_pair(wdl, dtz));\n+    void insert(Key key, TBEntry<WDL>* wdl, TBEntry<DTZ>* dtz) {\n+        for (Entry& entry : hashTable[key >> (64 - TBHASHBITS)])\n+            if (!entry.second.first || entry.first == key) {\n+                entry = std::make_pair(key, std::make_pair(wdl, dtz));\n                 return;\n             }\n \n@@ -277,24 +277,22 @@ class HashTable {\n     }\n \n public:\n-    template<typename E, int I = std::is_same<E, WDLEntry>::value ? 0 : 1>\n-    E* get(Key key) {\n-      Entry* entry = hashTable[key >> (64 - TBHASHBITS)];\n-\n-      for (int i = 0; i < HSHMAX; ++i, ++entry)\n-          if (entry->first == key)\n-              return std::get<I>(entry->second);\n-\n-      return nullptr;\n-  }\n-\n-  void clear() {\n-      std::memset(hashTable, 0, sizeof(hashTable));\n-      wdlTable.clear();\n-      dtzTable.clear();\n-  }\n-  size_t size() const { return wdlTable.size(); }\n-  void insert(const std::vector<PieceType>& pieces);\n+    template<TBType Type>\n+    TBEntry<Type>* get(Key key) {\n+        for (Entry& entry : hashTable[key >> (64 - TBHASHBITS)])\n+            if (entry.first == key)\n+                return std::get<Type>(entry.second);\n+\n+        return nullptr;\n+    }\n+\n+    void clear() {\n+        memset(hashTable, 0, sizeof(hashTable));\n+        wdlTable.clear();\n+        dtzTable.clear();\n+    }\n+    size_t size() const { return wdlTable.size(); }\n+    void insert(const std::vector<PieceType>& pieces);\n };\n \n HashTable EntryTable;\n@@ -407,77 +405,10 @@ class TBFile : public std::ifstream {\n \n std::string TBFile::Paths;\n \n-WDLEntry::WDLEntry(const std::string& code) {\n-\n-    StateInfo st;\n-    Position pos;\n-\n-    memset(this, 0, sizeof(WDLEntry));\n-\n-    ready = false;\n-    key = pos.set(code, WHITE, &st).material_key();\n-    pieceCount = popcount(pos.pieces());\n-    hasPawns = pos.pieces(PAWN);\n-\n-    for (Color c = WHITE; c <= BLACK; ++c)\n-        for (PieceType pt = PAWN; pt < KING; ++pt)\n-            if (popcount(pos.pieces(c, pt)) == 1)\n-                hasUniquePieces = true;\n-\n-    if (hasPawns) {\n-        // Set the leading color. In case both sides have pawns the leading color\n-        // is the side with less pawns because this leads to better compression.\n-        bool c =   !pos.count<PAWN>(BLACK)\n-                || (   pos.count<PAWN>(WHITE)\n-                    && pos.count<PAWN>(BLACK) >= pos.count<PAWN>(WHITE));\n-\n-        pawnTable.pawnCount[0] = pos.count<PAWN>(c ? WHITE : BLACK);\n-        pawnTable.pawnCount[1] = pos.count<PAWN>(c ? BLACK : WHITE);\n-    }\n-\n-    key2 = pos.set(code, BLACK, &st).material_key();\n-}\n-\n-WDLEntry::~WDLEntry() {\n-\n-    if (baseAddress)\n-        TBFile::unmap(baseAddress, mapping);\n-\n-    for (int i = 0; i < 2; ++i)\n-        if (hasPawns)\n-            for (File f = FILE_A; f <= FILE_D; ++f)\n-                delete pawnTable.file[i][f].precomp;\n-        else\n-            delete pieceTable[i].precomp;\n-}\n-\n-DTZEntry::DTZEntry(const WDLEntry& wdl) {\n-\n-    memset(this, 0, sizeof(DTZEntry));\n-\n-    ready = false;\n-    key = wdl.key;\n-    key2 = wdl.key2;\n-    pieceCount = wdl.pieceCount;\n-    hasPawns = wdl.hasPawns;\n-    hasUniquePieces = wdl.hasUniquePieces;\n-\n-    if (hasPawns) {\n-        pawnTable.pawnCount[0] = wdl.pawnTable.pawnCount[0];\n-        pawnTable.pawnCount[1] = wdl.pawnTable.pawnCount[1];\n-    }\n-}\n-\n-DTZEntry::~DTZEntry() {\n-\n+template<TBType Type>\n+TBEntry<Type>::~TBEntry() {\n     if (baseAddress)\n         TBFile::unmap(baseAddress, mapping);\n-\n-    if (hasPawns)\n-        for (File f = FILE_A; f <= FILE_D; ++f)\n-            delete pawnTable.file[f].precomp;\n-    else\n-        delete pieceTable.precomp;\n }\n \n void HashTable::insert(const std::vector<PieceType>& pieces) {\n@@ -630,13 +561,11 @@ int decompress_pairs(PairsData* d, uint64_t idx) {\n     return d->btree[sym].get<LR::Value>();\n }\n \n-bool check_dtz_stm(WDLEntry*, int, File) { return true; }\n-\n-bool check_dtz_stm(DTZEntry* entry, int stm, File f) {\n+bool check_dtz_stm(TBEntry<WDL>*, int, File) { return true; }\n \n-    int flags = entry->hasPawns ? entry->pawnTable.file[f].precomp->flags\n-                                : entry->pieceTable.precomp->flags;\n+bool check_dtz_stm(TBEntry<DTZ>* entry, int stm, File f) {\n \n+    int flags = entry->get(stm, f)->flags;\n     return   (flags & TBFlag::STM) == stm\n           || ((entry->key == entry->key2) && !entry->hasPawns);\n }\n@@ -645,20 +574,16 @@ bool check_dtz_stm(DTZEntry* entry, int stm, File f) {\n // values 0, 1, 2, ... in order of decreasing frequency. This is done for each\n // of the four WDLScore values. The mapping information necessary to reconstruct\n // the original values is stored in the TB file and read during map[] init.\n-WDLScore map_score(WDLEntry*, File, int value, WDLScore) { return WDLScore(value - 2); }\n+WDLScore map_score(TBEntry<WDL>*, File, int value, WDLScore) { return WDLScore(value - 2); }\n \n-int map_score(DTZEntry* entry, File f, int value, WDLScore wdl) {\n+int map_score(TBEntry<DTZ>* entry, File f, int value, WDLScore wdl) {\n \n     constexpr int WDLMap[] = { 1, 3, 0, 2, 0 };\n \n-    int flags = entry->hasPawns ? entry->pawnTable.file[f].precomp->flags\n-                                : entry->pieceTable.precomp->flags;\n-\n-    uint8_t* map = entry->hasPawns ? entry->pawnTable.map\n-                                   : entry->pieceTable.map;\n+    int flags = entry->get(0, f)->flags;\n \n-    uint16_t* idx = entry->hasPawns ? entry->pawnTable.file[f].map_idx\n-                                    : entry->pieceTable.map_idx;\n+    uint8_t* map = entry->map;\n+    uint16_t* idx = entry->get(0, f)->map_idx;\n     if (flags & TBFlag::Mapped)\n         value = map[idx[WDLMap[wdl + 2]] + value];\n \n@@ -679,10 +604,8 @@ int map_score(DTZEntry* entry, File f, int value, WDLScore wdl) {\n //\n //      idx = Binomial[1][s1] + Binomial[2][s2] + ... + Binomial[k][sk]\n //\n-template<typename Entry, typename T = typename Ret<Entry>::type>\n-T do_probe_table(const Position& pos, Entry* entry, WDLScore wdl, ProbeState* result) {\n-\n-    constexpr bool IsWDL = std::is_same<Entry, WDLEntry>::value;\n+template<TBType Type, typename T = typename TBEntry<Type>::Result>\n+T do_probe_table(const Position& pos, TBEntry<Type>* entry, WDLScore wdl, ProbeState* result) {\n \n     Square squares[TBPIECES];\n     Piece pieces[TBPIECES];\n@@ -715,7 +638,7 @@ T do_probe_table(const Position& pos, Entry* entry, WDLScore wdl, ProbeState* re\n \n         // In all the 4 tables, pawns are at the beginning of the piece sequence and\n         // their color is the reference one. So we just pick the first one.\n-        Piece pc = Piece(item(entry->pawnTable, 0, 0).precomp->pieces[0] ^ flipColor);\n+        Piece pc = Piece(entry->get(0, 0)->pieces[0] ^ flipColor);\n \n         assert(type_of(pc) == PAWN);\n \n@@ -731,15 +654,12 @@ T do_probe_table(const Position& pos, Entry* entry, WDLScore wdl, ProbeState* re\n         tbFile = file_of(squares[0]);\n         if (tbFile > FILE_D)\n             tbFile = file_of(squares[0] ^ 7); // Horizontal flip: SQ_H1 -> SQ_A1\n-\n-        d = item(entry->pawnTable , stm, tbFile).precomp;\n-    } else\n-        d = item(entry->pieceTable, stm, tbFile).precomp;\n+    }\n \n     // DTZ tables are one-sided, i.e. they store positions only for white to\n     // move or only for black to move, so check for side to move to be stm,\n     // early exit otherwise.\n-    if (!IsWDL && !check_dtz_stm(entry, stm, tbFile))\n+    if (Type == DTZ && !check_dtz_stm(entry, stm, tbFile))\n         return *result = CHANGE_STM, T();\n \n     // Now we are ready to get all the position pieces (but the lead pawns) and\n@@ -753,8 +673,10 @@ T do_probe_table(const Position& pos, Entry* entry, WDLScore wdl, ProbeState* re\n \n     assert(size >= 2);\n \n+    d = entry->get(stm, tbFile);\n+\n     // Then we reorder the pieces to have the same sequence as the one stored\n-    // in precomp->pieces[i]: the sequence that ensures the best compression.\n+    // in pieces[i]: the sequence that ensures the best compression.\n     for (int i = leadPawnsCnt; i < size; ++i)\n         for (int j = i; j < size; ++j)\n             if (d->pieces[i] == pieces[j])\n@@ -872,7 +794,7 @@ T do_probe_table(const Position& pos, Entry* entry, WDLScore wdl, ProbeState* re\n     Square* groupSq = squares + d->groupLen[0];\n \n     // Encode remainig pawns then pieces according to square, in ascending order\n-    bool remainingPawns = entry->hasPawns && entry->pawnTable.pawnCount[1];\n+    bool remainingPawns = entry->hasPawns && entry->pawnCount[1];\n \n     while (d->groupLen[++next])\n     {\n@@ -907,8 +829,8 @@ T do_probe_table(const Position& pos, Entry* entry, WDLScore wdl, ProbeState* re\n //\n // The actual grouping depends on the TB generator and can be inferred from the\n // sequence of pieces in piece[] array.\n-template<typename T>\n-void set_groups(T& e, PairsData* d, int order[], File f) {\n+template<TBType Type>\n+void set_groups(TBEntry<Type>& e, PairsData* d, int order[], File f) {\n \n     int n = 0, firstLen = e.hasPawns ? 0 : e.hasUniquePieces ? 3 : 2;\n     d->groupLen[n] = 1;\n@@ -934,7 +856,7 @@ void set_groups(T& e, PairsData* d, int order[], File f) {\n     // pawns/pieces -> remainig pawns -> remaining pieces. In particular the\n     // first group is at order[0] position and the remaining pawns, when present,\n     // are at order[1] position.\n-    bool pp = e.hasPawns && e.pawnTable.pawnCount[1]; // Pawns on both sides\n+    bool pp = e.hasPawns && e.pawnCount[1]; // Pawns on both sides\n     int next = pp ? 2 : 1;\n     int freeSquares = 64 - d->groupLen[0] - (pp ? d->groupLen[1] : 0);\n     uint64_t idx = 1;\n@@ -1048,18 +970,16 @@ uint8_t* set_sizes(PairsData* d, uint8_t* data) {\n     return data + d->symlen.size() * sizeof(LR) + (d->symlen.size() & 1);\n }\n \n-template<typename T>\n-uint8_t* set_dtz_map(WDLEntry&, T&, uint8_t*, File) { return nullptr; }\n+uint8_t* set_dtz_map(TBEntry<WDL>&, uint8_t*, File) { return nullptr; }\n \n-template<typename T>\n-uint8_t* set_dtz_map(DTZEntry&, T& p, uint8_t* data, File maxFile) {\n+uint8_t* set_dtz_map(TBEntry<DTZ>& e, uint8_t* data, File maxFile) {\n \n-    p.map = data;\n+    e.map = data;\n \n     for (File f = FILE_A; f <= maxFile; ++f) {\n-        if (item(p, 0, f).precomp->flags & TBFlag::Mapped)\n+        if (e.get(0, f)->flags & TBFlag::Mapped)\n             for (int i = 0; i < 4; ++i) { // Sequence like 3,x,x,x,1,x,0,2,x,x\n-                item(p, 0, f).map_idx[i] = (uint16_t)(data - p.map + 1);\n+                e.get(0, f)->map_idx[i] = (uint16_t)(data - e.map + 1);\n                 data += *data + 1;\n             }\n     }\n@@ -1067,10 +987,8 @@ uint8_t* set_dtz_map(DTZEntry&, T& p, uint8_t* data, File maxFile) {\n     return data += (uintptr_t)data & 1; // Word alignment\n }\n \n-template<typename Entry, typename T>\n-void do_init(Entry& e, T& p, uint8_t* data) {\n-\n-    const bool IsWDL = std::is_same<Entry, WDLEntry>::value;\n+template<TBType Type>\n+void do_init(TBEntry<Type>& e, uint8_t* data) {\n \n     PairsData* d;\n \n@@ -1081,17 +999,17 @@ void do_init(Entry& e, T& p, uint8_t* data) {\n \n     data++; // First byte stores flags\n \n-    const int sides = IsWDL && (e.key != e.key2) ? 2 : 1;\n+    const int sides = Type == WDL && (e.key != e.key2) ? 2 : 1;\n     const File maxFile = e.hasPawns ? FILE_D : FILE_A;\n \n-    bool pp = e.hasPawns && e.pawnTable.pawnCount[1]; // Pawns on both sides\n+    bool pp = e.hasPawns && e.pawnCount[1]; // Pawns on both sides\n \n-    assert(!pp || e.pawnTable.pawnCount[0]);\n+    assert(!pp || e.pawnCount[0]);\n \n     for (File f = FILE_A; f <= maxFile; ++f) {\n \n         for (int i = 0; i < sides; i++)\n-            item(p, i, f).precomp = new PairsData();\n+            *e.get(i, f) = PairsData();\n \n         int order[][2] = { { *data & 0xF, pp ? *(data + 1) & 0xF : 0xF },\n                            { *data >>  4, pp ? *(data + 1) >>  4 : 0xF } };\n@@ -1099,45 +1017,43 @@ void do_init(Entry& e, T& p, uint8_t* data) {\n \n         for (int k = 0; k < e.pieceCount; ++k, ++data)\n             for (int i = 0; i < sides; i++)\n-                item(p, i, f).precomp->pieces[k] = Piece(i ? *data >>  4 : *data & 0xF);\n+                e.get(i, f)->pieces[k] = Piece(i ? *data >>  4 : *data & 0xF);\n \n         for (int i = 0; i < sides; ++i)\n-            set_groups(e, item(p, i, f).precomp, order[i], f);\n+            set_groups(e, e.get(i, f), order[i], f);\n     }\n \n     data += (uintptr_t)data & 1; // Word alignment\n \n     for (File f = FILE_A; f <= maxFile; ++f)\n         for (int i = 0; i < sides; i++)\n-            data = set_sizes(item(p, i, f).precomp, data);\n+            data = set_sizes(e.get(i, f), data);\n \n-    if (!IsWDL)\n-        data = set_dtz_map(e, p, data, maxFile);\n+    if (Type == DTZ)\n+        data = set_dtz_map(e, data, maxFile);\n \n     for (File f = FILE_A; f <= maxFile; ++f)\n         for (int i = 0; i < sides; i++) {\n-            (d = item(p, i, f).precomp)->sparseIndex = (SparseEntry*)data;\n+            (d = e.get(i, f))->sparseIndex = (SparseEntry*)data;\n             data += d->sparseIndexSize * sizeof(SparseEntry);\n         }\n \n     for (File f = FILE_A; f <= maxFile; ++f)\n         for (int i = 0; i < sides; i++) {\n-            (d = item(p, i, f).precomp)->blockLength = (uint16_t*)data;\n+            (d = e.get(i, f))->blockLength = (uint16_t*)data;\n             data += d->blockLengthSize * sizeof(uint16_t);\n         }\n \n     for (File f = FILE_A; f <= maxFile; ++f)\n         for (int i = 0; i < sides; i++) {\n             data = (uint8_t*)(((uintptr_t)data + 0x3F) & ~0x3F); // 64 byte alignment\n-            (d = item(p, i, f).precomp)->data = data;\n+            (d = e.get(i, f))->data = data;\n             data += d->blocksNum * d->sizeofBlock;\n         }\n }\n \n-template<typename Entry>\n-void* init(Entry& e, const Position& pos) {\n-\n-    constexpr bool IsWDL = std::is_same<Entry, WDLEntry>::value;\n+template<TBType Type>\n+void* init(TBEntry<Type>& e, const Position& pos) {\n \n     static Mutex mutex;\n \n@@ -1162,23 +1078,24 @@ void* init(Entry& e, const Position& pos) {\n                                     { 0x71, 0xE8, 0x23, 0x5D } };\n \n     fname =  (e.key == pos.material_key() ? w + 'v' + b : b + 'v' + w)\n-           + (IsWDL ? \".rtbw\" : \".rtbz\");\n+           + (Type == WDL ? \".rtbw\" : \".rtbz\");\n \n-    uint8_t* data = TBFile(fname).map(&e.baseAddress, &e.mapping, TB_MAGIC[IsWDL]);\n+    uint8_t* data = TBFile(fname).map(&e.baseAddress, &e.mapping,\n+                                      TB_MAGIC[Type == WDL]);\n     if (data)\n-        e.hasPawns ? do_init(e, e.pawnTable, data) : do_init(e, e.pieceTable, data);\n+        do_init(e, data);\n \n     e.ready.store(true, std::memory_order_release);\n     return e.baseAddress;\n }\n \n-template<typename E, typename T = typename Ret<E>::type>\n+template<TBType Type, typename T = typename TBEntry<Type>::Result>\n T probe_table(const Position& pos, ProbeState* result, WDLScore wdl = WDLDraw) {\n \n     if (!(pos.pieces() ^ pos.pieces(KING)))\n         return T(WDLDraw); // KvK\n \n-    E* entry = EntryTable.get<E>(pos.material_key());\n+    TBEntry<Type>* entry = EntryTable.get<Type>(pos.material_key());\n \n     if (!entry || !init(*entry, pos))\n         return *result = FAIL, T();\n@@ -1247,7 +1164,7 @@ WDLScore search(Position& pos, ProbeState* result) {\n         value = bestValue;\n     else\n     {\n-        value = probe_table<WDLEntry>(pos, result);\n+        value = probe_table<WDL>(pos, result);\n \n         if (*result == FAIL)\n             return WDLDraw;\n@@ -1447,7 +1364,7 @@ int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n     if (*result == ZEROING_BEST_MOVE)\n         return dtz_before_zeroing(wdl);\n \n-    int dtz = probe_table<DTZEntry>(pos, result, wdl);\n+    int dtz = probe_table<DTZ>(pos, result, wdl);\n \n     if (*result == FAIL)\n         return 0;\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Segfault Issue**: Review the segfault in the syzygy implementation as reported in the linked forum thread. Investigate the uninitialized memory issue highlighted by valgrind.\n\n2. **Integration Testing**: Implement CI tests for tablebase integrity, including a script for \u201cexhaustive probe statistics\u201d to analyze all positions in syzygy files.\n\n3. **Benchmarking**: Conduct benchmarks comparing master and patch to identify regressions.\n\n4. **Code Cleanup**: Consider removing the `EntryPiece` structures for simplification as they appear largely equivalent.\n\n5. **Variable Initialization**: Ensure all variables are properly initialized to avoid issues witnessed in valgrind tests.\n\n6. **Collaborate on Solutions**: Reach out to @mcostalba and @syzygy1 for insights on validation and testing approaches."
      }
    ],
    "codediff_length": 22254
  },
  {
    "index": 99,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/Makefile b/src/Makefile\nindex 016aafec102..41c2aff6b64 100644\n--- a/src/Makefile\n+++ b/src/Makefile\n@@ -336,7 +336,7 @@ ifeq ($(pext),yes)\n \tendif\n endif\n \n-### 3.8 Link Time Optimization, it works since gcc 4.5 but not on mingw under Windows.\n+### 3.8 Link Time Optimization\n ### This is a mix of compile and link time options because the lto link phase\n ### needs access to the optimization flags.\n ifeq ($(optimize),yes)\ndiff --git a/src/bitbase.cpp b/src/bitbase.cpp\nindex be6f0d0afd3..7e27eb96a10 100644\n--- a/src/bitbase.cpp\n+++ b/src/bitbase.cpp\n@@ -108,25 +108,25 @@ namespace {\n     stm        = Color ((idx >> 12) & 0x01);\n     psq        = make_square(File((idx >> 13) & 0x3), Rank(RANK_7 - ((idx >> 15) & 0x7)));\n \n-    // Check if two pieces are on the same square or if a king can be captured\n+    // Invalid if two pieces are on the same square or if a king can be captured\n     if (   distance(ksq[WHITE], ksq[BLACK]) <= 1\n         || ksq[WHITE] == psq\n         || ksq[BLACK] == psq\n         || (stm == WHITE && (pawn_attacks_bb(WHITE, psq) & ksq[BLACK])))\n         result = INVALID;\n \n-    // Immediate win if a pawn can be promoted without getting captured\n+    // Win if the pawn can be promoted without getting captured\n     else if (   stm == WHITE\n              && rank_of(psq) == RANK_7\n-             && ksq[stm] != psq + NORTH\n-             && (    distance(ksq[~stm], psq + NORTH) > 1\n-                 || (attacks_bb<KING>(ksq[stm]) & (psq + NORTH))))\n+             && ksq[WHITE] != psq + NORTH\n+             && (    distance(ksq[BLACK], psq + NORTH) > 1\n+                 || (distance(ksq[WHITE], psq + NORTH) == 1)))\n         result = WIN;\n \n-    // Immediate draw if it is a stalemate or a king captures undefended pawn\n+    // Draw if it is stalemate or the black king can capture the pawn\n     else if (   stm == BLACK\n-             && (  !(attacks_bb<KING>(ksq[stm]) & ~(attacks_bb<KING>(ksq[~stm]) | pawn_attacks_bb(~stm, psq)))\n-                 || (attacks_bb<KING>(ksq[stm]) & psq & ~attacks_bb<KING>(ksq[~stm]))))\n+             && (  !(attacks_bb<KING>(ksq[BLACK]) & ~(attacks_bb<KING>(ksq[WHITE]) | pawn_attacks_bb(WHITE, psq)))\n+                 || (attacks_bb<KING>(ksq[BLACK]) & ~attacks_bb<KING>(ksq[WHITE]) & psq)))\n         result = DRAW;\n \n     // Position will be classified later\ndiff --git a/src/bitboard.cpp b/src/bitboard.cpp\nindex 3bb3ff8f8d5..0bf7eef91fd 100644\n--- a/src/bitboard.cpp\n+++ b/src/bitboard.cpp\n@@ -40,7 +40,7 @@ namespace {\n   Bitboard RookTable[0x19000];  // To store rook attacks\n   Bitboard BishopTable[0x1480]; // To store bishop attacks\n \n-  void init_magics(Bitboard table[], Magic magics[], Direction directions[]);\n+  void init_magics(PieceType pt, Bitboard table[], Magic magics[]);\n }\n \n \n@@ -79,11 +79,8 @@ void Bitboards::init() {\n       for (Square s2 = SQ_A1; s2 <= SQ_H8; ++s2)\n           SquareDistance[s1][s2] = std::max(distance<File>(s1, s2), distance<Rank>(s1, s2));\n \n-  Direction RookDirections[] = { NORTH, EAST, SOUTH, WEST };\n-  Direction BishopDirections[] = { NORTH_EAST, SOUTH_EAST, SOUTH_WEST, NORTH_WEST };\n-\n-  init_magics(RookTable, RookMagics, RookDirections);\n-  init_magics(BishopTable, BishopMagics, BishopDirections);\n+  init_magics(ROOK, RookTable, RookMagics);\n+  init_magics(BISHOP, BishopTable, BishopMagics);\n \n   for (Square s1 = SQ_A1; s1 <= SQ_H8; ++s1)\n   {\n@@ -109,15 +106,17 @@ void Bitboards::init() {\n \n namespace {\n \n-  Bitboard sliding_attack(Direction directions[], Square sq, Bitboard occupied) {\n+  Bitboard sliding_attack(PieceType pt, Square sq, Bitboard occupied) {\n \n     Bitboard attacks = 0;\n+    Direction   RookDirections[4] = {NORTH, SOUTH, EAST, WEST};\n+    Direction BishopDirections[4] = {NORTH_EAST, SOUTH_EAST, SOUTH_WEST, NORTH_WEST};\n \n-    for (int i = 0; i < 4; ++i)\n+    for(Direction d : (pt == ROOK ? RookDirections : BishopDirections))\n     {\n         Square s = sq;\n-        while(safe_destination(s, directions[i]) && !(occupied & s))\n-            attacks |= (s += directions[i]);\n+        while(safe_destination(s, d) && !(occupied & s))\n+            attacks |= (s += d);\n     }\n \n     return attacks;\n@@ -129,7 +128,7 @@ namespace {\n   // www.chessprogramming.org/Magic_Bitboards. In particular, here we use the so\n   // called \"fancy\" approach.\n \n-  void init_magics(Bitboard table[], Magic magics[], Direction directions[]) {\n+  void init_magics(PieceType pt, Bitboard table[], Magic magics[]) {\n \n     // Optimal PRNG seeds to pick the correct magics in the shortest time\n     int seeds[][RANK_NB] = { { 8977, 44560, 54343, 38998,  5731, 95205, 104912, 17020 },\n@@ -149,7 +148,7 @@ namespace {\n         // the number of 1s of the mask. Hence we deduce the size of the shift to\n         // apply to the 64 or 32 bits word to get the index.\n         Magic& m = magics[s];\n-        m.mask  = sliding_attack(directions, s, 0) & ~edges;\n+        m.mask  = sliding_attack(pt, s, 0) & ~edges;\n         m.shift = (Is64Bit ? 64 : 32) - popcount(m.mask);\n \n         // Set the offset for the attacks table of the square. We have individual\n@@ -161,7 +160,7 @@ namespace {\n         b = size = 0;\n         do {\n             occupancy[size] = b;\n-            reference[size] = sliding_attack(directions, s, b);\n+            reference[size] = sliding_attack(pt, s, b);\n \n             if (HasPext)\n                 m.attacks[pext(b, m.mask)] = reference[size];\ndiff --git a/src/bitboard.h b/src/bitboard.h\nindex 704f4bb4e8a..0f55810cece 100644\n--- a/src/bitboard.h\n+++ b/src/bitboard.h\n@@ -253,7 +253,7 @@ inline Bitboard pawn_attack_span(Color c, Square s) {\n /// the given color and on the given square is a passed pawn.\n \n inline Bitboard passed_pawn_span(Color c, Square s) {\n-  return forward_ranks_bb(c, s) & (adjacent_files_bb(s) | file_bb(s));\n+  return pawn_attack_span(c, s) | forward_file_bb(c, s);\n }\n \n \ndiff --git a/src/evaluate.cpp b/src/evaluate.cpp\nindex 036b93a933c..3b0891a2d4f 100644\n--- a/src/evaluate.cpp\n+++ b/src/evaluate.cpp\n@@ -676,16 +676,15 @@ namespace {\n   }\n \n \n-  // Evaluation::space() computes the space evaluation for a given side. The\n-  // space evaluation is a simple bonus based on the number of safe squares\n-  // available for minor pieces on the central four files on ranks 2--4. Safe\n-  // squares one, two or three squares behind a friendly pawn are counted\n-  // twice. Finally, the space bonus is multiplied by a weight. The aim is to\n-  // improve play on game opening.\n+  // Evaluation::space() computes a space evaluation for a given side, aiming to improve game\n+  // play in the opening. It is based on the number of safe squares on the 4 central files\n+  // on ranks 2 to 4. Completely safe squares behind a friendly pawn are counted twice.\n+  // Finally, the space bonus is multiplied by a weight which decreases according to occupancy.\n \n   template<Tracing T> template<Color Us>\n   Score Evaluation<T>::space() const {\n \n+    // Early exit if, for example, both queens or 6 minor pieces have been exchanged\n     if (pos.non_pawn_material() < SpaceThreshold)\n         return SCORE_ZERO;\n \ndiff --git a/src/movepick.cpp b/src/movepick.cpp\nindex 78102c52a34..5775f810600 100644\n--- a/src/movepick.cpp\n+++ b/src/movepick.cpp\n@@ -57,7 +57,7 @@ namespace {\n \n /// MovePicker constructor for the main search\n MovePicker::MovePicker(const Position& p, Move ttm, Depth d, const ButterflyHistory* mh, const LowPlyHistory* lp,\n-                       const CapturePieceToHistory* cph, const PieceToHistory** ch, Move cm, Move* killers, int pl)\n+                       const CapturePieceToHistory* cph, const PieceToHistory** ch, Move cm, const Move* killers, int pl)\n            : pos(p), mainHistory(mh), lowPlyHistory(lp), captureHistory(cph), continuationHistory(ch),\n              ttMove(ttm), refutations{{killers[0], 0}, {killers[1], 0}, {cm, 0}}, depth(d), ply(pl) {\n \ndiff --git a/src/movepick.h b/src/movepick.h\nindex 33c4b08602b..aaff388f641 100644\n--- a/src/movepick.h\n+++ b/src/movepick.h\n@@ -88,9 +88,9 @@ enum StatsType { NoCaptures, Captures };\n /// the move's from and to squares, see www.chessprogramming.org/Butterfly_Boards\n typedef Stats<int16_t, 10692, COLOR_NB, int(SQUARE_NB) * int(SQUARE_NB)> ButterflyHistory;\n \n-/// LowPlyHistory at higher depths records successful quiet moves on plies 0 to 3\n-/// and quiet moves which are/were in the PV (ttPv)\n-/// It get cleared with each new search and get filled during iterative deepening\n+/// At higher depths LowPlyHistory records successful quiet moves near the root and quiet\n+/// moves which are/were in the PV (ttPv)\n+/// It is cleared with each new search and filled during iterative deepening\n constexpr int MAX_LPH = 4;\n typedef Stats<int16_t, 10692, MAX_LPH, int(SQUARE_NB) * int(SQUARE_NB)> LowPlyHistory;\n \n@@ -133,7 +133,7 @@ class MovePicker {\n                                            const CapturePieceToHistory*,\n                                            const PieceToHistory**,\n                                            Move,\n-                                           Move*,\n+                                           const Move*,\n                                            int);\n   Move next_move(bool skipQuiets = false);\n \ndiff --git a/src/pawns.cpp b/src/pawns.cpp\nindex c1119a4102c..597dff2b0fb 100644\n--- a/src/pawns.cpp\n+++ b/src/pawns.cpp\n@@ -150,17 +150,17 @@ namespace {\n                 && !(theirPawns & adjacent_files_bb(s)))\n                 score -= Doubled;\n             else\n-                score -=   Isolated\n-                         + WeakUnopposed * !opposed;\n+                score -=  Isolated\n+                        + WeakUnopposed * !opposed;\n         }\n \n         else if (backward)\n-            score -=   Backward\n-                     + WeakUnopposed * !opposed;\n+            score -=  Backward\n+                    + WeakUnopposed * !opposed;\n \n         if (!support)\n-            score -=   Doubled * doubled\n-                     + WeakLever * more_than_one(lever);\n+            score -=  Doubled * doubled\n+                    + WeakLever * more_than_one(lever);\n     }\n \n     return score;\n@@ -196,7 +196,7 @@ Entry* probe(const Position& pos) {\n /// penalty for a king, looking at the king file and the two closest files.\n \n template<Color Us>\n-Score Entry::evaluate_shelter(const Position& pos, Square ksq) {\n+Score Entry::evaluate_shelter(const Position& pos, Square ksq) const {\n \n   constexpr Color Them = ~Us;\n \ndiff --git a/src/pawns.h b/src/pawns.h\nindex a3284a0fc64..e6098069025 100644\n--- a/src/pawns.h\n+++ b/src/pawns.h\n@@ -50,7 +50,7 @@ struct Entry {\n   Score do_king_safety(const Position& pos);\n \n   template<Color Us>\n-  Score evaluate_shelter(const Position& pos, Square ksq);\n+  Score evaluate_shelter(const Position& pos, Square ksq) const;\n \n   Key key;\n   Score scores[COLOR_NB];\ndiff --git a/src/psqt.cpp b/src/psqt.cpp\nindex abd23547af3..27c7a36f9f3 100644\n--- a/src/psqt.cpp\n+++ b/src/psqt.cpp\n@@ -106,7 +106,7 @@ Score psq[PIECE_NB][SQUARE_NB];\n // tables are initialized by flipping and changing the sign of the white scores.\n void init() {\n \n-  for (Piece pc = W_PAWN; pc <= W_KING; ++pc)\n+  for (Piece pc : {W_PAWN, W_KNIGHT, W_BISHOP, W_ROOK, W_QUEEN, W_KING})\n   {\n       Score score = make_score(PieceValue[MG][pc], PieceValue[EG][pc]);\n \ndiff --git a/src/search.cpp b/src/search.cpp\nindex d96ed7daac5..563d1aab410 100644\n--- a/src/search.cpp\n+++ b/src/search.cpp\n@@ -670,7 +670,7 @@ namespace {\n     ttPv = PvNode || (ttHit && tte->is_pv());\n     formerPv = ttPv && !PvNode;\n \n-    if (ttPv && depth > 12 && ss->ply - 1 < MAX_LPH && !pos.captured_piece() && is_ok((ss-1)->currentMove))\n+    if (ttPv && depth > 12 && ss->ply - 1 < MAX_LPH && !priorCapture && is_ok((ss-1)->currentMove))\n         thisThread->lowPlyHistory[ss->ply - 1][from_to((ss-1)->currentMove)] << stat_bonus(depth - 5);\n \n     // thisThread->ttHitAverage can be used to approximate the running average of ttHit\ndiff --git a/src/syzygy/tbprobe.cpp b/src/syzygy/tbprobe.cpp\nindex 6bfd78ad0df..95d58945d72 100644\n--- a/src/syzygy/tbprobe.cpp\n+++ b/src/syzygy/tbprobe.cpp\n@@ -1200,7 +1200,7 @@ WDLScore search(Position& pos, ProbeState* result) {\n     auto moveList = MoveList<LEGAL>(pos);\n     size_t totalCount = moveList.size(), moveCount = 0;\n \n-    for (const Move& move : moveList)\n+    for (const Move move : moveList)\n     {\n         if (   !pos.capture(move)\n             && (!CheckZeroingMoves || type_of(pos.moved_piece(move)) != PAWN))\n@@ -1362,7 +1362,7 @@ void Tablebases::init(const std::string& paths) {\n             LeadPawnsSize[leadPawnsCnt][f] = idx;\n         }\n \n-    // Add entries in TB tables if the corresponding \".rtbw\" file exsists\n+    // Add entries in TB tables if the corresponding \".rtbw\" file exists\n     for (PieceType p1 = PAWN; p1 < KING; ++p1) {\n         TBTables.add({KING, p1, KING});\n \n@@ -1469,7 +1469,7 @@ int Tablebases::probe_dtz(Position& pos, ProbeState* result) {\n     StateInfo st;\n     int minDTZ = 0xFFFF;\n \n-    for (const Move& move : MoveList<LEGAL>(pos))\n+    for (const Move move : MoveList<LEGAL>(pos))\n     {\n         bool zeroing = pos.capture(move) || type_of(pos.moved_piece(move)) == PAWN;\n \ndiff --git a/src/timeman.cpp b/src/timeman.cpp\nindex 1f598745ab0..d27962b7fc0 100644\n--- a/src/timeman.cpp\n+++ b/src/timeman.cpp\n@@ -79,7 +79,7 @@ void TimeManagement::init(Search::LimitsType& limits, Color us, int ply) {\n   {\n       opt_scale = std::min(0.008 + std::pow(ply + 3.0, 0.5) / 250.0,\n                            0.2 * limits.time[us] / double(timeLeft));\n-      max_scale = 4 + std::min(36, ply) / 12.0;\n+      max_scale = std::min(7.0, 4.0 + ply / 12.0);\n   }\n \n   // x moves in y seconds (+ z increment)\ndiff --git a/src/types.h b/src/types.h\nindex 580c846a10d..969d4e65e08 100644\n--- a/src/types.h\n+++ b/src/types.h\n@@ -40,7 +40,6 @@\n \n #include <cassert>\n #include <cctype>\n-#include <climits>\n #include <cstdint>\n #include <cstdlib>\n #include <algorithm>\n@@ -214,7 +213,6 @@ constexpr Value PieceValue[PHASE_NB][PIECE_NB] = {\n typedef int Depth;\n \n enum : int {\n-\n   DEPTH_QS_CHECKS     =  0,\n   DEPTH_QS_NO_CHECKS  = -1,\n   DEPTH_QS_RECAPTURES = -5,\n@@ -282,11 +280,11 @@ inline Value mg_value(Score s) {\n }\n \n #define ENABLE_BASE_OPERATORS_ON(T)                                \\\n-constexpr T operator+(T d1, T d2) { return T(int(d1) + int(d2)); } \\\n-constexpr T operator-(T d1, T d2) { return T(int(d1) - int(d2)); } \\\n+constexpr T operator+(T d1, int d2) { return T(int(d1) + d2); } \\\n+constexpr T operator-(T d1, int d2) { return T(int(d1) - d2); } \\\n constexpr T operator-(T d) { return T(-int(d)); }                  \\\n-inline T& operator+=(T& d1, T d2) { return d1 = d1 + d2; }         \\\n-inline T& operator-=(T& d1, T d2) { return d1 = d1 - d2; }\n+inline T& operator+=(T& d1, int d2) { return d1 = d1 + d2; }         \\\n+inline T& operator-=(T& d1, int d2) { return d1 = d1 - d2; }\n \n #define ENABLE_INCR_OPERATORS_ON(T)                                \\\n inline T& operator++(T& d) { return d = T(int(d) + 1); }           \\\n@@ -305,7 +303,6 @@ ENABLE_FULL_OPERATORS_ON(Value)\n ENABLE_FULL_OPERATORS_ON(Direction)\n \n ENABLE_INCR_OPERATORS_ON(PieceType)\n-ENABLE_INCR_OPERATORS_ON(Piece)\n ENABLE_INCR_OPERATORS_ON(Square)\n ENABLE_INCR_OPERATORS_ON(File)\n ENABLE_INCR_OPERATORS_ON(Rank)\n@@ -316,12 +313,6 @@ ENABLE_BASE_OPERATORS_ON(Score)\n #undef ENABLE_INCR_OPERATORS_ON\n #undef ENABLE_BASE_OPERATORS_ON\n \n-/// Additional operators to add integers to a Value\n-constexpr Value operator+(Value v, int i) { return Value(int(v) + i); }\n-constexpr Value operator-(Value v, int i) { return Value(int(v) - i); }\n-inline Value& operator+=(Value& v, int i) { return v = v + i; }\n-inline Value& operator-=(Value& v, int i) { return v = v - i; }\n-\n /// Additional operators to add a Direction to a Square\n constexpr Square operator+(Square s, Direction d) { return Square(int(s) + int(d)); }\n constexpr Square operator-(Square s, Direction d) { return Square(int(s) - int(d)); }\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **movegen.cpp (Lines 194-195)**: Simplify condition to `if (!(PseudoAttacks[Pt][from] & target & pos.check_squares(Pt)))`. Verify performance impacts when removing `Pt` tests, as they may affect compilation.\n\n2. **pawns.cpp (Lines 150-153)**: Replace `&& popcount(opposed) == 1` with `&& opposed` to streamline logic and remove unnecessary checks.\n\n3. **position.h (Line 252)**: Change assertion from `assert(pieceCount[make_piece(c, Pt)] == 1);` to `assert(count<Pt>(c) == 1);` for simplicity.\n\n4. **timeman.cpp (Line 82)**: Update code for clarity to `max_scale = std::min(7.0, 4.0 + ply / 12.0);`.\n\n5. **movepick.h Comment**: Revise for clarity; suggest updated wording focused on recording successful moves during iterative deepening."
      }
    ],
    "codediff_length": 15972
  },
  {
    "index": 100,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/core/include/webview/detail/backends/cocoa_webkit.hh b/core/include/webview/detail/backends/cocoa_webkit.hh\nold mode 100644\nnew mode 100755\nindex 2840afa7c..ae7fd3cd9\n--- a/core/include/webview/detail/backends/cocoa_webkit.hh\n+++ b/core/include/webview/detail/backends/cocoa_webkit.hh\n@@ -85,40 +85,10 @@ private:\n \n class cocoa_wkwebview_engine : public engine_base {\n public:\n-  cocoa_wkwebview_engine(bool debug, void *window)\n-      : m_debug{debug},\n-        m_window{static_cast<id>(window)},\n-        m_owns_window{!window} {\n-    auto app = get_shared_application();\n-    // See comments related to application lifecycle in create_app_delegate().\n-    if (!m_owns_window) {\n-      set_up_window();\n-    } else {\n-      // Only set the app delegate if it hasn't already been set.\n-      auto delegate = objc::msg_send<id>(app, \"delegate\"_sel);\n-      if (delegate) {\n-        set_up_window();\n-      } else {\n-        m_app_delegate = create_app_delegate();\n-        objc_setAssociatedObject(m_app_delegate, \"webview\", (id)this,\n-                                 OBJC_ASSOCIATION_ASSIGN);\n-        objc::msg_send<void>(app, \"setDelegate:\"_sel, m_app_delegate);\n-\n-        // Start the main run loop so that the app delegate gets the\n-        // NSApplicationDidFinishLaunchingNotification notification after the run\n-        // loop has started in order to perform further initialization.\n-        // We need to return from this constructor so this run loop is only\n-        // temporary.\n-        // Skip the main loop if this isn't the first instance of this class\n-        // because the launch event is only sent once. Instead, proceed to\n-        // create a window.\n-        if (get_and_set_is_first_instance()) {\n-          objc::msg_send<void>(app, \"run\"_sel);\n-        } else {\n-          set_up_window();\n-        }\n-      }\n-    }\n+  cocoa_wkwebview_engine(bool debug, void *window) : m_owns_window{!window} {\n+    window_init(window);\n+    window_settings(debug);\n+    dispatch_size_default(m_owns_window);\n   }\n \n   cocoa_wkwebview_engine(const cocoa_wkwebview_engine &) = delete;\n@@ -252,7 +222,7 @@ protected:\n     }\n     objc::msg_send<void>(m_window, \"center\"_sel);\n \n-    return {};\n+    return window_show();\n   }\n   noresult navigate_impl(const std::string &url) override {\n     objc::autoreleasepool arp;\n@@ -491,7 +461,7 @@ private:\n       objc::msg_send<void>(app, \"activateIgnoringOtherApps:\"_sel, YES);\n     }\n \n-    set_up_window();\n+    window_init();\n   }\n   void on_window_will_close(id /*delegate*/, id /*window*/) {\n     // Widget destroyed along with window.\n@@ -500,35 +470,7 @@ private:\n     m_window = nullptr;\n     dispatch([this] { on_window_destroyed(); });\n   }\n-  void set_up_window() {\n-    objc::autoreleasepool arp;\n-\n-    // Main window\n-    if (m_owns_window) {\n-      m_window = objc::msg_send<id>(\"NSWindow\"_cls, \"alloc\"_sel);\n-      auto style = NSWindowStyleMaskTitled;\n-      m_window = objc::msg_send<id>(\n-          m_window, \"initWithContentRect:styleMask:backing:defer:\"_sel,\n-          CGRectMake(0, 0, 0, 0), style, NSBackingStoreBuffered, NO);\n-\n-      m_window_delegate = create_window_delegate();\n-      objc_setAssociatedObject(m_window_delegate, \"webview\", (id)this,\n-                               OBJC_ASSOCIATION_ASSIGN);\n-      objc::msg_send<void>(m_window, \"setDelegate:\"_sel, m_window_delegate);\n-\n-      on_window_created();\n-    }\n-\n-    set_up_web_view();\n-    set_up_widget();\n-\n-    objc::msg_send<void>(m_window, \"setContentView:\"_sel, m_widget);\n-\n-    if (m_owns_window) {\n-      objc::msg_send<void>(m_window, \"makeKeyAndOrderFront:\"_sel, nullptr);\n-    }\n-  }\n-  void set_up_web_view() {\n+  void window_settings(bool debug) {\n     objc::autoreleasepool arp;\n \n     auto config = objc::autoreleased(\n@@ -541,7 +483,7 @@ private:\n     auto yes_value =\n         objc::msg_send<id>(\"NSNumber\"_cls, \"numberWithBool:\"_sel, YES);\n \n-    if (m_debug) {\n+    if (debug) {\n       // Equivalent Obj-C:\n       // [[config preferences] setValue:@YES forKey:@\"developerExtrasEnabled\"];\n       objc::msg_send<id>(preferences, \"setValue:forKey:\"_sel, yes_value,\n@@ -586,7 +528,7 @@ private:\n                              OBJC_ASSOCIATION_ASSIGN);\n     objc::msg_send<void>(m_webview, \"setUIDelegate:\"_sel, ui_delegate);\n \n-    if (m_debug) {\n+    if (debug) {\n       // Explicitly make WKWebView inspectable via Safari on OS versions that\n       // disable the feature by default (macOS 13.3 and later) and support\n       // enabling it. According to Apple, the behavior on older OS versions is\n@@ -616,6 +558,11 @@ private:\n     add_init_script(\"function(message) {\\n\\\n   return window.webkit.messageHandlers.__webview__.postMessage(message);\\n\\\n }\");\n+    set_up_widget();\n+    objc::msg_send<void>(m_window, \"setContentView:\"_sel, m_widget);\n+    if (m_owns_window) {\n+      objc::msg_send<void>(m_window, \"makeKeyAndOrderFront:\"_sel, nullptr);\n+    }\n   }\n   void set_up_widget() {\n     objc::autoreleasepool arp;\n@@ -652,6 +599,60 @@ private:\n     }\n     return temp;\n   }\n+  void window_init(void *window = nullptr) {\n+    if (!m_window) {\n+      m_window = static_cast<id>(window);\n+    }\n+    if (!m_owns_window) {\n+      return;\n+    }\n+    objc::autoreleasepool arp;\n+    auto app = get_shared_application();\n+    auto window_init_proceed = [this]() {\n+      m_window = objc::msg_send<id>(\"NSWindow\"_cls, \"alloc\"_sel);\n+      auto style = NSWindowStyleMaskTitled;\n+      m_window = objc::msg_send<id>(\n+          m_window, \"initWithContentRect:styleMask:backing:defer:\"_sel,\n+          CGRectMake(0, 0, 0, 0), style, NSBackingStoreBuffered, NO);\n+      m_window_delegate = create_window_delegate();\n+      objc_setAssociatedObject(m_window_delegate, \"webview\", (id)this,\n+                               OBJC_ASSOCIATION_ASSIGN);\n+      objc::msg_send<void>(m_window, \"setDelegate:\"_sel, m_window_delegate);\n+      on_window_created();\n+    };\n+\n+    auto delegate = objc::msg_send<id>(app, \"delegate\"_sel);\n+    // Only set the app delegate if it hasn't already been set.\n+    if (delegate) {\n+      return window_init_proceed();\n+    }\n+    // See comments related to application lifecycle in create_app_delegate().\n+    m_app_delegate = create_app_delegate();\n+    objc_setAssociatedObject(m_app_delegate, \"webview\", (id)this,\n+                             OBJC_ASSOCIATION_ASSIGN);\n+    objc::msg_send<void>(app, \"setDelegate:\"_sel, m_app_delegate);\n+    if (!get_and_set_is_first_instance()) {\n+      return window_init_proceed();\n+    }\n+\n+    // Start the main run loop so that the app delegate gets the\n+    // NSApplicationDidFinishLaunchingNotification notification after the run\n+    // loop has started in order to perform further initialization.\n+    // We need to return from this constructor so this run loop is only\n+    // temporary.\n+    // Skip the main loop if this isn't the first instance of this class\n+    // because the launch event is only sent once. Instead, proceed to\n+    // create a window.\n+    objc::msg_send<void>(app, \"run\"_sel);\n+  }\n+  noresult window_show() {\n+    objc::autoreleasepool arp;\n+    if (m_is_window_shown) {\n+      return {};\n+    }\n+    m_is_window_shown = true;\n+    return {};\n+  }\n \n   // Blocks while depleting the run loop of events.\n   void deplete_run_loop_event_queue() {\n@@ -674,7 +675,6 @@ private:\n     }\n   }\n \n-  bool m_debug{};\n   id m_app_delegate{};\n   id m_window_delegate{};\n   id m_window{};\n@@ -682,6 +682,7 @@ private:\n   id m_webview{};\n   id m_manager{};\n   bool m_owns_window{};\n+  bool m_is_window_shown{};\n };\n \n } // namespace detail\ndiff --git a/core/include/webview/detail/backends/gtk_webkitgtk.hh b/core/include/webview/detail/backends/gtk_webkitgtk.hh\nindex 834dfbb58..c1f4aad43 100644\n--- a/core/include/webview/detail/backends/gtk_webkitgtk.hh\n+++ b/core/include/webview/detail/backends/gtk_webkitgtk.hh\n@@ -99,55 +99,10 @@ private:\n \n class gtk_webkit_engine : public engine_base {\n public:\n-  gtk_webkit_engine(bool debug, void *window)\n-      : m_owns_window{!window}, m_window(static_cast<GtkWidget *>(window)) {\n-    if (m_owns_window) {\n-      if (!gtk_compat::init_check()) {\n-        throw exception{WEBVIEW_ERROR_UNSPECIFIED, \"GTK init failed\"};\n-      }\n-      m_window = gtk_compat::window_new();\n-      on_window_created();\n-      auto on_window_destroy = +[](GtkWidget *, gpointer arg) {\n-        auto *w = static_cast<gtk_webkit_engine *>(arg);\n-        w->m_window = nullptr;\n-        w->on_window_destroyed();\n-      };\n-      g_signal_connect(G_OBJECT(m_window), \"destroy\",\n-                       G_CALLBACK(on_window_destroy), this);\n-    }\n-    webkit_dmabuf::apply_webkit_dmabuf_workaround();\n-    // Initialize webview widget\n-    m_webview = webkit_web_view_new();\n-    g_object_ref_sink(m_webview);\n-    WebKitUserContentManager *manager = m_user_content_manager =\n-        webkit_web_view_get_user_content_manager(WEBKIT_WEB_VIEW(m_webview));\n-    webkitgtk_compat::connect_script_message_received(\n-        manager, \"__webview__\",\n-        [this](WebKitUserContentManager *, const std::string &r) {\n-          on_message(r);\n-        });\n-    webkitgtk_compat::user_content_manager_register_script_message_handler(\n-        manager, \"__webview__\");\n-    add_init_script(\"function(message) {\\n\\\n-  return window.webkit.messageHandlers.__webview__.postMessage(message);\\n\\\n-}\");\n-\n-    gtk_compat::window_set_child(GTK_WINDOW(m_window), GTK_WIDGET(m_webview));\n-    gtk_compat::widget_set_visible(GTK_WIDGET(m_webview), true);\n-\n-    WebKitSettings *settings =\n-        webkit_web_view_get_settings(WEBKIT_WEB_VIEW(m_webview));\n-    webkit_settings_set_javascript_can_access_clipboard(settings, true);\n-    if (debug) {\n-      webkit_settings_set_enable_write_console_messages_to_stdout(settings,\n-                                                                  true);\n-      webkit_settings_set_enable_developer_extras(settings, true);\n-    }\n-\n-    if (m_owns_window) {\n-      gtk_widget_grab_focus(GTK_WIDGET(m_webview));\n-      gtk_compat::widget_set_visible(GTK_WIDGET(m_window), true);\n-    }\n+  gtk_webkit_engine(bool debug, void *window) : m_owns_window{!window} {\n+    window_init(window);\n+    window_settings(debug);\n+    dispatch_size_default(m_owns_window);\n   }\n \n   gtk_webkit_engine(const gtk_webkit_engine &) = delete;\n@@ -236,7 +191,7 @@ protected:\n     } else {\n       return error_info{WEBVIEW_ERROR_INVALID_ARGUMENT, \"Invalid hint\"};\n     }\n-    return {};\n+    return window_show();\n   }\n \n   noresult navigate_impl(const std::string &url) override {\n@@ -316,6 +271,66 @@ private:\n   }\n #endif\n \n+  void window_init(void *window) {\n+    m_window = static_cast<GtkWidget *>(window);\n+    if (m_owns_window) {\n+      if (!gtk_compat::init_check()) {\n+        throw exception{WEBVIEW_ERROR_UNSPECIFIED, \"GTK init failed\"};\n+      }\n+      m_window = gtk_compat::window_new();\n+      on_window_created();\n+      auto on_window_destroy = +[](GtkWidget *, gpointer arg) {\n+        auto *w = static_cast<gtk_webkit_engine *>(arg);\n+        w->m_window = nullptr;\n+        w->on_window_destroyed();\n+      };\n+      g_signal_connect(G_OBJECT(m_window), \"destroy\",\n+                       G_CALLBACK(on_window_destroy), this);\n+    }\n+    webkit_dmabuf::apply_webkit_dmabuf_workaround();\n+    // Initialize webview widget\n+    m_webview = webkit_web_view_new();\n+    g_object_ref_sink(m_webview);\n+    WebKitUserContentManager *manager = m_user_content_manager =\n+        webkit_web_view_get_user_content_manager(WEBKIT_WEB_VIEW(m_webview));\n+    webkitgtk_compat::connect_script_message_received(\n+        manager, \"__webview__\",\n+        [this](WebKitUserContentManager *, const std::string &r) {\n+          on_message(r);\n+        });\n+    webkitgtk_compat::user_content_manager_register_script_message_handler(\n+        manager, \"__webview__\");\n+    add_init_script(\"function(message) {\\n\\\n+  return window.webkit.messageHandlers.__webview__.postMessage(message);\\n\\\n+}\");\n+  }\n+\n+  void window_settings(bool debug) {\n+    WebKitSettings *settings =\n+        webkit_web_view_get_settings(WEBKIT_WEB_VIEW(m_webview));\n+    webkit_settings_set_javascript_can_access_clipboard(settings, true);\n+    if (debug) {\n+      webkit_settings_set_enable_write_console_messages_to_stdout(settings,\n+                                                                  true);\n+      webkit_settings_set_enable_developer_extras(settings, true);\n+    }\n+  }\n+\n+  noresult window_show() {\n+    if (m_is_window_shown) {\n+      return {};\n+    }\n+    gtk_compat::window_set_child(GTK_WINDOW(m_window), GTK_WIDGET(m_webview));\n+    gtk_compat::widget_set_visible(GTK_WIDGET(m_webview), true);\n+\n+    if (m_owns_window) {\n+      gtk_widget_grab_focus(GTK_WIDGET(m_webview));\n+      gtk_compat::widget_set_visible(GTK_WIDGET(m_window), true);\n+    }\n+    m_is_window_shown = true;\n+    return {};\n+  }\n+\n   // Blocks while depleting the run loop of events.\n   void deplete_run_loop_event_queue() {\n     bool done{};\n@@ -330,6 +345,7 @@ private:\n   GtkWidget *m_webview{};\n   WebKitUserContentManager *m_user_content_manager{};\n   bool m_stop_run_loop{};\n+  bool m_is_window_shown{};\n };\n \n } // namespace detail\ndiff --git a/core/include/webview/detail/backends/win32_edge.hh b/core/include/webview/detail/backends/win32_edge.hh\nindex cf5ef82fa..0bb9cef54 100644\n--- a/core/include/webview/detail/backends/win32_edge.hh\n+++ b/core/include/webview/detail/backends/win32_edge.hh\n@@ -309,6 +309,210 @@ private:\n class win32_edge_engine : public engine_base {\n public:\n   win32_edge_engine(bool debug, void *window) : m_owns_window{!window} {\n+    window_init(window);\n+    window_settings(debug);\n+    dispatch_size_default(m_owns_window);\n+  }\n+\n+  virtual ~win32_edge_engine() {\n+    if (m_com_handler) {\n+      m_com_handler->Release();\n+      m_com_handler = nullptr;\n+    }\n+    if (m_webview) {\n+      m_webview->Release();\n+      m_webview = nullptr;\n+    }\n+    if (m_controller) {\n+      m_controller->Release();\n+      m_controller = nullptr;\n+    }\n+    // Replace wndproc to avoid callbacks and other bad things during\n+    // destruction.\n+    auto wndproc = reinterpret_cast<LONG_PTR>(\n+        +[](HWND hwnd, UINT msg, WPARAM wp, LPARAM lp) -> LRESULT {\n+          return DefWindowProcW(hwnd, msg, wp, lp);\n+        });\n+    if (m_widget) {\n+      SetWindowLongPtrW(m_widget, GWLP_WNDPROC, wndproc);\n+    }\n+    if (m_window && m_owns_window) {\n+      SetWindowLongPtrW(m_window, GWLP_WNDPROC, wndproc);\n+    }\n+    if (m_widget) {\n+      DestroyWindow(m_widget);\n+      m_widget = nullptr;\n+    }\n+    if (m_window) {\n+      if (m_owns_window) {\n+        DestroyWindow(m_window);\n+        on_window_destroyed(true);\n+      }\n+      m_window = nullptr;\n+    }\n+    if (m_owns_window) {\n+      bool done{};\n+      // Not strictly needed for windows to close immediately but aligns\n+      // behavior across backends.\n+      deplete_run_loop_event_queue(done, [&] { done = true; });\n+    }\n+    // We need the message window in order to deplete the event queue.\n+    if (m_message_window) {\n+      SetWindowLongPtrW(m_message_window, GWLP_WNDPROC, wndproc);\n+      DestroyWindow(m_message_window);\n+      m_message_window = nullptr;\n+    }\n+  }\n+\n+  win32_edge_engine(const win32_edge_engine &other) = delete;\n+  win32_edge_engine &operator=(const win32_edge_engine &other) = delete;\n+  win32_edge_engine(win32_edge_engine &&other) = delete;\n+  win32_edge_engine &operator=(win32_edge_engine &&other) = delete;\n+\n+protected:\n+  noresult run_impl() override {\n+    MSG msg;\n+    while (GetMessageW(&msg, nullptr, 0, 0) > 0) {\n+      TranslateMessage(&msg);\n+      DispatchMessageW(&msg);\n+    }\n+    return {};\n+  }\n+  result<void *> window_impl() override {\n+    if (m_window) {\n+      return m_window;\n+    }\n+    return error_info{WEBVIEW_ERROR_INVALID_STATE};\n+  }\n+  result<void *> widget_impl() override {\n+    if (m_widget) {\n+      return m_widget;\n+    }\n+    return error_info{WEBVIEW_ERROR_INVALID_STATE};\n+  }\n+  result<void *> browser_controller_impl() override {\n+    if (m_controller) {\n+      return m_controller;\n+    }\n+    return error_info{WEBVIEW_ERROR_INVALID_STATE};\n+  }\n+  noresult terminate_impl() override {\n+    PostQuitMessage(0);\n+    return {};\n+  }\n+  noresult dispatch_impl(dispatch_fn_t f) override {\n+    PostMessageW(m_message_window, WM_APP, 0, (LPARAM) new dispatch_fn_t(f));\n+    return {};\n+  }\n+\n+  noresult set_title_impl(const std::string &title) override {\n+    SetWindowTextW(m_window, widen_string(title).c_str());\n+    return {};\n+  }\n+\n+  noresult set_size_impl(int width, int height, webview_hint_t hints) override {\n+    auto style = GetWindowLong(m_window, GWL_STYLE);\n+    if (hints == WEBVIEW_HINT_FIXED) {\n+      style &= ~(WS_THICKFRAME | WS_MAXIMIZEBOX);\n+    } else {\n+      style |= (WS_THICKFRAME | WS_MAXIMIZEBOX);\n+    }\n+    SetWindowLong(m_window, GWL_STYLE, style);\n+\n+    if (hints == WEBVIEW_HINT_MAX) {\n+      m_maxsz.x = width;\n+      m_maxsz.y = height;\n+    } else if (hints == WEBVIEW_HINT_MIN) {\n+      m_minsz.x = width;\n+      m_minsz.y = height;\n+    } else {\n+      auto dpi = get_window_dpi(m_window);\n+      m_dpi = dpi;\n+      auto scaled_size =\n+          scale_size(width, height, get_default_window_dpi(), dpi);\n+      auto frame_size =\n+          make_window_frame_size(m_window, scaled_size.cx, scaled_size.cy, dpi);\n+      SetWindowPos(m_window, nullptr, 0, 0, frame_size.cx, frame_size.cy,\n+                   SWP_NOZORDER | SWP_NOACTIVATE | SWP_NOMOVE |\n+                       SWP_FRAMECHANGED);\n+    }\n+    return window_show();\n+  }\n+\n+  noresult navigate_impl(const std::string &url) override {\n+    auto wurl = widen_string(url);\n+    m_webview->Navigate(wurl.c_str());\n+    return {};\n+  }\n+\n+  noresult eval_impl(const std::string &js) override {\n+    // TODO: Skip if no content has begun loading yet. Can't check with\n+    //       ICoreWebView2::get_Source because it returns \"about:blank\".\n+    auto wjs = widen_string(js);\n+    m_webview->ExecuteScript(wjs.c_str(), nullptr);\n+    return {};\n+  }\n+\n+  noresult set_html_impl(const std::string &html) override {\n+    m_webview->NavigateToString(widen_string(html).c_str());\n+    return {};\n+  }\n+\n+  user_script add_user_script_impl(const std::string &js) override {\n+    auto wjs = widen_string(js);\n+    std::wstring script_id;\n+    bool done{};\n+    webview2_user_script_added_handler script_handler{\n+        [&](HRESULT res, LPCWSTR id) {\n+          if (SUCCEEDED(res)) {\n+            script_id = id;\n+          }\n+          done = true;\n+        }};\n+    auto wv2_script = [&]() {\n+      auto res = m_webview->AddScriptToExecuteOnDocumentCreated(\n+          wjs.c_str(), &script_handler);\n+      if (!SUCCEEDED(res)) {\n+        // There's a non-zero chance that we didn't get the script ID.\n+        // We convey the error and fail fast by throwing.\n+        throw exception(WEBVIEW_ERROR_UNSPECIFIED, \"Failed to bind script.\");\n+      };\n+    };\n+\n+    // Sadly we need to pump the even loop in order to get the script ID, however\n+    // we firstly guard against premature execution of the default window size\n+    default_size_guard(true);\n+    deplete_run_loop_event_queue(done, wv2_script);\n+\n+    // We conditionally reset the default size guard and\n+    // add put the sizing event back onto to the queue\n+    if (!m_is_window_shown) {\n+      default_size_guard(false);\n+      dispatch_size_default(m_owns_window);\n+    }\n+\n+    return user_script{\n+        js, user_script::impl_ptr{new user_script::impl{script_id, wjs},\n+                                  [](user_script::impl *p) { delete p; }}};\n+  }\n+\n+  void\n+  remove_all_user_scripts_impl(const std::list<user_script> &scripts) override {\n+    for (const auto &script : scripts) {\n+      const auto &id = script.get_impl().get_id();\n+      m_webview->RemoveScriptToExecuteOnDocumentCreated(id.c_str());\n+    }\n+  }\n+\n+  bool are_user_scripts_equal_impl(const user_script &first,\n+                                   const user_script &second) override {\n+    const auto &first_id = first.get_impl().get_id();\n+    const auto &second_id = second.get_impl().get_id();\n+    return first_id == second_id;\n+  }\n+\n+private:\n+  void window_init(void *window) {\n     if (!is_webview2_available()) {\n       throw exception{WEBVIEW_ERROR_MISSING_DEPENDENCY,\n                       \"WebView2 is unavailable\"};\n@@ -414,16 +618,12 @@ public:\n       on_window_created();\n \n       m_dpi = get_window_dpi(m_window);\n-      constexpr const int initial_width = 640;\n-      constexpr const int initial_height = 480;\n-      set_size(initial_width, initial_height, WEBVIEW_HINT_NONE);\n     } else {\n       m_window = IsWindow(static_cast<HWND>(window))\n                      ? static_cast<HWND>(window)\n                      : *(static_cast<HWND *>(window));\n       m_dpi = get_window_dpi(m_window);\n     }\n-\n     // Create a window that WebView2 will be embedded into.\n     WNDCLASSEXW widget_wc{};\n     widget_wc.cbSize = sizeof(WNDCLASSEX);\n@@ -512,203 +712,23 @@ public:\n     if (!m_message_window) {\n       throw exception{WEBVIEW_ERROR_INVALID_STATE, \"Message window is null\"};\n     }\n+  }\n \n-    if (m_owns_window) {\n-      ShowWindow(m_window, SW_SHOW);\n-      UpdateWindow(m_window);\n-      SetFocus(m_window);\n-    }\n-\n+  void window_settings(bool debug) {\n     auto cb =\n         std::bind(&win32_edge_engine::on_message, this, std::placeholders::_1);\n-\n     embed(m_widget, debug, cb).ensure_ok();\n   }\n \n-  virtual ~win32_edge_engine() {\n-    if (m_com_handler) {\n-      m_com_handler->Release();\n-      m_com_handler = nullptr;\n-    }\n-    if (m_webview) {\n-      m_webview->Release();\n-      m_webview = nullptr;\n-    }\n-    if (m_controller) {\n-      m_controller->Release();\n-      m_controller = nullptr;\n-    }\n-    // Replace wndproc to avoid callbacks and other bad things during\n-    // destruction.\n-    auto wndproc = reinterpret_cast<LONG_PTR>(\n-        +[](HWND hwnd, UINT msg, WPARAM wp, LPARAM lp) -> LRESULT {\n-          return DefWindowProcW(hwnd, msg, wp, lp);\n-        });\n-    if (m_widget) {\n-      SetWindowLongPtrW(m_widget, GWLP_WNDPROC, wndproc);\n-    }\n-    if (m_window && m_owns_window) {\n-      SetWindowLongPtrW(m_window, GWLP_WNDPROC, wndproc);\n-    }\n-    if (m_widget) {\n-      DestroyWindow(m_widget);\n-      m_widget = nullptr;\n-    }\n-    if (m_window) {\n-      if (m_owns_window) {\n-        DestroyWindow(m_window);\n-        on_window_destroyed(true);\n-      }\n-      m_window = nullptr;\n-    }\n-    if (m_owns_window) {\n-      // Not strictly needed for windows to close immediately but aligns\n-      // behavior across backends.\n-      deplete_run_loop_event_queue();\n-    }\n-    // We need the message window in order to deplete the event queue.\n-    if (m_message_window) {\n-      SetWindowLongPtrW(m_message_window, GWLP_WNDPROC, wndproc);\n-      DestroyWindow(m_message_window);\n-      m_message_window = nullptr;\n-    }\n-  }\n-\n-  win32_edge_engine(const win32_edge_engine &other) = delete;\n-  win32_edge_engine &operator=(const win32_edge_engine &other) = delete;\n-  win32_edge_engine(win32_edge_engine &&other) = delete;\n-  win32_edge_engine &operator=(win32_edge_engine &&other) = delete;\n-\n-protected:\n-  noresult run_impl() override {\n-    MSG msg;\n-    while (GetMessageW(&msg, nullptr, 0, 0) > 0) {\n-      TranslateMessage(&msg);\n-      DispatchMessageW(&msg);\n-    }\n-    return {};\n-  }\n-  result<void *> window_impl() override {\n-    if (m_window) {\n-      return m_window;\n-    }\n-    return error_info{WEBVIEW_ERROR_INVALID_STATE};\n-  }\n-  result<void *> widget_impl() override {\n-    if (m_widget) {\n-      return m_widget;\n-    }\n-    return error_info{WEBVIEW_ERROR_INVALID_STATE};\n-  }\n-  result<void *> browser_controller_impl() override {\n-    if (m_controller) {\n-      return m_controller;\n-    }\n-    return error_info{WEBVIEW_ERROR_INVALID_STATE};\n-  }\n-  noresult terminate_impl() override {\n-    PostQuitMessage(0);\n-    return {};\n-  }\n-  noresult dispatch_impl(dispatch_fn_t f) override {\n-    PostMessageW(m_message_window, WM_APP, 0, (LPARAM) new dispatch_fn_t(f));\n-    return {};\n-  }\n-\n-  noresult set_title_impl(const std::string &title) override {\n-    SetWindowTextW(m_window, widen_string(title).c_str());\n-    return {};\n-  }\n-\n-  noresult set_size_impl(int width, int height, webview_hint_t hints) override {\n-    auto style = GetWindowLong(m_window, GWL_STYLE);\n-    if (hints == WEBVIEW_HINT_FIXED) {\n-      style &= ~(WS_THICKFRAME | WS_MAXIMIZEBOX);\n-    } else {\n-      style |= (WS_THICKFRAME | WS_MAXIMIZEBOX);\n-    }\n-    SetWindowLong(m_window, GWL_STYLE, style);\n-\n-    if (hints == WEBVIEW_HINT_MAX) {\n-      m_maxsz.x = width;\n-      m_maxsz.y = height;\n-    } else if (hints == WEBVIEW_HINT_MIN) {\n-      m_minsz.x = width;\n-      m_minsz.y = height;\n-    } else {\n-      auto dpi = get_window_dpi(m_window);\n-      m_dpi = dpi;\n-      auto scaled_size =\n-          scale_size(width, height, get_default_window_dpi(), dpi);\n-      auto frame_size =\n-          make_window_frame_size(m_window, scaled_size.cx, scaled_size.cy, dpi);\n-      SetWindowPos(m_window, nullptr, 0, 0, frame_size.cx, frame_size.cy,\n-                   SWP_NOZORDER | SWP_NOACTIVATE | SWP_NOMOVE |\n-                       SWP_FRAMECHANGED);\n+  noresult window_show() {\n+    if (m_owns_window && !m_is_window_shown) {\n+      ShowWindow(m_window, SW_SHOW);\n+      UpdateWindow(m_window);\n+      SetFocus(m_window);\n+      m_is_window_shown = true;\n     }\n     return {};\n   }\n-\n-  noresult navigate_impl(const std::string &url) override {\n-    auto wurl = widen_string(url);\n-    m_webview->Navigate(wurl.c_str());\n-    return {};\n-  }\n-\n-  noresult eval_impl(const std::string &js) override {\n-    // TODO: Skip if no content has begun loading yet. Can't check with\n-    //       ICoreWebView2::get_Source because it returns \"about:blank\".\n-    auto wjs = widen_string(js);\n-    m_webview->ExecuteScript(wjs.c_str(), nullptr);\n-    return {};\n-  }\n-\n-  noresult set_html_impl(const std::string &html) override {\n-    m_webview->NavigateToString(widen_string(html).c_str());\n-    return {};\n-  }\n-\n-  user_script add_user_script_impl(const std::string &js) override {\n-    auto wjs = widen_string(js);\n-    std::wstring script_id;\n-    bool done{};\n-    webview2_user_script_added_handler handler{[&](HRESULT res, LPCWSTR id) {\n-      if (SUCCEEDED(res)) {\n-        script_id = id;\n-      }\n-      done = true;\n-    }};\n-    auto res =\n-        m_webview->AddScriptToExecuteOnDocumentCreated(wjs.c_str(), &handler);\n-    if (SUCCEEDED(res)) {\n-      // Sadly we need to pump the even loop in order to get the script ID.\n-      while (!done) {\n-        deplete_run_loop_event_queue();\n-      }\n-    }\n-    // TODO: There's a non-zero chance that we didn't get the script ID.\n-    //       We need to convey the error somehow.\n-    return user_script{\n-        js, user_script::impl_ptr{new user_script::impl{script_id, wjs},\n-                                  [](user_script::impl *p) { delete p; }}};\n-  }\n-\n-  void\n-  remove_all_user_scripts_impl(const std::list<user_script> &scripts) override {\n-    for (const auto &script : scripts) {\n-      const auto &id = script.get_impl().get_id();\n-      m_webview->RemoveScriptToExecuteOnDocumentCreated(id.c_str());\n-    }\n-  }\n-\n-  bool are_user_scripts_equal_impl(const user_script &first,\n-                                   const user_script &second) override {\n-    const auto &first_id = first.get_impl().get_id();\n-    const auto &second_id = second.get_impl().get_id();\n-    return first_id == second_id;\n-  }\n-\n-private:\n   noresult embed(HWND wnd, bool debug, msg_cb_t cb) {\n     std::atomic_flag flag = ATOMIC_FLAG_INIT;\n     flag.test_and_set();\n@@ -778,8 +798,8 @@ private:\n                         \"put_IsStatusBarEnabled failed\"};\n     }\n     add_init_script(\"function(message) {\\n\\\n-  return window.chrome.webview.postMessage(message);\\n\\\n-}\");\n+   return window.chrome.webview.postMessage(message);\\n\\\n+ }\");\n     resize_webview();\n     m_controller->put_IsVisible(TRUE);\n     ShowWindow(m_widget, SW_SHOW);\n@@ -858,9 +878,8 @@ private:\n   }\n \n   // Blocks while depleting the run loop of events.\n-  void deplete_run_loop_event_queue() {\n-    bool done{};\n-    dispatch([&] { done = true; });\n+  void deplete_run_loop_event_queue(bool &done, std::function<void()> f) {\n+    dispatch(f);\n     while (!done) {\n       MSG msg;\n       if (GetMessageW(&msg, nullptr, 0, 0) > 0) {\n@@ -886,6 +905,7 @@ private:\n   mswebview2::loader m_webview2_loader;\n   int m_dpi{};\n   bool m_owns_window{};\n+  bool m_is_window_shown{};\n };\n \n } // namespace detail\ndiff --git a/core/include/webview/detail/engine_base.hh b/core/include/webview/detail/engine_base.hh\nindex ddd17b325..cd2e7f4db 100644\n--- a/core/include/webview/detail/engine_base.hh\n+++ b/core/include/webview/detail/engine_base.hh\n@@ -136,6 +136,7 @@ window.__webview__.onUnbind(\" +\n   noresult set_title(const std::string &title) { return set_title_impl(title); }\n \n   noresult set_size(int width, int height, webview_hint_t hints) {\n+    m_is_size_set = true;\n     return set_size_impl(width, height, hints);\n   }\n \n@@ -200,6 +201,7 @@ protected:\n \n   void add_init_script(const std::string &post_fn) {\n     add_user_script(create_init_script(post_fn));\n+    m_script_is_init = false;\n   }\n \n   std::string create_init_script(const std::string &post_fn) {\n@@ -318,6 +320,19 @@ protected:\n     }\n   }\n \n+  void dispatch_size_default(bool m_owns_window) {\n+    if (!m_owns_window || m_script_is_init) {\n+      return;\n+    };\n+    dispatch([this]() {\n+      if (!m_is_size_set) {\n+        set_size(m_initial_width, m_initial_height, WEBVIEW_HINT_NONE);\n+      }\n+    });\n+  }\n+\n+  void default_size_guard(bool flag) { m_is_size_set = flag; }\n+\n private:\n   static std::atomic_uint &window_ref_count() {\n     static std::atomic_uint ref_count{0};\n@@ -337,6 +352,11 @@ private:\n   std::map<std::string, binding_ctx_t> bindings;\n   user_script *m_bind_script{};\n   std::list<user_script> m_user_scripts;\n+\n+  bool m_script_is_init{true};\n+  bool m_is_size_set{};\n+  static const int m_initial_width = 640;\n+  static const int m_initial_height = 480;\n };\n \n } // namespace detail\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Windows test failure is unrelated to changes. Confirm compatibility with `bind()` as it may temporarily spin the event loop, affecting dispatched callables.\n\n2. Change default window behavior: suppress initial visibility and let users control with `set_visible(true)`. Consider using a counter for state management instead of a boolean flag.\n\n3. GTK 4 doesn't support window resizing after setup; initial size should be set early to avoid issues. Current state of the PR is an improvement but requires further review.\n\n4. Commit refactoring resolves looping issues in `add_user_script_impl` and `deplete_run_loop_event_queue`, establishing consistent behavior across all platforms. Validate if changes handle default size correctly."
      }
    ],
    "codediff_length": 30265
  },
  {
    "index": 101,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.editorconfig b/.editorconfig\nindex 135a7e4bc..6f987c04b 100644\n--- a/.editorconfig\n+++ b/.editorconfig\n@@ -12,6 +12,9 @@ charset = utf-8\n indent_style = space\n indent_size = 4\n \n+[*.md]\n+indent_size = 2\n+\n [Makefile]\n indent_style = tab\n \ndiff --git a/docs/gguf.md b/docs/gguf.md\nnew file mode 100644\nindex 000000000..75610a45f\n--- /dev/null\n+++ b/docs/gguf.md\n@@ -0,0 +1,620 @@\n+# GGUF\n+\n+GGUF is a file format for storing models for inference with GGML and executors based on GGML. GGUF is a binary format that is designed for fast loading and saving of models, and for ease of reading. Models are traditionally developed using PyTorch or another framework, and then converted to GGUF for use in GGML.\n+\n+It is a successor file format to GGML, GGMF and GGJT, and is designed to be unambiguous by containing all the information needed to load a model. It is also designed to be extensible, so that new information can be added to models without breaking compatibility.\n+\n+For more information about the motivation behind GGUF, see [Historical State of Affairs](#historical-state-of-affairs).\n+\n+## Specification\n+\n+GGUF is a format based on the existing GGJT, but makes a few changes to the format to make it more extensible and easier to use. The following features are desired:\n+\n+- Single-file deployment: they can be easily distributed and loaded, and do not require any external files for additional information.\n+- Extensible: new features can be added to GGML-based executors/new information can be added to GGUF models without breaking compatibility with existing models.\n+- `mmap` compatibility: models can be loaded using `mmap` for fast loading and saving.\n+- Easy to use: models can be easily loaded and saved using a small amount of code, with no need for external libraries, regardless of the language used.\n+- Full information: all information needed to load a model is contained in the model file, and no additional information needs to be provided by the user.\n+\n+The key difference between GGJT and GGUF is the use of a key-value structure for the hyperparameters (now referred to as metadata), rather than a list of untyped values. This allows for new metadata to be added without breaking compatibility with existing models, and to annotate the model with additional information that may be useful for inference or for identifying the model.\n+\n+### File Structure\n+\n+GGUF files are structured as follows. They use a global alignment specified in the `general.alignment` metadata field, referred to as `ALIGNMENT` below. Where required, the file is padded with `0x00` bytes to the next multiple of `general.alignment`.\n+\n+Fields, including arrays, are written sequentially without alignment unless otherwise specified.\n+\n+Models are little-endian by default. They can also come in big-endian for use with big-endian computers; in this case, all values (including metadata values and tensors) will also be big-endian. At the time of writing, there is no way to determine if a model is big-endian; this may be rectified in future versions. If no additional information is provided, assume the model is little-endian.\n+\n+```c\n+enum ggml_type: uint32_t {\n+    GGML_TYPE_F32  = 0,\n+    GGML_TYPE_F16  = 1,\n+    GGML_TYPE_Q4_0 = 2,\n+    GGML_TYPE_Q4_1 = 3,\n+    // GGML_TYPE_Q4_2 = 4, support has been removed\n+    // GGML_TYPE_Q4_3 (5) support has been removed\n+    GGML_TYPE_Q5_0 = 6,\n+    GGML_TYPE_Q5_1 = 7,\n+    GGML_TYPE_Q8_0 = 8,\n+    GGML_TYPE_Q8_1 = 9,\n+    // k-quantizations\n+    GGML_TYPE_Q2_K = 10,\n+    GGML_TYPE_Q3_K = 11,\n+    GGML_TYPE_Q4_K = 12,\n+    GGML_TYPE_Q5_K = 13,\n+    GGML_TYPE_Q6_K = 14,\n+    GGML_TYPE_Q8_K = 15,\n+    GGML_TYPE_I8,\n+    GGML_TYPE_I16,\n+    GGML_TYPE_I32,\n+    GGML_TYPE_COUNT,\n+};\n+\n+enum gguf_metadata_value_type: uint32_t {\n+    // The value is a 8-bit unsigned integer.\n+    GGUF_METADATA_VALUE_TYPE_UINT8 = 0,\n+    // The value is a 8-bit signed integer.\n+    GGUF_METADATA_VALUE_TYPE_INT8 = 1,\n+    // The value is a 16-bit unsigned little-endian integer.\n+    GGUF_METADATA_VALUE_TYPE_UINT16 = 2,\n+    // The value is a 16-bit signed little-endian integer.\n+    GGUF_METADATA_VALUE_TYPE_INT16 = 3,\n+    // The value is a 32-bit unsigned little-endian integer.\n+    GGUF_METADATA_VALUE_TYPE_UINT32 = 4,\n+    // The value is a 32-bit signed little-endian integer.\n+    GGUF_METADATA_VALUE_TYPE_INT32 = 5,\n+    // The value is a 32-bit IEEE754 floating point number.\n+    GGUF_METADATA_VALUE_TYPE_FLOAT32 = 6,\n+    // The value is a boolean.\n+    // 1-byte value where 0 is false and 1 is true.\n+    // Anything else is invalid, and should be treated as either the model being invalid or the reader being buggy.\n+    GGUF_METADATA_VALUE_TYPE_BOOL = 7,\n+    // The value is a UTF-8 non-null-terminated string, with length prepended.\n+    GGUF_METADATA_VALUE_TYPE_STRING = 8,\n+    // The value is an array of other values, with the length and type prepended.\n+    ///\n+    // Arrays can be nested, and the length of the array is the number of elements in the array, not the number of bytes.\n+    GGUF_METADATA_VALUE_TYPE_ARRAY = 9,\n+    // The value is a 64-bit unsigned little-endian integer.\n+    GGUF_METADATA_VALUE_TYPE_UINT64 = 10,\n+    // The value is a 64-bit signed little-endian integer.\n+    GGUF_METADATA_VALUE_TYPE_INT64 = 11,\n+    // The value is a 64-bit IEEE754 floating point number.\n+    GGUF_METADATA_VALUE_TYPE_FLOAT64 = 12,\n+}\n+\n+// A string in GGUF.\n+struct gguf_string_t {\n+    // The length of the string, in bytes.\n+    uint64_t len;\n+    // The string as a UTF-8 non-null-terminated string.\n+    char string[len];\n+}\n+\n+union gguf_metadata_value_t {\n+    uint8_t uint8;\n+    int8_t int8;\n+    uint16_t uint16;\n+    int16_t int16;\n+    uint32_t uint32;\n+    int32_t int32;\n+    float float32;\n+    uint64_t uint64;\n+    int64_t int64;\n+    double float64;\n+    bool bool_;\n+    gguf_string_t string;\n+    struct {\n+        // Any value type is valid, including arrays.\n+        gguf_metadata_value_type type;\n+        // Number of elements, not bytes\n+        uint64_t len;\n+        // The array of values.\n+        gguf_metadata_value_t array[len];\n+    } array;\n+};\n+\n+struct gguf_metadata_kv_t {\n+    // The key of the metadata. It is a standard GGUF string, with the following caveats:\n+    // - It must be a valid ASCII string.\n+    // - It must be a hierarchical key, where each segment is `lower_snake_case` and separated by a `.`.\n+    // - It must be at most 2^16-1/65535 bytes long.\n+    // Any keys that do not follow these rules are invalid.\n+    gguf_string_t key;\n+\n+    // The type of the value.\n+    // Must be one of the `gguf_metadata_value_type` values.\n+    gguf_metadata_value_type value_type;\n+    // The value.\n+    gguf_metadata_value_t value;\n+};\n+\n+struct gguf_header_t {\n+    // Magic number to announce that this is a GGUF file.\n+    // Must be `GGUF` at the byte level: `0x47` `0x47` `0x55` `0x46`.\n+    // Your executor might do little-endian byte order, so it might be\n+    // check for 0x46554747 and letting the endianness cancel out.\n+    // Consider being *very* explicit about the byte order here.\n+    uint32_t magic;\n+    // The version of the format implemented.\n+    // Must be `3` for version described in this spec, which introduces big-endian support.\n+    //\n+    // This version should only be increased for structural changes to the format.\n+    // Changes that do not affect the structure of the file should instead update the metadata\n+    // to signify the change.\n+    uint32_t version;\n+    // The number of tensors in the file.\n+    // This is explicit, instead of being included in the metadata, to ensure it is always present\n+    // for loading the tensors.\n+    uint64_t tensor_count;\n+    // The number of metadata key-value pairs.\n+    uint64_t metadata_kv_count;\n+    // The metadata key-value pairs.\n+    gguf_metadata_kv_t metadata_kv[metadata_kv_count];\n+};\n+\n+uint64_t align_offset(uint64_t offset) {\n+    return offset + (ALIGNMENT - (offset % ALIGNMENT)) % ALIGNMENT;\n+}\n+\n+struct gguf_tensor_info_t {\n+    // The name of the tensor. It is a standard GGUF string, with the caveat that\n+    // it must be at most 64 bytes long.\n+    gguf_string_t name;\n+    // The number of dimensions in the tensor.\n+    // Currently at most 4, but this may change in the future.\n+    uint32_t n_dimensions;\n+    // The dimensions of the tensor.\n+    uint64_t dimensions[n_dimensions];\n+    // The type of the tensor.\n+    ggml_type type;\n+    // The offset of the tensor's data in this file in bytes.\n+    //\n+    // This offset is relative to `tensor_data`, not to the start\n+    // of the file, to make it easier for writers to write the file.\n+    // Readers should consider exposing this offset relative to the\n+    // file to make it easier to read the data.\n+    //\n+    // Must be a multiple of `ALIGNMENT`. That is, `align_offset(offset) == offset`.\n+    uint64_t offset;\n+};\n+\n+struct gguf_file_t {\n+    // The header of the file.\n+    gguf_header_t header;\n+\n+    // Tensor infos, which can be used to locate the tensor data.\n+    gguf_tensor_info_t tensor_infos[header.tensor_count];\n+\n+    // Padding to the nearest multiple of `ALIGNMENT`.\n+    //\n+    // That is, if `sizeof(header) + sizeof(tensor_infos)` is not a multiple of `ALIGNMENT`,\n+    // this padding is added to make it so.\n+    //\n+    // This can be calculated as `align_offset(position) - position`, where `position` is\n+    // the position of the end of `tensor_infos` (i.e. `sizeof(header) + sizeof(tensor_infos)`).\n+    uint8_t _padding[];\n+\n+    // Tensor data.\n+    //\n+    // This is arbitrary binary data corresponding to the weights of the model. This data should be close\n+    // or identical to the data in the original model file, but may be different due to quantization or\n+    // other optimizations for inference. Any such deviations should be recorded in the metadata or as\n+    // part of the architecture definition.\n+    //\n+    // Each tensor's data must be stored within this array, and located through its `tensor_infos` entry.\n+    // The offset of each tensor's data must be a multiple of `ALIGNMENT`, and the space between tensors\n+    // should be padded to `ALIGNMENT` bytes.\n+    uint8_t tensor_data[];\n+};\n+```\n+\n+## Standardized key-value pairs\n+\n+The following key-value pairs are standardized. This list may grow in the future as more use cases are discovered. Where possible, names are shared with the original model definitions to make it easier to map between the two.\n+\n+Not all of these are required, but they are all recommended. Keys that are required are bolded. For omitted pairs, the reader should assume that the value is unknown and either default or error as appropriate.\n+\n+The community can develop their own key-value pairs to carry additional data. However, these should be namespaced with the relevant community name to avoid collisions. For example, the `rustformers` community might use `rustformers.` as a prefix for all of their keys.\n+\n+If a particular community key is widely used, it may be promoted to a standardized key.\n+\n+By convention, most counts/lengths/etc are `uint64` unless otherwise specified. This is to allow for larger models to be supported in the future. Some models may use `uint32` for their values; it is recommended that readers support both.\n+\n+### General\n+\n+#### Required\n+\n+- **`general.architecture: string`**: describes what architecture this model implements. All lowercase ASCII, with only `[a-z0-9]+` characters allowed. Known values include:\n+  - `llama`\n+  - `mpt`\n+  - `gptneox`\n+  - `gptj`\n+  - `gpt2`\n+  - `bloom`\n+  - `falcon`\n+  - `rwkv`\n+- **`general.quantization_version: uint32`**: The version of the quantization format. Not required if the model is not quantized (i.e. no tensors are quantized). If any tensors are quantized, this _must_ be present. This is separate to the quantization scheme of the tensors itself; the quantization version may change without changing the scheme's name (e.g. the quantization scheme is Q5_K, and the quantization version is 4).\n+- **`general.alignment: uint32`**: the global alignment to use, as described above. This can vary to allow for different alignment schemes, but it must be a multiple of 8. Some writers may not write the alignment. If the alignment is **not** specified, assume it is `32`.\n+\n+#### General metadata\n+\n+- `general.name`: The name of the model. This should be a human-readable name that can be used to identify the model. It should be unique within the community that the model is defined in.\n+- `general.author`: The author of the model.\n+- `general.url`: URL to the model's homepage. This can be a GitHub repo, a paper, etc.\n+- `general.description: string`: free-form description of the model including anything that isn't covered by the other fields\n+- `general.license: string`: License of the model, expressed as a [SPDX license expression](https://spdx.github.io/spdx-spec/v2-draft/SPDX-license-expressions/) (e.g. `\"MIT OR Apache-2.0`). Do not include any other information, such as the license text or the URL to the license.\n+- `general.file_type: uint32`: An enumerated value describing the type of the majority of the tensors in the file. Optional; can be inferred from the tensor types.\n+  - `ALL_F32 = 0`\n+  - `MOSTLY_F16 = 1`\n+  - `MOSTLY_Q4_0 = 2`\n+  - `MOSTLY_Q4_1 = 3`\n+  - `MOSTLY_Q4_1_SOME_F16 = 4`\n+  - `MOSTLY_Q4_2 = 5` (support removed)\n+  - `MOSTLY_Q4_3 = 6` (support removed)\n+  - `MOSTLY_Q8_0 = 7`\n+  - `MOSTLY_Q5_0 = 8`\n+  - `MOSTLY_Q5_1 = 9`\n+  - `MOSTLY_Q2_K = 10`\n+  - `MOSTLY_Q3_K_S = 11`\n+  - `MOSTLY_Q3_K_M = 12`\n+  - `MOSTLY_Q3_K_L = 13`\n+  - `MOSTLY_Q4_K_S = 14`\n+  - `MOSTLY_Q4_K_M = 15`\n+  - `MOSTLY_Q5_K_S = 16`\n+  - `MOSTLY_Q5_K_M = 17`\n+  - `MOSTLY_Q6_K = 18`\n+\n+#### Source metadata\n+\n+Information about where this model came from. This is useful for tracking the provenance of the model, and for finding the original source if the model is modified. For a model that was converted from GGML, for example, these keys would point to the model that was converted from.\n+\n+- `general.source.url: string`: URL to the source of the model. Can be a GitHub repo, a paper, etc.\n+- `general.source.huggingface.repository: string`: Hugging Face model repository that this model is either hosted on or based on\n+\n+### LLM\n+\n+In the following, `[llm]` is used to fill in for the name of a specific LLM architecture. For example, `llama` for LLaMA, `mpt` for MPT, etc. If mentioned in an architecture's section, it is required for that architecture, but not all keys are required for all architectures. Consult the relevant section for more information.\n+\n+- `[llm].context_length: uint64`: Also known as `n_ctx`. length of the context (in tokens) that the model was trained on. For most architectures, this is the hard limit on the length of the input. Architectures, like RWKV, that are not reliant on transformer-style attention may be able to handle larger inputs, but this is not guaranteed.\n+- `[llm].embedding_length: uint64`: Also known as `n_embd`. Embedding layer size.\n+- `[llm].block_count: uint64`: The number of blocks of attention+feed-forward layers (i.e. the bulk of the LLM). Does not include the input or embedding layers.\n+- `[llm].feed_forward_length: uint64`: Also known as `n_ff`. The length of the feed-forward layer.\n+- `[llm].use_parallel_residual: bool`: Whether or not the parallel residual logic should be used.\n+- `[llm].tensor_data_layout: string`: When a model is converted to GGUF, tensors may be rearranged to improve performance. This key describes the layout of the tensor data. This is not required; if not present, it is assumed to be `reference`.\n+  - `reference`: tensors are laid out in the same order as the original model\n+  - further options can be found for each architecture in their respective sections\n+\n+#### Attention\n+\n+- `[llm].attention.head_count: uint64`: Also known as `n_head`. Number of attention heads.\n+- `[llm].attention.head_count_kv: uint64`: The number of heads per group used in Grouped-Query-Attention. If not present or if present and equal to `[llm].attention.head_count`, the model does not use GQA.\n+- `[llm].attention.max_alibi_bias: float32`: The maximum bias to use for ALiBI.\n+- `[llm].attention.clamp_kqv: float32`: Value (`C`) to clamp the values of the `Q`, `K`, and `V` tensors between (`[-C, C]`).\n+- `[llm].attention.layer_norm_epsilon: float32`: Layer normalization epsilon.\n+- `[llm].attention.layer_norm_rms_epsilon: float32`: Layer RMS normalization epsilon.\n+\n+#### RoPE\n+\n+- `[llm].rope.dimension_count: uint64`: The number of rotary dimensions for RoPE.\n+- `[llm].rope.freq_base: float32`: The base frequency for RoPE.\n+\n+##### Scaling\n+\n+The following keys describe RoPE scaling parameters:\n+\n+- `[llm].rope.scaling.type: string`: Can be `none`, `linear`, or `yarn`.\n+- `[llm].rope.scaling.factor: float32`: A scale factor for RoPE to adjust the context length.\n+- `[llm].rope.scaling.original_context_length: uint32_t`: The original context length of the base model.\n+- `[llm].rope.scaling.finetuned: bool`: True if model has been finetuned with RoPE scaling.\n+\n+Note that older models may not have these keys, and may instead use the following key:\n+\n+- `[llm].rope.scale_linear: float32`: A linear scale factor for RoPE to adjust the context length.\n+\n+It is recommended that models use the newer keys if possible, as they are more flexible and allow for more complex scaling schemes. Executors will need to support both indefinitely.\n+\n+#### Models\n+\n+The following sections describe the metadata for each model architecture. Each key specified _must_ be present.\n+\n+##### LLaMA\n+\n+- `llama.context_length`\n+- `llama.embedding_length`\n+- `llama.block_count`\n+- `llama.feed_forward_length`\n+- `llama.rope.dimension_count`\n+- `llama.attention.head_count`\n+- `llama.attention.layer_norm_rms_epsilon`\n+\n+###### Optional\n+\n+- `llama.rope.scale`\n+- `llama.attention.head_count_kv`\n+- `llama.tensor_data_layout`:\n+  - `Meta AI original pth`:\n+    ```python\n+    def permute(weights: NDArray, n_head: int) -> NDArray:\n+        return (weights.reshape(n_head, 2, weights.shape[0] // n_head // 2, *weights.shape[1:])\n+                    .swapaxes(1, 2)\n+                    .reshape(weights.shape))\n+    ```\n+\n+##### MPT\n+\n+- `mpt.context_length`\n+- `mpt.embedding_length`\n+- `mpt.block_count`\n+- `mpt.attention.head_count`\n+- `mpt.attention.alibi_bias_max`\n+- `mpt.attention.clip_kqv`\n+- `mpt.attention.layer_norm_epsilon`\n+\n+##### GPT-NeoX\n+\n+- `gptneox.context_length`\n+- `gptneox.embedding_length`\n+- `gptneox.block_count`\n+- `gptneox.use_parallel_residual`\n+- `gptneox.rope.dimension_count`\n+- `gptneox.attention.head_count`\n+- `gptneox.attention.layer_norm_epsilon`\n+\n+###### Optional\n+\n+- `gptneox.rope.scale`\n+\n+##### GPT-J\n+\n+- `gptj.context_length`\n+- `gptj.embedding_length`\n+- `gptj.block_count`\n+- `gptj.rope.dimension_count`\n+- `gptj.attention.head_count`\n+- `gptj.attention.layer_norm_epsilon`\n+\n+###### Optional\n+\n+- `gptj.rope.scale`\n+\n+##### GPT-2\n+\n+- `gpt2.context_length`\n+- `gpt2.embedding_length`\n+- `gpt2.block_count`\n+- `gpt2.attention.head_count`\n+- `gpt2.attention.layer_norm_epsilon`\n+\n+##### BLOOM\n+\n+- `bloom.context_length`\n+- `bloom.embedding_length`\n+- `bloom.block_count`\n+- `bloom.feed_forward_length`\n+- `bloom.attention.head_count`\n+- `bloom.attention.layer_norm_epsilon`\n+\n+##### Falcon\n+\n+- `falcon.context_length`\n+- `falcon.embedding_length`\n+- `falcon.block_count`\n+- `falcon.attention.head_count`\n+- `falcon.attention.head_count_kv`\n+- `falcon.attention.use_norm`\n+- `falcon.attention.layer_norm_epsilon`\n+\n+###### Optional\n+\n+- `falcon.tensor_data_layout`:\n+\n+  - `jploski` (author of the original GGML implementation of Falcon):\n+\n+    ```python\n+    # The original query_key_value tensor contains n_head_kv \"kv groups\",\n+    # each consisting of n_head/n_head_kv query weights followed by one key\n+    # and one value weight (shared by all query heads in the kv group).\n+    # This layout makes it a big pain to work with in GGML.\n+    # So we rearrange them here,, so that we have n_head query weights\n+    # followed by n_head_kv key weights followed by n_head_kv value weights,\n+    # in contiguous fashion.\n+\n+    if \"query_key_value\" in src:\n+        qkv = model[src].view(\n+            n_head_kv, n_head // n_head_kv + 2, head_dim, head_dim * n_head)\n+\n+        q = qkv[:, :-2 ].reshape(n_head * head_dim, head_dim * n_head)\n+        k = qkv[:, [-2]].reshape(n_head_kv * head_dim, head_dim * n_head)\n+        v = qkv[:, [-1]].reshape(n_head_kv * head_dim, head_dim * n_head)\n+\n+        model[src] = torch.cat((q,k,v)).reshape_as(model[src])\n+    ```\n+\n+##### RWKV\n+\n+The vocabulary size is the same as the number of rows in the `head` matrix.\n+\n+- `rwkv.architecture_version: uint32`: The only allowed value currently is 4. Version 5 is expected to appear some time in the future.\n+- `rwkv.context_length: uint64`: Length of the context used during training or fine-tuning. RWKV is able to handle larger context than this limit, but the output quality may suffer.\n+- `rwkv.block_count: uint64`\n+- `rwkv.embedding_length: uint64`\n+- `rwkv.feed_forward_length: uint64`\n+\n+##### Whisper\n+\n+Keys that do not have types defined should be assumed to share definitions with `llm.` keys.\n+(For example, `whisper.context_length` is equivalent to `llm.context_length`.)\n+This is because they are both transformer models.\n+\n+- `whisper.encoder.context_length`\n+- `whisper.encoder.embedding_length`\n+- `whisper.encoder.block_count`\n+- `whisper.encoder.mels_count: uint64`\n+- `whisper.encoder.attention.head_count`\n+\n+- `whisper.decoder.context_length`\n+- `whisper.decoder.embedding_length`\n+- `whisper.decoder.block_count`\n+- `whisper.decoder.attention.head_count`\n+\n+#### Prompting\n+\n+**TODO**: Include prompt format, and/or metadata about how it should be used (instruction, conversation, autocomplete, etc).\n+\n+### LoRA\n+\n+**TODO**: Figure out what metadata is needed for LoRA. Probably desired features:\n+\n+- match an existing model exactly, so that it can't be misapplied\n+- be marked as a LoRA so executors won't try to run it by itself\n+\n+Should this be an architecture, or should it share the details of the original model with additional fields to mark it as a LoRA?\n+\n+### Tokenizer\n+\n+The following keys are used to describe the tokenizer of the model. It is recommended that model authors support as many of these as possible, as it will allow for better tokenization quality with supported executors.\n+\n+#### GGML\n+\n+GGML supports an embedded vocabulary that enables inference of the model, but implementations of tokenization using this vocabulary (i.e. `llama.cpp`'s tokenizer) may have lower accuracy than the original tokenizer used for the model. When a more accurate tokenizer is available and supported, it should be used instead.\n+\n+It is not guaranteed to be standardized across models, and may change in the future. It is recommended that model authors use a more standardized tokenizer if possible.\n+\n+- `tokenizer.ggml.model: string`: The name of the tokenizer model.\n+  - `llama`: Llama style SentencePiece (tokens and scores extracted from HF `tokenizer.model`)\n+  - `replit`: Replit style SentencePiece (tokens and scores extracted from HF `spiece.model`)\n+  - `gpt2`: GPT-2 / GPT-NeoX style BPE (tokens extracted from HF `tokenizer.json`)\n+  - `rwkv`: RWKV tokenizer\n+- `tokenizer.ggml.tokens: array[string]`: A list of tokens indexed by the token ID used by the model.\n+- `tokenizer.ggml.scores: array[float32]`: If present, the score/probability of each token. If not present, all tokens are assumed to have equal probability. If present, it must have the same length and index as `tokens`.\n+- `tokenizer.ggml.token_type: array[int32]`: The token type (1=normal, 2=unknown, 3=control, 4=user defined, 5=unused, 6=byte). If present, it must have the same length and index as `tokens`.\n+- `tokenizer.ggml.merges: array[string]`: If present, the merges of the tokenizer. If not present, the tokens are assumed to be atomic.\n+- `tokenizer.ggml.added_tokens: array[string]`: If present, tokens that were added after training.\n+\n+##### Special tokens\n+\n+- `tokenizer.ggml.bos_token_id: uint32`: Beginning of sequence marker\n+- `tokenizer.ggml.eos_token_id: uint32`: End of sequence marker\n+- `tokenizer.ggml.unknown_token_id: uint32`: Unknown token\n+- `tokenizer.ggml.separator_token_id: uint32`: Separator token\n+- `tokenizer.ggml.padding_token_id: uint32`: Padding token\n+\n+#### Hugging Face\n+\n+Hugging Face maintains their own `tokenizers` library that supports a wide variety of tokenizers. If your executor uses this library, it may be able to use the model's tokenizer directly.\n+\n+- `tokenizer.huggingface.json: string`: the entirety of the HF `tokenizer.json` for a given model (e.g. <https://huggingface.co/mosaicml/mpt-7b-instruct/blob/main/tokenizer.json>). Included for compatibility with executors that support HF tokenizers directly.\n+\n+#### Other\n+\n+Other tokenizers may be used, but are not necessarily standardized. They may be executor-specific. They will be documented here as they are discovered/further developed.\n+\n+- `tokenizer.rwkv.world: string`: a RWKV World tokenizer, like [this](https://github.com/BlinkDL/ChatRWKV/blob/main/tokenizer/rwkv_vocab_v20230424.txt). This text file should be included verbatim.\n+\n+### Computation graph\n+\n+This is a future extension and still needs to be discussed, and may necessitate a new GGUF version. At the time of writing, the primary blocker is the stabilization of the computation graph format.\n+\n+A sample computation graph of GGML nodes could be included in the model itself, allowing an executor to run the model without providing its own implementation of the architecture. This would allow for a more consistent experience across executors, and would allow for more complex architectures to be supported without requiring the executor to implement them.\n+\n+## Standardized tensor names\n+\n+To minimize complexity and maximize compatibility, it is recommended that models using the transformer architecture use the following naming convention for their tensors:\n+\n+### Base layers\n+\n+`AA.weight` `AA.bias`\n+\n+where `AA` can be:\n+\n+- `token_embd`: Token embedding layer\n+- `pos_embd`: Position embedding layer\n+- `output_norm`: Output normalization layer\n+- `output`: Output layer\n+\n+### Attention and feed-forward layer blocks\n+\n+`blk.N.BB.weight` `blk.N.BB.bias`\n+\n+where N signifies the block number a layer belongs to, and where `BB` could be:\n+\n+- `attn_norm`: Attention normalization layer\n+- `attn_norm_2`: Attention normalization layer\n+- `attn_qkv`: Attention query-key-value layer\n+- `attn_q`: Attention query layer\n+- `attn_k`: Attention key layer\n+- `attn_v`: Attention value layer\n+- `attn_output`: Attention output layer\n+\n+- `ffn_norm`: Feed-forward network normalization layer\n+- `ffn_up`: Feed-forward network \"up\" layer\n+- `ffn_gate`: Feed-forward network \"gate\" layer\n+- `ffn_down`: Feed-forward network \"down\" layer\n+\n+## Version History\n+\n+This document is actively updated to describe the current state of the metadata, and these changes are not tracked outside of the commits.\n+\n+However, the format _itself_ has changed. The following sections describe the changes to the format itself.\n+\n+### v3\n+\n+Adds big-endian support.\n+\n+### v2\n+\n+Most countable values (lengths, etc) were changed from `uint32` to `uint64` to allow for larger models to be supported in the future.\n+\n+### v1\n+\n+Initial version.\n+\n+## Historical State of Affairs\n+\n+The following information is provided for context, but is not necessary to understand the rest of this document.\n+\n+### Overview\n+\n+At present, there are three GGML file formats floating around for LLMs:\n+\n+- **GGML** (unversioned): baseline format, with no versioning or alignment.\n+- **GGMF** (versioned): the same as GGML, but with versioning. Only one version exists.\n+- **GGJT**: Aligns the tensors to allow for use with `mmap`, which requires alignment. v1, v2 and v3 are identical, but the latter versions use a different quantization scheme that is incompatible with previous versions.\n+\n+GGML is primarily used by the examples in `ggml`, while GGJT is used by `llama.cpp` models. Other executors may use any of the three formats, but this is not 'officially' supported.\n+\n+These formats share the same fundamental structure:\n+\n+- a magic number with an optional version number\n+- model-specific hyperparameters, including\n+  - metadata about the model, such as the number of layers, the number of heads, etc.\n+  - a `ftype` that describes the type of the majority of the tensors,\n+    - for GGML files, the quantization version is encoded in the `ftype` divided by 1000\n+- an embedded vocabulary, which is a list of strings with length prepended. The GGMF/GGJT formats embed a float32 score next to the strings.\n+- finally, a list of tensors with their length-prepended name, type, and (aligned, in the case of GGJT) tensor data\n+\n+Notably, this structure does not identify what model architecture the model belongs to, nor does it offer any flexibility for changing the structure of the hyperparameters. This means that the only way to add new hyperparameters is to add them to the end of the list, which is a breaking change for existing models.\n+\n+### Drawbacks\n+\n+Unfortunately, over the last few months, there are a few issues that have become apparent with the existing models:\n+\n+- There's no way to identify which model architecture a given model is for, because that information isn't present\n+  - Similarly, existing programs cannot intelligently fail upon encountering new architectures\n+- Adding or removing any new hyperparameters is a breaking change, which is impossible for a reader to detect without using heuristics\n+- Each model architecture requires its own conversion script to their architecture's variant of GGML\n+- Maintaining backwards compatibility without breaking the structure of the format requires clever tricks, like packing the quantization version into the ftype, which are not guaranteed to be picked up by readers/writers, and are not consistent between the two formats\n+\n+### Why not other formats?\n+\n+There are a few other formats that could be used, but issues include:\n+\n+- requiring additional dependencies to load or save the model, which is complicated in a C environment\n+- limited or no support for 4-bit quantization\n+- existing cultural expectations (e.g. whether or not the model is a directory or a file)\n+- lack of support for embedded vocabularies\n+- lack of control over direction of future development\n+\n+Ultimately, it is likely that GGUF will remain necessary for the foreseeable future, and it is better to have a single format that is well-documented and supported by all executors than to contort an existing format to fit the needs of GGML.\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Suggest defining a freeform key-value pair structure for metadata, e.g.:\n   ```\n   ggml_magic\n   number_of_pairs\n   [\n       (key_length, key, value_type, value)\n   ]\n   ```\n2. Propose adding special key-values to identify tokens: `tokenizer.bos_token_id`, `tokenizer.eos_token_id`, etc.\n3. Recommend renaming cryptic keys to enhance clarity:\n   - `[llm].hidden_size` to `[llm].embedding_length`\n   - Use `_count` instead of `num_` for consistency.\n4. Define the next steps: \n   - Implement a Python script for Hugging Face model conversion to GGUF.\n   - Update existing code to load GGUF in `ggml`.\n5. Clarify that GGUF support implementation will be initiated once test models are established."
      }
    ],
    "codediff_length": 30903
  },
  {
    "index": 102,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/examples/CMakeLists.txt b/examples/CMakeLists.txt\nindex 7a4bb2466..9e3e42d50 100644\n--- a/examples/CMakeLists.txt\n+++ b/examples/CMakeLists.txt\n@@ -26,3 +26,4 @@ add_subdirectory(dolly-v2)\n add_subdirectory(replit)\n add_subdirectory(mpt)\n add_subdirectory(starcoder)\n+add_subdirectory(falcon)\ndiff --git a/examples/falcon/CMakeLists.txt b/examples/falcon/CMakeLists.txt\nnew file mode 100644\nindex 000000000..2969507ba\n--- /dev/null\n+++ b/examples/falcon/CMakeLists.txt\n@@ -0,0 +1,13 @@\n+#\n+# falcon\n+\n+set(TEST_TARGET falcon)\n+add_executable(${TEST_TARGET} main.cpp)\n+target_link_libraries(${TEST_TARGET} PRIVATE ggml common common-ggml)\n+\n+#\n+# falcon-quantize\n+\n+set(TEST_TARGET falcon-quantize)\n+add_executable(${TEST_TARGET} quantize.cpp)\n+target_link_libraries(${TEST_TARGET} PRIVATE ggml common common-ggml)\ndiff --git a/examples/falcon/README.md b/examples/falcon/README.md\nnew file mode 100644\nindex 000000000..2ce941831\n--- /dev/null\n+++ b/examples/falcon/README.md\n@@ -0,0 +1,9 @@\n+# falcon\n+\n+Transformer architecture: falcon-7b\n+\n+## Notes\n+\n+- No guarantees for correctness\n+- The tokenizer is currently hacked - probably works only for English\n+- Non-parallel residual is not supported\ndiff --git a/examples/falcon/convert-hf-to-ggml.py b/examples/falcon/convert-hf-to-ggml.py\nnew file mode 100644\nindex 000000000..7fe6d9f26\n--- /dev/null\n+++ b/examples/falcon/convert-hf-to-ggml.py\n@@ -0,0 +1,121 @@\n+# Convert Hugging Face fine-tuned bloom-like models to ggml format\n+#\n+# Usage:\n+#\n+#   python3 models/convert-h5-to-ggml.py \n+#\n+# This script is similar to \"convert-pt-to-ggml.py\"\n+#\n+\n+import io\n+import os\n+import sys\n+import struct\n+import json\n+import code\n+import torch\n+import numpy as np\n+\n+from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n+\n+# ref: https://github.com/openai/gpt-2/blob/master/src/encoder.py\n+def bytes_to_unicode():\n+    \"\"\"\n+    Returns list of utf-8 byte and a corresponding list of unicode strings.\n+    The reversible bpe codes work on unicode strings.\n+    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n+    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n+    This is a significant percentage of your normal, say, 32K bpe vocab.\n+    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n+    And avoids mapping to whitespace/control characters the bpe code barfs on.\n+    \"\"\"\n+    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"\u00a1\"), ord(\"\u00ac\")+1))+list(range(ord(\"\u00ae\"), ord(\"\u00ff\")+1))\n+    cs = bs[:]\n+    n = 0\n+    for b in range(2**8):\n+        if b not in bs:\n+            bs.append(b)\n+            cs.append(2**8+n)\n+            n += 1\n+    cs = [chr(n) for n in cs]\n+    return dict(zip(bs, cs))\n+\n+if len(sys.argv) < 3:\n+    print(\"Usage: python convert-hf-to-ggml.py model_name dir-output [use-f32]\")\n+    print(\"  model_name: name of the model to convert. Example: 'bigscience/bloomz-560m'\")\n+    print(\"  dir-output: directory where the output file will be written\")\n+    print(\"  use-f32:    if present, use float32 instead of float16\")\n+    sys.exit(1)\n+\n+model_name = sys.argv[1]\n+dir_out = sys.argv[2]\n+\n+# make sure the output directory exists\n+os.makedirs(dir_out, exist_ok=True)\n+\n+# possible data types\n+#   ftype == 0 -> float32\n+#   ftype == 1 -> float16\n+#\n+# map from ftype to string\n+ftype_str = [\"f32\", \"f16\"]\n+ftype = 1\n+if len(sys.argv) > 3:\n+    ftype = 0\n+\n+tokenizer = AutoTokenizer.from_pretrained(model_name)\n+config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n+hparams = config.to_dict()\n+print(\"Loading model: \", model_name)\n+model = AutoModelForCausalLM.from_pretrained(model_name, config=config, torch_dtype=torch.float16 if ftype == 1 else torch.float32, low_cpu_mem_usage=True, trust_remote_code=True)\n+print(\"Model loaded: \", model_name)\n+\n+\n+fname_out = dir_out + f\"/ggml-model-{model_name.split('/')[-1]}-{ftype_str[ftype]}.bin\"\n+fout = open(fname_out, \"wb\")\n+fout.write(struct.pack(\"i\", 0x67676d6c)) # magic: ggml in hex\n+fout.write(struct.pack(\"i\", hparams[\"vocab_size\"]))\n+fout.write(struct.pack(\"i\", hparams[\"hidden_size\"]))\n+fout.write(struct.pack(\"i\", hparams[\"n_head\"]))\n+fout.write(struct.pack(\"i\", hparams[\"n_layer\"]))\n+fout.write(struct.pack(\"i\", ftype))\n+\n+reverse_vocab = {id: encoded_tok for encoded_tok, id in tokenizer.vocab.items()}\n+byte_encoder = bytes_to_unicode()\n+byte_decoder = {v:k for k, v in byte_encoder.items()}\n+\n+for i in range(hparams[\"vocab_size\"]):\n+    text = bytearray([byte_decoder[c] for c in reverse_vocab[i]])\n+    fout.write(struct.pack(\"i\", len(text)))\n+    fout.write(text)\n+    \n+list_vars = model.state_dict()\n+for name in list_vars.keys():\n+    src = name\n+    data = list_vars[src].squeeze().numpy()\n+    data = data.astype(np.float32)\n+\n+    n_dims = len(data.shape)\n+    print(name, n_dims, data.shape)\n+\n+    # default type is fp32\n+    ftype_cur = 0\n+    if ftype == 1 and n_dims > 1:\n+        print(\"  Converting to float16\")\n+        data = data.astype(np.float16)\n+        ftype_cur = 1\n+\n+    # header\n+    str = name.encode('utf-8')\n+    fout.write(struct.pack(\"iii\", n_dims, len(str), ftype_cur))\n+    for i in range(n_dims):\n+        fout.write(struct.pack(\"i\", data.shape[n_dims - 1 - i]))\n+    fout.write(str)\n+\n+    # data\n+    data.tofile(fout)\n+\n+fout.close()\n+\n+print(\"Done. Output file: \" + fname_out)\n+print(\"\")\ndiff --git a/examples/falcon/main.cpp b/examples/falcon/main.cpp\nnew file mode 100644\nindex 000000000..1f232b2ee\n--- /dev/null\n+++ b/examples/falcon/main.cpp\n@@ -0,0 +1,760 @@\n+#include \"ggml/ggml.h\"\n+\n+#include \"common.h\"\n+#include \"common-ggml.h\"\n+\n+#include <cassert>\n+#include <cmath>\n+#include <cstdio>\n+#include <cstring>\n+#include <cinttypes>\n+#include <fstream>\n+#include <map>\n+#include <string>\n+#include <vector>\n+\n+// default hparams (Falcon 7B)\n+// TODO add n_head_kv to support 40B\n+struct falcon_hparams {\n+    int32_t n_vocab = 65024;\n+    int32_t n_ctx   = 2048;\n+    int32_t n_embd  = 4544;\n+    int32_t n_head  = 71;\n+    int32_t n_layer = 32;\n+    int32_t ftype   = 1;\n+};\n+\n+struct falcon_layer {\n+    // normalization\n+    struct ggml_tensor* attention_norm;\n+    struct ggml_tensor* attention_norm_b;\n+\n+    // attention\n+    struct ggml_tensor* query_key_value;\n+    struct ggml_tensor* wo;\n+\n+    // ff\n+    struct ggml_tensor* ffn_up;\n+    struct ggml_tensor* ffn_down;\n+};\n+\n+struct falcon_model {\n+    falcon_hparams hparams;\n+\n+    struct ggml_tensor* tok_embeddings;\n+    struct ggml_tensor* output_norm;\n+    struct ggml_tensor* output_norm_b;\n+    struct ggml_tensor* lm_head;\n+\n+    std::vector<falcon_layer> layers;\n+\n+    // key + value memory\n+    struct ggml_tensor* memory_k;\n+    struct ggml_tensor* memory_v;\n+\n+    struct ggml_context* ctx;\n+    std::map<std::string, struct ggml_tensor*> tensors;\n+};\n+\n+// load the model's weights from a file\n+bool falcon_model_load(const std::string & fname, falcon_model & model, gpt_vocab & vocab) {\n+    printf(\"%s: loading model from '%s' - please wait ...\\n\", __func__, fname.c_str());\n+\n+    auto fin = std::ifstream(fname, std::ios::binary);\n+    if (!fin) {\n+        fprintf(stderr, \"%s: failed to open '%s'\\n\", __func__, fname.c_str());\n+        return false;\n+    }\n+\n+    // verify magic\n+    {\n+        uint32_t magic;\n+        fin.read((char *) &magic, sizeof(magic));\n+        if (magic != 0x67676d6c) {\n+            fprintf(stderr, \"%s: invalid model file '%s' (bad magic)\\n\", __func__, fname.c_str());\n+            return false;\n+        }\n+    }\n+\n+    // load hparams\n+    {\n+        auto & hparams = model.hparams;\n+\n+        fin.read((char *) &hparams.n_vocab, sizeof(hparams.n_vocab));\n+        fin.read((char *) &hparams.n_embd,  sizeof(hparams.n_embd));\n+        fin.read((char *) &hparams.n_head,  sizeof(hparams.n_head));\n+        fin.read((char *) &hparams.n_layer, sizeof(hparams.n_layer));\n+        fin.read((char *) &hparams.ftype,   sizeof(hparams.ftype));\n+\n+        const int32_t qntvr = hparams.ftype / GGML_QNT_VERSION_FACTOR;\n+\n+        printf(\"%s: n_vocab = %d\\n\", __func__, hparams.n_vocab);\n+        printf(\"%s: n_embd  = %d\\n\", __func__, hparams.n_embd);\n+        printf(\"%s: n_head  = %d\\n\", __func__, hparams.n_head);\n+        printf(\"%s: n_layer = %d\\n\", __func__, hparams.n_layer);\n+        printf(\"%s: ftype   = %d\\n\", __func__, hparams.ftype);\n+        printf(\"%s: qntvr   = %d\\n\", __func__, qntvr);\n+\n+        hparams.ftype %= GGML_QNT_VERSION_FACTOR;\n+    }\n+\n+    // load vocab\n+    {\n+        const int32_t n_vocab = model.hparams.n_vocab;\n+\n+        std::string word;\n+        std::vector<char> buf(128);\n+\n+        for (int i = 0; i < n_vocab; i++) {\n+            uint32_t len;\n+            fin.read((char *) &len, sizeof(len));\n+\n+            buf.resize(len);\n+            fin.read((char *) buf.data(), len);\n+            word.assign(buf.data(), len);\n+\n+            vocab.token_to_id[word] = i;\n+            vocab.id_to_token[i] = word;\n+        }\n+    }\n+\n+    // for the big tensors, we have the option to store the data in 16-bit floats or quantized\n+    // in order to save memory and also to speed up the computation\n+    ggml_type wtype = ggml_ftype_to_ggml_type((ggml_ftype) (model.hparams.ftype));\n+    if (wtype == GGML_TYPE_COUNT) {\n+        fprintf(stderr, \"%s: invalid model file '%s' (bad ftype value %d)\\n\",\n+                __func__, fname.c_str(), model.hparams.ftype);\n+        return false;\n+    }\n+\n+    auto & ctx = model.ctx;\n+\n+    size_t ctx_size = 0;\n+\n+    {\n+        const auto& hparams = model.hparams;\n+\n+        const int n_embd = hparams.n_embd;\n+        const int n_head = hparams.n_head;\n+        const int n_layer = hparams.n_layer;\n+        const int n_ctx = hparams.n_ctx;\n+        const int n_ff = 4 * model.hparams.n_embd;\n+        const int n_vocab = hparams.n_vocab;\n+        const int head_dim = hparams.n_embd / hparams.n_head;\n+\n+        ctx_size +=\n+            n_embd * n_vocab * ggml_type_sizef(wtype);  // tok_embeddings\n+\n+        ctx_size += n_embd * ggml_type_sizef(GGML_TYPE_F32);  // output_norm\n+        ctx_size += n_embd * ggml_type_sizef(GGML_TYPE_F32);  // output_norm_b\n+\n+        ctx_size += n_embd * n_vocab * ggml_type_sizef(wtype);  // lm_head\n+\n+        ctx_size +=\n+            n_layer *\n+            (n_embd * ggml_type_sizef(GGML_TYPE_F32));  // attention_norm\n+        ctx_size +=\n+            n_layer *\n+            (n_embd * ggml_type_sizef(GGML_TYPE_F32));  // attention_norm_b\n+\n+        ctx_size += n_layer * (n_embd * (n_embd + 2 * (n_embd / n_head)) *\n+                               ggml_type_sizef(wtype));  // query_key_value\n+        ctx_size += n_layer * (n_embd * n_embd * ggml_type_sizef(wtype));  // wo\n+\n+        ctx_size +=\n+            n_layer * (n_embd * ggml_type_sizef(GGML_TYPE_F32));  // ffn_norm\n+        ctx_size +=\n+            n_layer * (n_embd * ggml_type_sizef(GGML_TYPE_F32));  // ffn_norm_b\n+\n+        ctx_size +=\n+            n_layer * (n_ff * n_embd * ggml_type_sizef(wtype));  // ffn_up\n+        ctx_size +=\n+            n_layer * (n_ff * n_embd * ggml_type_sizef(wtype));  // ffn_down\n+\n+        ctx_size += n_ctx * n_layer * head_dim *\n+                    ggml_type_sizef(GGML_TYPE_F32);  // memory_k\n+        ctx_size += n_ctx * n_layer * head_dim *\n+                    ggml_type_sizef(GGML_TYPE_F32);  // memory_v\n+\n+        ctx_size += (5 + 10 * n_layer) * 256;  // object overhead TODO:\n+        printf(\"%s: ggml ctx size = %6.2f MB\\n\", __func__, ctx_size/(1024.0*1024.0));\n+    }\n+\n+    // create the ggml context\n+    {\n+        struct ggml_init_params params = {\n+            .mem_size   = ctx_size,\n+            .mem_buffer = NULL,\n+            .no_alloc   = false,\n+        };\n+\n+        model.ctx = ggml_init(params);\n+        if (!model.ctx) {\n+            fprintf(stderr, \"%s: ggml_init() failed\\n\", __func__);\n+            return false;\n+        }\n+    }\n+\n+    // prepare memory for the weights\n+    {\n+        const auto& hparams = model.hparams;\n+\n+        const int n_embd = hparams.n_embd;\n+        const int n_head = hparams.n_head;\n+        const int n_layer = hparams.n_layer;\n+        const int n_ff = 4 * model.hparams.n_embd;\n+        const int n_vocab = hparams.n_vocab;\n+\n+        model.layers.resize(n_layer);\n+\n+        model.tok_embeddings = ggml_new_tensor_2d(ctx, wtype, n_embd, n_vocab);\n+\n+        model.output_norm = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_embd);\n+        model.output_norm_b = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_embd);\n+        model.lm_head = ggml_new_tensor_2d(ctx, wtype, n_embd, n_vocab);\n+\n+        // map by name\n+        model.tensors[\"transformer.word_embeddings.weight\"] =\n+            model.tok_embeddings;\n+\n+        model.tensors[\"transformer.ln_f.weight\"] = model.output_norm;\n+        model.tensors[\"transformer.ln_f.bias\"] = model.output_norm_b;\n+        model.tensors[\"lm_head.weight\"] = model.lm_head;\n+\n+        for (int i = 0; i < n_layer; ++i) {\n+            auto& layer = model.layers[i];\n+\n+            layer.attention_norm =\n+                ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_embd);\n+            layer.attention_norm_b =\n+                ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_embd);\n+\n+            // query_key_value shape for config.multi_query == True:\n+            layer.query_key_value = ggml_new_tensor_2d(\n+                ctx, wtype, n_embd, n_embd + 2 * (n_embd / n_head));\n+            layer.wo = ggml_new_tensor_2d(ctx, wtype, n_embd, n_embd);\n+\n+            layer.ffn_up = ggml_new_tensor_2d(ctx, wtype, n_embd, n_ff);\n+            layer.ffn_down = ggml_new_tensor_2d(ctx, wtype, n_ff, n_embd);\n+\n+            // map by name\n+            model.tensors[\"transformer.h.\" + std::to_string(i) +\n+                          \".input_layernorm.weight\"] = layer.attention_norm;\n+            model.tensors[\"transformer.h.\" + std::to_string(i) +\n+                          \".input_layernorm.bias\"] = layer.attention_norm_b;\n+\n+            model.tensors[\"transformer.h.\" + std::to_string(i) +\n+                          \".self_attention.query_key_value.weight\"] =\n+                layer.query_key_value;\n+            model.tensors[\"transformer.h.\" + std::to_string(i) +\n+                          \".self_attention.dense.weight\"] = layer.wo;\n+\n+            model.tensors[\"transformer.h.\" + std::to_string(i) +\n+                          \".mlp.dense_h_to_4h.weight\"] = layer.ffn_up;\n+            model.tensors[\"transformer.h.\" + std::to_string(i) +\n+                          \".mlp.dense_4h_to_h.weight\"] = layer.ffn_down;\n+        }\n+    }\n+\n+    // key + value memory\n+    {\n+        const auto & hparams = model.hparams;\n+\n+        const int n_layer = hparams.n_layer;\n+        const int n_ctx   = hparams.n_ctx;\n+        const int head_dim = hparams.n_embd / hparams.n_head;\n+\n+        const int64_t n_mem      = n_layer*n_ctx;\n+        const int64_t n_elements = head_dim*n_mem;\n+\n+        model.memory_k = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_elements);\n+        model.memory_v = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_elements);\n+\n+        const size_t memory_size = ggml_nbytes(model.memory_k) + ggml_nbytes(model.memory_v);\n+\n+        printf(\"%s: memory_size = %8.2f MB, n_mem = %\" PRId64 \"\\n\", __func__, memory_size/1024.0/1024.0, n_mem);\n+    }\n+\n+    // load weights\n+    {\n+        int n_tensors = 0;\n+        size_t total_size = 0;\n+\n+        printf(\"%s: \", __func__);\n+\n+        while (true) {\n+            int32_t n_dims;\n+            int32_t length;\n+            int32_t ttype;\n+\n+            fin.read(reinterpret_cast<char *>(&n_dims), sizeof(n_dims));\n+            fin.read(reinterpret_cast<char *>(&length), sizeof(length));\n+            fin.read(reinterpret_cast<char *>(&ttype),  sizeof(ttype));\n+\n+            if (fin.eof()) {\n+                break;\n+            }\n+\n+            int32_t nelements = 1;\n+            int32_t ne[2] = { 1, 1 };\n+            for (int i = 0; i < n_dims; ++i) {\n+                fin.read(reinterpret_cast<char *>(&ne[i]), sizeof(ne[i]));\n+                nelements *= ne[i];\n+            }\n+\n+            std::string name(length, 0);\n+            fin.read(&name[0], length);\n+\n+            if (model.tensors.find(name.data()) == model.tensors.end()) {\n+                fprintf(stderr, \"%s: unknown tensor '%s' in model file\\n\", __func__, name.data());\n+                return false;\n+            }\n+\n+            auto tensor = model.tensors[name.data()];\n+            if (ggml_nelements(tensor) != nelements) {\n+                fprintf(stderr, \"%s: tensor '%s' has wrong size in model file\\n\", __func__, name.data());\n+                return false;\n+            }\n+\n+            if (tensor->ne[0] != ne[0] || tensor->ne[1] != ne[1]) {\n+                fprintf(stderr, \"%s: tensor '%s' has wrong shape in model file: got [%5d, %5d], expected [%5d, %5d]\\n\",\n+                        __func__, name.data(), (int) tensor->ne[0], (int) tensor->ne[1], ne[0], ne[1]);\n+                return false;\n+            }\n+\n+            // for debugging\n+            if (0) {\n+                printf(\"%24s - [%5d, %5d], type = %6s, %6.2f MB, %9zu bytes\\n\", name.data(), ne[0], ne[1], ggml_type_name(ggml_type(ttype)), ggml_nbytes(tensor)/1024.0/1024.0, ggml_nbytes(tensor));\n+            }\n+\n+            const size_t bpe = ggml_type_size(ggml_type(ttype));\n+\n+            if ((nelements*bpe)/ggml_blck_size(tensor->type) != ggml_nbytes(tensor)) {\n+                fprintf(stderr, \"%s: tensor '%s' has wrong size in model file: got %zu, expected %zu\\n\",\n+                        __func__, name.data(), ggml_nbytes(tensor), nelements*bpe);\n+                return false;\n+            }\n+\n+            fin.read(reinterpret_cast<char *>(tensor->data), ggml_nbytes(tensor));\n+\n+            total_size += ggml_nbytes(tensor);\n+            if (++n_tensors % 8 == 0) {\n+                printf(\".\");\n+                fflush(stdout);\n+            }\n+        }\n+\n+        printf(\" done\\n\");\n+\n+        printf(\"%s: model size = %8.2f MB / num tensors = %d\\n\", __func__, total_size/1024.0/1024.0, n_tensors);\n+    }\n+\n+    fin.close();\n+\n+    return true;\n+}\n+\n+\n+// evaluate the transformer\n+//\n+//   - model:     the model\n+//   - n_threads: number of threads to use\n+//   - n_past:    the context size so far\n+//   - embd_inp:  the embeddings of the tokens in the context\n+//   - embd_w:    the predicted logits for the next token\n+//\n+bool falcon_eval(\n+        const falcon_model & model,\n+        const int n_threads,\n+        const int n_past,\n+        const std::vector<gpt_vocab::id> & embd_inp,\n+              std::vector<float>         & embd_w,\n+              size_t                     & mem_per_token) {\n+    const int N = embd_inp.size();\n+\n+    const auto & hparams = model.hparams;\n+\n+    const int n_embd  = hparams.n_embd;\n+    const int n_layer = hparams.n_layer;\n+    const int n_ctx   = hparams.n_ctx;\n+    const int n_head  = hparams.n_head;\n+    const int n_vocab = hparams.n_vocab;\n+    const size_t head_dim = n_embd / n_head;\n+\n+    static size_t buf_size = 256u*1024*1024;\n+    static void * buf = malloc(buf_size);\n+\n+    // use 2 scratch buffers\n+    // TODO: very hacky solution - reimplement in a more elegant way\n+    static size_t scr0_size = 256u*1024*1024;\n+    static void * scr0 = malloc(scr0_size);\n+\n+    static size_t scr1_size = 256u*1024*1024;\n+    static void * scr1 = malloc(scr1_size);\n+\n+    if (mem_per_token > 0 && mem_per_token*N > buf_size) {\n+        const size_t buf_size_new = 1.1*(mem_per_token*N); // add 10% to account for ggml object overhead\n+        //printf(\"\\n%s: reallocating buffer from %zu to %zu bytes\\n\", __func__, buf_size, buf_size_new);\n+\n+        // reallocate\n+        buf_size = buf_size_new;\n+        buf = realloc(buf, buf_size);\n+        if (buf == nullptr) {\n+            fprintf(stderr, \"%s: failed to allocate %zu bytes\\n\", __func__, buf_size);\n+            return false;\n+        }\n+    }\n+\n+    struct ggml_init_params params = {\n+        .mem_size   = buf_size,\n+        .mem_buffer = buf,\n+        .no_alloc   = false,\n+    };\n+\n+    struct ggml_context * ctx0 = ggml_init(params);\n+    struct ggml_cgraph gf = {};\n+    gf.n_threads = n_threads;\n+\n+    struct ggml_tensor * embd = ggml_new_tensor_1d(ctx0, GGML_TYPE_I32, N);\n+    memcpy(embd->data, embd_inp.data(), N*ggml_element_size(embd));\n+\n+    // wte\n+    struct ggml_tensor * inpL = ggml_get_rows(ctx0, model.tok_embeddings, embd);\n+    struct ggml_tensor* repeat_dummy = ggml_new_tensor_3d(ctx0, inpL->type, head_dim, N + n_past, n_head);\n+\n+    for (int il = 0; il < n_layer; ++il) {\n+        struct ggml_tensor * cur;\n+        struct ggml_tensor * layernorm_output;\n+\n+        ggml_set_scratch(ctx0, { 0, scr0_size, scr0, });\n+\n+        // self-attention\n+        {\n+            {\n+                cur = ggml_norm(ctx0, inpL);\n+\n+                cur = ggml_add(ctx0,\n+                        ggml_mul(ctx0,\n+                            ggml_repeat(ctx0, model.layers[il].attention_norm, cur),\n+                            cur),\n+                        ggml_repeat(ctx0, model.layers[il].attention_norm_b, cur));\n+            }\n+            layernorm_output = cur;\n+\n+            // compute QKV\n+            cur = ggml_mul_mat(ctx0, model.layers[il].query_key_value, cur);\n+\n+            size_t fused_qkv_row_nb =\n+                (n_embd + 2 * (n_embd / n_head)) * sizeof(float);\n+\n+            struct ggml_tensor* Qcur =\n+                ggml_view_3d(ctx0, cur, head_dim, n_head, N,\n+                             head_dim * sizeof(float), fused_qkv_row_nb, 0);\n+\n+            struct ggml_tensor* Kcur = ggml_view_3d(\n+                ctx0, cur, head_dim, 1, N, head_dim * sizeof(float),\n+                fused_qkv_row_nb, n_embd * sizeof(float));\n+\n+            struct ggml_tensor* Vcur = ggml_view_3d(\n+                ctx0, cur, head_dim, 1, N, head_dim * sizeof(float),\n+                fused_qkv_row_nb, (n_embd + head_dim) * sizeof(float));\n+\n+            // using mode = 2 for neox mode\n+            Qcur = ggml_rope_inplace(ctx0, Qcur, n_past, head_dim, 2);\n+            Kcur = ggml_rope_inplace(ctx0, Kcur, n_past, head_dim, 2);\n+\n+            // store key and value to memory\n+            {\n+                struct ggml_tensor* k = ggml_view_1d(\n+                    ctx0, model.memory_k, N * head_dim,\n+                    (ggml_element_size(model.memory_k) * head_dim) *\n+                        (il * n_ctx + n_past));\n+                struct ggml_tensor* v = ggml_view_1d(\n+                    ctx0, model.memory_v, N * head_dim,\n+                    (ggml_element_size(model.memory_v) * head_dim) *\n+                        (il * n_ctx + n_past));\n+\n+                ggml_build_forward_expand(&gf, ggml_cpy(ctx0, Kcur, k));\n+                ggml_build_forward_expand(&gf, ggml_cpy(ctx0, Vcur, v));\n+            }\n+\n+            // Q = Qcur.contiguous().view(n_embd/n_head, n_head, N).permute(0, 2, 1, 3)\n+            struct ggml_tensor * Q =\n+                ggml_permute(ctx0,\n+                        Qcur,\n+                        0, 2, 1, 3);\n+\n+            struct ggml_tensor* K = ggml_permute(\n+                ctx0,\n+                ggml_reshape_3d(\n+                    ctx0,\n+                    ggml_view_1d(ctx0, model.memory_k, (n_past + N) * head_dim,\n+                                 il * n_ctx *\n+                                     ggml_element_size(model.memory_k) *\n+                                     head_dim),\n+                    head_dim, 1, n_past + N),\n+                0, 2, 1, 3);\n+\n+            // K * Q\n+            K = ggml_cont(ctx0, ggml_repeat(ctx0, K, repeat_dummy));\n+            struct ggml_tensor * KQ = ggml_mul_mat(ctx0, K, Q);\n+\n+            // KQ_scaled = KQ / sqrt(n_embd/n_head)\n+            struct ggml_tensor * KQ_scaled =\n+                ggml_scale_inplace(ctx0,\n+                        KQ,\n+                        ggml_new_f32(ctx0, 1.0f/sqrt(float(n_embd)/n_head))\n+                        );\n+\n+            // KQ_masked = mask_past(KQ_scaled)\n+            struct ggml_tensor * KQ_masked = ggml_diag_mask_inf_inplace(ctx0, KQ_scaled, n_past);\n+\n+            // KQ = soft_max(KQ_masked)\n+            struct ggml_tensor * KQ_soft_max = ggml_soft_max_inplace(ctx0, KQ_masked);\n+\n+            // V_trans = Vmem.view(n_embd/n_head, n_head, n_past + N).permute(1, 2, 0, 3).contiguous()\n+            struct ggml_tensor* V = ggml_permute(\n+                ctx0,\n+                ggml_reshape_3d(\n+                    ctx0,\n+                    ggml_view_1d(ctx0, model.memory_v, (n_past + N) * head_dim,\n+                                 il * n_ctx *\n+                                     ggml_element_size(model.memory_v) *\n+                                     head_dim),\n+                    head_dim, 1, n_past + N),\n+                0, 2, 1, 3);\n+            \n+            V = ggml_cont(ctx0, ggml_transpose(ctx0, ggml_repeat(ctx0, V, repeat_dummy)));\n+\n+            // KQV = transpose(V) * KQ_soft_max\n+            struct ggml_tensor * KQV = ggml_mul_mat(ctx0, V, KQ_soft_max);\n+\n+            // KQV_merged = KQV.permute(0, 2, 1, 3)\n+            struct ggml_tensor * KQV_merged = ggml_permute(ctx0, KQV, 0, 2, 1, 3);\n+\n+            // cur = KQV_merged.contiguous().view(n_embd, N)\n+            cur = ggml_cpy(ctx0,\n+                    KQV_merged,\n+                    ggml_new_tensor_2d(ctx0, GGML_TYPE_F32, n_embd, N));\n+\n+            // projection\n+            {\n+                cur = ggml_mul_mat(ctx0,\n+                        model.layers[il].wo,\n+                        cur);\n+            }\n+        }\n+\n+        ggml_set_scratch(ctx0, { 0, scr1_size, scr1, });\n+\n+        struct ggml_tensor* inpFF = layernorm_output;\n+        struct ggml_tensor* attn_out = ggml_cpy(\n+            ctx0, cur, ggml_new_tensor_2d(ctx0, GGML_TYPE_F32, n_embd, N));\n+\n+        {\n+            cur = ggml_mul_mat(ctx0, model.layers[il].ffn_up, inpFF);\n+            cur = ggml_gelu(ctx0, cur);\n+            cur = ggml_mul_mat(ctx0, model.layers[il].ffn_down, cur);\n+        }\n+\n+        cur = ggml_add(ctx0, cur, attn_out);\n+        cur = ggml_add(ctx0, cur, inpL);\n+        // input for next layer\n+        inpL = cur;\n+    }\n+\n+    ggml_set_scratch(ctx0, { 0, scr0_size, scr0, });\n+\n+    // norm\n+    {\n+        inpL = ggml_norm(ctx0, inpL);\n+\n+        // inpL = ln_f_g*inpL + ln_f_b\n+        inpL = ggml_add(ctx0,\n+                ggml_mul(ctx0,\n+                    ggml_repeat(ctx0, model.output_norm, inpL),\n+                    inpL),\n+                ggml_repeat(ctx0, model.output_norm_b, inpL));\n+    }\n+\n+    ggml_set_scratch(ctx0, { 0, 0, nullptr, });\n+\n+    // lm_head\n+    {\n+        inpL = ggml_mul_mat(ctx0, model.lm_head, inpL);\n+\n+        //inpL = ggml_add(ctx0,\n+        //        ggml_repeat(ctx0, model.lmh_b, inpL),\n+        //        inpL);\n+    }\n+\n+    // logits -> probs\n+    //inpL = ggml_soft_max_inplace(ctx0, inpL);\n+\n+    // run the computation\n+    ggml_build_forward_expand(&gf, inpL);\n+    ggml_graph_compute       (ctx0, &gf);\n+\n+    //if (n_past%100 == 0) {\n+    //    ggml_graph_print   (&gf);\n+    //    ggml_graph_dump_dot(&gf, NULL, \"gpt-2.dot\");\n+    //}\n+\n+    //embd_w.resize(n_vocab*N);\n+    //memcpy(embd_w.data(), ggml_get_data(inpL), sizeof(float)*n_vocab*N);\n+\n+    // return result for just the last token\n+    embd_w.resize(n_vocab);\n+    memcpy(embd_w.data(), (float *) ggml_get_data(inpL) + (n_vocab*(N-1)), sizeof(float)*n_vocab);\n+\n+    if (mem_per_token == 0) {\n+        mem_per_token = ggml_used_mem(ctx0)/N;\n+    }\n+    //printf(\"used_mem = %zu\\n\", ggml_used_mem(ctx0));\n+\n+    ggml_free(ctx0);\n+\n+    return true;\n+}\n+\n+int main(int argc, char ** argv) {\n+    ggml_time_init();\n+\n+    const int64_t t_main_start_us = ggml_time_us();\n+\n+    gpt_params params;\n+    params.model = \"models/falcon-7b/ggml-model-f16.bin\";\n+\n+    if (gpt_params_parse(argc, argv, params) == false) {\n+        return 1;\n+    }\n+\n+    if (params.seed < 0) {\n+        params.seed = time(NULL);\n+    }\n+\n+    printf(\"%s: seed = %d\\n\", __func__, params.seed);\n+\n+    std::mt19937 rng(params.seed);\n+    if (params.prompt.empty()) {\n+        params.prompt = gpt_random_prompt(rng);\n+    }\n+\n+    int64_t t_load_us = 0;\n+\n+    gpt_vocab vocab;\n+    falcon_model model;\n+\n+    // load the model\n+    {\n+        const int64_t t_start_us = ggml_time_us();\n+\n+        if (!falcon_model_load(params.model, model, vocab)) {\n+            fprintf(stderr, \"%s: failed to load model from '%s'\\n\", __func__, params.model.c_str());\n+            return 1;\n+        }\n+\n+        t_load_us = ggml_time_us() - t_start_us;\n+\n+        test_gpt_tokenizer(vocab, params.token_test);\n+    }\n+\n+    int n_past = 0;\n+\n+    int64_t t_sample_us  = 0;\n+    int64_t t_predict_us = 0;\n+\n+    std::vector<float> logits;\n+\n+    // tokenize the prompt\n+    std::vector<gpt_vocab::id> embd_inp = ::gpt_tokenize(vocab, params.prompt);\n+\n+    params.n_predict = std::min(params.n_predict, model.hparams.n_ctx - (int) embd_inp.size());\n+\n+    printf(\"%s: number of tokens in prompt = %zu\\n\", __func__, embd_inp.size());\n+    for (int i = 0; i < embd_inp.size(); i++) {\n+        printf(\"%s: token[%d] = %6d, %s\\n\", __func__, i, embd_inp[i], vocab.id_to_token.at(embd_inp[i]).c_str());\n+    }\n+    printf(\"\\n\");\n+\n+    std::vector<gpt_vocab::id> embd;\n+\n+    // determine the required inference memory per token:\n+    size_t mem_per_token = 0;\n+    falcon_eval(model, params.n_threads, 0, { 0, 1, 2, 3 }, logits, mem_per_token);\n+\n+    for (int i = embd.size(); i < embd_inp.size() + params.n_predict; i++) {\n+        // predict\n+        if (embd.size() > 0) {\n+            const int64_t t_start_us = ggml_time_us();\n+\n+            if (!falcon_eval(model, params.n_threads, n_past, embd, logits, mem_per_token)) {\n+                printf(\"Failed to predict\\n\");\n+                return 1;\n+            }\n+\n+            t_predict_us += ggml_time_us() - t_start_us;\n+        }\n+\n+        n_past += embd.size();\n+        embd.clear();\n+\n+        if (i >= embd_inp.size()) {\n+            // sample next token\n+            const int   top_k = params.top_k;\n+            const float top_p = params.top_p;\n+            const float temp  = params.temp;\n+\n+            const int n_vocab = model.hparams.n_vocab;\n+\n+            gpt_vocab::id id = 0;\n+\n+            {\n+                const int64_t t_start_sample_us = ggml_time_us();\n+\n+                id = gpt_sample_top_k_top_p(vocab, logits.data() + (logits.size() - n_vocab), top_k, top_p, temp, rng);\n+\n+                t_sample_us += ggml_time_us() - t_start_sample_us;\n+            }\n+\n+            // add it to the context\n+            embd.push_back(id);\n+        } else {\n+            // if here, it means we are still processing the input prompt\n+            for (int k = i; k < embd_inp.size(); k++) {\n+                embd.push_back(embd_inp[k]);\n+                if (embd.size() > params.n_batch) {\n+                    break;\n+                }\n+            }\n+            i += embd.size() - 1;\n+        }\n+\n+        // display text\n+        for (auto id : embd) {\n+            printf(\"%s\", vocab.id_to_token[id].c_str());\n+        }\n+        fflush(stdout);\n+\n+        // end of text token\n+        if (embd.back() == 0) {\n+            break;\n+        }\n+    }\n+\n+    // report timing\n+    {\n+        const int64_t t_main_end_us = ggml_time_us();\n+\n+        printf(\"\\n\\n\");\n+        printf(\"%s: mem per token = %8zu bytes\\n\", __func__, mem_per_token);\n+        printf(\"%s:     load time = %8.2f ms\\n\", __func__, t_load_us/1000.0f);\n+        printf(\"%s:   sample time = %8.2f ms\\n\", __func__, t_sample_us/1000.0f);\n+        printf(\"%s:  predict time = %8.2f ms / %.2f ms per token\\n\", __func__, t_predict_us/1000.0f, t_predict_us/1000.0f/n_past);\n+        printf(\"%s:    total time = %8.2f ms\\n\", __func__, (t_main_end_us - t_main_start_us)/1000.0f);\n+    }\n+\n+    ggml_free(model.ctx);\n+\n+    return 0;\n+}\n\\ No newline at end of file\ndiff --git a/examples/falcon/quantize.cpp b/examples/falcon/quantize.cpp\nnew file mode 100644\nindex 000000000..34de50410\n--- /dev/null\n+++ b/examples/falcon/quantize.cpp\n@@ -0,0 +1,167 @@\n+#include \"ggml/ggml.h\"\n+\n+#include \"common.h\"\n+#include \"common-ggml.h\"\n+\n+#include <cassert>\n+#include <cmath>\n+#include <cstdio>\n+#include <cstring>\n+#include <fstream>\n+#include <map>\n+#include <string>\n+#include <vector>\n+#include <regex>\n+\n+// default hparams (Falcon 7B)\n+struct falcon_hparams {\n+    int32_t n_vocab = 65024;\n+    int32_t n_embd  = 4544;\n+    int32_t n_head  = 71;\n+    int32_t n_layer = 32;\n+    int32_t ftype   = 1;\n+};\n+\n+// quantize a model\n+bool falcon_model_quantize(const std::string & fname_inp, const std::string & fname_out, ggml_ftype ftype) {\n+    gpt_vocab vocab;\n+\n+    printf(\"%s: loading model from '%s'\\n\", __func__, fname_inp.c_str());\n+\n+    auto finp = std::ifstream(fname_inp, std::ios::binary);\n+    if (!finp) {\n+        fprintf(stderr, \"%s: failed to open '%s' for reading\\n\", __func__, fname_inp.c_str());\n+        return false;\n+    }\n+\n+    auto fout = std::ofstream(fname_out, std::ios::binary);\n+    if (!fout) {\n+        fprintf(stderr, \"%s: failed to open '%s' for writing\\n\", __func__, fname_out.c_str());\n+        return false;\n+    }\n+\n+    // verify magic\n+    {\n+        uint32_t magic;\n+        finp.read((char *) &magic, sizeof(magic));\n+        if (magic != 0x67676d6c) {\n+            fprintf(stderr, \"%s: invalid model file '%s' (bad magic)\\n\", __func__, fname_inp.c_str());\n+            return false;\n+        }\n+\n+        fout.write((char *) &magic, sizeof(magic));\n+    }\n+\n+    falcon_hparams hparams;\n+\n+    // load hparams\n+    {\n+        finp.read((char *) &hparams.n_vocab, sizeof(hparams.n_vocab));\n+        finp.read((char *) &hparams.n_embd,  sizeof(hparams.n_embd));\n+        finp.read((char *) &hparams.n_head,  sizeof(hparams.n_head));\n+        finp.read((char *) &hparams.n_layer, sizeof(hparams.n_layer));\n+        finp.read((char *) &hparams.ftype,   sizeof(hparams.ftype));\n+\n+        const int32_t qntvr_src =    hparams.ftype / GGML_QNT_VERSION_FACTOR;\n+        const int32_t ftype_dst = GGML_QNT_VERSION * GGML_QNT_VERSION_FACTOR + ftype;\n+\n+        printf(\"%s: n_vocab     = %d\\n\", __func__, hparams.n_vocab);\n+        printf(\"%s: n_embd      = %d\\n\", __func__, hparams.n_embd);\n+        printf(\"%s: n_head      = %d\\n\", __func__, hparams.n_head);\n+        printf(\"%s: n_layer     = %d\\n\", __func__, hparams.n_layer);\n+        printf(\"%s: ftype (src) = %d\\n\", __func__, hparams.ftype);\n+        printf(\"%s: qntvr (src) = %d\\n\", __func__, qntvr_src);\n+        printf(\"%s: ftype (dst) = %d\\n\", __func__, ftype_dst);\n+        printf(\"%s: qntvr (dst) = %d\\n\", __func__, GGML_QNT_VERSION);\n+\n+        fout.write((char *) &hparams.n_vocab, sizeof(hparams.n_vocab));\n+        fout.write((char *) &hparams.n_embd,  sizeof(hparams.n_embd));\n+        fout.write((char *) &hparams.n_head,  sizeof(hparams.n_head));\n+        fout.write((char *) &hparams.n_layer, sizeof(hparams.n_layer));\n+        fout.write((char *) &ftype_dst,       sizeof(ftype_dst));\n+    }\n+\n+    // load vocab\n+    {\n+        const int32_t n_vocab = hparams.n_vocab;\n+\n+        std::string word;\n+        for (int i = 0; i < n_vocab; i++) {\n+            uint32_t len;\n+            finp.read ((char *) &len, sizeof(len));\n+            fout.write((char *) &len, sizeof(len));\n+\n+            word.resize(len);\n+            finp.read ((char *) word.data(), len);\n+            fout.write((char *) word.data(), len);\n+\n+            vocab.token_to_id[word] = i;\n+            vocab.id_to_token[i] = word;\n+        }\n+    }\n+\n+    // regexes of tensor names to be quantized\n+    const std::vector<std::string> to_quant = {\n+        \".*weight\",\n+    };\n+\n+    if (!ggml_common_quantize_0(finp, fout, ftype, to_quant, {})) {\n+        fprintf(stderr, \"%s: failed to quantize model '%s'\\n\", __func__, fname_inp.c_str());\n+        return false;\n+    }\n+\n+    finp.close();\n+    fout.close();\n+\n+    return true;\n+}\n+\n+// usage:\n+//  ./falcon-quantize models/stalellm2-117M/ggml-model.bin models/stablelm2-117M/ggml-model-quant.bin type\n+//\n+int main(int argc, char ** argv) {\n+    if (argc != 4) {\n+        fprintf(stderr, \"usage: %s model-f32.bin model-quant.bin type\\n\", argv[0]);\n+        ggml_print_ftypes(stderr);\n+        return 1;\n+    }\n+\n+    // needed to initialize f16 tables\n+    {\n+        struct ggml_init_params params = { 0, NULL, false };\n+        struct ggml_context * ctx = ggml_init(params);\n+        ggml_free(ctx);\n+    }\n+\n+    const std::string fname_inp = argv[1];\n+    const std::string fname_out = argv[2];\n+\n+    const ggml_ftype ftype = ggml_parse_ftype(argv[3]);\n+\n+    const int64_t t_main_start_us = ggml_time_us();\n+\n+    int64_t t_quantize_us = 0;\n+\n+    // load the model\n+    {\n+        const int64_t t_start_us = ggml_time_us();\n+\n+        if (!falcon_model_quantize(fname_inp, fname_out, ggml_ftype(ftype))) {\n+            fprintf(stderr, \"%s: failed to quantize model from '%s'\\n\", __func__, fname_inp.c_str());\n+            return 1;\n+        }\n+\n+        t_quantize_us = ggml_time_us() - t_start_us;\n+    }\n+\n+    // report timing\n+    {\n+        const int64_t t_main_end_us = ggml_time_us();\n+\n+        printf(\"\\n\");\n+        printf(\"%s: quantize time = %8.2f ms\\n\", __func__, t_quantize_us/1000.0f);\n+        printf(\"%s:    total time = %8.2f ms\\n\", __func__, (t_main_end_us - t_main_start_us)/1000.0f);\n+    }\n+\n+    return 0;\n+}\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. The current implementation uses `ggml_repeat` with copies; create a new repeat operation tailored for broadcasting to prevent issues with tensor shapes.\n\n2. Existing `ggml_repeat` only handles `float32`. Consider implementing `ggml_repeat2` to support other types and ensure backward compatibility.\n\n3. Increasing `ctx_size` is crucial; current adjustments to `ctx_size += 3 * 1024 * 1024 * 1024` and `GGML_MAX_NODES` to 262144 are necessary for 40B model support.\n\n4. Simplify the query head logic to encourage easier debugging; consider handling reshuffling of the `qkv` tensor during model conversion.\n\n5. Ensure all models' tests are run to identify further bugs by adjusting memory and recomputing tensor configurations."
      }
    ],
    "codediff_length": 37482
  },
  {
    "index": 103,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.gitignore b/.gitignore\nindex 4bf0fa095..c86edad24 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -1,4 +1,6 @@\n build/\n+release/\n+debug/\n build-*/\n out/\n tmp/\ndiff --git a/include/ggml-alloc.h b/include/ggml-alloc.h\nindex 2cb150fd2..fcd6566b4 100644\n--- a/include/ggml-alloc.h\n+++ b/include/ggml-alloc.h\n@@ -53,8 +53,8 @@ GGML_API void           ggml_gallocr_free(ggml_gallocr_t galloc);\n // call with a worst-case graph to avoid buffer reallocations\n // not strictly required for single buffer usage: ggml_gallocr_alloc_graph will reallocate the buffers automatically if needed\n // returns false if the buffer allocation failed\n-GGML_API bool ggml_gallocr_reserve(ggml_gallocr_t galloc, struct ggml_cgraph * graph);\n-GGML_API bool ggml_gallocr_reserve_n(\n+GGML_API enum ggml_status ggml_gallocr_reserve(ggml_gallocr_t galloc, struct ggml_cgraph * graph);\n+GGML_API enum ggml_status ggml_gallocr_reserve_n(\n     ggml_gallocr_t galloc,\n     struct ggml_cgraph * graph,\n     const int * node_buffer_ids,\ndiff --git a/src/ggml-alloc.c b/src/ggml-alloc.c\nindex a3d3f6901..499dab0fd 100644\n--- a/src/ggml-alloc.c\n+++ b/src/ggml-alloc.c\n@@ -94,7 +94,7 @@ enum ggml_status ggml_tallocr_alloc(struct ggml_tallocr * talloc, struct ggml_te\n     size = GGML_PAD(size, talloc->alignment);\n \n     if (talloc->offset + size > ggml_backend_buffer_get_size(talloc->buffer)) {\n-        GGML_LOG_ERROR(\"%s: not enough space in the buffer to allocate %s (needed %zu, available %zu)\\n\",\n+        GGML_LOG_ERROR(\"%s: not enough space in the buffer to allocate tensor '%s' (needed %zu, available %zu)\\n\",\n                 __func__, tensor->name, size, ggml_backend_buffer_get_size(talloc->buffer) - talloc->offset);\n         GGML_ABORT(\"not enough space in the buffer\");\n     }\n@@ -378,6 +378,7 @@ struct ggml_gallocr {\n };\n \n ggml_gallocr_t ggml_gallocr_new_n(ggml_backend_buffer_type_t * bufts, int n_bufs) {\n+    //GGML_LOG_TRACE(\"%s: nbufs=%d\\n\", __func__, n_bufs);\n     ggml_gallocr_t galloc = (ggml_gallocr_t)calloc(1, sizeof(struct ggml_gallocr));\n     GGML_ASSERT(galloc != NULL);\n \n@@ -670,7 +671,8 @@ static void ggml_gallocr_alloc_graph_impl(ggml_gallocr_t galloc, struct ggml_cgr\n     }\n }\n \n-bool ggml_gallocr_reserve_n(ggml_gallocr_t galloc, struct ggml_cgraph * graph, const int * node_buffer_ids, const int * leaf_buffer_ids) {\n+enum ggml_status ggml_gallocr_reserve_n(ggml_gallocr_t galloc, struct ggml_cgraph * graph, const int * node_buffer_ids, const int * leaf_buffer_ids) {\n+    //GGML_LOG_DEBUG(\"%s:  \\n\", __func__);\n     size_t min_hash_size = graph->n_nodes + graph->n_leafs;\n     // add 25% margin to avoid hash collisions\n     min_hash_size += min_hash_size / 4;\n@@ -771,16 +773,16 @@ bool ggml_gallocr_reserve_n(ggml_gallocr_t galloc, struct ggml_cgraph * graph, c\n             galloc->buffers[i] = ggml_backend_buft_alloc_buffer(galloc->bufts[i], new_size);\n             if (galloc->buffers[i] == NULL) {\n                 GGML_LOG_ERROR(\"%s: failed to allocate %s buffer of size %zu\\n\", __func__, ggml_backend_buft_name(galloc->bufts[i]), new_size);\n-                return false;\n+                return GGML_STATUS_ALLOC_FAILED;\n             }\n             ggml_backend_buffer_set_usage(galloc->buffers[i], GGML_BACKEND_BUFFER_USAGE_COMPUTE);\n         }\n     }\n \n-    return true;\n+    return GGML_STATUS_SUCCESS;\n }\n \n-bool ggml_gallocr_reserve(ggml_gallocr_t galloc, struct ggml_cgraph *graph) {\n+enum ggml_status ggml_gallocr_reserve(ggml_gallocr_t galloc, struct ggml_cgraph *graph) {\n     return ggml_gallocr_reserve_n(galloc, graph, NULL, NULL);\n }\n \n@@ -865,13 +867,16 @@ static bool ggml_gallocr_needs_realloc(ggml_gallocr_t galloc, struct ggml_cgraph\n     return false;\n }\n \n+// Check with reviewers: any cons to return a ggml_status here?\n bool ggml_gallocr_alloc_graph(ggml_gallocr_t galloc, struct ggml_cgraph * graph) {\n     if (ggml_gallocr_needs_realloc(galloc, graph)) {\n         if (galloc->n_buffers == 1) {\n #ifndef NDEBUG\n             GGML_LOG_DEBUG(\"%s: reallocating buffers automatically\\n\", __func__);\n #endif\n-            if (!ggml_gallocr_reserve(galloc, graph)) {\n+            enum ggml_status s = ggml_gallocr_reserve(galloc, graph);\n+            if (s != GGML_STATUS_SUCCESS) {\n+                GGML_LOG_INFO(\"%s: ggml_gallocr_reserve failed to reserve. status=%d \\n\", __func__, s);\n                 return false;\n             }\n         } else {\ndiff --git a/src/ggml-backend.cpp b/src/ggml-backend.cpp\nindex 273075f4e..6eab4ae7e 100644\n--- a/src/ggml-backend.cpp\n+++ b/src/ggml-backend.cpp\n@@ -40,8 +40,14 @@ ggml_backend_buffer_t ggml_backend_buft_alloc_buffer(ggml_backend_buffer_type_t\n         // return a dummy buffer for zero-sized allocations\n         return ggml_backend_buffer_init(buft, {}, NULL, 0);\n     }\n-\n-    return buft->iface.alloc_buffer(buft, size);\n+    ggml_backend_buffer_t b = NULL;\n+    try {\n+      b = buft->iface.alloc_buffer(buft, size);\n+    }  catch (const std::exception &e) {\n+        GGML_LOG_ERROR(\"%s: iface.alloc_buffer failed: %s \\n\", __func__, e.what());\n+        return NULL;\n+    }\n+    return b;\n }\n \n size_t ggml_backend_buft_get_alignment(ggml_backend_buffer_type_t buft) {\n@@ -174,6 +180,7 @@ enum ggml_backend_buffer_usage ggml_backend_buffer_get_usage(ggml_backend_buffer\n }\n \n ggml_backend_buffer_type_t ggml_backend_buffer_get_type(ggml_backend_buffer_t buffer) {\n+    assert(buffer);\n     return buffer->buft;\n }\n \n@@ -331,7 +338,16 @@ enum ggml_status ggml_backend_graph_compute(ggml_backend_t backend, struct ggml_\n }\n \n enum ggml_status ggml_backend_graph_compute_async(ggml_backend_t backend, struct ggml_cgraph * cgraph) {\n-    return backend->iface.graph_compute(backend, cgraph);\n+    ggml_status s;\n+    try {\n+        s = backend->iface.graph_compute(backend, cgraph);\n+    } catch(std::bad_alloc &e) {\n+        return GGML_STATUS_ALLOC_FAILED;\n+    }  catch (std::exception &e) {\n+        GGML_LOG_INFO(\"%s: graph_compute threw: %s\", __func__, e.what());\n+        return  GGML_STATUS_FAILED;\n+    }\n+    return s;\n }\n \n bool ggml_backend_supports_op(ggml_backend_t backend, const struct ggml_tensor * op) {\ndiff --git a/src/ggml-cuda/common.cuh b/src/ggml-cuda/common.cuh\nindex 8284a0017..f42376402 100644\n--- a/src/ggml-cuda/common.cuh\n+++ b/src/ggml-cuda/common.cuh\n@@ -136,8 +136,8 @@ static int ggml_cuda_highest_compiled_arch(const int arch) {\n \n #define GGML_CUDA_MAX_STREAMS 8\n \n-[[noreturn]]\n-void ggml_cuda_error(const char * stmt, const char * func, const char * file, int line, const char * msg);\n+// Print the error. Will also either abort or throw an exception.\n+[[noreturn]] void ggml_cuda_error(const char * stmt, const char * func, const char * file, int line, const char * msg);\n \n #define CUDA_CHECK_GEN(err, success, error_fn)                                      \\\n      do {                                                                           \\\n@@ -178,6 +178,7 @@ static const char * cu_get_error_str(CUresult err) {\n     cuGetErrorString(err, &err_str);\n     return err_str;\n }\n+// Will print error and abort/throw\n #define CU_CHECK(err) CUDA_CHECK_GEN(err, CUDA_SUCCESS, cu_get_error_str)\n #endif\n \ndiff --git a/src/ggml-cuda/ggml-cuda.cu b/src/ggml-cuda/ggml-cuda.cu\nindex 4af189701..f8952e17d 100644\n--- a/src/ggml-cuda/ggml-cuda.cu\n+++ b/src/ggml-cuda/ggml-cuda.cu\n@@ -72,7 +72,13 @@ void ggml_cuda_error(const char * stmt, const char * func, const char * file, in\n     GGML_LOG_ERROR(\"  current device: %d, in function %s at %s:%d\\n\", id, func, file, line);\n     GGML_LOG_ERROR(\"  %s\\n\", stmt);\n     // abort with GGML_ABORT to get a stack trace\n-    GGML_ABORT(GGML_CUDA_NAME \" error\");\n+    static const char* GGML_CUDA_NO_ABORT = getenv(\"GGML_CUDA_NO_ABORT\");\n+    if (!GGML_CUDA_NO_ABORT) {\n+        GGML_ABORT(GGML_CUDA_NAME \" error\");\n+    }\n+#ifndef __CUDA_ARCH__\n+    throw std::runtime_error(msg);\n+#endif\n }\n \n // this is faster on Windows\n@@ -94,6 +100,7 @@ int ggml_cuda_get_device() {\n     return id;\n }\n \n+// Note: Does not abort/throw because does not use CUDA_CHECK\n static cudaError_t ggml_cuda_device_malloc(void ** ptr, size_t size, int device) {\n     ggml_cuda_set_device(device);\n #if defined(GGML_USE_HIP) && defined(GGML_HIP_UMA)\n@@ -546,7 +553,8 @@ static void * ggml_backend_cuda_buffer_get_base(ggml_backend_buffer_t buffer) {\n \n static enum ggml_status ggml_backend_cuda_buffer_init_tensor(ggml_backend_buffer_t buffer, ggml_tensor * tensor) {\n     ggml_backend_cuda_buffer_context * ctx = (ggml_backend_cuda_buffer_context *)buffer->context;\n-\n+    GGML_ASSERT(tensor);\n+    GGML_LOG_DEBUG(\"%s: t=%p %s\\n\", __func__, tensor, tensor->name);\n     if (tensor->view_src != NULL) {\n         assert(tensor->view_src->buffer->buft == buffer->buft);\n         return GGML_STATUS_SUCCESS;\n@@ -957,8 +965,14 @@ static ggml_backend_buffer_t ggml_backend_cuda_split_buffer_type_alloc_buffer(gg\n     // however, the size still represents the maximum cumulative size of all the device buffers after the tensors are allocated,\n     // as returned by get_alloc_size. this limit is enforced during tensor allocation by ggml-alloc, so it must be correct.\n     ggml_backend_cuda_split_buffer_context * ctx = new ggml_backend_cuda_split_buffer_context();\n-\n-    return ggml_backend_buffer_init(buft, ggml_backend_cuda_split_buffer_interface, ctx, size);\n+    ggml_backend_buffer_t b = NULL;\n+    try {\n+        b = ggml_backend_buffer_init(buft, ggml_backend_cuda_split_buffer_interface, ctx, size);\n+    }  catch (std::exception &e) {\n+        GGML_LOG_ERROR(\"%s: ggml_backend_buffer_init threw: %s \\n\", __func__, e.what());\n+        return NULL;\n+    }\n+    return b;\n }\n \n static size_t ggml_backend_cuda_split_buffer_type_get_alignment(ggml_backend_buffer_type_t buft) {\ndiff --git a/src/ggml.c b/src/ggml.c\nindex 950772c75..41e7714c6 100644\n--- a/src/ggml.c\n+++ b/src/ggml.c\n@@ -1685,6 +1685,7 @@ void * ggml_new_buffer(struct ggml_context * ctx, size_t nbytes) {\n }\n \n struct ggml_tensor * ggml_dup_tensor(struct ggml_context * ctx, const struct ggml_tensor * src) {\n+    assert(src);\n     return ggml_new_tensor(ctx, src->type, GGML_MAX_DIMS, src->ne);\n }\n \n@@ -2731,6 +2732,8 @@ struct ggml_tensor * ggml_mul_mat(\n         struct ggml_context * ctx,\n         struct ggml_tensor  * a,\n         struct ggml_tensor  * b) {\n+    assert(a);\n+    assert(b);\n     GGML_ASSERT(ggml_can_mul_mat(a, b));\n     GGML_ASSERT(!ggml_is_transposed(a));\n \ndiff --git a/tests/CMakeLists.txt b/tests/CMakeLists.txt\nindex 5db778cd8..5c952db2b 100644\n--- a/tests/CMakeLists.txt\n+++ b/tests/CMakeLists.txt\n@@ -412,3 +412,14 @@ add_executable(${TEST_TARGET} ${TEST_TARGET}.c)\n target_link_libraries(${TEST_TARGET} PRIVATE ggml)\n add_test(NAME ${TEST_TARGET} COMMAND $<TARGET_FILE:${TEST_TARGET}>)\n set_property(TEST ${TEST_TARGET} PROPERTY ENVIRONMENT \"LLVM_PROFILE_FILE=${TEST_TARGET}.profraw\")\n+\n+#\n+# test-oom (atm only cuda)\n+\n+if(GGML_CUDA)\n+    set(TEST_TARGET test-oom)\n+    add_executable(${TEST_TARGET} ${TEST_TARGET}.cpp)\n+    target_link_libraries(${TEST_TARGET} PRIVATE ggml)\n+    add_test(NAME ${TEST_TARGET} COMMAND $<TARGET_FILE:${TEST_TARGET}>)\n+    set_property(TEST ${TEST_TARGET} PROPERTY ENVIRONMENT \"LLVM_PROFILE_FILE=${TEST_TARGET}.profraw\")\n+endif()\ndiff --git a/tests/test-arange.cpp b/tests/test-arange.cpp\nindex 4b7a98584..047ba4887 100644\n--- a/tests/test-arange.cpp\n+++ b/tests/test-arange.cpp\n@@ -76,7 +76,7 @@ int main(int /*argc*/, const char** /*argv*/) {\n             ggml_backend_cpu_set_n_threads(backend, n_threads);\n         }\n \n-        ggml_backend_graph_compute(backend, graph);\n+        GGML_ASSERT(ggml_backend_graph_compute(backend, graph) == GGML_STATUS_SUCCESS);\n \n         float * output = new float[ggml_nelements(t)];\n         ggml_backend_tensor_get(t, output, 0, ggml_nbytes(t));\ndiff --git a/tests/test-mul-mat.cpp b/tests/test-mul-mat.cpp\nindex 578d3e786..59096a78c 100644\n--- a/tests/test-mul-mat.cpp\n+++ b/tests/test-mul-mat.cpp\n@@ -151,8 +151,9 @@ struct ggml_tensor* compute(const test_model & model, ggml_gallocr_t allocr) {\n         ggml_backend_cpu_set_n_threads(model.backend, n_threads);\n     }\n \n-\n-    ggml_backend_graph_compute(model.backend, gf);\n+    ggml_status status = ggml_backend_graph_compute(model.backend, gf);\n+    if (status != GGML_STATUS_SUCCESS)\n+        return nullptr;\n \n     //ggml_graph_print(gf);\n \n@@ -313,6 +314,10 @@ int main(void)\n     }\n \n     struct ggml_tensor * result = compute(model, allocr);\n+    if (!result) {\n+        printf(\"ggml_mul_mat: failed to compute graph\");\n+        return EXIT_FAILURE;\n+    }\n \n     std::vector<float> out_data(ggml_nelements(result));\n \ndiff --git a/tests/test-oom.cpp b/tests/test-oom.cpp\nnew file mode 100644\nindex 000000000..736866fb8\n--- /dev/null\n+++ b/tests/test-oom.cpp\n@@ -0,0 +1,236 @@\n+#include <cassert>\n+#include <cmath>\n+#include <cstdio>\n+#include <cstring>\n+#include <vector>\n+#include \"ggml.h\"\n+#include \"ggml-cpp.h\" // shared ptr\n+#include \"ggml-backend.h\"\n+#include \"ggml-cpu.h\"\n+#ifdef GGML_USE_CUDA\n+#include \"ggml-cuda.h\"\n+#endif\n+\n+struct test_model {\n+    struct ggml_tensor * a = nullptr;\n+    struct ggml_tensor * b = nullptr;\n+    ggml_backend_ptr backend = NULL;\n+    ggml_backend_buffer_ptr buffer = NULL;\n+    struct ggml_context * ctx = nullptr;\n+    int M =0, N=0, K=1;\n+};\n+\n+// in MB\n+size_t getCudaFreeMem() {\n+    size_t cudafree = 0;\n+    size_t cudatotal = 0;\n+    ggml_backend_cuda_get_device_memory(0, &cudafree, &cudatotal);\n+    return cudafree/1024/1024;\n+}\n+\n+ggml_status load_model(test_model & model, unsigned S) {\n+    size_t totalFreeMem = getCudaFreeMem();\n+    printf(\"%s: cuda free: %ld MB \\n\", __func__, totalFreeMem);\n+\n+    // for a 2d matrix multiplication: K = shared dim, M=num rows for the left tensor A, N=num cols for the right tensor B\n+    model.M = S;\n+    model.N = S;\n+    model.K = S;\n+    printf(\"%s: M=%d N=%d K=%d \\n\", __func__, model.M, model.N, model.K);\n+\n+    size_t buffer_size = 0;\n+    {\n+        buffer_size += (model.M * model.K) * ggml_type_size(GGML_TYPE_F32); // tensor a\n+        buffer_size += (model.K * model.N) * ggml_type_size(GGML_TYPE_F32); // tensor b\n+        buffer_size += (model.M * model.N) * ggml_type_size(GGML_TYPE_F32); // output tensor\n+        buffer_size += 1024; // overhead\n+    }\n+    printf(\"%s: backend buffer size = %ld KB\\n\", __func__, buffer_size/1024);\n+\n+    int num_tensors = 3;\n+    struct ggml_init_params params {\n+        /*.mem_size   =*/ ggml_tensor_overhead() * num_tensors,\n+            /*.mem_buffer =*/ NULL,\n+            /*.no_alloc   =*/ true, //\n+            };\n+\n+    // initialize the backend\n+    printf(\"%s: using CUDA backend\\n\", __func__);\n+    model.backend = ggml_backend_ptr(ggml_backend_cuda_init(0)); // shared ptr\n+    if (!model.backend.get()) {\n+        printf(\"%s: ggml_backend_cuda_init() failed\\n\", __func__);\n+        return GGML_STATUS_FAILED;\n+    }\n+\n+    model.buffer = ggml_backend_buffer_ptr(ggml_backend_alloc_buffer(model.backend.get(), buffer_size));\n+    if (!model.buffer) {\n+        printf(\"%s: model.buffer null \\n\", __func__);\n+        return GGML_STATUS_ALLOC_FAILED;\n+    }\n+\n+    printf(\"%s: buffer allocated. cuda free: %ld MB \\n\", __func__, getCudaFreeMem());\n+\n+    // create context\n+    model.ctx = ggml_init(params);\n+    printf(\"%s: ctx created. cuda free: %ld MB \\n\", __func__, getCudaFreeMem());\n+\n+    // create tensors\n+    printf(\"%s: creating input tensors...\\n\", __func__);\n+    model.a = ggml_new_tensor_2d(model.ctx, GGML_TYPE_F32, model.K, model.M);\n+    if (!model.a) {\n+        printf(\"%s: cannot create tensor a \\n\", __func__);\n+        abort();\n+    }\n+    model.a->name[0] = 'A';\n+    //printf(\"Matrix A: [%i, %i]\\n\", K, M);\n+    model.b = ggml_new_tensor_2d(model.ctx, GGML_TYPE_F32, model.K, model.N);\n+    if(!model.b)\n+        abort();\n+    model.b->name[0] = 'B';\n+    //printf(\"Matrix B: [%i, %i]\\n\", K, N);\n+    printf(\"%s: tensors (a&b) created. cuda free: %ld MB \\n\", __func__, getCudaFreeMem());\n+\n+    // create an allocator\n+    struct ggml_tallocr alloc = ggml_tallocr_new(model.buffer.get());\n+\n+    // alloc memory for a\n+    ggml_tallocr_alloc(&alloc, model.a);\n+\n+    // alloc memory for b\n+    ggml_tallocr_alloc(&alloc, model.b);\n+    return GGML_STATUS_SUCCESS;\n+}\n+\n+\n+struct ggml_cgraph * build_graph(const test_model& model, ggml_tensor* a, ggml_tensor *b, unsigned repeat) {\n+    printf(\"build_graph %d...\\n\", repeat);\n+    static size_t buf_size = ggml_tensor_overhead() * GGML_DEFAULT_GRAPH_SIZE + ggml_graph_overhead();\n+    printf(\"%s: graph buf size: %ld KB\\n\", __func__, buf_size/1024);\n+    static std::vector<uint8_t> buf(buf_size);\n+\n+    struct ggml_init_params params0 = {\n+        /*.mem_size   =*/ buf_size,\n+        /*.mem_buffer =*/ buf.data(),\n+        /*.no_alloc   =*/ true, // the tensors will be allocated later by ggml_gallocr_alloc_graph()\n+    };\n+\n+    // create a temporally context to build the graph\n+    struct ggml_context * ctx0 = ggml_init(params0);\n+    if (!ctx0) {\n+        printf(\"error: ggml_init returned null\\n\");\n+        return nullptr;\n+    }\n+\n+    struct ggml_cgraph * gf = ggml_new_graph(ctx0);\n+    if (!gf)\n+        return nullptr;\n+\n+    // zT = x @ yT\n+    struct ggml_tensor * result = ggml_mul_mat(ctx0, a, ggml_cont(ctx0, b));\n+    if (!result) {\n+        printf(\"error:  ggml_mul_mat returned null\\n\");\n+        return nullptr;\n+    }\n+\n+    // z = (zT)T\n+    struct ggml_tensor* T = ggml_transpose(ctx0, result);\n+    if (!T) {\n+        fprintf(stderr, \"error: ggml_transpose returned null\\n\");\n+        return nullptr;\n+    }\n+\n+    struct ggml_tensor* c = ggml_cont(ctx0, T);\n+    if (!c) {\n+        fprintf(stderr, \"error: ggml_cont returned null\\n\");\n+        return nullptr;\n+    }\n+\n+    std::vector<struct ggml_tensor *> outTensors;\n+    outTensors.push_back(c);\n+    for (unsigned i=0; i < repeat; i++) {\n+        struct ggml_tensor * d = ggml_mul_mat(ctx0, outTensors.back(), ggml_cont(ctx0, outTensors.back()));\n+        if (!d) {\n+            printf(\"error:  ggml_mul_mat returned null\\n\");\n+            return nullptr;\n+        }\n+        //printf(\"%s: matmul out: %s %ld %ld \\n\", __func__, d->name, d->ne[0], d->ne[1]);\n+        outTensors.push_back(d);\n+        c = ggml_concat(ctx0, c, d, 0);\n+    }\n+\n+    ggml_build_forward_expand(gf, c);\n+\n+    // delete the temporally context used to build the graph\n+    ggml_free(ctx0);\n+    return gf;\n+}\n+\n+ggml_status compute(const test_model & model, ggml_gallocr_t allocr, unsigned repeat) {\n+    printf(\"compute ...\\n\");\n+    printf(\"compute: free device mem: %ld MB\\n\", getCudaFreeMem());\n+\n+    ggml_tensor* ot = NULL;\n+    ggml_tensor* left = model.a;\n+    ggml_tensor* right = model.b;\n+\n+    struct ggml_cgraph * gf = build_graph(model, left, right, repeat);\n+    printf(\"conpute: graph built. free cuda mem: %ld MB\\n\", getCudaFreeMem());\n+\n+    // allocate tensors\n+    if (!ggml_gallocr_alloc_graph(allocr, gf))\n+        return GGML_STATUS_ALLOC_FAILED;\n+\n+    printf(\"%s: graph buf allocated. free device mem: %ld MB\\n\", __func__, getCudaFreeMem());\n+\n+    ggml_status status = ggml_backend_graph_compute(model.backend.get(), gf);\n+    if (status != GGML_STATUS_SUCCESS)\n+        return status;\n+\n+    ggml_graph_print(gf);\n+    printf(\"compute: graph computed. free device mem: %ld MB\\n\", getCudaFreeMem());\n+    // in this case, the output tensor is the last one in the graph\n+    ot = ggml_graph_node(gf, -1);\n+    if (!ot)\n+        return GGML_STATUS_FAILED;\n+    printf(\"%s: output tensor shape: %ld x %ld name: %s\\n\", __func__, ot->ne[0], ot->ne[1], ot->name);\n+\n+    return GGML_STATUS_SUCCESS;\n+}\n+\n+\n+int main(void) {\n+#ifndef GGML_USE_CUDA\n+    fprintf(stderr, \"note: test-oom ony implemented for the cuda backend at the moment\");\n+    return 0;\n+#endif\n+\n+    const char* GGML_CUDA_NO_ABORT = getenv(\"GGML_CUDA_NO_ABORT\");\n+    if (!GGML_CUDA_NO_ABORT) {\n+      fprintf(stderr, \"warning: skipping: test-oom requires the GGML_CUDA_NO_ABORT envvar to be set\\n\");\n+      return 0;\n+    }\n+\n+    test_model model;\n+\n+    ggml_status status = load_model(model, 8192); // will also init the backend\n+    if (status != GGML_STATUS_SUCCESS) {\n+        printf(\"failed to load model\");\n+        return GGML_EXIT_ABORTED;\n+    }\n+\n+    ggml_gallocr_t allocr = NULL;\n+    allocr = ggml_gallocr_new(ggml_backend_get_default_buffer_type(model.backend.get()));\n+    if (!allocr) {\n+        printf(\"Cannot ggml_gallocr_new\\n\");\n+        return GGML_EXIT_ABORTED;\n+    }\n+\n+    // will run multiple matmul in a lopp accumulating big output tensors. Should oom.\n+    status = compute(model, allocr, 160);\n+    if (status == GGML_STATUS_SUCCESS) {\n+        printf(\"main: compute failed to oom (matmul too small to oom the GPU? for loop too smal ?)\\n\");\n+        return GGML_EXIT_ABORTED;\n+    }\n+    printf(\"main: compute correctly OOM: ggml status=%d expected: %d \\n\", status, GGML_STATUS_ALLOC_FAILED);\n+    return GGML_EXIT_SUCCESS;\n+}\ndiff --git a/tests/test-timestep_embedding.cpp b/tests/test-timestep_embedding.cpp\nindex a55865973..e41942633 100644\n--- a/tests/test-timestep_embedding.cpp\n+++ b/tests/test-timestep_embedding.cpp\n@@ -159,7 +159,7 @@ int main(int argc, const char** argv) {\n             ggml_backend_cpu_set_n_threads(backend, n_threads);\n         }\n \n-        ggml_backend_graph_compute(backend, graph);\n+        GGML_ASSERT(ggml_backend_graph_compute(backend, graph) == GGML_STATUS_SUCCESS);\n \n         float * output = new float[ggml_nelements(t)];\n         ggml_backend_tensor_get(t, output, 0, ggml_nbytes(t));\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Change CUDA_CHECK macros to throw exceptions on errors. This will require catching exceptions in ggml-backend functions to prevent leaks.\n2. Ensure all ggml-backend interface functions are marked `noexcept` and are exception-safe, adhering to RAII principles.\n3. Update `ggml_cuda_error(...)` to throw exceptions conditionally based on an environment variable and provide logging for debugging.\n4. Document that the backend remains usable after an error return and emphasize clean shutdown handling for OOM scenarios.\n5. Retain abort behavior for cases where preconditions are not met, but implement exception handling for recoverable CUDA errors."
      }
    ],
    "codediff_length": 21519
  },
  {
    "index": 104,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.gitignore b/.gitignore\nindex fbf3c634b..19760d3df 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -1,6 +1,7 @@\n build/\n build-debug/\n build-release/\n+build-rpc/\n build-sanitize-addr/\n build-sanitize-thread/\n build-cov/\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 2249363d9..53e61f0d8 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -46,6 +46,7 @@ option(GGML_CLBLAST                 \"ggml: use clBLAST\"                  OFF)\n option(GGML_HIPBLAS                 \"ggml: use hipBLAS\"                  OFF)\n option(GGML_CUBLAS                  \"ggml: use cuBLAS\"                   OFF)\n option(GGML_METAL                   \"ggml: use Metal\"                    OFF)\n+option(GGML_RPC                     \"ggml: use RPC\"                      OFF)\n \n option(GGML_CUDA_FORCE_DMMV                 \"ggml: use dmmv instead of mmvq CUDA kernels\"     OFF)\n option(GGML_CUDA_FORCE_MMQ                  \"ggml: use mmq kernels instead of cuBLAS\"         OFF)\ndiff --git a/examples/CMakeLists.txt b/examples/CMakeLists.txt\nindex 666821611..ca6e443f6 100644\n--- a/examples/CMakeLists.txt\n+++ b/examples/CMakeLists.txt\n@@ -26,3 +26,6 @@ add_subdirectory(sam)\n add_subdirectory(yolo)\n add_subdirectory(simple)\n add_subdirectory(magika)\n+if (GGML_RPC)\n+  add_subdirectory(rpc)\n+endif()\n\\ No newline at end of file\ndiff --git a/examples/gpt-2/CMakeLists.txt b/examples/gpt-2/CMakeLists.txt\nindex a1e9df73e..b782b998e 100644\n--- a/examples/gpt-2/CMakeLists.txt\n+++ b/examples/gpt-2/CMakeLists.txt\n@@ -46,3 +46,7 @@ endif()\n if (GGML_METAL)\n     add_compile_definitions(GGML_USE_METAL)\n endif()\n+\n+if (GGML_RPC)\n+    add_compile_definitions(GGML_USE_RPC)\n+endif()\n\\ No newline at end of file\ndiff --git a/examples/gpt-2/main-backend.cpp b/examples/gpt-2/main-backend.cpp\nindex bd4cb80b1..38abbf5b8 100644\n--- a/examples/gpt-2/main-backend.cpp\n+++ b/examples/gpt-2/main-backend.cpp\n@@ -10,6 +10,10 @@\n #include \"ggml-metal.h\"\n #endif\n \n+#ifdef GGML_USE_RPC\n+#include \"ggml-rpc.h\"\n+#endif\n+\n #include \"common.h\"\n #include \"common-ggml.h\"\n \n@@ -218,6 +222,14 @@ bool gpt2_model_load(const std::string & fname, gpt2_model & model, gpt_vocab &\n     }\n #endif\n \n+#ifdef GGML_USE_RPC\n+    fprintf(stderr, \"%s: using RPC backend\\n\", __func__);\n+    model.backend = ggml_backend_rpc_init(\"localhost:50051\");\n+    if (!model.backend) {\n+        fprintf(stderr, \"%s: ggml_backend_rpc_init() failed\\n\", __func__);\n+    }\n+#endif\n+\n     if (!model.backend) {\n         // fallback to CPU backend\n         fprintf(stderr, \"%s: using CPU backend\\n\", __func__);\ndiff --git a/examples/rpc/CMakeLists.txt b/examples/rpc/CMakeLists.txt\nnew file mode 100644\nindex 000000000..7279de0d2\n--- /dev/null\n+++ b/examples/rpc/CMakeLists.txt\n@@ -0,0 +1,5 @@\n+add_executable(client client.cpp)\n+target_link_libraries(client PRIVATE ggml)\n+\n+add_executable(server server.cpp)\n+target_link_libraries(server PRIVATE ggml)\ndiff --git a/examples/rpc/client.cpp b/examples/rpc/client.cpp\nnew file mode 100644\nindex 000000000..b2891cd7d\n--- /dev/null\n+++ b/examples/rpc/client.cpp\n@@ -0,0 +1,182 @@\n+#include \"ggml.h\"\n+#include \"ggml/ggml-alloc.h\"\n+#include \"ggml/ggml-backend.h\"\n+\n+#include \"ggml-rpc.h\"\n+#include <cstdio>\n+#include <cstdlib>\n+\n+// This is a simple model with two tensors a and b\n+struct simple_model {\n+    struct ggml_tensor * a;\n+    struct ggml_tensor * b;\n+\n+    // RPC backend\n+    ggml_backend_t backend = NULL;\n+\n+    // the backend buffer to storage the tensors data of a and b\n+    ggml_backend_buffer_t buffer;\n+\n+    // the context to define the tensor information (dimensions, size, memory address)\n+    struct ggml_context * ctx;\n+};\n+\n+void load_model(simple_model & model, float * a, float * b, int rows_A, int cols_A, int rows_B, int cols_B)\n+{\n+    int num_tensors = 2;\n+\n+    struct ggml_init_params params {\n+            /*.mem_size   =*/ ggml_tensor_overhead() * num_tensors,\n+            /*.mem_buffer =*/ NULL,\n+            /*.no_alloc   =*/ true,\n+    };\n+\n+    // create context\n+    model.ctx = ggml_init(params);\n+\n+    // create tensors\n+    model.a = ggml_new_tensor_2d(model.ctx, GGML_TYPE_F32, cols_A, rows_A);\n+    model.b = ggml_new_tensor_2d(model.ctx, GGML_TYPE_F32, cols_B, rows_B);\n+\n+    // create a backend buffer (backend memory) and alloc the tensors from the context\n+    model.buffer = ggml_backend_alloc_ctx_tensors(model.ctx, model.backend);\n+\n+    // load data from cpu memory to backend buffer\n+    ggml_backend_tensor_set(model.a, a, 0, ggml_nbytes(model.a));\n+    ggml_backend_tensor_set(model.b, b, 0, ggml_nbytes(model.b));\n+}\n+\n+// build the compute graph to perform a matrix multiplication\n+struct ggml_cgraph * build_graph(const simple_model& model) {\n+    static size_t buf_size = ggml_tensor_overhead()*GGML_DEFAULT_GRAPH_SIZE + ggml_graph_overhead();\n+    static std::vector<uint8_t> buf(buf_size);\n+\n+    struct ggml_init_params params0 = {\n+        /*.mem_size   =*/ buf_size,\n+        /*.mem_buffer =*/ buf.data(),\n+        /*.no_alloc   =*/ true, // the tensors will be allocated later by ggml_allocr_alloc_graph()\n+    };\n+\n+    // create a temporally context to build the graph\n+    struct ggml_context * ctx0 = ggml_init(params0);\n+\n+    struct ggml_cgraph  * gf = ggml_new_graph(ctx0);\n+\n+    // result = a*b^T\n+    struct ggml_tensor * result = ggml_mul_mat(ctx0, model.a, model.b);\n+\n+    // build operations nodes\n+    ggml_build_forward_expand(gf, result);\n+\n+    // delete the temporally context used to build the graph\n+    ggml_free(ctx0);\n+    return gf;\n+}\n+\n+// compute with backend\n+struct ggml_tensor * compute(const simple_model & model, ggml_gallocr_t allocr) {\n+    // reset the allocator to free all the memory allocated during the previous inference\n+\n+    struct ggml_cgraph * gf = build_graph(model);\n+\n+    // allocate tensors\n+    ggml_gallocr_alloc_graph(allocr, gf);\n+\n+    ggml_status status = ggml_backend_graph_compute(model.backend, gf);\n+    if (status != GGML_STATUS_SUCCESS) {\n+        fprintf(stderr, \"%s: ggml_backend_graph_compute() failed\\n\", __func__);\n+        exit(1);\n+    }\n+\n+    // in this case, the output tensor is the last one in the graph\n+    return gf->nodes[gf->n_nodes - 1];\n+}\n+\n+int main(int argc, char * argv[])\n+{\n+    if (argc < 2) {\n+        fprintf(stderr, \"Usage: %s <server_addr>\\n\", argv[0]);\n+        return 1;\n+    }\n+    ggml_time_init();\n+\n+    // initialize data of matrices to perform matrix multiplication\n+    const int rows_A = 4, cols_A = 2;\n+\n+    float matrix_A[rows_A * cols_A] = {\n+        2, 8,\n+        5, 1,\n+        4, 2,\n+        8, 6\n+    };\n+\n+    const int rows_B = 3, cols_B = 2;\n+    /* Transpose([\n+        10, 9, 5,\n+        5, 9, 4\n+    ]) 2 rows, 3 cols */\n+    float matrix_B[rows_B * cols_B] = {\n+        10, 5,\n+        9, 9,\n+        5, 4\n+    };\n+\n+    simple_model model;\n+    model.backend = ggml_backend_rpc_init(argv[1]);\n+    if (!model.backend) {\n+        fprintf(stderr, \"%s: ggml_backend_rpc_init() failed\\n\", __func__);\n+        exit(1);\n+    }\n+    load_model(model, matrix_A, matrix_B, rows_A, cols_A, rows_B, cols_B);\n+\n+    // calculate the temporaly memory required to compute\n+    ggml_gallocr_t allocr = NULL;\n+\n+    {\n+        allocr = ggml_gallocr_new(ggml_backend_get_default_buffer_type(model.backend));\n+\n+        // create the worst case graph for memory usage estimation\n+        struct ggml_cgraph * gf = build_graph(model);\n+        ggml_gallocr_reserve(allocr, gf);\n+        size_t mem_size = ggml_gallocr_get_buffer_size(allocr, 0);\n+\n+        fprintf(stderr, \"%s: compute buffer size: %.4f KB\\n\", __func__, mem_size/1024.0);\n+    }\n+\n+    // perform computation\n+    struct ggml_tensor * result = compute(model, allocr);\n+\n+    // create a array to print result\n+    std::vector<float> out_data(ggml_nelements(result));\n+\n+    // bring the data from the backend memory\n+    ggml_backend_tensor_get(result, out_data.data(), 0, ggml_nbytes(result));\n+\n+    // expected result:\n+    // [ 60.00 110.00 54.00 29.00\n+    //  55.00 90.00 126.00 28.00\n+    //  50.00 54.00 42.00 64.00 ]\n+\n+    printf(\"mul mat (%d x %d) (transposed result):\\n[\", (int) result->ne[0], (int) result->ne[1]);\n+    for (int j = 0; j < result->ne[1] /* rows */; j++) {\n+        if (j > 0) {\n+            printf(\"\\n\");\n+        }\n+\n+        for (int i = 0; i < result->ne[0] /* cols */; i++) {\n+            printf(\" %.2f\", out_data[i * result->ne[1] + j]);\n+        }\n+    }\n+    printf(\" ]\\n\");\n+\n+    // release backend memory used for computation\n+    ggml_gallocr_free(allocr);\n+\n+    // free memory\n+    ggml_free(model.ctx);\n+\n+    // release backend memory and free backend\n+    ggml_backend_buffer_free(model.buffer);\n+    ggml_backend_free(model.backend);\n+    return 0;\n+}\ndiff --git a/examples/rpc/server.cpp b/examples/rpc/server.cpp\nnew file mode 100644\nindex 000000000..6673f1611\n--- /dev/null\n+++ b/examples/rpc/server.cpp\n@@ -0,0 +1,36 @@\n+#include <memory>\n+#include <string>\n+#include <grpcpp/ext/proto_server_reflection_plugin.h>\n+#include <grpcpp/grpcpp.h>\n+#include <grpcpp/health_check_service_interface.h>\n+\n+#include \"ggml-rpc.h\"\n+\n+int main(int argc, char * argv[])\n+{\n+    if (argc < 2) {\n+        fprintf(stderr, \"Usage: %s <port>\\n\", argv[0]);\n+        return 1;\n+    }\n+    int port = std::stoi(argv[1]);\n+    std::string server_address = \"0.0.0.0:\" + std::to_string(port);\n+    BackendImpl service;\n+\n+    grpc::EnableDefaultHealthCheckService(true);\n+    grpc::reflection::InitProtoReflectionServerBuilderPlugin();\n+    grpc::ServerBuilder builder;\n+    // Listen on the given address without any authentication mechanism.\n+    builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());\n+    builder.RegisterService(&service);\n+    builder.SetMaxSendMessageSize(1024 * 1024 * 1024);\n+    builder.SetMaxMessageSize(1024 * 1024 * 1024);\n+    builder.SetMaxReceiveMessageSize(1024 * 1024 * 1024);\n+    std::unique_ptr<grpc::Server> server(builder.BuildAndStart());\n+    std::cout << \"RPC backend listening on \" << server_address << std::endl;\n+\n+    // Wait for the server to shutdown. Note that some other thread must be\n+    // responsible for shutting down the server for this call to ever return.\n+    server->Wait();\n+\n+    return 0;\n+}\ndiff --git a/src/CMakeLists.txt b/src/CMakeLists.txt\nindex e784fc824..6266a082a 100644\n--- a/src/CMakeLists.txt\n+++ b/src/CMakeLists.txt\n@@ -321,6 +321,43 @@ if (GGML_METAL)\n         )\n endif()\n \n+if (GGML_RPC)\n+    find_package(protobuf CONFIG REQUIRED)\n+    message(STATUS \"Using protobuf ${Protobuf_VERSION}\")\n+    set(_PROTOBUF_LIBPROTOBUF protobuf::libprotobuf)\n+    set(_PROTOBUF_PROTOC $<TARGET_FILE:protobuf::protoc>)\n+\n+    find_package(gRPC CONFIG REQUIRED)\n+    message(STATUS \"Using gRPC ${gRPC_VERSION}\")\n+    set(_GRPC_CPP_PLUGIN_EXECUTABLE $<TARGET_FILE:gRPC::grpc_cpp_plugin>)\n+\n+    # Proto file\n+    get_filename_component(ggml_proto \"ggml-rpc.proto\" ABSOLUTE)\n+    get_filename_component(ggml_proto_path \"${ggml_proto}\" PATH)\n+\n+    # Generated sources\n+    set(ggml_proto_srcs \"${CMAKE_CURRENT_BINARY_DIR}/ggml-rpc.pb.cc\")\n+    set(ggml_proto_hdrs \"${CMAKE_CURRENT_BINARY_DIR}/ggml-rpc.pb.h\")\n+    set(ggml_grpc_srcs \"${CMAKE_CURRENT_BINARY_DIR}/ggml-rpc.grpc.pb.cc\")\n+    set(ggml_grpc_hdrs \"${CMAKE_CURRENT_BINARY_DIR}/ggml-rpc.grpc.pb.h\")\n+\n+    add_custom_command(\n+        OUTPUT \"${ggml_proto_srcs}\" \"${ggml_proto_hdrs}\" \"${ggml_grpc_srcs}\" \"${ggml_grpc_hdrs}\"\n+        COMMAND ${_PROTOBUF_PROTOC}\n+        ARGS --grpc_out \"${CMAKE_CURRENT_BINARY_DIR}\"\n+            --cpp_out \"${CMAKE_CURRENT_BINARY_DIR}\"\n+            -I \"${ggml_proto_path}\"\n+            --plugin=protoc-gen-grpc=\"${_GRPC_CPP_PLUGIN_EXECUTABLE}\"\n+            \"${ggml_proto}\"\n+        DEPENDS \"${ggml_proto}\")\n+\n+    # Include generated *.pb.h files\n+    set(GGML_EXTRA_INCS  ${GGML_EXTRA_INCS}  ${CMAKE_CURRENT_BINARY_DIR})\n+\n+    set(GGML_RPC_SOURCES ggml-rpc.cpp ggml-rpc.h ${ggml_grpc_srcs} ${ggml_grpc_hdrs} ${ggml_proto_srcs} ${ggml_proto_hdrs})\n+    set(GGML_EXTRA_LIBS ${GGML_EXTRA_LIBS} gRPC::grpc++ gRPC::grpc gRPC::grpc++_reflection ${_PROTOBUF_LIBPROTOBUF})\n+endif()\n+\n if (GGML_PERF)\n     set(GGML_EXTRA_FLAGS ${GGML_EXTRA_FLAGS} -DGGML_PERF)\n endif()\n@@ -338,6 +375,7 @@ add_library(${TARGET}\n     ${GGML_CUDA_SOURCES}\n     ${GGML_OPENCL_SOURCES}\n     ${GGML_METAL_SOURCES}\n+    ${GGML_RPC_SOURCES}\n     )\n \n target_include_directories(${TARGET} PUBLIC\ndiff --git a/src/ggml-rpc.cpp b/src/ggml-rpc.cpp\nnew file mode 100644\nindex 000000000..887bd4f61\n--- /dev/null\n+++ b/src/ggml-rpc.cpp\n@@ -0,0 +1,634 @@\n+#include \"ggml-rpc.h\"\n+#include \"ggml.h\"\n+#include \"ggml-backend-impl.h\"\n+#include \"ggml-rpc.grpc.pb.h\"\n+\n+#ifdef GGML_USE_CUBLAS\n+#include \"ggml-cuda.h\"\n+#endif\n+\n+#ifdef GGML_USE_METAL\n+#include \"ggml-metal.h\"\n+#endif\n+\n+#include <grpcpp/grpcpp.h>\n+#include <memory>\n+#include <string>\n+\n+#define UNUSED GGML_UNUSED\n+\n+#define GGML_DEBUG 0\n+#if (GGML_DEBUG >= 1)\n+#define GGML_PRINT_DEBUG(...) printf(__VA_ARGS__)\n+#else\n+#define GGML_PRINT_DEBUG(...)\n+#endif\n+\n+static ggml_guid_t ggml_backend_rpc_guid() {\n+    static ggml_guid guid = { 0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff};\n+    return &guid;\n+}\n+\n+struct ggml_backend_rpc_context {\n+    std::string endpoint;\n+    std::string name;\n+    std::shared_ptr<ggml::Backend::Stub> stub;\n+};\n+\n+// rpc buffer\n+\n+struct ggml_backend_rpc_buffer_context {\n+    std::shared_ptr<ggml::Backend::Stub> stub;\n+    uint64_t remote_ptr;\n+    std::string name;\n+};\n+\n+GGML_CALL static const char * ggml_backend_rpc_buffer_get_name(ggml_backend_buffer_t buffer) {\n+    GGML_PRINT_DEBUG(\"buffer get name\\n\");\n+    ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;\n+    return ctx->name.c_str();\n+}\n+\n+GGML_CALL static void ggml_backend_rpc_buffer_free_buffer(ggml_backend_buffer_t buffer) {\n+    GGML_PRINT_DEBUG(\"buffer free\\n\");\n+    ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;\n+    ggml::FreeBufferRequest request;\n+    request.set_bufptr(ctx->remote_ptr);\n+    ggml::FreeBufferReply reply;\n+    grpc::ClientContext context;\n+    grpc::Status status = ctx->stub->FreeBuffer(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+    delete ctx;\n+}\n+\n+GGML_CALL static void * ggml_backend_rpc_buffer_get_base(ggml_backend_buffer_t buffer) {\n+    GGML_PRINT_DEBUG(\"buffer get base\\n\");\n+    ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;\n+    ggml::BufferGetBaseRequest request;\n+    request.set_bufptr(ctx->remote_ptr);\n+    ggml::BufferGetBaseReply reply;\n+    grpc::ClientContext context;\n+    grpc::Status status = ctx->stub->BufferGetBase(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+    return reinterpret_cast<void *>(reply.baseptr());\n+}\n+\n+static void serialize_tensor(const ggml_tensor * tensor, ggml::Tensor * protobuf_tensor) {\n+    protobuf_tensor->set_id(reinterpret_cast<uint64_t>(tensor));\n+    protobuf_tensor->set_type(tensor->type);\n+    protobuf_tensor->set_backend(tensor->backend);\n+    if (tensor->buffer) {\n+        ggml_backend_buffer_t buffer = tensor->buffer;\n+        ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;\n+        protobuf_tensor->set_bufptr(ctx->remote_ptr);\n+    } else {\n+        protobuf_tensor->set_bufptr(0);\n+    }\n+    for (uint32_t i = 0; i < GGML_MAX_DIMS; i++) {\n+        protobuf_tensor->add_ne(tensor->ne[i]);\n+        protobuf_tensor->add_nb(tensor->nb[i]);\n+    }\n+    protobuf_tensor->set_op(tensor->op);\n+    for (uint32_t i = 0; i < GGML_MAX_OP_PARAMS / sizeof(int32_t); i++) {\n+        protobuf_tensor->add_op_params(tensor->op_params[i]);\n+    }\n+    protobuf_tensor->set_flags(tensor->flags);\n+    for (uint32_t i = 0; i < GGML_MAX_SRC; i++) {\n+        protobuf_tensor->add_src(reinterpret_cast<uint64_t>(tensor->src[i]));\n+    }\n+    protobuf_tensor->set_view_src(reinterpret_cast<uint64_t>(tensor->view_src));\n+    protobuf_tensor->set_view_offs(tensor->view_offs);\n+    protobuf_tensor->set_data(reinterpret_cast<uint64_t>(tensor->data));\n+    protobuf_tensor->set_name(tensor->name);\n+    protobuf_tensor->set_extra(reinterpret_cast<uint64_t>(tensor->extra));\n+}\n+\n+static ggml_tensor * deserialize_tensor(struct ggml_context * ctx, const ggml::Tensor & protobuf_tensor) {\n+    ggml_tensor * result = ggml_new_tensor_4d(ctx, (ggml_type) protobuf_tensor.type(),\n+        protobuf_tensor.ne(0), protobuf_tensor.ne(1), protobuf_tensor.ne(2), protobuf_tensor.ne(3));\n+    for (uint32_t i = 0; i < GGML_MAX_DIMS; i++) {\n+        result->nb[i] = protobuf_tensor.nb(i);\n+    }\n+    result->backend = (ggml_backend_type) protobuf_tensor.backend();\n+    result->buffer = reinterpret_cast<ggml_backend_buffer_t>(protobuf_tensor.bufptr());\n+    result->op = (ggml_op) protobuf_tensor.op();\n+    for (uint32_t i = 0; i < GGML_MAX_OP_PARAMS / sizeof(int32_t); i++) {\n+        result->op_params[i] = protobuf_tensor.op_params(i);\n+    }\n+    result->flags = protobuf_tensor.flags();\n+    result->data = reinterpret_cast<void *>(protobuf_tensor.data());\n+    snprintf(result->name, GGML_MAX_NAME, \"%s\", protobuf_tensor.name().c_str());\n+    result->extra = reinterpret_cast<void *>(protobuf_tensor.extra());\n+    return result;\n+}\n+\n+GGML_CALL static void ggml_backend_rpc_buffer_init_tensor(ggml_backend_buffer_t buffer, ggml_tensor * tensor) {\n+    GGML_PRINT_DEBUG(\"buffer init tensor\\n\");\n+    if (tensor->view_src != NULL && tensor->view_offs == 0) {\n+        assert(tensor->view_src->buffer->buft == buffer->buft);\n+        tensor->backend = tensor->view_src->backend;\n+        tensor->extra = tensor->view_src->extra;\n+        return;\n+    }\n+    ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;\n+    ggml::InitTensorRequest request;\n+    ggml::Tensor * protobuf_tensor = request.mutable_tensor();\n+    serialize_tensor(tensor, protobuf_tensor);\n+    ggml::InitTensorReply reply;\n+    grpc::ClientContext context;\n+    grpc::Status status = ctx->stub->InitTensor(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+    const ggml::Tensor & initialized_tensor = reply.tensor();\n+    tensor->backend = (ggml_backend_type) initialized_tensor.backend();\n+    tensor->extra = reinterpret_cast<void *>(initialized_tensor.extra());\n+}\n+\n+GGML_CALL static void ggml_backend_rpc_buffer_set_tensor(ggml_backend_buffer_t buffer, ggml_tensor * tensor, const void * data, size_t offset, size_t size) {\n+    GGML_PRINT_DEBUG(\"buffer set tensor\\n\");\n+    ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;\n+    ggml::SetTensorRequest request;\n+    ggml::Tensor * protobuf_tensor = request.mutable_tensor();\n+    serialize_tensor(tensor, protobuf_tensor);\n+    request.set_offset(offset);\n+    std::string datastr((const char *)data, size);\n+    request.set_data(datastr);\n+    ggml::SetTensorReply reply;\n+    grpc::ClientContext context;\n+    grpc::Status status = ctx->stub->SetTensor(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+}\n+\n+GGML_CALL static void ggml_backend_rpc_buffer_get_tensor(ggml_backend_buffer_t buffer, const ggml_tensor * tensor, void * data, size_t offset, size_t size) {\n+    GGML_PRINT_DEBUG(\"buffer get tensor\\n\");\n+    ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;\n+    ggml::GetTensorRequest request;\n+    ggml::Tensor * protobuf_tensor = request.mutable_tensor();\n+    serialize_tensor(tensor, protobuf_tensor);\n+    request.set_offset(offset);\n+    request.set_size(size);\n+    ggml::GetTensorReply reply;\n+    grpc::ClientContext context;\n+    grpc::Status status = ctx->stub->GetTensor(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+    memcpy(data, reply.data().c_str(), size);\n+}\n+\n+GGML_CALL static bool ggml_backend_rpc_buffer_cpy_tensor(ggml_backend_buffer_t buffer, const ggml_tensor * src, ggml_tensor * dst) {\n+    GGML_PRINT_DEBUG(\"buffer cpy tensor\\n\");\n+    UNUSED(buffer);\n+    ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;\n+    ggml::CopyTensorRequest request;\n+    ggml::Tensor * protobuf_src = request.mutable_src();\n+    serialize_tensor(src, protobuf_src);\n+    ggml::Tensor * protobuf_dst = request.mutable_dst();\n+    serialize_tensor(dst, protobuf_dst);\n+    ggml::CopyTensorReply reply;\n+    grpc::ClientContext context;\n+    grpc::Status status = ctx->stub->CopyTensor(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+    return reply.result();\n+}\n+\n+GGML_CALL static void ggml_backend_rpc_buffer_clear(ggml_backend_buffer_t buffer, uint8_t value) {\n+    GGML_PRINT_DEBUG(\"buffer clear\\n\");\n+    ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;\n+    ggml::BufferClearRequest request;\n+    request.set_bufptr(ctx->remote_ptr);\n+    request.set_value(value);\n+    ggml::BufferClearReply reply;\n+    grpc::ClientContext context;\n+    grpc::Status status = ctx->stub->BufferClear(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+}\n+\n+static ggml_backend_buffer_i ggml_backend_rpc_buffer_interface = {\n+    /* .get_name        = */ ggml_backend_rpc_buffer_get_name,\n+    /* .free_buffer     = */ ggml_backend_rpc_buffer_free_buffer,\n+    /* .get_base        = */ ggml_backend_rpc_buffer_get_base,\n+    /* .init_tensor     = */ ggml_backend_rpc_buffer_init_tensor,\n+    /* .set_tensor      = */ ggml_backend_rpc_buffer_set_tensor,\n+    /* .get_tensor      = */ ggml_backend_rpc_buffer_get_tensor,\n+    /* .cpy_tensor      = */ ggml_backend_rpc_buffer_cpy_tensor,\n+    /* .clear           = */ ggml_backend_rpc_buffer_clear,\n+    /* .reset           = */ NULL,\n+};\n+\n+// rpc buffer type\n+struct ggml_backend_rpc_buffer_type_context {\n+    std::shared_ptr<ggml::Backend::Stub> stub;\n+    std::string name;\n+};\n+\n+GGML_CALL static const char * ggml_backend_rpc_buffer_type_name(ggml_backend_buffer_type_t buft) {\n+    GGML_PRINT_DEBUG(\"buffer type name\\n\");\n+    ggml_backend_rpc_buffer_type_context * buft_ctx = (ggml_backend_rpc_buffer_type_context *)buft->context;\n+    return buft_ctx->name.c_str();\n+}\n+\n+GGML_CALL static ggml_backend_buffer_t ggml_backend_rpc_buffer_type_alloc_buffer(ggml_backend_buffer_type_t buft, size_t size) {\n+    GGML_PRINT_DEBUG(\"alloc buffer, size: %zu\\n\", size);\n+    ggml_backend_rpc_buffer_type_context * buft_ctx = (ggml_backend_rpc_buffer_type_context *)buft->context;\n+    ggml::AllocateBufferRequest request;\n+    request.set_size(size);\n+    ggml::AllocateBufferReply reply;\n+    grpc::ClientContext context;\n+    grpc::Status status = buft_ctx->stub->AllocateBuffer(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+\n+    ggml_backend_buffer_t buffer = ggml_backend_buffer_init(buft,\n+        ggml_backend_rpc_buffer_interface,\n+        new ggml_backend_rpc_buffer_context{buft_ctx->stub, reply.bufptr(), \"RPC Buffer\"},\n+        reply.size());\n+\n+    return buffer;\n+}\n+\n+GGML_CALL static size_t ggml_backend_rpc_buffer_type_get_alignment(ggml_backend_buffer_type_t buft) {\n+    GGML_PRINT_DEBUG(\"get alignment\\n\");\n+    ggml::GetAlignmentRequest request;\n+    ggml::GetAlignmentReply reply;\n+    grpc::ClientContext context;\n+    ggml_backend_rpc_buffer_type_context * buft_ctx = (ggml_backend_rpc_buffer_type_context *)buft->context;\n+    grpc::Status status = buft_ctx->stub->GetAlignment(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+    return reply.alignment();\n+}\n+\n+GGML_CALL static size_t ggml_backend_rpc_buffer_type_get_alloc_size(ggml_backend_buffer_type_t buft, const ggml_tensor * tensor) {\n+    // TODO: temporary workaround\n+    return ggml_nbytes(tensor);\n+\n+    GGML_PRINT_DEBUG(\"get alloc size\\n\");\n+    ggml::GetAllocSizeRequest request;\n+    ggml::Tensor * protobuf_tensor = request.mutable_tensor();\n+    serialize_tensor(tensor, protobuf_tensor);\n+    ggml::GetAllocSizeReply reply;\n+    grpc::ClientContext context;\n+    ggml_backend_rpc_buffer_type_context * buft_ctx = (ggml_backend_rpc_buffer_type_context *)buft->context;\n+    grpc::Status status = buft_ctx->stub->GetAllocSize(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+    return reply.size();\n+}\n+\n+GGML_CALL static bool ggml_backend_rpc_buffer_type_supports_backend(ggml_backend_buffer_type_t buft, ggml_backend_t backend) {\n+    GGML_PRINT_DEBUG(\"buffer type supports backend\\n\");\n+    if (!ggml_backend_is_rpc(backend)) {\n+        return false;\n+    }\n+\n+    ggml_backend_rpc_buffer_type_context * buft_ctx = (ggml_backend_rpc_buffer_type_context *)buft->context;\n+    ggml_backend_rpc_context * rpc_ctx = (ggml_backend_rpc_context *)backend->context;\n+\n+    return buft_ctx->stub == rpc_ctx->stub;\n+}\n+\n+static ggml_backend_buffer_type_i ggml_backend_rpc_buffer_type_interface = {\n+    /* .get_name         = */ ggml_backend_rpc_buffer_type_name,\n+    /* .alloc_buffer     = */ ggml_backend_rpc_buffer_type_alloc_buffer,\n+    /* .get_alignment    = */ ggml_backend_rpc_buffer_type_get_alignment,\n+    /* .get_max_size     = */ NULL, // defaults to SIZE_MAX\n+    /* .get_alloc_size   = */ ggml_backend_rpc_buffer_type_get_alloc_size,\n+    /* .supports_backend = */ ggml_backend_rpc_buffer_type_supports_backend,\n+    /* .is_host          = */ NULL,\n+};\n+\n+\n+GGML_CALL static const char * ggml_backend_rpc_name(ggml_backend_t backend) {\n+    GGML_PRINT_DEBUG(\"backend name\\n\");\n+    ggml_backend_rpc_context * rpc_ctx = (ggml_backend_rpc_context *)backend->context;\n+\n+    return rpc_ctx->name.c_str();\n+}\n+\n+GGML_CALL static void ggml_backend_rpc_free(ggml_backend_t backend) {\n+    GGML_PRINT_DEBUG(\"backend free\\n\");\n+    ggml_backend_rpc_context * rpc_ctx = (ggml_backend_rpc_context *)backend->context;\n+    delete rpc_ctx;\n+    delete backend;\n+}\n+\n+GGML_CALL static ggml_backend_buffer_type_t ggml_backend_rpc_get_default_buffer_type(ggml_backend_t backend) {\n+    GGML_PRINT_DEBUG(\"get default buffer type\\n\");\n+    ggml_backend_rpc_context * rpc_ctx = (ggml_backend_rpc_context *)backend->context;\n+    static ggml_backend_buffer_type buft;\n+    buft.iface = ggml_backend_rpc_buffer_type_interface;\n+    buft.context = new ggml_backend_rpc_buffer_type_context{rpc_ctx->stub, \"RPC\"};\n+    return &buft;\n+}\n+\n+GGML_CALL static void ggml_backend_rpc_synchronize(ggml_backend_t backend) {\n+    GGML_PRINT_DEBUG(\"synchronize\\n\");\n+    UNUSED(backend);\n+    //GGML_ASSERT(false && \"not implemented\");\n+}\n+\n+static void add_node(ggml::GraphComputeRequest & request, ggml_tensor * node, std::unordered_set<ggml_tensor*> & visited) {\n+    if (node == nullptr) {\n+        return;\n+    }\n+    if (visited.find(node) != visited.end()) {\n+        return;\n+    }\n+    visited.insert(node);\n+    for (int i = 0; i < GGML_MAX_SRC; i++) {\n+        add_node(request, node->src[i], visited);\n+    }\n+    add_node(request, node->view_src, visited);\n+\n+    ggml::Tensor * protobuf_tensor = request.add_tensors();\n+    GGML_PRINT_DEBUG(\"add node: %p\\n\", (void*)node);\n+    serialize_tensor(node, protobuf_tensor);\n+}\n+\n+GGML_CALL static enum ggml_status ggml_backend_rpc_graph_compute(ggml_backend_t backend, ggml_cgraph * cgraph) {\n+    GGML_PRINT_DEBUG(\"graph compute\\n\");\n+    ggml_backend_rpc_context * rpc_ctx = (ggml_backend_rpc_context *)backend->context;\n+    ggml::GraphComputeRequest request;\n+    std::unordered_set<ggml_tensor*> visited;\n+    for (int i = 0; i < cgraph->n_nodes; i++) {\n+        ggml_tensor * node = cgraph->nodes[i];\n+        add_node(request, node, visited);\n+        request.add_nodes(reinterpret_cast<uint64_t>(node));\n+    }\n+    ggml::GraphComputeReply reply;\n+    grpc::ClientContext context;\n+    grpc::Status status = rpc_ctx->stub->GraphCompute(&context, request, &reply);\n+    GGML_ASSERT(status.ok());\n+    return (enum ggml_status)reply.status();\n+}\n+\n+GGML_CALL static bool ggml_backend_rpc_supports_op(ggml_backend_t backend, const ggml_tensor * op) {\n+    GGML_PRINT_DEBUG(\"supports op\\n\");\n+    UNUSED(backend);\n+    UNUSED(op);\n+    GGML_ASSERT(false && \"not implemented\");\n+    return true;\n+}\n+\n+static ggml_backend_i ggml_backend_rpc_interface = {\n+    /* .get_name                = */ ggml_backend_rpc_name,\n+    /* .free                    = */ ggml_backend_rpc_free,\n+    /* .get_default_buffer_type = */ ggml_backend_rpc_get_default_buffer_type,\n+    /* .set_tensor_async        = */ NULL,\n+    /* .get_tensor_async        = */ NULL,\n+    /* .cpy_tensor_async        = */ NULL,\n+    /* .synchronize             = */ ggml_backend_rpc_synchronize,\n+    /* .graph_plan_create       = */ NULL,\n+    /* .graph_plan_free         = */ NULL,\n+    /* .graph_plan_compute      = */ NULL,\n+    /* .graph_compute           = */ ggml_backend_rpc_graph_compute,\n+    /* .supports_op             = */ ggml_backend_rpc_supports_op,\n+    /* .event_new               = */ NULL,\n+    /* .event_free              = */ NULL,\n+    /* .event_record            = */ NULL,\n+    /* .event_wait              = */ NULL,\n+    /* .event_synchronize       = */ NULL,\n+};\n+\n+GGML_CALL ggml_backend_t ggml_backend_rpc_init(const char * endpoint) {\n+    GGML_PRINT_DEBUG(\"backend init\\n\");\n+    auto channel = grpc::CreateChannel(endpoint, grpc::InsecureChannelCredentials());\n+    ggml_backend_rpc_context * ctx = new ggml_backend_rpc_context {\n+        /* .endpoint = */ endpoint,\n+        /* .name   = */ \"RPC\",\n+        /* .stub   = */ ggml::Backend::NewStub(channel)\n+    };\n+\n+    ggml_backend_t rpc_backend = new ggml_backend {\n+        /* .guid      = */ ggml_backend_rpc_guid(),\n+        /* .interface = */ ggml_backend_rpc_interface,\n+        /* .context   = */ ctx\n+    };\n+\n+    return rpc_backend;\n+}\n+\n+GGML_API GGML_CALL bool ggml_backend_is_rpc(ggml_backend_t backend) {\n+    return backend != NULL && ggml_guid_matches(backend->guid, ggml_backend_rpc_guid());\n+}\n+\n+// Server-side implementation of the RPC backend\n+\n+BackendImpl::BackendImpl() {\n+    // the RPC backend simply delegates to one of the existing backends\n+#ifdef GGML_USE_CUBLAS\n+    fprintf(stderr, \"%s: using CUDA backend\\n\", __func__);\n+    backend = ggml_backend_cuda_init(0); // init device 0\n+    if (!backend) {\n+        fprintf(stderr, \"%s: ggml_backend_cuda_init() failed\\n\", __func__);\n+    }\n+#endif\n+\n+#ifdef GGML_USE_METAL\n+    fprintf(stderr, \"%s: using Metal backend\\n\", __func__);\n+    backend = ggml_backend_metal_init();\n+    if (!backend) {\n+        fprintf(stderr, \"%s: ggml_backend_metal_init() failed\\n\", __func__);\n+    }\n+#endif\n+\n+    // if there aren't GPU Backends fallback to CPU backend\n+    if (!backend) {\n+        fprintf(stderr, \"%s: using CPU backend\\n\", __func__);\n+        backend = ggml_backend_cpu_init();\n+    }\n+}\n+\n+BackendImpl::~BackendImpl() {\n+    ggml_backend_free(backend);\n+}\n+\n+grpc::Status BackendImpl::GetAlignment(grpc::ServerContext* context, const ggml::GetAlignmentRequest* request, ggml::GetAlignmentReply* reply) {\n+    GGML_PRINT_DEBUG(\"GetAlignment\\n\");\n+    UNUSED(context);\n+    UNUSED(request);\n+    ggml_backend_buffer_type_t buft = ggml_backend_get_default_buffer_type(backend);\n+    reply->set_alignment(ggml_backend_buft_get_alignment(buft));\n+    return grpc::Status::OK;\n+}\n+\n+grpc::Status BackendImpl::GetAllocSize(grpc::ServerContext* context, const ggml::GetAllocSizeRequest* request, ggml::GetAllocSizeReply* reply) {\n+    GGML_PRINT_DEBUG(\"GetAllocSize\\n\");\n+    UNUSED(context);\n+    struct ggml_init_params params {\n+        /*.mem_size   =*/ ggml_tensor_overhead(),\n+        /*.mem_buffer =*/ NULL,\n+        /*.no_alloc   =*/ true,\n+    };\n+    struct ggml_context * ctx = ggml_init(params);\n+    ggml_tensor * tensor = deserialize_tensor(ctx, request->tensor());\n+    size_t size = ggml_backend_buft_get_alloc_size(ggml_backend_get_default_buffer_type(backend), tensor);\n+    reply->set_size(size);\n+    ggml_free(ctx);\n+    return grpc::Status::OK;\n+}\n+\n+grpc::Status BackendImpl::AllocateBuffer(grpc::ServerContext* context, const ggml::AllocateBufferRequest* request, ggml::AllocateBufferReply* reply) {\n+    GGML_PRINT_DEBUG(\"AllocateBuffer, size: %u\\n\", request->size());\n+    UNUSED(context);\n+    ggml_backend_buffer_type_t buft = ggml_backend_get_default_buffer_type(backend);\n+    ggml_backend_buffer_t buffer = ggml_backend_buft_alloc_buffer(buft, request->size());\n+    reply->set_bufptr(reinterpret_cast<uint64_t>(buffer));\n+    reply->set_size(buffer->size);\n+    GGML_PRINT_DEBUG(\"bufptr: %p, size: %lu\\n\", (void*)buffer, buffer->size);\n+    return grpc::Status::OK;\n+}\n+\n+grpc::Status BackendImpl::BufferGetBase(grpc::ServerContext* context, const ggml::BufferGetBaseRequest* request, ggml::BufferGetBaseReply* reply) {\n+    GGML_PRINT_DEBUG(\"BufferGetBase, bufptr: %p\\n\", (void*)request->bufptr());\n+    UNUSED(context);\n+    ggml_backend_buffer_t buffer = reinterpret_cast<ggml_backend_buffer_t>(request->bufptr());\n+    void * base = ggml_backend_buffer_get_base(buffer);\n+    GGML_PRINT_DEBUG(\"baseptr: %p\\n\", base);\n+    reply->set_baseptr(reinterpret_cast<uint64_t>(base));\n+    return grpc::Status::OK;\n+}\n+\n+grpc::Status BackendImpl::FreeBuffer(grpc::ServerContext* context, const ggml::FreeBufferRequest* request, ggml::FreeBufferReply* reply) {\n+    GGML_PRINT_DEBUG(\"FreeBuffer, bufptr: %p\\n\", (void*)request->bufptr());\n+    UNUSED(context);\n+    UNUSED(reply);\n+    ggml_backend_buffer_t buffer = reinterpret_cast<ggml_backend_buffer_t>(request->bufptr());\n+    ggml_backend_buffer_free(buffer);\n+    return grpc::Status::OK;\n+}\n+\n+grpc::Status BackendImpl::BufferClear(grpc::ServerContext* context, const ggml::BufferClearRequest* request, ggml::BufferClearReply* reply) {\n+    GGML_PRINT_DEBUG(\"BufferClear, bufptr: %p, value: %u\\n\", (void*)request->bufptr(), request->value());\n+    UNUSED(context);\n+    UNUSED(reply);\n+    ggml_backend_buffer_t buffer = reinterpret_cast<ggml_backend_buffer_t>(request->bufptr());\n+    ggml_backend_buffer_clear(buffer, request->value());\n+    return grpc::Status::OK;\n+}\n+\n+grpc::Status BackendImpl::InitTensor(grpc::ServerContext* context, const ggml::InitTensorRequest* request, ggml::InitTensorReply* reply) {\n+    GGML_PRINT_DEBUG(\"InitTensor\\n\");\n+    UNUSED(context);\n+    struct ggml_init_params params {\n+        /*.mem_size   =*/ ggml_tensor_overhead(),\n+        /*.mem_buffer =*/ NULL,\n+        /*.no_alloc   =*/ true,\n+    };\n+    struct ggml_context * ctx = ggml_init(params);\n+    ggml_tensor * tensor = deserialize_tensor(ctx, request->tensor());\n+    ggml_backend_buffer_init_tensor(tensor->buffer, tensor);\n+    serialize_tensor(tensor, reply->mutable_tensor());\n+    ggml_free(ctx);\n+    return grpc::Status::OK;\n+}\n+\n+grpc::Status BackendImpl::SetTensor(grpc::ServerContext* context, const ggml::SetTensorRequest* request, ggml::SetTensorReply* reply) {\n+    UNUSED(context);\n+    UNUSED(reply);\n+    struct ggml_init_params params {\n+            /*.mem_size   =*/ ggml_tensor_overhead(),\n+            /*.mem_buffer =*/ NULL,\n+            /*.no_alloc   =*/ true,\n+    };\n+    struct ggml_context * ctx = ggml_init(params);\n+    struct ggml_tensor * tensor = deserialize_tensor(ctx, request->tensor());\n+    GGML_PRINT_DEBUG(\"SetTensor, bufptr: %p, dataptr: %p, offset: %u, size: %lu\\n\", (void*)tensor->buffer,\n+        (void*)tensor->data, request->offset(), request->data().size());\n+    ggml_backend_tensor_set(tensor, request->data().c_str(), request->offset(), request->data().size());\n+    ggml_free(ctx);\n+    return grpc::Status::OK;\n+}\n+\n+grpc::Status BackendImpl::GetTensor(grpc::ServerContext* context, const ggml::GetTensorRequest* request, ggml::GetTensorReply* reply) {\n+    UNUSED(context);\n+    struct ggml_init_params params {\n+            /*.mem_size   =*/ ggml_tensor_overhead(),\n+            /*.mem_buffer =*/ NULL,\n+            /*.no_alloc   =*/ true,\n+    };\n+    struct ggml_context * ctx = ggml_init(params);\n+    struct ggml_tensor * tensor = deserialize_tensor(ctx, request->tensor());\n+    GGML_PRINT_DEBUG(\"GetTensor, bufptr: %p, dataptr: %p, offset: %u, size: %u\\n\", (void*)tensor->buffer,\n+        (void*)tensor->data, request->offset(), request->size());\n+    std::string data(request->size(), 0);\n+    ggml_backend_tensor_get(tensor, &data[0], request->offset(), request->size());\n+    reply->set_data(data);\n+    ggml_free(ctx);\n+    return grpc::Status::OK;\n+}\n+\n+grpc::Status BackendImpl::CopyTensor(grpc::ServerContext* context, const ggml::CopyTensorRequest* request, ggml::CopyTensorReply* reply) {\n+    UNUSED(context);\n+    struct ggml_init_params params {\n+            /*.mem_size   =*/ 2*ggml_tensor_overhead(),\n+            /*.mem_buffer =*/ NULL,\n+            /*.no_alloc   =*/ true,\n+    };\n+    struct ggml_context * ctx = ggml_init(params);\n+    struct ggml_tensor * src = deserialize_tensor(ctx, request->src());\n+    struct ggml_tensor * dst = deserialize_tensor(ctx, request->dst());\n+    GGML_PRINT_DEBUG(\"CopyTensor, src: %p, dst: %p\\n\", (void*)src, (void*)dst);\n+    bool result = ggml_backend_buffer_copy_tensor(src, dst);\n+    reply->set_result(result);\n+    ggml_free(ctx);\n+    return grpc::Status::OK;\n+}\n+\n+static struct ggml_tensor * create_node(uint64_t id,\n+                                        struct ggml_context * ctx,\n+                                        const ggml::GraphComputeRequest* request,\n+                                        std::unordered_map<uint64_t, struct ggml_tensor*> & tensor_map) {\n+    if (id == 0) {\n+        return nullptr;\n+    }\n+    if (tensor_map.find(id) != tensor_map.end()) {\n+        return tensor_map[id];\n+    }\n+    for (int i = 0; i < request->tensors_size(); i++) {\n+        if (request->tensors(i).id() == id) {\n+            GGML_PRINT_DEBUG(\"create node: %lx\\n\", id);\n+            const ggml::Tensor & protobuf_tensor = request->tensors(i);\n+            struct ggml_tensor * result = deserialize_tensor(ctx, protobuf_tensor);\n+            tensor_map[id] = result;\n+            for (int i = 0; i < GGML_MAX_SRC; i++) {\n+                result->src[i] = create_node(protobuf_tensor.src(i), ctx, request, tensor_map);\n+            }\n+            result->view_src = create_node(protobuf_tensor.view_src(), ctx, request, tensor_map);\n+            result->view_offs = protobuf_tensor.view_offs();\n+            return result;\n+        }\n+    }\n+    GGML_ASSERT(false && \"tensor not found\");\n+    return nullptr;\n+}\n+\n+grpc::Status BackendImpl::GraphCompute(grpc::ServerContext* context, const ggml::GraphComputeRequest* request, ggml::GraphComputeReply* reply) {\n+    GGML_PRINT_DEBUG(\"GraphCompute\\n\");\n+    UNUSED(context);\n+    int num_tensors = request->tensors_size();\n+    struct ggml_init_params params {\n+            /*.mem_size   =*/ ggml_tensor_overhead() * num_tensors,\n+            /*.mem_buffer =*/ NULL,\n+            /*.no_alloc   =*/ true,\n+    };\n+    struct ggml_context * ctx = ggml_init(params);\n+    std::unordered_map<uint64_t, ggml_tensor*> tensor_map;\n+\n+    int num_nodes = request->nodes_size();\n+    static size_t buf_size = ggml_tensor_overhead()*num_nodes + ggml_graph_overhead();\n+    static std::vector<uint8_t> buf(buf_size);\n+\n+    struct ggml_init_params params0 = {\n+        /*.mem_size   =*/ buf_size,\n+        /*.mem_buffer =*/ buf.data(),\n+        /*.no_alloc   =*/ true,\n+    };\n+\n+    struct ggml_context * ctx0 = ggml_init(params0);\n+    struct ggml_cgraph * graph = ggml_new_graph_custom(ctx0, num_nodes, false);\n+    graph->n_nodes = num_nodes;\n+    for (int i = 0; i < num_nodes; i++) {\n+        graph->nodes[i] = create_node(request->nodes(i), ctx, request, tensor_map);\n+    }\n+    ggml_status status = ggml_backend_graph_compute(backend, graph);\n+    reply->set_status(status);\n+    ggml_free(ctx);\n+    ggml_free(ctx0);\n+    return grpc::Status::OK;\n+}\ndiff --git a/src/ggml-rpc.h b/src/ggml-rpc.h\nnew file mode 100644\nindex 000000000..56555d6c0\n--- /dev/null\n+++ b/src/ggml-rpc.h\n@@ -0,0 +1,38 @@\n+#pragma once\n+\n+#include \"ggml.h\"\n+#include \"ggml-backend.h\"\n+#include \"ggml-rpc.grpc.pb.h\"\n+\n+#ifdef  __cplusplus\n+extern \"C\" {\n+#endif\n+\n+// backend API\n+GGML_API GGML_CALL ggml_backend_t ggml_backend_rpc_init(const char * endpoint);\n+GGML_API GGML_CALL bool ggml_backend_is_rpc(ggml_backend_t backend);\n+\n+class BackendImpl : public ggml::Backend::Service {\n+public:\n+    BackendImpl();\n+    ~BackendImpl();\n+\n+    grpc::Status GetAlignment(grpc::ServerContext* context, const ggml::GetAlignmentRequest* request, ggml::GetAlignmentReply* reply) override;\n+    grpc::Status GetAllocSize(grpc::ServerContext* context, const ggml::GetAllocSizeRequest* request, ggml::GetAllocSizeReply* reply) override;\n+    grpc::Status AllocateBuffer(grpc::ServerContext* context, const ggml::AllocateBufferRequest* request, ggml::AllocateBufferReply* reply) override;\n+    grpc::Status BufferGetBase(grpc::ServerContext* context, const ggml::BufferGetBaseRequest* request, ggml::BufferGetBaseReply* reply) override;\n+    grpc::Status FreeBuffer(grpc::ServerContext* context, const ggml::FreeBufferRequest* request, ggml::FreeBufferReply* reply) override;\n+    grpc::Status BufferClear(grpc::ServerContext* context, const ggml::BufferClearRequest* request, ggml::BufferClearReply* reply) override;\n+    grpc::Status InitTensor(grpc::ServerContext* context, const ggml::InitTensorRequest* request, ggml::InitTensorReply* reply) override;\n+    grpc::Status SetTensor(grpc::ServerContext* context, const ggml::SetTensorRequest* request, ggml::SetTensorReply* reply) override;\n+    grpc::Status GetTensor(grpc::ServerContext* context, const ggml::GetTensorRequest* request, ggml::GetTensorReply* reply) override;\n+    grpc::Status CopyTensor(grpc::ServerContext* context, const ggml::CopyTensorRequest* request, ggml::CopyTensorReply* reply) override;\n+    grpc::Status GraphCompute(grpc::ServerContext* context, const ggml::GraphComputeRequest* request, ggml::GraphComputeReply* reply) override;\n+\n+private:\n+    ggml_backend_t backend = NULL;\n+};\n+\n+#ifdef  __cplusplus\n+}\n+#endif\ndiff --git a/src/ggml-rpc.proto b/src/ggml-rpc.proto\nnew file mode 100644\nindex 000000000..ef8393794\n--- /dev/null\n+++ b/src/ggml-rpc.proto\n@@ -0,0 +1,131 @@\n+syntax = \"proto3\";\n+\n+package ggml;\n+\n+service Backend {\n+\n+  rpc GetAlignment (GetAlignmentRequest) returns (GetAlignmentReply) {}\n+  rpc GetAllocSize (GetAllocSizeRequest) returns (GetAllocSizeReply) {}\n+  rpc AllocateBuffer (AllocateBufferRequest) returns (AllocateBufferReply) {}\n+  rpc BufferGetBase (BufferGetBaseRequest) returns (BufferGetBaseReply) {}\n+  rpc FreeBuffer (FreeBufferRequest) returns (FreeBufferReply) {}\n+  rpc BufferClear (BufferClearRequest) returns (BufferClearReply) {}\n+\n+  rpc InitTensor (InitTensorRequest) returns (InitTensorReply) {}\n+  rpc SetTensor (SetTensorRequest) returns (SetTensorReply) {}\n+  rpc GetTensor (GetTensorRequest) returns (GetTensorReply) {}\n+  rpc CopyTensor (CopyTensorRequest) returns (CopyTensorReply) {}\n+  rpc GraphCompute (GraphComputeRequest) returns (GraphComputeReply) {}\n+}\n+\n+message Tensor {\n+  // use the local tensor address as ID\n+  uint64 id = 1;\n+\n+  int32 type = 2;\n+  int32 backend = 3;\n+  uint64 bufptr = 4;\n+  repeated int64 ne = 5;\n+  repeated uint32 nb = 6;\n+  int32 op = 7;\n+  repeated int32 op_params = 8;\n+  int32 flags = 9;\n+  repeated uint64 src = 10;\n+  uint64 view_src = 11;\n+  uint32 view_offs = 12;\n+  uint64 data = 13;\n+  string name = 14;\n+  uint64 extra = 15;\n+}\n+\n+message GetAlignmentRequest {\n+}\n+\n+message GetAlignmentReply {\n+  uint32 alignment = 1;\n+}\n+\n+message GetAllocSizeRequest {\n+  Tensor tensor = 1;\n+}\n+\n+message GetAllocSizeReply {\n+  uint32 size = 1;\n+}\n+\n+message AllocateBufferRequest {\n+  uint32 size = 1;\n+}\n+\n+message AllocateBufferReply {\n+  uint64 bufptr = 1;\n+  uint32 size = 2;\n+}\n+\n+message BufferGetBaseRequest {\n+  uint64 bufptr = 1;\n+}\n+\n+message BufferGetBaseReply {\n+  uint64 baseptr = 1;\n+}\n+\n+message FreeBufferRequest {\n+  uint64 bufptr = 1;\n+}\n+\n+message FreeBufferReply {\n+}\n+\n+message BufferClearRequest {\n+  uint64 bufptr = 1;\n+  uint32 value = 2;\n+}\n+\n+message BufferClearReply {\n+}\n+\n+message InitTensorRequest {\n+  Tensor tensor = 1;\n+}\n+\n+message InitTensorReply {\n+  Tensor tensor = 1;\n+}\n+\n+message SetTensorRequest {\n+  Tensor tensor = 1;\n+  uint32 offset = 2;\n+  bytes data = 3;\n+}\n+\n+message SetTensorReply {\n+}\n+\n+message GetTensorRequest {\n+  Tensor tensor = 1;\n+  uint32 offset = 2;\n+  uint32 size = 3;\n+}\n+\n+message GetTensorReply {\n+  bytes data = 1;\n+}\n+\n+message CopyTensorRequest {\n+  Tensor src = 2;\n+  Tensor dst = 3;\n+}\n+\n+message CopyTensorReply {\n+  bool result = 1;\n+}\n+\n+message GraphComputeRequest {\n+  repeated Tensor tensors = 1;\n+  repeated uint64 nodes = 2;\n+}\n+\n+message GraphComputeReply {\n+  int32 status = 1;\n+}\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Tensor Mapping**: Ensure buffer pointers from remote tensors are accurately mapped to local buffers. Use the provided `map_tensor` function structure. \n\n2. **Graph Reconstruction Issues**: The gpt-2 model is producing garbage outputs. Investigate potential errors during compute graph reconstruction.\n\n3. **C++ Compatibility**: gRPC requires C++17. Modify build configuration by adding `-DCMAKE_CXX_STANDARD=17` to CMake. Verify compatibility with C++11.\n\n4. **Allocation Error**: `GetAllocSize` cannot be buffered; consider returning `ggml_nbytes` as a temporary solution.\n\n5. **Performance Monitoring**: Evaluate the predict time for CPU versus RPC; assess the impact of buffer allocations on performance.\n\n6. **Debugging Logs**: Comment out debug print statements in the RPC backend to reduce log volume for clarity during debugging."
      }
    ],
    "codediff_length": 44650
  },
  {
    "index": 105,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/ggml-cuda/clamp.cu b/src/ggml-cuda/clamp.cu\nindex 611db8864..fe415e7f7 100644\n--- a/src/ggml-cuda/clamp.cu\n+++ b/src/ggml-cuda/clamp.cu\n@@ -1,20 +1,24 @@\n #include \"clamp.cuh\"\n \n+static __device__ __forceinline__ float op_clamp(float x, float min, float max) {\n+    return fminf(fmaxf(x, min), max);\n+}\n+\n template <class T>\n-static __global__ void op_clamp(const T * x, T * dst, const T min, const T max, const int k) {\n+static __global__ void op_clamp_kernel(const T * x, T * dst, const T min, const T max, const int k) {\n     const int i = blockDim.x*blockIdx.x + threadIdx.x;\n \n     if (i >= k) {\n         return;\n     }\n \n-    dst[i] = x[i] < min ? min : (x[i] > max ? max : x[i]);\n+    dst[i] = (T)op_clamp((float)x[i], (float)min, (float)max);\n }\n \n template <class T>\n static void clamp_cuda(const T * x, T * dst, const T min, const T max, const int k, cudaStream_t stream) {\n     const int num_blocks = (k + CUDA_CLAMP_BLOCK_SIZE - 1) / CUDA_CLAMP_BLOCK_SIZE;\n-    op_clamp<<<num_blocks, CUDA_CLAMP_BLOCK_SIZE, 0, stream>>>(x, dst, min, max, k);\n+    op_clamp_kernel<<<num_blocks, CUDA_CLAMP_BLOCK_SIZE, 0, stream>>>(x, dst, min, max, k);\n }\n \n \ndiff --git a/src/ggml-cuda/unary.cu b/src/ggml-cuda/unary.cu\nindex 9b0eaaccd..ec5773e01 100644\n--- a/src/ggml-cuda/unary.cu\n+++ b/src/ggml-cuda/unary.cu\n@@ -1,447 +1,213 @@\n #include \"unary.cuh\"\n \n-template <class T>\n-static __global__ void op_abs(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-\n-    dst[i] = fabsf(x[i]);\n+static __device__ __forceinline__ float op_abs(float x) {\n+    return fabsf(x);\n }\n \n-template <class T>\n-static __global__ void op_sgn(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-\n-    dst[i] = (T)(x[i] > (T)0.f ? 1.f : ((x[i] < (T)0.f ? -1.f : 0.f)));\n+static __device__ __forceinline__ float op_sgn(float x) {\n+    return (x > 0.f ? 1.f : ((x < 0.f ? -1.f : 0.f)));\n }\n \n-template <class T>\n-static __global__ void op_neg(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-\n-    dst[i] = -x[i];\n+static __device__ __forceinline__ float op_neg(float x) {\n+    return -x;\n }\n \n-template <class T>\n-static __global__ void op_step(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-\n-    dst[i] = x[i] > (T)0.0f;\n+static __device__ __forceinline__ float op_step(float x) {\n+    return x > 0.0f;\n }\n \n-template <class T>\n-static __global__ void op_gelu(const T * x, T * dst, const int k) {\n-    const T GELU_COEF_A    = 0.044715f;\n-    const T SQRT_2_OVER_PI = 0.79788456080286535587989211986876f;\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n+static __device__ __forceinline__ float op_gelu(float x) {\n+    const float GELU_COEF_A    = 0.044715f;\n+    const float SQRT_2_OVER_PI = 0.79788456080286535587989211986876f;\n \n-    T xi = x[i];\n-    dst[i] = (T)0.5f*xi*((T)1.0f + (T)tanhf(SQRT_2_OVER_PI*xi*((T)1.0f + GELU_COEF_A*xi*xi)));\n+    return 0.5f*x*(1.0f + tanhf(SQRT_2_OVER_PI*x*(1.0f + GELU_COEF_A*x*x)));\n }\n \n-template <class T>\n-static __global__ void op_gelu_quick(const T * x, T * dst, int k) {\n-    const T GELU_QUICK_COEF = -1.702f;\n-    const int i  = blockDim.x*blockIdx.x + threadIdx.x;\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = x[i] * ((T)1.0f / ((T)1.0f + (T)expf(GELU_QUICK_COEF * x[i])));\n-}\n+static __device__ __forceinline__ float op_gelu_quick(float x) {\n+    const float GELU_QUICK_COEF = -1.702f;\n \n-template <class T>\n-static __global__ void op_silu(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = x[i] / ((T)1.0f + (T)expf(-x[i]));\n+    return x * (1.0f / (1.0f + expf(GELU_QUICK_COEF * x)));\n }\n \n-template <class T>\n-static __global__ void op_silu_back(\n-        const T * grad, const T * xf, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-\n-    const T xfi = xf[i];\n-    const T s = (T)1.0f / ((T)1.0f + (T)expf(-xfi));\n-    dst[i] = grad[i] * s * ((T)1.0f + xfi * ((T)1.0f - s));\n+static __device__ __forceinline__ float op_silu(float x) {\n+    return x / (1.0f + expf(-x));\n }\n \n-template <class T>\n-static __global__ void op_tanh(const T * x, T * dst, int k) {\n-    const int i  = blockDim.x*blockIdx.x + threadIdx.x;\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = tanhf(x[i]);\n+static __device__ __forceinline__ float op_tanh(float x) {\n+    return tanhf(x);\n }\n \n-template <class T>\n-static __global__ void op_relu(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = fmaxf(x[i], 0);\n+static __device__ __forceinline__ float op_relu(float x) {\n+    return fmaxf(x, 0);\n }\n \n-template <class T>\n-static __global__ void op_sigmoid(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = (T)1.0f / ((T)1.0f + (T)expf(-x[i]));\n+static __device__ __forceinline__ float op_sigmoid(float x) {\n+    return 1.0f / (1.0f + expf(-x));\n }\n \n-template <class T>\n-static __global__ void op_hardsigmoid(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = fminf(1.0f, fmaxf(0.0f, (x[i] + (T)3.0f) / (T)6.0f));\n+static __device__ __forceinline__ float op_hardsigmoid(float x) {\n+    return fminf(1.0f, fmaxf(0.0f, (x + 3.0f) / 6.0f));\n }\n \n-template <class T>\n-static __global__ void op_hardswish(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = x[i] * (T)fminf(1.0f, fmaxf(0.0f, (x[i] + (T)3.0f) / (T)6.0f));\n+static __device__ __forceinline__ float op_hardswish(float x) {\n+    return x * fminf(1.0f, fmaxf(0.0f, (x + 3.0f) / 6.0f));\n }\n \n-template <class T>\n-static __global__ void op_exp(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = expf(x[i]);\n+static __device__ __forceinline__ float op_exp(float x) {\n+    return expf(x);\n }\n \n-template <class T>\n-static __global__ void op_leaky_relu(const T * x, T * dst, const int k, const float negative_slope) {\n-    const int i  = blockDim.x*blockIdx.x + threadIdx.x;\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = (T)fmaxf(x[i], 0) + (T)fminf(x[i], 0.0f) * (T)negative_slope;\n+static __device__ __forceinline__ float op_sqr(float x) {\n+    return x * x;\n }\n \n-template <class T>\n-static __global__ void op_sqr(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = x[i] * x[i];\n+static __device__ __forceinline__ float op_sqrt(float x) {\n+    return sqrtf(x);\n }\n \n-template <class T>\n-static __global__ void op_sqrt(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = sqrtf(x[i]);\n+static __device__ __forceinline__ float op_sin(float x) {\n+    return sinf(x);\n }\n \n-template <class T>\n-static __global__ void op_sin(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = sinf(x[i]);\n+static __device__ __forceinline__ float op_cos(float x) {\n+    return cosf(x);\n }\n \n-template <class T>\n-static __global__ void op_cos(const T * x, T * dst, const int k) {\n-    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n-\n-    if (i >= k) {\n-        return;\n-    }\n-    dst[i] = cosf(x[i]);\n+static __device__ __forceinline__ float op_log(float x) {\n+    return logf(x);\n }\n \n-template <class T>\n-static __global__ void op_log(const T * x, T * dst, const int k) {\n+template <float (*op)(float), typename T>\n+static __global__ void unary_op_kernel(const T * x, T * dst, const int k) {\n     const int i = blockDim.x*blockIdx.x + threadIdx.x;\n \n     if (i >= k) {\n         return;\n     }\n-    dst[i] = logf(x[i]);\n-}\n \n-template <class T>\n-static void abs_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_NEG_BLOCK_SIZE - 1) / CUDA_NEG_BLOCK_SIZE;\n-    op_abs<<<num_blocks, CUDA_NEG_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+    dst[i] = (T)op((float)x[i]);\n }\n \n-template <class T>\n-static void sgn_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n+template <float (*op)(float), typename T>\n+static void unary_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n     const int num_blocks = (k + CUDA_NEG_BLOCK_SIZE - 1) / CUDA_NEG_BLOCK_SIZE;\n-    op_sgn<<<num_blocks, CUDA_NEG_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+    unary_op_kernel<op><<<num_blocks, CUDA_NEG_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n }\n \n-template <class T>\n-static void neg_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_NEG_BLOCK_SIZE - 1) / CUDA_NEG_BLOCK_SIZE;\n-    op_neg<<<num_blocks, CUDA_NEG_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n-}\n+template <float (*op)(float)>\n+void ggml_cuda_op_unary(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    const ggml_tensor * src0 = dst->src[0];\n+    const void * src0_d = src0->data;\n+    void * dst_d = dst->data;\n+    cudaStream_t stream = ctx.stream();\n \n-template <class T>\n-static void step_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_STEP_BLOCK_SIZE - 1) / CUDA_STEP_BLOCK_SIZE;\n-    op_step<<<num_blocks, CUDA_STEP_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n-}\n+    GGML_ASSERT(ggml_is_contiguous(src0));\n \n-template <class T>\n-static void gelu_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_GELU_BLOCK_SIZE - 1) / CUDA_GELU_BLOCK_SIZE;\n-    op_gelu<<<num_blocks, CUDA_GELU_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n-}\n+    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n+    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n+    GGML_ASSERT(src0->type == dst->type);\n \n-template <class T>\n-static void gelu_quick_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_GELU_BLOCK_SIZE - 1) / CUDA_GELU_BLOCK_SIZE;\n-    op_gelu_quick<<<num_blocks, CUDA_GELU_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+    if (src0->type == GGML_TYPE_F16) {\n+        unary_cuda<op>((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n+    } else {\n+        unary_cuda<op>((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n+    }\n }\n \n-template <class T>\n-static void silu_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_SILU_BLOCK_SIZE - 1) / CUDA_SILU_BLOCK_SIZE;\n-    op_silu<<<num_blocks, CUDA_SILU_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_abs(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_abs>(ctx, dst);\n }\n \n-template <class T>\n-static void silu_back_cuda(const T * grad, const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_SILU_BACK_BLOCK_SIZE - 1) / CUDA_SILU_BLOCK_SIZE;\n-    op_silu_back<<<num_blocks, CUDA_SILU_BACK_BLOCK_SIZE, 0, stream>>>(grad, x, dst, k);\n+void ggml_cuda_op_sgn(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_sgn>(ctx, dst);\n }\n \n-template <class T>\n-static void tanh_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_TANH_BLOCK_SIZE - 1) / CUDA_TANH_BLOCK_SIZE;\n-    op_tanh<<<num_blocks, CUDA_TANH_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_neg(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_neg>(ctx, dst);\n }\n \n-template <class T>\n-static void relu_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_RELU_BLOCK_SIZE - 1) / CUDA_RELU_BLOCK_SIZE;\n-    op_relu<<<num_blocks, CUDA_RELU_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_step(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_step>(ctx, dst);\n }\n \n-template <class T>\n-static void sigmoid_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_SIGMOID_BLOCK_SIZE - 1) / CUDA_SIGMOID_BLOCK_SIZE;\n-    op_sigmoid<<<num_blocks, CUDA_SIGMOID_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_gelu(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_gelu>(ctx, dst);\n }\n \n-template <class T>\n-static void hardsigmoid_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_HARDSIGMOID_BLOCK_SIZE - 1) / CUDA_HARDSIGMOID_BLOCK_SIZE;\n-    op_hardsigmoid<<<num_blocks, CUDA_HARDSIGMOID_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_gelu_quick(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_gelu_quick>(ctx, dst);\n }\n \n-template <class T>\n-static void hardswish_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_HARDSWISH_BLOCK_SIZE - 1) / CUDA_HARDSWISH_BLOCK_SIZE;\n-    op_hardswish<<<num_blocks, CUDA_HARDSWISH_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_silu(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_silu>(ctx, dst);\n }\n \n-template <class T>\n-static void exp_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_EXP_BLOCK_SIZE - 1) / CUDA_EXP_BLOCK_SIZE;\n-    op_exp<<<num_blocks, CUDA_EXP_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_tanh(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_tanh>(ctx, dst);\n }\n \n-template <class T>\n-static void leaky_relu_cuda(const T * x, T * dst, const int k, const float negative_slope, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_RELU_BLOCK_SIZE - 1) / CUDA_RELU_BLOCK_SIZE;\n-    op_leaky_relu<<<num_blocks, CUDA_RELU_BLOCK_SIZE, 0, stream>>>(x, dst, k, negative_slope);\n+void ggml_cuda_op_relu(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_relu>(ctx, dst);\n }\n \n-template <class T>\n-static void sqr_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_SQR_BLOCK_SIZE - 1) / CUDA_SQR_BLOCK_SIZE;\n-    op_sqr<<<num_blocks, CUDA_SQR_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_sigmoid(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_sigmoid>(ctx, dst);\n }\n \n-template <class T>\n-static void sqrt_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_SQRT_BLOCK_SIZE - 1) / CUDA_SQRT_BLOCK_SIZE;\n-    op_sqrt<<<num_blocks, CUDA_SQRT_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_hardsigmoid(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_hardsigmoid>(ctx, dst);\n }\n \n-template <class T>\n-static void sin_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_SIN_BLOCK_SIZE - 1) / CUDA_SIN_BLOCK_SIZE;\n-    op_sin<<<num_blocks, CUDA_SIN_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_hardswish(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_hardswish>(ctx, dst);\n }\n \n-template <class T>\n-static void cos_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_COS_BLOCK_SIZE - 1) / CUDA_COS_BLOCK_SIZE;\n-    op_cos<<<num_blocks, CUDA_COS_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_exp(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_exp>(ctx, dst);\n }\n \n-template <class T>\n-static void log_cuda(const T * x, T * dst, const int k, cudaStream_t stream) {\n-    const int num_blocks = (k + CUDA_COS_BLOCK_SIZE - 1) / CUDA_COS_BLOCK_SIZE;\n-    op_log<<<num_blocks, CUDA_COS_BLOCK_SIZE, 0, stream>>>(x, dst, k);\n+void ggml_cuda_op_sqr(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_sqr>(ctx, dst);\n }\n \n-void ggml_cuda_op_abs(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        abs_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        abs_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n+void ggml_cuda_op_sqrt(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_sqrt>(ctx, dst);\n }\n \n-void ggml_cuda_op_sgn(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        sgn_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        sgn_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n+void ggml_cuda_op_sin(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_sin>(ctx, dst);\n }\n \n-void ggml_cuda_op_neg(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        neg_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        neg_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n+void ggml_cuda_op_cos(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_cos>(ctx, dst);\n }\n \n-void ggml_cuda_op_step(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        step_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        step_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n+void ggml_cuda_op_log(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n+    ggml_cuda_op_unary<op_log>(ctx, dst);\n }\n \n-void ggml_cuda_op_gelu(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n+/* silu_back */\n \n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        gelu_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        gelu_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n+static __device__ __forceinline__ float op_silu_back(float grad, float x) {\n+    const float s = 1.0f / (1.0f + expf(-x));\n+    return grad * s * (1.0f + x * (1.0f - s));\n }\n \n-void ggml_cuda_op_silu(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n+template <class T>\n+static __global__ void silu_back_kernel(const T * grad, const T * xf, T * dst, const int k) {\n+    const int i = blockDim.x*blockIdx.x + threadIdx.x;\n \n-    GGML_ASSERT(ggml_is_contiguous(src0));\n+    if (i >= k) {\n+        return;\n+    }\n \n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n+    dst[i] = (T)op_silu_back((float)grad[i], (float)xf[i]);\n+}\n \n-    if (src0->type == GGML_TYPE_F16) {\n-        silu_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        silu_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n+template <class T>\n+static void silu_back_cuda(const T * grad, const T * x, T * dst, const int k, cudaStream_t stream) {\n+    const int num_blocks = (k + CUDA_SILU_BACK_BLOCK_SIZE - 1) / CUDA_SILU_BLOCK_SIZE;\n+    silu_back_kernel<<<num_blocks, CUDA_SILU_BACK_BLOCK_SIZE, 0, stream>>>(grad, x, dst, k);\n }\n \n void ggml_cuda_op_silu_back(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n@@ -467,137 +233,27 @@ void ggml_cuda_op_silu_back(ggml_backend_cuda_context & ctx, ggml_tensor * dst)\n     }\n }\n \n-void ggml_cuda_op_gelu_quick(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n+/* leaky relu */\n \n-    if (src0->type == GGML_TYPE_F16) {\n-        gelu_quick_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        gelu_quick_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n+static __device__ __forceinline__ float op_leaky_relu(float x, const float negative_slope) {\n+    return fmaxf(x, 0) + fminf(x, 0.0f) * negative_slope;\n }\n \n-void ggml_cuda_op_tanh(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        tanh_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        tanh_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n-}\n-\n-void ggml_cuda_op_relu(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        relu_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        relu_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n-}\n-\n-void ggml_cuda_op_sigmoid(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n+template <class T>\n+static __global__ void leaky_relu_kernel(const T * x, T * dst, const int k, const float negative_slope) {\n+    const int i  = blockDim.x*blockIdx.x + threadIdx.x;\n \n-    if (src0->type == GGML_TYPE_F16) {\n-        sigmoid_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        sigmoid_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n+    if (i >= k) {\n+        return;\n     }\n-}\n \n-void ggml_cuda_op_hardsigmoid(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        hardsigmoid_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        hardsigmoid_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n+    dst[i] = (T)op_leaky_relu((float)x[i], negative_slope);\n }\n \n-void ggml_cuda_op_hardswish(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        hardswish_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        hardswish_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n-}\n-\n-void ggml_cuda_op_exp(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        exp_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        exp_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n+template <class T>\n+static void leaky_relu_cuda(const T * x, T * dst, const int k, const float negative_slope, cudaStream_t stream) {\n+    const int num_blocks = (k + CUDA_RELU_BLOCK_SIZE - 1) / CUDA_RELU_BLOCK_SIZE;\n+    leaky_relu_kernel<<<num_blocks, CUDA_RELU_BLOCK_SIZE, 0, stream>>>(x, dst, k, negative_slope);\n }\n \n void ggml_cuda_op_leaky_relu(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n@@ -621,98 +277,3 @@ void ggml_cuda_op_leaky_relu(ggml_backend_cuda_context & ctx, ggml_tensor * dst)\n         leaky_relu_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), negative_slope, stream);\n     }\n }\n-\n-void ggml_cuda_op_sqr(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        sqr_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        sqr_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n-}\n-\n-void ggml_cuda_op_sqrt(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        sqrt_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        sqrt_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n-}\n-\n-void ggml_cuda_op_sin(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        sin_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        sin_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n-}\n-\n-void ggml_cuda_op_cos(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        cos_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        cos_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n-}\n-\n-void ggml_cuda_op_log(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {\n-    const ggml_tensor * src0 = dst->src[0];\n-    const void * src0_d = src0->data;\n-    void * dst_d = dst->data;\n-    cudaStream_t stream = ctx.stream();\n-\n-    GGML_ASSERT(ggml_is_contiguous(src0));\n-\n-    GGML_ASSERT(src0->type == GGML_TYPE_F32 || src0->type == GGML_TYPE_F16);\n-    GGML_ASSERT( dst->type == GGML_TYPE_F32 ||  dst->type == GGML_TYPE_F16);\n-    GGML_ASSERT(src0->type == dst->type);\n-\n-    if (src0->type == GGML_TYPE_F16) {\n-        log_cuda((const half *)src0_d, (half *)dst_d, ggml_nelements(src0), stream);\n-    } else {\n-        log_cuda((const float *)src0_d, (float *)dst_d, ggml_nelements(src0), stream);\n-    }\n-}\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Confirm if `ggml/ci` only runs on the `master` branch to address CI issues when testing changes. \n\n2. For changes in `llama.cpp` that require `ggml` updates, strictly follow the two-PR workflow: \n   - Open a PR in `ggml` first (before merging).\n   - Update the submodule in `llama.cpp` to point to the latest `ggml` branch after merging.\n\n3. Consider transitioning to a monorepo to reduce submodule overhead, making contributions easier and more attractive.\n\n4. Ensure CMake targets in `ggml` are optimized for lean builds, allowing users to compile necessary components without unnecessary overhead.\n\n5. Enhance visibility of `ggml` as an independent project, ensuring it isn't perceived merely as part of larger repos. \n\n6. Explore adding CI runners to `ggml` for better integration testing while establishing longer-term solutions."
      }
    ],
    "codediff_length": 32268
  },
  {
    "index": 106,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/ci/run.sh b/ci/run.sh\nindex e61f639aa..44d5a2a97 100644\n--- a/ci/run.sh\n+++ b/ci/run.sh\n@@ -277,6 +277,15 @@ function gg_run_yolo {\n     grep -q \"truck: 56%\" $OUT/${ci}-main.log\n     grep -q \"bicycle: 59%\" $OUT/${ci}-main.log\n \n+    python3 ../examples/yolo/gguf_add_file.py yolov3-tiny.gguf yolov3-tiny-data.gguf data/coco.names data/labels/*.png\n+\n+    (time ./bin/yolov3-tiny -m yolov3-tiny-data.gguf -i ${path_models}/dog.jpg ) 2>&1 | tee -a $OUT/${ci}-main2.log\n+\n+    grep -q \"dog: 57%\" $OUT/${ci}-main2.log\n+    grep -q \"car: 52%\" $OUT/${ci}-main2.log\n+    grep -q \"truck: 56%\" $OUT/${ci}-main2.log\n+    grep -q \"bicycle: 59%\" $OUT/${ci}-main2.log\n+\n     set +e\n }\n \ndiff --git a/examples/yolo/gguf_add_file.py b/examples/yolo/gguf_add_file.py\nnew file mode 100755\nindex 000000000..bcc1bf700\n--- /dev/null\n+++ b/examples/yolo/gguf_add_file.py\n@@ -0,0 +1,177 @@\n+#!/usr/bin/env python3\n+# gguf_add_file.py srcfile dstfile addfiles ...\n+\n+from __future__ import annotations\n+\n+import logging\n+import argparse\n+import os\n+import sys\n+from pathlib import Path\n+from typing import Any\n+\n+import numpy as np\n+import numpy.typing as npt\n+\n+# Necessary to load the local gguf package\n+if \"NO_LOCAL_GGUF\" not in os.environ and (Path(__file__).parent.parent.parent / 'gguf-py').exists():\n+    sys.path.insert(0, str(Path(__file__).parent.parent))\n+\n+from gguf import GGUFReader, GGUFWriter, ReaderField, GGMLQuantizationType, GGUFEndian, GGUFValueType, Keys  # noqa: E402\n+\n+logger = logging.getLogger(\"ggufi_add_file\")\n+\n+\n+def get_file_host_endian(reader: GGUFReader) -> tuple[str, str]:\n+    host_endian = 'LITTLE' if np.uint32(1) == np.uint32(1).newbyteorder(\"<\") else 'BIG'\n+    if reader.byte_order == 'S':\n+        file_endian = 'BIG' if host_endian == 'LITTLE' else 'LITTLE'\n+    else:\n+        file_endian = host_endian\n+    return (host_endian, file_endian)\n+\n+\n+def get_byteorder(reader: GGUFReader) -> GGUFEndian:\n+    if np.uint32(1) == np.uint32(1).newbyteorder(\"<\"):\n+        # Host is little endian\n+        host_endian = GGUFEndian.LITTLE\n+        swapped_endian = GGUFEndian.BIG\n+    else:\n+        # Sorry PDP or other weird systems that don't use BE or LE.\n+        host_endian = GGUFEndian.BIG\n+        swapped_endian = GGUFEndian.LITTLE\n+\n+    if reader.byte_order == \"S\":\n+        return swapped_endian\n+    else:\n+        return host_endian\n+\n+\n+def decode_field(field: ReaderField) -> Any:\n+    if field and field.types:\n+        main_type = field.types[0]\n+\n+        if main_type == GGUFValueType.ARRAY:\n+            sub_type = field.types[-1]\n+\n+            if sub_type == GGUFValueType.STRING:\n+                return [str(bytes(field.parts[idx]), encoding='utf8') for idx in field.data]\n+            else:\n+                return [pv for idx in field.data for pv in field.parts[idx].tolist()]\n+        if main_type == GGUFValueType.STRING:\n+            return str(bytes(field.parts[-1]), encoding='utf8')\n+        else:\n+            return field.parts[-1][0]\n+\n+    return None\n+\n+\n+def get_field_data(reader: GGUFReader, key: str) -> Any:\n+    field = reader.get_field(key)\n+\n+    return decode_field(field)\n+\n+\n+def copy_with_filename(reader: gguf.GGUFReader, writer: gguf.GGUFWriter, filename: str[Any]) -> None:\n+    logger.debug(f'copy_with_filename: {filename}') #debug\n+    val = filename\n+    for field in reader.fields.values():\n+        # Suppress virtual fields and fields written by GGUFWriter\n+        if field.name == Keys.General.ARCHITECTURE or field.name.startswith('GGUF.'):\n+            logger.debug(f'Suppressing {field.name}')\n+            continue\n+\n+        # Copy existed fields except 'embedded_files'\n+        if not field.name == Keys.EMBEDDED_FILES:\n+            cur_val = decode_field(field)\n+            writer.add_key(field.name)\n+            writer.add_val(cur_val, field.types[0])\n+            logger.debug(f'Copying {field.name}')\n+            continue\n+\n+        # Update embedded_files\n+        val = decode_field(field)\n+        for path in filename:\n+            logger.debug(f'Adding {field.name}: {path}')\n+            val.append(path)\n+\n+    # Add filenames to kv\n+    logger.info(f'* Modifying {Keys.EMBEDDED_FILES} to {val}')\n+    writer.add_array(Keys.EMBEDDED_FILES, val)\n+    \n+    for tensor in reader.tensors:\n+        # Dimensions are written in reverse order, so flip them first\n+        shape = np.flipud(tensor.shape)\n+        writer.add_tensor_info(tensor.name, shape, tensor.data.dtype, tensor.data.nbytes, tensor.tensor_type)\n+\n+    # Add file info as tensor_info\n+    for path in filename:\n+        logger.debug(f'Adding tensor_info {path}')\n+        with open(path, \"rb\") as f:\n+            data = f.read()\n+            data_len = len(data)\n+            dims = [data_len]\n+            raw_dtype = GGMLQuantizationType.I8\n+            writer.add_tensor_info(path, dims, np.float16, data_len, raw_dtype)\n+\n+    writer.write_header_to_file()\n+    writer.write_kv_data_to_file()\n+    writer.write_ti_data_to_file()\n+\n+    for tensor in reader.tensors:\n+        writer.write_tensor_data(tensor.data)\n+\n+    # Write file body as tensor data\n+    for path in filename:\n+        logger.debug(f'Adding tensor data {path}')\n+        with open(path, \"rb\") as f:\n+            data = f.read()\n+            data_len = len(data)\n+            # write data with padding\n+            writer.write_data(data)\n+\n+    writer.close()\n+\n+\n+def main() -> None:\n+    parser = argparse.ArgumentParser(description=\"Add files to GGUF file metadata\")\n+    parser.add_argument(\"input\",        type=str,            help=\"GGUF format model input filename\")\n+    parser.add_argument(\"output\",       type=str,            help=\"GGUF format model output filename\")\n+    parser.add_argument(\"addfiles\",     type=str, nargs='+', help=\"add filenames ...\")\n+    parser.add_argument(\"--force\",      action=\"store_true\", help=\"Bypass warnings without confirmation\")\n+    parser.add_argument(\"--verbose\",    action=\"store_true\", help=\"Increase output verbosity\")\n+    args = parser.parse_args(None if len(sys.argv) > 1 else [\"--help\"])\n+    logging.basicConfig(level=logging.DEBUG if args.verbose else logging.INFO)\n+\n+    logger.info(f'* Loading: {args.input}')\n+    reader = GGUFReader(args.input, 'r')\n+    arch = get_field_data(reader, Keys.General.ARCHITECTURE)\n+    endianess = get_byteorder(reader)\n+\n+    if os.path.isfile(args.output) and not args.force:\n+        logger.warning('*** Warning *** Warning *** Warning **')\n+        logger.warning(f'* The \"{args.output}\" GGUF file already exists, it will be overwritten!')\n+        logger.warning('* Enter exactly YES if you are positive you want to proceed:')\n+        response = input('YES, I am sure> ')\n+        if response != 'YES':\n+            logger.info(\"You didn't enter YES. Okay then, see ya!\")\n+            sys.exit(0)\n+\n+    logger.info(f'* Writing: {args.output}')\n+    writer = GGUFWriter(args.output, arch=arch, endianess=endianess)\n+\n+    alignment = get_field_data(reader, Keys.General.ALIGNMENT)\n+    if alignment is not None:\n+        logger.debug(f'Setting custom alignment: {alignment}')\n+        writer.data_alignment = alignment\n+\n+    if args.addfiles is not None:\n+        filename = []\n+        for path in args.addfiles:\n+            filename.append(path)\n+            logger.info(f'* Adding: {path}')\n+        copy_with_filename(reader, writer, filename)\n+ \n+\n+if __name__ == '__main__':\n+    main()\ndiff --git a/examples/yolo/yolo-image.cpp b/examples/yolo/yolo-image.cpp\nindex ceddc4182..4a0172323 100644\n--- a/examples/yolo/yolo-image.cpp\n+++ b/examples/yolo/yolo-image.cpp\n@@ -88,6 +88,31 @@ bool load_image(const char *fname, yolo_image & img)\n     return true;\n }\n \n+bool load_image_from_memory(const char * buffer, int len, yolo_image & img)\n+{\n+    int w, h, c;\n+    uint8_t * data = stbi_load_from_memory((uint8_t *)buffer, len, &w, &h, &c, 3);\n+    if (!data) {\n+        return false;\n+    }\n+    c = 3;\n+    img.w = w;\n+    img.h = h;\n+    img.c = c;\n+    img.data.resize(w*h*c);\n+    for (int k = 0; k < c; ++k){\n+        for (int j = 0; j < h; ++j){\n+            for (int i = 0; i < w; ++i){\n+                int dst_index = i + w*j + w*h*k;\n+                int src_index = k + c*i + c*w*j;\n+                img.data[dst_index] = (float)data[src_index]/255.;\n+            }\n+        }\n+    }\n+    stbi_image_free(data);\n+    return true;\n+}\n+\n static yolo_image resize_image(const yolo_image & im, int w, int h)\n {\n     yolo_image resized(w, h, im.c);\ndiff --git a/examples/yolo/yolo-image.h b/examples/yolo/yolo-image.h\nindex 124e1cd29..e7169547c 100644\n--- a/examples/yolo/yolo-image.h\n+++ b/examples/yolo/yolo-image.h\n@@ -32,6 +32,7 @@ struct yolo_image {\n };\n \n bool load_image(const char *fname, yolo_image & img);\n+bool load_image_from_memory(const char * buffer, int len, yolo_image & img);\n void draw_box_width(yolo_image & a, int x1, int y1, int x2, int y2, int w, float r, float g, float b);\n yolo_image letterbox_image(const yolo_image & im, int w, int h);\n bool save_image(const yolo_image & im, const char *name, int quality);\ndiff --git a/examples/yolo/yolov3-tiny.cpp b/examples/yolo/yolov3-tiny.cpp\nindex b8c81347c..6bc7ce749 100644\n--- a/examples/yolo/yolov3-tiny.cpp\n+++ b/examples/yolo/yolov3-tiny.cpp\n@@ -30,6 +30,7 @@ struct yolo_model {\n     int height = 416;\n     std::vector<conv2d_layer> conv2d_layers;\n     struct ggml_context * ctx;\n+    struct gguf_context * ctx_gguf;\n };\n \n struct yolo_layer {\n@@ -71,6 +72,7 @@ static bool load_model(const std::string & fname, yolo_model & model) {\n         fprintf(stderr, \"%s: gguf_init_from_file() failed\\n\", __func__);\n         return false;\n     }\n+    model.ctx_gguf = ctx;\n     model.width  = 416;\n     model.height = 416;\n     model.conv2d_layers.resize(13);\n@@ -100,6 +102,47 @@ static bool load_model(const std::string & fname, yolo_model & model) {\n     return true;\n }\n \n+// istream from memory\n+#include <streambuf>\n+#include <istream>\n+\n+struct membuf : std::streambuf {\n+    membuf(const char * begin, const char * end) {\n+        char * b(const_cast<char *>(begin));\n+        char * e(const_cast<char *>(end));\n+        this->begin = b;\n+        this->end = e;\n+        this->setg(b, b, e);\n+    }\n+\n+    membuf(const char * base, size_t size) {\n+        char * b(const_cast<char *>(begin));\n+        this->begin = b;\n+        this->end = b + size;\n+        this->setg(b, b, end);\n+    }\n+    \n+    virtual pos_type seekoff(off_type off, std::ios_base::seekdir dir, std::ios_base::openmode which = std::ios_base::in) override {\n+        if(dir == std::ios_base::cur) {\n+            gbump(off);\n+        } else if (dir == std::ios_base::end) {\n+            setg(begin, end + off, end);\n+        } else if (dir == std::ios_base::beg) {\n+            setg(begin, begin + off, end);\n+        }\n+\n+        return gptr() - eback();\n+    }\n+    \n+    virtual pos_type seekpos(std::streampos pos, std::ios_base::openmode mode) override {\n+        return seekoff(pos - pos_type(off_type(0)), std::ios_base::beg, mode);\n+    }\n+    \n+    char * begin;\n+    char * end;\n+};\n+\n+\n static bool load_labels(const char * filename, std::vector<std::string> & labels)\n {\n     std::ifstream file_in(filename);\n@@ -114,6 +157,32 @@ static bool load_labels(const char * filename, std::vector<std::string> & labels\n     return true;\n }\n \n+static bool load_labels_gguf(struct ggml_context * ctx, const struct gguf_context * ctx_gguf, const char * filename, std::vector<std::string> & labels)\n+{\n+    struct ggml_tensor * tensor = ggml_get_tensor(ctx, filename);\n+    if (tensor == NULL) {\n+        return false;\n+    }\n+    int tensoridx = gguf_find_tensor(ctx_gguf, filename);\n+    if (tensoridx == -1) {\n+        return false;\n+    }\n+    const size_t len = ggml_nelements(tensor);\n+    const size_t offset = gguf_get_tensor_offset(ctx_gguf, tensoridx);\n+    const char * data = (char *)gguf_get_data(ctx_gguf);\n+    membuf buf(data + offset, data + offset + len);\n+    std::istream file_in(&buf);\n+    if (!file_in) {\n+        return false;\n+    }\n+    std::string line;\n+    while (std::getline(file_in, line)) {\n+        labels.push_back(line);\n+    }\n+    GGML_ASSERT(labels.size() == 80);\n+    return true;\n+}\n+\n static bool load_alphabet(std::vector<yolo_image> & alphabet)\n {\n     alphabet.resize(8 * 128);\n@@ -130,6 +199,35 @@ static bool load_alphabet(std::vector<yolo_image> & alphabet)\n     return true;\n }\n \n+static bool load_alphabet_gguf(struct ggml_context * ctx, const struct gguf_context * ctx_gguf, std::vector<yolo_image> & alphabet)\n+{\n+    alphabet.resize(8 * 128);\n+    for (int j = 0; j < 8; j++) {\n+        for (int i = 32; i < 127; i++) {\n+            char fname[256];\n+            sprintf(fname, \"data/labels/%d_%d.png\", i, j);\n+            struct ggml_tensor * tensor = ggml_get_tensor(ctx, fname);\n+            if (tensor == NULL) {\n+                fprintf(stderr, \"Cannot find '%s' in tensor\\n\", fname);\n+                return false;\n+            }\n+            int tensoridx = gguf_find_tensor(ctx_gguf, fname);\n+            if (tensoridx == -1) {\n+                fprintf(stderr, \"Cannot find '%s' in tensor\\n\", fname);\n+                return false;\n+            }\n+            const size_t len = ggml_nelements(tensor);\n+            const size_t offset = gguf_get_tensor_offset(ctx_gguf, tensoridx);\n+            const char * data = (char *)gguf_get_data(ctx_gguf);\n+            if (!load_image_from_memory(data + offset, len, alphabet[j*128 + i])) {\n+                fprintf(stderr, \"Cannot load '%s'\\n\", fname);\n+                return false;\n+            }\n+        }\n+    }\n+    return true;\n+}\n+\n static ggml_tensor * apply_conv2d(ggml_context * ctx, ggml_tensor * input, const conv2d_layer & layer)\n {\n     struct ggml_tensor * result = ggml_conv_2d(ctx, layer.weights, input, 1, 1, layer.padding, layer.padding, 1, 1);\n@@ -503,14 +601,20 @@ int main(int argc, char *argv[])\n         return 1;\n     }\n     std::vector<std::string> labels;\n-    if (!load_labels(\"data/coco.names\", labels)) {\n-        fprintf(stderr, \"%s: failed to load labels from 'data/coco.names'\\n\", __func__);\n-        return 1;\n+    if (!load_labels_gguf(model.ctx, model.ctx_gguf, \"data/coco.names\", labels)) {\n+        fprintf(stderr, \"%s: skipped loading labels from 'data/coco.names' in model\\n\", __func__);\n+        if (!load_labels(\"data/coco.names\", labels)) {\n+            fprintf(stderr, \"%s: failed to load labels from 'data/coco.names'\\n\", __func__);\n+            return 1;\n+        }\n     }\n     std::vector<yolo_image> alphabet;\n-    if (!load_alphabet(alphabet)) {\n-        fprintf(stderr, \"%s: failed to load alphabet\\n\", __func__);\n-        return 1;\n+    if (!load_alphabet_gguf(model.ctx, model.ctx_gguf, alphabet)) {\n+        fprintf(stderr, \"%s: skipped loading alphabet from model\\n\", __func__);\n+        if (!load_alphabet(alphabet)) {\n+            fprintf(stderr, \"%s: failed to load alphabet\\n\", __func__);\n+            return 1;\n+        }\n     }\n     const int64_t t_start_ms = ggml_time_ms();\n     detect(img, model, params.thresh, labels, alphabet);\ndiff --git a/src/ggml.c b/src/ggml.c\nindex d5d33c2ba..910b75b94 100644\n--- a/src/ggml.c\n+++ b/src/ggml.c\n@@ -21920,14 +21920,17 @@ int gguf_find_tensor(const struct gguf_context * ctx, const char * name) {\n }\n \n size_t gguf_get_tensor_offset(const struct gguf_context * ctx, int i) {\n+    GGML_ASSERT(i >= 0 && i < gguf_get_n_tensors(ctx));\n     return ctx->infos[i].offset;\n }\n \n char * gguf_get_tensor_name(const struct gguf_context * ctx, int i) {\n+    GGML_ASSERT(i >= 0 && i < gguf_get_n_tensors(ctx));\n     return ctx->infos[i].name.data;\n }\n \n enum ggml_type gguf_get_tensor_type(const struct gguf_context * ctx, int i) {\n+    GGML_ASSERT(i >= 0 && i < gguf_get_n_tensors(ctx));\n     return ctx->infos[i].type;\n }\n \n@@ -22242,7 +22245,7 @@ static void gguf_write_to_buf(const struct gguf_context * ctx, struct gguf_buf *\n         gguf_bwrite_el (buf, &kv->type, sizeof(kv->type));\n \n         switch (kv->type) {\n-            case GGUF_TYPE_UINT8:   gguf_bwrite_el( buf, &kv->value.uint8,   sizeof(kv->value.uint8)  ); break;\n+            case GGUF_TYPE_UINT8:   gguf_bwrite_el (buf, &kv->value.uint8,   sizeof(kv->value.uint8)  ); break;\n             case GGUF_TYPE_INT8:    gguf_bwrite_el (buf, &kv->value.int8,    sizeof(kv->value.int8)   ); break;\n             case GGUF_TYPE_UINT16:  gguf_bwrite_el (buf, &kv->value.uint16,  sizeof(kv->value.uint16) ); break;\n             case GGUF_TYPE_INT16:   gguf_bwrite_el (buf, &kv->value.int16,   sizeof(kv->value.int16)  ); break;\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Embed files in new data structure requires three components: path name string, length of data, and data stream. Ensure compatibility with existing key names to avoid conflicts.\n\n2. Introduced a workaround for NULL bytes in file body; revise handling to prevent assumptions of no NULL bytes.\n\n3. Removed NAMEDOBJECT usage; store file paths with leading '/' to prevent conflicts.\n\n4. Reorganized `gguf-addfile.py`:\n   - Fixed key-value copying logic.\n   - Refactored code, removing unused sections.\n   - Added checks for overwriting output files with `--force` option.\n\n5. Added `gguf_get_tensor_size` and `gguf_find_key_array` functions in `ggml.c`. \n\n6. Updated `ci/run.sh` to include tests for GGUF file creation and reading, and note to refine CI later."
      }
    ],
    "codediff_length": 16588
  },
  {
    "index": 107,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/examples/CMakeLists.txt b/examples/CMakeLists.txt\nindex e3404fb8b..b569ecd64 100644\n--- a/examples/CMakeLists.txt\n+++ b/examples/CMakeLists.txt\n@@ -28,3 +28,4 @@ add_subdirectory(replit)\n add_subdirectory(mpt)\n add_subdirectory(starcoder)\n add_subdirectory(sam)\n+add_subdirectory(plugin)\ndiff --git a/examples/plugin/CMakeLists.txt b/examples/plugin/CMakeLists.txt\nnew file mode 100644\nindex 000000000..aac1c62ad\n--- /dev/null\n+++ b/examples/plugin/CMakeLists.txt\n@@ -0,0 +1,10 @@\n+add_library(plugin-model STATIC model.cpp)\n+target_link_libraries(plugin-model PUBLIC ggml::ggml)\n+\n+add_executable(cpu-plugin cpu-plugin.cpp)\n+target_link_libraries(cpu-plugin plugin-model)\n+\n+if (GGML_CUBLAS)\n+    add_executable(cuda-plugin cuda-plugin.cpp)\n+    target_link_libraries(cuda-plugin plugin-model)\n+endif()\ndiff --git a/examples/plugin/README.md b/examples/plugin/README.md\nnew file mode 100644\nindex 000000000..b75db63d4\n--- /dev/null\n+++ b/examples/plugin/README.md\n@@ -0,0 +1,5 @@\n+# GGML Plugin\n+\n+This example showcases the use of GGML as a plugin.\n+\n+The executables demonstrate how to initialize a backend and run inference with a model whose data comes from the outside.\ndiff --git a/examples/plugin/cpu-plugin.cpp b/examples/plugin/cpu-plugin.cpp\nnew file mode 100644\nindex 000000000..548aadecf\n--- /dev/null\n+++ b/examples/plugin/cpu-plugin.cpp\n@@ -0,0 +1,41 @@\n+#include \"model.hpp\"\n+\n+#include <ggml-backend.h>\n+\n+#include <vector>\n+#include <iostream>\n+\n+int main() {\n+    auto backend = ggml_backend_cpu_init();\n+\n+    std::vector<float> weights_data;\n+    for (int i = 0; i < 10; ++i) {\n+        weights_data.push_back(float(i));\n+    }\n+\n+    void* weights = weights_data.data();\n+\n+    model m(backend, weights_data.size(), GGML_TYPE_F32, weights);\n+\n+    std::vector<float> input_data;\n+    for (size_t i = 0; i < weights_data.size(); ++i) {\n+        input_data.push_back(float(i) / 10);\n+    }\n+\n+    std::vector<float> output_data(input_data.size());\n+\n+    void* input = input_data.data();\n+    void* output = output_data.data();\n+\n+    m.compute(output, input);\n+\n+    ggml_backend_free(backend);\n+\n+    std::cout << \"[\";\n+    for (auto o : output_data) {\n+        std::cout << o << \", \";\n+    }\n+    std::cout << \"]\\n\";\n+\n+    return 0;\n+}\ndiff --git a/examples/plugin/cuda-plugin.cpp b/examples/plugin/cuda-plugin.cpp\nnew file mode 100644\nindex 000000000..8f278a57c\n--- /dev/null\n+++ b/examples/plugin/cuda-plugin.cpp\n@@ -0,0 +1,67 @@\n+#include \"model.hpp\"\n+\n+#include <vector>\n+#include <iostream>\n+\n+#include <ggml-cuda.h>\n+#include <cuda_runtime.h>\n+#include <cublas_v2.h>\n+\n+int main() {\n+    // init cuda\n+    int device_id = 0;\n+    cudaSetDevice(device_id);\n+    cublasHandle_t cublas_handle = nullptr;\n+    cublasCreate(&cublas_handle);\n+    cudaStream_t cuda_stream = nullptr;\n+    cudaStreamCreateWithFlags(&cuda_stream, cudaStreamNonBlocking);\n+\n+    // create plugin backend\n+    auto backend = ggml_backend_cuda_init_plugin(device_id, cublas_handle, cuda_stream);\n+\n+    // init weights\n+    std::vector<float> weights_data;\n+    for (int i = 0; i < 10; ++i) {\n+        weights_data.push_back(float(i));\n+    }\n+\n+    void* weights = nullptr;\n+    cudaMallocAsync(&weights, data_size(weights_data), cuda_stream);\n+    cudaMemcpyAsync(weights, weights_data.data(), data_size(weights_data), cudaMemcpyHostToDevice, cuda_stream);\n+\n+    // create model with weights\n+    model m(backend, weights_data.size(), GGML_TYPE_F32, weights);\n+\n+    // init input and output data\n+    std::vector<float> input_data;\n+    for (size_t i = 0; i < weights_data.size(); ++i) {\n+        input_data.push_back(float(i) / 10);\n+    }\n+\n+    std::vector<float> output_data(input_data.size());\n+\n+    void* input = nullptr;\n+    cudaMallocAsync(&input, data_size(input_data), cuda_stream);\n+    cudaMemcpyAsync(input, input_data.data(), data_size(input_data), cudaMemcpyHostToDevice, cuda_stream);\n+\n+    void* output = nullptr;\n+    cudaMallocAsync(&output, data_size(output_data), cuda_stream);\n+\n+    // compute with cuda pointers\n+    m.compute(output, input);\n+\n+    // get data back from cuda pointers\n+    cudaMemcpyAsync(output_data.data(), output, data_size(output_data), cudaMemcpyDeviceToHost, cuda_stream);\n+    cudaStreamSynchronize(cuda_stream);\n+\n+    ggml_backend_free(backend);\n+\n+    // print result\n+    std::cout << \"[\";\n+    for (auto o : output_data) {\n+        std::cout << o << \", \";\n+    }\n+    std::cout << \"]\\n\";\n+\n+    return 0;\n+}\ndiff --git a/examples/plugin/model.cpp b/examples/plugin/model.cpp\nnew file mode 100644\nindex 000000000..8dde16c40\n--- /dev/null\n+++ b/examples/plugin/model.cpp\n@@ -0,0 +1,67 @@\n+#include \"model.hpp\"\n+\n+#include <ggml-alloc.h>\n+#include <ggml-backend.h>\n+\n+#include <cassert>\n+\n+model::model(ggml_backend_t be, int64_t s, ggml_type t, void* weights_data)\n+    : backend(be)\n+    , size(s)\n+    , type(t)\n+{\n+    assert(weights_data);\n+    static constexpr size_t numWeightTensors = sizeof(weights_t) / sizeof(ggml_tensor*);\n+    wctx = ggml_init({\n+        /*.mem_size   =*/ ggml_tensor_overhead() * numWeightTensors,\n+        /*.mem_buffer =*/ nullptr,\n+        /*.no_alloc   =*/ true,\n+        });\n+    weights.w = ggml_new_tensor_1d(wctx, type, size);\n+    wbuf = ggml_backend_alloc_buffer(backend, 0);\n+    auto wallocr = ggml_allocr_new_from_buffer(wbuf);\n+    ggml_allocr_set_tensor_external_data(wallocr, weights.w, weights_data, 0);\n+    ggml_allocr_free(wallocr);\n+\n+    cbuf = ggml_backend_alloc_buffer(backend, 0);\n+    callocr = ggml_allocr_new_from_buffer(cbuf);\n+}\n+\n+model::~model() {\n+    ggml_free(wctx);\n+    ggml_backend_buffer_free(wbuf);\n+    ggml_allocr_free(callocr);\n+    ggml_backend_buffer_free(cbuf);\n+}\n+\n+struct io_tensors {\n+    ggml_tensor* input = nullptr;\n+    ggml_tensor* output = nullptr;\n+};\n+\n+void model::compute(void* output, void* input) {\n+    assert(input);\n+    assert(output);\n+\n+    static constexpr size_t num_io_tensors = sizeof(io_tensors) / sizeof(ggml_tensor*);\n+    auto cctx = ggml_init({\n+        /*.mem_size   =*/ ggml_tensor_overhead() * num_io_tensors + ggml_graph_overhead(),\n+        /*.mem_buffer =*/ nullptr,\n+        /*.no_alloc   =*/ true,\n+        });\n+\n+    io_tensors io = {};\n+    io.input = ggml_new_tensor_1d(cctx, type, size);\n+    io.output = ggml_add(cctx, io.input, weights.w);\n+\n+    ggml_allocr_set_tensor_external_data(callocr, io.input, input, 0);\n+    ggml_allocr_set_tensor_external_data(callocr, io.output, output, 0);\n+\n+    auto graph = ggml_new_graph(cctx);\n+    ggml_build_forward_expand(graph, io.output);\n+\n+    ggml_backend_graph_compute(backend, graph);\n+\n+    ggml_allocr_reset(callocr);\n+    ggml_free(cctx);\n+}\ndiff --git a/examples/plugin/model.hpp b/examples/plugin/model.hpp\nnew file mode 100644\nindex 000000000..fee63d9c0\n--- /dev/null\n+++ b/examples/plugin/model.hpp\n@@ -0,0 +1,35 @@\n+#pragma once\n+#include <ggml.h>\n+#include <cstdint>\n+\n+typedef struct ggml_backend* ggml_backend_t;\n+struct ggml_backend_buffer;\n+struct ggml_allocr;\n+\n+struct model {\n+    struct weights_t {\n+        ggml_tensor* w = nullptr;\n+    } weights;\n+\n+    ggml_backend_t backend = nullptr;\n+\n+    ggml_context* wctx = nullptr;\n+    ggml_backend_buffer* wbuf = nullptr; // weights buffer\n+\n+    ggml_backend_buffer* cbuf = nullptr; // compute buffer\n+    ggml_allocr* callocr = nullptr; // compute allocator\n+\n+    const int64_t size;\n+    const ggml_type type;\n+\n+    model(ggml_backend_t be, int64_t s, ggml_type t, void* weights_data);\n+    ~model();\n+\n+    void compute(void* output, void* input);\n+};\n+\n+// util\n+template <typename Vec>\n+size_t data_size(const Vec& vec) {\n+    return vec.size() * sizeof(typename Vec::value_type);\n+}\ndiff --git a/include/ggml/ggml-alloc.h b/include/ggml/ggml-alloc.h\nindex e38758878..9f9c9a8b9 100644\n--- a/include/ggml/ggml-alloc.h\n+++ b/include/ggml/ggml-alloc.h\n@@ -23,6 +23,13 @@ GGML_API void   ggml_allocr_alloc      (struct ggml_allocr * alloc, struct ggml_\n GGML_API size_t ggml_allocr_alloc_graph(struct ggml_allocr * alloc, struct ggml_cgraph * graph);\n GGML_API size_t ggml_allocr_max_size   (struct ggml_allocr * alloc);\n \n+// set tensor data from external pointer (shallow copy)\n+// WARNING! It is the responsibility of the user to ensure that the provided pointer:\n+// * is compatible with the buffer backend (same address space)\n+// * points to memory of the right size and type/quantization as described by the tensor\n+// * remains valid while the associated tensor is used\n+GGML_API void   ggml_allocr_set_tensor_external_data(struct ggml_allocr * alloc, struct ggml_tensor * tensor, void * data, size_t data_offset);\n+\n GGML_API size_t ggml_allocr_alloc_graph_n(\n                     struct ggml_allocr * alloc,\n                     struct ggml_cgraph ** graphs, int n_graphs,\ndiff --git a/src/CMakeLists.txt b/src/CMakeLists.txt\nindex b225597ed..3abbfec82 100644\n--- a/src/CMakeLists.txt\n+++ b/src/CMakeLists.txt\n@@ -249,7 +249,12 @@ if (GGML_PERF)\n     set(GGML_EXTRA_FLAGS ${GGML_EXTRA_FLAGS} -DGGML_PERF)\n endif()\n \n-add_library(${TARGET}\n+if (GGML_PLUGIN)\n+    set(GGML_LIB_TYPE STATIC)\n+    set(CMAKE_POSITION_INDEPENDENT_CODE ON)\n+endif()\n+\n+add_library(${TARGET} ${GGML_LIB_TYPE}\n     ggml.c\n     ggml-alloc.c\n     ggml-backend.c\n@@ -261,6 +266,8 @@ add_library(${TARGET}\n     ${GGML_METAL_SOURCES}\n     )\n \n+add_library(ggml::ggml ALIAS ggml)\n+\n target_include_directories(${TARGET} PUBLIC\n     .\n     ../include\n@@ -274,7 +281,7 @@ else()\n     target_link_libraries(${TARGET} PUBLIC m ${GGML_EXTRA_LIBS} ${CMAKE_THREAD_LIBS_INIT})\n endif()\n \n-if (BUILD_SHARED_LIBS)\n+if (BUILD_SHARED_LIBS AND NOT GGML_PLUGIN)\n     set(CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS ON)\n \n     target_link_libraries(${TARGET} PUBLIC\ndiff --git a/src/ggml-alloc.c b/src/ggml-alloc.c\nindex 34eba3f83..5da722d1a 100644\n--- a/src/ggml-alloc.c\n+++ b/src/ggml-alloc.c\n@@ -183,6 +183,15 @@ void ggml_allocr_alloc(struct ggml_allocr * alloc, struct ggml_tensor * tensor)\n     alloc->max_size = MAX(alloc->max_size, (char*)addr - (char*)alloc->data + size);\n }\n \n+void ggml_allocr_set_tensor_external_data(struct ggml_allocr * alloc, struct ggml_tensor * tensor, void * data, size_t data_offset) {\n+    GGML_ASSERT(!ggml_is_view(tensor)); // views generally get data pointer from one of their sources\n+    GGML_ASSERT(tensor->data == NULL); // avoid allocating tensor which already has memory allocated\n+    GGML_ASSERT(data_offset == 0); // not supported yet\n+    tensor->data = data;\n+    tensor->buffer = alloc->buffer;\n+    ggml_backend_buffer_init_tensor(alloc->buffer, tensor);\n+}\n+\n // this is a very naive implementation, but for our case the number of free blocks should be very small\n static void ggml_allocr_free_tensor(struct ggml_allocr * alloc, struct ggml_tensor * tensor) {\n     if (ggml_allocr_is_own(alloc, tensor) == false) {\ndiff --git a/src/ggml-backend.c b/src/ggml-backend.c\nindex ca8d83daf..45cf7cfa1 100644\n--- a/src/ggml-backend.c\n+++ b/src/ggml-backend.c\n@@ -231,8 +231,11 @@ static struct ggml_backend_buffer_i cpu_backend_buffer_i_from_ptr = {\n static const size_t TENSOR_ALIGNMENT = 64; // should be enough for AVX 512\n \n static ggml_backend_buffer_t ggml_backend_cpu_alloc_buffer(ggml_backend_t backend, size_t size) {\n-    size += TENSOR_ALIGNMENT;   // malloc may return an address that is not aligned\n-    void * data = malloc(size); // TODO: maybe use GGML_ALIGNED_MALLOC?\n+    void * data = NULL;\n+    if (size) {\n+        size += TENSOR_ALIGNMENT; // malloc may return an address that is not aligned\n+        data = malloc(size);      // TODO: maybe use GGML_ALIGNED_MALLOC?\n+    }\n \n     return ggml_backend_buffer_init(backend, cpu_backend_buffer_i, data, size);\n }\n@@ -364,7 +367,7 @@ ggml_backend_t ggml_backend_cpu_init(void) {\n \n     *cpu_backend = (struct ggml_backend) {\n         /* .interface = */ cpu_backend_i,\n-        /* .context   = */ ctx\n+        /* .context   = */ ctx,\n     };\n     return cpu_backend;\n }\ndiff --git a/src/ggml-cuda.cu b/src/ggml-cuda.cu\nindex 5bd83bb5c..507250f9f 100644\n--- a/src/ggml-cuda.cu\n+++ b/src/ggml-cuda.cu\n@@ -463,6 +463,9 @@ inline cudaError_t ggml_cuda_set_device(const int device) {\n     return cudaSetDevice(device);\n }\n \n+static bool g_cublas_initialized = false;\n+static bool g_cublas_initialized_as_plugin = false;\n+\n static int g_device_count = -1;\n static int g_main_device = 0;\n static int g_compute_capabilities[GGML_CUDA_MAX_DEVICES];\n@@ -5632,9 +5635,7 @@ static void ggml_cuda_pool_free(void * ptr, size_t size) {\n \n \n void ggml_init_cublas() {\n-    static bool initialized = false;\n-\n-    if (!initialized) {\n+    if (!g_cublas_initialized) {\n \n #ifdef __HIP_PLATFORM_AMD__\n         // Workaround for a rocBLAS bug when using multiple graphics cards:\n@@ -5655,9 +5656,9 @@ void ggml_init_cublas() {\n             g_tensor_split[id] = total_vram;\n             total_vram += prop.totalGlobalMem;\n #if defined(GGML_USE_HIPBLAS) && defined(__HIP_PLATFORM_AMD__)\n-            g_compute_capabilities[id] = 100*prop.major + 10*prop.minor + CC_OFFSET_AMD;\n+            g_compute_capabilities[id] = 100 * prop.major + 10 * prop.minor + CC_OFFSET_AMD;\n #else\n-            g_compute_capabilities[id] = 100*prop.major + 10*prop.minor;\n+            g_compute_capabilities[id] = 100 * prop.major + 10 * prop.minor;\n #endif // defined(GGML_USE_HIPBLAS) && defined(__HIP_PLATFORM_AMD__)\n         }\n         for (int id = 0; id < g_device_count; ++id) {\n@@ -5680,7 +5681,7 @@ void ggml_init_cublas() {\n         // configure logging to stdout\n         // CUBLAS_CHECK(cublasLoggerConfigure(1, 1, 0, nullptr));\n \n-        initialized = true;\n+        g_cublas_initialized = true;\n     }\n }\n \n@@ -7536,6 +7537,26 @@ static const char * ggml_backend_cuda_name(ggml_backend_t backend) {\n }\n \n static void ggml_backend_cuda_free(ggml_backend_t backend) {\n+    for (int id = 0; id < GGML_CUDA_MAX_DEVICES; ++id) {\n+        for (int is = 0; is < MAX_STREAMS; ++is) {\n+            auto & stream = g_cudaStreams[id][is];\n+            if (!stream) break;\n+            if (!g_cublas_initialized_as_plugin) {\n+                cudaStreamDestroy(stream);\n+            }\n+            stream = nullptr;\n+        }\n+\n+        auto & cublasHandle = g_cublas_handles[id];\n+        if (!cublasHandle) continue;\n+        if (!g_cublas_initialized_as_plugin) {\n+            cublasDestroy(cublasHandle);\n+        }\n+        cublasHandle = nullptr;\n+    }\n+    g_cublas_initialized = false;\n+    g_cublas_initialized_as_plugin = false;\n+\n     ggml_backend_context_cuda * cuda_ctx = (ggml_backend_context_cuda *)backend->context;\n     delete cuda_ctx;\n     delete backend;\n@@ -7640,10 +7661,14 @@ static struct ggml_backend_buffer_i cuda_backend_buffer_interface = {\n };\n \n static ggml_backend_buffer_t ggml_backend_cuda_alloc_buffer(ggml_backend_t backend, size_t size) {\n-    ggml_cuda_set_device(g_main_device);\n-\n     ggml_backend_buffer_context_cuda * ctx = new ggml_backend_buffer_context_cuda;\n-    CUDA_CHECK(cudaMalloc(&ctx->device, size));\n+    if (size) {\n+        ggml_cuda_set_device(g_main_device);\n+        CUDA_CHECK(cudaMalloc(&ctx->device, size));\n+    }\n+    else {\n+        ctx->device = NULL;\n+    }\n     return ggml_backend_buffer_init(backend, cuda_backend_buffer_interface, ctx, size);\n }\n \n@@ -7767,15 +7792,40 @@ static ggml_backend_i cuda_backend_i = {\n     /* .supports_op         = */ nullptr,\n };\n \n+static ggml_backend_t create_cuda_backend(ggml_backend_context_cuda* ctx) {\n+    ggml_backend_t cuda_backend = new ggml_backend{\n+        /* .interface = */ cuda_backend_i,\n+        /* .context   = */ ctx,\n+    };\n+\n+    return cuda_backend;\n+}\n+\n ggml_backend_t ggml_backend_cuda_init() {\n     ggml_init_cublas(); // TODO: remove from ggml.c\n \n     ggml_backend_context_cuda * ctx = new ggml_backend_context_cuda;\n+    return create_cuda_backend(ctx);\n+}\n \n-    ggml_backend_t cuda_backend = new ggml_backend {\n-        /* .interface = */ cuda_backend_i,\n-        /* .context   = */ ctx\n-    };\n+ggml_backend_t ggml_backend_cuda_init_plugin(int main_device, void * cublas_handle, void * cuda_stream) {\n+    GGML_ASSERT(g_cublas_initialized == false && \"currently only a single cuda backend is supported\");\n \n-    return cuda_backend;\n+    g_device_count = main_device + 1;\n+    int id = g_main_device = main_device;\n+\n+    cudaDeviceProp prop;\n+    CUDA_CHECK(cudaGetDeviceProperties(&prop, id));\n+    fprintf(stderr, \"  Device %d: %s, compute capability %d.%d\\n\", id, prop.name, prop.major, prop.minor);\n+\n+    // g_tensor_split[id] = 0;\n+    g_compute_capabilities[id] = 100 * prop.major + 10 * prop.minor;\n+    g_cublas_handles[id] = (cublasHandle_t)cublas_handle;\n+    g_cudaStreams[id][0] = (cudaStream_t)cuda_stream;\n+\n+    g_cublas_initialized = true;\n+    g_cublas_initialized_as_plugin = true;\n+\n+    ggml_backend_context_cuda* ctx = new ggml_backend_context_cuda;\n+    return create_cuda_backend(ctx);\n }\ndiff --git a/src/ggml-cuda.h b/src/ggml-cuda.h\nindex 57adc9cf3..e542461a6 100644\n--- a/src/ggml-cuda.h\n+++ b/src/ggml-cuda.h\n@@ -45,6 +45,7 @@ GGML_API void   ggml_cuda_get_device_description(int device, char * description,\n \n // backend API\n GGML_API ggml_backend_t ggml_backend_cuda_init(void); // TODO: take a list of devices to use\n+GGML_API ggml_backend_t ggml_backend_cuda_init_plugin(int main_device, void * cublas_handle, void * cuda_stream);\n \n #ifdef  __cplusplus\n }\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Setting the tensor buffer to `NULL` is problematic; backend association is required, except for CPU compatibility.\n2. Implement custom buffer functions (e.g., `ggml_backend_cpu_buffer_from_ptr`) and allocate tensors at specific offsets.\n3. Avoid a global dummy buffer; each backend may not support external pointers.\n4. The CUDA backend needs unique extras per tensor and cannot reuse a global ring buffer.\n5. Modify `init_tensor` to reuse `tensor->extra` if set; avoid duplicating code in `set_tensor_external_data`.\n6. Transition to an auxiliary allocator for setting external pointers; once assigned, they should remain fixed.\n7. It's premature to merge changes to `ggml-backend`; use the legacy `ggml-cuda` interface for now.\n8. Consider reinitializing tensor views during computation instead of building for optimization."
      }
    ],
    "codediff_length": 17363
  },
  {
    "index": 108,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/include/ggml.h b/include/ggml.h\nindex 8fcc16df9..51aa5b3a0 100644\n--- a/include/ggml.h\n+++ b/include/ggml.h\n@@ -481,6 +481,7 @@ extern \"C\" {\n         GGML_OP_CONV_TRANSPOSE_1D,\n         GGML_OP_IM2COL,\n         GGML_OP_IM2COL_BACK,\n+        GGML_OP_CONV_2D_DW,\n         GGML_OP_CONV_TRANSPOSE_2D,\n         GGML_OP_POOL_1D,\n         GGML_OP_POOL_2D,\n@@ -677,6 +678,9 @@ extern \"C\" {\n     GGML_API bool ggml_is_contiguous_1(const struct ggml_tensor * tensor); // contiguous for dims >= 1\n     GGML_API bool ggml_is_contiguous_2(const struct ggml_tensor * tensor); // contiguous for dims >= 2\n \n+    // true for tensor that is stored in memory as CxWxHxN and has been permuted to WxHxCxN\n+    GGML_API bool ggml_is_contiguous_channels(const struct ggml_tensor * tensor);\n+\n     GGML_API bool ggml_are_same_shape (const struct ggml_tensor * t0, const struct ggml_tensor * t1);\n     GGML_API bool ggml_are_same_stride(const struct ggml_tensor * t0, const struct ggml_tensor * t1);\n \n@@ -1660,7 +1664,7 @@ extern \"C\" {\n             struct ggml_tensor  * a,\n             struct ggml_tensor  * b);\n \n-    // depthwise\n+    // depthwise (via im2col and mul_mat)\n     GGML_API struct ggml_tensor * ggml_conv_2d_dw(\n             struct ggml_context * ctx,\n             struct ggml_tensor  * a,  // convolution kernel\n@@ -1672,6 +1676,22 @@ extern \"C\" {\n             int                  d0,  // dilation dimension 0\n             int                  d1); // dilation dimension 1\n \n+    // Depthwise 2D convolution\n+    // may be faster than ggml_conv_2d_dw, but not available in all backends\n+    // a:   KW    KH    1    C    convolution kernel\n+    // b:   W     H     C    N    input data\n+    // res: W_out H_out C    N\n+    GGML_API struct ggml_tensor * ggml_conv_2d_dw_direct(\n+            struct ggml_context * ctx,\n+            struct ggml_tensor  * a,\n+            struct ggml_tensor  * b,\n+            int                   stride0,\n+            int                   stride1,\n+            int                   pad0,\n+            int                   pad1,\n+            int                   dilation0,\n+            int                   dilation1);\n+\n     GGML_API struct ggml_tensor * ggml_conv_transpose_2d_p0(\n             struct ggml_context * ctx,\n             struct ggml_tensor  * a,\ndiff --git a/src/ggml-cpu/ggml-cpu.c b/src/ggml-cpu/ggml-cpu.c\nindex 504003287..dbad8f61a 100644\n--- a/src/ggml-cpu/ggml-cpu.c\n+++ b/src/ggml-cpu/ggml-cpu.c\n@@ -1932,6 +1932,10 @@ static void ggml_compute_forward(struct ggml_compute_params * params, struct ggm\n             {\n                 ggml_compute_forward_im2col_back_f32(params, tensor);\n             } break;\n+        case GGML_OP_CONV_2D_DW:\n+            {\n+                ggml_compute_forward_conv_2d_dw(params, tensor);\n+            } break;\n         case GGML_OP_CONV_TRANSPOSE_2D:\n             {\n                 ggml_compute_forward_conv_transpose_2d(params, tensor);\n@@ -2268,6 +2272,7 @@ static int ggml_get_n_tasks(struct ggml_tensor * node, int n_threads) {\n             } break;\n         case GGML_OP_IM2COL:\n         case GGML_OP_IM2COL_BACK:\n+        case GGML_OP_CONV_2D_DW:\n         case GGML_OP_CONV_TRANSPOSE_1D:\n         case GGML_OP_CONV_TRANSPOSE_2D:\n             {\ndiff --git a/src/ggml-cpu/ops.cpp b/src/ggml-cpu/ops.cpp\nindex 9e86de595..1308d0697 100644\n--- a/src/ggml-cpu/ops.cpp\n+++ b/src/ggml-cpu/ops.cpp\n@@ -6064,6 +6064,178 @@ void ggml_compute_forward_conv_transpose_2d(\n     }\n }\n \n+// ggml_compute_forward_conv_2d_dw\n+\n+struct ggml_conv_2d_dw_params {\n+    int64_t channels;\n+    int64_t batch;\n+    int64_t src_w;\n+    int64_t src_h;\n+    int64_t dst_w;\n+    int64_t dst_h;\n+    int64_t knl_w;\n+    int64_t knl_h;\n+    int stride_x;\n+    int stride_y;\n+    int pad_x;\n+    int pad_y;\n+    int dilation_x;\n+    int dilation_y;\n+};\n+\n+static void ggml_compute_forward_conv_2d_dw_cwhn(\n+        const ggml_compute_params * params,\n+        const ggml_tensor * src,\n+        const ggml_tensor * kernel,\n+        ggml_tensor * dst,\n+        const ggml_conv_2d_dw_params & p) {\n+\n+    const int64_t c = p.channels;\n+    const float * knl_data = (const float *)kernel->data;\n+\n+    const int64_t rows_total = p.dst_h * p.batch;\n+    const int64_t rows_per_thread = (rows_total + params->nth - 1) / params->nth;\n+    const int64_t row_start = params->ith * rows_per_thread;\n+    const int64_t row_end = MIN(row_start + rows_per_thread, rows_total);\n+\n+#ifdef GGML_SIMD\n+    const int64_t pkg_size = GGML_F32_EPR;\n+    const int64_t pkg_count = c / pkg_size;\n+    const int64_t c_pkg_end = pkg_count * pkg_size;\n+#else\n+    const int64_t c_pkg_end = 0;\n+#endif\n+\n+    for (int64_t row = row_start; row < row_end; ++row) {\n+        const int64_t dst_y = row % p.dst_h;\n+        const float * src_data = (const float *)src->data + (row / p.dst_h) * p.src_w * p.src_h * c;\n+        for (int64_t dst_x = 0; dst_x < p.dst_w; ++dst_x) {\n+            float * dst_data = (float *)dst->data + (row * p.dst_w + dst_x) * c;\n+            const int64_t src_y_base = dst_y * p.stride_y - p.pad_y;\n+            const int64_t src_x_base = dst_x * p.stride_x - p.pad_x;\n+\n+#ifdef GGML_SIMD\n+            // Vectorized loop\n+            for (int64_t c_i = 0; c_i < c_pkg_end; c_i += pkg_size) {\n+                GGML_F32_VEC sum = GGML_F32_VEC_ZERO;\n+                for (int64_t knl_y = 0; knl_y < p.knl_h; ++knl_y) {\n+                    const int64_t src_y = src_y_base + knl_y * p.dilation_y;\n+                    if (src_y < 0 || src_y >= p.src_h) {\n+                        continue;\n+                    }\n+                    for (int64_t knl_x = 0; knl_x < p.knl_w; ++knl_x) {\n+                        const int64_t src_x = src_x_base + knl_x * p.dilation_x;\n+                        if (src_x < 0 || src_x >= p.src_w) {\n+                            continue;\n+                        }\n+                        GGML_F32_VEC k = GGML_F32_VEC_LOAD(knl_data + (knl_y * p.knl_w + knl_x) * c + c_i);\n+                        GGML_F32_VEC s = GGML_F32_VEC_LOAD(src_data + (src_y * p.src_w + src_x) * c + c_i);\n+                        sum = GGML_F32_VEC_FMA(sum, k, s);\n+                    }\n+                }\n+                GGML_F32_VEC_STORE(dst_data + c_i, sum);\n+            }\n+#endif\n+            // Scalar loop\n+            for (int64_t c_i = c_pkg_end; c_i < c; ++c_i) {\n+                float sum = 0.0f;\n+                for (int64_t knl_y = 0; knl_y < p.knl_h; ++knl_y) {\n+                    const int64_t src_y = src_y_base + knl_y * p.dilation_y;\n+                    if (src_y < 0 || src_y >= p.src_h) {\n+                        continue;\n+                    }\n+                    for (int64_t knl_x = 0; knl_x < p.knl_w; ++knl_x) {\n+                        const int64_t src_x = src_x_base + knl_x * p.dilation_x;\n+                        if (src_x < 0 || src_x >= p.src_w) {\n+                            continue;\n+                        }\n+                        sum += knl_data[(knl_y * p.knl_w + knl_x) * c + c_i]\n+                             * src_data[(src_y * p.src_w + src_x) * c + c_i];\n+                    }\n+                }\n+                dst_data[c_i] = sum;\n+            }\n+        }\n+    }\n+}\n+\n+static void ggml_compute_forward_conv_2d_dw_whcn(\n+        const ggml_compute_params * params,\n+        const ggml_tensor * src,\n+        const ggml_tensor * kernel,\n+        ggml_tensor * dst,\n+        const ggml_conv_2d_dw_params & p) {\n+\n+    const int64_t n = p.channels * p.batch;\n+    const int64_t per_thread = (n + params->nth - 1) / params->nth;\n+    const int64_t start = params->ith * per_thread;\n+    const int64_t end = MIN(start + per_thread, n);\n+\n+    for (int64_t i = start; i < end; ++i) {\n+        const float * knl_data = (const float *)kernel->data + (i % p.channels) * p.knl_w * p.knl_h;\n+        const float * src_data = (const float *)src->data + i * p.src_w * p.src_h;\n+        float * dst_data = (float *)dst->data + i * p.dst_w * p.dst_h;\n+\n+        for (int64_t dst_y = 0; dst_y < p.dst_h; ++dst_y) {\n+            for (int64_t dst_x = 0; dst_x < p.dst_w; ++dst_x) {\n+\n+                float sum = 0.0f;\n+                for (int64_t knl_y = 0; knl_y < p.knl_h; ++knl_y) {\n+                    const int64_t src_y = dst_y * p.stride_y + knl_y * p.dilation_y - p.pad_y;\n+                    if (src_y < 0 || src_y >= p.src_h) {\n+                        continue;\n+                    }\n+                    for (int64_t knl_x = 0; knl_x < p.knl_w; ++knl_x) {\n+                        const int64_t src_x = dst_x * p.stride_x + knl_x * p.dilation_x - p.pad_x;\n+                        if (src_x < 0 || src_x >= p.src_w) {\n+                            continue;\n+                        }\n+                        sum += knl_data[knl_y * p.knl_w + knl_x]\n+                             * src_data[src_y * p.src_w + src_x];\n+                    }\n+                }\n+                dst_data[dst_y * p.dst_w + dst_x] = sum;\n+            }\n+        }\n+    }\n+}\n+\n+void ggml_compute_forward_conv_2d_dw(\n+        const ggml_compute_params * params,\n+        ggml_tensor * dst) {\n+\n+    const ggml_tensor * kernel = dst->src[0];\n+    const ggml_tensor * src = dst->src[1];\n+    ggml_conv_2d_dw_params p;\n+    p.channels = src->ne[2];\n+    p.batch = src->ne[3];\n+    p.src_w = src->ne[0];\n+    p.src_h = src->ne[1];\n+    p.dst_w = dst->ne[0];\n+    p.dst_h = dst->ne[1];\n+    p.knl_w = kernel->ne[0];\n+    p.knl_h = kernel->ne[1];\n+    p.stride_x = dst->op_params[0];\n+    p.stride_y = dst->op_params[1];\n+    p.pad_x = dst->op_params[2];\n+    p.pad_y = dst->op_params[3];\n+    p.dilation_x = dst->op_params[4];\n+    p.dilation_y = dst->op_params[5];\n+\n+    GGML_ASSERT(kernel->ne[3] == p.channels);\n+    GGML_ASSERT(dst->ne[3] == p.batch);\n+\n+    if (ggml_is_contiguous(src)) {\n+        ggml_compute_forward_conv_2d_dw_whcn(params, src, kernel, dst, p);\n+    } else if (ggml_is_contiguous_channels(src)) {\n+        // kernel should also have channels most contiguous in memory\n+        GGML_ASSERT(kernel->nb[0] >= kernel->nb[2] && kernel->nb[1] >= kernel->nb[0]);\n+        ggml_compute_forward_conv_2d_dw_cwhn(params, src, kernel, dst, p);\n+    } else {\n+        GGML_ABORT(\"non-contiguous memory layout not supported\");\n+    }\n+}\n+\n // ggml_compute_forward_pool_1d_sk_p0\n \n static void ggml_compute_forward_pool_1d_sk_p0(\ndiff --git a/src/ggml-cpu/ops.h b/src/ggml-cpu/ops.h\nindex 410a37204..dc081b9e6 100644\n--- a/src/ggml-cpu/ops.h\n+++ b/src/ggml-cpu/ops.h\n@@ -65,6 +65,7 @@ void ggml_compute_forward_conv_transpose_1d(const struct ggml_compute_params * p\n void ggml_compute_forward_im2col(const struct ggml_compute_params * params, struct ggml_tensor * dst);\n void ggml_compute_forward_im2col_back_f32(const struct ggml_compute_params * params, struct ggml_tensor * dst);\n void ggml_compute_forward_conv_transpose_2d(const struct ggml_compute_params * params, struct ggml_tensor * dst);\n+void ggml_compute_forward_conv_2d_dw(const struct ggml_compute_params * params, struct ggml_tensor * dst);\n void ggml_compute_forward_pool_1d(const struct ggml_compute_params * params, struct ggml_tensor * dst);\n void ggml_compute_forward_pool_2d(const struct ggml_compute_params * params, struct ggml_tensor * dst);\n void ggml_compute_forward_pool_2d_back(const struct ggml_compute_params * params, struct ggml_tensor * dst);\ndiff --git a/src/ggml.c b/src/ggml.c\nindex 950772c75..c8b2feff4 100644\n--- a/src/ggml.c\n+++ b/src/ggml.c\n@@ -956,6 +956,7 @@ static const char * GGML_OP_NAME[GGML_OP_COUNT] = {\n     \"CONV_TRANSPOSE_1D\",\n     \"IM2COL\",\n     \"IM2COL_BACK\",\n+    \"CONV_2D_DW\",\n     \"CONV_TRANSPOSE_2D\",\n     \"POOL_1D\",\n     \"POOL_2D\",\n@@ -993,7 +994,7 @@ static const char * GGML_OP_NAME[GGML_OP_COUNT] = {\n     \"OPT_STEP_ADAMW\",\n };\n \n-static_assert(GGML_OP_COUNT == 81, \"GGML_OP_COUNT != 81\");\n+static_assert(GGML_OP_COUNT == 82, \"GGML_OP_COUNT != 82\");\n \n static const char * GGML_OP_SYMBOL[GGML_OP_COUNT] = {\n     \"none\",\n@@ -1050,6 +1051,7 @@ static const char * GGML_OP_SYMBOL[GGML_OP_COUNT] = {\n     \"conv_transpose_1d(x)\",\n     \"im2col(x)\",\n     \"im2col_back(x)\",\n+    \"conv_2d_dw(x)\",\n     \"conv_transpose_2d(x)\",\n     \"pool_1d(x)\",\n     \"pool_2d(x)\",\n@@ -1087,7 +1089,7 @@ static const char * GGML_OP_SYMBOL[GGML_OP_COUNT] = {\n     \"adamw(x)\",\n };\n \n-static_assert(GGML_OP_COUNT == 81, \"GGML_OP_COUNT != 81\");\n+static_assert(GGML_OP_COUNT == 82, \"GGML_OP_COUNT != 82\");\n \n static_assert(GGML_OP_POOL_COUNT == 2, \"GGML_OP_POOL_COUNT != 2\");\n \n@@ -1344,6 +1346,13 @@ bool ggml_is_permuted(const struct ggml_tensor * tensor) {\n     return tensor->nb[0] > tensor->nb[1] || tensor->nb[1] > tensor->nb[2] || tensor->nb[2] > tensor->nb[3];\n }\n \n+bool ggml_is_contiguous_channels(const struct ggml_tensor * tensor) {\n+    return\n+        tensor->nb[0] > tensor->nb[2] &&\n+        tensor->nb[1] > tensor->nb[0] &&\n+        tensor->nb[2] == ggml_type_size(tensor->type);\n+}\n+\n static inline bool ggml_is_padded_1d(const struct ggml_tensor * tensor) {\n     static_assert(GGML_MAX_DIMS == 4, \"GGML_MAX_DIMS is not 4 - update this function\");\n \n@@ -4050,6 +4059,46 @@ struct ggml_tensor * ggml_conv_2d_dw(\n     return result;\n }\n \n+// ggml_conv_2d_dw_direct\n+\n+struct ggml_tensor * ggml_conv_2d_dw_direct(\n+        struct ggml_context * ctx,\n+        struct ggml_tensor  * a,\n+        struct ggml_tensor  * b,\n+        int                   stride0,\n+        int                   stride1,\n+        int                   pad0,\n+        int                   pad1,\n+        int                   dilation0,  \n+        int                   dilation1) {\n+    GGML_ASSERT(a->ne[2] == 1);\n+    GGML_ASSERT(a->ne[3] == b->ne[2]);\n+    int64_t ne[4];\n+    ne[0] = ggml_calc_conv_output_size(b->ne[0], a->ne[0], stride0, pad0, dilation0);\n+    ne[1] = ggml_calc_conv_output_size(b->ne[1], a->ne[1], stride1, pad1, dilation1);\n+    ne[2] = b->ne[2];\n+    ne[3] = b->ne[3];\n+\n+    struct ggml_tensor * result = ggml_new_tensor(ctx, b->type, 4, ne);\n+\n+    if (ggml_is_contiguous_channels(b)) {\n+        // Result will be permuted the same way as input (CWHN order)\n+        const int64_t type_size = ggml_type_size(result->type);\n+        GGML_ASSERT(ggml_blck_size(result->type) == 1);\n+        result->nb[0] = result->ne[2] * type_size;\n+        result->nb[1] = result->ne[0] * result->nb[0];\n+        result->nb[2] = type_size;\n+    }\n+\n+    int32_t params[] = { stride0, stride1, pad0, pad1, dilation0, dilation1 };\n+    ggml_set_op_params(result, params, sizeof(params));\n+\n+    result->op     = GGML_OP_CONV_2D_DW;\n+    result->src[0] = a;\n+    result->src[1] = b;\n+    return result;\n+}\n+\n // ggml_conv_transpose_2d_p0\n \n static int64_t ggml_calc_conv_transpose_output_size(int64_t ins, int64_t ks, int s, int p) {\ndiff --git a/tests/CMakeLists.txt b/tests/CMakeLists.txt\nindex 5db778cd8..27f398ac9 100644\n--- a/tests/CMakeLists.txt\n+++ b/tests/CMakeLists.txt\n@@ -384,6 +384,16 @@ add_test(NAME ${TEST_TARGET} COMMAND $<TARGET_FILE:${TEST_TARGET}>)\n set_property(TEST ${TEST_TARGET} PROPERTY ENVIRONMENT \"LLVM_PROFILE_FILE=${TEST_TARGET}.profraw\")\n \n \n+#\n+# test-conv2d-dw\n+\n+set(TEST_TARGET test-conv2d-dw)\n+add_executable(${TEST_TARGET} ${TEST_TARGET}.cpp)\n+target_link_libraries(${TEST_TARGET} PRIVATE ggml)\n+add_test(NAME ${TEST_TARGET} COMMAND $<TARGET_FILE:${TEST_TARGET}>)\n+set_property(TEST ${TEST_TARGET} PROPERTY ENVIRONMENT \"LLVM_PROFILE_FILE=${TEST_TARGET}.profraw\")\n+\n+\n #\n # test-mul-mat\n \ndiff --git a/tests/test-conv2d-dw.cpp b/tests/test-conv2d-dw.cpp\nnew file mode 100644\nindex 000000000..d4c029082\n--- /dev/null\n+++ b/tests/test-conv2d-dw.cpp\n@@ -0,0 +1,153 @@\n+#include <ggml.h>\n+#include <ggml-cpu.h>\n+#include <ggml-alloc.h>\n+#include <ggml-backend.h>\n+#include <ggml-cpp.h>\n+\n+#include <cassert>\n+#include <cmath>\n+#include <cstdio>\n+#include <cstring>\n+#include <vector>\n+\n+std::vector<float> f32_range(int n, float start, float end) {\n+    std::vector<float> values(n);\n+    float step = (end - start) / n;\n+    for (int i = 0; i < n; i++) {\n+        values[i] = start + i * step;\n+    }\n+    return values;\n+}\n+\n+// Most straightforward implementation without any optimizations\n+std::vector<float> conv_2d_dw_reference(\n+        int src_w, int src_h, const float * src_data,\n+        int knl_w, int knl_h, const float * knl_data,\n+        int channels, int batch, int stride, int pad, int dilation) {\n+\n+    int dst_w = (src_w + 2 * pad - dilation * (knl_w - 1) - 1) / stride + 1;\n+    int dst_h = (src_h + 2 * pad - dilation * (knl_h - 1) - 1) / stride + 1;\n+    std::vector<float> dst_data(dst_w * dst_h * channels * batch);\n+\n+    for (int b = 0; b < batch; b++) {\n+        const float * src_base = src_data + b * src_w * src_h * channels;\n+        float * dst_base = dst_data.data() + b * dst_w * dst_h * channels;\n+        for (int c = 0; c < channels; c++) {\n+            for (int y = 0; y < dst_h; y++) {\n+                for (int x = 0; x < dst_w; x++) {\n+                    float sum = 0;\n+                    for (int knl_y = 0; knl_y < knl_h; knl_y++) {\n+                        for (int knl_x = 0; knl_x < knl_w; knl_x++) {\n+                            int src_x = x * stride + knl_x * dilation - pad;\n+                            int src_y = y * stride + knl_y * dilation - pad;\n+                            if (src_x >= 0 && src_x < src_w && src_y >= 0 && src_y < src_h) {\n+                                sum += src_base[c * src_w * src_h + src_y * src_w + src_x] *\n+                                       knl_data[c * knl_w * knl_h + knl_y * knl_w + knl_x];\n+                            }\n+                        }\n+                    }\n+                    dst_base[c * dst_w * dst_h + y * dst_w + x] = sum;\n+                }\n+            }\n+        }\n+    }\n+    return dst_data;\n+}\n+\n+bool check_equal(const std::vector<float> & result, const std::vector<float> & expected) {\n+    if (result.size() != expected.size()) {\n+        printf(\"result.size() = %d, expected.size() = %d\\n\", (int)result.size(), (int)expected.size());\n+        return false;\n+    }\n+    for (int i = 0; i < result.size(); i++) {\n+        if(std::abs(result[i] - expected[i]) > 1e-5) {\n+            printf(\"result[%d] %f != %f expected[%d]\\n\", i, result[i], expected[i], i);\n+            return false;\n+        }\n+    }\n+    return true;\n+}\n+\n+bool test_conv_2d_dw(\n+        int channels,\n+        int kernel_size,\n+        int stride,\n+        int pad,\n+        int dilation,\n+        bool contiguous_channels) {\n+    ggml_time_init();\n+\n+    const int batch = 2;\n+    const int src_w = 8;\n+    const int src_h = 6;\n+    const int knl_w = kernel_size;\n+    const int knl_h = kernel_size;\n+\n+    ggml_init_params params {\n+        /*.mem_size   =*/ 64 * ggml_tensor_overhead() + ggml_graph_overhead(),\n+        /*.mem_buffer =*/ NULL,\n+        /*.no_alloc   =*/ true\n+    };\n+\n+    ggml_context_ptr ctx_ptr{ggml_init(params)};\n+    ggml_context * ctx = ctx_ptr.get();\n+    ggml_cgraph * gf = ggml_new_graph(ctx);\n+\n+    // Build graph\n+    ggml_tensor * src_input = ggml_new_tensor_4d(ctx, GGML_TYPE_F32, src_w, src_h, channels, batch);\n+    ggml_tensor * knl_input = ggml_new_tensor_4d(ctx, GGML_TYPE_F32, knl_w, knl_h, 1, channels);\n+    ggml_tensor * src = src_input;\n+    ggml_tensor * knl = knl_input;\n+    if (contiguous_channels) {\n+        // Convert tensor to [C, W, H, N] layout in memory, then permute strides back to [W, H, C, N]\n+        src = ggml_cont(ctx, ggml_permute(ctx, src, 1, 2, 0, 3));\n+        src = ggml_permute(ctx, src, 2, 0, 1, 3);\n+        knl = ggml_cont(ctx, ggml_permute(ctx, knl, 2, 3, 1, 0));\n+        knl = ggml_permute(ctx, knl, 3, 2, 0, 1);\n+    }\n+    ggml_tensor * res = ggml_conv_2d_dw_direct(\n+        ctx, knl, src, stride, stride, pad, pad, dilation, dilation);\n+    if (contiguous_channels) {\n+        res = ggml_cont(ctx, res);\n+    }\n+    ggml_build_forward_expand(gf, res);\n+\n+    // Create backend & allocate buffers\n+    ggml_backend_ptr backend_ptr{ggml_backend_cpu_init()};\n+    ggml_backend_t backend = backend_ptr.get();\n+    ggml_backend_cpu_set_n_threads(backend, 2);\n+    ggml_backend_buffer_ptr buffer{ggml_backend_alloc_ctx_tensors(ctx, backend)};\n+\n+    std::vector<float> src_values = f32_range(ggml_nelements(src), -1.f, 1.f);\n+    std::vector<float> knl_values = f32_range(ggml_nelements(knl), -1.f, 1.f);\n+    ggml_backend_tensor_set(src_input, src_values.data(), 0, ggml_nbytes(src));\n+    ggml_backend_tensor_set(knl_input, knl_values.data(), 0, ggml_nbytes(knl));\n+\n+    ggml_backend_graph_compute(backend, gf);\n+\n+    std::vector<float> res_values(ggml_nelements(res));\n+    ggml_backend_tensor_get(res, res_values.data(), 0, ggml_nbytes(res));\n+\n+    std::vector<float> expected = conv_2d_dw_reference(\n+        src_w, src_h, src_values.data(),\n+        knl_w, knl_h, knl_values.data(),\n+        channels, batch, stride, pad, dilation);\n+\n+    bool passed = check_equal(res_values, expected);\n+\n+    printf(\"ggml_conv_2d_dw(channels=%d, kernel=%dx%d, stride=%d, pad=%d, dilation=%d, layout=%s): %s\\n\",\n+        channels, kernel_size, kernel_size, stride, pad, dilation, contiguous_channels ? \"CWHN\" : \"WHCN\",\n+        passed ? \"\\033[32mPASSED\\033[0m\" : \"\\033[31mFAILED\\033[0m\");\n+    return passed;\n+}\n+\n+int main(int argc, char ** argv) {\n+    bool passed = true;\n+    passed = test_conv_2d_dw(3, 1, 1, 0, 1, false) && passed;\n+    passed = test_conv_2d_dw(3, 1, 1, 0, 1, true) && passed;\n+    passed = test_conv_2d_dw(42, 3, 2, 1, 1, false) && passed;\n+    passed = test_conv_2d_dw(42, 3, 2, 1, 1, true) && passed;\n+    passed = test_conv_2d_dw(8, 5, 1, 2, 2, false) && passed;\n+    passed = test_conv_2d_dw(8, 5, 1, 2, 2, true) && passed;\n+    return passed ? 0 : 1;\n+}\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Consider implementing dynamic dispatch for the depthwise convolution operator based on dilation requirements, similar to PyTorch\u2019s approach. This can utilize `ggml_compute_forward_...` for streamlined execution.\n  \n2. The `ggml_conv_2d` function has excessive parameters; focus on refining existing depthwise implementations instead of merging functionality.\n\n3. Backends need to implement `GGML_OP_DEPTHWISE_CONV_2D` to maintain compatibility, particularly as some backends, like Metal, require a temporary buffer for IM2COL.\n\n4. Address the complexity of conditionally creating backend-specific graphs for operations as it results in performance overhead. Using `MTLHeap` in the Metal backend to allocate temporary buffers can help.\n\n5. Implement merging of convolutions under a single operation type, ensuring upcoming depthwise operations support dilation during the transition."
      }
    ],
    "codediff_length": 21689
  },
  {
    "index": 109,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/examples/CMakeLists.txt b/examples/CMakeLists.txt\nindex fc776c713..f206567a1 100644\n--- a/examples/CMakeLists.txt\n+++ b/examples/CMakeLists.txt\n@@ -11,3 +11,4 @@ add_subdirectory(whisper)\n add_subdirectory(mnist)\n add_subdirectory(stablelm)\n add_subdirectory(dolly-v2)\n+add_subdirectory(starcoder)\ndiff --git a/examples/starcoder/CMakeLists.txt b/examples/starcoder/CMakeLists.txt\nnew file mode 100644\nindex 000000000..4c25b4d91\n--- /dev/null\n+++ b/examples/starcoder/CMakeLists.txt\n@@ -0,0 +1,13 @@\n+#\n+# starcoder\n+\n+set(TEST_TARGET starcoder)\n+add_executable(${TEST_TARGET} main.cpp)\n+target_link_libraries(${TEST_TARGET} PRIVATE ggml common common-ggml)\n+\n+#\n+# starcoder-quantize\n+\n+set(TEST_TARGET starcoder-quantize)\n+add_executable(${TEST_TARGET} quantize.cpp)\n+target_link_libraries(${TEST_TARGET} PRIVATE ggml common common-ggml)\ndiff --git a/examples/starcoder/README.md b/examples/starcoder/README.md\nnew file mode 100644\nindex 000000000..194757863\n--- /dev/null\n+++ b/examples/starcoder/README.md\n@@ -0,0 +1,112 @@\n+# \ud83d\udcab StarCoder\n+\n+This is a C++ example running \ud83d\udcab StarCoder inference using the [ggml](https://github.com/ggerganov/ggml) library.\n+\n+The program runs on the CPU - no video card is required.\n+\n+The example supports the following \ud83d\udcab StarCoder models:\n+\n+- `bigcode/starcoder`\n+- `bigcode/gpt_bigcode-santacoder` aka the smol StarCoder\n+\n+Sample performance on MacBook M1 Pro:\n+\n+TODO\n+\n+\n+Sample output:\n+\n+```\n+$ ./bin/starcoder -h\n+usage: ./bin/starcoder [options]\n+\n+options:\n+  -h, --help            show this help message and exit\n+  -s SEED, --seed SEED  RNG seed (default: -1)\n+  -t N, --threads N     number of threads to use during computation (default: 8)\n+  -p PROMPT, --prompt PROMPT\n+                        prompt to start generation with (default: random)\n+  -n N, --n_predict N   number of tokens to predict (default: 200)\n+  --top_k N             top-k sampling (default: 40)\n+  --top_p N             top-p sampling (default: 0.9)\n+  --temp N              temperature (default: 1.0)\n+  -b N, --batch_size N  batch size for prompt processing (default: 8)\n+  -m FNAME, --model FNAME\n+                        model path (default: models/starcoder-117M/ggml-model.bin)\n+\n+$ ./bin/starcoder -m ../models/bigcode/gpt_bigcode-santacoder-ggml-q4_1.bin -p \"def fibonnaci(\" -t 4 --top_k 0 --top_p 0.95 --temp 0.2      \n+main: seed = 1683881276\n+gpt2_model_load: loading model from '../models/bigcode/gpt_bigcode-santacoder-ggml-q4_1.bin'\n+gpt2_model_load: n_vocab = 49280\n+gpt2_model_load: n_ctx   = 2048\n+gpt2_model_load: n_embd  = 2048\n+gpt2_model_load: n_head  = 16\n+gpt2_model_load: n_layer = 24\n+gpt2_model_load: ftype   = 3\n+gpt2_model_load: ggml ctx size = 1794.90 MB\n+gpt2_model_load: memory size =   768.00 MB, n_mem = 49152\n+gpt2_model_load: model size  =  1026.83 MB\n+main: prompt: 'def fibonnaci('\n+main: number of tokens in prompt = 7, first 8 tokens: 563 24240 78 2658 64 2819 7 \n+\n+def fibonnaci(n):\n+    if n == 0:\n+        return 0\n+    elif n == 1:\n+        return 1\n+    else:\n+        return fibonacci(n-1) + fibonacci(n-2)\n+\n+print(fibo(10))\n+\n+main: mem per token =  9597928 bytes\n+main:     load time =   480.43 ms\n+main:   sample time =    26.21 ms\n+main:  predict time =  3987.95 ms / 19.36 ms per token\n+main:    total time =  4580.56 ms\n+```\n+\n+## Quick start\n+```bash\n+git clone https://github.com/ggerganov/ggml\n+cd ggml\n+\n+# Convert HF model to ggml\n+python examples/starcoder/convert-hf-to-ggml.py bigcode/gpt_bigcode-santacoder\n+\n+# Build ggml + examples\n+mkdir build && cd build\n+cmake .. && make -j4 starcoder starcoder-quantize\n+\n+# quantize the model\n+./bin/starcoder-quantize ../models/bigcode/gpt_bigcode-santacoder-ggml.bin ../models/bigcode/gpt_bigcode-santacoder-ggml-q4_1.bin 3\n+\n+# run inference\n+./bin/starcoder -m ../models/bigcode/gpt_bigcode-santacoder-ggml-q4_1.bin -p \"def fibonnaci(\" --top_k 0 --top_p 0.95 --temp 0.2\n+```\n+\n+\n+## Downloading and converting the original models (\ud83d\udcab StarCoder)\n+\n+You can download the original model and convert it to `ggml` format using the script `convert-hf-to-ggml.py`:\n+\n+```\n+# Convert HF model to ggml\n+python examples/starcoder/convert-hf-to-ggml.py bigcode/gpt_bigcode-santacoder\n+```\n+\n+This conversion requires that you have python and Transformers installed on your computer.\n+\n+## Quantizing the models\n+\n+You can also try to quantize the `ggml` models via 4-bit integer quantization.\n+\n+```\n+# quantize the model\n+./bin/starcoder-quantize ../models/bigcode/gpt_bigcode-santacoder-ggml.bin ../models/bigcode/gpt_bigcode-santacoder-ggml-q4_1.bin 3\n+```\n+\n+| Model | Original size | Quantized size | Quantization type |\n+| --- | --- | --- | --- |\n+| `bigcode/gpt_bigcode-santacoder` | 5396.45 MB | 1026.83 MB | 4-bit integer (q4_1) |\n+| `bigcode/starcoder` | 71628.23 MB | 13596.23 MB | 4-bit integer (q4_1) |\n\\ No newline at end of file\ndiff --git a/examples/starcoder/convert-hf-to-ggml.py b/examples/starcoder/convert-hf-to-ggml.py\nnew file mode 100644\nindex 000000000..c3ddfe7e1\n--- /dev/null\n+++ b/examples/starcoder/convert-hf-to-ggml.py\n@@ -0,0 +1,212 @@\n+# Convert HF models to ggml format\n+#\n+\n+import sys\n+import struct\n+import json\n+import torch\n+import numpy as np\n+import re\n+import os\n+\n+from transformers import AutoModelForCausalLM\n+from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, BloomForCausalLM\n+\n+# ref: https://github.com/openai/gpt-2/blob/master/src/encoder.py\n+def bytes_to_unicode():\n+    \"\"\"\n+    Returns list of utf-8 byte and a corresponding list of unicode strings.\n+    The reversible bpe codes work on unicode strings.\n+    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n+    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n+    This is a signficant percentage of your normal, say, 32K bpe vocab.\n+    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n+    And avoids mapping to whitespace/control characters the bpe code barfs on.\n+    \"\"\"\n+    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"\u00a1\"), ord(\"\u00ac\")+1))+list(range(ord(\"\u00ae\"), ord(\"\u00ff\")+1))\n+    cs = bs[:]\n+    n = 0\n+    for b in range(2**8):\n+        if b not in bs:\n+            bs.append(b)\n+            cs.append(2**8+n)\n+            n += 1\n+    cs = [chr(n) for n in cs]\n+    return dict(zip(bs, cs))\n+\n+if len(sys.argv) < 2:\n+    print(\"Usage: python convert-hf-to-ggml.py hf-model-name [use-f32]\")\n+    print(\"Example: python convert-hf-to-ggml.py bigcode/gpt_bigcode-santacoder\")\n+    print(\"Example: python convert-hf-to-ggml.py bigcode/starcoder\")\n+    sys.exit(1)\n+\n+model_name = sys.argv[1].strip()\n+fname_out = \"models/\" + sys.argv[1].strip() + \"-ggml.bin\"\n+os.makedirs(os.path.dirname(fname_out), exist_ok=True)\n+\n+\n+\n+# use 16-bit or 32-bit floats\n+use_f16 = True\n+if len(sys.argv) > 2:\n+    use_f16 = False\n+\n+print(\"Loading model: \", model_name)\n+tokenizer = AutoTokenizer.from_pretrained(model_name)\n+config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n+hparams = config.to_dict()\n+model = AutoModelForCausalLM.from_pretrained(model_name, config=config, torch_dtype=torch.float16 if use_f16 else torch.float32, low_cpu_mem_usage=True, trust_remote_code=True, offload_state_dict=True)\n+print(\"Model loaded: \", model_name)\n+\n+#print (model)\n+\n+list_vars = model.state_dict()\n+#print (list_vars)\n+\n+encoder = tokenizer.vocab\n+# Add added_tokens (special tokens) to the encoder\n+encoder.update(tokenizer.get_added_vocab())\n+print(hparams)\n+\n+print(\"Saving ggml model to: \", fname_out)\n+fout = open(fname_out, \"wb\")\n+\n+fout.write(struct.pack(\"i\", 0x67676d6c)) # magic: ggml in hex\n+vocab_size = hparams[\"vocab_size\"]\n+fout.write(struct.pack(\"i\", vocab_size))\n+# fout.write(struct.pack(\"i\", len(encoder)))\n+fout.write(struct.pack(\"i\", hparams[\"n_positions\"]))\n+fout.write(struct.pack(\"i\", hparams[\"n_embd\"]))\n+fout.write(struct.pack(\"i\", hparams[\"n_head\"]))\n+fout.write(struct.pack(\"i\", hparams[\"n_layer\"]))\n+fout.write(struct.pack(\"i\", use_f16))\n+\n+byte_encoder = bytes_to_unicode()\n+byte_decoder = {v:k for k, v in byte_encoder.items()}\n+\n+fout.write(struct.pack(\"i\", vocab_size))\n+\n+counter = 0\n+# sort by value\n+for key in sorted(encoder, key=encoder.get):\n+    text = bytearray([byte_decoder[c] for c in key])\n+    fout.write(struct.pack(\"i\", len(text)))\n+    fout.write(text)\n+    counter += 1\n+\n+# TODO: Repeat last token until vocab_size\n+while counter < vocab_size:\n+    fout.write(struct.pack(\"i\", len(text)))\n+    fout.write(text)\n+    counter += 1\n+# assert counter == config.vocab_size\n+\n+for name in list_vars.keys():\n+    data = list_vars[name].squeeze().numpy()\n+    print(\"Processing variable: \" + name + \" with shape: \", data.shape)\n+\n+    # rename headers to keep compatibility\n+    if name == \"transformer.ln_f.weight\":\n+        name = \"model/ln_f/g\"\n+    elif name == \"transformer.ln_f.bias\":\n+        name = \"model/ln_f/b\"\n+    elif name == \"transformer.wte.weight\":\n+        name = \"model/wte\"\n+    elif name == \"transformer.wpe.weight\":\n+        name = \"model/wpe\"\n+    elif name == \"lm_head.weight\":\n+        name = \"model/lm_head\"\n+    elif re.match(r\"transformer.h\\.\\d+\\.ln_1\\.weight\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/ln_1/g\"\n+    elif re.match(r\"transformer.h\\.\\d+\\.ln_1\\.bias\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/ln_1/b\"\n+    elif re.match(r\"transformer.h\\.\\d+\\.attn\\.c_attn\\.weight\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/attn/c_attn/w\"\n+    elif re.match(r\"transformer.h\\.\\d+\\.attn\\.c_attn\\.bias\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/attn/c_attn/b\"\n+    elif re.match(r\"transformer.h\\.\\d+\\.attn\\.c_proj\\.weight\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/attn/c_proj/w\"\n+    elif re.match(r\"transformer.h.\\d+.attn.c_proj.bias\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/attn/c_proj/b\"\n+    elif re.match(r\"transformer.h.\\d+.ln_2.weight\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/ln_2/g\"\n+    elif re.match(r\"transformer.h.\\d+.ln_2.bias\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/ln_2/b\"\n+    elif re.match(r\"transformer.h.\\d+.mlp.c_fc.weight\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/mlp/c_fc/w\"\n+    elif re.match(r\"transformer.h.\\d+.mlp.c_fc.bias\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/mlp/c_fc/b\"\n+    elif re.match(r\"transformer.h.\\d+.mlp.c_proj.weight\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/mlp/c_proj/w\"\n+    elif re.match(r\"transformer.h.\\d+.mlp.c_proj.bias\", name):\n+        i = re.findall(\"\\d+\", name)[0]\n+        name = f\"model/h{i}/mlp/c_proj/b\"\n+    else:\n+        print(\"Unrecognized variable name. %s\", name)\n+\n+    # we don't need these\n+    if name.endswith(\"attn.masked_bias\") or name.endswith(\".attn.bias\"):\n+        print(\"  Skipping variable: \" + name)\n+        continue\n+\n+    n_dims = len(data.shape);\n+\n+    # ftype == 0 -> float32, ftype == 1 -> float16\n+    ftype = 0;\n+    if use_f16:\n+        if (name == \"model/wte\" or name == \"model/lm_head\" or name[-2:] == \"/g\" or name[-2:] == \"/w\") and n_dims == 2:\n+            print(\"  Converting to float16\")\n+            data = data.astype(np.float16)\n+            ftype = 1\n+        else:\n+            print(\"  Converting to float32\")\n+            data = data.astype(np.float32)\n+            ftype = 0\n+\n+    \"model/h.*/attn/c_attn/w\"\n+    \"model/h.*/attn/c_proj/w\"\n+    \"model/h.*/mlp/c_fc/w\"\n+    \"model/h.*/mlp/c_proj/w\"\n+    if name[-14:] == \"/attn/c_attn/w\" or name[-14:] == \"/attn/c_attn/b\":\n+        print(\"  Duplicate K,V heads to use MHA instead of MQA\")\n+\n+        embed_dim = hparams[\"n_embd\"]\n+        head_dim = embed_dim // hparams[\"n_head\"]\n+\n+        # ((n_heads + 2) * head_dim, hidden_dim) -> (3 * n_heads * head_dim, hidden_dim)\n+        q, k ,v = np.split(data, (hparams[\"n_head\"] * head_dim, (hparams[\"n_head\"] + 1) * head_dim), axis=0)\n+        # duplicate k, v along the first axis (head_dim, hidden_dim) -> (n_heads * head_dim, hidden_dim)\n+        if len(k.shape) == 2:\n+            k = np.tile(k, (hparams[\"n_head\"], 1))\n+            v = np.tile(v, (hparams[\"n_head\"], 1))\n+        elif len(k.shape) == 1:\n+            k = np.tile(k, (hparams[\"n_head\"]))\n+            v = np.tile(v, (hparams[\"n_head\"]))\n+        # concat q, k, v along the first axis (n_heads * head_dim, hidden_dim) -> (3 * n_heads * head_dim, hidden_dim)\n+        data = np.concatenate((q, k, v), axis=0)\n+\n+    # header\n+    str = name.encode('utf-8')\n+    fout.write(struct.pack(\"iii\", n_dims, len(str), ftype))\n+    for i in range(n_dims):\n+        fout.write(struct.pack(\"i\", data.shape[n_dims - 1 - i]))\n+    fout.write(str);\n+\n+    # data\n+    data.tofile(fout)\n+\n+fout.close()\n+\n+print(\"Done. Output file: \" + fname_out)\n+print(\"\")\ndiff --git a/examples/starcoder/main.cpp b/examples/starcoder/main.cpp\nnew file mode 100644\nindex 000000000..af9151cd5\n--- /dev/null\n+++ b/examples/starcoder/main.cpp\n@@ -0,0 +1,847 @@\n+#include \"ggml/ggml.h\"\n+\n+#include \"common.h\"\n+#include \"common-ggml.h\"\n+\n+#include <cassert>\n+#include <cmath>\n+#include <cstdio>\n+#include <cstring>\n+#include <fstream>\n+#include <map>\n+#include <string>\n+#include <vector>\n+#include <iostream>\n+#include <unistd.h>\n+\n+// default hparams (GPT-2 117M)\n+// https://huggingface.co/bigcode/gpt_bigcode-santacoder/blob/main/config.json\n+struct gpt2_hparams {\n+    int32_t n_vocab = 49280;\n+    int32_t n_ctx   = 2048;\n+    int32_t n_embd  = 2048;\n+    int32_t n_head  = 16;\n+    int32_t n_layer = 24;\n+    int32_t ftype   = 1;\n+};\n+\n+struct gpt2_layer {\n+    // normalization\n+    struct ggml_tensor * ln_1_g;\n+    struct ggml_tensor * ln_1_b;\n+\n+    struct ggml_tensor * ln_2_g;\n+    struct ggml_tensor * ln_2_b;\n+\n+    // attention\n+    struct ggml_tensor * c_attn_attn_w;\n+    struct ggml_tensor * c_attn_attn_b;\n+\n+    struct ggml_tensor * c_attn_proj_w;\n+    struct ggml_tensor * c_attn_proj_b;\n+\n+    // mlp\n+    struct ggml_tensor * c_mlp_fc_w;\n+    struct ggml_tensor * c_mlp_fc_b;\n+\n+    struct ggml_tensor * c_mlp_proj_w;\n+    struct ggml_tensor * c_mlp_proj_b;\n+};\n+\n+struct gpt2_model {\n+    gpt2_hparams hparams;\n+\n+    // normalization\n+    struct ggml_tensor * ln_f_g;\n+    struct ggml_tensor * ln_f_b;\n+\n+    struct ggml_tensor * wte;     // position embedding\n+    struct ggml_tensor * wpe;     //    token embedding\n+    struct ggml_tensor * lm_head; // language model head\n+\n+    std::vector<gpt2_layer> layers;\n+\n+    // key + value memory\n+    struct ggml_tensor * memory_k;\n+    struct ggml_tensor * memory_v;\n+\n+    //\n+    struct ggml_context * ctx;\n+    std::map<std::string, struct ggml_tensor *> tensors;\n+};\n+\n+// load the model's weights from a file\n+bool gpt2_model_load(const std::string & fname, gpt2_model & model, gpt_vocab & vocab) {\n+    printf(\"%s: loading model from '%s'\\n\", __func__, fname.c_str());\n+\n+    auto fin = std::ifstream(fname, std::ios::binary);\n+    if (!fin) {\n+        fprintf(stderr, \"%s: failed to open '%s'\\n\", __func__, fname.c_str());\n+        return false;\n+    }\n+\n+    // verify magic\n+    {\n+        uint32_t magic;\n+        fin.read((char *) &magic, sizeof(magic));\n+        if (magic != 0x67676d6c) {\n+            fprintf(stderr, \"%s: invalid model file '%s' (bad magic)\\n\", __func__, fname.c_str());\n+            return false;\n+        }\n+    }\n+\n+    // load hparams\n+    {\n+        auto & hparams = model.hparams;\n+\n+        fin.read((char *) &hparams.n_vocab, sizeof(hparams.n_vocab));\n+        fin.read((char *) &hparams.n_ctx,   sizeof(hparams.n_ctx));\n+        fin.read((char *) &hparams.n_embd,  sizeof(hparams.n_embd));\n+        fin.read((char *) &hparams.n_head,  sizeof(hparams.n_head));\n+        fin.read((char *) &hparams.n_layer, sizeof(hparams.n_layer));\n+        fin.read((char *) &hparams.ftype,   sizeof(hparams.ftype));\n+\n+        printf(\"%s: n_vocab = %d\\n\", __func__, hparams.n_vocab);\n+        printf(\"%s: n_ctx   = %d\\n\", __func__, hparams.n_ctx);\n+        printf(\"%s: n_embd  = %d\\n\", __func__, hparams.n_embd);\n+        printf(\"%s: n_head  = %d\\n\", __func__, hparams.n_head);\n+        printf(\"%s: n_layer = %d\\n\", __func__, hparams.n_layer);\n+        printf(\"%s: ftype   = %d\\n\", __func__, hparams.ftype);\n+    }\n+\n+    // load vocab\n+    {\n+        int32_t n_vocab = 0;\n+        fin.read((char *) &n_vocab, sizeof(n_vocab));\n+\n+        if (n_vocab != model.hparams.n_vocab) {\n+            fprintf(stderr, \"%s: invalid model file '%s' (bad vocab size %d != %d)\\n\",\n+                    __func__, fname.c_str(), n_vocab, model.hparams.n_vocab);\n+            return false;\n+        }\n+\n+        std::string word;\n+        for (int i = 0; i < n_vocab; i++) {\n+            uint32_t len;\n+            fin.read((char *) &len, sizeof(len));\n+\n+            word.resize(len);\n+            fin.read((char *) word.data(), len);\n+\n+            vocab.token_to_id[word] = i;\n+            vocab.id_to_token[i] = word;\n+\n+            // if (i < 10) fprintf(stderr, \"%.s: vocab[%d] = '%s'\\n\", __func__, i, word.c_str());\n+        }\n+    }\n+\n+    // for the big tensors, we have the option to store the data in 16-bit floats or quantized\n+    // in order to save memory and also to speed up the computation\n+    ggml_type wtype = ggml_ftype_to_ggml_type((ggml_ftype) (model.hparams.ftype));\n+    if (wtype == GGML_TYPE_COUNT) {\n+        fprintf(stderr, \"%s: invalid model file '%s' (bad ftype value %d)\\n\",\n+                __func__, fname.c_str(), model.hparams.ftype);\n+        return false;\n+    }\n+\n+    auto & ctx = model.ctx;\n+\n+    size_t ctx_size = 0;\n+\n+    {\n+        const auto & hparams = model.hparams;\n+\n+        const int n_embd  = hparams.n_embd;\n+        const int n_layer = hparams.n_layer;\n+        const int n_ctx   = hparams.n_ctx;\n+        const int n_vocab = hparams.n_vocab;\n+\n+        const int head_dim = n_embd / hparams.n_head;\n+        const int kv_heads = hparams.n_head; // 1 if MQA else hparams.n_head\n+        const int kv_dim   = kv_heads * head_dim;\n+\n+        ctx_size += n_embd*ggml_type_sizef(GGML_TYPE_F32); // ln_f_g\n+        ctx_size += n_embd*ggml_type_sizef(GGML_TYPE_F32); // ln_f_b\n+\n+        ctx_size += n_vocab*n_embd*ggml_type_sizef(wtype);         // wte\n+        ctx_size +=   n_ctx*n_embd*ggml_type_sizef(GGML_TYPE_F32); // wpe\n+        ctx_size += n_vocab*n_embd*ggml_type_sizef(wtype);         // lm_head\n+\n+        ctx_size += n_layer*(n_embd*ggml_type_sizef(GGML_TYPE_F32)); // ln_1_g\n+        ctx_size += n_layer*(n_embd*ggml_type_sizef(GGML_TYPE_F32)); // ln_1_b\n+\n+        ctx_size += n_layer*(n_embd*ggml_type_sizef(GGML_TYPE_F32)); // ln_2_g\n+        ctx_size += n_layer*(n_embd*ggml_type_sizef(GGML_TYPE_F32)); // ln_2_b\n+\n+        ctx_size += n_layer*((n_embd + 2*kv_dim)*n_embd*ggml_type_sizef(wtype));         // c_attn_attn_w // TODO:\n+        ctx_size += n_layer*(       (n_embd + 2*kv_dim)*ggml_type_sizef(GGML_TYPE_F32)); // c_attn_attn_b\n+\n+        ctx_size += n_layer*(n_embd*n_embd*ggml_type_sizef(wtype));           // c_attn_proj_w\n+        ctx_size += n_layer*(       n_embd*ggml_type_sizef(GGML_TYPE_F32));   // c_attn_proj_b\n+\n+        ctx_size += n_layer*(4*n_embd*n_embd*ggml_type_sizef(wtype));         // c_mlp_fc_w\n+        ctx_size += n_layer*(       4*n_embd*ggml_type_sizef(GGML_TYPE_F32)); // c_mlp_fc_b\n+\n+        ctx_size += n_layer*(4*n_embd*n_embd*ggml_type_sizef(wtype));         // c_mlp_proj_w\n+        ctx_size += n_layer*(         n_embd*ggml_type_sizef(GGML_TYPE_F32)); // c_mlp_proj_b\n+\n+        ctx_size += n_ctx*n_layer*n_embd*ggml_type_sizef(GGML_TYPE_F32); // memory_k\n+        ctx_size += n_ctx*n_layer*n_embd*ggml_type_sizef(GGML_TYPE_F32); // memory_v\n+\n+        ctx_size += (6 + 12*n_layer)*256; // object overhead\n+\n+        printf(\"%s: ggml ctx size = %6.2f MB\\n\", __func__, ctx_size/(1024.0*1024.0));\n+    }\n+\n+    // create the ggml context\n+    {\n+        struct ggml_init_params params = {\n+            .mem_size   = ctx_size,\n+            .mem_buffer = NULL,\n+            .no_alloc   = false,\n+        };\n+\n+        model.ctx = ggml_init(params);\n+        if (!model.ctx) {\n+            fprintf(stderr, \"%s: ggml_init() failed\\n\", __func__);\n+            return false;\n+        }\n+    }\n+\n+    // prepare memory for the weights\n+    {\n+        const auto & hparams = model.hparams;\n+\n+        const int n_embd  = hparams.n_embd;\n+        const int n_layer = hparams.n_layer;\n+        const int n_ctx   = hparams.n_ctx;\n+        const int n_vocab = hparams.n_vocab;\n+\n+        const int head_dim = n_embd / hparams.n_head;\n+        const int kv_heads = hparams.n_head; // 1 if MQA else hparams.n_head\n+        const int kv_dim   = kv_heads * head_dim;\n+\n+        model.layers.resize(n_layer);\n+\n+        model.ln_f_g = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_embd);\n+        model.ln_f_b = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_embd);\n+\n+        model.wte     = ggml_new_tensor_2d(ctx, wtype,         n_embd, n_vocab);\n+        model.wpe     = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, n_embd, n_ctx);\n+        model.lm_head = ggml_new_tensor_2d(ctx, wtype,         n_embd, n_vocab);\n+\n+        // map by name\n+        model.tensors[\"model/ln_f/g\"] = model.ln_f_g;\n+        model.tensors[\"model/ln_f/b\"] = model.ln_f_b;\n+\n+        model.tensors[\"model/wte\"]     = model.wte;\n+        model.tensors[\"model/wpe\"]     = model.wpe;\n+        model.tensors[\"model/lm_head\"] = model.lm_head;\n+\n+        for (int i = 0; i < n_layer; ++i) {\n+            auto & layer = model.layers[i];\n+\n+            layer.ln_1_g        = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+            layer.ln_1_b        = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+\n+            layer.ln_2_g        = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+            layer.ln_2_b        = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+\n+            layer.c_attn_attn_w = ggml_new_tensor_2d(ctx, wtype,           n_embd, n_embd + 2*kv_dim);\n+            layer.c_attn_attn_b = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_embd + 2*kv_dim);\n+\n+            layer.c_attn_proj_w = ggml_new_tensor_2d(ctx, wtype,           n_embd, n_embd);\n+            layer.c_attn_proj_b = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+\n+            layer.c_mlp_fc_w    = ggml_new_tensor_2d(ctx, wtype,           n_embd, 4*n_embd); //TODO: 4*n_embd = config.n_inner\n+            layer.c_mlp_fc_b    = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, 4*n_embd);\n+\n+            layer.c_mlp_proj_w  = ggml_new_tensor_2d(ctx, wtype,         4*n_embd, n_embd);\n+            layer.c_mlp_proj_b  = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+\n+            // map by name\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/ln_1/g\"]        = layer.ln_1_g;\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/ln_1/b\"]        = layer.ln_1_b;\n+\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/ln_2/g\"]        = layer.ln_2_g;\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/ln_2/b\"]        = layer.ln_2_b;\n+\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/attn/c_attn/w\"] = layer.c_attn_attn_w;\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/attn/c_attn/b\"] = layer.c_attn_attn_b;\n+\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/attn/c_proj/w\"] = layer.c_attn_proj_w;\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/attn/c_proj/b\"] = layer.c_attn_proj_b;\n+\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/mlp/c_fc/w\"]    = layer.c_mlp_fc_w;\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/mlp/c_fc/b\"]    = layer.c_mlp_fc_b;\n+\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/mlp/c_proj/w\"]  = layer.c_mlp_proj_w;\n+            model.tensors[\"model/h\" + std::to_string(i) + \"/mlp/c_proj/b\"]  = layer.c_mlp_proj_b;\n+        }\n+    }\n+\n+    // key + value memory\n+    {\n+        const auto & hparams = model.hparams;\n+\n+        const int n_embd  = hparams.n_embd;\n+        const int n_layer = hparams.n_layer;\n+        const int n_ctx   = hparams.n_ctx;\n+\n+        const int n_mem      = n_layer*n_ctx;\n+        const int n_elements = n_embd*n_mem;\n+\n+        model.memory_k = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_elements);\n+        model.memory_v = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_elements);\n+\n+        const size_t memory_size = ggml_nbytes(model.memory_k) + ggml_nbytes(model.memory_v);\n+\n+        printf(\"%s: memory size = %8.2f MB, n_mem = %d\\n\", __func__, memory_size/1024.0/1024.0, n_mem);\n+    }\n+\n+    // load weights\n+    {\n+        size_t total_size = 0;\n+\n+        bool has_lm_head = false;\n+\n+        while (true) {\n+            int32_t n_dims;\n+            int32_t length;\n+            int32_t ttype;\n+\n+            fin.read(reinterpret_cast<char *>(&n_dims), sizeof(n_dims));\n+            fin.read(reinterpret_cast<char *>(&length), sizeof(length));\n+            fin.read(reinterpret_cast<char *>(&ttype),  sizeof(ttype));\n+\n+            if (fin.eof()) {\n+                break;\n+            }\n+\n+            int32_t nelements = 1;\n+            int32_t ne[2] = { 1, 1 };\n+            for (int i = 0; i < n_dims; ++i) {\n+                fin.read(reinterpret_cast<char *>(&ne[i]), sizeof(ne[i]));\n+                nelements *= ne[i];\n+            }\n+\n+            std::string name(length, 0);\n+            fin.read(&name[0], length);\n+\n+            if (model.tensors.find(name.data()) == model.tensors.end()) {\n+                fprintf(stderr, \"%s: unknown tensor '%s' in model file\\n\", __func__, name.data());\n+                return false;\n+            }\n+\n+            auto tensor = model.tensors[name.data()];\n+            if (tensor->ne[0] != ne[0] || tensor->ne[1] != ne[1]) {\n+                fprintf(stderr, \"%s: tensor '%s' has wrong shape in model file: got [%d, %d], expected [%d, %d]\\n\",\n+                        __func__, name.data(), (int) tensor->ne[0], (int) tensor->ne[1], ne[0], ne[1]);\n+                return false;\n+            }\n+            if (ggml_nelements(tensor) != nelements) {\n+                fprintf(stderr, \"%s: tensor '%s' has wrong size in model file. got %d, expected %d\\n\",\n+                        __func__, name.data(), (int) ggml_nelements(tensor), nelements);\n+                return false;\n+            }\n+\n+            // for debugging\n+            if (0) {\n+                printf(\"%24s - [%5d, %5d], type = %6s, %6.2f MB, %9zu bytes\\n\", name.data(), ne[0], ne[1], ggml_type_name(ggml_type(ttype)), ggml_nbytes(tensor)/1024.0/1024.0, ggml_nbytes(tensor));\n+            }\n+\n+            const size_t bpe = ggml_type_size(ggml_type(ttype));\n+\n+            if ((nelements*bpe)/ggml_blck_size(tensor->type) != ggml_nbytes(tensor)) {\n+                fprintf(stderr, \"%s: tensor '%s' has wrong size in model file: got %zu, expected %zu\\n\",\n+                        __func__, name.data(), ggml_nbytes(tensor), nelements*bpe);\n+                return false;\n+            }\n+\n+            fin.read(reinterpret_cast<char *>(tensor->data), ggml_nbytes(tensor));\n+\n+            // GPT-2 models share the WTE tensor as the LM head\n+            if (name == \"model/wte\" && has_lm_head == false) {\n+                memcpy(model.lm_head->data, tensor->data, ggml_nbytes(tensor));\n+            }\n+\n+            if (name == \"model/lm_head\") {\n+                has_lm_head = true;\n+            }\n+\n+            total_size += ggml_nbytes(tensor);\n+        }\n+\n+        printf(\"%s: model size  = %8.2f MB\\n\", __func__, total_size/1024.0/1024.0);\n+    }\n+\n+    fin.close();\n+\n+    return true;\n+}\n+\n+// evaluate the transformer\n+//\n+//   - model:     the model\n+//   - n_threads: number of threads to use\n+//   - n_past:    the context size so far\n+//   - embd_inp:  the embeddings of the tokens in the context\n+//   - embd_w:    the predicted logits for the next token\n+//\n+bool gpt2_eval(\n+        const gpt2_model & model,\n+        const int n_threads,\n+        const int n_past,\n+        const std::vector<gpt_vocab::id> & embd_inp,\n+              std::vector<float>         & embd_w,\n+              size_t                     & mem_per_token) {\n+    const int N = embd_inp.size();\n+\n+    const auto & hparams = model.hparams;\n+\n+    const int n_embd  = hparams.n_embd;\n+    const int n_layer = hparams.n_layer;\n+    const int n_ctx   = hparams.n_ctx;\n+    const int n_head  = hparams.n_head;\n+    const int n_vocab = hparams.n_vocab;\n+\n+    static size_t buf_size = 256u*1024*1024;\n+    static void * buf = malloc(buf_size);\n+\n+    if (mem_per_token > 0 && mem_per_token*N > buf_size) {\n+        const size_t buf_size_new = 1.1*(mem_per_token*N); // add 10% to account for ggml object overhead\n+        //printf(\"\\n%s: reallocating buffer from %zu to %zu bytes\\n\", __func__, buf_size, buf_size_new);\n+\n+        // reallocate\n+        buf_size = buf_size_new;\n+        buf = realloc(buf, buf_size);\n+        if (buf == nullptr) {\n+            fprintf(stderr, \"%s: failed to allocate %zu bytes\\n\", __func__, buf_size);\n+            return false;\n+        }\n+    }\n+\n+    struct ggml_init_params params = {\n+        .mem_size   = buf_size,\n+        .mem_buffer = buf,\n+        .no_alloc   = false,\n+    };\n+\n+    struct ggml_context * ctx0 = ggml_init(params);\n+    struct ggml_cgraph gf = {};\n+    gf.n_threads = n_threads;\n+\n+    struct ggml_tensor * embd = ggml_new_tensor_1d(ctx0, GGML_TYPE_I32, N);\n+    memcpy(embd->data, embd_inp.data(), N*ggml_element_size(embd));\n+\n+    struct ggml_tensor * position = ggml_new_tensor_1d(ctx0, GGML_TYPE_I32, N);\n+    for (int i = 0; i < N; ++i) {\n+        ((int32_t *) position->data)[i] = n_past + i;\n+    }\n+\n+    // wte + wpe\n+    struct ggml_tensor * inpL =\n+        ggml_add(ctx0,\n+                ggml_get_rows(ctx0, model.wte, embd),\n+                ggml_get_rows(ctx0, model.wpe, position));\n+\n+    for (int il = 0; il < n_layer; ++il) {\n+        struct ggml_tensor * cur;\n+\n+        // norm\n+        {\n+            // [ 768, N]\n+            cur = ggml_norm(ctx0, inpL);\n+\n+            // cur = ln_1_g*cur + ln_1_b\n+            // [ 768, N]\n+            cur = ggml_add(ctx0,\n+                    ggml_mul(ctx0,\n+                        ggml_repeat(ctx0, model.layers[il].ln_1_g, cur),\n+                        cur),\n+                    ggml_repeat(ctx0, model.layers[il].ln_1_b, cur));\n+        }\n+\n+        // attn\n+        // [2304, 768] - model.layers[il].c_attn_attn_w\n+        // [2304,   1] - model.layers[il].c_attn_attn_b\n+        // [ 768,   N] - cur (in)\n+        // [2304,   N] - cur (out)\n+        //\n+        // cur = attn_w*cur + attn_b\n+        // [2304, N]\n+        {\n+            cur = ggml_mul_mat(ctx0,\n+                    model.layers[il].c_attn_attn_w,\n+                    cur);\n+\n+            cur = ggml_add(ctx0,\n+                    ggml_repeat(ctx0, model.layers[il].c_attn_attn_b, cur),\n+                    cur);\n+        }\n+\n+        // self-attention\n+        {\n+            struct ggml_tensor * Qcur = ggml_view_2d(ctx0, cur, n_embd, N, cur->nb[1], 0*sizeof(float)*n_embd);\n+            struct ggml_tensor * Kcur = ggml_view_2d(ctx0, cur, n_embd, N, cur->nb[1], 1*sizeof(float)*n_embd);\n+            struct ggml_tensor * Vcur = ggml_view_2d(ctx0, cur, n_embd, N, cur->nb[1], 2*sizeof(float)*n_embd);\n+\n+            // store key and value to memory\n+            if (N >= 1) {\n+                struct ggml_tensor * k = ggml_view_1d(ctx0, model.memory_k, N*n_embd, (ggml_element_size(model.memory_k)*n_embd)*(il*n_ctx + n_past));\n+                struct ggml_tensor * v = ggml_view_1d(ctx0, model.memory_v, N*n_embd, (ggml_element_size(model.memory_v)*n_embd)*(il*n_ctx + n_past));\n+\n+                ggml_build_forward_expand(&gf, ggml_cpy(ctx0, Kcur, k));\n+                ggml_build_forward_expand(&gf, ggml_cpy(ctx0, Vcur, v));\n+            }\n+\n+            // Q = Qcur.contiguous().view(n_embd/n_head, n_head, N).permute(0, 2, 1, 3)\n+            // [64, N, 12]\n+            struct ggml_tensor * Q =\n+                ggml_permute(ctx0,\n+                        ggml_cpy(ctx0,\n+                            Qcur,\n+                            ggml_new_tensor_3d(ctx0, GGML_TYPE_F32, n_embd/n_head, n_head, N)),\n+                        0, 2, 1, 3);\n+\n+            // K = Kmem.view(n_embd/n_head, n_head, n_past + N).permute(0, 2, 1, 3)\n+            // [64, n_past + N, 12]\n+            struct ggml_tensor * K =\n+                ggml_permute(ctx0,\n+                        ggml_reshape_3d(ctx0,\n+                            ggml_view_1d(ctx0, model.memory_k, (n_past + N)*n_embd, il*n_ctx*ggml_element_size(model.memory_k)*n_embd),\n+                            n_embd/n_head, n_head, n_past + N),\n+                        0, 2, 1, 3); //TODO: need to be tiled \n+\n+            // GG: flash attention\n+            //struct ggml_tensor * V =\n+            //    ggml_cpy(ctx0,\n+            //            ggml_permute(ctx0,\n+            //                ggml_reshape_3d(ctx0,\n+            //                    ggml_view_1d(ctx0, model.memory_v, (n_past + N)*n_embd, il*n_ctx*ggml_element_size(model.memory_v)*n_embd),\n+            //                    n_embd/n_head, n_head, n_past + N),\n+            //                1, 2, 0, 3),\n+            //            ggml_new_tensor_3d(ctx0, GGML_TYPE_F32, n_past + N, n_embd/n_head, n_head));\n+\n+            //struct ggml_tensor * KQV = ggml_flash_attn(ctx0, Q, K, V, true);\n+\n+            // K * Q\n+            // [n_past + N, N, 12]\n+            struct ggml_tensor * KQ = ggml_mul_mat(ctx0, K, Q); //TODO: check if it broadcasts\n+\n+            // KQ_scaled = KQ / sqrt(n_embd/n_head)\n+            // [n_past + N, N, 12]\n+            struct ggml_tensor * KQ_scaled =\n+                ggml_scale(ctx0,\n+                        KQ,\n+                        ggml_new_f32(ctx0, 1.0f/sqrt(float(n_embd)/n_head))\n+                        );\n+\n+            // KQ_masked = mask_past(KQ_scaled)\n+            // [n_past + N, N, 12]\n+            struct ggml_tensor * KQ_masked = ggml_diag_mask_inf(ctx0, KQ_scaled, n_past);\n+\n+            // KQ = soft_max(KQ_masked)\n+            // [n_past + N, N, 12]\n+            struct ggml_tensor * KQ_soft_max = ggml_soft_max(ctx0, KQ_masked);\n+\n+            // V_trans = Vmem.view(n_embd/n_head, n_head, n_past + N).permute(1, 2, 0, 3).contiguous()\n+            // [n_past + N, 64, 12]\n+            struct ggml_tensor * V_trans =\n+                ggml_cpy(ctx0,\n+                        ggml_permute(ctx0,\n+                            ggml_reshape_3d(ctx0,\n+                                ggml_view_1d(ctx0, model.memory_v, (n_past + N)*n_embd, il*n_ctx*ggml_element_size(model.memory_v)*n_embd),\n+                                n_embd/n_head, n_head, n_past + N),\n+                            1, 2, 0, 3),\n+                        ggml_new_tensor_3d(ctx0, model.memory_v->type, n_past + N, n_embd/n_head, n_head));\n+\n+            // KQV = transpose(V) * KQ_soft_max\n+            // [64, N, 12]\n+            struct ggml_tensor * KQV = ggml_mul_mat(ctx0, V_trans, KQ_soft_max);\n+\n+            // KQV_merged = KQV.permute(0, 2, 1, 3)\n+            // [64, 12, N]\n+            struct ggml_tensor * KQV_merged = ggml_permute(ctx0, KQV, 0, 2, 1, 3);\n+\n+            // cur = KQV_merged.contiguous().view(n_embd, N)\n+            // [768, N]\n+            cur = ggml_cpy(ctx0,\n+                    KQV_merged,\n+                    ggml_new_tensor_2d(ctx0, GGML_TYPE_F32, n_embd, N));\n+        }\n+\n+        // projection\n+        // [ 768, 768] - model.layers[il].c_attn_proj_w\n+        // [ 768,   1] - model.layers[il].c_attn_proj_b\n+        // [ 768,   N] - cur (in)\n+        // [ 768,   N] - cur (out)\n+        //\n+        // cur = proj_w*cur + proj_b\n+        // [768, N]\n+        {\n+            cur = ggml_mul_mat(ctx0,\n+                    model.layers[il].c_attn_proj_w,\n+                    cur);\n+\n+            cur = ggml_add(ctx0,\n+                    ggml_repeat(ctx0, model.layers[il].c_attn_proj_b, cur),\n+                    cur);\n+        }\n+\n+        // add the input\n+        cur = ggml_add(ctx0, cur, inpL);\n+\n+        struct ggml_tensor * inpFF = cur;\n+\n+        // feed-forward network\n+        {\n+            // norm\n+            {\n+                cur = ggml_norm(ctx0, inpFF);\n+\n+                // cur = ln_2_g*cur + ln_2_b\n+                // [ 768, N]\n+                cur = ggml_add(ctx0,\n+                        ggml_mul(ctx0,\n+                            ggml_repeat(ctx0, model.layers[il].ln_2_g, cur),\n+                            cur),\n+                        ggml_repeat(ctx0, model.layers[il].ln_2_b, cur));\n+            }\n+\n+            // fully connected\n+            // [3072, 768] - model.layers[il].c_mlp_fc_w\n+            // [3072,   1] - model.layers[il].c_mlp_fc_b\n+            // [ 768,   N] - cur (in)\n+            // [3072,   N] - cur (out)\n+            //\n+            // cur = fc_w*cur + fc_b\n+            // [3072, N]\n+            cur = ggml_mul_mat(ctx0,\n+                    model.layers[il].c_mlp_fc_w,\n+                    cur);\n+\n+            cur = ggml_add(ctx0,\n+                    ggml_repeat(ctx0, model.layers[il].c_mlp_fc_b, cur),\n+                    cur);\n+\n+            // GELU activation\n+            // [3072, N]\n+            cur = ggml_gelu(ctx0, cur);\n+\n+            // projection\n+            // [ 768, 3072] - model.layers[il].c_mlp_proj_w\n+            // [ 768,    1] - model.layers[il].c_mlp_proj_b\n+            // [3072,    N] - cur (in)\n+            // [ 768,    N] - cur (out)\n+            //\n+            // cur = proj_w*cur + proj_b\n+            // [768, N]\n+            cur = ggml_mul_mat(ctx0,\n+                    model.layers[il].c_mlp_proj_w,\n+                    cur);\n+\n+            cur = ggml_add(ctx0,\n+                    ggml_repeat(ctx0, model.layers[il].c_mlp_proj_b, cur),\n+                    cur);\n+        }\n+\n+        // input for next layer\n+        inpL = ggml_add(ctx0, cur, inpFF);\n+    }\n+\n+    // norm\n+    {\n+        // [ 768, N]\n+        inpL = ggml_norm(ctx0, inpL);\n+\n+        // inpL = ln_f_g*inpL + ln_f_b\n+        // [ 768, N]\n+        inpL = ggml_add(ctx0,\n+                ggml_mul(ctx0,\n+                    ggml_repeat(ctx0, model.ln_f_g, inpL),\n+                    inpL),\n+                ggml_repeat(ctx0, model.ln_f_b, inpL));\n+    }\n+\n+    // inpL = WTE * inpL\n+    // [ 768, 50257] - model.lm_head\n+    // [ 768, N]     - inpL\n+    inpL = ggml_mul_mat(ctx0, model.lm_head, inpL);\n+\n+    // logits -> probs\n+    //inpL = ggml_soft_max(ctx0, inpL);\n+\n+    // run the computation\n+    ggml_build_forward_expand(&gf, inpL);\n+    ggml_graph_compute       (ctx0, &gf);\n+\n+    //if (n_past%100 == 0) {\n+    //    ggml_graph_print   (&gf);\n+    //    ggml_graph_dump_dot(&gf, NULL, \"gpt-2.dot\");\n+    //}\n+\n+    //embd_w.resize(n_vocab*N);\n+    //memcpy(embd_w.data(), ggml_get_data(inpL), sizeof(float)*n_vocab*N);\n+\n+    // return result just for the last token\n+    embd_w.resize(n_vocab);\n+    memcpy(embd_w.data(), (float *) ggml_get_data(inpL) + (n_vocab*(N-1)), sizeof(float)*n_vocab);\n+\n+    if (mem_per_token == 0) {\n+        mem_per_token = ggml_used_mem(ctx0)/N;\n+    }\n+    //printf(\"used_mem = %zu\\n\", ggml_used_mem(ctx0));\n+\n+    ggml_free(ctx0);\n+\n+    return true;\n+}\n+\n+int main(int argc, char ** argv) {\n+    const int64_t t_main_start_us = ggml_time_us();\n+\n+    gpt_params params;\n+    params.model = \"models/gpt-2-117M/ggml-model.bin\";\n+\n+    if (gpt_params_parse(argc, argv, params) == false) {\n+        return 1;\n+    }\n+\n+    if (params.seed < 0) {\n+        params.seed = time(NULL);\n+    }\n+\n+    printf(\"%s: seed = %d\\n\", __func__, params.seed);\n+\n+    std::mt19937 rng(params.seed);\n+    if (params.prompt.empty()) {\n+        if( !isatty(STDIN_FILENO) ){\n+            std::string line;\n+            while( std::getline(std::cin, line) ){\n+                params.prompt = params.prompt + \"\\n\" + line;\n+            }\n+        } else {\n+            params.prompt = gpt_random_prompt(rng);\n+        }\n+    }\n+\n+    int64_t t_load_us = 0;\n+\n+    gpt_vocab vocab;\n+    gpt2_model model;\n+\n+    // load the model\n+    {\n+        const int64_t t_start_us = ggml_time_us();\n+\n+        if (!gpt2_model_load(params.model, model, vocab)) {\n+            fprintf(stderr, \"%s: failed to load model from '%s'\\n\", __func__, params.model.c_str());\n+            return 1;\n+        }\n+\n+        t_load_us = ggml_time_us() - t_start_us;\n+    }\n+\n+    int n_past = 0;\n+\n+    int64_t t_sample_us  = 0;\n+    int64_t t_predict_us = 0;\n+\n+    std::vector<float> logits;\n+\n+    // tokenize the prompt\n+    std::vector<gpt_vocab::id> embd_inp = ::gpt_tokenize(vocab, params.prompt);\n+\n+    params.n_predict = std::min(params.n_predict, model.hparams.n_ctx - (int) embd_inp.size());\n+\n+    printf(\"%s: prompt: '%s'\\n\", __func__, params.prompt.c_str());\n+    printf(\"%s: number of tokens in prompt = %zu, first 8 tokens: \", __func__, embd_inp.size());\n+    for (int i = 0; i < std::min(8, (int) embd_inp.size()); i++) {\n+        printf(\"%d \", embd_inp[i]);\n+    }\n+    printf(\"\\n\\n\");\n+\n+    // submit the input prompt token-by-token\n+    // this reduces the memory usage during inference, at the cost of a bit of speed at the beginning\n+    std::vector<gpt_vocab::id> embd;\n+\n+    // determine the required inference memory per token:\n+    size_t mem_per_token = 0;\n+    gpt2_eval(model, params.n_threads, 0, { 0, 1, 2, 3 }, logits, mem_per_token);\n+\n+    for (int i = embd.size(); i < embd_inp.size() + params.n_predict; i++) {\n+        // predict\n+        if (embd.size() > 0) {\n+            const int64_t t_start_us = ggml_time_us();\n+\n+            if (!gpt2_eval(model, params.n_threads, n_past, embd, logits, mem_per_token)) {\n+                printf(\"Failed to predict\\n\");\n+                return 1;\n+            }\n+\n+            t_predict_us += ggml_time_us() - t_start_us;\n+        }\n+\n+        n_past += embd.size();\n+        embd.clear();\n+\n+        if (i >= embd_inp.size()) {\n+            // sample next token\n+            const int   top_k = params.top_k;\n+            const float top_p = params.top_p;\n+            const float temp  = params.temp;\n+\n+            const int n_vocab = model.hparams.n_vocab;\n+\n+            gpt_vocab::id id = 0;\n+\n+            {\n+                const int64_t t_start_sample_us = ggml_time_us();\n+\n+                id = gpt_sample_top_k_top_p(vocab, logits.data() + (logits.size() - n_vocab), top_k, top_p, temp, rng);\n+\n+                t_sample_us += ggml_time_us() - t_start_sample_us;\n+            }\n+\n+            // add it to the context\n+            embd.push_back(id);\n+        } else {\n+            // if here, it means we are still processing the input prompt\n+            for (int k = i; k < embd_inp.size(); k++) {\n+                embd.push_back(embd_inp[k]);\n+                if (embd.size() >= params.n_batch) {\n+                    break;\n+                }\n+            }\n+            i += embd.size() - 1;\n+        }\n+\n+        // display text\n+        for (auto id : embd) {\n+            printf(\"%s\", vocab.id_to_token[id].c_str());\n+        }\n+        fflush(stdout);\n+\n+        // end of text token\n+        if (embd.back() == 0) { //TODO: this is only for starcoder\n+            break;\n+        }\n+    }\n+\n+    // report timing\n+    {\n+        const int64_t t_main_end_us = ggml_time_us();\n+\n+        printf(\"\\n\\n\");\n+        printf(\"%s: mem per token = %8zu bytes\\n\", __func__, mem_per_token);\n+        printf(\"%s:     load time = %8.2f ms\\n\", __func__, t_load_us/1000.0f);\n+        printf(\"%s:   sample time = %8.2f ms\\n\", __func__, t_sample_us/1000.0f);\n+        printf(\"%s:  predict time = %8.2f ms / %.2f ms per token\\n\", __func__, t_predict_us/1000.0f, t_predict_us/1000.0f/n_past);\n+        printf(\"%s:    total time = %8.2f ms\\n\", __func__, (t_main_end_us - t_main_start_us)/1000.0f);\n+    }\n+\n+    ggml_free(model.ctx);\n+\n+    return 0;\n+}\ndiff --git a/examples/starcoder/quantize.cpp b/examples/starcoder/quantize.cpp\nnew file mode 100644\nindex 000000000..2ed612d00\n--- /dev/null\n+++ b/examples/starcoder/quantize.cpp\n@@ -0,0 +1,178 @@\n+#include \"ggml/ggml.h\"\n+\n+#include \"common.h\"\n+#include \"common-ggml.h\"\n+\n+#include <cassert>\n+#include <cmath>\n+#include <cstdio>\n+#include <cstring>\n+#include <fstream>\n+#include <map>\n+#include <string>\n+#include <vector>\n+#include <regex>\n+\n+// default hparams (GPT-2 117M)\n+struct gpt2_hparams {\n+    int32_t n_vocab = 49280;\n+    int32_t n_ctx   = 2048;\n+    int32_t n_embd  = 2048;\n+    int32_t n_head  = 16;\n+    int32_t n_layer = 24;\n+    int32_t f16     = 1;\n+};\n+\n+// quantize a model\n+bool gpt2_model_quantize(const std::string & fname_inp, const std::string & fname_out, ggml_ftype ftype) {\n+    gpt_vocab vocab;\n+\n+    printf(\"%s: loading model from '%s'\\n\", __func__, fname_inp.c_str());\n+\n+    auto finp = std::ifstream(fname_inp, std::ios::binary);\n+    if (!finp) {\n+        fprintf(stderr, \"%s: failed to open '%s' for reading\\n\", __func__, fname_inp.c_str());\n+        return false;\n+    }\n+\n+    auto fout = std::ofstream(fname_out, std::ios::binary);\n+    if (!fout) {\n+        fprintf(stderr, \"%s: failed to open '%s' for writing\\n\", __func__, fname_out.c_str());\n+        return false;\n+    }\n+\n+    // verify magic\n+    {\n+        uint32_t magic;\n+        finp.read((char *) &magic, sizeof(magic));\n+        if (magic != 0x67676d6c) {\n+            fprintf(stderr, \"%s: invalid model file '%s' (bad magic)\\n\", __func__, fname_inp.c_str());\n+            return false;\n+        }\n+\n+        fout.write((char *) &magic, sizeof(magic));\n+    }\n+\n+    gpt2_hparams hparams;\n+\n+    // load hparams\n+    {\n+        finp.read((char *) &hparams.n_vocab, sizeof(hparams.n_vocab));\n+        finp.read((char *) &hparams.n_ctx,   sizeof(hparams.n_ctx));\n+        finp.read((char *) &hparams.n_embd,  sizeof(hparams.n_embd));\n+        finp.read((char *) &hparams.n_head,  sizeof(hparams.n_head));\n+        finp.read((char *) &hparams.n_layer, sizeof(hparams.n_layer));\n+        finp.read((char *) &hparams.f16,     sizeof(hparams.f16));\n+\n+        printf(\"%s: n_vocab = %d\\n\", __func__, hparams.n_vocab);\n+        printf(\"%s: n_ctx   = %d\\n\", __func__, hparams.n_ctx);\n+        printf(\"%s: n_embd  = %d\\n\", __func__, hparams.n_embd);\n+        printf(\"%s: n_head  = %d\\n\", __func__, hparams.n_head);\n+        printf(\"%s: n_layer = %d\\n\", __func__, hparams.n_layer);\n+        printf(\"%s: f16     = %d\\n\", __func__, hparams.f16);\n+\n+        fout.write((char *) &hparams.n_vocab, sizeof(hparams.n_vocab));\n+        fout.write((char *) &hparams.n_ctx,   sizeof(hparams.n_ctx));\n+        fout.write((char *) &hparams.n_embd,  sizeof(hparams.n_embd));\n+        fout.write((char *) &hparams.n_head,  sizeof(hparams.n_head));\n+        fout.write((char *) &hparams.n_layer, sizeof(hparams.n_layer));\n+        fout.write((char *) &ftype,           sizeof(hparams.f16));\n+    }\n+\n+    // load vocab\n+    {\n+        int32_t n_vocab = 0;\n+        finp.read ((char *) &n_vocab, sizeof(n_vocab));\n+        fout.write((char *) &n_vocab, sizeof(n_vocab));\n+\n+        if (n_vocab != hparams.n_vocab) {\n+            fprintf(stderr, \"%s: invalid model file '%s' (bad vocab size %d != %d)\\n\",\n+                    __func__, fname_inp.c_str(), n_vocab, hparams.n_vocab);\n+            return false;\n+        }\n+\n+        std::string word;\n+        for (int i = 0; i < n_vocab; i++) {\n+            uint32_t len;\n+            finp.read ((char *) &len, sizeof(len));\n+            fout.write((char *) &len, sizeof(len));\n+\n+            word.resize(len);\n+            finp.read ((char *) word.data(), len);\n+            fout.write((char *) word.data(), len);\n+\n+            vocab.token_to_id[word] = i;\n+            vocab.id_to_token[i] = word;\n+        }\n+    }\n+\n+    // regexes of tensor names to be quantized\n+    const std::vector<std::string> to_quant = {\n+        \"model/wte\",\n+        \"model/lm_head\",\n+        \"model/h.*/attn/c_attn/w\",\n+        \"model/h.*/attn/c_proj/w\",\n+        \"model/h.*/mlp/c_fc/w\",\n+        \"model/h.*/mlp/c_proj/w\",\n+    };\n+\n+    if (!ggml_common_quantize_0(finp, fout, ftype, to_quant, {})) {\n+        fprintf(stderr, \"%s: failed to quantize model '%s'\\n\", __func__, fname_inp.c_str());\n+        return false;\n+    }\n+\n+    finp.close();\n+    fout.close();\n+\n+    return true;\n+}\n+\n+// usage:\n+//  ./gpt-2-quantize models/gpt-2-117M/ggml-model.bin models/gpt-2-117M/ggml-model-quant.bin type\n+//\n+int main(int argc, char ** argv) {\n+    if (argc != 4) {\n+        fprintf(stderr, \"usage: %s model-f32.bin model-quant.bin type\\n\", argv[0]);\n+        ggml_print_ftypes(stderr);\n+        return 1;\n+    }\n+\n+    // needed to initialize f16 tables\n+    {\n+        struct ggml_init_params params = { 0, NULL, false };\n+        struct ggml_context * ctx = ggml_init(params);\n+        ggml_free(ctx);\n+    }\n+\n+    const std::string fname_inp = argv[1];\n+    const std::string fname_out = argv[2];\n+\n+    const ggml_ftype ftype = ggml_parse_ftype(argv[3]);\n+\n+    const int64_t t_main_start_us = ggml_time_us();\n+\n+    int64_t t_quantize_us = 0;\n+\n+    // load the model\n+    {\n+        const int64_t t_start_us = ggml_time_us();\n+\n+        if (!gpt2_model_quantize(fname_inp, fname_out, ggml_ftype(ftype))) {\n+            fprintf(stderr, \"%s: failed to quantize model from '%s'\\n\", __func__, fname_inp.c_str());\n+            return 1;\n+        }\n+\n+        t_quantize_us = ggml_time_us() - t_start_us;\n+    }\n+\n+    // report timing\n+    {\n+        const int64_t t_main_end_us = ggml_time_us();\n+\n+        printf(\"\\n\");\n+        printf(\"%s: quantize time = %8.2f ms\\n\", __func__, t_quantize_us/1000.0f);\n+        printf(\"%s:    total time = %8.2f ms\\n\", __func__, (t_main_end_us - t_main_start_us)/1000.0f);\n+    }\n+\n+    return 0;\n+}\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Issue with Memory Allocation**: You're encountering a `GGML_ASSERT` failure related to `ctx->mem_buffer` being NULL. Ensure sufficient RAM is allocated for model loading, especially with large models.\n\n2. **Model Execution Problem**: The prompt `def hello_world(` outputs unexpected results. This may indicate issues with the model quantization format after recent changes. Requantize weights using the latest code or revert to a previous commit for compatibility.\n\n3. **Build Errors**: If facing a `fatal error: 'wchar.h' file not found`, clear the build directory (`rm -rf build`) and rebuild to resolve SDK upgrade issues.\n\n4. **Parameter Tuning**: Adjust `top_k` to 1 and set `n=64` to limit output length and improve response coherence, as demonstrated with the `fibonacci` prompt.  \n\n5. **Model Sharing**: Share quantized models on Hugging Face after confirming they function properly to aid others."
      }
    ],
    "codediff_length": 49933
  },
  {
    "index": 110,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/include/ggml/ggml.h b/include/ggml/ggml.h\nindex 3eddc44b9..4b16032f0 100644\n--- a/include/ggml/ggml.h\n+++ b/include/ggml/ggml.h\n@@ -400,15 +400,16 @@ extern \"C\" {\n         GGML_OP_ALIBI,\n         GGML_OP_CLAMP,\n         GGML_OP_CONV_1D,\n-        GGML_OP_CONV_2D,\n+        GGML_OP_CONV_1D_STAGE_0,  // internal\n+        GGML_OP_CONV_1D_STAGE_1,  // internal\n         GGML_OP_CONV_TRANSPOSE_1D,\n+        GGML_OP_CONV_2D,\n+        GGML_OP_CONV_2D_STAGE_0, // internal\n+        GGML_OP_CONV_2D_STAGE_1, // internal\n         GGML_OP_CONV_TRANSPOSE_2D,\n         GGML_OP_POOL_1D,\n         GGML_OP_POOL_2D,\n \n-        GGML_OP_CONV_1D_STAGE_0,  // internal\n-        GGML_OP_CONV_1D_STAGE_1,  // internal\n-\n         GGML_OP_UPSCALE, // nearest interpolate\n \n         GGML_OP_FLASH_ATTN,\n@@ -1016,9 +1017,9 @@ extern \"C\" {\n             struct ggml_tensor  * b,\n             float                 eps);\n \n-    // A: n columns, m rows\n-    // B: n columns, p rows  (i.e. we transpose it internally)\n-    // result is m columns, p rows\n+    // A: k columns, n rows => [ne03, ne02, n, k]\n+    // B: k columns, m rows  (i.e. we transpose it internally) => [ne03 * x, ne02 * y, m, k]\n+    // result is n columns, m rows => [ne03 * x, ne02 * y, m, n]\n     GGML_API struct ggml_tensor * ggml_mul_mat(\n             struct ggml_context * ctx,\n             struct ggml_tensor  * a,\ndiff --git a/src/ggml.c b/src/ggml.c\nindex 6d1776ca4..2d3c7b801 100644\n--- a/src/ggml.c\n+++ b/src/ggml.c\n@@ -571,7 +571,6 @@ int64_t ggml_cycles_per_ms(void) {\n #define ggml_perf_cycles_per_ms() 0\n #endif\n \n-\n //\n // cache line\n //\n@@ -1828,7 +1827,6 @@ ggml_type_traits_t ggml_internal_get_type_traits(enum ggml_type type) {\n     return type_traits[type];\n }\n \n-\n //\n // simd mappings\n //\n@@ -4057,16 +4055,17 @@ static const char * GGML_OP_NAME[GGML_OP_COUNT] = {\n     \"ALIBI\",\n     \"CLAMP\",\n     \"CONV_1D\",\n+    \"CONV_1D_STAGE_0\",\n+    \"CONV_1D_STAGE_1\",\n     \"CONV_TRANSPOSE_1D\",\n     \"CONV_2D\",\n+    \"CONV_2D_STAGE_0\",\n+    \"CONV_2D_STAGE_1\",\n     \"CONV_TRANSPOSE_2D\",\n     \"POOL_1D\",\n     \"POOL_2D\",\n     \"UPSCALE\",\n \n-    \"CONV_1D_STAGE_0\",\n-    \"CONV_1D_STAGE_1\",\n-\n     \"FLASH_ATTN\",\n     \"FLASH_FF\",\n     \"FLASH_ATTN_BACK\",\n@@ -4092,7 +4091,7 @@ static const char * GGML_OP_NAME[GGML_OP_COUNT] = {\n     \"CROSS_ENTROPY_LOSS_BACK\",\n };\n \n-static_assert(GGML_OP_COUNT == 71, \"GGML_OP_COUNT != 71\");\n+static_assert(GGML_OP_COUNT == 73, \"GGML_OP_COUNT != 73\");\n \n static const char * GGML_OP_SYMBOL[GGML_OP_COUNT] = {\n     \"none\",\n@@ -4143,16 +4142,17 @@ static const char * GGML_OP_SYMBOL[GGML_OP_COUNT] = {\n     \"alibi(x)\",\n     \"clamp(x)\",\n     \"conv_1d(x)\",\n+    \"conv_1d_stage_0(x)\",\n+    \"conv_1d_stage_1(x)\",\n     \"conv_transpose_1d(x)\",\n     \"conv_2d(x)\",\n+    \"conv_2d_stage_0(x)\",\n+    \"conv_2d_stage_1(x)\",\n     \"conv_transpose_2d(x)\",\n     \"pool_1d(x)\",\n     \"pool_2d(x)\",\n     \"upscale(x)\",\n \n-    \"conv_1d_stage_0(x)\",\n-    \"conv_1d_stage_1(x)\",\n-\n     \"flash_attn(x)\",\n     \"flash_ff(x)\",\n     \"flash_attn_back(x)\",\n@@ -4178,7 +4178,7 @@ static const char * GGML_OP_SYMBOL[GGML_OP_COUNT] = {\n     \"cross_entropy_loss_back(x,y)\",\n };\n \n-static_assert(GGML_OP_COUNT == 71, \"GGML_OP_COUNT != 71\");\n+static_assert(GGML_OP_COUNT == 73, \"GGML_OP_COUNT != 73\");\n \n static_assert(GGML_OP_POOL_COUNT == 2, \"GGML_OP_POOL_COUNT != 2\");\n \n@@ -4209,8 +4209,10 @@ static void ggml_setup_op_has_task_pass(void) {\n         p[GGML_OP_CONV_1D                ] = true;\n         p[GGML_OP_CONV_1D_STAGE_0        ] = true;\n         p[GGML_OP_CONV_1D_STAGE_1        ] = true;\n-        p[GGML_OP_CONV_2D                ] = true;\n         p[GGML_OP_CONV_TRANSPOSE_1D      ] = true;\n+        p[GGML_OP_CONV_2D                ] = true;\n+        p[GGML_OP_CONV_2D_STAGE_0        ] = true;\n+        p[GGML_OP_CONV_2D_STAGE_1        ] = true;\n         p[GGML_OP_CONV_TRANSPOSE_2D      ] = true;\n         p[GGML_OP_FLASH_ATTN_BACK        ] = true;\n         p[GGML_OP_CROSS_ENTROPY_LOSS     ] = true;\n@@ -5921,7 +5923,6 @@ struct ggml_tensor * ggml_sqrt_inplace(\n     return ggml_sqrt_impl(ctx, a, true);\n }\n \n-\n // ggml_log\n \n static struct ggml_tensor * ggml_log_impl(\n@@ -5975,7 +5976,6 @@ struct ggml_tensor * ggml_sum(\n     return result;\n }\n \n-\n // ggml_sum_rows\n \n struct ggml_tensor * ggml_sum_rows(\n@@ -6607,7 +6607,6 @@ struct ggml_tensor * ggml_set_2d_inplace(\n     return ggml_set_impl(ctx, a, b, nb1, a->nb[2], a->nb[3], offset, false);\n }\n \n-\n // ggml_cpy\n \n static struct ggml_tensor * ggml_cpy_impl(\n@@ -6687,7 +6686,6 @@ struct ggml_tensor * ggml_cont_inplace(\n     return ggml_cont_impl(ctx, a, true);\n }\n \n-\n // make contiguous, with new shape\n GGML_API struct ggml_tensor * ggml_cont_1d(\n         struct ggml_context * ctx,\n@@ -7140,7 +7138,6 @@ struct ggml_tensor * ggml_diag(\n     return result;\n }\n \n-\n // ggml_diag_mask_inf\n \n static struct ggml_tensor * ggml_diag_mask_inf_impl(\n@@ -7252,7 +7249,6 @@ struct ggml_tensor * ggml_soft_max_inplace(\n     return ggml_soft_max_impl(ctx, a, true);\n }\n \n-\n // ggml_soft_max_back\n \n static struct ggml_tensor * ggml_soft_max_back_impl(\n@@ -7669,7 +7665,11 @@ GGML_API struct ggml_tensor * ggml_conv_transpose_1d(\n \n // ggml_conv_2d\n \n-struct ggml_tensor * ggml_conv_2d(\n+// im2col: [N, IC, IH, IW] => [N, OH, OW, IC*KH*KW]\n+// a: [OC\uff0cIC, KH, KW]\n+// b: [N, IC, IH, IW]\n+// result: [N, OH, OW, IC*KH*KW]\n+static struct ggml_tensor * ggml_conv_2d_stage_0(\n     struct ggml_context * ctx,\n     struct ggml_tensor  * a,\n     struct ggml_tensor  * b,\n@@ -7688,17 +7688,21 @@ struct ggml_tensor * ggml_conv_2d(\n         is_node = true;\n     }\n \n+    const int64_t OH = ggml_calc_conv_output_size(b->ne[1], a->ne[1], s1, p1, d1);\n+    const int64_t OW = ggml_calc_conv_output_size(b->ne[0], a->ne[0], s0, p0, d0);\n+\n     const int64_t ne[4] = {\n-        ggml_calc_conv_output_size(b->ne[0], a->ne[0], s0, p0, d0),\n-        ggml_calc_conv_output_size(b->ne[1], a->ne[1], s1, p1, d1),\n-        a->ne[3], b->ne[3],\n+        a->ne[2] * a->ne[1] * a->ne[0],\n+        OW,\n+        OH,\n+        b->ne[3],\n     };\n-    struct ggml_tensor * result = ggml_new_tensor(ctx, GGML_TYPE_F32, 4, ne);\n+    struct ggml_tensor * result = ggml_new_tensor(ctx, GGML_TYPE_F16, 4, ne);\n \n     int32_t params[] = { s0, s1, p0, p1, d0, d1 };\n     ggml_set_op_params(result, params, sizeof(params));\n \n-    result->op = GGML_OP_CONV_2D;\n+    result->op = GGML_OP_CONV_2D_STAGE_0;\n     result->grad = is_node ? ggml_dup_tensor(ctx, result) : NULL;\n     result->src[0] = a;\n     result->src[1] = b;\n@@ -7707,8 +7711,61 @@ struct ggml_tensor * ggml_conv_2d(\n \n }\n \n-// ggml_conv_2d_sk_p0\n+// gemm: [N, OC, OH, OW] = [OC, IC * KH * KW] x [N*OH*OW, IC * KH * KW]\n+// a: [OC, IC, KH, KW]\n+// b: [N, OH, OW, IC * KH * KW]\n+// result: [N, OC, OH, OW]\n+static struct ggml_tensor * ggml_conv_2d_stage_1(\n+    struct ggml_context * ctx,\n+    struct ggml_tensor  * a,\n+    struct ggml_tensor  * b) {\n+\n+    bool is_node = false;\n+\n+    if (a->grad || b->grad) {\n+        GGML_ASSERT(false); // TODO: implement backward\n+        is_node = true;\n+    }\n+\n+    const int64_t ne[4] = {\n+        b->ne[1],\n+        b->ne[2],\n+        a->ne[3],\n+        b->ne[3],\n+    };\n+    struct ggml_tensor * result = ggml_new_tensor(ctx, GGML_TYPE_F32, 4, ne);\n+\n+    result->op = GGML_OP_CONV_2D_STAGE_1;\n+    result->grad = is_node ? ggml_dup_tensor(ctx, result) : NULL;\n+    result->src[0] = a;\n+    result->src[1] = b;\n+\n+    return result;\n+\n+}\n+\n+// a: [OC\uff0cIC, KH, KW]\n+// b: [N, IC, IH, IW]\n+// result: [N, OC, OH, OW]\n+struct ggml_tensor * ggml_conv_2d(\n+    struct ggml_context * ctx,\n+    struct ggml_tensor  * a,\n+    struct ggml_tensor  * b,\n+    int                  s0,\n+    int                  s1,\n+    int                  p0,\n+    int                  p1,\n+    int                  d0,\n+    int                  d1) {\n+\n+    struct ggml_tensor * result = ggml_conv_2d_stage_0(ctx, a, b, s0, s1, p0, p1, d0, d1); // [N, OH, OW, IC * KH * KW]\n+    result = ggml_conv_2d_stage_1(ctx, a, result);\n+\n+    return result;\n+\n+}\n \n+// ggml_conv_2d_sk_p0\n struct ggml_tensor * ggml_conv_2d_sk_p0(\n         struct ggml_context * ctx,\n         struct ggml_tensor  * a,\n@@ -8147,7 +8204,6 @@ static struct ggml_tensor * ggml_add_rel_pos_impl(\n     return result;\n }\n \n-\n struct ggml_tensor * ggml_add_rel_pos(\n         struct ggml_context * ctx,\n         struct ggml_tensor  * a,\n@@ -8592,8 +8648,6 @@ struct ggml_tensor * ggml_map_custom3_inplace(\n     return ggml_map_custom3_impl(ctx, a, b, c, fun, n_tasks, userdata, true);\n }\n \n-\n-\n // ggml_cross_entropy_loss\n \n struct ggml_tensor * ggml_cross_entropy_loss(\n@@ -9794,7 +9848,6 @@ static void ggml_compute_forward_add1(\n     }\n }\n \n-\n // ggml_compute_forward_acc\n \n static void ggml_compute_forward_acc_f32(\n@@ -9934,7 +9987,6 @@ static void ggml_compute_forward_sub_f32(\n             const int i2 = (ir - i3*ne2*ne1)/ne1;\n             const int i1 = (ir - i3*ne2*ne1 - i2*ne1);\n \n-\n #ifdef GGML_USE_ACCELERATE\n             vDSP_vsub(\n                     (float *) ((char *) src1->data + i3*nb13 + i2*nb12 + i1*nb11), 1,\n@@ -10115,7 +10167,6 @@ static void ggml_compute_forward_div_f32(\n             const int i2 = (ir - i3*ne2*ne1)/ne1;\n             const int i1 = (ir - i3*ne2*ne1 - i2*ne1);\n \n-\n #ifdef GGML_USE_ACCELERATE\n             UNUSED(ggml_vec_div_f32);\n \n@@ -10253,7 +10304,6 @@ static void ggml_compute_forward_sqrt(\n     }\n }\n \n-\n // ggml_compute_forward_log\n \n static void ggml_compute_forward_log_f32(\n@@ -12086,7 +12136,6 @@ static void ggml_compute_forward_out_prod_f32(\n         }\n     }\n \n-\n     //int64_t t1 = ggml_perf_time_us();\n     //static int64_t acc = 0;\n     //acc += t1 - t0;\n@@ -12282,7 +12331,6 @@ static void ggml_compute_forward_scale_f32(\n \n     const size_t nb1 = dst->nb[1];\n \n-\n     for (int i1 = ir0; i1 < ir1; i1++) {\n         if (dst->data != src0->data) {\n             // src0 is same shape as dst => same indices\n@@ -12680,7 +12728,6 @@ static void ggml_compute_forward_get_rows_back_f32(\n     }\n }\n \n-\n static void ggml_compute_forward_get_rows_back(\n         const struct ggml_compute_params * params,\n         const struct ggml_tensor * src0,\n@@ -13966,6 +14013,7 @@ static void ggml_compute_forward_conv_1d_f32(\n     }\n }\n \n+// TODO: reuse ggml_mul_mat or implement ggml_im2col and remove stage_0 and stage_1\n static void gemm_f16_out_f32(int64_t m, int64_t n, int64_t k,\n                              ggml_fp16_t * A,\n                              ggml_fp16_t * B,\n@@ -14419,6 +14467,144 @@ static void ggml_compute_forward_conv_transpose_1d(\n \n // ggml_compute_forward_conv_2d\n \n+// src0: kernel [OC, IC, KH, KW]\n+// src1: image [N, IC, IH, IW]\n+// dst:  result [N, OH, OW, IC*KH*KW]\n+static void ggml_compute_forward_conv_2d_stage_0_f32(\n+        const struct ggml_compute_params * params,\n+        const struct ggml_tensor * src0,\n+        const struct ggml_tensor * src1,\n+              struct ggml_tensor * dst) {\n+    GGML_ASSERT(src0->type == GGML_TYPE_F16);\n+    GGML_ASSERT(src1->type == GGML_TYPE_F32);\n+    GGML_ASSERT( dst->type == GGML_TYPE_F16);\n+\n+    int64_t t0 = ggml_perf_time_us();\n+    UNUSED(t0);\n+\n+    GGML_TENSOR_BINARY_OP_LOCALS;\n+\n+    const int64_t N = ne13;\n+    const int64_t IC = ne12;\n+    const int64_t IH = ne11;\n+    const int64_t IW = ne10;\n+\n+    // const int64_t OC = ne03;\n+    // const int64_t IC = ne02;\n+    const int64_t KH = ne01;\n+    const int64_t KW = ne00;\n+\n+    const int64_t OH = ne2;\n+    const int64_t OW = ne1;\n+\n+    const int ith = params->ith;\n+    const int nth = params->nth;\n+\n+    const int32_t s0 = ((const int32_t*)(dst->op_params))[0];\n+    const int32_t s1 = ((const int32_t*)(dst->op_params))[1];\n+    const int32_t p0 = ((const int32_t*)(dst->op_params))[2];\n+    const int32_t p1 = ((const int32_t*)(dst->op_params))[3];\n+    const int32_t d0 = ((const int32_t*)(dst->op_params))[4];\n+    const int32_t d1 = ((const int32_t*)(dst->op_params))[5];\n+\n+    GGML_ASSERT(nb00 == sizeof(ggml_fp16_t));\n+    GGML_ASSERT(nb10 == sizeof(float));\n+\n+    if (params->type == GGML_TASK_INIT) {\n+        memset(dst->data, 0, ggml_nbytes(dst));\n+        return;\n+    }\n+\n+    if (params->type == GGML_TASK_FINALIZE) {\n+        return;\n+    }\n+\n+    // im2col: [N, IC, IH, IW] => [N, OH, OW, IC*KH*KW]\n+    {\n+        ggml_fp16_t * const wdata = (ggml_fp16_t *) dst->data;\n+\n+        for (int64_t in = 0; in < N; in++) {\n+            for (int64_t ioh = 0; ioh < OH; ioh++) {\n+                for (int64_t iow = 0; iow < OW; iow++) {\n+                    for (int64_t iic = ith; iic < IC; iic+=nth) {\n+\n+                        // micro kernel\n+                        ggml_fp16_t * dst_data = wdata + (in*OH*OW + ioh*OW + iow)*(IC*KH*KW); // [IC, KH, KW]\n+                        const float * const src_data = (float *)((char *) src1->data + in*nb13 + iic*nb12); // [IH, IW]\n+\n+                        for (int64_t ikh = 0; ikh < KH; ikh++) {\n+                            for (int64_t ikw = 0; ikw < KW; ikw++) {\n+                                const int64_t iiw = iow*s0 + ikw*d0 - p0;\n+                                const int64_t iih = ioh*s1 + ikh*d1 - p1;\n+\n+                                if (!(iih < 0 || iih >= IH || iiw < 0 || iiw >= IW)) {\n+                                    dst_data[iic*(KH*KW) + ikh*KW + ikw] = GGML_FP32_TO_FP16(src_data[iih*IW + iiw]);\n+                                }\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+// gemm: [N, OC, OH, OW] = [OC, IC * KH * KW] x [N*OH*OW, IC * KH * KW]\n+// src0: [OC, IC, KH, KW]\n+// src1: [N, OH, OW, IC * KH * KW]\n+// result: [N, OC, OH, OW]\n+static void ggml_compute_forward_conv_2d_stage_1_f16(\n+        const struct ggml_compute_params * params,\n+        const struct ggml_tensor * src0,\n+        const struct ggml_tensor * src1,\n+              struct ggml_tensor * dst) {\n+    GGML_ASSERT(src0->type == GGML_TYPE_F16);\n+    GGML_ASSERT(src1->type == GGML_TYPE_F16);\n+    GGML_ASSERT( dst->type == GGML_TYPE_F32);\n+\n+    int64_t t0 = ggml_perf_time_us();\n+    UNUSED(t0);\n+\n+    if (params->type == GGML_TASK_INIT) {\n+        return;\n+    }\n+\n+    if (params->type == GGML_TASK_FINALIZE) {\n+        return;\n+    }\n+\n+    GGML_TENSOR_BINARY_OP_LOCALS;\n+\n+    GGML_ASSERT(nb00 == sizeof(ggml_fp16_t));\n+    GGML_ASSERT(nb10 == sizeof(ggml_fp16_t));\n+    GGML_ASSERT(nb0  == sizeof(float));\n+\n+    const int N = ne13;\n+    const int OH = ne12;\n+    const int OW = ne11;\n+\n+    const int OC = ne03;\n+    const int IC = ne02;\n+    const int KH = ne01;\n+    const int KW = ne00;\n+\n+    const int ith = params->ith;\n+    const int nth = params->nth;\n+\n+    int64_t m = OC;\n+    int64_t n = OH * OW;\n+    int64_t k = IC * KH * KW;\n+\n+    // [N, OC, OH, OW] = [OC, IC * KH * KW] x [N*OH*OW, IC * KH * KW]\n+    for (int i = 0; i < N; i++) {\n+        ggml_fp16_t * A = (ggml_fp16_t *)src0->data; // [m, k]\n+        ggml_fp16_t * B = (ggml_fp16_t *)src1->data + i * m * k; // [n, k]\n+        float * C = (float *)dst->data + i * m * n; // [m, n]\n+\n+        gemm_f16_out_f32(m, n, k, A, B, C, ith, nth);\n+    }\n+}\n+\n static void ggml_compute_forward_conv_2d_f16_f32(\n         const struct ggml_compute_params * params,\n         const struct ggml_tensor * src0,\n@@ -14433,14 +14619,38 @@ static void ggml_compute_forward_conv_2d_f16_f32(\n \n     GGML_TENSOR_BINARY_OP_LOCALS\n \n+    // src1: image [N, IC, IH, IW]\n+    // src0: kernel [OC, IC, KH, KW]\n+    // dst:  result [N, OC, OH, OW]\n+    // ne12: IC\n+    // ne0: OW\n+    // ne1: OH\n+    // nk0: KW\n+    // nk1: KH\n+    // ne13: N\n+\n+    const int N = ne13;\n+    const int IC = ne12;\n+    const int IH = ne11;\n+    const int IW = ne10;\n+\n+    const int OC = ne03;\n+    // const int IC = ne02;\n+    const int KH = ne01;\n+    const int KW = ne00;\n+\n+    const int OH = ne1;\n+    const int OW = ne0;\n+\n     const int ith = params->ith;\n     const int nth = params->nth;\n \n-    const int nk0 = ne00;\n-    const int nk1 = ne01;\n+    // const int nk0 = ne00;\n+    // const int nk1 = ne01;\n \n     // size of the convolution row - the kernel size unrolled across all channels\n-    const int ew0 = nk0*nk1*ne02;\n+    // const int ew0 = nk0*nk1*ne02;\n+    // ew0: IC*KH*KW\n \n     const int32_t s0 = ((const int32_t*)(dst->op_params))[0];\n     const int32_t s1 = ((const int32_t*)(dst->op_params))[1];\n@@ -14456,24 +14666,27 @@ static void ggml_compute_forward_conv_2d_f16_f32(\n         memset(params->wdata, 0, params->wsize);\n \n         // prepare source data (src1)\n+        // im2col: [N, IC, IH, IW] => [N*OH*OW, IC*KH*KW]\n+\n         {\n             ggml_fp16_t * const wdata = (ggml_fp16_t *) params->wdata + 0;\n \n-            for (int i13 = 0; i13 < ne13; i13++) {\n-                for (int i12 = 0; i12 < ne12; i12++) {\n-                    const float * const src = (float *)((char *) src1->data + i13*nb13 + i12*nb12);\n-                    ggml_fp16_t * dst_data = wdata + i13*(ne1*ne0*ew0);\n-\n-                    for (int i1 = 0; i1 < ne1; i1++) {\n-                        for (int i0 = 0; i0 < ne0; i0++) {\n-                            for (int ik1 = 0; ik1 < nk1; ik1++) {\n-                                for (int ik0 = 0; ik0 < nk0; ik0++) {\n-                                    const int idx0 = i0*s0 + ik0*d0 - p0;\n-                                    const int idx1 = i1*s1 + ik1*d1 - p1;\n-\n-                                    if (!(idx1 < 0 || idx1 >= ne11 || idx0 < 0 || idx0 >= ne10)) {\n-                                        dst_data[(i1*ne0 + i0)*ew0 + i12*(nk0*nk1) + ik1*nk0 + ik0] =\n-                                            GGML_FP32_TO_FP16(src[idx1*ne10 + idx0]);\n+            for (int in = 0; in < N; in++) {\n+                for (int iic = 0; iic < IC; iic++) {\n+                    for (int ioh = 0; ioh < OH; ioh++) {\n+                        for (int iow = 0; iow < OW; iow++) {\n+\n+                            // micro kernel\n+                            ggml_fp16_t * dst_data = wdata + (in*OH*OW + ioh*OW + iow)*(IC*KH*KW); // [IC, KH, KW]\n+                            const float * const src_data = (float *)((char *) src1->data + in*nb13 + iic*nb12); // [IH, IW]\n+\n+                            for (int ikh = 0; ikh < KH; ikh++) {\n+                                for (int ikw = 0; ikw < KW; ikw++) {\n+                                    const int iiw = iow*s0 + ikw*d0 - p0;\n+                                    const int iih = ioh*s1 + ikh*d1 - p1;\n+\n+                                    if (!(iih < 0 || iih >= IH || iiw < 0 || iiw >= IW)) {\n+                                        dst_data[iic*(KH*KW) + ikh*KW + ikw] = GGML_FP32_TO_FP16(src_data[iih*IW + iiw]);\n                                     }\n                                 }\n                             }\n@@ -14490,30 +14703,22 @@ static void ggml_compute_forward_conv_2d_f16_f32(\n         return;\n     }\n \n-    // total patches in dst\n-    const int np = ne2;\n-\n-    // patches per thread\n-    const int dp = (np + nth - 1)/nth;\n+    ggml_fp16_t * const wdata = (ggml_fp16_t *) params->wdata + 0;\n+    // wdata: [N*OH*OW, IC*KH*KW]\n+    // dst: result [N, OC, OH, OW]\n+    // src0: kernel [OC, IC, KH, KW]\n \n-    // patch range for this thread\n-    const int ip0 = dp*ith;\n-    const int ip1 = MIN(ip0 + dp, np);\n+    int64_t m = OC;\n+    int64_t n = OH * OW;\n+    int64_t k = IC * KH * KW;\n \n-    ggml_fp16_t * const wdata = (ggml_fp16_t *) params->wdata + 0;\n+    // [N, OC, OH, OW] = [OC, IC * KH * KW] x [N*OH*OW, IC * KH * KW]\n+    for (int i = 0; i < N; i++) {\n+        ggml_fp16_t * A = (ggml_fp16_t *)src0->data; // [m, k]\n+        ggml_fp16_t * B = (ggml_fp16_t *)wdata + i * m * k; // [n, k]\n+        float * C = (float *)dst->data + i * m * n; // [m * k]\n \n-    for (int i3 = 0; i3 < ne3; i3++) {\n-        for (int i2 = ip0; i2 < ip1; i2++) {\n-            float * dst_data = (float *)((char *) dst->data + i3*nb3 + i2*nb2);\n-\n-            for (int i1 = 0; i1 < ne1; ++i1) {\n-                for (int i0 = 0; i0 < ne0; ++i0) {\n-                    ggml_vec_dot_f16(ew0, dst_data + i1*ne0 + i0,\n-                            (ggml_fp16_t *) ((char *) src0->data + i2*nb03),\n-                            (ggml_fp16_t *)                wdata + i3*nb3 + (i1*ne0 + i0)*ew0);\n-                }\n-            }\n-        }\n+        gemm_f16_out_f32(m, n, k, A, B, C, ith, nth);\n     }\n }\n \n@@ -14539,6 +14744,48 @@ static void ggml_compute_forward_conv_2d(\n     }\n }\n \n+static void ggml_compute_forward_conv_2d_stage_0(\n+        const struct ggml_compute_params * params,\n+        const struct ggml_tensor * src0,\n+        const struct ggml_tensor * src1,\n+              struct ggml_tensor * dst) {\n+    switch (src0->type) {\n+        case GGML_TYPE_F16:\n+            {\n+                ggml_compute_forward_conv_2d_stage_0_f32(params, src0, src1, dst);\n+            } break;\n+        case GGML_TYPE_F32:\n+            {\n+                GGML_ASSERT(false);\n+            } break;\n+        default:\n+            {\n+                GGML_ASSERT(false);\n+            } break;\n+    }\n+}\n+\n+static void ggml_compute_forward_conv_2d_stage_1(\n+        const struct ggml_compute_params * params,\n+        const struct ggml_tensor * src0,\n+        const struct ggml_tensor * src1,\n+              struct ggml_tensor * dst) {\n+    switch (src0->type) {\n+        case GGML_TYPE_F16:\n+            {\n+                ggml_compute_forward_conv_2d_stage_1_f16(params, src0, src1, dst);\n+            } break;\n+        case GGML_TYPE_F32:\n+            {\n+                GGML_ASSERT(false);\n+            } break;\n+        default:\n+            {\n+                GGML_ASSERT(false);\n+            } break;\n+    }\n+}\n+\n // ggml_compute_forward_conv_transpose_2d\n \n static void ggml_compute_forward_conv_transpose_2d(\n@@ -16095,7 +16342,6 @@ static void ggml_compute_forward_add_rel_pos_f32(\n     const int ip0 = dp*ith;\n     const int ip1 = MIN(ip0 + dp, np);\n \n-\n     for (int64_t i13 = ip0; i13 < ip1; ++i13) {\n         for (int64_t i12 = 0; i12 < ne12; ++i12) {\n             for (int64_t i11 = 0; i11 < ne11; ++i11) {\n@@ -16162,7 +16408,6 @@ static void ggml_compute_forward_map_unary_f32(\n     }\n }\n \n-\n static void ggml_compute_forward_map_unary(\n         const struct ggml_compute_params * params,\n         const struct ggml_tensor * src0,\n@@ -16210,7 +16455,6 @@ static void ggml_compute_forward_map_binary_f32(\n     }\n }\n \n-\n static void ggml_compute_forward_map_binary(\n         const struct ggml_compute_params * params,\n         const struct ggml_tensor * src0,\n@@ -16262,7 +16506,6 @@ static void ggml_compute_forward_map_custom2_f32(\n     fun(dst, a, b);\n }\n \n-\n // ggml_compute_forward_map_custom3\n \n static void ggml_compute_forward_map_custom3_f32(\n@@ -16537,7 +16780,6 @@ static void ggml_compute_forward_cross_entropy_loss_back_f32(\n         ggml_vec_sub_f32(nc, ds0, ds0, s1);\n         ggml_vec_scale_f32(nc, ds0, d[0] / (float) nr);\n \n-\n #ifndef NDEBUG\n         for (int i = 0; i < nc; ++i) {\n             assert(!isnan(ds0[i]));\n@@ -16565,7 +16807,6 @@ static void ggml_compute_forward_cross_entropy_loss_back(\n     }\n }\n \n-\n /////////////////////////////////\n \n static void ggml_compute_forward(struct ggml_compute_params * params, struct ggml_tensor * tensor) {\n@@ -16773,6 +17014,14 @@ static void ggml_compute_forward(struct ggml_compute_params * params, struct ggm\n             {\n                 ggml_compute_forward_conv_2d(params, tensor->src[0], tensor->src[1], tensor);\n             } break;\n+        case GGML_OP_CONV_2D_STAGE_0:\n+            {\n+                ggml_compute_forward_conv_2d_stage_0(params, tensor->src[0], tensor->src[1], tensor);\n+            } break;\n+        case GGML_OP_CONV_2D_STAGE_1:\n+            {\n+                ggml_compute_forward_conv_2d_stage_1(params, tensor->src[0], tensor->src[1], tensor);\n+            } break;\n         case GGML_OP_CONV_TRANSPOSE_2D:\n             {\n                 ggml_compute_forward_conv_transpose_2d(params, tensor->src[0], tensor->src[1], tensor);\n@@ -17702,11 +17951,19 @@ static void ggml_compute_backward(struct ggml_context * ctx, struct ggml_tensor\n             {\n                 GGML_ASSERT(false); // TODO: not implemented\n             } break;\n+        case GGML_OP_CONV_TRANSPOSE_1D:\n+            {\n+                GGML_ASSERT(false); // TODO: not implemented\n+            } break;\n         case GGML_OP_CONV_2D:\n             {\n                 GGML_ASSERT(false); // TODO: not implemented\n             } break;\n-        case GGML_OP_CONV_TRANSPOSE_1D:\n+        case GGML_OP_CONV_2D_STAGE_0:\n+            {\n+                GGML_ASSERT(false); // TODO: not implemented\n+            } break;\n+        case GGML_OP_CONV_2D_STAGE_1:\n             {\n                 GGML_ASSERT(false); // TODO: not implemented\n             } break;\n@@ -18635,6 +18892,7 @@ struct ggml_cplan ggml_graph_plan(struct ggml_cgraph * cgraph, int n_threads) {\n                     const int64_t ne0 = node->ne[0];\n                     const int64_t ne1 = node->ne[1];\n                     const int64_t ne2 = node->ne[2];\n+                    const int64_t ne3 = node->ne[3];\n                     const int64_t nk = ne00*ne01;\n                     const int64_t ew0 = nk * ne02;\n \n@@ -18645,7 +18903,8 @@ struct ggml_cplan ggml_graph_plan(struct ggml_cgraph * cgraph, int n_threads) {\n \n                     if (node->src[0]->type == GGML_TYPE_F16 &&\n                         node->src[1]->type == GGML_TYPE_F32) {\n-                        cur = sizeof(ggml_fp16_t)*(ne0*ne1*ew0);\n+                        // im2col: [N*OH*OW, IC*KH*KW]\n+                        cur = sizeof(ggml_fp16_t)*(ne3*ne0*ne1*ew0);\n                     } else if (node->src[0]->type == GGML_TYPE_F32 &&\n                                node->src[1]->type == GGML_TYPE_F32) {\n                         cur = sizeof(float)*      (ne10*ne11*ne12);\n@@ -18655,6 +18914,14 @@ struct ggml_cplan ggml_graph_plan(struct ggml_cgraph * cgraph, int n_threads) {\n \n                     work_size = MAX(work_size, cur);\n                 } break;\n+            case GGML_OP_CONV_2D_STAGE_0:\n+                {\n+                    n_tasks = n_threads;\n+                } break;\n+            case GGML_OP_CONV_2D_STAGE_1:\n+                {\n+                    n_tasks = n_threads;\n+                } break;\n             case GGML_OP_CONV_TRANSPOSE_2D:\n                 {\n                     n_tasks = n_threads;\n@@ -19842,7 +20109,6 @@ static enum ggml_opt_result ggml_opt_adam(\n \n         opt->loss_after = fx;\n \n-\n         // check convergence\n         if (fabsf(fx - fx_prev[0])/fx < params.adam.eps_f) {\n             GGML_PRINT_DEBUG(\"converged\\n\");\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Concurrency Issue**: There's a race condition with the shared `params` variable in OpenMP threads. Clone `params` for each thread to resolve this.\n\n2. **F16 Usage**: The `ggml_compute_forward_mul_mat()` function does not support `src1` being F16; it must be F32. Ensure compatibility for a smoother operation.\n\n3. **2-Step Process**: Evaluate if the two-stage convolution is necessary after making the INIT step multi-threaded. Consider refactoring to consolidate stages for potential performance gains.\n\n4. **Memory Efficiency**: The current matrix multiplication approach wastes memory. Investigate alternatives, such as splitting inputs into tiles to reduce memory usage.\n\n5. **Testing**: Verify that the branch works for all relevant use cases, especially in `ggml_conv_2d`, and confirm no existing functionality is broken. Prioritize tests on various convolution specs."
      }
    ],
    "codediff_length": 26611
  },
  {
    "index": 111,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/include/ggml/ggml.h b/include/ggml/ggml.h\nindex 4b16032f0..79cba14ce 100644\n--- a/include/ggml/ggml.h\n+++ b/include/ggml/ggml.h\n@@ -499,6 +499,11 @@ extern \"C\" {\n         int32_t op_params[GGML_MAX_OP_PARAMS / sizeof(int32_t)];\n \n         bool is_param;\n+        bool not_own_data;\n+        bool dynamic;\n+        bool dynamic_hold;\n+        int  n_dst;\n+        int  n_dst_curr;\n \n         struct ggml_tensor * grad;\n         struct ggml_tensor * src[GGML_MAX_SRC];\n@@ -517,7 +522,7 @@ extern \"C\" {\n \n         void * extra; // extra things e.g. for ggml-cuda.cu\n \n-        char padding[12];\n+        char padding[4];\n     };\n \n     static const size_t GGML_TENSOR_SIZE = sizeof(struct ggml_tensor);\n@@ -584,6 +589,7 @@ extern \"C\" {\n         size_t mem_size;   // bytes\n         void * mem_buffer; // if NULL, memory will be allocated internally\n         bool   no_alloc;   // don't allocate memory for the tensor data\n+        bool   dynamic;    // allocate memory for the tensor data dynamically\n     };\n \n \n@@ -658,11 +664,23 @@ extern \"C\" {\n     GGML_API void                  ggml_free(struct ggml_context * ctx);\n \n     GGML_API size_t  ggml_used_mem(const struct ggml_context * ctx);\n+    GGML_API size_t  ggml_used_mem_of_data(const struct ggml_context* ctx);\n \n     GGML_API size_t  ggml_set_scratch (struct ggml_context * ctx, struct ggml_scratch scratch);\n     GGML_API bool    ggml_get_no_alloc(struct ggml_context * ctx);\n     GGML_API void    ggml_set_no_alloc(struct ggml_context * ctx, bool no_alloc);\n \n+    GGML_API void    ggml_set_dynamic(struct ggml_context * ctx, bool dynamic);\n+    GGML_API bool    ggml_get_dynamic(struct ggml_context* ctx);\n+\n+    GGML_API void    ggml_hold_dynamic_tensor(struct ggml_tensor * tensor);\n+    GGML_API void    ggml_free_dynamic_tensor(struct ggml_tensor * tensor);\n+    GGML_API size_t  ggml_dynamic_size(void);\n+    GGML_API size_t  ggml_max_dynamic_size(void);\n+    GGML_API size_t  ggml_curr_max_dynamic_size(void);\n+    GGML_API void    ggml_reset_curr_max_dynamic_size(void);\n+\n+\n     GGML_API void *  ggml_get_mem_buffer     (const struct ggml_context * ctx);\n     GGML_API size_t  ggml_get_mem_size       (const struct ggml_context * ctx);\n     GGML_API size_t  ggml_get_max_tensor_size(const struct ggml_context * ctx);\ndiff --git a/src/ggml.c b/src/ggml.c\nindex 2d3c7b801..8cb6ae27e 100644\n--- a/src/ggml.c\n+++ b/src/ggml.c\n@@ -213,6 +213,51 @@ inline static void * ggml_aligned_malloc(size_t size) {\n #endif\n #endif\n \n+\n+size_t dynamic_mem_size = 0;\n+size_t max_dynamic_mem_size = 0;\n+\n+size_t curr_max_dynamic_mem_size = 0;\n+\n+inline static void* ggml_dynamic_malloc(size_t size) {\n+    void *ptr = GGML_ALIGNED_MALLOC(GGML_MEM_ALIGN + size);\n+    dynamic_mem_size += size;\n+    if (dynamic_mem_size > max_dynamic_mem_size) {\n+        max_dynamic_mem_size = dynamic_mem_size;\n+    }\n+    if (dynamic_mem_size > curr_max_dynamic_mem_size) {\n+        curr_max_dynamic_mem_size = dynamic_mem_size;\n+    }\n+    *((size_t*)ptr) = size;\n+    return (char*)ptr + GGML_MEM_ALIGN;\n+}\n+\n+inline static void ggml_dynamic_free(void * ptr) {\n+    void* realptr = (char*)ptr-GGML_MEM_ALIGN;\n+    size_t size = *((size_t*)realptr);\n+    dynamic_mem_size -= size;\n+    GGML_ALIGNED_FREE(realptr);\n+}\n+\n+size_t  ggml_dynamic_size(void) {\n+    return dynamic_mem_size;\n+}\n+\n+size_t  ggml_max_dynamic_size(void) {\n+    return max_dynamic_mem_size;\n+}\n+\n+size_t  ggml_curr_max_dynamic_size(void) {\n+    return curr_max_dynamic_mem_size;\n+}\n+\n+void  ggml_reset_curr_max_dynamic_size(void) {\n+    curr_max_dynamic_mem_size = dynamic_mem_size;\n+}\n+\n+#define GGML_DYNAMIC_MALLOC(size)  ggml_dynamic_malloc(size)\n+#define GGML_DYNAMIC_FREE(ptr)     ggml_dynamic_free(ptr)\n+\n #define UNUSED GGML_UNUSED\n #define SWAP(x, y, T) do { T SWAP = x; x = y; y = SWAP; } while (0)\n \n@@ -4237,6 +4282,9 @@ struct ggml_context {\n     bool   no_alloc;\n     bool   no_alloc_save; // this is used to save the no_alloc state when using scratch buffers\n \n+    bool   dynamic;\n+    bool   dynamic_save;\n+\n     int    n_objects;\n \n     struct ggml_object * objects_begin;\n@@ -4707,6 +4755,8 @@ struct ggml_context * ggml_init(struct ggml_init_params params) {\n         /*.mem_buffer_owned   =*/ params.mem_buffer ? false : true,\n         /*.no_alloc           =*/ params.no_alloc,\n         /*.no_alloc_save      =*/ params.no_alloc,\n+        /*.dynamic            =*/ params.dynamic,\n+        /*.dynamic_save       =*/ params.dynamic,\n         /*.n_objects          =*/ 0,\n         /*.objects_begin      =*/ NULL,\n         /*.objects_end        =*/ NULL,\n@@ -4729,6 +4779,27 @@ void ggml_free(struct ggml_context * ctx) {\n     // make this function thread safe\n     ggml_critical_section_start();\n \n+    struct ggml_object* obj = ctx->objects_begin;\n+\n+    while (obj != NULL) {\n+        if (obj->type != GGML_OBJECT_TENSOR) {\n+            obj = obj->next;\n+            continue;\n+        }\n+        struct ggml_tensor* tensor = (struct ggml_tensor*)((char*)ctx->mem_buffer + obj->offs);\n+        if (tensor->not_own_data) {\n+            obj = obj->next;\n+            continue;\n+        }\n+\n+        if (tensor->dynamic && tensor->data != NULL) {\n+            GGML_DYNAMIC_FREE(tensor->data);\n+            tensor->data = NULL;\n+        }\n+\n+        obj = obj->next;\n+    }\n+\n     bool found = false;\n \n     for (int i = 0; i < GGML_MAX_CONTEXTS; i++) {\n@@ -4758,6 +4829,32 @@ size_t ggml_used_mem(const struct ggml_context * ctx) {\n     return ctx->objects_end == NULL ? 0 : ctx->objects_end->offs + ctx->objects_end->size;\n }\n \n+GGML_API size_t ggml_used_mem_of_data(const struct ggml_context* ctx) {\n+    size_t mem_size = 0;\n+\n+    struct ggml_object* obj = ctx->objects_begin;\n+\n+    while (obj != NULL) {\n+        if (obj->type != GGML_OBJECT_TENSOR) {\n+            obj = obj->next;\n+            continue;\n+        }\n+        struct ggml_tensor* tensor = (struct ggml_tensor*)((char*)ctx->mem_buffer + obj->offs);\n+        if (tensor->not_own_data || tensor->dynamic) {\n+            obj = obj->next;\n+            continue;\n+        }\n+\n+        const size_t size = ggml_nbytes(tensor);\n+\n+        mem_size += size;\n+\n+        obj = obj->next;\n+    }\n+\n+    return mem_size;\n+}\n+\n size_t ggml_set_scratch(struct ggml_context * ctx, struct ggml_scratch scratch) {\n     const size_t result = ctx->scratch.data ? ctx->scratch.offs : 0;\n \n@@ -4774,6 +4871,23 @@ void ggml_set_no_alloc(struct ggml_context * ctx, bool no_alloc) {\n     ctx->no_alloc = no_alloc;\n }\n \n+void ggml_set_dynamic(struct ggml_context * ctx, bool dynamic) {\n+    ctx->dynamic = dynamic;\n+}\n+\n+bool ggml_get_dynamic(struct ggml_context* ctx) {\n+    return ctx->dynamic;\n+}\n+\n+void ggml_hold_dynamic_tensor(struct ggml_tensor * tensor) {\n+    tensor->dynamic_hold = true;\n+}\n+\n+void ggml_free_dynamic_tensor(struct ggml_tensor * tensor) {\n+    GGML_DYNAMIC_FREE(tensor->data);\n+    tensor->dynamic_hold = false;\n+}\n+\n void * ggml_get_mem_buffer(const struct ggml_context * ctx) {\n     return ctx->mem_buffer;\n }\n@@ -4815,6 +4929,9 @@ static void ggml_scratch_save(struct ggml_context * ctx) {\n     ctx->no_alloc_save = ctx->no_alloc;\n     ctx->no_alloc      = false;\n \n+    ctx->dynamic_save  = ctx->dynamic;\n+    ctx->dynamic       = false;\n+\n     ctx->scratch_save = ctx->scratch;\n     ctx->scratch.data = NULL;\n }\n@@ -4822,6 +4939,8 @@ static void ggml_scratch_save(struct ggml_context * ctx) {\n static void ggml_scratch_load(struct ggml_context * ctx) {\n     ctx->no_alloc = ctx->no_alloc_save;\n \n+    ctx->dynamic  = ctx->dynamic_save;\n+\n     ctx->scratch = ctx->scratch_save;\n }\n \n@@ -4901,7 +5020,7 @@ static struct ggml_tensor * ggml_new_tensor_impl(\n \n     size_t obj_alloc_size = 0;\n \n-    if (view_src == NULL && !ctx->no_alloc) {\n+    if (view_src == NULL && !ctx->no_alloc && !ctx->dynamic) {\n         if (ctx->scratch.data != NULL) {\n             // allocate tensor data in the scratch buffer\n             if (ctx->scratch.offs + data_size > ctx->scratch.size) {\n@@ -4936,6 +5055,11 @@ static struct ggml_tensor * ggml_new_tensor_impl(\n         /*.op           =*/ GGML_OP_NONE,\n         /*.op_params    =*/ { 0 },\n         /*.is_param     =*/ false,\n+        /*.not_own_data =*/ false,\n+        /*.dynamic      =*/ ctx->dynamic,\n+        /*.dinamic_hold =*/ false,\n+        /*.n_dst        =*/ 0,\n+        /*.n_dst_curr   =*/ 0,\n         /*.grad         =*/ NULL,\n         /*.src          =*/ { NULL },\n         /*.perf_runs    =*/ 0,\n@@ -4943,7 +5067,7 @@ static struct ggml_tensor * ggml_new_tensor_impl(\n         /*.perf_time_us =*/ 0,\n         /*.view_src     =*/ view_src,\n         /*.view_offs    =*/ view_offs,\n-        /*.data         =*/ obj_alloc_size > 0 ? (void *)(result + 1) : data,\n+        /*.data         =*/ (obj_alloc_size > 0 && !ctx->no_alloc && !ctx->dynamic) ? (void *)(result + 1) : data,\n         /*.name         =*/ { 0 },\n         /*.extra        =*/ NULL,\n         /*.padding      =*/ { 0 },\n@@ -5493,6 +5617,8 @@ struct ggml_tensor * ggml_view_tensor(\n         result->nb[i] = src->nb[i];\n     }\n \n+    result->not_own_data = true;\n+\n     return result;\n }\n \n@@ -6757,6 +6883,7 @@ struct ggml_tensor * ggml_reshape(\n     ggml_format_name(result, \"%s (reshaped)\", a->name);\n \n     result->op   = GGML_OP_RESHAPE;\n+    result->not_own_data = true;\n     result->grad = is_node ? ggml_dup_tensor(ctx, result) : NULL;\n     result->src[0] = a;\n \n@@ -6781,6 +6908,7 @@ struct ggml_tensor * ggml_reshape_1d(\n     ggml_format_name(result, \"%s (reshaped)\", a->name);\n \n     result->op   = GGML_OP_RESHAPE;\n+    result->not_own_data = true;\n     result->grad = is_node ? ggml_dup_tensor(ctx, result) : NULL;\n     result->src[0] = a;\n \n@@ -6806,6 +6934,7 @@ struct ggml_tensor * ggml_reshape_2d(\n     ggml_format_name(result, \"%s (reshaped)\", a->name);\n \n     result->op   = GGML_OP_RESHAPE;\n+    result->not_own_data = true;\n     result->grad = is_node ? ggml_dup_tensor(ctx, result) : NULL;\n     result->src[0] = a;\n \n@@ -6832,6 +6961,7 @@ struct ggml_tensor * ggml_reshape_3d(\n     ggml_format_name(result, \"%s (reshaped)\", a->name);\n \n     result->op   = GGML_OP_RESHAPE;\n+    result->not_own_data = true;\n     result->grad = is_node ? ggml_dup_tensor(ctx, result) : NULL;\n     result->src[0] = a;\n \n@@ -6859,6 +6989,7 @@ struct ggml_tensor * ggml_reshape_4d(\n     ggml_format_name(result, \"%s (reshaped)\", a->name);\n \n     result->op   = GGML_OP_RESHAPE;\n+    result->not_own_data = true;\n     result->grad = is_node ? ggml_dup_tensor(ctx, result) : NULL;\n     result->src[0] = a;\n \n@@ -6884,6 +7015,7 @@ static struct ggml_tensor * ggml_view_impl(\n     ggml_set_op_params(result, &offset, sizeof(offset));\n \n     result->op   = GGML_OP_VIEW;\n+    result->not_own_data = true;\n     result->grad = is_node ? ggml_dup_tensor(ctx, result) : NULL;\n     result->src[0] = a;\n \n@@ -18181,6 +18313,8 @@ static void ggml_visit_parents(struct ggml_cgraph * cgraph, struct ggml_tensor *\n         return;\n     }\n \n+    node->n_dst = 0;\n+\n     for (int i = 0; i < GGML_MAX_SRC; ++i) {\n         const int k =\n             (cgraph->order == GGML_CGRAPH_EVAL_ORDER_LEFT_TO_RIGHT) ? i :\n@@ -18188,6 +18322,7 @@ static void ggml_visit_parents(struct ggml_cgraph * cgraph, struct ggml_tensor *\n             /* unknown order, just fall back to using i*/ i;\n         if (node->src[k]) {\n             ggml_visit_parents(cgraph, node->src[k]);\n+            node->src[k]->n_dst++;\n         }\n     }\n \n@@ -18489,6 +18624,75 @@ static void ggml_graph_compute_perf_stats_node(struct ggml_tensor * node, const\n     node->perf_time_us += time_us_cur;\n }\n \n+\n+static void on_node_compute_start(struct ggml_tensor* node) {\n+    // printf(\"on_node_compute_start %s dynamic %d not_own_data %d hold %d\\n\",\n+    // GGML_OP_NAME[node->op], node->dynamic, node->not_own_data, node->dynamic_hold);\n+    if (node->dynamic) {\n+        if (node->not_own_data) {\n+            //GGML_ASSERT(node->data == NULL);\n+\n+            if (node->op == GGML_OP_VIEW) {\n+                size_t offset;\n+                memcpy(&offset, node->op_params, sizeof(offset));\n+                node->data = (void*)((char*)node->src[0]->data + offset);\n+            }\n+            else {\n+                node->data = node->src[0]->data;\n+            }\n+\n+        }\n+        else {\n+            if (node->data != NULL && node->dynamic_hold) {\n+                return;\n+            }\n+            GGML_ASSERT(node->data == NULL);\n+            node->data = GGML_DYNAMIC_MALLOC(ggml_nbytes(node));\n+        }\n+    }\n+    // printf(\"on_node_compute_start done %s dynamic %d not_own_data %d hold %d\\n\",\n+    // GGML_OP_NAME[node->op], node->dynamic, node->not_own_data, node->dynamic_hold);\n+}\n+\n+static void on_node_all_dst_compute_done(struct ggml_tensor* node) {\n+    if (node->not_own_data) {\n+        for (int i = 0; i < GGML_MAX_SRC; i++) {\n+            struct ggml_tensor* curr = node->src[i];\n+            if (curr) {\n+                GGML_ASSERT(curr->n_dst_curr > 0);\n+                curr->n_dst_curr--;\n+                if (curr->n_dst_curr == 0) {\n+                    on_node_all_dst_compute_done(curr);\n+                }\n+            }\n+        }\n+    }\n+    else {\n+        if (node->dynamic && !node->dynamic_hold) {\n+            GGML_DYNAMIC_FREE(node->data);\n+            node->data = NULL;\n+        }\n+    }\n+}\n+\n+static void on_node_compute_done(struct ggml_tensor* node) {\n+    // printf(\"on_node_compute_done %s dynamic %d not_own_data %d hold %d\\n\",\n+    // GGML_OP_NAME[node->op], node->dynamic, node->not_own_data, node->dynamic_hold);\n+    if (node->not_own_data) {\n+        return;\n+    }\n+    for (int i = 0; i < GGML_MAX_SRC; i++) {\n+        struct ggml_tensor* curr = node->src[i];\n+        if (curr) {\n+            GGML_ASSERT(curr->n_dst_curr > 0);\n+            curr->n_dst_curr--;\n+            if (curr->n_dst_curr == 0) {\n+                on_node_all_dst_compute_done(curr);\n+            }\n+        }\n+    }\n+}\n+\n static thread_ret_t ggml_graph_compute_thread(void * data) {\n     struct ggml_compute_state * state = (struct ggml_compute_state *) data;\n \n@@ -18526,6 +18730,8 @@ static thread_ret_t ggml_graph_compute_thread(void * data) {\n                     ggml_compute_forward(&params, node);\n                 }\n                 ggml_graph_compute_perf_stats_node(node, state->shared);\n+\n+                on_node_compute_done(node);\n             }\n \n             // distribute new work or execute it direct if 1T\n@@ -18541,6 +18747,7 @@ static thread_ret_t ggml_graph_compute_thread(void * data) {\n                 params.nth = n_tasks;\n \n                 /* INIT */\n+                on_node_compute_start(node);\n                 if (GGML_OP_HAS_INIT[node->op]) {\n                     params.type = GGML_TASK_INIT;\n                     ggml_compute_forward(&params, node);\n@@ -18558,6 +18765,8 @@ static thread_ret_t ggml_graph_compute_thread(void * data) {\n                     }\n \n                     ggml_graph_compute_perf_stats_node(node, state->shared);\n+\n+                    on_node_compute_done(node);\n                 } else {\n                     break;\n                 }\n@@ -19093,10 +19302,15 @@ int ggml_graph_compute(struct ggml_cgraph * cgraph, struct ggml_cplan * cplan) {\n         }\n \n         for (int i = 0; i < cgraph->n_nodes; ++i) {\n+            cgraph->nodes[i]->n_dst_curr = cgraph->nodes[i]->n_dst;\n             if (cgraph->nodes[i]->op != GGML_OP_NONE) {\n                 GGML_ASSERT(cplan->n_tasks[i] > 0);\n             }\n         }\n+\n+        for (int i = 0; i < cgraph->n_leafs; ++i) {\n+            cgraph->leafs[i]->n_dst_curr = cgraph->leafs[i]->n_dst;\n+        }\n     }\n \n     const int n_threads = cplan->n_threads;\n@@ -19454,6 +19668,7 @@ struct ggml_cgraph ggml_graph_import(const char * fname, struct ggml_context **\n                 .mem_size   = fsize + overhead,\n                 .mem_buffer = NULL,\n                 .no_alloc   = false,\n+                .dynamic    = false,\n             };\n \n             *ctx_data = ggml_init(params);\n@@ -19512,6 +19727,7 @@ struct ggml_cgraph ggml_graph_import(const char * fname, struct ggml_context **\n                 .mem_size   = size_eval + overhead,\n                 .mem_buffer = NULL,\n                 .no_alloc   = true,\n+                .dynamic    = false,\n             };\n \n             *ctx_eval = ggml_init(params);\n@@ -20717,6 +20933,7 @@ enum ggml_opt_result ggml_opt(\n             .mem_size   = 16*1024*1024,\n             .mem_buffer = NULL,\n             .no_alloc   = false,\n+            .dynamic    = false,\n         };\n \n         ctx = ggml_init(params_ctx);\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Dynamic Mode vs. `ggml-alloc`**: Prefer `ggml-alloc` to reduce memory fragmentation; dynamic mode's memory allocation strategy is unproven.\n2. **Code Change**: Change `alloc->data` to `alloc->base` to resolve compilation errors.\n3. **Tensor Naming**: Add names to allocated tensors for better tracking and debugging memory usage.\n4. **Performance Optimization**: Implement broadcasting in `ggml_add` and `ggml_mul` to reduce memory use and enhance performance.\n5. **Memory Management**: Define `GGML_ALLOCATOR_DEBUG` to analyze tensor allocations and evaluate fragmentation losses, especially during inference.\n6. **Graph Evaluation Order**: Consider changing the evaluation order to reduce peak memory usage; use depth-based evaluation to minimize simultaneous tensor allocations.\n7. **Memory Fragmentation**: Explore strategies like reordering graph evaluations to minimize fragmentation."
      }
    ],
    "codediff_length": 16578
  },
  {
    "index": 112,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/examples/CMakeLists.txt b/examples/CMakeLists.txt\nindex fc776c713..c24c3c0c1 100644\n--- a/examples/CMakeLists.txt\n+++ b/examples/CMakeLists.txt\n@@ -11,3 +11,4 @@ add_subdirectory(whisper)\n add_subdirectory(mnist)\n add_subdirectory(stablelm)\n add_subdirectory(dolly-v2)\n+add_subdirectory(redpajama)\ndiff --git a/examples/redpajama/CMakeLists.txt b/examples/redpajama/CMakeLists.txt\nnew file mode 100644\nindex 000000000..d66572c35\n--- /dev/null\n+++ b/examples/redpajama/CMakeLists.txt\n@@ -0,0 +1,13 @@\n+#\n+# redpajama\n+\n+set(TEST_TARGET redpajama)\n+add_executable(${TEST_TARGET} main.cpp)\n+target_link_libraries(${TEST_TARGET} PRIVATE ggml common common-ggml)\n+\n+#\n+# redpajama-quantize\n+\n+set(TEST_TARGET redpajama-quantize)\n+add_executable(${TEST_TARGET} quantize.cpp)\n+target_link_libraries(${TEST_TARGET} PRIVATE ggml common common-ggml)\ndiff --git a/examples/redpajama/README.md b/examples/redpajama/README.md\nnew file mode 100644\nindex 000000000..1c18e65f6\n--- /dev/null\n+++ b/examples/redpajama/README.md\n@@ -0,0 +1,104 @@\n+# RedPajama\n+\n+Transformer architecture: GPT-NeoX\n+\n+Ref: https://github.com/togethercomputer/RedPajama-Data\n+\n+## Usage\n+\n+```bash\n+# get the repo and build it\n+git clone https://github.com/ggerganov/ggml\n+cd ggml\n+mkdir build && cd build\n+cmake ..\n+make -j\n+\n+# get the RedPajama 3B Base model\n+git clone https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1\n+\n+# convert model to FP16\n+python3 ../examples/redpajama/convert-h5-to-ggml.py ./RedPajama-INCITE-Base-3B-v1/ 1\n+\n+# run inference using FP16 precision\n+make -j && ./bin/redpajama -m ./RedPajama-INCITE-Base-3B-v1/ggml-model-f16.bin -p \"I believe the meaning of life is\" -t 8 -n 64\n+\n+main: seed = 1683382277\n+redpajama_model_load: loading model from './RedPajama-INCITE-Base-3B-v1/ggml-model-f16.bin' - please wait ...\n+redpajama_model_load: n_vocab = 50432\n+redpajama_model_load: n_ctx   = 2048\n+redpajama_model_load: n_embd  = 2560\n+redpajama_model_load: n_head  = 32\n+redpajama_model_load: n_layer = 32\n+redpajama_model_load: n_rot   = 80\n+redpajama_model_load: ftype   = 1\n+redpajama_model_load: ggml ctx size = 7376.40 MB\n+redpajama_model_load: memory_size =   640.00 MB, n_mem = 65536\n+redpajama_model_load: ................................................ done\n+redpajama_model_load: model size =  5296.58 MB / num tensors = 388\n+main: number of tokens in prompt = 7\n+main: token[0] =     42, I\n+main: token[1] =   2868,  believe\n+main: token[2] =    253,  the\n+main: token[3] =   4495,  meaning\n+main: token[4] =    273,  of\n+main: token[5] =   1495,  life\n+main: token[6] =    310,  is\n+\n+I believe the meaning of life is to find your gift. A gift that is given to you by God.\u201d \u2013 Audrey Hepburn\n+\u201cLife\u2019s most persistent and urgent question is, \u2018What are you doing for others?\u2019\u201d \u2013 Martin Luther King, Jr.\n+\u201cYou have to figure out what you\u2019re supposed to be doing.\u201d\n+\n+main: mem per token = 16137360 bytes\n+main:     load time =  4786.43 ms\n+main:   sample time =    15.11 ms\n+main:  predict time = 17114.62 ms / 244.49 ms per token\n+main:    total time = 22845.03 ms\n+```\n+\n+## 4-bit integer quantization mode\n+\n+```bash\n+# quantize the model to 4-bits using Q4_3 quantization\n+./bin/redpajama-quantize RedPajama-INCITE-Base-3B-v1/ggml-model-f16.bin RedPajama-INCITE-Base-3B-v1/ggml-model-q4_0.bin 2\n+\n+# run the quantized model\n+./bin/redpajama -m ./RedPajama-INCITE-Base-3B-v1/ggml-model-q4_0.bin -p \"I believe the meaning of life is\" -t 8 -n 64\n+\n+main: seed = 1683383230\n+redpajama_model_load: loading model from './RedPajama-INCITE-Base-3B-v1/ggml-model-q4_0.bin' - please wait ...\n+redpajama_model_load: n_vocab = 50432\n+redpajama_model_load: n_ctx   = 2048\n+redpajama_model_load: n_embd  = 2560\n+redpajama_model_load: n_head  = 32\n+redpajama_model_load: n_layer = 32\n+redpajama_model_load: n_rot   = 80\n+redpajama_model_load: ftype   = 2\n+redpajama_model_load: ggml ctx size = 3737.80 MB\n+redpajama_model_load: memory_size =   640.00 MB, n_mem = 65536\n+redpajama_model_load: ................................................ done\n+redpajama_model_load: model size =  1657.99 MB / num tensors = 388\n+main: number of tokens in prompt = 7\n+main: token[0] =     42, I\n+main: token[1] =   2868,  believe\n+main: token[2] =    253,  the\n+main: token[3] =   4495,  meaning\n+main: token[4] =    273,  of\n+main: token[5] =   1495,  life\n+main: token[6] =    310,  is\n+\n+I believe the meaning of life is to love, to love deeply, to be able to love, to love without conditions, to love without measure, to love unconditionally, and to love until death.\n+The story of the song, I think, is that my love was never returned by my husband. He was a good man, but a\n+\n+main: mem per token = 16128400 bytes\n+main:     load time =   841.67 ms\n+main:   sample time =    13.05 ms\n+main:  predict time =  9297.83 ms / 132.83 ms per token\n+main:    total time = 10695.10 ms\n+```\n+\n+## Notes\n+\n+- No guarantees for correctness\n+- The tokenizer is currently hacked - probably works only for English\n+- Contributions and improvements are welcome\ndiff --git a/examples/redpajama/convert-h5-to-ggml.py b/examples/redpajama/convert-h5-to-ggml.py\nnew file mode 100644\nindex 000000000..ecbe2fadd\n--- /dev/null\n+++ b/examples/redpajama/convert-h5-to-ggml.py\n@@ -0,0 +1,116 @@\n+import sys\n+import struct\n+import json\n+import torch\n+import numpy as np\n+\n+from transformers import AutoModelForCausalLM, AutoTokenizer\n+\n+if len(sys.argv) < 3:\n+    print(\"Usage: convert-h5-to-ggml.py dir-model [use-f32]\\n\")\n+    print(\"  ftype == 0 -> float32\")\n+    print(\"  ftype == 1 -> float16\")\n+    sys.exit(1)\n+\n+# output in the same directory as the model\n+dir_model = sys.argv[1]\n+fname_out = sys.argv[1] + \"/ggml-model.bin\"\n+\n+with open(dir_model + \"/tokenizer.json\", \"r\", encoding=\"utf-8\") as f:\n+    encoder = json.load(f)\n+\n+with open(dir_model + \"/config.json\", \"r\", encoding=\"utf-8\") as f:\n+    hparams = json.load(f)\n+\n+# possible data types\n+#   ftype == 0 -> float32\n+#   ftype == 1 -> float16\n+#\n+# map from ftype to string\n+ftype_str = [\"f32\", \"f16\"]\n+\n+ftype = 1\n+if len(sys.argv) > 2:\n+    ftype = int(sys.argv[2])\n+    if ftype < 0 or ftype > 1:\n+        print(\"Invalid ftype: \" + str(ftype))\n+        sys.exit(1)\n+    fname_out = sys.argv[1] + \"/ggml-model-\" + ftype_str[ftype] + \".bin\"\n+\n+\n+tokenizer = AutoTokenizer.from_pretrained(dir_model)\n+model = AutoModelForCausalLM.from_pretrained(dir_model, low_cpu_mem_usage=True)\n+#print (model)\n+\n+#print(tokenizer.encode('I believe the meaning of life is'))\n+\n+list_vars = model.state_dict()\n+for name in list_vars.keys():\n+    print(name, list_vars[name].shape, list_vars[name].dtype)\n+\n+fout = open(fname_out, \"wb\")\n+\n+print(hparams)\n+\n+fout.write(struct.pack(\"i\", 0x67676d6c)) # magic: ggml in hex\n+fout.write(struct.pack(\"i\", hparams[\"vocab_size\"]))\n+fout.write(struct.pack(\"i\", hparams[\"max_position_embeddings\"]))\n+fout.write(struct.pack(\"i\", hparams[\"hidden_size\"]))\n+fout.write(struct.pack(\"i\", hparams[\"num_attention_heads\"]))\n+fout.write(struct.pack(\"i\", hparams[\"num_hidden_layers\"]))\n+fout.write(struct.pack(\"i\", int(hparams[\"rotary_pct\"]*(hparams[\"hidden_size\"]//hparams[\"num_attention_heads\"]))))\n+fout.write(struct.pack(\"i\", ftype))\n+\n+# TODO: temporary hack to not deal with implementing the tokenizer\n+dot_token = tokenizer.encode('.')[0]\n+for i in range(hparams[\"vocab_size\"]):\n+    text = tokenizer.decode([dot_token, i]).encode('utf-8')\n+    # remove the first byte (it's always '.')\n+    text = text[1:]\n+    fout.write(struct.pack(\"i\", len(text)))\n+    fout.write(text)\n+\n+for name in list_vars.keys():\n+    data = list_vars[name].squeeze().numpy()\n+    print(\"Processing variable: \" + name + \" with shape: \", data.shape)\n+\n+    # we don't need these\n+    if name.endswith(\".attention.masked_bias\") or     \\\n+       name.endswith(\".attention.bias\") or \\\n+       name.endswith(\".attention.rotary_emb.inv_freq\"):\n+        print(\"  Skipping variable: \" + name)\n+        continue\n+\n+    n_dims = len(data.shape);\n+\n+    # ftype == 0 -> float32, ftype == 1 -> float16\n+    ftype_cur = 0;\n+    if ftype != 0:\n+        if name[-7:] == \".weight\" and n_dims == 2:\n+            print(\"  Converting to float16\")\n+            data = data.astype(np.float16)\n+            ftype_cur = 1\n+        else:\n+            print(\"  Converting to float32\")\n+            data = data.astype(np.float32)\n+            ftype_cur = 0\n+    else:\n+        if data.dtype != np.float32:\n+            print(\"  Converting to float32\")\n+            data = data.astype(np.float32)\n+            ftype_cur = 0\n+\n+    # header\n+    str = name.encode('utf-8')\n+    fout.write(struct.pack(\"iii\", n_dims, len(str), ftype_cur))\n+    for i in range(n_dims):\n+        fout.write(struct.pack(\"i\", data.shape[n_dims - 1 - i]))\n+    fout.write(str);\n+\n+    # data\n+    data.tofile(fout)\n+\n+fout.close()\n+\n+print(\"Done. Output file: \" + fname_out)\n+print(\"\")\ndiff --git a/examples/redpajama/main.cpp b/examples/redpajama/main.cpp\nnew file mode 100644\nindex 000000000..2089f34ee\n--- /dev/null\n+++ b/examples/redpajama/main.cpp\n@@ -0,0 +1,772 @@\n+#include \"ggml/ggml.h\"\n+\n+#include \"common.h\"\n+#include \"common-ggml.h\"\n+\n+#include <cassert>\n+#include <cmath>\n+#include <cstdio>\n+#include <cstring>\n+#include <fstream>\n+#include <map>\n+#include <string>\n+#include <vector>\n+#include <iostream>\n+#include <unistd.h>\n+\n+// default hparams (RedPajama 3B)\n+struct redpajama_hparams {\n+    int32_t n_vocab = 50254; // tokenizer.vocab_size\n+    int32_t n_ctx   = 2048; // model.config.max_position_embeddings\n+    int32_t n_embd  = 2560; // model.config.hidden_size\n+    int32_t n_head  = 32; // model.config.num_attention_heads\n+    int32_t n_layer = 32; // model.config.num_hidden_layers\n+    int32_t n_rot   = 80; // rotary_pct[100%] * (n_embd / n_head)\n+    int32_t ftype   = GGML_FTYPE_MOSTLY_F16;\n+};\n+\n+struct redpajama_layer {\n+    // pre normalization\n+    struct ggml_tensor * ln_1_g;\n+    struct ggml_tensor * ln_1_b;\n+\n+    // attention\n+    struct ggml_tensor * c_attn_attn_w;\n+    struct ggml_tensor * c_attn_attn_b;\n+\n+    struct ggml_tensor * c_attn_proj_w;\n+    struct ggml_tensor * c_attn_proj_b;\n+\n+    // post normalization\n+    struct ggml_tensor * ln_2_g;\n+    struct ggml_tensor * ln_2_b;\n+\n+    // ff\n+    struct ggml_tensor * c_mlp_fc_w;\n+    struct ggml_tensor * c_mlp_fc_b;\n+\n+    struct ggml_tensor * c_mlp_proj_w;\n+    struct ggml_tensor * c_mlp_proj_b;\n+};\n+\n+struct redpajama_model {\n+    redpajama_hparams hparams;\n+\n+    // normalization\n+    struct ggml_tensor * ln_f_g;\n+    struct ggml_tensor * ln_f_b;\n+\n+    struct ggml_tensor * wte; // position embedding\n+\n+    struct ggml_tensor * lmh_g; // language model head\n+    //struct ggml_tensor * lmh_b; // language model bias\n+\n+    std::vector<redpajama_layer> layers;\n+\n+    // key + value memory\n+    struct ggml_tensor * memory_k;\n+    struct ggml_tensor * memory_v;\n+\n+    //\n+    struct ggml_context * ctx;\n+    std::map<std::string, struct ggml_tensor *> tensors;\n+};\n+\n+// load the model's weights from a file\n+bool redpajama_model_load(const std::string & fname, redpajama_model & model, gpt_vocab & vocab) {\n+    printf(\"%s: loading model from '%s' - please wait ...\\n\", __func__, fname.c_str());\n+\n+    auto fin = std::ifstream(fname, std::ios::binary);\n+    if (!fin) {\n+        fprintf(stderr, \"%s: failed to open '%s'\\n\", __func__, fname.c_str());\n+        return false;\n+    }\n+\n+    // verify magic\n+    {\n+        uint32_t magic;\n+        fin.read((char *) &magic, sizeof(magic));\n+        if (magic != 0x67676d6c) {\n+            fprintf(stderr, \"%s: invalid model file '%s' (bad magic)\\n\", __func__, fname.c_str());\n+            return false;\n+        }\n+    }\n+\n+    // load hparams\n+    {\n+        auto & hparams = model.hparams;\n+\n+        fin.read((char *) &hparams.n_vocab, sizeof(hparams.n_vocab));\n+        fin.read((char *) &hparams.n_ctx,   sizeof(hparams.n_ctx));\n+        fin.read((char *) &hparams.n_embd,  sizeof(hparams.n_embd));\n+        fin.read((char *) &hparams.n_head,  sizeof(hparams.n_head));\n+        fin.read((char *) &hparams.n_layer, sizeof(hparams.n_layer));\n+        fin.read((char *) &hparams.n_rot,   sizeof(hparams.n_rot));\n+        fin.read((char *) &hparams.ftype,   sizeof(hparams.ftype));\n+\n+        printf(\"%s: n_vocab = %d\\n\", __func__, hparams.n_vocab);\n+        printf(\"%s: n_ctx   = %d\\n\", __func__, hparams.n_ctx);\n+        printf(\"%s: n_embd  = %d\\n\", __func__, hparams.n_embd);\n+        printf(\"%s: n_head  = %d\\n\", __func__, hparams.n_head);\n+        printf(\"%s: n_layer = %d\\n\", __func__, hparams.n_layer);\n+        printf(\"%s: n_rot   = %d\\n\", __func__, hparams.n_rot);\n+        printf(\"%s: ftype   = %d\\n\", __func__, hparams.ftype);\n+    }\n+\n+    // load vocab\n+    {\n+        const int32_t n_vocab = model.hparams.n_vocab;\n+\n+        std::string word;\n+        for (int i = 0; i < n_vocab; i++) {\n+            uint32_t len;\n+            fin.read((char *) &len, sizeof(len));\n+\n+            word.resize(len);\n+            fin.read((char *) word.data(), len);\n+\n+            vocab.token_to_id[word] = i;\n+            vocab.id_to_token[i] = word;\n+        }\n+    }\n+\n+    // for the big tensors, we have the option to store the data in 16-bit floats or quantized\n+    // in order to save memory and also to speed up the computation\n+    ggml_type wtype = ggml_ftype_to_ggml_type((ggml_ftype) (model.hparams.ftype));\n+    if (wtype == GGML_TYPE_COUNT) {\n+        fprintf(stderr, \"%s: invalid model file '%s' (bad ftype value %d)\\n\",\n+                __func__, fname.c_str(), model.hparams.ftype);\n+        return false;\n+    }\n+\n+    auto & ctx = model.ctx;\n+\n+    size_t ctx_size = 0;\n+\n+    {\n+        const auto & hparams = model.hparams;\n+\n+        const int n_embd  = hparams.n_embd;\n+        const int n_layer = hparams.n_layer;\n+        const int n_ctx   = hparams.n_ctx;\n+        const int n_vocab = hparams.n_vocab;\n+\n+        ctx_size += n_embd*ggml_type_sizef(GGML_TYPE_F32); // ln_f_g\n+        ctx_size += n_embd*ggml_type_sizef(GGML_TYPE_F32); // ln_f_b\n+\n+        ctx_size += n_embd*n_vocab*ggml_type_sizef(wtype); // wte\n+\n+        ctx_size += n_embd*n_vocab*ggml_type_sizef(wtype);           // lmh_g\n+        //ctx_size +=        n_vocab*ggml_type_sizef(GGML_TYPE_F32); // lmh_b\n+\n+        ctx_size += n_layer*(n_embd*ggml_type_sizef(GGML_TYPE_F32)); // ln_1_g\n+        ctx_size += n_layer*(n_embd*ggml_type_sizef(GGML_TYPE_F32)); // ln_1_b\n+\n+        ctx_size += n_layer*(3*n_embd*n_embd*ggml_type_sizef(wtype));         // c_attn_attn_w\n+        ctx_size += n_layer*(       3*n_embd*ggml_type_sizef(GGML_TYPE_F32)); // c_attn_attn_b\n+\n+        ctx_size += n_layer*(n_embd*n_embd*ggml_type_sizef(wtype));         // c_attn_proj_w\n+        ctx_size += n_layer*(n_embd*n_embd*ggml_type_sizef(GGML_TYPE_F32)); // c_attn_proj_b\n+\n+        ctx_size += n_layer*(n_embd*ggml_type_sizef(GGML_TYPE_F32)); // ln_2_g\n+        ctx_size += n_layer*(n_embd*ggml_type_sizef(GGML_TYPE_F32)); // ln_2_b\n+\n+        ctx_size += n_layer*(4*n_embd*n_embd*ggml_type_sizef(wtype));         // c_mlp_fc_w\n+        ctx_size += n_layer*(       4*n_embd*ggml_type_sizef(GGML_TYPE_F32)); // c_mlp_fc_b\n+\n+        ctx_size += n_layer*(4*n_embd*n_embd*ggml_type_sizef(wtype));         // c_mlp_proj_w\n+        ctx_size += n_layer*(         n_embd*ggml_type_sizef(GGML_TYPE_F32)); // c_mlp_proj_b\n+\n+        ctx_size += n_ctx*n_layer*n_embd*ggml_type_sizef(GGML_TYPE_F32); // memory_k\n+        ctx_size += n_ctx*n_layer*n_embd*ggml_type_sizef(GGML_TYPE_F32); // memory_v\n+\n+        ctx_size += (6 + 16*n_layer)*256; // object overhead\n+\n+        printf(\"%s: ggml ctx size = %6.2f MB\\n\", __func__, ctx_size/(1024.0*1024.0));\n+    }\n+\n+    // create the ggml context\n+    {\n+        struct ggml_init_params params = {\n+            .mem_size   = ctx_size,\n+            .mem_buffer = NULL,\n+            .no_alloc   = false,\n+        };\n+\n+        model.ctx = ggml_init(params);\n+        if (!model.ctx) {\n+            fprintf(stderr, \"%s: ggml_init() failed\\n\", __func__);\n+            return false;\n+        }\n+    }\n+\n+    // prepare memory for the weights\n+    {\n+        const auto & hparams = model.hparams;\n+\n+        const int n_embd  = hparams.n_embd;\n+        const int n_layer = hparams.n_layer;\n+        const int n_ctx   = hparams.n_ctx;\n+        const int n_vocab = hparams.n_vocab;\n+\n+        model.layers.resize(n_layer);\n+\n+        model.wte    = ggml_new_tensor_2d(ctx, wtype,         n_embd, n_vocab);\n+\n+        model.ln_f_g = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_embd);\n+        model.ln_f_b = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_embd);\n+\n+        model.lmh_g  = ggml_new_tensor_2d(ctx, wtype,         n_embd, n_vocab);\n+        //model.lmh_b  = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, n_vocab);\n+\n+        // map by name\n+        model.tensors[\"gpt_neox.embed_in.weight\"] = model.wte;\n+\n+        model.tensors[\"gpt_neox.final_layer_norm.weight\"] = model.ln_f_g;\n+        model.tensors[\"gpt_neox.final_layer_norm.bias\"]   = model.ln_f_b;\n+\n+        model.tensors[\"embed_out.weight\"] = model.lmh_g;\n+        //model.tensors[\"lm_head.bias\"]   = model.lmh_b;\n+\n+        for (int i = 0; i < n_layer; ++i) {\n+            auto & layer = model.layers[i];\n+\n+            layer.ln_1_g          = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+            layer.ln_1_b          = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+\n+            layer.c_attn_attn_w   = ggml_new_tensor_2d(ctx, wtype,           n_embd, 3*n_embd);\n+            layer.c_attn_attn_b   = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, 3*n_embd);\n+\n+            layer.c_attn_proj_w   = ggml_new_tensor_2d(ctx, wtype,           n_embd,   n_embd);\n+            layer.c_attn_proj_b   = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+\n+            layer.ln_2_g          = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+            layer.ln_2_b          = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+\n+            layer.c_mlp_fc_w      = ggml_new_tensor_2d(ctx, wtype,           n_embd, 4*n_embd);\n+            layer.c_mlp_fc_b      = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, 4*n_embd);\n+\n+            layer.c_mlp_proj_w    = ggml_new_tensor_2d(ctx, wtype,         4*n_embd,   n_embd);\n+            layer.c_mlp_proj_b    = ggml_new_tensor_1d(ctx, GGML_TYPE_F32,   n_embd);\n+\n+            // map by name\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".input_layernorm.weight\"] = layer.ln_1_g;\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".input_layernorm.bias\"]   = layer.ln_1_b;\n+\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".attention.query_key_value.weight\"] = layer.c_attn_attn_w;\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".attention.query_key_value.bias\"]   = layer.c_attn_attn_b;\n+\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".attention.dense.weight\"] = layer.c_attn_proj_w;\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".attention.dense.bias\"]   = layer.c_attn_proj_b;\n+\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".post_attention_layernorm.weight\"] = layer.ln_2_g;\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".post_attention_layernorm.bias\"]   = layer.ln_2_b;\n+\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".mlp.dense_h_to_4h.weight\"] = layer.c_mlp_fc_w;\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".mlp.dense_h_to_4h.bias\"]   = layer.c_mlp_fc_b;\n+\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".mlp.dense_4h_to_h.weight\"] = layer.c_mlp_proj_w;\n+            model.tensors[\"gpt_neox.layers.\" + std::to_string(i) + \".mlp.dense_4h_to_h.bias\"]   = layer.c_mlp_proj_b;\n+        }\n+    }\n+\n+    // key + value memory\n+    {\n+        const auto & hparams = model.hparams;\n+\n+        const int n_embd  = hparams.n_embd;\n+        const int n_layer = hparams.n_layer;\n+        const int n_ctx   = hparams.n_ctx;\n+\n+        const int64_t n_mem      = n_layer*n_ctx;\n+        const int64_t n_elements = n_embd*n_mem;\n+\n+        model.memory_k = ggml_new_tensor_1d(ctx, GGML_TYPE_F16, n_elements);\n+        model.memory_v = ggml_new_tensor_1d(ctx, GGML_TYPE_F16, n_elements);\n+\n+        const size_t memory_size = ggml_nbytes(model.memory_k) + ggml_nbytes(model.memory_v);\n+\n+        printf(\"%s: memory_size = %8.2f MB, n_mem = %lld\\n\", __func__, memory_size/1024.0/1024.0, n_mem);\n+    }\n+\n+    // load weights\n+    {\n+        int n_tensors = 0;\n+        size_t total_size = 0;\n+\n+        printf(\"%s: \", __func__);\n+\n+        while (true) {\n+            int32_t n_dims;\n+            int32_t length;\n+            int32_t ttype;\n+\n+            fin.read(reinterpret_cast<char *>(&n_dims), sizeof(n_dims));\n+            fin.read(reinterpret_cast<char *>(&length), sizeof(length));\n+            fin.read(reinterpret_cast<char *>(&ttype),  sizeof(ttype));\n+\n+            if (fin.eof()) {\n+                break;\n+            }\n+\n+            int32_t nelements = 1;\n+            int32_t ne[2] = { 1, 1 };\n+            for (int i = 0; i < n_dims; ++i) {\n+                fin.read(reinterpret_cast<char *>(&ne[i]), sizeof(ne[i]));\n+                nelements *= ne[i];\n+            }\n+\n+            std::string name(length, 0);\n+            fin.read(&name[0], length);\n+\n+            if (model.tensors.find(name.data()) == model.tensors.end()) {\n+                fprintf(stderr, \"%s: unknown tensor '%s' in model file\\n\", __func__, name.data());\n+                return false;\n+            }\n+\n+            auto tensor = model.tensors[name.data()];\n+            if (ggml_nelements(tensor) != nelements) {\n+                fprintf(stderr, \"%s: tensor '%s' has wrong size in model file\\n\", __func__, name.data());\n+                return false;\n+            }\n+\n+            if (tensor->ne[0] != ne[0] || tensor->ne[1] != ne[1]) {\n+                fprintf(stderr, \"%s: tensor '%s' has wrong shape in model file: got [%5d, %5d], expected [%5d, %5d]\\n\",\n+                        __func__, name.data(), (int) tensor->ne[0], (int) tensor->ne[1], ne[0], ne[1]);\n+                return false;\n+            }\n+\n+            // for debugging\n+            if (0) {\n+                printf(\"%24s - [%5d, %5d], type = %6s, %6.2f MB, %9zu bytes\\n\", name.data(), ne[0], ne[1], ggml_type_name(ggml_type(ttype)), ggml_nbytes(tensor)/1024.0/1024.0, ggml_nbytes(tensor));\n+            }\n+\n+            const size_t bpe = ggml_type_size(ggml_type(ttype));\n+\n+            if ((nelements*bpe)/ggml_blck_size(tensor->type) != ggml_nbytes(tensor)) {\n+                fprintf(stderr, \"%s: tensor '%s' has wrong size in model file: got %zu, expected %zu\\n\",\n+                        __func__, name.data(), ggml_nbytes(tensor), nelements*bpe);\n+                return false;\n+            }\n+\n+            fin.read(reinterpret_cast<char *>(tensor->data), ggml_nbytes(tensor));\n+\n+            total_size += ggml_nbytes(tensor);\n+            if (++n_tensors % 8 == 0) {\n+                printf(\".\");\n+                fflush(stdout);\n+            }\n+        }\n+\n+        printf(\" done\\n\");\n+\n+        printf(\"%s: model size = %8.2f MB / num tensors = %d\\n\", __func__, total_size/1024.0/1024.0, n_tensors);\n+    }\n+\n+    fin.close();\n+\n+    return true;\n+}\n+\n+// evaluate the transformer\n+//\n+//   - model:     the model\n+//   - n_threads: number of threads to use\n+//   - n_past:    the context size so far\n+//   - embd_inp:  the embeddings of the tokens in the context\n+//   - embd_w:    the predicted logits for the next token\n+//\n+bool redpajama_eval(\n+        const redpajama_model & model,\n+        const int n_threads,\n+        const int n_past,\n+        const std::vector<gpt_vocab::id> & embd_inp,\n+              std::vector<float>         & embd_w,\n+              size_t                     & mem_per_token) {\n+    const int N = embd_inp.size();\n+\n+    const auto & hparams = model.hparams;\n+\n+    const int n_embd  = hparams.n_embd;\n+    const int n_layer = hparams.n_layer;\n+    const int n_ctx   = hparams.n_ctx;\n+    const int n_head  = hparams.n_head;\n+    const int n_vocab = hparams.n_vocab;\n+    const int n_rot   = hparams.n_rot;\n+\n+    static size_t buf_size = 256u*1024*1024;\n+    static void * buf = malloc(buf_size);\n+\n+    if (mem_per_token > 0 && mem_per_token*N > buf_size) {\n+        const size_t buf_size_new = 1.1*(mem_per_token*N); // add 10% to account for ggml object overhead\n+        //printf(\"\\n%s: reallocating buffer from %zu to %zu bytes\\n\", __func__, buf_size, buf_size_new);\n+\n+        // reallocate\n+        buf_size = buf_size_new;\n+        buf = realloc(buf, buf_size);\n+        if (buf == nullptr) {\n+            fprintf(stderr, \"%s: failed to allocate %zu bytes\\n\", __func__, buf_size);\n+            return false;\n+        }\n+    }\n+\n+    struct ggml_init_params params = {\n+        .mem_size   = buf_size,\n+        .mem_buffer = buf,\n+        .no_alloc   = false,\n+    };\n+\n+    struct ggml_context * ctx0 = ggml_init(params);\n+    struct ggml_cgraph gf = { .n_threads = n_threads };\n+\n+    struct ggml_tensor * embd = ggml_new_tensor_1d(ctx0, GGML_TYPE_I32, N);\n+    memcpy(embd->data, embd_inp.data(), N*ggml_element_size(embd));\n+\n+    // wte\n+    struct ggml_tensor * inpL = ggml_get_rows(ctx0, model.wte, embd);\n+\n+    for (int il = 0; il < n_layer; ++il) {\n+        struct ggml_tensor * cur;\n+\n+        // self-attention\n+        {\n+            {\n+                cur = ggml_norm(ctx0, inpL);\n+\n+                cur = ggml_add(ctx0,\n+                        ggml_mul(ctx0,\n+                            ggml_repeat(ctx0, model.layers[il].ln_1_g, cur),\n+                            cur),\n+                        ggml_repeat(ctx0, model.layers[il].ln_1_b, cur));\n+            }\n+\n+            // compute QKV\n+            {\n+                cur = ggml_mul_mat(ctx0,\n+                        model.layers[il].c_attn_attn_w,\n+                        cur);\n+\n+                cur = ggml_add(ctx0,\n+                        ggml_repeat(ctx0, model.layers[il].c_attn_attn_b, cur),\n+                        cur);\n+            }\n+\n+            struct ggml_tensor * Qcur = ggml_cont(ctx0, ggml_view_3d(ctx0, cur, n_embd/n_head, n_head, N, cur->nb[1]/n_head, cur->nb[1], 0*sizeof(float)*n_embd/n_head));\n+            struct ggml_tensor * Kcur = ggml_cont(ctx0, ggml_view_3d(ctx0, cur, n_embd/n_head, n_head, N, cur->nb[1]/n_head, cur->nb[1], 1*sizeof(float)*n_embd/n_head));\n+            struct ggml_tensor * Vcur = ggml_cont(ctx0, ggml_view_3d(ctx0, cur, n_embd/n_head, n_head, N, cur->nb[1]/n_head, cur->nb[1], 2*sizeof(float)*n_embd/n_head));\n+\n+            // using mode = 2 for GPT-NeoX mode\n+            Qcur = ggml_rope(ctx0, Qcur, n_past, n_rot, 2);\n+            Kcur = ggml_rope(ctx0, Kcur, n_past, n_rot, 2);\n+\n+            // store key and value to memory\n+            {\n+                Vcur = ggml_transpose(ctx0, ggml_reshape_2d(ctx0, Vcur, n_embd, N));\n+\n+                struct ggml_tensor * k = ggml_view_1d(ctx0, model.memory_k, N*n_embd, (ggml_element_size(model.memory_k)*n_embd)*(il*n_ctx + n_past));\n+                struct ggml_tensor * v = ggml_view_2d(ctx0, model.memory_v, N, n_embd,\n+                        (   n_ctx)*ggml_element_size(model.memory_v),\n+                        (il*n_ctx)*ggml_element_size(model.memory_v)*n_embd + n_past*ggml_element_size(model.memory_v));\n+\n+                ggml_build_forward_expand(&gf, ggml_cpy(ctx0, Kcur, k));\n+                ggml_build_forward_expand(&gf, ggml_cpy(ctx0, Vcur, v));\n+            }\n+\n+            // Q = Qcur.contiguous().view(n_embd/n_head, n_head, N).permute(0, 2, 1, 3)\n+            struct ggml_tensor * Q =\n+                ggml_permute(ctx0,\n+                        Qcur,\n+                        0, 2, 1, 3);\n+\n+            // K = Kmem.view(n_embd/n_head, n_head, n_past + N).permute(0, 2, 1, 3)\n+            struct ggml_tensor * K =\n+                ggml_permute(ctx0,\n+                        ggml_reshape_3d(ctx0,\n+                            ggml_view_1d(ctx0, model.memory_k, (n_past + N)*n_embd, il*n_ctx*ggml_element_size(model.memory_k)*n_embd),\n+                            n_embd/n_head, n_head, n_past + N),\n+                        0, 2, 1, 3);\n+\n+            // K * Q\n+            struct ggml_tensor * KQ = ggml_mul_mat(ctx0, K, Q);\n+\n+            // KQ_scaled = KQ / sqrt(n_embd/n_head)\n+            struct ggml_tensor * KQ_scaled =\n+                ggml_scale(ctx0,\n+                        KQ,\n+                        ggml_new_f32(ctx0, 1.0f/sqrt(float(n_embd)/n_head))\n+                        );\n+\n+            // KQ_masked = mask_past(KQ_scaled)\n+            struct ggml_tensor * KQ_masked = ggml_diag_mask_inf(ctx0, KQ_scaled, n_past);\n+\n+            // KQ = soft_max(KQ_masked)\n+            struct ggml_tensor * KQ_soft_max = ggml_soft_max(ctx0, KQ_masked);\n+\n+            // V_trans = Vmem.view(n_embd/n_head, n_head, n_past + N).permute(1, 2, 0, 3).contiguous()\n+            struct ggml_tensor * V =\n+                ggml_view_3d(ctx0, model.memory_v,\n+                        n_past + N, n_embd/n_head, n_head,\n+                        n_ctx*ggml_element_size(model.memory_v),\n+                        n_ctx*ggml_element_size(model.memory_v)*n_embd/n_head,\n+                        il*n_ctx*ggml_element_size(model.memory_v)*n_embd);\n+\n+            // KQV = transpose(V) * KQ_soft_max\n+            struct ggml_tensor * KQV = ggml_mul_mat(ctx0, V, KQ_soft_max);\n+\n+            // KQV_merged = KQV.permute(0, 2, 1, 3)\n+            struct ggml_tensor * KQV_merged = ggml_permute(ctx0, KQV, 0, 2, 1, 3);\n+\n+            // cur = KQV_merged.contiguous().view(n_embd, N)\n+            cur = ggml_cpy(ctx0,\n+                    KQV_merged,\n+                    ggml_new_tensor_2d(ctx0, GGML_TYPE_F32, n_embd, N));\n+\n+            // projection\n+            {\n+                cur = ggml_mul_mat(ctx0,\n+                        model.layers[il].c_attn_proj_w,\n+                        cur);\n+\n+                cur = ggml_add(ctx0, ggml_repeat(ctx0, model.layers[il].c_attn_proj_b, cur), cur);\n+            }\n+\n+        }\n+\n+        // layer input + Attn\n+        cur  = ggml_add(ctx0, cur, inpL);\n+\n+        struct ggml_tensor * inpFF = cur;\n+\n+        // feed-forward network\n+        {\n+            // post attention layer norm\n+            {\n+                cur = ggml_norm(ctx0, cur);\n+\n+                cur = ggml_add(ctx0,\n+                    ggml_mul(ctx0,\n+                        ggml_repeat(ctx0, model.layers[il].ln_2_g, cur),\n+                        cur),\n+                    ggml_repeat(ctx0, model.layers[il].ln_2_b, cur));\n+            }\n+\n+            cur = ggml_mul_mat(ctx0,\n+                    model.layers[il].c_mlp_fc_w,\n+                    cur);\n+\n+            cur = ggml_add(ctx0,\n+                    ggml_repeat(ctx0, model.layers[il].c_mlp_fc_b, cur),\n+                    cur);\n+\n+            // GELU activation\n+            cur = ggml_gelu(ctx0, cur);\n+\n+            // projection\n+            // cur = proj_w*cur + proj_b\n+            cur = ggml_mul_mat(ctx0,\n+                    model.layers[il].c_mlp_proj_w,\n+                    cur);\n+\n+            cur = ggml_add(ctx0,\n+                    ggml_repeat(ctx0, model.layers[il].c_mlp_proj_b, cur),\n+                    cur);\n+        }\n+\n+        // layer input + FF\n+        inpL = ggml_add(ctx0, cur, inpFF);\n+    }\n+\n+    // norm\n+    {\n+        inpL = ggml_norm(ctx0, inpL);\n+\n+        // inpL = ln_f_g*inpL + ln_f_b\n+        inpL = ggml_add(ctx0,\n+                ggml_mul(ctx0,\n+                    ggml_repeat(ctx0, model.ln_f_g, inpL),\n+                    inpL),\n+                ggml_repeat(ctx0, model.ln_f_b, inpL));\n+    }\n+\n+    // lm_head\n+    {\n+        inpL = ggml_mul_mat(ctx0, model.lmh_g, inpL);\n+\n+        //inpL = ggml_add(ctx0,\n+        //        ggml_repeat(ctx0, model.lmh_b, inpL),\n+        //        inpL);\n+    }\n+\n+    // logits -> probs\n+    //inpL = ggml_soft_max(ctx0, inpL);\n+\n+    // run the computation\n+    ggml_build_forward_expand(&gf, inpL);\n+    ggml_graph_compute       (ctx0, &gf);\n+\n+    //if (n_past%100 == 0) {\n+    //    ggml_graph_print   (&gf);\n+    //    ggml_graph_dump_dot(&gf, NULL, \"gpt-2.dot\");\n+    //}\n+\n+    //embd_w.resize(n_vocab*N);\n+    //memcpy(embd_w.data(), ggml_get_data(inpL), sizeof(float)*n_vocab*N);\n+\n+    // return result for just the last token\n+    embd_w.resize(n_vocab);\n+    memcpy(embd_w.data(), (float *) ggml_get_data(inpL) + (n_vocab*(N-1)), sizeof(float)*n_vocab);\n+\n+    if (mem_per_token == 0) {\n+        mem_per_token = ggml_used_mem(ctx0)/N;\n+    }\n+    //printf(\"used_mem = %zu\\n\", ggml_used_mem(ctx0));\n+\n+    ggml_free(ctx0);\n+\n+    return true;\n+}\n+\n+int main(int argc, char ** argv) {\n+    const int64_t t_main_start_us = ggml_time_us();\n+\n+    gpt_params params;\n+    params.model = \"models/RedPajama-INCITE-Base-3B-v1/ggml-model-f16.bin\";\n+\n+    if (gpt_params_parse(argc, argv, params) == false) {\n+        return 1;\n+    }\n+\n+    if (params.seed < 0) {\n+        params.seed = time(NULL);\n+    }\n+\n+    printf(\"%s: seed = %d\\n\", __func__, params.seed);\n+\n+    std::mt19937 rng(params.seed);\n+    if (params.prompt.empty()) {\n+        if( !isatty(STDIN_FILENO) ){\n+            std::string line;\n+            while( std::getline(std::cin, line) ){\n+                params.prompt = params.prompt + \"\\n\" + line;\n+            }\n+        } else {\n+            params.prompt = gpt_random_prompt(rng);\n+        }\n+    }\n+\n+    int64_t t_load_us = 0;\n+\n+    gpt_vocab vocab;\n+    redpajama_model model;\n+\n+    // load the model\n+    {\n+        const int64_t t_start_us = ggml_time_us();\n+\n+        if (!redpajama_model_load(params.model, model, vocab)) {\n+            fprintf(stderr, \"%s: failed to load model from '%s'\\n\", __func__, params.model.c_str());\n+            return 1;\n+        }\n+\n+        t_load_us = ggml_time_us() - t_start_us;\n+    }\n+\n+    int n_past = 0;\n+\n+    int64_t t_sample_us  = 0;\n+    int64_t t_predict_us = 0;\n+\n+    std::vector<float> logits;\n+\n+    // tokenize the prompt\n+    std::vector<gpt_vocab::id> embd_inp = ::gpt_tokenize(vocab, params.prompt);\n+\n+    params.n_predict = std::min(params.n_predict, model.hparams.n_ctx - (int) embd_inp.size());\n+\n+    printf(\"%s: number of tokens in prompt = %zu\\n\", __func__, embd_inp.size());\n+    for (int i = 0; i < embd_inp.size(); i++) {\n+        printf(\"%s: token[%d] = %6d, %s\\n\", __func__, i, embd_inp[i], vocab.id_to_token.at(embd_inp[i]).c_str());\n+    }\n+    printf(\"\\n\");\n+\n+    std::vector<gpt_vocab::id> embd;\n+\n+    // determine the required inference memory per token:\n+    size_t mem_per_token = 0;\n+    redpajama_eval(model, params.n_threads, 0, { 0, 1, 2, 3 }, logits, mem_per_token);\n+\n+    for (int i = embd.size(); i < embd_inp.size() + params.n_predict; i++) {\n+        // predict\n+        if (embd.size() > 0) {\n+            const int64_t t_start_us = ggml_time_us();\n+\n+            if (!redpajama_eval(model, params.n_threads, n_past, embd, logits, mem_per_token)) {\n+                printf(\"Failed to predict\\n\");\n+                return 1;\n+            }\n+\n+            t_predict_us += ggml_time_us() - t_start_us;\n+        }\n+\n+        n_past += embd.size();\n+        embd.clear();\n+\n+        if (i >= embd_inp.size()) {\n+            // sample next token\n+            const int   top_k = params.top_k;\n+            const float top_p = params.top_p;\n+            const float temp  = params.temp;\n+\n+            const int n_vocab = model.hparams.n_vocab;\n+\n+            gpt_vocab::id id = 0;\n+\n+            {\n+                const int64_t t_start_sample_us = ggml_time_us();\n+\n+                id = gpt_sample_top_k_top_p(vocab, logits.data() + (logits.size() - n_vocab), top_k, top_p, temp, rng);\n+\n+                t_sample_us += ggml_time_us() - t_start_sample_us;\n+            }\n+\n+            // add it to the context\n+            embd.push_back(id);\n+        } else {\n+            // if here, it means we are still processing the input prompt\n+            for (int k = i; k < embd_inp.size(); k++) {\n+                embd.push_back(embd_inp[k]);\n+                if (embd.size() > params.n_batch) {\n+                    break;\n+                }\n+            }\n+            i += embd.size() - 1;\n+        }\n+\n+        // display text\n+        for (auto id : embd) {\n+            printf(\"%s\", vocab.id_to_token[id].c_str());\n+        }\n+        fflush(stdout);\n+\n+        // end of text token\n+        if (embd.back() == 0) {\n+            break;\n+        }\n+    }\n+\n+    // report timing\n+    {\n+        const int64_t t_main_end_us = ggml_time_us();\n+\n+        printf(\"\\n\\n\");\n+        printf(\"%s: mem per token = %8zu bytes\\n\", __func__, mem_per_token);\n+        printf(\"%s:     load time = %8.2f ms\\n\", __func__, t_load_us/1000.0f);\n+        printf(\"%s:   sample time = %8.2f ms\\n\", __func__, t_sample_us/1000.0f);\n+        printf(\"%s:  predict time = %8.2f ms / %.2f ms per token\\n\", __func__, t_predict_us/1000.0f, t_predict_us/1000.0f/n_past);\n+        printf(\"%s:    total time = %8.2f ms\\n\", __func__, (t_main_end_us - t_main_start_us)/1000.0f);\n+    }\n+\n+    ggml_free(model.ctx);\n+\n+    return 0;\n+}\ndiff --git a/examples/redpajama/quantize.cpp b/examples/redpajama/quantize.cpp\nnew file mode 100644\nindex 000000000..c25467934\n--- /dev/null\n+++ b/examples/redpajama/quantize.cpp\n@@ -0,0 +1,168 @@\n+#include \"ggml/ggml.h\"\n+\n+#include \"common.h\"\n+#include \"common-ggml.h\"\n+\n+#include <cassert>\n+#include <cmath>\n+#include <cstdio>\n+#include <cstring>\n+#include <fstream>\n+#include <map>\n+#include <string>\n+#include <vector>\n+#include <regex>\n+\n+// default hparams (RedPajama 3B)\n+struct redpajama_hparams {\n+    int32_t n_vocab = 50254; // tokenizer.vocab_size\n+    int32_t n_ctx   = 2048; // model.config.max_position_embeddings\n+    int32_t n_embd  = 2560; // model.config.hidden_size\n+    int32_t n_head  = 32; // model.config.num_attention_heads\n+    int32_t n_layer = 32; // model.config.num_hidden_layers\n+    int32_t n_rot   = 80; // rotary_pct[100%] * (n_embd / n_head)\n+    int32_t ftype   = GGML_FTYPE_MOSTLY_F16;\n+};\n+\n+// quantize a model\n+bool redpajama_model_quantize(const std::string & fname_inp, const std::string & fname_out, ggml_ftype ftype) {\n+    gpt_vocab vocab;\n+\n+    printf(\"%s: loading model from '%s'\\n\", __func__, fname_inp.c_str());\n+\n+    auto finp = std::ifstream(fname_inp, std::ios::binary);\n+    if (!finp) {\n+        fprintf(stderr, \"%s: failed to open '%s' for reading\\n\", __func__, fname_inp.c_str());\n+        return false;\n+    }\n+\n+    auto fout = std::ofstream(fname_out, std::ios::binary);\n+    if (!fout) {\n+        fprintf(stderr, \"%s: failed to open '%s' for writing\\n\", __func__, fname_out.c_str());\n+        return false;\n+    }\n+\n+    // verify magic\n+    {\n+        uint32_t magic;\n+        finp.read((char *) &magic, sizeof(magic));\n+        if (magic != 0x67676d6c) {\n+            fprintf(stderr, \"%s: invalid model file '%s' (bad magic)\\n\", __func__, fname_inp.c_str());\n+            return false;\n+        }\n+\n+        fout.write((char *) &magic, sizeof(magic));\n+    }\n+\n+    redpajama_hparams hparams;\n+\n+    // load hparams\n+    {\n+        finp.read((char *) &hparams.n_vocab, sizeof(hparams.n_vocab));\n+        finp.read((char *) &hparams.n_ctx,   sizeof(hparams.n_ctx));\n+        finp.read((char *) &hparams.n_embd,  sizeof(hparams.n_embd));\n+        finp.read((char *) &hparams.n_head,  sizeof(hparams.n_head));\n+        finp.read((char *) &hparams.n_layer, sizeof(hparams.n_layer));\n+        finp.read((char *) &hparams.n_rot,   sizeof(hparams.n_rot));\n+        finp.read((char *) &hparams.ftype,   sizeof(hparams.ftype));\n+\n+        printf(\"%s: n_vocab = %d\\n\", __func__, hparams.n_vocab);\n+        printf(\"%s: n_ctx   = %d\\n\", __func__, hparams.n_ctx);\n+        printf(\"%s: n_embd  = %d\\n\", __func__, hparams.n_embd);\n+        printf(\"%s: n_head  = %d\\n\", __func__, hparams.n_head);\n+        printf(\"%s: n_layer = %d\\n\", __func__, hparams.n_layer);\n+        printf(\"%s: ftype   = %d\\n\", __func__, hparams.ftype);\n+\n+        fout.write((char *) &hparams.n_vocab, sizeof(hparams.n_vocab));\n+        fout.write((char *) &hparams.n_ctx,   sizeof(hparams.n_ctx));\n+        fout.write((char *) &hparams.n_embd,  sizeof(hparams.n_embd));\n+        fout.write((char *) &hparams.n_head,  sizeof(hparams.n_head));\n+        fout.write((char *) &hparams.n_layer, sizeof(hparams.n_layer));\n+        fout.write((char *) &hparams.n_rot,   sizeof(hparams.n_rot));\n+        fout.write((char *) &ftype,           sizeof(hparams.ftype));\n+    }\n+\n+    // load vocab\n+    {\n+        const int32_t n_vocab = hparams.n_vocab;\n+\n+        std::string word;\n+        for (int i = 0; i < n_vocab; i++) {\n+            uint32_t len;\n+            finp.read ((char *) &len, sizeof(len));\n+            fout.write((char *) &len, sizeof(len));\n+\n+            word.resize(len);\n+            finp.read ((char *) word.data(), len);\n+            fout.write((char *) word.data(), len);\n+\n+            vocab.token_to_id[word] = i;\n+            vocab.id_to_token[i] = word;\n+        }\n+    }\n+\n+    // regexes of tensor names to be quantized\n+    const std::vector<std::string> to_quant = {\n+        \".*weight\",\n+    };\n+\n+    if (!ggml_common_quantize_0(finp, fout, ftype, to_quant, {})) {\n+        fprintf(stderr, \"%s: failed to quantize model '%s'\\n\", __func__, fname_inp.c_str());\n+        return false;\n+    }\n+\n+    finp.close();\n+    fout.close();\n+\n+    return true;\n+}\n+\n+// usage:\n+//  ./redpajama2-quantize models/redpajama2-117M/ggml-model.bin models/redpajama2-117M/ggml-model-quant.bin type\n+//\n+int main(int argc, char ** argv) {\n+    if (argc != 4) {\n+        fprintf(stderr, \"usage: %s model-f16.bin model-quant.bin type\\n\", argv[0]);\n+        ggml_print_ftypes(stderr);\n+        return 1;\n+    }\n+\n+    // needed to initialize f16 tables\n+    {\n+        struct ggml_init_params params = { 0, NULL, false };\n+        struct ggml_context * ctx = ggml_init(params);\n+        ggml_free(ctx);\n+    }\n+\n+    const std::string fname_inp = argv[1];\n+    const std::string fname_out = argv[2];\n+\n+    const ggml_ftype ftype = ggml_parse_ftype(argv[3]);\n+\n+    const int64_t t_main_start_us = ggml_time_us();\n+\n+    int64_t t_quantize_us = 0;\n+\n+    // load the model\n+    {\n+        const int64_t t_start_us = ggml_time_us();\n+\n+        if (!redpajama_model_quantize(fname_inp, fname_out, ggml_ftype(ftype))) {\n+            fprintf(stderr, \"%s: failed to quantize model from '%s'\\n\", __func__, fname_inp.c_str());\n+            return 1;\n+        }\n+\n+        t_quantize_us = ggml_time_us() - t_start_us;\n+    }\n+\n+    // report timing\n+    {\n+        const int64_t t_main_end_us = ggml_time_us();\n+\n+        printf(\"\\n\");\n+        printf(\"%s: quantize time = %8.2f ms\\n\", __func__, t_quantize_us/1000.0f);\n+        printf(\"%s:    total time = %8.2f ms\\n\", __func__, (t_main_end_us - t_main_start_us)/1000.0f);\n+    }\n+\n+    return 0;\n+}\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "- **Bug:** The commit includes a call to `ggml_time_us()` without initializing `timer_freq` via `ggml_time_init()`, leading to a potential division by zero error.\n\n- **Compatibility Issue:** The current implementation does not support bfloat16 on Mac OS, blocking model conversion.\n\n- **Code Quality:** Examples lack sufficient error handling, particularly for RAM checks when loading models.\n\n- **Action Item:** Verify if Pull Request #139 works with RedPajama; if successful, merge it to reduce code duplication instead of creating new examples.\n\n- **Hash Verification:** Ensure model SHA256 matches the expected value upon download to prevent loading issues. \n\n- **Next Steps:** Investigate model loading failures and consider consolidating related model implementations to improve maintainability."
      }
    ],
    "codediff_length": 42959
  },
  {
    "index": 113,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/ggml.c b/src/ggml.c\nindex 3d10dd00d..1eaf17c98 100644\n--- a/src/ggml.c\n+++ b/src/ggml.c\n@@ -4168,10 +4168,9 @@ static inline bool ggml_is_matrix(const struct ggml_tensor * tensor) {\n static inline bool ggml_can_mul_mat(const struct ggml_tensor * t0, const struct ggml_tensor * t1) {\n     static_assert(GGML_MAX_DIMS == 4, \"GGML_MAX_DIMS is not 4 - update this function\");\n \n-    return\n-        (t0->ne[0] == t1->ne[0])  &&\n-        (t0->ne[2] == t1->ne[2])  &&\n-        (t0->ne[3] == t1->ne[3]);\n+    return (t0->ne[0]           == t1->ne[0])  &&\n+           (t1->ne[2]%t0->ne[2] == 0)          && // verify t0 is broadcastable\n+           (t1->ne[3]%t0->ne[3] == 0);\n }\n \n static inline bool ggml_can_out_prod(const struct ggml_tensor * t0, const struct ggml_tensor * t1) {\n@@ -6036,8 +6035,8 @@ struct ggml_tensor * ggml_mul_mat(\n         is_node = true;\n     }\n \n-    const int64_t ne[4] = { a->ne[1], b->ne[1], a->ne[2], b->ne[3] };\n-    struct ggml_tensor * result = ggml_new_tensor(ctx, GGML_TYPE_F32, MIN(a->n_dims, b->n_dims), ne);\n+    const int64_t ne[4] = { a->ne[1], b->ne[1], b->ne[2], b->ne[3] };\n+    struct ggml_tensor * result = ggml_new_tensor(ctx, GGML_TYPE_F32, MAX(a->n_dims, b->n_dims), ne);\n \n     result->op   = GGML_OP_MUL_MAT;\n     result->grad = is_node ? ggml_dup_tensor(ctx, result) : NULL;\n@@ -7173,7 +7172,6 @@ struct ggml_tensor* ggml_conv_2d(\n     int                  d0,\n     int                  d1) {\n \n-    GGML_ASSERT(b->ne[3] == 1);\n     GGML_ASSERT(a->ne[2] == b->ne[2]);\n     bool is_node = false;\n \n@@ -7185,7 +7183,7 @@ struct ggml_tensor* ggml_conv_2d(\n     const int64_t ne[4] = {\n         ggml_calc_conv_output_size(b->ne[0], a->ne[0], s0, p0, d0),\n         ggml_calc_conv_output_size(b->ne[1], a->ne[1], s1, p1, d1),\n-        a->ne[3], 1,\n+        a->ne[3], b->ne[3],\n     };\n     struct ggml_tensor* result = ggml_new_tensor(ctx, GGML_TYPE_F32, 4, ne);\n \n@@ -10641,7 +10639,6 @@ static void ggml_compute_forward_rms_norm_back(\n     }\n }\n \n-\n // ggml_compute_forward_mul_mat\n \n #if defined(GGML_USE_ACCELERATE) || defined(GGML_USE_OPENBLAS)\n@@ -10685,17 +10682,17 @@ static void ggml_compute_forward_mul_mat(\n     const int ith = params->ith;\n     const int nth = params->nth;\n \n-    GGML_ASSERT(ne02 == ne12);\n-    GGML_ASSERT(ne03 == ne13);\n-    GGML_ASSERT(ne2  == ne12);\n-    GGML_ASSERT(ne3  == ne13);\n-\n     const enum ggml_type type = src0->type;\n \n     ggml_vec_dot_t    const vec_dot               = type_traits[type].vec_dot;\n     enum ggml_type    const vec_dot_type          = type_traits[type].vec_dot_type;\n     ggml_from_float_t const from_float_to_vec_dot = type_traits[vec_dot_type].from_float;\n \n+    GGML_ASSERT(ne0 == ne01);\n+    GGML_ASSERT(ne1 == ne11);\n+    GGML_ASSERT(ne2 == ne12);\n+    GGML_ASSERT(ne3 == ne13);\n+\n     // we don't support permuted src0 or src1\n     GGML_ASSERT(nb00 == GGML_TYPE_SIZE[type]);\n     GGML_ASSERT(nb10 == sizeof(float));\n@@ -10706,16 +10703,16 @@ static void ggml_compute_forward_mul_mat(\n     GGML_ASSERT(nb1 <= nb2);\n     GGML_ASSERT(nb2 <= nb3);\n \n-    GGML_ASSERT(ne0 == ne01);\n-    GGML_ASSERT(ne1 == ne11);\n-    GGML_ASSERT(ne2 == ne02);\n-    GGML_ASSERT(ne3 == ne03);\n-\n     // nb01 >= nb00 - src0 is not transposed\n     //   compute by src0 rows\n \n #if defined(GGML_USE_CLBLAST)\n     if (ggml_cl_can_mul_mat(src0, src1, dst)) {\n+        // TODO: handle case when src0 is broadcast-able into src1 across 2nd,3rd dimension\n+        //       ref: https://github.com/ggerganov/ggml/pull/224\n+        GGML_ASSERT(ne02 == ne12);\n+        GGML_ASSERT(ne03 == ne13);\n+\n         if (params->ith == 0 && params->type == GGML_TASK_COMPUTE) {\n             ggml_cl_mul_mat(src0, src1, dst, params->wdata, params->wsize);\n         }\n@@ -10725,6 +10722,11 @@ static void ggml_compute_forward_mul_mat(\n \n #if defined(GGML_USE_ACCELERATE) || defined(GGML_USE_OPENBLAS)\n     if (ggml_compute_forward_mul_mat_use_blas(src0, src1, dst)) {\n+        // TODO: handle case when src0 is broadcast-able into src1 across 2nd,3rd dimension\n+        //       ref: https://github.com/ggerganov/ggml/pull/224\n+        GGML_ASSERT(ne02 == ne12);\n+        GGML_ASSERT(ne03 == ne13);\n+\n         if (params->ith != 0) {\n             return;\n         }\n@@ -10794,41 +10796,38 @@ static void ggml_compute_forward_mul_mat(\n         return;\n     }\n \n-    // parallelize by src0 rows using ggml_vec_dot_q\n+    // parallelize by src0 rows\n+    const int64_t dr = (ne01 + nth - 1)/nth;\n \n-    // total rows in src0\n-    const int nr = ne01*ne02*ne03;\n+    const int64_t ir10 = dr*ith;\n+    const int64_t ir11 = MIN(ir10 + dr, ne01);\n \n-    // rows per thread\n-    const int dr = (nr + nth - 1)/nth;\n-\n-    // row range for this thread\n-    const int ir0 = dr*ith;\n-    const int ir1 = MIN(ir0 + dr, nr);\n+    // src1 rows\n+    const int64_t nr1 = ne11*ne12*ne13;\n \n     void * wdata = (src1->type == vec_dot_type) ? src1->data : params->wdata;\n-    const size_t row_size = ne00*GGML_TYPE_SIZE[vec_dot_type]/GGML_BLCK_SIZE[vec_dot_type];\n+    const size_t row_size = ne10*GGML_TYPE_SIZE[vec_dot_type]/GGML_BLCK_SIZE[vec_dot_type];\n \n-    for (int ir = ir0; ir < ir1; ++ir) {\n-        // src0 indices\n-        const int i03 = ir/(ne02*ne01);\n-        const int i02 = (ir - i03*ne02*ne01)/ne01;\n-        const int i01 = (ir - i03*ne02*ne01 - i02*ne01);\n+    for (int64_t ir1 = 0; ir1 < nr1; ++ir1) {\n+        const int64_t i13 = (ir1/(ne12*ne11));\n+        const int64_t i12 = (ir1 - i13*ne12*ne11)/ne11;\n+        const int64_t i11 = (ir1 - i13*ne12*ne11 - i12*ne11);\n \n-        const int i13 = i03;\n-        const int i12 = i02;\n+        const int64_t ir0 = (ir1/ne11)%(ne02*ne03);\n+        const int64_t i03 = (ir0/(ne02));\n+        const int64_t i02 = (ir0 - i03*ne02);\n \n-        const int i0 = i01;\n-        const int i2 = i02;\n-        const int i3 = i03;\n+        const int64_t i1 = i11;\n+        const int64_t i2 = i12;\n+        const int64_t i3 = i13;\n \n-        void * src0_row = (void *) ((char *) src0->data + (i01*nb01 + i02*nb02 + i03*nb03));\n-        char * src1_col =          ((char *)      wdata + (      (0 + i12*ne11 + i13*ne12*ne11)*row_size));\n+        const char * src0_row = (const char *) src0->data + (  0 + i02*nb02 + i03*nb03     );\n+        const char * src1_col = (const char *)      wdata + (i11 + i12*ne11 + i13*ne12*ne11)*row_size;\n \n-        float * dst_col = (float *) ((char *) dst->data + (i0*nb0 + 0*nb1 + i2*nb2 + i3*nb3));\n+        float * dst_col = (float *) ((char *) dst->data + (i1*nb1 + i2*nb2 + i3*nb3));\n \n-        for (int64_t ic = 0; ic < ne11; ++ic) {\n-            vec_dot(ne00, &dst_col[ic*ne0], src0_row, (void *) (src1_col + ic*row_size));\n+        for (int64_t ir = ir10; ir < ir11; ++ir) {\n+            vec_dot(ne00, &dst_col[ir], src0_row + ir*nb01, src1_col);\n         }\n     }\n \n@@ -13013,16 +13012,18 @@ static void ggml_compute_forward_conv_2d_sk_p0_f16_f32(\n         {\n             ggml_fp16_t * const wdata = (ggml_fp16_t *) params->wdata + 0;\n \n-            for (int i12 = 0; i12 < ne12; i12++) {\n-                const float * const src = (float *)((char *) src1->data + i12*nb12);\n-                ggml_fp16_t * dst_data = wdata;\n-\n-                for (int i1 = 0; i1 < ne1; i1++) {\n-                    for (int i0 = 0; i0 < ne0; i0++) {\n-                        for (int ik1 = 0; ik1 < nk1; ik1++) {\n-                            for (int ik0 = 0; ik0 < nk0; ik0++) {\n-                                dst_data[(i1*ne0 + i0)*ew0 + i12*(nk0*nk1) + ik1*nk0 + ik0] =\n-                                    GGML_FP32_TO_FP16(src[(i1*nk1 + ik1)*ne10 + (i0*nk0 + ik0)]);\n+            for (int i13 = 0; i13 < ne13; i13++) {\n+                for (int i12 = 0; i12 < ne12; i12++) {\n+                    const float * const src = (float *)((char *) src1->data + i13*nb13 + i12*nb12);\n+                    ggml_fp16_t * dst_data = wdata + i13*(ne1*ne0*ew0);\n+\n+                    for (int i1 = 0; i1 < ne1; i1++) {\n+                        for (int i0 = 0; i0 < ne0; i0++) {\n+                            for (int ik1 = 0; ik1 < nk1; ik1++) {\n+                                for (int ik0 = 0; ik0 < nk0; ik0++) {\n+                                    dst_data[(i1*ne0 + i0)*ew0 + i12*(nk0*nk1) + ik1*nk0 + ik0] =\n+                                        GGML_FP32_TO_FP16(src[(i1*nk1 + ik1)*ne10 + (i0*nk0 + ik0)]);\n+                                }\n                             }\n                         }\n                     }\n@@ -13049,14 +13050,16 @@ static void ggml_compute_forward_conv_2d_sk_p0_f16_f32(\n \n     ggml_fp16_t * const wdata = (ggml_fp16_t *) params->wdata + 0;\n \n-    for (int i2 = ip0; i2 < ip1; i2++) {\n-        float * dst_data = (float *)((char *) dst->data + i2*nb2);\n-\n-        for (int i1 = 0; i1 < ne1; ++i1) {\n-            for (int i0 = 0; i0 < ne0; ++i0) {\n-                ggml_vec_dot_f16(ew0, dst_data + i1*ne0 + i0,\n-                        (ggml_fp16_t *) ((char *) src0->data + i2*nb03),\n-                        (ggml_fp16_t *)                wdata + (i1*ne0 + i0)*ew0);\n+    for (int i3 = 0; i3 < ne3; i3++) {\n+        for (int i2 = ip0; i2 < ip1; i2++) {\n+            float * dst_data = (float *)((char *) dst->data + i3*nb3 + i2*nb2);\n+\n+            for (int i1 = 0; i1 < ne1; ++i1) {\n+                for (int i0 = 0; i0 < ne0; ++i0) {\n+                    ggml_vec_dot_f16(ew0, dst_data + i1*ne0 + i0,\n+                            (ggml_fp16_t *) ((char *) src0->data + i2*nb03),\n+                            (ggml_fp16_t *)                wdata + i3*nb3 + (i1*ne0 + i0)*ew0);\n+                }\n             }\n         }\n     }\n@@ -16558,8 +16561,6 @@ struct ggml_cplan ggml_graph_plan(struct ggml_cgraph * cgraph, int n_threads) {\n                 {\n                     n_tasks = n_threads;\n \n-                    GGML_ASSERT(node->src[1]->ne[3] == 1);\n-\n                     const int64_t ne00 = node->src[0]->ne[0]; // W\n                     const int64_t ne01 = node->src[0]->ne[1]; // H\n                     const int64_t ne02 = node->src[0]->ne[2]; // C\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. `ggml_norm` produces different results for identical samples in a batch. The sum of normed tensors should reflect the number of identical samples, indicating a bug in `ggml_norm` affecting output vectors.\n\n2. The issue was traced to an incorrect offset calculation in `conv_2d_sk_p0`, which needs correction to ensure consistent outputs for batched inputs. \n\n3. Debugging with tensor sums can be misleading; consider using more reliable methods.\n\n4. Batch inference implementation for text encoding in `clip.cpp` is needed, with attention to handling varying lengths.\n\n5. A new benchmark utility shows a 1.4x speedup for batch inference, indicating potential for further performance enhancements. \n\n6. Resolve current conflicts and prepare for review."
      }
    ],
    "codediff_length": 10044
  },
  {
    "index": 114,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 8802602541..e181b28c9e 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -268,6 +268,7 @@ set(DROGON_SOURCES\n     lib/src/RateLimiter.cc\n     lib/src/RealIpResolver.cc\n     lib/src/SecureSSLRedirector.cc\n+    lib/src/Redirector.cc\n     lib/src/SessionManager.cc\n     lib/src/SlashRemover.cc\n     lib/src/SlidingWindowRateLimiter.cc\n@@ -710,6 +711,7 @@ install(FILES ${DROGON_MONITORING_HEADERS}\n \n set(DROGON_PLUGIN_HEADERS\n     lib/inc/drogon/plugins/Plugin.h\n+    lib/inc/drogon/plugins/Redirector.h\n     lib/inc/drogon/plugins/SecureSSLRedirector.h\n     lib/inc/drogon/plugins/AccessLogger.h\n     lib/inc/drogon/plugins/RealIpResolver.h\ndiff --git a/lib/inc/drogon/HttpRequest.h b/lib/inc/drogon/HttpRequest.h\nindex a40fafa07c..e1728200b9 100644\n--- a/lib/inc/drogon/HttpRequest.h\n+++ b/lib/inc/drogon/HttpRequest.h\n@@ -416,6 +416,7 @@ class DROGON_EXPORT HttpRequest\n \n     /// Set the path of the request\n     virtual void setPath(const std::string &path) = 0;\n+    virtual void setPath(std::string &&path) = 0;\n \n     /**\n      * @brief The default behavior is to encode the value of setPath\ndiff --git a/lib/inc/drogon/plugins/Redirector.h b/lib/inc/drogon/plugins/Redirector.h\nnew file mode 100644\nindex 0000000000..4bbea15dbf\n--- /dev/null\n+++ b/lib/inc/drogon/plugins/Redirector.h\n@@ -0,0 +1,119 @@\n+/**\n+ *  @file Redirector.h\n+ *  @author An Tao\n+ *\n+ *  Copyright 2018, An Tao.  All rights reserved.\n+ *  https://github.com/an-tao/drogon\n+ *  Use of this source code is governed by a MIT license\n+ *  that can be found in the License file.\n+ *\n+ *  Drogon\n+ *\n+ */\n+\n+#pragma once\n+\n+#include <drogon/plugins/Plugin.h>\n+#include <drogon/HttpRequest.h>\n+#include <vector>\n+\n+namespace drogon\n+{\n+namespace plugin\n+{\n+/**\n+ * @brief The RedirectorHandler is a function object that can be registered to\n+ * the Redirector plugin. It is used to redirect requests to proper URLs. Users\n+ * can modify the protocol, host and path of the request. If a false value is\n+ * returned, the request will be considered as invalid and a 404 response will\n+ * be sent to the client.\n+ */\n+using RedirectorHandler =\n+    std::function<bool(const drogon::HttpRequestPtr &,\n+                       std::string &,  //\"http://\" or \"https://\"\n+                       std::string &,  // host\n+                       bool &)>;       // path changed or not\n+/**\n+ * @brief The PathRewriteHandler is a function object that can be registered to\n+ * the Redirector plugin. It is used to rewrite the path of the request. The\n+ * Redirector plugin will call all registered PathRewriteHandlers in the order\n+ * of registration. If one or more handlers return true, the request will be\n+ * redirected to the new path.\n+ */\n+using PathRewriteHandler = std::function<bool(const drogon::HttpRequestPtr &)>;\n+\n+/**\n+ * @brief The ForwardHandler is a function object that can be registered to the\n+ * Redirector plugin. It is used to forward the request to next processing steps\n+ * in the framework. The Redirector plugin will call all registered\n+ * ForwardHandlers in the order of registration. Users can use this handler to\n+ * change the request path or any other part of the request.\n+ */\n+using ForwardHandler = std::function<void(const drogon::HttpRequestPtr &)>;\n+\n+/**\n+ * @brief This plugin is used to redirect requests to proper URLs. It is a\n+ * helper plugin for other plugins, e.g. SlashRemover.\n+ * Users can register a handler to this plugin to redirect requests. All\n+ * handlers will be called in the order of registration.\n+ * The json configuration is as follows:\n+ *\n+ * @code\n+   {\n+      \"name\": \"drogon::plugin::Redirector\",\n+      \"dependencies\": [],\n+      \"config\": {\n+      }\n+   }\n+   @endcode\n+ *\n+ */\n+class DROGON_EXPORT Redirector : public drogon::Plugin<Redirector>,\n+                                 public std::enable_shared_from_this<Redirector>\n+{\n+  public:\n+    Redirector()\n+    {\n+    }\n+\n+    void initAndStart(const Json::Value &config) override;\n+    void shutdown() override;\n+\n+    void registerRedirectHandler(RedirectorHandler &&handler)\n+    {\n+        handlers_.emplace_back(std::move(handler));\n+    }\n+\n+    void registerRedirectHandler(const RedirectorHandler &handler)\n+    {\n+        handlers_.emplace_back(handler);\n+    }\n+\n+    void registerPathRewriteHandler(PathRewriteHandler &&handler)\n+    {\n+        pathRewriteHandlers_.emplace_back(std::move(handler));\n+    }\n+\n+    void registerPathRewriteHandler(const PathRewriteHandler &handler)\n+    {\n+        pathRewriteHandlers_.emplace_back(handler);\n+    }\n+\n+    void registerForwardHandler(ForwardHandler &&handler)\n+    {\n+        forwardHandlers_.emplace_back(std::move(handler));\n+    }\n+\n+    void registerForwardHandler(const ForwardHandler &handler)\n+    {\n+        forwardHandlers_.emplace_back(handler);\n+    }\n+\n+  private:\n+    std::vector<RedirectorHandler> handlers_;\n+    std::vector<PathRewriteHandler> pathRewriteHandlers_;\n+    std::vector<ForwardHandler> forwardHandlers_;\n+};\n+\n+}  // namespace plugin\n+}  // namespace drogon\n\\ No newline at end of file\ndiff --git a/lib/inc/drogon/plugins/SecureSSLRedirector.h b/lib/inc/drogon/plugins/SecureSSLRedirector.h\nindex 704ee011bf..0493e733bf 100644\n--- a/lib/inc/drogon/plugins/SecureSSLRedirector.h\n+++ b/lib/inc/drogon/plugins/SecureSSLRedirector.h\n@@ -25,7 +25,7 @@ namespace plugin\n  * @code\n    {\n       \"name\": \"drogon::plugin::SecureSSLRedirector\",\n-      \"dependencies\": [],\n+      \"dependencies\": [\"drogon::plugin::Redirector\"],\n       \"config\": {\n             \"ssl_redirect_exempt\": [\"^/.*\\\\.jpg\", ...],\n             \"secure_ssl_host\": \"localhost:8849\"\n@@ -64,8 +64,12 @@ class DROGON_EXPORT SecureSSLRedirector\n     void shutdown() override;\n \n   private:\n-    HttpResponsePtr redirectingAdvice(const HttpRequestPtr &) const;\n-    HttpResponsePtr redirectToSSL(const HttpRequestPtr &) const;\n+    bool redirectingAdvice(const HttpRequestPtr &,\n+                           std::string &,\n+                           std::string &) const;\n+    bool redirectToSSL(const HttpRequestPtr &,\n+                       std::string &,\n+                       std::string &) const;\n \n     std::regex exemptPegex_;\n     bool regexFlag_{false};\ndiff --git a/lib/inc/drogon/plugins/SlashRemover.h b/lib/inc/drogon/plugins/SlashRemover.h\nindex db5e91caad..27c541aee1 100644\n--- a/lib/inc/drogon/plugins/SlashRemover.h\n+++ b/lib/inc/drogon/plugins/SlashRemover.h\n@@ -27,7 +27,7 @@ namespace drogon::plugin\n  * @code\n   {\n      \"name\": \"drogon::plugin::SlashRemover\",\n-     \"dependencies\": [],\n+     \"dependencies\": [\"drogon::plugin::Redirector\"],\n      \"config\": {\n         // If true, it removes all trailing slashes, e.g.\n ///home// -> ///home\ndiff --git a/lib/src/HttpRequestImpl.h b/lib/src/HttpRequestImpl.h\nindex dde3767b47..1cbb452ab6 100644\n--- a/lib/src/HttpRequestImpl.h\n+++ b/lib/src/HttpRequestImpl.h\n@@ -159,6 +159,11 @@ class HttpRequestImpl : public HttpRequest\n         path_ = path;\n     }\n \n+    void setPath(std::string &&path) override\n+    {\n+        path_ = std::move(path);\n+    }\n+\n     void setPathEncode(bool pathEncode) override\n     {\n         pathEncode_ = pathEncode;\ndiff --git a/lib/src/Redirector.cc b/lib/src/Redirector.cc\nnew file mode 100644\nindex 0000000000..447dac6692\n--- /dev/null\n+++ b/lib/src/Redirector.cc\n@@ -0,0 +1,87 @@\n+/**\n+ *\n+ *  @file Redirector.cc\n+ *  An Tao\n+ *\n+ *  Copyright 2018, An Tao.  All rights reserved.\n+ *  https://github.com/an-tao/drogon\n+ *  Use of this source code is governed by a MIT license\n+ *  that can be found in the License file.\n+ *\n+ *  Drogon\n+ *\n+ */\n+\n+#include <drogon/drogon.h>\n+#include <drogon/plugins/Redirector.h>\n+\n+using namespace drogon;\n+using namespace drogon::plugin;\n+\n+void Redirector::initAndStart(const Json::Value &config)\n+{\n+    auto weakPtr = std::weak_ptr<Redirector>(shared_from_this());\n+    drogon::app().registerSyncAdvice(\n+        [weakPtr](const HttpRequestPtr &req) -> HttpResponsePtr {\n+            auto thisPtr = weakPtr.lock();\n+            if (!thisPtr)\n+            {\n+                return HttpResponsePtr{};\n+            }\n+            std::string protocol, host;\n+            bool pathChanged{false};\n+            for (auto &handler : thisPtr->handlers_)\n+            {\n+                if (!handler(req, protocol, host, pathChanged))\n+                {\n+                    return HttpResponse::newNotFoundResponse();\n+                }\n+            }\n+            for (auto &handler : thisPtr->pathRewriteHandlers_)\n+            {\n+                pathChanged |= handler(req);\n+            }\n+            if (!protocol.empty() || !host.empty() || pathChanged)\n+            {\n+                std::string url;\n+                if (protocol.empty())\n+                {\n+                    if (!host.empty())\n+                    {\n+                        url = req->isOnSecureConnection() ? \"https://\"\n+                                                          : \"http://\";\n+                        url.append(host);\n+                    }\n+                }\n+                else\n+                {\n+                    url = std::move(protocol);\n+                    if (!host.empty())\n+                    {\n+                        url.append(host);\n+                    }\n+                    else\n+                    {\n+                        url.append(req->getHeader(\"host\"));\n+                    }\n+                }\n+                url.append(req->path());\n+                auto &query = req->query();\n+                if (!query.empty())\n+                {\n+                    url.append(\"?\").append(query);\n+                }\n+                return HttpResponse::newRedirectionResponse(url);\n+            }\n+            for (auto &handler : thisPtr->forwardHandlers_)\n+            {\n+                handler(req);\n+            }\n+            return HttpResponsePtr{};\n+        });\n+}\n+\n+void Redirector::shutdown()\n+{\n+    LOG_TRACE << \"Redirector plugin is shutdown!\";\n+}\ndiff --git a/lib/src/SecureSSLRedirector.cc b/lib/src/SecureSSLRedirector.cc\nindex da5d0e3192..f715f3e018 100644\n--- a/lib/src/SecureSSLRedirector.cc\n+++ b/lib/src/SecureSSLRedirector.cc\n@@ -5,6 +5,7 @@\n  */\n #include <drogon/drogon.h>\n #include <drogon/plugins/SecureSSLRedirector.h>\n+#include <drogon/plugins/Redirector.h>\n #include <string>\n \n using namespace drogon;\n@@ -42,14 +43,24 @@ void SecureSSLRedirector::initAndStart(const Json::Value &config)\n     }\n     secureHost_ = config.get(\"secure_ssl_host\", \"\").asString();\n     std::weak_ptr<SecureSSLRedirector> weakPtr = shared_from_this();\n-    app().registerSyncAdvice([weakPtr](const HttpRequestPtr &req) {\n-        auto thisPtr = weakPtr.lock();\n-        if (!thisPtr)\n-        {\n-            return HttpResponsePtr{};\n-        }\n-        return thisPtr->redirectingAdvice(req);\n-    });\n+    auto redirector = drogon::app().getPlugin<Redirector>();\n+    if (!redirector)\n+    {\n+        LOG_ERROR << \"Redirector plugin is not found!\";\n+        return;\n+    }\n+    redirector->registerRedirectHandler(\n+        [weakPtr](const drogon::HttpRequestPtr &req,\n+                  std::string &protocol,\n+                  std::string &host,\n+                  bool &) -> bool {\n+            auto thisPtr = weakPtr.lock();\n+            if (!thisPtr)\n+            {\n+                return false;\n+            }\n+            return thisPtr->redirectingAdvice(req, protocol, host);\n+        });\n }\n \n void SecureSSLRedirector::shutdown()\n@@ -57,60 +68,58 @@ void SecureSSLRedirector::shutdown()\n     /// Shutdown the plugin\n }\n \n-HttpResponsePtr SecureSSLRedirector::redirectingAdvice(\n-    const HttpRequestPtr &req) const\n+bool SecureSSLRedirector::redirectingAdvice(const HttpRequestPtr &req,\n+                                            std::string &protocol,\n+                                            std::string &host) const\n {\n-    if (req->isOnSecureConnection())\n+    if (req->isOnSecureConnection() || protocol == \"https://\")\n     {\n-        return HttpResponsePtr{};\n+        return true;\n     }\n     else if (regexFlag_)\n     {\n         std::smatch regexResult;\n         if (std::regex_match(req->path(), regexResult, exemptPegex_))\n         {\n-            return HttpResponsePtr{};\n+            return true;\n         }\n         else\n         {\n-            return redirectToSSL(req);\n+            return redirectToSSL(req, protocol, host);\n         }\n     }\n     else\n     {\n-        return redirectToSSL(req);\n+        return redirectToSSL(req, protocol, host);\n     }\n }\n \n-HttpResponsePtr SecureSSLRedirector::redirectToSSL(\n-    const HttpRequestPtr &req) const\n+bool SecureSSLRedirector::redirectToSSL(const HttpRequestPtr &req,\n+                                        std::string &protocol,\n+                                        std::string &host) const\n {\n     if (!secureHost_.empty())\n     {\n-        static std::string urlPrefix{\"https://\" + secureHost_};\n-        std::string query{urlPrefix + req->path()};\n-        if (!req->query().empty())\n-        {\n-            query += \"?\" + req->query();\n-        }\n-        return HttpResponse::newRedirectionResponse(query);\n+        host = secureHost_;\n+        protocol = \"https://\";\n+        return true;\n     }\n-    else\n+    else if (host.empty())\n     {\n-        const auto &host = req->getHeader(\"host\");\n-        if (!host.empty())\n+        const auto &reqHost = req->getHeader(\"host\");\n+        if (!reqHost.empty())\n         {\n-            std::string query{\"https://\" + host};\n-            query += req->path();\n-            if (!req->query().empty())\n-            {\n-                query += \"?\" + req->query();\n-            }\n-            return HttpResponse::newRedirectionResponse(query);\n+            protocol = \"https://\";\n+            return true;\n         }\n         else\n         {\n-            return HttpResponse::newNotFoundResponse();\n+            return false;\n         }\n     }\n+    else\n+    {\n+        protocol = \"https://\";\n+        return true;\n+    }\n }\ndiff --git a/lib/src/SlashRemover.cc b/lib/src/SlashRemover.cc\nindex d52f77103a..9582d4f8ce 100644\n--- a/lib/src/SlashRemover.cc\n+++ b/lib/src/SlashRemover.cc\n@@ -1,11 +1,13 @@\n-#include \"drogon/plugins/SlashRemover.h\"\n-#include \"drogon/HttpAppFramework.h\"\n+#include <drogon/plugins/SlashRemover.h>\n+#include <drogon/plugins/Redirector.h>\n+#include <drogon/HttpAppFramework.h>\n #include \"drogon/utils/FunctionTraits.h\"\n #include <functional>\n #include <string>\n+#include <regex>\n \n using namespace drogon;\n-using namespace plugin;\n+using namespace drogon::plugin;\n using std::string;\n \n #define TRAILING_SLASH_REGEX \".+\\\\/$\"\n@@ -64,6 +66,31 @@ static inline void removeExcessiveSlashes(string& url)\n     removeDuplicateSlashes(url);\n }\n \n+static inline bool handleReq(const drogon::HttpRequestPtr& req, int removeMode)\n+{\n+    static const std::regex regex(regexes[removeMode - 1]);\n+    if (std::regex_match(req->path(), regex))\n+    {\n+        string newPath = req->path();\n+        switch (removeMode)\n+        {\n+            case trailing:\n+                removeTrailingSlashes(newPath);\n+                break;\n+            case duplicate:\n+                removeDuplicateSlashes(newPath);\n+                break;\n+            case both:\n+            default:\n+                removeExcessiveSlashes(newPath);\n+                break;\n+        }\n+        req->setPath(std::move(newPath));\n+        return true;\n+    }\n+    return false;\n+}\n+\n void SlashRemover::initAndStart(const Json::Value& config)\n {\n     trailingSlashes_ = config.get(\"remove_trailing_slashes\", true).asBool();\n@@ -73,33 +100,23 @@ void SlashRemover::initAndStart(const Json::Value& config)\n         (trailingSlashes_ * trailing) | (duplicateSlashes_ * duplicate);\n     if (!removeMode)\n         return;\n-    app().registerHandlerViaRegex(\n-        regexes[removeMode - 1],\n-        [removeMode,\n-         this](const HttpRequestPtr& req,\n-               std::function<void(const HttpResponsePtr&)>&& callback) {\n-            string newPath = req->path();\n-            switch (removeMode)\n-            {\n-                case trailing:\n-                    removeTrailingSlashes(newPath);\n-                    break;\n-                case duplicate:\n-                    removeDuplicateSlashes(newPath);\n-                    break;\n-                case both:\n-                default:\n-                    removeExcessiveSlashes(newPath);\n-                    break;\n-            }\n-            if (redirect_)\n-                callback(HttpResponse::newRedirectionResponse(newPath));\n-            else\n-            {\n-                req->setPath(newPath);\n-                app().forward(req, std::move(callback));\n-            }\n-        });\n+    auto redirector = app().getPlugin<Redirector>();\n+    if (!redirector)\n+    {\n+        LOG_ERROR << \"Redirector plugin is not found!\";\n+        return;\n+    }\n+    auto func = [removeMode](const HttpRequestPtr& req) -> bool {\n+        return handleReq(req, removeMode);\n+    };\n+    if (redirect_)\n+    {\n+        redirector->registerPathRewriteHandler(std::move(func));\n+    }\n+    else\n+    {\n+        redirector->registerForwardHandler(std::move(func));\n+    }\n }\n \n void SlashRemover::shutdown()\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Path Handling**: Remove unnecessary `req->setPath(newPath)` in `SlashRemover` if `redirect` is true. Assign only when `redirect` is false and protocol/host haven\u2019t changed.\n\n2. **Execution Order**: Enforce a strict execution order:\n   - 1. `SecureSSLRedirector`\n   - 2. `IPRewriter`\n   - 3. `SubdomainRedirector`\n   - 4. `SlashRemover`\n\n3. **Boolean References**: Pass `redirect` and `forward` booleans as references to handlers. Modify them accordingly to allow the redirector to make informed decisions.\n\n4. **Handler Groups**: Organize redirectors into three groups to prioritize execution and reduce redundant checks:\n   - Group 1: Critical redirectors (e.g., `SecureSSLRedirector`)\n   - Group 2: Less critical redirectors (e.g., `SlashRemover`)\n   - Group 3: Forwarders \n\n5. **Consistency Issue**: Address inconsistency in path modification during redirects and forwarding. Ensure that `SlashRemover` correctly handles cases with duplicate slashes based on redirect conditions. \n\nNext steps: Implement the execution order and update handler registration logic, testing for expected forwarding behavior post-redirect."
      }
    ],
    "codediff_length": 17254
  },
  {
    "index": 115,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/qml/filters/fisheye/meta.qml b/src/qml/filters/fisheye/meta.qml\nnew file mode 100644\nindex 0000000000..1f15f77c2a\n--- /dev/null\n+++ b/src/qml/filters/fisheye/meta.qml\n@@ -0,0 +1,27 @@\n+/*\n+ * Copyright (c) 2022 Meltytech, LLC\n+ *\n+ * This program is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+ \n+\n+import QtQuick 2.0\n+import org.shotcut.qml 1.0\n+\n+Metadata {\n+    type: Metadata.Filter\n+    name: qsTr(\"Fisheye\")\n+    mlt_service: 'frei0r.defish0r'\n+    qml: 'ui.qml'\n+}\ndiff --git a/src/qml/filters/fisheye/ui.qml b/src/qml/filters/fisheye/ui.qml\nnew file mode 100644\nindex 0000000000..2ea7414d7f\n--- /dev/null\n+++ b/src/qml/filters/fisheye/ui.qml\n@@ -0,0 +1,833 @@\n+/*\r\n+ * Copyright (c) 2022 Meltytech, LLC\r\n+ *\r\n+ * This program is free software: you can redistribute it and/or modify\r\n+ * it under the terms of the GNU General Public License as published by\r\n+ * the Free Software Foundation, either version 3 of the License, or\r\n+ * (at your option) any later version.\r\n+ *\r\n+ * This program is distributed in the hope that it will be useful,\r\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n+ * GNU General Public License for more details.\r\n+ *\r\n+ * You should have received a copy of the GNU General Public License\r\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\r\n+ */\r\n+\r\n+import QtQuick 2.12\r\n+import QtQuick.Controls 2.12\r\n+import QtQuick.Layouts 1.12\r\n+import Shotcut.Controls 1.0 as Shotcut\r\n+import QtQuick.Controls.Styles 1.1\r\n+\r\n+Item {\r\n+    width: 300\r\n+    height: 228\r\n+    id: mainItemLayout\r\n+    SystemPalette { id: activePalette }\r\n+\r\n+    //plugin input index values\r\n+    property string focalRatioParam: '0'\r\n+    property string deFishParam: '1'\r\n+    property string lensTypeParam: '2'\r\n+    property string scaePresetParam: '3'\r\n+    property string scaleManualParam: '4'\r\n+    property string qualityParam: '5'\r\n+    property string aspectPresetParam: '6'\r\n+    property string aspectManualParam: '7'\r\n+    property string cropParam: '8'\r\n+    property string stretchParam: '9'\r\n+    property string scaleYParam: '10'    \r\n+\r\n+    //default plugin values\r\n+    property double focalRatioDefault: 0.5  //default was 0.0\r\n+    property bool   deFishDefault: false\r\n+    property double lensTypeDefault: 0.6    //default #3\r\n+    property double scalePresetDefault: 0.6 //default #3\r\n+    property double scaleManualDefault: 0.5\r\n+    property double qualityDefault: 0.16\r\n+    property double aspectPresetDefault: 0.0\r\n+    property double aspectManualDefault: 0.5\r\n+    property bool cropDefault: false\r\n+    property double stretchDefault: 0.5\r\n+    property bool superViewDefault: false\r\n+    property double scaleYDefault: 0.5    \r\n+\r\n+    //hide user sliders\r\n+    property bool scaleShowSlider: false\r\n+    property bool aspectShowSlider: false\r\n+    property bool cameraShowNew: false\r\n+    property bool pluginShowNew: false    //hide newer dll features?\r\n+    property bool stretchShowSlider: false\r\n+    property bool scaleYShowSlider: false  \r\n+\r\n+    //combobox presets text index\r\n+    property int iDX_CAMERA: 11\r\n+    property int iDX_WIDE: 12\r\n+    property int iDX_RESULT: 13\r\n+\r\n+    property var defaultParameters: [focalRatioParam,deFishParam,lensTypeParam,scaePresetParam,\r\n+                scaleManualParam,qualityParam,aspectPresetParam,aspectManualParam, cropParam, stretchParam, scaleYParam]\r\n+    \r\n+    property bool blockUpdate: true\r\n+    \r\n+    //todo: no cropped action versions yet\r\n+    //preset data. used for comboboxes.\r\n+    function getPresetData(index) {\r\n+        switch (index) {\r\n+            //Action\r\n+            // tries to keep all 4 borders in frame. straighten left/right edge. zoomed center, makes motion look faster\r\n+            //\r\n+            //Focused\r\n+            // close match gopro studio, trimed left/right edges, centre zoom slightly, makes motion look faster\r\n+            //\r\n+            //Linear\r\n+            // minimal distortion at frame centre. edges have increased croped to suit\r\n+\r\n+\r\n+            //HERO3\r\n+            case  0: return [0.736, true, lensValue(4), scalePreset(1), scaleManual(0.000), qualityIndex(2), aspectPreset(1), aspectManual(0.000),  false, dynamicStretch(0.0), scaleY(0.00), 'HERO3 1080', 'Wide', 'Focus']\r\n+\r\n+            //HERO4 1080 (medium)\r\n+            case  1: return [0.634, true, lensValue(1), scalePreset(4), scaleManual(0.011), qualityIndex(2), aspectPreset(5), aspectManual(-0.07), false, dynamicStretch(0.0), scaleY(0.12), 'HERO4 1080', 'Medium', 'Action']\r\n+            case  2: return [0.643, true, lensValue(1), scalePreset(1), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.01), false, dynamicStretch(0.0), scaleY(0.00), 'HERO4 1080', 'Medium', 'Focus']\r\n+            case  3: return [0.685, true, lensValue(4), scalePreset(2), scaleManual(0.000), qualityIndex(2), aspectPreset(1), aspectManual(-0.00), false, dynamicStretch(0.0), scaleY(0.00), 'HERO4 1080', 'Medium', 'Linear']\r\n+            //HERO4 1080 (wide)\r\n+            case  4: return [0.700, true, lensValue(1), scalePreset(4), scaleManual(0.019), qualityIndex(2), aspectPreset(5), aspectManual(-0.01), false, dynamicStretch(0.0), scaleY(0.23), 'HERO4 1080', 'Wide', 'Action']\r\n+            case  5: return [0.704, true, lensValue(1), scalePreset(1), scaleManual(0.000), qualityIndex(2), aspectPreset(1), aspectManual(-0.00), false, dynamicStretch(0.0), scaleY(0.00), 'HERO4 1080', 'Wide', 'Focus']\r\n+            case  6: return [0.700, true, lensValue(1), scalePreset(2), scaleManual(0.000), qualityIndex(2), aspectPreset(1), aspectManual(-0.00), false, dynamicStretch(0.0), scaleY(0.00), 'HERO4 1080', 'Wide', 'Linear']\r\n+            //HERO4 1080 (superview)\r\n+            case  7: return [0.725, true, lensValue(1), scalePreset(4), scaleManual(0.038), qualityIndex(2), aspectPreset(5), aspectManual(-0.23), false, dynamicStretch(-0.14), scaleY(0.15), 'HERO4 1080', 'SuperView', 'Action']\r\n+            case  8: return [0.737, true, lensValue(1), scalePreset(1), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.25), false, dynamicStretch(-0.14), scaleY(0.00), 'HERO4 1080', 'SuperView', 'Focus']\r\n+            case  9: return [0.725, true, lensValue(1), scalePreset(2), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.25), false, dynamicStretch(-0.14), scaleY(0.00), 'HERO4 1080', 'SuperView', 'Linear']        \r\n+            //HERO4 1440\r\n+            case 10: return [0.781, true, lensValue(4), scalePreset(4), scaleManual(0.041), qualityIndex(2), aspectPreset(5), aspectManual(-0.23), false, dynamicStretch(0.0), scaleY(0.18), 'HERO4 1440', 'Wide', 'Action']\r\n+            case 11: return [0.739, true, lensValue(1), scalePreset(1), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.21), false, dynamicStretch(0.0), scaleY(0.00), 'HERO4 1440', 'Wide', 'Focus']\r\n+            case 12: return [0.739, true, lensValue(1), scalePreset(2), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.21), false, dynamicStretch(0.0), scaleY(0.00), 'HERO4 1440', 'Wide', 'Linear']\r\n+            //HERO4 1440 4:3 (videos default saved aspect ratio)\r\n+            case 13: return [0.782, true, lensValue(4), scalePreset(4), scaleManual(0.042), qualityIndex(2), aspectPreset(5), aspectManual(-0.02), false, dynamicStretch(0.0), scaleY(0.18), 'HERO4 1440 4:3', 'Wide', 'Action']\r\n+            case 14: return [0.739, true, lensValue(1), scalePreset(1), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.03), false, dynamicStretch(0.0), scaleY(0.00), 'HERO4 1440 4:3', 'Wide', 'Focus']\r\n+            case 15: return [0.736, true, lensValue(1), scalePreset(2), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.04), false, dynamicStretch(0.0), scaleY(0.00), 'HERO4 1440 4:3', 'Wide', 'Linear']\r\n+ \r\n+            //HERO 5\r\n+            case 16: return [0.730, true, lensValue(4), scalePreset(2), scaleManual(0.000), qualityIndex(2), aspectPreset(1), aspectManual(-0.00), false, dynamicStretch(0.0), scaleY(0.00), 'HERO5 1080', 'Wide', 'Linear']\r\n+            case 17: return [0.696, true, lensValue(4), scalePreset(2), scaleManual(0.000), qualityIndex(2), aspectPreset(1), aspectManual(-0.00), false, dynamicStretch(0.0), scaleY(0.00), 'HERO5 1080', 'SuperView', 'Linear']\r\n+\r\n+            //4k CLONE\r\n+            case 18: return [0.494, true, lensValue(1), scalePreset(1), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.41), false, dynamicStretch(0.0), scaleY(0.00), '4K CLONE 1080p', 'Wide', 'Action']\r\n+            case 19: return [0.643, true, lensValue(1), scalePreset(1), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.01), false, dynamicStretch(0.0), scaleY(0.00), '4K CLONE 1080p', 'Wide', 'Focus']\r\n+            case 20: return [0.695, true, lensValue(4), scalePreset(2), scaleManual(0.000), qualityIndex(2), aspectPreset(1), aspectManual(-0.00), false, dynamicStretch(0.0), scaleY(0.00), '4K CLONE 1080p', 'Wide', 'Linear']\r\n+\r\n+            case 21: return [0.442, true, lensValue(1), scalePreset(1), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.14), false, dynamicStretch(0.0), scaleY(0.00), '4K CLONE 720p',  'Medium', 'Focus']\r\n+            case 22: return [0.531, true, lensValue(4), scalePreset(2), scaleManual(0.000), qualityIndex(2), aspectPreset(5), aspectManual(-0.21), false, dynamicStretch(0.0), scaleY(0.00), '4K CLONE 720p', 'Medium', 'Linear']\r\n+            //               focal, defish, lens,       scalePreset,    scaleManual,        interpolation,   A/R_preset,      A/R_manual,          crop,  fix stretch,         scaleY,        camera, qsTr(mode), qsTr(result)\r\n+        }\r\n+\r\n+        return '' //done\r\n+    }\r\n+\r\n+    //set UI control values\r\n+    function setControlData() {\r\n+        var activeIndex\r\n+\r\n+        // #0 Focal Ratio\r\n+        focalRatioSlider.value = filter.getDouble(focalRatioParam)\r\n+\r\n+        // #1 Fish or Defish\r\n+        if (filter.get(deFishParam) === '1')\r\n+             fisheyeRemoveButton.checked = true\r\n+        else\r\n+            fisheyeAddButton.checked = true\r\n+\r\n+        // #2 Mapping function (lens type)\r\n+        lensCombo.currentIndex = indexFromFloat(lensTypeParam, lensCombo.count) - 1\r\n+\r\n+        // #3 Scaling method\r\n+        activeIndex = indexFromFloat(scaePresetParam, scaleCombo.count )\r\n+        scaleCombo.currentIndex = activeIndex - 1\r\n+        scaleShowSlider = (activeIndex == scaleCombo.count) //only show custom slider when last option used\r\n+\r\n+        // #4 Manual Scale\r\n+        scaleManualSlider.value = filter.getDouble(scaleManualParam) - 0.5\r\n+\r\n+        // #5 interpolation quality\r\n+        qualityCombo.currentIndex = indexFromFloat(qualityParam, qualityCombo.count) - 1\r\n+\r\n+        // #6 Pixel aspect ratio presets\r\n+        activeIndex = indexFromFloat(aspectPresetParam, aspectCombo.count)\r\n+        aspectCombo.currentIndex = activeIndex - 1\r\n+        aspectShowSlider = (activeIndex == aspectCombo.count) //only show custom slider when last option used\r\n+\r\n+        // #7 Manual Pixel Aspect ratio\r\n+        aspectManualSlider.value = filter.getDouble(aspectManualParam) - 0.5\r\n+\r\n+        // #8 crop\r\n+        cropCheckBox.checked = (filter.get(cropParam) === '1')\r\n+\r\n+        // #9 stretch\r\n+        stretchSlider.value = filter.getDouble(stretchParam) - 0.5\r\n+        stretchCheckBox.checked = (stretchSlider.value !== 0.0)\r\n+        stretchShowSlider = stretchCheckBox.checked\r\n+        \r\n+        // #10 scale Y\r\n+        scaleYSlider.value = filter.getDouble(scaleYParam) - 0.5\r\n+        scaleYCheckBox.checked = (scaleYSlider.value !== 0.0)\r\n+        scaleYShowSlider = scaleYCheckBox.checked\r\n+\r\n+        setScollbarHeight()\r\n+    }\r\n+\r\n+    //set plugin values\r\n+    function setPluginData(idx0, idx1, idx2, idx3, idx4, idx5, idx6, idx7, idx8, idx9, idx10) {\r\n+        filter.set(focalRatioParam, idx0)   // focal ratio\r\n+        filter.set(deFishParam, idx1)       // add/remove fisheye\r\n+        filter.set(lensTypeParam, idx2)     // Lens type\r\n+        filter.set(scaePresetParam, idx3)   // scale Presets\r\n+        filter.set(scaleManualParam, idx4)  // scale manual\r\n+        filter.set(qualityParam, idx5)      // Filter\r\n+        filter.set(aspectPresetParam, idx6) // A/R Presets\r\n+        filter.set(aspectManualParam, idx7) // A/R Manual\r\n+        filter.set(cropParam, idx8)         // crop\r\n+        filter.set(stretchParam, idx9)      // stretch\r\n+        filter.set(scaleYParam, idx10)      // scaleY \r\n+    }\r\n+\r\n+    //fix scrollbar height when dynamic slider visability changes\r\n+    function setScollbarHeight(){\r\n+        mainItemLayout.height = 228\r\n+        mainItemLayout.height += stretchShowSlider? 26: 0\r\n+        mainItemLayout.height += scaleShowSlider? 26: 0\r\n+        mainItemLayout.height += aspectShowSlider? 26: 0\r\n+        mainItemLayout.height += cameraShowNew? 26*4: 0\r\n+        mainItemLayout.height += scaleYShowSlider? 26: 0\r\n+    }\r\n+\r\n+    //get text string from presets\r\n+    function getPresetName(index, strIdx) {\r\n+        var v_ret = getPresetData(index)\r\n+        if (v_ret !== '') {\r\n+            if (strIdx == iDX_CAMERA)\r\n+                return v_ret[strIdx]\r\n+            else\r\n+                return qsTr(v_ret[strIdx]) //language on 'mode' and 'results'\r\n+        }\r\n+        return v_ret\r\n+    }\r\n+\r\n+    //fill combobox 'camera'\r\n+    function fillCameraCombo() {\r\n+        var a_list = [''] //start blank\r\n+        var v_more = true\r\n+        var v_ret = ''\r\n+        var i = 0\r\n+\r\n+        do {\r\n+            v_ret = getPresetName(i, iDX_CAMERA)\r\n+            if (v_ret !== ''){\r\n+                if (a_list.indexOf(v_ret) === -1)\r\n+                    a_list.push(v_ret) //append unique camera\r\n+            } else {\r\n+                v_more = false\r\n+            }\r\n+\r\n+            i += 1\r\n+        } while(v_more)\r\n+\r\n+        cameraCombo.model = a_list\r\n+        fillModeCombo()\r\n+\r\n+    }\r\n+    //fill combobox 'camera modes'\r\n+    function fillModeCombo() {\r\n+        var a_list = []\r\n+        var v_more = true\r\n+        var v_ret = ''\r\n+        var i = 0\r\n+        var v_cam = cameraCombo.currentText\r\n+        \r\n+        if (v_cam === '') return\r\n+\r\n+        do {\r\n+            v_ret = getPresetName(i, iDX_CAMERA)\r\n+            if (v_ret !== '' ){\r\n+                if (v_ret === v_cam) {\r\n+                    v_ret = getPresetName(i, iDX_WIDE)\r\n+                    if (a_list.indexOf(v_ret) === -1){\r\n+                        a_list.push(v_ret) //append unique modes\r\n+                    }\r\n+                }\r\n+            } else {\r\n+                v_more = false\r\n+            }\r\n+            i += 1\r\n+        } while(v_more)\r\n+\r\n+        camModeCombo.model = a_list\r\n+        fillResultsCombo()\r\n+    }\r\n+\r\n+    //fill combobox 'results'\r\n+    function fillResultsCombo()  {\r\n+        var a_list = []\r\n+        var v_more = true\r\n+        var v_ret = ''\r\n+        var i = 0\r\n+        var v_cam = cameraCombo.currentText\r\n+        var v_mode = camModeCombo.currentText\r\n+\r\n+        do {\r\n+            v_ret = getPresetName(i, iDX_CAMERA)\r\n+            if (v_ret !== '' ){\r\n+                if (   v_cam === v_ret //match camera\r\n+                    && v_mode === getPresetName(i, iDX_WIDE)) //match mode\r\n+                {\r\n+                    a_list.push(getPresetName(i, iDX_RESULT)) //append unique results\r\n+                }\r\n+            } else {\r\n+                v_more = false\r\n+            }\r\n+            i += 1\r\n+        } while(v_more)\r\n+\r\n+        resultCombo.model = a_list\r\n+    }\r\n+\r\n+    //update plugin/ui with preset data\r\n+    function sendPresetData(index){\r\n+        var v_ret = getPresetData(index)\r\n+        setPluginData(v_ret[0], v_ret[1], v_ret[2], v_ret[3], v_ret[4], v_ret[5], v_ret[6], v_ret[7], v_ret[8], v_ret[9], v_ret[10])\r\n+        setControlData()\r\n+    }\r\n+    //'Apply' button pressed\r\n+    function setCameraData(){\r\n+        var v_more = true\r\n+        var v_cam = cameraCombo.currentText\r\n+        var v_mode = camModeCombo.currentText\r\n+        var v_result = resultCombo.currentText\r\n+        var i = 0\r\n+        var v_ret = ''\r\n+\r\n+        do {\r\n+            v_ret = getPresetName(i, iDX_CAMERA)\r\n+            if (v_ret !== '' ){\r\n+                if (   v_cam === v_ret //match camera\r\n+                    && v_mode === getPresetName(i, iDX_WIDE) //match mode\r\n+                    && v_result === getPresetName(i, iDX_RESULT)) //match result\r\n+                {\r\n+                    sendPresetData(i)\r\n+                    v_more = false\r\n+                }\r\n+            } else {\r\n+                v_more = false\r\n+            }\r\n+            i += 1\r\n+        } while(v_more)\r\n+    }\r\n+\r\n+    //lens presets\r\n+    function lensValue(index) { return floatFromIndex(index, lensCombo.count) }\r\n+    //scale presets\r\n+    function scalePreset(index) { return floatFromIndex(index, scaleCombo.count) }\r\n+    //scale manual\r\n+    function scaleManual(fValue) { return fValue + 0.5 }\r\n+    //quality presets\r\n+    function qualityIndex(index) { return floatFromIndex(index, qualityCombo.count) }\r\n+    //aspect ratio presets\r\n+    function aspectPreset(index) { return floatFromIndex(index, aspectCombo.count) }\r\n+    //aspect ratio manual\r\n+    function aspectManual(fValue) { return fValue + 0.5 }    \r\n+    //dynamic stretch\r\n+    function dynamicStretch(fValue) { return fValue + 0.5 }\r\n+    //scale Y preset\r\n+    function scaleY(fValue) { return fValue + 0.5 }    \r\n+\r\n+    //calculate a float for plugin. 1-based\r\n+    function floatFromIndex(idx, max) {\r\n+        if (idx < 1)\r\n+            idx = 1\r\n+        if (idx > max)\r\n+            idx = max\r\n+        return ((1 / (max-1)) * (idx-1)).toPrecision(6)\r\n+    }\r\n+\r\n+    //convert float to int for UI inputs. 1-based\r\n+    function indexFromFloat(idx, max) {\r\n+        var v_rng = 1 / max\r\n+        var v_plug = filter.getDouble(idx)\r\n+        for (var i = 1; i < max; i++) {\r\n+            if (v_plug < (v_rng * i)) {\r\n+                return i\r\n+            }\r\n+        }\r\n+        return max\r\n+    }\r\n+\r\n+    //index for reset button. 1-based\r\n+    function setDefaultIndex(value, max){\r\n+        var v_rng = 1 / max\r\n+        for (var i = 1; i < max; i++) {\r\n+            if (value < (v_rng * i))\r\n+                return i\r\n+        }\r\n+        return max\r\n+    }\r\n+\r\n+    //set presets\r\n+    function setPresetData() {\r\n+        var v_more = true\r\n+        var v_ret = ''\r\n+        var i = 0\r\n+\r\n+        do {\r\n+            v_ret = getPresetData(i)\r\n+            if (v_ret !== '' ){\r\n+                setPluginData(v_ret[0], v_ret[1], v_ret[2], v_ret[3], v_ret[4], v_ret[5], v_ret[6], v_ret[7], v_ret[8], v_ret[9], v_ret[10])\r\n+                filter.savePreset(preset.parameters, qsTr(v_ret[iDX_CAMERA]+ ' ' +qsTr(v_ret[iDX_WIDE]) + ' (' +qsTr(v_ret[iDX_RESULT])+')'))\r\n+            } else {\r\n+                v_more = false\r\n+            }\r\n+            i += 1\r\n+        } while(v_more)\r\n+    }\r\n+\r\n+    Component.onCompleted: {\r\n+        if (filter.getDouble(scaleYParam) > 0.0) \r\n+            pluginShowNew = true        \r\n+          \r\n+        filter.blockSignals = true\r\n+        if (filter.isNew) {\r\n+            setPresetData()\r\n+\r\n+            // save (default) in preset dropdown\r\n+            setPluginData(focalRatioDefault, deFishDefault, lensTypeDefault, scalePresetDefault, scaleManualDefault,\r\n+                            qualityDefault, aspectPresetDefault, aspectManualDefault, cropDefault, stretchDefault, scaleYDefault)\r\n+            filter.savePreset(defaultParameters)\r\n+        }\r\n+        filter.blockSignals = false\r\n+\r\n+        if (cameraShowNew) fillCameraCombo()\r\n+\r\n+        setControlData()\r\n+        blockUpdate = false\r\n+    }\r\n+\r\n+\r\n+    GridLayout {\r\n+        columns: 3\r\n+        anchors.fill: parent\r\n+        anchors.margins: 8\r\n+\r\n+        // Row 1 Preset\r\n+        Label {\r\n+            text: qsTr('Preset')\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        Shotcut.Preset {\r\n+            id: preset\r\n+            parameters: defaultParameters\r\n+            onPresetSelected: setControlData()\r\n+        }\r\n+        Row {width: 6} //blank\r\n+\r\n+        // Row 2 defish/fish\r\n+        Label {\r\n+            text: qsTr('Fisheye')\r\n+            Shotcut.HoverTip { text: qsTr('Add or remove fisheye effect') }\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        RowLayout {\r\n+            ButtonGroup { id: fisheyeGroup }\r\n+            RadioButton {\r\n+                id: fisheyeRemoveButton\r\n+                text: qsTr('Remove')\r\n+                ButtonGroup.group: fisheyeGroup\r\n+                checked: deFishDefault\r\n+                onCheckedChanged: {\r\n+                    if (blockUpdate) return\r\n+                    if (checked) { filter.set(deFishParam, true) }\r\n+                }\r\n+            }\r\n+            RadioButton {\r\n+                id: fisheyeAddButton\r\n+                text: qsTr('Add')\r\n+                ButtonGroup.group: fisheyeGroup\r\n+                checked: !deFishDefault\r\n+                onCheckedChanged: {\r\n+                    if (blockUpdate) return\r\n+                    if (checked) { filter.set(deFishParam, false) }\r\n+                }\r\n+            }\r\n+        }\r\n+        Shotcut.UndoButton {\r\n+            onClicked: {\r\n+                fisheyeRemoveButton.checked = deFishDefault\r\n+                fisheyeAddButton.checked = !deFishDefault\r\n+            }\r\n+        }\r\n+\r\n+        // Row 3: focal ratio\r\n+        Label {\r\n+            text: qsTr('Focal ratio')\r\n+            leftPadding: 10\r\n+            Shotcut.HoverTip { text: qsTr('The amount of lens distortion') }\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        Shotcut.SliderSpinner {\r\n+            id: focalRatioSlider\r\n+            minimumValue: 0\r\n+            maximumValue: 1\r\n+            decimals: 3\r\n+            suffix: ''\r\n+            value: focalRatioDefault\r\n+            onValueChanged: { if (blockUpdate) return; filter.set(focalRatioParam, value) }\r\n+        }\r\n+        Shotcut.UndoButton {\r\n+            onClicked: focalRatioSlider.value = focalRatioDefault\r\n+        }\r\n+\r\n+        // Row 4: Interpolation Quality\r\n+        Label {\r\n+            text: qsTr('Quality')\r\n+            Shotcut.HoverTip { text: qsTr( 'Resample quality') }\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        Shotcut.ComboBox {\r\n+            id: qualityCombo\r\n+            implicitWidth: 120\r\n+            model: ListModel {\r\n+                id: qualityModel\r\n+                ListElement { text: qsTr('Nearest neighbor'); value: 0.0 }\r\n+                ListElement { text: qsTr('Bilinear'); value: 0.166 }\r\n+                ListElement { text: qsTr('Bicubic smooth'); value: 0.333 }\r\n+                ListElement { text: qsTr('Bicubic sharp'); value: 0.500 }\r\n+                ListElement { text: qsTr('Spline 4x4'); value: 0.666 }\r\n+                ListElement { text: qsTr('Spline 6x6'); value: 0.833 }\r\n+                ListElement { text: qsTr('Lanczos 16x16'); value: 1.0 }\r\n+            }\r\n+            textRole: 'text'\r\n+            onActivated: {\r\n+                filter.set(qualityParam, qualityModel.get(currentIndex).value)\r\n+            }\r\n+        }\r\n+         Shotcut.UndoButton {\r\n+            onClicked: {\r\n+                filter.set(qualityParam, qualityDefault)\r\n+                qualityCombo.currentIndex = setDefaultIndex(qualityDefault, qualityCombo.count) - 1\r\n+            }\r\n+        }\r\n+\r\n+        // Row 5: Lens Type\r\n+        Label {\r\n+            text: qsTr('Lens')\r\n+            Shotcut.HoverTip { text: qsTr('Select a lens distortion pattern that best matches your camera') }\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        RowLayout {\r\n+            Shotcut.ComboBox {\r\n+                id: lensCombo\r\n+                implicitWidth: 120\r\n+                model: ListModel {\r\n+                    id: lensModel\r\n+                    ListElement { text: qsTr('Equidistant'); value: 0.0 }\r\n+                    ListElement { text: qsTr('Ortographic'); value: 0.333 }\r\n+                    ListElement { text: qsTr('Equiarea'); value: 0.666 }\r\n+                    ListElement { text: qsTr('Stereographic'); value: 1.0 }\r\n+                }\r\n+                textRole: 'text'\r\n+                onActivated: {\r\n+                    filter.set(lensTypeParam, lensModel.get(currentIndex).value)\r\n+                }\r\n+            }\r\n+            CheckBox {\r\n+                text: qsTr('Non-Linear scale') //stretch view\r\n+                leftPadding: 6\r\n+                Shotcut.HoverTip { text: qsTr(  'The image will be stretched/squished to fix camera scaling between 4:3 and 16:9\\n'+\r\n+                                                'Like used in GoPro\\'s superview' ) }\r\n+                id: stretchCheckBox\r\n+                padding: 0\r\n+                visible: pluginShowNew\r\n+                checked: superViewDefault\r\n+                onCheckedChanged: {\r\n+                    if (blockUpdate) return\r\n+                    stretchShowSlider = checked\r\n+                    filter.set(stretchParam, checked? stretchSlider.value+0.5: 0.5)                    \r\n+                    setScollbarHeight()\r\n+                }\r\n+            }\r\n+        }\r\n+        Shotcut.UndoButton {\r\n+            onClicked: {\r\n+                filter.set(lensTypeParam, lensTypeDefault)\r\n+                lensCombo.currentIndex = setDefaultIndex(lensTypeDefault, lensCombo.count) - 1\r\n+                stretchCheckBox.checked = superViewDefault\r\n+            }\r\n+        }\r\n+\r\n+        // Row 6: fix stretch\r\n+        Label {\r\n+            visible: stretchShowSlider\r\n+            text: qsTr('Scale')\r\n+            Shotcut.HoverTip { text: qsTr(  'Use negative values for up-scaled videos\\n'+\r\n+                                            'Use positive values for down-scaled videos' ) }\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        Shotcut.SliderSpinner {\r\n+            visible: stretchShowSlider\r\n+            id: stretchSlider\r\n+            minimumValue: -0.5\r\n+            maximumValue: 0.5\r\n+            decimals: 2\r\n+            suffix: ''\r\n+            value: 0\r\n+            onValueChanged: { if (blockUpdate) return; filter.set(stretchParam, value+0.5) }\r\n+        }\r\n+        Shotcut.UndoButton {\r\n+            visible: stretchShowSlider\r\n+            onClicked: stretchSlider.value = stretchDefault - 0.5\r\n+        }\r\n+\r\n+\r\n+        //line seperator #1\r\n+         RowLayout {\r\n+            Layout.columnSpan: 3\r\n+            Label { text: qsTr('Scale')}  \r\n+            Rectangle{ Layout.fillWidth: true;height: 1; color: activePalette.text; opacity: 0.3 }\r\n+        }\r\n+        \r\n+        // Row 7: Scale (Preset)\r\n+        Label {\r\n+            text: qsTr('Preset')\r\n+            Shotcut.HoverTip { text: qsTr( 'Preset scale methods\\n'+\r\n+                                           'Lock pixels at specific locations') }\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        RowLayout {\r\n+            Shotcut.ComboBox {\r\n+                id: scaleCombo\r\n+                implicitWidth: 120\r\n+                model: ListModel {\r\n+                    id: scaleModel\r\n+                    ListElement { text: qsTr('Scale to Fill'); value: 0.0 }\r\n+                    ListElement { text: qsTr('Keep Center Scale'); value: 0.333 }\r\n+                    ListElement { text: qsTr('Scale to Fit'); value: 0.666 }\r\n+                    ListElement { text: qsTr('Manual Scale'); value: 1.0 }\r\n+                }\r\n+                textRole: 'text'\r\n+                onActivated: {\r\n+                    filter.set(scaePresetParam, scaleModel.get(currentIndex).value)\r\n+                    scaleShowSlider = ((currentIndex+1)==scaleCombo.count) //show user input?\r\n+                    setScollbarHeight()\r\n+                }\r\n+            }\r\n+            CheckBox {\r\n+                text: qsTr('Y')\r\n+                leftPadding: 6\r\n+                Shotcut.HoverTip { text: qsTr('Scale Y separately\\nThis changes video aspect ratio') }\r\n+                id: scaleYCheckBox\r\n+                visible: pluginShowNew                \r\n+                padding: 0\r\n+                checked: false\r\n+                onCheckedChanged: {\r\n+                    if (blockUpdate) return\r\n+                    filter.set(scaleYParam, checked? scaleYSlider.value+0.5:0.5)\r\n+                    scaleYShowSlider = checked                  \r\n+                    setScollbarHeight()\r\n+                }\r\n+            }            \r\n+            CheckBox {\r\n+                text: qsTr('Crop')\r\n+                leftPadding: 6\r\n+                Shotcut.HoverTip { text: qsTr('Remove distorted edges') }                \r\n+                id: cropCheckBox\r\n+                padding: 0\r\n+                checked: cropDefault\r\n+                visible: (pluginShowNew && fisheyeRemoveButton.checked)\r\n+                onCheckedChanged: { if (blockUpdate) return; filter.set(cropParam, checked) }\r\n+            }\r\n+        }\r\n+        Shotcut.UndoButton {\r\n+            onClicked: {\r\n+                filter.set(scaePresetParam, scalePresetDefault)\r\n+                scaleCombo.currentIndex = setDefaultIndex(scalePresetDefault, scaleCombo.count) - 1\r\n+                scaleShowSlider = false\r\n+                cropCheckBox.checked = cropDefault\r\n+                scaleYShowSlider = false\r\n+                scaleYCheckBox.checked = false\r\n+                setScollbarHeight()\r\n+            }\r\n+        }\r\n+\r\n+        // Row 8: Scale (Manual)\r\n+        Label {\r\n+            text: qsTr('Manual')\r\n+            Shotcut.HoverTip { text: qsTr('User set zoom/scale\\nSides of image are not fixed') }\r\n+            Layout.alignment: Qt.AlignRight\r\n+            visible: scaleShowSlider\r\n+        }\r\n+        Shotcut.SliderSpinner {\r\n+            id: scaleManualSlider\r\n+            visible: scaleShowSlider\r\n+            minimumValue: -0.5\r\n+            maximumValue: 0.5\r\n+            decimals: 3\r\n+            suffix: ''\r\n+            value: 0\r\n+            onValueChanged: { if (blockUpdate) return; filter.set(scaleManualParam, value+0.5) }\r\n+        }\r\n+        Shotcut.UndoButton {\r\n+            visible: scaleShowSlider\r\n+            onClicked: scaleManualSlider.value = 0\r\n+        }\r\n+       \r\n+        // Row 9: Scale (Y)\r\n+        Label {\r\n+            text: qsTr('Y ratio')\r\n+            Shotcut.HoverTip { text: qsTr('Seperate Y scale') }\r\n+            Layout.alignment: Qt.AlignRight\r\n+            visible:  scaleYShowSlider\r\n+        }\r\n+        Shotcut.SliderSpinner {\r\n+            id: scaleYSlider\r\n+            visible: scaleYShowSlider\r\n+            minimumValue: -0.49\r\n+            maximumValue: 0.5\r\n+            value: 0\r\n+            decimals: 2\r\n+            suffix: ''\r\n+            onValueChanged: { if (blockUpdate) return; filter.set(scaleYParam, value+0.5) }\r\n+        }\r\n+        Shotcut.UndoButton {\r\n+            visible: scaleYShowSlider\r\n+            onClicked: scaleYSlider.value = 0\r\n+        }        \r\n+\r\n+        //line seperator #2\r\n+         RowLayout {\r\n+            Layout.columnSpan: 3\r\n+            Label { text: qsTr('Aspect')}  \r\n+            Rectangle{ Layout.fillWidth: true; height: 1; color: activePalette.text; opacity: 0.3 }\r\n+        }\r\n+        \r\n+        // Row 10: A/R (Preset)\r\n+        Label {\r\n+            text: qsTr('Preset')\r\n+            Shotcut.HoverTip { text: qsTr( 'Preset pixel aspect ratio') }\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        RowLayout {\r\n+            Shotcut.ComboBox {\r\n+                id: aspectCombo\r\n+                implicitWidth: 120\r\n+                model: ListModel {\r\n+                    id: aspectModel\r\n+                    ListElement { text:      'Square Pixel'; value: 0.0 }\r\n+                    ListElement { text:      'PAL DV  1.067'; value: 0.250 }\r\n+                    ListElement { text:      'NTSC DV 0.889'; value: 0.500 }\r\n+                    ListElement { text:      'HDV     1.333'; value: 0.750 }\r\n+                    ListElement { text: qsTr('Manual Aspect'); value: 1.0 }\r\n+                }\r\n+                textRole: 'text'\r\n+                onActivated: {\r\n+                    filter.set(aspectPresetParam, aspectModel.get(currentIndex).value)\r\n+                    aspectShowSlider = ((currentIndex+1) == aspectCombo.count) //show user input?\r\n+                    setScollbarHeight()\r\n+                }\r\n+            }\r\n+        }\r\n+        Shotcut.UndoButton {\r\n+            onClicked: {\r\n+                filter.set(aspectPresetParam, aspectPresetDefault)\r\n+                aspectCombo.currentIndex = setDefaultIndex(aspectPresetDefault, aspectCombo.count) - 1\r\n+                aspectShowSlider = false\r\n+                setScollbarHeight()\r\n+            }\r\n+        }\r\n+\r\n+        // Row 11: A/R (Manual)\r\n+        Label {\r\n+            text: qsTr('Manual')\r\n+            Shotcut.HoverTip { text: qsTr( 'User set pixel aspect ratios\\n'+\r\n+                                           'Change top/side distortion bias') }\r\n+            Layout.alignment: Qt.AlignRight\r\n+            visible: aspectShowSlider\r\n+        }\r\n+        Shotcut.SliderSpinner {\r\n+            id: aspectManualSlider\r\n+            minimumValue: -0.5\r\n+            maximumValue: 0.5\r\n+            decimals: 2\r\n+            suffix: ''\r\n+            visible: aspectShowSlider\r\n+            value: 0 \r\n+            onValueChanged: { if (blockUpdate) return; filter.set(aspectManualParam, value+0.5) }\r\n+        }\r\n+        Shotcut.UndoButton {\r\n+            visible: aspectShowSlider\r\n+            onClicked: aspectManualSlider.value = 0\r\n+        }\r\n+\r\n+        //line seperator #3\r\n+         RowLayout {\r\n+            visible: cameraShowNew\r\n+            Layout.columnSpan: 3\r\n+            Label { text: qsTr('Cameras')}  \r\n+            Rectangle{ Layout.fillWidth: true; height: 1; color: activePalette.text; opacity: 0.3 }\r\n+        }\r\n+\r\n+        //row 12 combo cameras\r\n+         Label {\r\n+            visible: cameraShowNew\r\n+            text: qsTr('Camera')\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        Shotcut.ComboBox {\r\n+            visible: cameraShowNew\r\n+            Layout.columnSpan: 2\r\n+            id: cameraCombo\r\n+            implicitWidth: 120\r\n+            model: ListModel { id: tempList1 }\r\n+            onActivated: fillModeCombo()\r\n+        }\r\n+        //row 13 combo camera mode\r\n+         Label {\r\n+            visible: cameraShowNew\r\n+            text: qsTr('Record mode')\r\n+            leftPadding: 10\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        Shotcut.ComboBox {\r\n+            visible: cameraShowNew\r\n+            Layout.columnSpan: 2\r\n+            id: camModeCombo\r\n+            implicitWidth: 120\r\n+            model:  ListModel { id: tempList2 }\r\n+            onActivated: fillResultsCombo()\r\n+        }\r\n+        //row 14 combo results\r\n+        Label {\r\n+            visible: cameraShowNew\r\n+            text: qsTr('Result')\r\n+            Layout.alignment: Qt.AlignRight\r\n+        }\r\n+        Row {\r\n+            visible: cameraShowNew\r\n+            Layout.columnSpan: 2\r\n+            Shotcut.ComboBox {\r\n+                id: resultCombo\r\n+                implicitWidth: 120\r\n+                model:  ListModel { id: tempList3 }\r\n+            }\r\n+            Shotcut.Button {\r\n+                Layout.alignment: Qt.AlignRight\r\n+                text: qsTr('Apply')\r\n+                implicitWidth: 80\r\n+                onClicked: setCameraData()\r\n+            }\r\n+        }\r\n+\r\n+        Item {\r\n+            Layout.fillHeight: true\r\n+        }\r\n+    }\r\n+}\r\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **UI Adjustment:** Set all `ComboBoxes` to `implicitWidth: 150` to prevent text truncation on Linux and macOS.\n\n2. **Default Behavior:** Change default action from Add to Remove in the filter since it\u2019s the most common use case.\n\n3. **Slice Threading Support:** Implement `filter.set('threads', 0)` to enable automatic thread determination. Investigate visual artifacts when this is applied.\n\n4. **MLT Changes:** Modify `src/modules/frei0r/frei0r_helper.c` to set `ctx->time = index;` in `f0r_update_slice` for threading context.\n\n5. **OpenMP Alternative:** Consider switching to OpenMP for threading if slice threading has limitations. Review existing usage in other Shotcut plugins.\n\n6. **Memory Leak Issue:** Investigate repeated calls to `f0r_construct()` vs. `f0r_destruct()` leading to a memory leak, especially with rapid add/remove of filters."
      }
    ],
    "codediff_length": 36458
  },
  {
    "index": 116,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/scripts/build-shotcut-msys2.sh b/scripts/build-shotcut-msys2.sh\nindex 44ad75fe74..f27b807357 100755\n--- a/scripts/build-shotcut-msys2.sh\n+++ b/scripts/build-shotcut-msys2.sh\n@@ -64,6 +64,9 @@ ENABLE_LADSPA=1\n LADSPA_HEAD=0\n LADSPA_REVISION=\"origin/shotcut\"\n MLT_DISABLE_SOX=0\n+ENABLE_WHISPERCPP=1\n+WHISPERCPP_HEAD=1\n+WHISPERCPP_REVISION=\n \n ################################################################################\n # Location of config file - if not overridden on command line\n@@ -160,6 +163,9 @@ function to_key {\n     bigsh0t)\n       echo 8\n     ;;\n+    whisper.cpp)\n+      echo 9\n+    ;;\n     dav1d)\n       echo 10\n     ;;\n@@ -394,6 +400,9 @@ function set_globals {\n     if test \"$ENABLE_LADSPA\" = 1 && test \"$LADSPA_HEAD\" = 1 -o \"$LADSPA_REVISION\" != \"\"; then\n         SUBDIRS=\"ladspa-swh $SUBDIRS\"\n     fi\n+    if test \"$ENABLE_WHISPERCPP\" = 1  && test \"$WHISPERCPP_HEAD\" = 1 -o \"$WHISPERCPP_REVISION\" != \"\"; then\n+        SUBDIRS=\"whisper.cpp $SUBDIRS\"\n+    fi\n     SUBDIRS=\"$SUBDIRS mlt shotcut\"\n   fi\n \n@@ -428,6 +437,7 @@ function set_globals {\n   REPOLOCS[7]=\"https://github.com/GPUOpen-LibrariesAndSDKs/AMF.git\"\n #  REPOLOCS[8]=\"https://bitbucket.org/dandennedy/bigsh0t.git\"\n   REPOLOCS[8]=\"https://bitbucket.org/leo_sutic/bigsh0t.git\"\n+  REPOLOCS[9]=\"https://github.com/ggerganov/whisper.cpp.git\"\n   REPOLOCS[10]=\"https://code.videolan.org/videolan/dav1d.git\"\n   REPOLOCS[11]=\"https://aomedia.googlesource.com/aom\"\n   REPOLOCS[12]=\"https://github.com/Netflix/vmaf.git\"\n@@ -625,6 +635,14 @@ function set_globals {\n   BUILD[8]=\"ninja -j $MAKEJ\"\n   INSTALL[8]=\"install -p -c *.dll \"$FINAL_INSTALL_DIR\"/lib/frei0r-1\"\n \n+  #####\n+  # whisper.cpp\n+  CONFIG[9]=\"cmake -B build -G Ninja -D CMAKE_INSTALL_PREFIX=$FINAL_INSTALL_DIR $CMAKE_DEBUG_FLAG -D BUILD_SHARED_LIBS=ON -D GGML_NATIVE=OFF -D WHISPER_BUILD_SERVER=OFF -D WHISPER_BUILD_TESTS=OFF\"\n+  CFLAGS_[9]=$CFLAGS\n+  LDFLAGS_[9]=$LDFLAGS\n+  BUILD[9]=\"ninja -C build -j $MAKEJ\"\n+  INSTALL[9]=\"install_whispercpp\"\n+\n   #####\n   # dav1d\n   CONFIG[10]=\"meson setup builddir --prefix=$FINAL_INSTALL_DIR --libdir=$FINAL_INSTALL_DIR/lib\"\n@@ -744,6 +762,12 @@ function install_spatialaudio {\n   cmd sed -i \"s,-I/${TARGET_ARCH}/include,,\" \"$FINAL_INSTALL_DIR\"/lib/pkgconfig/spatialaudio.pc\n }\n \n+function install_whispercpp {\n+  cmd ninja -C build install\n+  cmd install -p -c build/bin/main.exe $FINAL_INSTALL_DIR/bin/whisper.cpp-main.exe\n+  cmd mkdir -p $FINAL_INSTALL_DIR/share/shotcut/whisper_models\n+  cmd install -p -c models/ggml-base-q5_1.bin $FINAL_INSTALL_DIR/share/shotcut/whisper_models\n+}\n \n ######################################################################\n # FEEDBACK FUNCTIONS\n@@ -949,6 +973,10 @@ function get_subproject {\n       cmd cd $1 || die \"Unable to change to directory $1\"\n   fi # git/svn\n \n+  if [ \"$1\" = \"whisper.cpp\" ]; then\n+    cmd sh ./models/download-ggml-model.sh base-q5_1\n+  fi\n+\n   feedback_status Done getting or updating source for $1\n   cmd popd\n }\n@@ -1179,6 +1207,7 @@ function deploy\n     cmd mv bin/ffplay.exe .\n     cmd mv bin/ffprobe.exe .\n     cmd mv bin/glaxnimate.exe .\n+    cmd mv bin/whisper.cpp-main.exe .\n     cmd rm -rf bin include etc man manifest src *.txt\n     cmd rm lib/*\n     cmd rm -rf lib/cmake lib/pkgconfig lib/gdk-pixbuf-2.0 lib/glib-2.0 lib/gtk-2.0\ndiff --git a/scripts/build-shotcut.sh b/scripts/build-shotcut.sh\nindex a1037f929d..980449f460 100755\n--- a/scripts/build-shotcut.sh\n+++ b/scripts/build-shotcut.sh\n@@ -101,6 +101,9 @@ LIBWEBP_REVISION=\"v1.3.2\"\n ENABLE_LIBSPATIALAUDIO=1\n LIBSPATIALAUDIO_HEAD=1\n LIBSPATIALAUDIO_REVISION=\n+ENABLE_WHISPERCPP=1\n+WHISPERCPP_HEAD=1\n+WHISPERCPP_REVISION=\n \n PYTHON_VERSION_DEFAULT=3.8\n PYTHON_VERSION_DARWIN=3.11\n@@ -268,6 +271,9 @@ function to_key {\n     SVT-AV1)\n       echo 29\n     ;;\n+    whisper.cpp)\n+      echo 30\n+    ;;\n     *)\n       echo UNKNOWN\n     ;;\n@@ -514,6 +520,9 @@ function set_globals {\n     if test \"$ENABLE_LIBSPATIALAUDIO\" = 1  && test \"$LIBSPATIALAUDIO_HEAD\" = 1 -o \"$LIBSPATIALAUDIO_REVISION\" != \"\"; then\n         SUBDIRS=\"libspatialaudio $SUBDIRS\"\n     fi\n+    if test \"$ENABLE_WHISPERCPP\" = 1  && test \"$WHISPERCPP_HEAD\" = 1 -o \"$WHISPERCPP_REVISION\" != \"\"; then\n+        SUBDIRS=\"whisper.cpp $SUBDIRS\"\n+    fi\n   fi\n \n   if [ \"$DEBUG_BUILD\" = \"1\" ]; then\n@@ -566,6 +575,7 @@ function set_globals {\n   REPOLOCS[27]=\"https://github.com/opencv/opencv_contrib.git\"\n   REPOLOCS[28]=\"https://github.com/webmproject/libwebp.git\"\n   REPOLOCS[29]=\"https://gitlab.com/AOMediaCodec/SVT-AV1.git\"\n+  REPOLOCS[30]=\"https://github.com/ggerganov/whisper.cpp.git\"\n \n   # REPOTYPE Array holds the repo types. (Yes, this might be redundant, but easy for me)\n   REPOTYPES[0]=\"git\"\n@@ -596,6 +606,7 @@ function set_globals {\n   REPOTYPES[27]=\"git\"\n   REPOTYPES[28]=\"git\"\n   REPOTYPES[29]=\"git\"\n+  REPOTYPES[30]=\"git\"\n \n   # And, set up the revisions\n   REVISIONS[0]=\"\"\n@@ -1089,6 +1100,21 @@ function set_globals {\n   LDFLAGS_[29]=$LDFLAGS\n   BUILD[29]=\"ninja -C build -j $MAKEJ\"\n   INSTALL[29]=\"ninja -C build install\"\n+  \n+  #####\n+  # whisper.cpp\n+  CONFIG[30]=\"cmake -B build -G Ninja -D CMAKE_INSTALL_PREFIX=$FINAL_INSTALL_DIR $CMAKE_DEBUG_FLAG -D BUILD_SHARED_LIBS=ON -D GGML_NATIVE=OFF -D WHISPER_BUILD_SERVER=OFF -D WHISPER_BUILD_TESTS=OFF\"\n+  [ \"$TARGET_OS\" = \"Darwin\" ] && CONFIG[30]=\"${CONFIG[30]} -D CMAKE_OSX_ARCHITECTURES='arm64;x86_64'\"\n+  if test \"$TARGET_OS\" = \"Darwin\" ; then\n+    CONFIG[30]=\"${CONFIG[30]} -D CMAKE_OSX_ARCHITECTURES='arm64;x86_64'\"\n+    CONFIG[30]=\"${CONFIG[30]} -D OpenMP_C_FLAGS=-I/opt/local/include/libomp -D OpenMP_CXX_FLAGS=-I/opt/local/include/libomp -D OpenMP_C_LIB_NAMES=libomp -D OpenMP_CXX_LIB_NAMES=libomp -D OpenMP_libomp_LIBRARY=omp\"\n+    LDFLAGS_[30]=\"$LDFLAGS -L /opt/local/lib/libomp\"\n+  else\n+    CFLAGS_[30]=$CFLAGS\n+    LDFLAGS_[30]=$LDFLAGS\n+  fi\n+  BUILD[30]=\"ninja -C build -j $MAKEJ\"\n+  INSTALL[30]=\"install_whispercpp\"\n }\n \n function build_ffmpeg_darwin {\n@@ -1200,6 +1226,13 @@ EOF\n   cmd ninja install\n }\n \n+function install_whispercpp {\n+  cmd ninja -C build install\n+  cmd install -p -c build/bin/main $FINAL_INSTALL_DIR/bin/whisper.cpp-main\n+  cmd mkdir -p $FINAL_INSTALL_DIR/share/shotcut/whisper_models\n+  cmd install -p -c models/ggml-base-q5_1.bin $FINAL_INSTALL_DIR/share/shotcut/whisper_models\n+}\n+\n ######################################################################\n # FEEDBACK FUNCTIONS\n ######################################################################\n@@ -1410,6 +1443,10 @@ function get_subproject {\n       cmd cd $1 || die \"Unable to change to directory $1\"\n   fi # git/svn\n \n+  if [ \"$1\" = \"whisper.cpp\" ]; then\n+    cmd sh ./models/download-ggml-model.sh base-q5_1\n+  fi\n+\n   feedback_status Done getting or updating source for $1\n   cmd popd\n }\n@@ -1832,10 +1869,10 @@ function deploy_mac\n \n   log Copying supplementary executables\n   cmd mkdir -p MacOS 2>/dev/null\n-  cmd cp -a \"$FINAL_INSTALL_DIR\"/bin/{melt,ffmpeg,ffplay,ffprobe,glaxnimate,gopro2gpx} MacOS\n+  cmd cp -a \"$FINAL_INSTALL_DIR\"/bin/{melt,ffmpeg,ffplay,ffprobe,glaxnimate,gopro2gpx,whisper.cpp-main} MacOS\n   cmd mkdir -p Frameworks 2>/dev/null\n   cmd cp -p ../../lib/libCuteLogger.dylib Frameworks\n-  for exe in MacOS/Shotcut MacOS/melt MacOS/ffmpeg MacOS/ffplay MacOS/ffprobe MacOS/glaxnimate; do\n+  for exe in MacOS/Shotcut MacOS/melt MacOS/ffmpeg MacOS/ffplay MacOS/ffprobe MacOS/glaxnimate MacOS/whisper.cpp-main; do\n     fixlibs \"$exe\"\n     log fixing rpath of executable \"$exe\"\n     cmd install_name_tool -delete_rpath \"$FINAL_INSTALL_DIR/lib\" \"$exe\" 2> /dev/null\n@@ -1912,6 +1949,10 @@ function deploy_mac\n   cmd install -d lib\n   cmd cp -pLR /opt/local/Library/Frameworks/Python.framework/Versions/${PYTHON_VERSION_DARWIN}/lib/python${PYTHON_VERSION_DARWIN} lib\n \n+  # Whisper.cpp models\n+  log Copying Whisper.cpp models\n+  cmd cp -a \"$FINAL_INSTALL_DIR\"/share/shotcut/whisper_models Resources/shotcut\n+\n   log Fixing rpath in libraries\n   cmd find . -name '*.dylib' -exec sh -c \"install_name_tool -delete_rpath \\\"/opt/local/lib/libomp\\\" {} 2> /dev/null\" \\;\n   cmd find . -name '*.dylib' -exec sh -c \"install_name_tool -delete_rpath \\\"$FINAL_INSTALL_DIR/lib\\\" {} 2> /dev/null\" \\;\n@@ -1941,7 +1982,7 @@ function deploy_mac\n     cmd cp -a \"$FINAL_INSTALL_DIR\"/lib/pkgconfig Shotcut/Contents/Frameworks/lib\n     log Symlinking libs\n     pushd Shotcut/Contents/Frameworks\n-    for lib in avcodec avdevice avfilter avformat avutil epoxy mlt++-7 mlt-7 movit mp3lame opus postproc swresample swscale vidstab x264 x265; do\n+    for lib in avcodec avdevice avfilter avformat avutil epoxy mlt++-7 mlt-7 movit mp3lame opus postproc swresample swscale vidstab whisper x264 x265; do\n       dylib=$(ls lib$lib.*.dylib | head -n 1)\n       cmd ln -sf $dylib lib$lib.dylib\n     done\n@@ -2026,7 +2067,7 @@ End-of-environment-setup-template\n   cp $TMPFILE \"$FINAL_INSTALL_DIR/source-me\" || die \"Unable to create environment script - cp failed\"\n \n   log Creating wrapper scripts in $TMPFILE\n-  for exe in melt ffmpeg ffplay ffprobe glaxnimate; do\n+  for exe in melt ffmpeg ffplay ffprobe glaxnimate whisper.cpp-main; do\n     cat > $TMPFILE <<End-of-exe-wrapper\n #!/bin/sh\n # Set up environment\ndiff --git a/src/CMakeLists.txt b/src/CMakeLists.txt\nindex 8c0a7fd0f5..7790d0417b 100644\n--- a/src/CMakeLists.txt\n+++ b/src/CMakeLists.txt\n@@ -37,6 +37,7 @@ add_executable(shotcut WIN32 MACOSX_BUNDLE\n   dialogs/textviewerdialog.ui\n   dialogs/transcodedialog.cpp dialogs/transcodedialog.h\n   dialogs/transcodedialog.ui\n+  dialogs/transcribeaudiodialog.cpp dialogs/transcribeaudiodialog.h\n   dialogs/unlinkedfilesdialog.cpp dialogs/unlinkedfilesdialog.h\n   dialogs/unlinkedfilesdialog.ui\n   docks/encodedock.cpp docks/encodedock.h\n@@ -65,6 +66,7 @@ add_executable(shotcut WIN32 MACOSX_BUNDLE\n   jobs/postjobaction.cpp jobs/postjobaction.h\n   jobs/qimagejob.cpp jobs/qimagejob.h\n   jobs/videoqualityjob.cpp jobs/videoqualityjob.h\n+  jobs/whisperjob.cpp jobs/whisperjob.h\n   main.cpp\n   mainwindow.cpp mainwindow.h\n   mainwindow.ui\ndiff --git a/src/dialogs/transcribeaudiodialog.cpp b/src/dialogs/transcribeaudiodialog.cpp\nnew file mode 100644\nindex 0000000000..03fc6bc693\n--- /dev/null\n+++ b/src/dialogs/transcribeaudiodialog.cpp\n@@ -0,0 +1,345 @@\n+/*\n+ * Copyright (c) 2024 Meltytech, LLC\n+ *\n+ * This program is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+#include \"transcribeaudiodialog.h\"\n+\n+#include \"docks/timelinedock.h\"\n+#include \"Logger.h\"\n+#include \"mainwindow.h\"\n+#include \"shotcut_mlt_properties.h\"\n+#include \"util.h\"\n+#include \"qmltypes/qmlapplication.h\"\n+\n+#include <MltProducer.h>\n+#include <QCheckBox>\n+#include <QComboBox>\n+#include <QDialogButtonBox>\n+#include <QFileDialog>\n+#include <QGridLayout>\n+#include <QLabel>\n+#include <QLineEdit>\n+#include <QListWidget>\n+#include <QPushButton>\n+#include <QSpinBox>\n+\n+// List of supported languages from whispercpp\n+static const std::vector<const char *> whisperLanguages = {\n+    \"en\", \"zh\", \"de\", \"es\", \"ru\", \"ko\", \"fr\", \"ja\", \"pt\", \"tr\",\n+    \"pl\", \"ca\", \"nl\", \"ar\", \"sv\", \"it\", \"id\", \"hi\", \"fi\", \"vi\",\n+    \"he\", \"uk\", \"el\", \"ms\", \"cs\", \"ro\", \"da\", \"hu\", \"ta\", \"no\",\n+    \"th\", \"ur\", \"hr\", \"bg\", \"lt\", \"la\", \"mi\", \"ml\", \"cy\", \"sk\",\n+    \"te\", \"fa\", \"lv\", \"bn\", \"sr\", \"az\", \"sl\", \"kn\", \"et\", \"mk\",\n+    \"br\", \"eu\", \"is\", \"hy\", \"ne\", \"mn\", \"bs\", \"kk\", \"sq\", \"sw\",\n+    \"gl\", \"mr\", \"pa\", \"si\", \"km\", \"sn\", \"yo\", \"so\", \"af\", \"oc\",\n+    \"ka\", \"be\", \"tg\", \"sd\", \"gu\", \"am\", \"yi\", \"lo\", \"uz\", \"fo\",\n+    \"ht\", \"ps\", \"tk\", \"nn\", \"mt\", \"sa\", \"lb\", \"my\", \"bo\", \"tl\",\n+    \"mg\", \"as\", \"tt\", \"haw\", \"ln\", \"ha\", \"ba\", \"jw\", \"su\", \"yue\",\n+};\n+\n+static void fillLanguages(QComboBox *combo)\n+{\n+    QMap<QString, QString> codeMap;\n+    for (int i = 0; i < whisperLanguages.size(); i++) {\n+        QString langCode = whisperLanguages[i];\n+        QLocale::Language lang = QLocale::codeToLanguage(langCode);\n+        if (lang == QLocale::AnyLanguage) {\n+            LOG_ERROR() << \"Language not found\" << langCode;\n+            continue;\n+        }\n+        QString langStr = QLocale::languageToString(lang);\n+        if (!langCode.isEmpty() && !langStr.isEmpty()) {\n+            codeMap.insert(langStr, langCode);\n+        }\n+    }\n+    for (auto it = codeMap.keyValueBegin(); it != codeMap.keyValueEnd(); ++it) {\n+        combo->addItem(it->first, it->second);\n+    }\n+}\n+\n+TranscribeAudioDialog::TranscribeAudioDialog(const QString &trackName, QWidget *parent)\n+    : QDialog(parent)\n+{\n+    setWindowTitle(tr(\"Speech to Text\"));\n+    setWindowModality(QmlApplication::dialogModality());\n+\n+    Mlt::Producer *multitrack = MAIN.multitrack();\n+\n+    if (!multitrack || !multitrack->is_valid()) {\n+        LOG_ERROR() << \"Invalid multitrack\";\n+        return;\n+    }\n+\n+    QGridLayout *grid = new QGridLayout();\n+\n+    grid->addWidget(new QLabel(tr(\"Name\")), 0, 0, Qt::AlignRight);\n+    m_name = new QLineEdit(this);\n+    m_name->setText(trackName);\n+    grid->addWidget(m_name, 0, 1);\n+\n+    grid->addWidget(new QLabel(tr(\"Language\")), 1, 0, Qt::AlignRight);\n+    m_lang = new QComboBox(this);\n+    fillLanguages(m_lang);\n+    // Try to set the default to the system language\n+    QString currentLangCode = QLocale::languageToCode(QLocale::system().language(),\n+                                                      QLocale::ISO639Part1);\n+    for (int i = 0; i < m_lang->count(); i++) {\n+        if (m_lang->itemData(i).toString() == currentLangCode) {\n+            m_lang->setCurrentIndex(i);\n+            break;\n+        }\n+    }\n+    // Fall back to English\n+    if (m_lang->currentIndex() == -1) {\n+        for (int i = 0; i < m_lang->count(); i++) {\n+            if (m_lang->itemData(i).toString() == \"en\") {\n+                m_lang->setCurrentIndex(i);\n+                break;\n+            }\n+        }\n+    }\n+    grid->addWidget(m_lang, 1, 1);\n+\n+    m_translate = new QCheckBox(this);\n+    m_translate->setCheckState(Qt::Unchecked);\n+    grid->addWidget(m_translate, 2, 0, Qt::AlignRight);\n+    grid->addWidget(new QLabel(tr(\"Translate to English\")), 2, 1, Qt::AlignLeft);\n+\n+    grid->addWidget(new QLabel(tr(\"Maximum line length\")), 3, 0, Qt::AlignRight);\n+    m_maxLength = new QSpinBox(this);\n+    m_maxLength->setRange(10, 100);\n+    m_maxLength->setValue(42);\n+    m_maxLength->setSuffix(\" characters\");\n+    grid->addWidget(m_maxLength, 3, 1);\n+\n+    m_nonspoken = new QCheckBox(this);\n+    m_nonspoken->setCheckState(Qt::Unchecked);\n+    grid->addWidget(m_nonspoken, 4, 0, Qt::AlignRight);\n+    grid->addWidget(new QLabel(tr(\"Include non-spoken sounds\")), 4, 1, Qt::AlignLeft);\n+\n+    QLabel *tracksLabel = new QLabel(tr(\"Tracks with speech\"));\n+    tracksLabel->setToolTip(tr(\"Select tracks that contain speech to be transcribed.\"));\n+    grid->addWidget(tracksLabel, 5, 0, Qt::AlignRight);\n+    m_trackList = new QListWidget(this);\n+    m_trackList->setSelectionMode(QAbstractItemView::NoSelection);\n+    m_trackList->setSizeAdjustPolicy(QAbstractScrollArea::AdjustToContentsOnFirstShow);\n+    m_trackList->setSizePolicy(QSizePolicy::Expanding, QSizePolicy::Maximum);\n+    m_trackList->setToolTip(tracksLabel->toolTip());\n+    Mlt::Tractor tractor(*multitrack);\n+    if (!tractor.is_valid()) {\n+        LOG_ERROR() << \"Invalid tractor\";\n+        return;\n+    }\n+    TrackList trackList = MAIN.timelineDock()->model()->trackList();\n+    if (trackList.size() == 0) {\n+        LOG_ERROR() << \"No tracks\";\n+        return;\n+    }\n+    for (int trackIndex = 0; trackIndex < trackList.size(); trackIndex++) {\n+        std::unique_ptr<Mlt::Producer> track(tractor.track(trackList[trackIndex].mlt_index));\n+        if (track) {\n+            QString trackName = QString::fromUtf8(track->get(kTrackNameProperty));\n+            if (!trackName.isEmpty()) {\n+                QListWidgetItem *listItem = new QListWidgetItem(trackName, m_trackList);\n+                if (track->get_int(\"hide\") & 2) {\n+                    listItem->setCheckState(Qt::Unchecked);\n+                } else {\n+                    listItem->setCheckState(Qt::Checked);\n+                }\n+                listItem->setData(Qt::UserRole, QVariant(trackList[trackIndex].mlt_index));\n+                m_trackList->addItem(listItem);\n+            }\n+        }\n+    }\n+    grid->addWidget(m_trackList, 5, 1, Qt::AlignLeft);\n+\n+    // The config section is a single widget with a unique grid layout inside of it.\n+    // The config section is hidden by hiding the config widget (and the layout it contains)\n+    static const int maxPathWidth = 350;\n+    m_configWidget = new QWidget(this);\n+    QGridLayout *configLayout = new QGridLayout(this);\n+    m_configWidget->setLayout(configLayout);\n+\n+    // Horizontal separator line\n+    QFrame *line = new QFrame(m_configWidget);\n+    line->setFrameShape(QFrame::HLine);\n+    line->setFrameShadow(QFrame::Sunken);\n+    configLayout->addWidget(line, 0, 0, 1, 2);\n+\n+    // Whisper.cpp exe\n+    configLayout->addWidget(new QLabel(tr(\"Whisper.cpp executable\")), 1, 0, Qt::AlignRight);\n+    m_exeLabel = new QLineEdit(this);\n+    m_exeLabel->setFixedWidth(maxPathWidth);\n+    m_exeLabel->setReadOnly(true);\n+    configLayout->addWidget(m_exeLabel, 1, 1, Qt::AlignLeft);\n+    QPushButton *exeBrowseButton = new QPushButton(this);\n+    exeBrowseButton->setIcon(QIcon::fromTheme(\"document-open\",\n+                                              QIcon(\":/icons/oxygen/32x32/actions/document-open.png\")));\n+    connect(exeBrowseButton, &QAbstractButton::clicked, this, [&] {\n+        auto path = QFileDialog::getOpenFileName(this, tr(\"Find Whisper.cpp\"), Settings.whisperExe(),\n+                                                 QString(),\n+                                                 nullptr, Util::getFileDialogOptions());\n+        if (QFileInfo(path).isExecutable())\n+        {\n+            Settings.setWhisperExe(path);\n+            updateWhisperStatus();\n+        }\n+    });\n+    configLayout->addWidget(exeBrowseButton, 1, 2, Qt::AlignLeft);\n+\n+    // Whisper.cpp model\n+    configLayout->addWidget(new QLabel(tr(\"GGML Model\")), 2, 0, Qt::AlignRight);\n+    m_modelLabel = new QLineEdit(this);\n+    m_modelLabel->setFixedWidth(maxPathWidth);\n+    m_modelLabel->setReadOnly(true);\n+    configLayout->addWidget(m_modelLabel, 2, 1, Qt::AlignLeft);\n+    QPushButton *modelBrowseButton = new QPushButton(this);\n+    modelBrowseButton->setIcon(QIcon::fromTheme(\"document-open\",\n+                                                QIcon(\":/icons/oxygen/32x32/actions/document-open.png\")));\n+    connect(modelBrowseButton, &QAbstractButton::clicked, this, [&] {\n+        auto path = QFileDialog::getOpenFileName(this, tr(\"Find Whisper.cpp\"), Settings.whisperModel(),\n+                                                 \"*.bin\",\n+                                                 nullptr, Util::getFileDialogOptions());\n+        if (QFileInfo(path).exists())\n+        {\n+            LOG_INFO() << \"Model found\" << path;\n+            Settings.setWhisperModel(path);\n+            updateWhisperStatus();\n+        } else\n+        {\n+            LOG_INFO() << \"Model not found\" << path;\n+        }\n+    });\n+    configLayout->addWidget(modelBrowseButton, 2, 2, Qt::AlignLeft);\n+\n+    grid->addWidget(m_configWidget, 6, 0, 1, 2);\n+\n+    // Add a button box to the dialog\n+    m_buttonBox = new QDialogButtonBox(QDialogButtonBox::Ok | QDialogButtonBox::Cancel);\n+    QPushButton *configButton = new QPushButton(tr(\"Configuration\"));\n+    configButton->setCheckable(true);\n+    connect(configButton, &QPushButton::toggled, this, [&](bool checked) {\n+        m_configWidget->setVisible(checked);\n+    });\n+    updateWhisperStatus();\n+    QPushButton *okButton = m_buttonBox->button(QDialogButtonBox::Ok);\n+    if (!m_buttonBox->button(QDialogButtonBox::Ok)->isEnabled()) {\n+        // Show the config section\n+        configButton->setChecked(true);\n+        m_configWidget->setVisible(true);\n+    } else {\n+        configButton->setChecked(false);\n+        m_configWidget->setVisible(false);\n+    }\n+    m_buttonBox->addButton(configButton, QDialogButtonBox::ActionRole);\n+    grid->addWidget(m_buttonBox, 7, 0, 1, 2);\n+    connect(m_buttonBox, SIGNAL(clicked(QAbstractButton *)), this, SLOT(clicked(QAbstractButton *)));\n+\n+    setLayout(grid);\n+    setModal(true);\n+    layout()->setSizeConstraint(QLayout::SetFixedSize);\n+}\n+\n+QList<int> TranscribeAudioDialog::tracks()\n+{\n+    QList<int> tracks;\n+    for (int i = 0; i < m_trackList->count(); i++) {\n+        QListWidgetItem *item = m_trackList->item(i);\n+        if (item && item->checkState() == Qt::Checked) {\n+            tracks << item->data(Qt::UserRole).toInt();\n+        }\n+    }\n+    return tracks;\n+}\n+\n+void TranscribeAudioDialog::clicked(QAbstractButton *button)\n+{\n+    QDialogButtonBox::ButtonRole role = m_buttonBox->buttonRole(button);\n+    if (role == QDialogButtonBox::AcceptRole) {\n+        LOG_DEBUG() << \"Accept\";\n+        accept();\n+    } else if (role == QDialogButtonBox::RejectRole) {\n+        LOG_DEBUG() << \"Reject\";\n+        reject();\n+    } else {\n+        LOG_DEBUG() << \"Unknown role\" << role;\n+    }\n+}\n+\n+\n+QString TranscribeAudioDialog::name()\n+{\n+    return m_name->text();\n+}\n+\n+QString TranscribeAudioDialog::language()\n+{\n+    return m_lang->currentData().toString();\n+}\n+\n+bool TranscribeAudioDialog::translate()\n+{\n+    return m_translate->checkState() == Qt::Checked;\n+}\n+\n+int TranscribeAudioDialog::maxLineLength()\n+{\n+    return m_maxLength->value();\n+}\n+\n+bool TranscribeAudioDialog::includeNonspoken()\n+{\n+    return m_nonspoken->checkState() == Qt::Checked;\n+}\n+\n+void TranscribeAudioDialog::updateWhisperStatus()\n+{\n+    bool exeFound = QFileInfo(Settings.whisperExe()).isExecutable();\n+    bool modelFound = QFileInfo(Settings.whisperModel()).exists();\n+\n+    m_exeLabel->setText(Settings.whisperExe());\n+    m_modelLabel->setText(Settings.whisperModel());\n+\n+    QPushButton *okButton = m_buttonBox->button(QDialogButtonBox::Ok);\n+    if (!exeFound || !modelFound) {\n+        // Disable the OK button;\n+        okButton->setDisabled(true);\n+    } else {\n+        okButton->setDisabled(false);\n+    }\n+\n+    if (exeFound) {\n+        QPalette palette;\n+        m_exeLabel->setPalette(palette);\n+        m_exeLabel->setToolTip(tr(\"Path to Whisper.cpp executable\"));\n+    } else {\n+        QPalette palette;\n+        palette.setColor(QPalette::Text, Qt::red);\n+        m_exeLabel->setPalette(palette);\n+        m_exeLabel->setToolTip(tr(\"Whisper.cpp executable not found\"));\n+    }\n+\n+    if (modelFound) {\n+        QPalette palette;\n+        m_modelLabel->setPalette(palette);\n+        m_modelLabel->setToolTip(tr(\"Path to GGML model\"));\n+    } else {\n+        QPalette palette;\n+        palette.setColor(QPalette::Text, Qt::red);\n+        m_modelLabel->setPalette(palette);\n+        m_modelLabel->setToolTip(tr(\"GGML model not found\"));\n+    }\n+}\ndiff --git a/src/dialogs/transcribeaudiodialog.h b/src/dialogs/transcribeaudiodialog.h\nnew file mode 100644\nindex 0000000000..154f5edf2a\n--- /dev/null\n+++ b/src/dialogs/transcribeaudiodialog.h\n@@ -0,0 +1,61 @@\n+/*\n+ * Copyright (c) 2024 Meltytech, LLC\n+ *\n+ * This program is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+#ifndef TRANSCRIBEAUDIODIALOG_H\n+#define TRANSCRIBEAUDIODIALOG_H\n+\n+#include <QDialog>\n+\n+class QAbstractButton;\n+class QCheckBox;\n+class QComboBox;\n+class QDialogButtonBox;\n+class QLineEdit;\n+class QListWidget;\n+class QSpinBox;\n+\n+class TranscribeAudioDialog : public QDialog\n+{\n+    Q_OBJECT\n+\n+public:\n+    explicit TranscribeAudioDialog(const QString &trackName, QWidget *parent);\n+    QString name();\n+    QString language();\n+    QList<int> tracks();\n+    bool translate();\n+    int maxLineLength();\n+    bool includeNonspoken();\n+\n+private slots:\n+    void clicked(QAbstractButton *button);\n+\n+private:\n+    void updateWhisperStatus();\n+    QLineEdit *m_name;\n+    QComboBox *m_lang;\n+    QCheckBox *m_translate;\n+    QSpinBox *m_maxLength;\n+    QCheckBox *m_nonspoken;\n+    QListWidget *m_trackList;\n+    QWidget *m_configWidget;\n+    QLineEdit *m_exeLabel;\n+    QLineEdit *m_modelLabel;\n+    QDialogButtonBox *m_buttonBox;\n+};\n+\n+#endif // TRANSCRIBEAUDIODIALOG_H\ndiff --git a/src/docks/subtitlesdock.cpp b/src/docks/subtitlesdock.cpp\nindex 1d2a5f8932..e30167458c 100644\n--- a/src/docks/subtitlesdock.cpp\n+++ b/src/docks/subtitlesdock.cpp\n@@ -23,9 +23,14 @@\n #include \"shotcut_mlt_properties.h\"\n #include \"util.h\"\n #include \"dialogs/subtitletrackdialog.h\"\n+#include \"dialogs/transcribeaudiodialog.h\"\n+#include \"jobqueue.h\"\n+#include \"jobs/meltjob.h\"\n+#include \"jobs/whisperjob.h\"\n #include \"models/subtitlesmodel.h\"\n #include \"models/subtitlesselectionmodel.h\"\n #include \"widgets/docktoolbar.h\"\n+#include \"qmltypes/qmlapplication.h\"\n #include <Logger.h>\n \n #include \"MltPlaylist.h\"\n@@ -40,7 +45,6 @@\n #include <QItemSelection>\n #include <QItemSelectionModel>\n #include <QLabel>\n-#include <QLineEdit>\n #include <QMenu>\n #include <QMessageBox>\n #include <QProcess>\n@@ -64,6 +68,55 @@ static mlt_position msToPosition(int64_t ms)\n     return ms * MLT.profile().frame_rate_num() / MLT.profile().frame_rate_den() / 1000;\n }\n \n+static QList<Subtitles::SubtitleItem> readSrtFile(const QString &path, int64_t timeOffset,\n+                                                  bool includeNonspoken)\n+{\n+    QList<Subtitles::SubtitleItem> items;\n+\n+    // Read the subtitles\n+    Subtitles::SubtitleVector srtItems = Subtitles::readFromSrtFile(path.toUtf8().toStdString());\n+    if (srtItems.size() == 0) {\n+        return items;\n+    }\n+\n+    // Convert the items to the return list\n+    Subtitles::SubtitleItem item;\n+    for (int i = 0; i < srtItems.size(); i++) {\n+        // Clean up the lines\n+        QStringList lines = QString::fromStdString(srtItems[i].text).split('\\n');\n+        QString text;\n+        for (int i = 0; i < lines.size(); i++) {\n+            // Remove HTML\n+            QString line = QTextDocumentFragment::fromHtml(lines[i]).toPlainText();\n+            // Remove unnecessary space\n+            line = line.simplified();\n+            // Remove leading \"-\"\n+            if (line.startsWith(\"-\")) {\n+                line = line.remove(0, 1).simplified();\n+            }\n+            // Remove unspoken sounds if requested\n+            if (!includeNonspoken &&\n+                    ((line.startsWith(\"[\") && line.endsWith(\"]\")) ||\n+                     (line.startsWith(\"(\") && line.endsWith(\")\")))) {\n+                continue;\n+            }\n+            if (i != 0) {\n+                text += \"\\n\";\n+            }\n+            text += line;\n+        }\n+        text = text.trimmed();\n+        if (!text.isEmpty()) {\n+            // Shift the subtitles to the position\n+            item.start = srtItems[i].start + timeOffset;\n+            item.end = srtItems[i].end + timeOffset;\n+            item.text = text.toUtf8().toStdString();\n+            items.append(item);\n+        }\n+    }\n+    return items;\n+}\n+\n SubtitlesDock::SubtitlesDock(QWidget *parent) :\n     QDockWidget(parent)\n     , m_model(nullptr)\n@@ -134,6 +187,7 @@ SubtitlesDock::SubtitlesDock(QWidget *parent) :\n     mainMenu->addAction(Actions[\"subtitleMoveAction\"]);\n     mainMenu->addAction(Actions[\"subtitleBurnInAction\"]);\n     mainMenu->addAction(Actions[\"subtitleGenerateTextAction\"]);\n+    mainMenu->addAction(Actions[\"subtitleSpeechToTextAction\"]);\n     mainMenu->addAction(Actions[\"subtitleTrackTimelineAction\"]);\n     mainMenu->addAction(Actions[\"subtitleShowPrevNextAction\"]);\n \n@@ -360,6 +414,12 @@ void SubtitlesDock::setupActions()\n     connect(action, &QAction::triggered, this, &SubtitlesDock::generateTextOnTimeline);\n     Actions.add(\"subtitleGenerateTextAction\", action, windowTitle());\n \n+    action = new QAction(tr(\"Speech to Text...\"), this);\n+    action->setToolTip(\n+        tr(\"Detect speech and transcribe to a new subtitle track.\"));\n+    connect(action, &QAction::triggered, this, &SubtitlesDock::speechToText);\n+    Actions.add(\"subtitleSpeechToTextAction\", action, windowTitle());\n+\n     action = new QAction(tr(\"Track Timeline Cursor\"), this);\n     action->setToolTip(tr(\"Track the timeline cursor\"));\n     action->setCheckable(true);\n@@ -413,6 +473,24 @@ void SubtitlesDock::setModel(SubtitlesModel *model, SubtitlesSelectionModel *sel\n     refreshWidgets();\n }\n \n+void SubtitlesDock::importSrtFromFile(const QString &srtPath, const QString &trackName,\n+                                      const QString &lang, bool includeNonspoken)\n+{\n+    QList<Subtitles::SubtitleItem> items = readSrtFile(srtPath, 0, includeNonspoken);\n+    if (items.size() == 0) {\n+        MAIN.showStatusMessage(QObject::tr(\"No subtitles found to import\"));\n+        return;\n+    }\n+\n+    SubtitlesModel::SubtitleTrack track;\n+    track.name = trackName;\n+    track.lang = lang;\n+\n+    m_model->importSubtitlesToNewTrack(track, items);\n+\n+    MAIN.showStatusMessage(QObject::tr(\"Imported %1 subtitle items\").arg(items.size()));\n+}\n+\n void SubtitlesDock::addSubtitleTrack()\n {\n     int newIndex = m_model->trackCount();\n@@ -420,14 +498,9 @@ void SubtitlesDock::addSubtitleTrack()\n         MAIN.showStatusMessage(tr(\"Add a clip to the timeline to create subtitles.\"));\n         return;\n     }\n-    int i = 1;\n-    QString suggestedName = tr(\"Subtitle Track %1\").arg(i);\n-    while (trackNameExists(suggestedName)) {\n-        suggestedName = tr(\"Subtitle Track %1\").arg(i++);\n-    }\n     QString currentLangCode = QLocale::languageToCode(QLocale::system().language(),\n                                                       QLocale::ISO639Part2);\n-    SubtitleTrackDialog dialog(suggestedName, currentLangCode, this);\n+    SubtitleTrackDialog dialog(availableTrackName(), currentLangCode, this);\n     if (dialog.exec() == QDialog::Accepted) {\n         SubtitlesModel::SubtitleTrack track;\n         track.name = dialog.getName();\n@@ -536,28 +609,12 @@ void SubtitlesDock::importSubtitles()\n     }\n \n     // Read the subtitles\n-    Subtitles::SubtitleVector srtItems = Subtitles::readFromSrtFile(tmpFileName.toUtf8().toStdString());\n-    if (srtItems.size() == 0) {\n+    int64_t msTime = positionToMs(m_pos);\n+    QList<Subtitles::SubtitleItem> items = readSrtFile(tmpFileName, msTime, true);\n+    if (items.size() == 0) {\n         MAIN.showStatusMessage(QObject::tr(\"No subtitles found to import\"));\n         return;\n     }\n-    QList<Subtitles::SubtitleItem> items = QList(srtItems.cbegin(), srtItems.cend());\n-    int64_t msTime = positionToMs(m_pos);\n-    for (int i = 0; i < items.size(); i++) {\n-        // Shift the subtitles to the position\n-        items[i].start += msTime;\n-        items[i].end += msTime;\n-        // Strip out HTML\n-        QStringList lines = QString::fromStdString(items[i].text).split('\\n');\n-        QString text;\n-        for (int i = 0; i < lines.size(); i++) {\n-            if (i != 0) {\n-                text += \"\\n\";\n-            }\n-            text += QTextDocumentFragment::fromHtml(lines[i]).toPlainText();\n-        }\n-        items[i].text = text.toUtf8().toStdString();\n-    }\n     ensureTrackExists();\n     m_model->importSubtitles(m_trackCombo->currentIndex(), msTime, items);\n     MAIN.showStatusMessage(QObject::tr(\"Imported %1 subtitle items\").arg(items.size()));\n@@ -906,6 +963,7 @@ void SubtitlesDock::updateActionAvailablity()\n         Actions[\"subtitleSetEndAction\"]->setEnabled(false);\n         Actions[\"subtitleBurnInAction\"]->setEnabled(false);\n         Actions[\"subtitleGenerateTextAction\"]->setEnabled(false);\n+        Actions[\"subtitleSpeechToTextAction\"]->setEnabled(false);\n     } else {\n         m_addToTimelineLabel->setVisible(false);\n         Actions[\"subtitleCreateEditItemAction\"]->setEnabled(true);\n@@ -913,6 +971,7 @@ void SubtitlesDock::updateActionAvailablity()\n         Actions[\"subtitleEditTrackAction\"]->setEnabled(true);\n         Actions[\"SubtitleImportAction\"]->setEnabled(true);\n         Actions[\"subtitleAddItemAction\"]->setEnabled(true);\n+        Actions[\"subtitleSpeechToTextAction\"]->setEnabled(true);\n         if (m_model->trackCount() == 0) {\n             Actions[\"subtitleRemoveTrackAction\"]->setEnabled(false);\n             Actions[\"SubtitleExportAction\"]->setEnabled(false);\n@@ -977,6 +1036,16 @@ void SubtitlesDock::selectItemForTime()\n     }\n }\n \n+QString SubtitlesDock::availableTrackName()\n+{\n+    int i = 1;\n+    QString suggestedName = tr(\"Subtitle Track %1\").arg(i);\n+    while (trackNameExists(suggestedName)) {\n+        suggestedName = tr(\"Subtitle Track %1\").arg(i++);\n+    }\n+    return suggestedName;\n+}\n+\n bool SubtitlesDock::trackNameExists(const QString &name)\n {\n     QList<SubtitlesModel::SubtitleTrack> tracks = m_model->getTracks();\n@@ -1022,7 +1091,6 @@ void SubtitlesDock::burnInOnTimeline()\n     emit createOrEditFilterOnOutput(&filter, QStringList() << \"feed\");\n }\n \n-\n void SubtitlesDock::generateTextOnTimeline()\n {\n     int trackIndex = m_trackCombo->currentIndex();\n@@ -1071,3 +1139,88 @@ void SubtitlesDock::generateTextOnTimeline()\n     }\n     emit addAllTimeline(&playlist, true, true);\n }\n+\n+void SubtitlesDock::speechToText()\n+{\n+    TranscribeAudioDialog dialog(availableTrackName(), this);\n+    if (dialog.exec() != QDialog::Accepted) {\n+        return;\n+    }\n+    if (trackNameExists(dialog.name())) {\n+        MAIN.showStatusMessage(tr(\"Subtitle track already exists: %1\").arg(dialog.name()));\n+        return;\n+    }\n+\n+    QString tmpLocation = QStandardPaths::writableLocation(QStandardPaths::AppDataLocation) + \"/\";\n+\n+    // Make a copy of the timeline producer\n+    QString xml = MLT.XML(MAIN.multitrack());\n+    std::unique_ptr<Mlt::Producer> tempProducer(new Mlt::Producer(MLT.profile(), \"xml-string\",\n+                                                                  xml.toUtf8().constData()));\n+\n+    // Mute tracks as requested\n+    Mlt::Tractor tractor(*tempProducer.get());\n+    if (!tractor.is_valid()) {\n+        LOG_ERROR() << \"Invalid tractor\";\n+        return;\n+    }\n+    int trackCount = tractor.count();\n+    if (trackCount <= 0) {\n+        LOG_ERROR() << \"No tracks\";\n+        return;\n+    }\n+    QList<int> tracks = dialog.tracks();\n+    for (int trackIndex = 0; trackIndex < trackCount; trackIndex++) {\n+        std::unique_ptr<Mlt::Producer> track(tractor.track(trackIndex));\n+        if (track) {\n+            if (tracks.contains(trackIndex)) {\n+                track->set(\"hide\", 0);\n+            } else {\n+                track->set(\"hide\", 2);\n+            }\n+        }\n+    }\n+\n+    // Convert to XML\n+    QString wavXml = MLT.XML(tempProducer.get());\n+\n+    // Create a temporary wav file\n+    QTemporaryFile *tmpWav = Util::writableTemporaryFile(tmpLocation, \"shotcut-XXXXXX.wav\");\n+    if (!tmpWav->open()) {\n+        LOG_ERROR() << \"Failed to open temporary file\" << tmpWav->fileName();\n+        return;\n+    }\n+    tmpWav->close();\n+\n+    // Make the wav file from the timeline\n+    QStringList args;\n+    args << \"-consumer\" << \"avformat:\" + tmpWav->fileName() << \"video_off=1\" << \"ar=16000\" << \"ac=1\";\n+    QString jobName = tr(\"Transcribe Audio Step 1: Extract Audio\");\n+    MeltJob *wavJob = new MeltJob(jobName, wavXml, args, MLT.profile().frame_rate_num(),\n+                                  MLT.profile().frame_rate_den());\n+    tmpWav->setParent(wavJob);\n+    JOBS.add(wavJob);\n+\n+    // Create a temporary srt file\n+    QTemporaryFile *tmpSrt = Util::writableTemporaryFile(tmpLocation, \"shotcut-XXXXXX.srt\");\n+    if (!tmpSrt->open()) {\n+        LOG_ERROR() << \"Failed to open temporary file\" << tmpSrt->fileName();\n+        return;\n+    }\n+    tmpWav->close();\n+\n+    // Run speech transcription on the wav file\n+    jobName = tr(\"Transcribe Audio Step 2: Transcribe Audio\");\n+    WhisperJob *whisperJob = new WhisperJob(jobName, tmpWav->fileName(), tmpSrt->fileName(),\n+                                            dialog.language(), dialog.translate(), dialog.maxLineLength());\n+    // Ensure the language code is 3 character (part 2)\n+    QString langCode = dialog.language();\n+    QLocale::Language lang = QLocale::codeToLanguage(langCode);\n+    if (lang != QLocale::AnyLanguage) {\n+        langCode = QLocale::languageToCode(lang, QLocale::ISO639Part2);\n+    }\n+    whisperJob->setPostJobAction(new ImportSrtPostJobAction(tmpSrt->fileName(), dialog.name(), langCode,\n+                                                            dialog.includeNonspoken(), this));\n+    tmpSrt->setParent(whisperJob);\n+    JOBS.add(whisperJob);\n+}\ndiff --git a/src/docks/subtitlesdock.h b/src/docks/subtitlesdock.h\nindex e64391dfba..585d636260 100644\n--- a/src/docks/subtitlesdock.h\n+++ b/src/docks/subtitlesdock.h\n@@ -27,9 +27,7 @@ class SubtitlesSelectionModel;\n class QComboBox;\n class QItemSelection;\n class QLabel;\n-class QLineEdit;\n class QTextEdit;\n-class QToolButton;\n class QTreeView;\n \n class SubtitlesDock : public QDockWidget\n@@ -40,6 +38,8 @@ class SubtitlesDock : public QDockWidget\n     explicit SubtitlesDock(QWidget *parent = 0);\n     ~SubtitlesDock();\n     void setModel(SubtitlesModel *model, SubtitlesSelectionModel *selectionModel);\n+    void importSrtFromFile(const QString &srtPath, const QString &trackName, const QString &lang,\n+                           bool includeNonspoken);\n \n signals:\n     void seekRequested(int pos);\n@@ -78,10 +78,13 @@ private slots:\n     void setCurrentItem(int trackIndex, int itemIndex);\n     void refreshWidgets();\n     void selectItemForTime();\n+    QString availableTrackName();\n     bool trackNameExists(const QString &name);\n     void ensureTrackExists();\n     void burnInOnTimeline();\n     void generateTextOnTimeline();\n+    void speechToText();\n+    bool findWhisperExe();\n \n     SubtitlesModel *m_model;\n     SubtitlesSelectionModel *m_selectionModel;\ndiff --git a/src/jobs/abstractjob.cpp b/src/jobs/abstractjob.cpp\nindex 1a88e7758d..ba0838bd18 100644\n--- a/src/jobs/abstractjob.cpp\n+++ b/src/jobs/abstractjob.cpp\n@@ -132,6 +132,7 @@ void AbstractJob::start(const QString &program, const QStringList &arguments)\n         prog = \"nice\";\n     }\n #endif\n+    appendToLog(prog + \" \" + args.join(\" \") + \"\\n\");\n     QProcess::start(prog, args);\n     AbstractJob::start();\n     m_actionPause->setEnabled(true);\ndiff --git a/src/jobs/meltjob.cpp b/src/jobs/meltjob.cpp\nindex fd8c00b890..abad607472 100644\n--- a/src/jobs/meltjob.cpp\n+++ b/src/jobs/meltjob.cpp\n@@ -1,5 +1,5 @@\n /*\n- * Copyright (c) 2012-2022 Meltytech, LLC\n+ * Copyright (c) 2012-2024 Meltytech, LLC\n  *\n  * This program is free software: you can redistribute it and/or modify\n  * it under the terms of the GNU General Public License as published by\n@@ -74,6 +74,13 @@ void MeltJob::onShowFolderTriggered()\n     Util::showInFolder(objectName());\n }\n \n+MeltJob::MeltJob(const QString &name, const QString &xml, const QStringList &args, int frameRateNum,\n+                 int frameRateDen)\n+    : MeltJob(name, xml, frameRateNum, frameRateDen)\n+{\n+    m_args = args;\n+}\n+\n MeltJob::MeltJob(const QString &name, const QStringList &args, int frameRateNum, int frameRateDen)\n     : MeltJob(name, QString(), frameRateNum, frameRateDen)\n {\n@@ -107,12 +114,15 @@ void MeltJob::start()\n     args << \"-verbose\";\n     args << \"-progress2\";\n     args << \"-abort\";\n+    if (!m_xml.isNull()) {\n+        if (m_useMultiConsumer) {\n+            args << \"xml:\" + QUrl::toPercentEncoding(xmlPath()) + \"?multi:1\";\n+        } else {\n+            args << \"xml:\" + QUrl::toPercentEncoding(xmlPath());\n+        }\n+    }\n     if (m_args.size() > 0) {\n         args.append(m_args);\n-    } else if (m_useMultiConsumer) {\n-        args << \"xml:\" + QUrl::toPercentEncoding(xmlPath()) + \"?multi:1\";\n-    } else {\n-        args << \"xml:\" + QUrl::toPercentEncoding(xmlPath());\n     }\n     if (m_in > -1) {\n         args << QString(\"in=%1\").arg(m_in);\ndiff --git a/src/jobs/meltjob.h b/src/jobs/meltjob.h\nindex c97fdfe603..ed85c1edc0 100644\n--- a/src/jobs/meltjob.h\n+++ b/src/jobs/meltjob.h\n@@ -1,5 +1,5 @@\n /*\n- * Copyright (c) 2012-2022 Meltytech, LLC\n+ * Copyright (c) 2012-2024 Meltytech, LLC\n  *\n  * This program is free software: you can redistribute it and/or modify\n  * it under the terms of the GNU General Public License as published by\n@@ -29,6 +29,8 @@ class MeltJob : public AbstractJob\n     MeltJob(const QString &name, const QString &xml, int frameRateNum, int frameRateDen,\n             QThread::Priority priority = Settings.jobPriority());\n     MeltJob(const QString &name, const QStringList &args, int frameRateNum, int frameRateDen);\n+    MeltJob(const QString &name, const QString &xml, const QStringList &args, int frameRateNum,\n+            int frameRateDen);\n     virtual ~MeltJob();\n     QString xml();\n     QString xmlPath() const\ndiff --git a/src/jobs/postjobaction.cpp b/src/jobs/postjobaction.cpp\nindex c499b7b2e7..f64943b88d 100644\n--- a/src/jobs/postjobaction.cpp\n+++ b/src/jobs/postjobaction.cpp\n@@ -18,6 +18,7 @@\n #include \"postjobaction.h\"\n #include \"mainwindow.h\"\n #include \"docks/playlistdock.h\"\n+#include \"docks/subtitlesdock.h\"\n #include \"shotcut_mlt_properties.h\"\n #include <Logger.h>\n \n@@ -117,3 +118,9 @@ void ProxyFinalizePostJobAction::doAction()\n         QFile::remove(m_dstFile);\n     }\n }\n+\n+\n+void ImportSrtPostJobAction::doAction()\n+{\n+    m_dock->importSrtFromFile(m_srtFile, m_trackName, m_lang, m_includeNonspoken);\n+}\ndiff --git a/src/jobs/postjobaction.h b/src/jobs/postjobaction.h\nindex d0ba7e8f68..2544dbe6c9 100644\n--- a/src/jobs/postjobaction.h\n+++ b/src/jobs/postjobaction.h\n@@ -1,5 +1,5 @@\n /*\n- * Copyright (c) 2018-2021 Meltytech, LLC\n+ * Copyright (c) 2018-2024 Meltytech, LLC\n  *\n  * This program is free software: you can redistribute it and/or modify\n  * it under the terms of the GNU General Public License as published by\n@@ -117,4 +117,28 @@ class ProxyFinalizePostJobAction : public FilePropertiesPostJobAction\n     QString m_dstFile;\n };\n \n+class SubtitlesDock;\n+\n+class ImportSrtPostJobAction : public PostJobAction\n+{\n+public:\n+    ImportSrtPostJobAction(const QString &srtFile, const QString &trackName, const QString &lang,\n+                           bool includeNonspoken, SubtitlesDock *dock)\n+        : m_srtFile(srtFile)\n+        , m_trackName(trackName)\n+        , m_lang(lang)\n+        , m_includeNonspoken(includeNonspoken)\n+        , m_dock(dock)\n+    {}\n+    virtual ~ImportSrtPostJobAction() {}\n+    void doAction();\n+\n+protected:\n+    const QString m_srtFile;\n+    const QString m_trackName;\n+    const QString m_lang;\n+    const bool m_includeNonspoken;\n+    SubtitlesDock *m_dock;\n+};\n+\n #endif // POSTJOBACTION_H\ndiff --git a/src/jobs/whisperjob.cpp b/src/jobs/whisperjob.cpp\nnew file mode 100644\nindex 0000000000..304914e619\n--- /dev/null\n+++ b/src/jobs/whisperjob.cpp\n@@ -0,0 +1,113 @@\n+/*\n+ * Copyright (c) 2024 Meltytech, LLC\n+ *\n+ * This program is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+#include \"whisperjob.h\"\n+\n+#include \"dialogs/textviewerdialog.h\"\n+#include <Logger.h>\n+#include \"mainwindow.h\"\n+\n+#include <QApplication>\n+#include <QDir>\n+#include <QFileInfo>\n+#include <QTimer>\n+#include <QThread>\n+\n+WhisperJob::WhisperJob(const QString &name, const QString &iWavFile, const QString &oSrtFile,\n+                       const QString &lang, bool translate, int maxLength,\n+                       QThread::Priority priority)\n+    : AbstractJob(name, priority)\n+    , m_iWavFile(iWavFile)\n+    , m_oSrtFile(oSrtFile)\n+    , m_lang(lang)\n+    , m_translate(translate)\n+    , m_maxLength(maxLength)\n+    , m_previousPercent(0)\n+{\n+}\n+\n+WhisperJob::~WhisperJob()\n+{\n+    LOG_DEBUG() << \"begin\";\n+}\n+\n+void WhisperJob::start()\n+{\n+    QString whisperPath = Settings.whisperExe();\n+    auto modelPath = Settings.whisperModel();\n+\n+    setReadChannel(QProcess::StandardOutput);\n+    setProcessChannelMode(QProcess::MergedChannels);\n+    QString of = m_oSrtFile;\n+    of.remove(\".srt\");\n+    QStringList args;\n+    args << \"-f\" << m_iWavFile;\n+    args << \"-m\" << modelPath;\n+    args << \"-l\" << m_lang;\n+    if (m_translate) {\n+        args << \"-tr\";\n+    }\n+    args << \"-of\" << of;\n+    args << \"-osrt\";\n+    args << \"-pp\";\n+    args << \"-ml\" << QString::number(m_maxLength);\n+    args << \"-sow\";\n+\n+#if QT_POINTER_SIZE == 4\n+    // Limit to 1 rendering thread on 32-bit process to reduce memory usage.\n+    auto threadCount = 1;\n+#else\n+    auto threadCount = qMax(1, QThread::idealThreadCount() - 1);\n+#endif\n+    args << \"-t\" << QString::number(threadCount);\n+\n+    LOG_DEBUG() << whisperPath  + \" \" + args.join(' ');\n+    AbstractJob::start(whisperPath, args);\n+    emit progressUpdated(m_item, 0);\n+}\n+\n+void WhisperJob::onViewSrtTriggered()\n+{\n+    QFile srtFile(m_oSrtFile);\n+    QString text = srtFile.readAll();\n+\n+    TextViewerDialog dialog(&MAIN, true);\n+    dialog.setWindowTitle(tr(\"SRT\"));\n+    dialog.setText(text);\n+    dialog.exec();\n+}\n+\n+void WhisperJob::onReadyRead()\n+{\n+    QString msg;\n+    do {\n+        msg = readLine();\n+        if (!msg.isEmpty()) {\n+            int index = msg.indexOf(\"progress = \");\n+            if (index > -1) {\n+                QString num = msg.mid(index + 11).remove(\"%\").trimmed();\n+                int percent = num.toInt();\n+                if (percent != m_previousPercent) {\n+                    emit progressUpdated(m_item, percent);\n+                    QCoreApplication::processEvents();\n+                    m_previousPercent = percent;\n+                }\n+            }\n+            appendToLog(msg);\n+        }\n+    } while (!msg.isEmpty());\n+}\ndiff --git a/src/jobs/whisperjob.h b/src/jobs/whisperjob.h\nnew file mode 100644\nindex 0000000000..90aa13676d\n--- /dev/null\n+++ b/src/jobs/whisperjob.h\n@@ -0,0 +1,49 @@\n+/*\n+ * Copyright (c) 2024 Meltytech, LLC\n+ *\n+ * This program is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+#ifndef WHISPERJOB_H\n+#define WHISPERJOB_H\n+\n+#include \"abstractjob.h\"\n+#include <QTemporaryFile>\n+\n+class WhisperJob : public AbstractJob\n+{\n+    Q_OBJECT\n+public:\n+    WhisperJob(const QString &name, const QString &iWavFile, const QString &oSrtFile,\n+               const QString &lang, bool translate, int maxLength,\n+               QThread::Priority priority = Settings.jobPriority());\n+    virtual ~WhisperJob();\n+\n+public slots:\n+    void start();\n+    void onViewSrtTriggered();\n+\n+protected slots:\n+    void onReadyRead();\n+\n+private:\n+    const QString m_iWavFile;\n+    const QString m_oSrtFile;\n+    const QString m_lang;\n+    const bool m_translate;\n+    const int m_maxLength;\n+    int m_previousPercent;\n+};\n+\n+#endif // WHISPERJOB_H\ndiff --git a/src/mainwindow.h b/src/mainwindow.h\nindex b5357a96c0..bd25494c39 100644\n--- a/src/mainwindow.h\n+++ b/src/mainwindow.h\n@@ -80,6 +80,10 @@ class MainWindow : public QMainWindow\n     {\n         return m_playlistDock;\n     }\n+    TimelineDock *timelineDock() const\n+    {\n+        return m_timelineDock;\n+    }\n     FilterController *filterController() const\n     {\n         return m_filterController;\ndiff --git a/src/models/subtitlesmodel.cpp b/src/models/subtitlesmodel.cpp\nindex 81d85dd9e2..c92d379921 100644\n--- a/src/models/subtitlesmodel.cpp\n+++ b/src/models/subtitlesmodel.cpp\n@@ -318,6 +318,29 @@ void SubtitlesModel::importSubtitles(int trackIndex, int64_t msTime,\n     MAIN.undoStack()->push(command);\n }\n \n+void SubtitlesModel::importSubtitlesToNewTrack(SubtitlesModel::SubtitleTrack &track,\n+                                               QList<Subtitles::SubtitleItem> &items)\n+{\n+    if (!m_producer) {\n+        LOG_DEBUG() << \"No producer\";\n+        return;\n+    }\n+\n+    int trackIndex = m_tracks.size();\n+\n+    MAIN.undoStack()->beginMacro(QObject::tr(\"Import %1 subtitle items\").arg(items.size()));\n+\n+    Subtitles::InsertTrackCommand *trackCommand = new Subtitles::InsertTrackCommand(*this, track,\n+                                                                                    trackIndex);\n+    MAIN.undoStack()->push(trackCommand);\n+\n+    Subtitles::OverwriteSubtitlesCommand *overwriteCommand = new Subtitles::OverwriteSubtitlesCommand(\n+        *this, trackIndex, items);\n+    MAIN.undoStack()->push(overwriteCommand);\n+\n+    MAIN.undoStack()->endMacro();\n+}\n+\n void SubtitlesModel::exportSubtitles(const QString &filePath, int trackIndex) const\n {\n     if (!m_producer) {\ndiff --git a/src/models/subtitlesmodel.h b/src/models/subtitlesmodel.h\nindex e220ecda40..865707757c 100644\n--- a/src/models/subtitlesmodel.h\n+++ b/src/models/subtitlesmodel.h\n@@ -78,6 +78,8 @@ class SubtitlesModel : public QAbstractItemModel\n     int itemIndexAfterTime(int trackIndex, int64_t msTime) const;\n     const Subtitles::SubtitleItem &getItem(int trackIndex, int itemIndex) const;\n     void importSubtitles(int trackIndex, int64_t msTime, QList<Subtitles::SubtitleItem> &items);\n+    void importSubtitlesToNewTrack(SubtitlesModel::SubtitleTrack &track,\n+                                   QList<Subtitles::SubtitleItem> &items);\n     void exportSubtitles(const QString &filePath, int trackIndex) const;\n     void overwriteItem(int trackIndex, const Subtitles::SubtitleItem &item);\n     void appendItem(int trackIndex, const Subtitles::SubtitleItem &item);\ndiff --git a/src/settings.cpp b/src/settings.cpp\nindex f15e74b5b5..a29172c4f6 100644\n--- a/src/settings.cpp\n+++ b/src/settings.cpp\n@@ -16,6 +16,9 @@\n  */\n \n #include \"settings.h\"\n+\n+#include \"qmltypes/qmlapplication.h\"\n+\n #include <QApplication>\n #include <QColor>\n #include <QLocale>\n@@ -1340,6 +1343,35 @@ bool ShotcutSettings::subtitlesShowPrevNext() const\n     return settings.value(\"subtitles/showPrevNext\", true).toBool();\n }\n \n+void ShotcutSettings::setWhisperExe(const QString &path)\n+{\n+    settings.setValue(\"subtitles/whisperExe\", path);\n+}\n+\n+QString ShotcutSettings::whisperExe()\n+{\n+    QDir dir(qApp->applicationDirPath());\n+#if defined(Q_OS_WIN)\n+    auto exe = \"whisper.cpp-main.exe\";\n+#else\n+    auto exe = \"whisper.cpp-main\";\n+#endif\n+    return settings.value(\"subtitles/whisperExe\", dir.absoluteFilePath(exe)).toString();\n+}\n+\n+void ShotcutSettings::setWhisperModel(const QString &path)\n+{\n+    settings.setValue(\"subtitles/whisperModel\", path);\n+}\n+\n+QString ShotcutSettings::whisperModel()\n+{\n+    QDir dataPath = QmlApplication::dataDir();\n+    dataPath.cd(\"shotcut/whisper_models\");\n+    return settings.value(\"subtitles/whisperModel\",\n+                          dataPath.absoluteFilePath(\"ggml-base-q5_1.bin\")).toString();\n+}\n+\n void ShotcutSettings::setNotesZoom(int zoom)\n {\n     settings.setValue(\"notes/zoom\", zoom);\ndiff --git a/src/settings.h b/src/settings.h\nindex c6a06e67a8..62f6b9be3a 100644\n--- a/src/settings.h\n+++ b/src/settings.h\n@@ -336,6 +336,10 @@ class ShotcutSettings : public QObject\n     bool subtitlesTrackTimeline() const;\n     void setSubtitlesShowPrevNext(bool b);\n     bool subtitlesShowPrevNext() const;\n+    void setWhisperExe(const QString &path);\n+    QString whisperExe();\n+    void setWhisperModel(const QString &path);\n+    QString whisperModel();\n \n     // Notes\n     void setNotesZoom(int zoom);\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Model Directory Structure**: Define a new directory structure for models: `appdata/models/whisper/` and for plugins as `appdata/plugins/`. This allows users to manage multiple models effectively. \n   \n2. **Model Selection UI**: Implement a UI option to allow users to select a custom model. Use an expandable drawer in the dialog. For distro packages, make it open by default to avoid confusion about model locations.\n\n3. **Executable Selection**: Integrate a file-open dialog to select the `whisper.cpp-main` executable if not found. Utilize `QFileDialog::getOpenFileName` similar to the implementation in `glaxnimateproducerwidget.cpp`.\n\n4. **OpenVINO Considerations**: Explore integrating OpenVINO for broader GPU support and potential audio noise reduction capabilities. \n\n5. **Documentation**: Update documentation to reflect these changes and assist users in understanding model placement, since reliance on documentation alone may lead to support requests. \n\nNext steps: Implement the above suggestions in the upcoming days."
      }
    ],
    "codediff_length": 53052
  },
  {
    "index": 117,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/scripts/build-shotcut.sh b/scripts/build-shotcut.sh\nindex 3dbe045c41..67303a6f66 100755\n--- a/scripts/build-shotcut.sh\n+++ b/scripts/build-shotcut.sh\n@@ -26,25 +26,10 @@ SOURCES_CLEAN=1\n INSTALL_AS_ROOT=0\n CREATE_STARTUP_SCRIPT=1\n ENABLE_FREI0R=1\n-FREI0R_HEAD=1\n-FREI0R_REVISION=\n ENABLE_MOVIT=1\n-SUBDIRS=\n-MOVIT_HEAD=1\n-MOVIT_REVISION=\n-LIBEPOXY_REVISION=\n-X264_HEAD=1\n-X264_REVISION=\n-X265_HEAD=1\n-X265_REVISION=\n-LIBVPX_HEAD=1\n-LIBVPX_REVISION=\n ENABLE_LAME=1\n-LIBOPUS_HEAD=1\n-LIBOPUS_REVISION=\n ENABLE_SWH_PLUGINS=1\n-FFMPEG_HEAD=0\n-FFMPEG_REVISION=\"origin/release/2.3\"\n+SUBDIRS=\n FFMPEG_SUPPORT_H264=1\n FFMPEG_SUPPORT_H265=1\n FFMPEG_SUPPORT_LIBVPX=1\n@@ -54,22 +39,42 @@ FFMPEG_SUPPORT_FAAC=0\n FFMPEG_SUPPORT_OPUS=1\n FFMPEG_ADDITIONAL_OPTIONS=\n ENABLE_VIDSTAB=1\n-VIDSTAB_HEAD=1\n-VIDSTAB_REVISION=\n-MLT_HEAD=1\n-MLT_REVISION=\n-LOG_COLORS=0\n-SHOTCUT_HEAD=1\n-SHOTCUT_REVISION=\n ENABLE_WEBVFX=1\n-WEBVFX_HEAD=1\n-WEBVFX_REVISION=\n+LOG_COLORS=0\n # QT_INCLUDE_DIR=\"$(pkg-config --variable=prefix QtCore)/include\"\n QT_INCLUDE_DIR=${QTDIR:+${QTDIR}/include}\n # QT_LIB_DIR=\"$(pkg-config --variable=prefix QtCore)/lib\"\n QT_LIB_DIR=${QTDIR:+${QTDIR}/lib}\n MLT_DISABLE_SOX=0\n \n+# Revisions section\n+# if XX_HEAD is set to 1, update-revs.sh will resolve the refspec\n+# from FETCHFROM and assign it to XX_REVISION\n+FREI0R_HEAD=1\n+FREI0R_REVISION=baa08d27193d758b5139dfa503dbedc881298f1c #v1.4-25-gbaa08d2 FETCHFROM:origin/master\n+MOVIT_HEAD=1\n+MOVIT_REVISION=b757b4f1ca57c6dcabfe4ad696a2b887544d1a71 #1.1.3 FETCHFROM:origin/master\n+LIBEPOXY_HEAD=1\n+LIBEPOXY_REVISION=20062c25e7612cab023cdef44d3277ba1bd0b2de #v1.2-13-g20062c2 FETCHFROM:origin/master\n+X264_HEAD=1\n+X264_REVISION=121396c71b4907ca82301d1a529795d98daab5f8 #unknown-tag FETCHFROM:origin/master\n+X265_HEAD=1\n+X265_REVISION=5c5574c5a98f15ddf545479d80296765398f1f09 #1.6-154-g5c5574c FETCHFROM:origin/master\n+LIBVPX_HEAD=1\n+LIBVPX_REVISION=5e300cac2ca3c7cc628a05a41e1e270387c5a690 #v1.4.0-111-g5e300ca FETCHFROM:origin/master\n+LIBOPUS_HEAD=1\n+LIBOPUS_REVISION=36e0445e619a2814b05d4e48dbaee785b70aac4d #draft-ietf-codec-oggopus-06-21-g36e0445 FETCHFROM:origin/master\n+VIDSTAB_HEAD=1\n+VIDSTAB_REVISION=4ec5be1ba92325de8154106a1470a49242459125 #release-0.98a-14-g4ec5be1 FETCHFROM:origin/master\n+MLT_HEAD=1\n+MLT_REVISION=e8257fb4cea1700b6211ac28542f0d5be37427a4 #v0.9.6-17-ge8257fb FETCHFROM:origin/master\n+SHOTCUT_HEAD=1\n+SHOTCUT_REVISION=a1622c54fa72413bdb5ac115af1ef2b2b7ddba16 #v15.04-9-ga1622c5 FETCHFROM:origin/master\n+WEBVFX_HEAD=1\n+WEBVFX_REVISION=a54b0938757d53033424f411a0292926249313ba #0.4.4-44-ga54b093 FETCHFROM:origin/master\n+FFMPEG_HEAD=0\n+FFMPEG_REVISION=\"origin/release/2.3\"\n+\n ################################################################################\n # Location of config file - if not overriden on command line\n CONFIGFILE=build-shotcut.conf\n@@ -390,7 +395,6 @@ function set_globals {\n   REPOLOCS[0]=\"git://github.com/FFmpeg/FFmpeg.git\"\n   REPOLOCS[1]=\"git://github.com/mltframework/mlt.git\"\n   REPOLOCS[2]=\"git://github.com/ddennedy/frei0r.git\"\n-#  REPOLOCS[3]=\"git://git.videolan.org/x264.git\"\n   REPOLOCS[3]=\"git://repo.or.cz/x264.git\"\n   REPOLOCS[4]=\"http://git.chromium.org/webm/libvpx.git\"\n   REPOLOCS[5]=\"http://git.sesse.net/movit/\"\n@@ -422,57 +426,20 @@ function set_globals {\n   REPOTYPES[14]=\"http-tgz\"\n \n   # And, set up the revisions\n-  REVISIONS[0]=\"\"\n-  if test 0 = \"$FFMPEG_HEAD\" -a \"$FFMPEG_REVISION\" ; then\n-    REVISIONS[0]=\"$FFMPEG_REVISION\"\n-  fi\n-  # Git, just use blank or the hash.\n-  REVISIONS[1]=\"\"\n-  if test 0 = \"$MLT_HEAD\" -a \"$MLT_REVISION\" ; then\n-    REVISIONS[1]=\"$MLT_REVISION\"\n-  fi\n-  REVISIONS[2]=\"\"\n-  if test 0 = \"$FREI0R_HEAD\" -a \"$FREI0R_REVISION\" ; then\n-    REVISIONS[2]=\"$FREI0R_REVISION\"\n-  fi\n-  REVISIONS[3]=\"\"\n-  if test 0 = \"$X264_HEAD\" -a \"$X264_REVISION\" ; then\n-    REVISIONS[3]=\"$X264_REVISION\"\n-  fi\n-  REVISIONS[4]=\"\"\n-  if test 0 = \"$LIBVPX_HEAD\" -a \"$LIBVPX_REVISION\" ; then\n-    REVISIONS[4]=\"$LIBVPX_REVISION\"\n-  fi\n-  REVISIONS[5]=\"\"\n-  if test 0 = \"$MOVIT_HEAD\" -a \"$MOVIT_REVISION\" ; then\n-    REVISIONS[5]=\"$MOVIT_REVISION\"\n-  fi\n+  REVISIONS[0]=\"$FFMPEG_REVISION\"\n+  REVISIONS[1]=\"$MLT_REVISION\"\n+  REVISIONS[2]=\"$FREI0R_REVISION\"\n+  REVISIONS[3]=\"$X264_REVISION\"\n+  REVISIONS[4]=\"$LIBVPX_REVISION\"\n+  REVISIONS[5]=\"$MOVIT_REVISION\"\n   REVISIONS[6]=\"lame-3.99.5\"\n-  REVISIONS[7]=\"\"\n-  if test 0 = \"$SHOTCUT_HEAD\" -a \"$SHOTCUT_REVISION\" ; then\n-    REVISIONS[7]=\"$SHOTCUT_REVISION\"\n-  fi\n+  REVISIONS[7]=\"$SHOTCUT_REVISION\"\n   REVISIONS[8]=\"swh-plugins-0.4.15+1\"\n-  REVISIONS[9]=\"\"\n-  if test 0 = \"$WEBVFX_HEAD\" -a \"$WEBVFX_REVISION\" ; then\n-    REVISIONS[9]=\"$WEBVFX_REVISION\"\n-  fi\n-  REVISIONS[10]=\"\"\n-  if test 0 = \"$VIDSTAB_HEAD\" -a \"$VIDSTAB_REVISION\" ; then\n-    REVISIONS[10]=\"$VIDSTAB_REVISION\"\n-  fi\n-  REVISIONS[11]=\"\"\n-  if test \"$LIBEPOXY_REVISION\" ; then\n-    REVISIONS[11]=\"$LIBEPOXY_REVISION\"\n-  fi\n-  REVISIONS[12]=\"\"\n-  if test 0 = \"$LIBOPUS_HEAD\" -a \"$LIBOPUS_REVISION\" ; then\n-    REVISIONS[12]=\"$LIBOPUS_REVISION\"\n-  fi\n-  REVISIONS[13]=\"\"\n-  if test 0 = \"$X265_HEAD\" -a \"$X265_REVISION\" ; then\n-    REVISIONS[13]=\"$X265_REVISION\"\n-  fi\n+  REVISIONS[9]=\"$WEBVFX_REVISION\"\n+  REVISIONS[10]=\"$VIDSTAB_REVISION\"\n+  REVISIONS[11]=\"$LIBEPOXY_REVISION\"\n+  REVISIONS[12]=\"$LIBOPUS_REVISION\"\n+  REVISIONS[13]=\"$X265_REVISION\"\n   REVISIONS[14]=\"eigen-eigen-10219c95fe65\"\n \n   # Figure out the number of cores in the system. Used both by make and startup script\n@@ -1126,15 +1093,26 @@ function get_subproject {\n               # Found git repo\n               debug \"Found git repo, will update\"\n \n-              if ! git diff-index --quiet ${REVISION:-master}; then\n-                  die \"git repository has local changes, aborting checkout. Consider disabling ACTION_GET_COMPILE_INSTALL or ACTION_GET_ONLY in your build config if you want to compile with these changes\"\n+              if [ -z \"$REVISION\" ]; then\n+                  die \"Building $1 without specifying a SHA is no longer supported\"\n               fi\n \n               feedback_status \"Pulling git sources for $1\"\n-              cmd git reset --hard || die \"Unable to reset git tree for $1\"\n-              cmd git checkout master || die \"Unable to git checkout master\"\n-              cmd git --no-pager pull $REPOLOC master || die \"Unable to git pull sources for $1\"\n-              cmd git checkout $REVISION || die \"Unable to git checkout $REVISION\"\n+              cmd git fetch $REPOLOC || die \"Unable to git fetch from $REPOLOC\"\n+\n+              if ! git rev-parse --verify $REVISION > /dev/null 2>&1; then\n+                  die \"$REVISION was not a reachable SHA after fetching from $REPOLOC\"\n+              fi\n+\n+              if ! git diff-index --quiet HEAD; then\n+                  die \"git repository has uncommited changes, aborting checkout. Consider disabling ACTION_GET_COMPILE_INSTALL or ACTION_GET_ONLY in your build config if you want to compile with these changes\"\n+              fi\n+\n+              if [ \"$(git rev-parse $REVISION)\" != \"$(git rev-parse HEAD)\" -a \"$(git merge-base HEAD $REVISION)\" ==  \"$(git rev-parse $REVISION)\" ]; then\n+                  die \"git repository HEAD is ahead of the remote, aborting checkout. Consider disabling ACTION_GET_COMPILE_INSTALL or ACTION_GET_ONLY in your build config if you want to compile with these changes\"\n+              fi\n+\n+              cmd git checkout -f $REVISION || die \"Unable to checkout $REVISION\"\n           else\n               # A dir with the expected name, but not a git repo, bailing out\n               PWD=`pwd`\ndiff --git a/scripts/update-revs.sh b/scripts/update-revs.sh\nnew file mode 100755\nindex 0000000000..177eda1fbf\n--- /dev/null\n+++ b/scripts/update-revs.sh\n@@ -0,0 +1,143 @@\n+#!/usr/bin/env bash\n+\n+set -e\n+cd $(dirname $0)\n+\n+updateSummary=$(mktemp)\n+trap \"rm $updateSummary\" EXIT\n+echo Pulled in new commits from dependency repoes >> $updateSummary\n+echo >> $updateSummary\n+\n+die() {\n+    echo \"ERROR: $@\"\n+    exit 1\n+}\n+\n+wasSetOnlyOnce() {\n+    local VARNAME=$1\n+    local FILE=$2\n+    test $(egrep \"^${VARNAME}=\" $FILE | wc -l) -eq 1\n+}\n+\n+readBashVar() {\n+    local NAME=$1\n+    local FILE=$2\n+\n+    if ! wasSetOnlyOnce ${NAME} $FILE; then\n+        die Expected ${NAME} to be set exactly once in $FILE\n+    fi\n+    egrep -o \"^${NAME}=[^ ]*\" $FILE | cut -d= -f2\n+}\n+\n+chdirToMatchingRepo() {\n+    remote=$1\n+    for repo in ../../*; do\n+        if test -f $repo/.git/config && grep -q $remote $repo/.git/config; then\n+            cd $repo\n+            return 0\n+        fi\n+    done\n+    return -1\n+}\n+\n+setBashVar() {\n+    local NAME=$1\n+    local VALUE=$2\n+    local FILE=$3\n+    local COMMENT=$4\n+    sed -i \"s?^${NAME}=.*?${NAME}=${VALUE} #${COMMENT}?g\" $FILE\n+}\n+\n+findRemote() {\n+    local VARNAME=$1\n+    local FILE=$2\n+    if [ $(egrep \"^${VARNAME}=\" $FILE | wc -l) -ne 1 ]; then\n+        die Expected $VARNAME to be set only once in $FILE\n+    fi\n+\n+    grep \"${VARNAME}.*FETCHFROM\" $FILE | egrep -o 'FETCHFROM:[^ ]+' | cut -d: -f2\n+}\n+\n+findRepository() {\n+    local INDEX=$1\n+    local FILE=$2\n+    egrep -o \"REPOLOCS\\[$INDEX\\]=.*\" $FILE | cut -d= -f2 | sed 's/\"//g'\n+}\n+\n+validate() {\n+    local NAME=$1\n+    local FILE=$2\n+\n+    if ! wasSetOnlyOnce ${NAME}_REVISION $FILE; then\n+        die Expected ${NAME}_REVISION to be set exactly once in $FILE\n+    fi\n+    if ! wasSetOnlyOnce ${NAME}_HEAD $FILE; then\n+        die Expected ${NAME}_HEAD to be set exactly once in $FILE\n+    fi\n+    if [ -z \"$(readBashVar ${NAME}_REVISION $FILE)\" ]; then\n+        die ${NAME}_REVISION was not set\n+    fi\n+}\n+\n+updateRevision() {\n+    local INDEX=$1\n+    local NAME=$2\n+\n+    if ! wasSetOnlyOnce ${NAME}_HEAD build-shotcut.sh; then\n+        die ${NAME}_HEAD was not set\n+    fi\n+\n+    local HEAD=$(readBashVar ${NAME}_HEAD build-shotcut.sh)\n+\n+    if [ \"$HEAD\" = \"1\" ]; then\n+        echo -- $NAME Reading from HEAD\n+        validate $NAME build-shotcut.sh\n+        REMOTE=$(findRemote ${NAME}_REVISION build-shotcut.sh)\n+        if [ -z \"$REMOTE\" ]; then\n+            die $NAME was set to read from HEAD, but did not have a FETCHFROM tag\n+        fi\n+        echo Remote detected: $REMOTE\n+        REPO=$(findRepository $INDEX build-shotcut.sh)\n+        echo Repository detected:  $REPO\n+        PREVIOUS_SHA=$(readBashVar ${NAME}_REVISION build-shotcut.sh)\n+        if ! chdirToMatchingRepo $REPO; then\n+            die Failed to find repo containing $REPO\n+        fi\n+        echo Entered $(pwd)\n+        git fetch\n+\n+        NEWSHA=$(git rev-parse $REMOTE)\n+        DESCRIPTION=$(git describe --tags $NEWSHA 2>/dev/null || echo unknown-tag)\n+        echo $REMOTE was resolved to $NEWSHA \\($DESCRIPTION\\)\n+        if [ \"$NEWSHA\" != \"$PREVIOUS_SHA\" ]; then\n+            echo $NAME: moving to $DESCRIPTION \\($(git log --oneline ${PREVIOUS_SHA}..${NEWSHA} | wc -l) new commits\\) | tee -a $updateSummary\n+            echo \"    $PREVIOUS_SHA..$NEWSHA\" | tee -a $updateSummary\n+            echo Inspect with: git -C $(pwd) log $PREVIOUS_SHA..$NEWSHA\n+        fi\n+        cd - > /dev/null\n+        setBashVar ${NAME}_REVISION \"$NEWSHA\" \"build-shotcut.sh\" \"$DESCRIPTION FETCHFROM:${REMOTE}\"\n+\n+    elif [ \"$HEAD\" = \"0\" ]; then\n+        echo -- $NAME Not reading from HEAD\n+    else\n+        die ${NAME}_HEAD is invalid, set to $HEAD\n+    fi\n+}\n+\n+updateRevision 0  FFMPEG\n+updateRevision 1  MLT\n+updateRevision 2  FREI0R\n+updateRevision 3  X264\n+updateRevision 4  LIBVPX\n+updateRevision 5  MOVIT\n+updateRevision 7  SHOTCUT\n+updateRevision 9  WEBVFX\n+updateRevision 10 VIDSTAB\n+updateRevision 11 LIBEPOXY\n+updateRevision 12 LIBOPUS\n+updateRevision 13 X265\n+\n+if [ $(cat $updateSummary | wc -l) -gt 2 ]; then\n+    git commit -F $updateSummary build-shotcut.sh\n+fi\n+\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Add a switch to allow specifying the latest version for all or specific dependencies to facilitate automated builds against the latest versions.\n\n2. Restore the ability to specify branch/version in the config script, as it was removed unintentionally. Ensure users can pin versions.\n\n3. Propose that build servers execute `update-revs.sh` before `build-shotcut.sh`, discarding the resulting commit or making the commit optional.\n\n4. Consider simplifying update processes: revert to previous manual revision updates on a monthly basis for clarity, while allowing user overrides in the config.\n\n5. Address workflow compatibility issues with `update-revs.sh` in clean build environments; suggest adjustments to accommodate this condition.\n\n6. Maintain ability for users to specify individual projects in builds to enhance workflow efficiency."
      }
    ],
    "codediff_length": 11684
  },
  {
    "index": 118,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/src/dialogs/transcodedialog.cpp b/src/dialogs/transcodedialog.cpp\nindex 18b6cf76fc..1554a08c0a 100644\n--- a/src/dialogs/transcodedialog.cpp\n+++ b/src/dialogs/transcodedialog.cpp\n@@ -106,6 +106,17 @@ void TranscodeDialog::set709Convert(bool enable)\n     ui->convert709CheckBox->setChecked(enable);\n }\n \n+QString TranscodeDialog::sampleRate() const\n+{\n+    QString sampleRate;\n+    if ( ui->sampleRateComboBox->currentIndex() == 1 ) {\n+        sampleRate = \"44100\";\n+    } else if ( ui->sampleRateComboBox->currentIndex() == 2 ) {\n+        sampleRate = \"48000\";\n+    }\n+    return sampleRate;\n+}\n+\n void TranscodeDialog::showSubClipCheckBox()\n {\n     ui->subclipCheckBox->show();\ndiff --git a/src/dialogs/transcodedialog.h b/src/dialogs/transcodedialog.h\nindex 0b2e2d86d7..3579a36638 100644\n--- a/src/dialogs/transcodedialog.h\n+++ b/src/dialogs/transcodedialog.h\n@@ -46,6 +46,7 @@ class TranscodeDialog : public QDialog\n     QString frc() const;\n     bool get709Convert();\n     void set709Convert(bool enable);\n+    QString sampleRate() const;\n     void showSubClipCheckBox();\n     bool isSubClip() const;\n     void setSubClipChecked(bool checked);\ndiff --git a/src/dialogs/transcodedialog.ui b/src/dialogs/transcodedialog.ui\nindex bcc070239b..31bac12ba4 100644\n--- a/src/dialogs/transcodedialog.ui\n+++ b/src/dialogs/transcodedialog.ui\n@@ -144,7 +144,7 @@\n     <widget class=\"QWidget\" name=\"advancedWidget\" native=\"true\">\r\n      <layout class=\"QVBoxLayout\" name=\"verticalLayout_2\">\r\n       <item>\r\n-       <layout class=\"QGridLayout\" name=\"gridLayout\" columnstretch=\"0,1\">\r\n+       <layout class=\"QGridLayout\" name=\"gridLayout\" columnstretch=\"0,0\">\r\n         <item row=\"4\" column=\"1\">\r\n          <widget class=\"FrameRateWidget\" name=\"fpsWidget\" native=\"true\">\r\n           <property name=\"toolTip\">\r\n@@ -152,37 +152,36 @@\n           </property>\r\n          </widget>\r\n         </item>\r\n-        <item row=\"0\" column=\"0\" colspan=\"2\">\r\n-         <widget class=\"Line\" name=\"line\">\r\n-          <property name=\"orientation\">\r\n-           <enum>Qt::Horizontal</enum>\r\n-          </property>\r\n-         </widget>\r\n-        </item>\r\n-        <item row=\"3\" column=\"1\">\r\n-         <widget class=\"QCheckBox\" name=\"fpsCheckBox\">\r\n+        <item row=\"6\" column=\"1\">\r\n+         <widget class=\"QCheckBox\" name=\"convert709CheckBox\">\r\n           <property name=\"toolTip\">\r\n-           <string>Change the frame rate from its source.</string>\r\n+           <string>This is useful when the source video is HDR (High Dynamic Range), which requires tone-mapping to the old, standard range.</string>\r\n           </property>\r\n           <property name=\"text\">\r\n-           <string>Override frame rate</string>\r\n+           <string>Convert to BT.709 colorspace</string>\r\n           </property>\r\n          </widget>\r\n         </item>\r\n-        <item row=\"6\" column=\"1\">\r\n-         <widget class=\"QCheckBox\" name=\"convert709CheckBox\">\r\n+        <item row=\"1\" column=\"1\">\r\n+         <widget class=\"QCheckBox\" name=\"subclipCheckBox\">\r\n           <property name=\"toolTip\">\r\n-           <string>This is useful when the source video is HDR (High Dynamic Range), which requires tone-mapping to the old, standard range.</string>\r\n+           <string>This option converts only the trimmed portion of the source\r\n+clip plus a little instead of the entire clip. When this option is\r\n+used not all of the matching source clips are replaced, instead\r\n+only the currently selected one.</string>\r\n           </property>\r\n           <property name=\"text\">\r\n-           <string>Convert to BT.709 colorspace</string>\r\n+           <string>Use sub-clip</string>\r\n           </property>\r\n          </widget>\r\n         </item>\r\n-        <item row=\"5\" column=\"0\">\r\n-         <widget class=\"QLabel\" name=\"frcLabel\">\r\n+        <item row=\"9\" column=\"1\">\r\n+         <widget class=\"QCheckBox\" name=\"advancedCheckBox\">\r\n+          <property name=\"toolTip\">\r\n+           <string>Enable this to keep the Advanced section open for the next time this dialog appears.</string>\r\n+          </property>\r\n           <property name=\"text\">\r\n-           <string>Frame rate conversion</string>\r\n+           <string>Keep Advanced open</string>\r\n           </property>\r\n          </widget>\r\n         </item>\r\n@@ -197,16 +196,30 @@ Motion Compensation: Interpolate new frames using motion compensation. This meth\n           </property>\r\n          </widget>\r\n         </item>\r\n-        <item row=\"1\" column=\"1\">\r\n-         <widget class=\"QCheckBox\" name=\"subclipCheckBox\">\r\n+        <item row=\"0\" column=\"0\" colspan=\"2\">\r\n+         <widget class=\"Line\" name=\"line\">\r\n+          <property name=\"orientation\">\r\n+           <enum>Qt::Horizontal</enum>\r\n+          </property>\r\n+         </widget>\r\n+        </item>\r\n+        <item row=\"3\" column=\"1\">\r\n+         <widget class=\"QCheckBox\" name=\"fpsCheckBox\">\r\n           <property name=\"toolTip\">\r\n-           <string>This option converts only the trimmed portion of the source\r\n-clip plus a little instead of the entire clip. When this option is\r\n-used not all of the matching source clips are replaced, instead\r\n-only the currently selected one.</string>\r\n+           <string>Change the frame rate from its source.</string>\r\n           </property>\r\n           <property name=\"text\">\r\n-           <string>Use sub-clip</string>\r\n+           <string>Override frame rate</string>\r\n+          </property>\r\n+         </widget>\r\n+        </item>\r\n+        <item row=\"7\" column=\"0\">\r\n+         <widget class=\"QLabel\" name=\"sampleRateLabel\">\r\n+          <property name=\"enabled\">\r\n+           <bool>true</bool>\r\n+          </property>\r\n+          <property name=\"text\">\r\n+           <string>Sample rate</string>\r\n           </property>\r\n          </widget>\r\n         </item>\r\n@@ -227,14 +240,36 @@ only the currently selected one.</string>\n           </property>\r\n          </widget>\r\n         </item>\r\n+        <item row=\"5\" column=\"0\">\r\n+         <widget class=\"QLabel\" name=\"frcLabel\">\r\n+          <property name=\"text\">\r\n+           <string>Frame rate conversion</string>\r\n+          </property>\r\n+         </widget>\r\n+        </item>\r\n         <item row=\"7\" column=\"1\">\r\n-         <widget class=\"QCheckBox\" name=\"advancedCheckBox\">\r\n-          <property name=\"toolTip\">\r\n-           <string>Enable this to keep the Advanced section open for the next time this dialog appears.</string>\r\n+         <widget class=\"QComboBox\" name=\"sampleRateComboBox\">\r\n+          <property name=\"enabled\">\r\n+           <bool>true</bool>\r\n           </property>\r\n-          <property name=\"text\">\r\n-           <string>Keep Advanced open</string>\r\n+          <property name=\"currentText\">\r\n+           <string>Same as original</string>\r\n           </property>\r\n+          <item>\r\n+           <property name=\"text\">\r\n+            <string>Same as original</string>\r\n+           </property>\r\n+          </item>\r\n+          <item>\r\n+           <property name=\"text\">\r\n+            <string>44100</string>\r\n+           </property>\r\n+          </item>\r\n+          <item>\r\n+           <property name=\"text\">\r\n+            <string>48000</string>\r\n+           </property>\r\n+          </item>\r\n          </widget>\r\n         </item>\r\n        </layout>\r\ndiff --git a/src/widgets/avformatproducerwidget.cpp b/src/widgets/avformatproducerwidget.cpp\nindex eb3eeb08cb..6f5704405d 100644\n--- a/src/widgets/avformatproducerwidget.cpp\n+++ b/src/widgets/avformatproducerwidget.cpp\n@@ -861,6 +861,11 @@ void AvformatProducerWidget::convert(TranscodeDialog &dialog)\n         }\n         args << \"-map_metadata\" << \"0\" << \"-ignore_unknown\";\n \n+        // Set Sample rate if different than source\n+        if ( !dialog.sampleRate().isEmpty() ) {\n+            args << \"-ar\" << dialog.sampleRate();\n+        }\n+\n         // Set video filters\n         args << \"-vf\";\n         QString filterString;\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Audio artifacts may occur when concatenating independently resampled audio chunks. Investigate over/underflow issues in MLT services related to resampling. \n2. Implement user-configurable audio sample rate conversion that defaults to \u201cno change.\u201d \n3. Create a \"ducking\" mechanism to smoothly transition between clips to mitigate discontinuity, possibly integrated with the mix transition feature. \n4. Explore implementing audio sample rate conversion as a link rather than a filter to streamline processing. \n5. Consider integrating FFmpeg's adeclick filter into Shotcut to handle problematic audio sources. \n6. Develop a full-time audio proxy system to optimize memory usage while exporting at different sample rates. \n7. Ensure clear user options and naming conventions to avoid confusion between Export and Convert functionalities."
      }
    ],
    "codediff_length": 7830
  },
  {
    "index": 119,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/makefiles/Makefile.dotnet.mk b/makefiles/Makefile.dotnet.mk\nindex 8bb8b003687..1895f3bd389 100644\n--- a/makefiles/Makefile.dotnet.mk\n+++ b/makefiles/Makefile.dotnet.mk\n@@ -68,12 +68,15 @@ endif\n DOTNET_ORTOOLS_SNK := $(BIN_DIR)/or-tools.snk\n DOTNET_ORTOOLS_SNK_PATH := $(subst /,$S,$(DOTNET_ORTOOLS_SNK))\n OR_TOOLS_ASSEMBLY_NAME := Google.OrTools\n-OR_TOOLS_NATIVE_ASSEMBLY_NAME := $(OR_TOOLS_ASSEMBLY_NAME).runtime.$(RUNTIME_IDENTIFIER)\n+OR_TOOLS_NATIVE_PROJECT_NAME := $(OR_TOOLS_ASSEMBLY_NAME).runtime.$(RUNTIME_IDENTIFIER)\n+OR_TOOLS_NATIVE_ASSEMBLY_NAME := google-ortools-native\n OR_TOOLS_FSHARP_ASSEMBLY_NAME := $(OR_TOOLS_ASSEMBLY_NAME).FSharp\n OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME := $(OR_TOOLS_ASSEMBLY_NAME).FSharp.Tests\n DOTNET_ORTOOLS_NUPKG := $(PACKAGE_DIR)/$(OR_TOOLS_ASSEMBLY_NAME).$(OR_TOOLS_VERSION).nupkg\n-DOTNET_ORTOOLS_NATIVE_NUPKG := $(PACKAGE_DIR)/$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).$(OR_TOOLS_VERSION).nupkg\n+DOTNET_ORTOOLS_NATIVE_NUPKG := $(PACKAGE_DIR)/$(OR_TOOLS_NATIVE_PROJECT_NAME).$(OR_TOOLS_VERSION).nupkg\n DOTNET_ORTOOLS_FSHARP_NUPKG := $(PACKAGE_DIR)/$(OR_TOOLS_FSHARP_ASSEMBLY_NAME).$(OR_TOOLS_VERSION).nupkg\n+NUGET_PACK_ARGS := -c Release --include-symbols\n+DOTNET_BUILD_ARGS := -c Release /p:Platform=x64\n \n ######################\n ##  RUNTIME CSHARP  ##\n@@ -81,7 +84,9 @@ DOTNET_ORTOOLS_FSHARP_NUPKG := $(PACKAGE_DIR)/$(OR_TOOLS_FSHARP_ASSEMBLY_NAME).$\n .PHONY: dotnet_runtime # Build C# runtime OR-Tools\n dotnet_runtime: $(DOTNET_ORTOOLS_NATIVE_NUPKG)\n \n-# Protobufs generated code\n+###################################################################\n+# Protobuf: generate C# cs files from proto specification files. ##\n+###################################################################\n $(GEN_DIR)/ortools/constraint_solver/SearchLimit.pb.cs: \\\n  $(SRC_DIR)/ortools/constraint_solver/search_limit.proto \\\n  | $(GEN_DIR)/ortools/constraint_solver\n@@ -138,7 +143,9 @@ $(GEN_DIR)/ortools/util/OptionalBoolean.pb.cs: \\\n  --csharp_opt=file_extension=.pb.cs \\\n  $(SRC_DIR)$Sortools$Sutil$Soptional_boolean.proto\n \n-# Auto-generated rid dependent source code\n+#############################################################################################\n+# Swig: Generate C# wrapper cs files from swig specification files and C wrapper .c files. ##\n+#############################################################################################\n $(GEN_DIR)/ortools/linear_solver/linear_solver_csharp_wrap.cc: \\\n  $(SRC_DIR)/ortools/linear_solver/csharp/linear_solver.i \\\n  $(SRC_DIR)/ortools/base/base.i \\\n@@ -150,7 +157,7 @@ $(GEN_DIR)/ortools/linear_solver/linear_solver_csharp_wrap.cc: \\\n  -o $(GEN_PATH)$Sortools$Slinear_solver$Slinear_solver_csharp_wrap.cc \\\n  -module operations_research_linear_solver \\\n  -namespace $(OR_TOOLS_ASSEMBLY_NAME).LinearSolver \\\n- -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).$(SWIG_DOTNET_LIB_SUFFIX)\" \\\n+ -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)\" \\\n  -outdir $(GEN_PATH)$Sortools$Slinear_solver \\\n  $(SRC_DIR)$Sortools$Slinear_solver$Scsharp$Slinear_solver.i\n \n@@ -172,7 +179,7 @@ $(GEN_DIR)/ortools/constraint_solver/constraint_solver_csharp_wrap.cc: \\\n  -o $(GEN_PATH)$Sortools$Sconstraint_solver$Sconstraint_solver_csharp_wrap.cc \\\n  -module operations_research_constraint_solver \\\n  -namespace $(OR_TOOLS_ASSEMBLY_NAME).ConstraintSolver \\\n- -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).$(SWIG_DOTNET_LIB_SUFFIX)\" \\\n+ -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)\" \\\n  -outdir $(GEN_PATH)$Sortools$Sconstraint_solver \\\n  $(SRC_DIR)$Sortools$Sconstraint_solver$Scsharp$Srouting.i\n \t$(SED) -i -e 's/CSharp_new_Solver/CSharp_new_CpSolver/g' \\\n@@ -216,7 +223,7 @@ $(GEN_DIR)/ortools/algorithms/knapsack_solver_csharp_wrap.cc: \\\n  -o $(GEN_PATH)$Sortools$Salgorithms$Sknapsack_solver_csharp_wrap.cc \\\n  -module operations_research_algorithms \\\n  -namespace $(OR_TOOLS_ASSEMBLY_NAME).Algorithms \\\n- -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).$(SWIG_DOTNET_LIB_SUFFIX)\" \\\n+ -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)\" \\\n  -outdir $(GEN_PATH)$Sortools$Salgorithms \\\n  $(SRC_DIR)$Sortools$Salgorithms$Scsharp$Sknapsack_solver.i\n \t$(SED) -i -e 's/< long long >/< int64_t >/g' \\\n@@ -240,7 +247,7 @@ $(GEN_DIR)/ortools/graph/graph_csharp_wrap.cc: \\\n  -o $(GEN_PATH)$Sortools$Sgraph$Sgraph_csharp_wrap.cc \\\n  -module operations_research_graph \\\n  -namespace $(OR_TOOLS_ASSEMBLY_NAME).Graph \\\n- -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).$(SWIG_DOTNET_LIB_SUFFIX)\" \\\n+ -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)\" \\\n  -outdir $(GEN_PATH)$Sortools$Sgraph \\\n  $(SRC_DIR)$Sortools$Sgraph$Scsharp$Sgraph.i\n \n@@ -261,7 +268,7 @@ $(GEN_DIR)/ortools/sat/sat_csharp_wrap.cc: \\\n  -o $(GEN_PATH)$Sortools$Ssat$Ssat_csharp_wrap.cc \\\n  -module operations_research_sat \\\n  -namespace $(OR_TOOLS_ASSEMBLY_NAME).Sat \\\n- -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).$(SWIG_DOTNET_LIB_SUFFIX)\" \\\n+ -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)\" \\\n  -outdir $(GEN_PATH)$Sortools$Ssat \\\n  $(SRC_DIR)$Sortools$Ssat$Scsharp$Ssat.i\n \n@@ -282,7 +289,7 @@ $(GEN_DIR)/ortools/util/sorted_interval_list_csharp_wrap.cc: \\\n  -o $(GEN_PATH)$Sortools$Sutil$Ssorted_interval_list_csharp_wrap.cc \\\n  -module operations_research_util \\\n  -namespace $(OR_TOOLS_ASSEMBLY_NAME).Util \\\n- -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).$(SWIG_DOTNET_LIB_SUFFIX)\" \\\n+ -dllimport \"$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)\" \\\n  -outdir $(GEN_PATH)$Sortools$Sutil \\\n  $(SRC_DIR)$Sortools$Sutil$Scsharp$Ssorted_interval_list.i\n \t$(SED) -i -e 's/< long long >/< int64 >/g' \\\n@@ -295,6 +302,9 @@ $(OBJ_DIR)/swig/sorted_interval_list_csharp_wrap.$O: \\\n  -c $(GEN_PATH)$Sortools$Sutil$Ssorted_interval_list_csharp_wrap.cc \\\n  $(OBJ_OUT)$(OBJ_DIR)$Sswig$Ssorted_interval_list_csharp_wrap.$O\n \n+############\n+# Signing ##\n+############\n ifneq ($(DOTNET_SNK),)\n $(DOTNET_ORTOOLS_SNK): | $(BIN_DIR)\n \t$(COPY) $(DOTNET_SNK) $(DOTNET_ORTOOLS_SNK_PATH)\n@@ -303,6 +313,9 @@ $(DOTNET_ORTOOLS_SNK): ortools/dotnet/CreateSigningKey/CreateSigningKey.csproj |\n \t\"$(DOTNET_BIN)\" run --project ortools$Sdotnet$SCreateSigningKey$SCreateSigningKey.csproj $S$(DOTNET_ORTOOLS_SNK_PATH)\n endif\n \n+##########################################\n+# Swig: Generate native wrapper binary. ##\n+##########################################\n $(LIB_DIR)/$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).$(SWIG_DOTNET_LIB_SUFFIX): \\\n  $(OR_TOOLS_LIBS) \\\n  $(OBJ_DIR)/swig/linear_solver_csharp_wrap.$O \\\n@@ -323,15 +336,15 @@ $(LIB_DIR)/$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).$(SWIG_DOTNET_LIB_SUFFIX): \\\n  $(OR_TOOLS_LNK) \\\n  $(OR_TOOLS_LDFLAGS)\n \n-$(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)/$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).csproj: \\\n- $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)/$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).csproj.in\n+$(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_NATIVE_PROJECT_NAME)/$(OR_TOOLS_NATIVE_PROJECT_NAME).csproj: \\\n+ $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_NATIVE_PROJECT_NAME)/$(OR_TOOLS_NATIVE_PROJECT_NAME).csproj.in\n \t$(SED) -e \"s/@PROJECT_VERSION@/$(OR_TOOLS_VERSION)/\" \\\n- ortools$Sdotnet$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).csproj.in \\\n- > ortools$Sdotnet$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).csproj\n+ ortools$Sdotnet$S$(OR_TOOLS_NATIVE_PROJECT_NAME)$S$(OR_TOOLS_NATIVE_PROJECT_NAME).csproj.in \\\n+ > ortools$Sdotnet$S$(OR_TOOLS_NATIVE_PROJECT_NAME)$S$(OR_TOOLS_NATIVE_PROJECT_NAME).csproj\n \n $(DOTNET_ORTOOLS_NATIVE_NUPKG): \\\n  $(LIB_DIR)/$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).$(SWIG_DOTNET_LIB_SUFFIX) \\\n- $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)/$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).csproj \\\n+ $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_NATIVE_PROJECT_NAME)/$(OR_TOOLS_NATIVE_PROJECT_NAME).csproj \\\n  $(SRC_DIR)/ortools/constraint_solver/csharp/IntVarArrayHelper.cs \\\n  $(SRC_DIR)/ortools/constraint_solver/csharp/IntervalVarArrayHelper.cs \\\n  $(SRC_DIR)/ortools/constraint_solver/csharp/IntArrayHelper.cs \\\n@@ -358,8 +371,8 @@ $(DOTNET_ORTOOLS_NATIVE_NUPKG): \\\n  $(GEN_DIR)/ortools/sat/CpModel.pb.cs \\\n  $(GEN_DIR)/ortools/util/OptionalBoolean.pb.cs \\\n  | $(DOTNET_ORTOOLS_SNK) $(PACKAGE_DIR)\n-\t\"$(DOTNET_BIN)\" build ortools$Sdotnet$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).csproj\n-\t\"$(DOTNET_BIN)\" pack ortools$Sdotnet$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME).csproj\n+\t\"$(DOTNET_BIN)\" build $(DOTNET_BUILD_ARGS) ortools$Sdotnet$S$(OR_TOOLS_NATIVE_PROJECT_NAME)$S$(OR_TOOLS_NATIVE_PROJECT_NAME).csproj\n+\t\"$(DOTNET_BIN)\" pack $(NUGET_PACK_ARGS) ortools$Sdotnet$S$(OR_TOOLS_NATIVE_PROJECT_NAME)$S$(OR_TOOLS_NATIVE_PROJECT_NAME).csproj\n \n ##############\n ##  CSHARP  ##\n@@ -367,25 +380,20 @@ $(DOTNET_ORTOOLS_NATIVE_NUPKG): \\\n .PHONY: dotnet_csharp # Build C# OR-Tools\n dotnet_csharp: $(DOTNET_ORTOOLS_NUPKG)\n \n+#  create csproj for managed project\n $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_ASSEMBLY_NAME)/$(OR_TOOLS_ASSEMBLY_NAME).csproj: \\\n  $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_ASSEMBLY_NAME)/$(OR_TOOLS_ASSEMBLY_NAME).csproj.in\n \t$(SED) -e \"s/@PROJECT_VERSION@/$(OR_TOOLS_VERSION)/\" \\\n  ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)$S$(OR_TOOLS_ASSEMBLY_NAME).csproj.in \\\n  > ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)$S$(OR_TOOLS_ASSEMBLY_NAME).csproj\n \n-$(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_ASSEMBLY_NAME)/runtime.json: \\\n- $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_ASSEMBLY_NAME)/runtime.json.in\n-\t$(SED) -e \"s/@PROJECT_VERSION@/$(OR_TOOLS_VERSION)/\" \\\n- ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)$Sruntime.json.in \\\n- > ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)$Sruntime.json\n-\n+# Pack managed project nuget\n $(DOTNET_ORTOOLS_NUPKG): \\\n  $(DOTNET_ORTOOLS_NATIVE_NUPKG) \\\n  $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_ASSEMBLY_NAME)/$(OR_TOOLS_ASSEMBLY_NAME).csproj \\\n- $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_ASSEMBLY_NAME)/runtime.json \\\n  | $(DOTNET_ORTOOLS_SNK) $(PACKAGE_DIR)\n-\t\"$(DOTNET_BIN)\" build ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)\n-\t\"$(DOTNET_BIN)\" pack ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)\n+\t\"$(DOTNET_BIN)\" build $(DOTNET_BUILD_ARGS) ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)\n+\t\"$(DOTNET_BIN)\" pack $(NUGET_PACK_ARGS) ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)\n \n ##############\n ##  FSHARP  ##\n@@ -393,19 +401,22 @@ $(DOTNET_ORTOOLS_NUPKG): \\\n .PHONY: dotnet_fsharp # Build F# OR-Tools\n dotnet_fsharp: $(DOTNET_ORTOOLS_FSHARP_NUPKG)\n \n+# create fsproj\n $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)/$(OR_TOOLS_FSHARP_ASSEMBLY_NAME).fsproj: \\\n  $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)/$(OR_TOOLS_FSHARP_ASSEMBLY_NAME).fsproj.in\n \t$(SED) -e \"s/@PROJECT_VERSION@/$(OR_TOOLS_VERSION)/\" \\\n  ortools$Sdotnet$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME).fsproj.in \\\n  > ortools$Sdotnet$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME).fsproj\n \n+# build and pack nuget\n $(DOTNET_ORTOOLS_FSHARP_NUPKG): \\\n  $(DOTNET_ORTOOLS_NUPKG) \\\n  $(SRC_DIR)/ortools/dotnet/$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)/$(OR_TOOLS_FSHARP_ASSEMBLY_NAME).fsproj \\\n  | $(DOTNET_ORTOOLS_SNK) $(PACKAGE_DIR)\n-\t\"$(DOTNET_BIN)\" build ortools$Sdotnet$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)\n-\t\"$(DOTNET_BIN)\" pack ortools$Sdotnet$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)\n+\t\"$(DOTNET_BIN)\" build $(DOTNET_BUILD_ARGS) ortools$Sdotnet$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)\n+\t\"$(DOTNET_BIN)\" pack $(NUGET_PACK_ARGS) ortools$Sdotnet$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)\n \n+# create test fsproj\n ortools/dotnet/$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME)/$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME).fsproj: \\\n  ortools/dotnet/$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME)/$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME).fsproj.in\n \t$(SED) -e \"s/@PROJECT_VERSION@/$(OR_TOOLS_VERSION)/\" \\\n@@ -415,8 +426,8 @@ ortools/dotnet/$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME)/$(OR_TOOLS_FSHARP_TESTS_AS\n .PHONY: test_dotnet_fsharp # Run F# OrTools Tests\n test_dotnet_fsharp: $(DOTNET_ORTOOLS_FSHARP_NUPKG) \\\n  ortools/dotnet/$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME)/$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME).fsproj\n-\t\"$(DOTNET_BIN)\" build ortools$Sdotnet$S$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME)\n-\t\"$(DOTNET_BIN)\" test ortools$Sdotnet$S$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME)\n+\t\"$(DOTNET_BIN)\" build $(DOTNET_BUILD_ARGS) ortools$Sdotnet$S$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME)\n+\t\"$(DOTNET_BIN)\" test $(DOTNET_BUILD_ARGS) ortools$Sdotnet$S$(OR_TOOLS_FSHARP_TESTS_ASSEMBLY_NAME)\n \n ###################\n ##  .NET SOURCE  ##\n@@ -691,11 +702,10 @@ clean_dotnet:\n \t-$(DELREC) ortools$Sdotnet$SCreateSigningKey$Sbin\n \t-$(DELREC) ortools$Sdotnet$SCreateSigningKey$Sobj\n \t-$(DEL) $(DOTNET_ORTOOLS_SNK_PATH)\n-\t-$(DEL) ortools$Sdotnet$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)*.csproj\n-\t-$(DELREC) ortools$Sdotnet$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)$Sbin\n-\t-$(DELREC) ortools$Sdotnet$S$(OR_TOOLS_NATIVE_ASSEMBLY_NAME)$Sobj\n+\t-$(DEL) ortools$Sdotnet$S$(OR_TOOLS_NATIVE_PROJECT_NAME)$S$(OR_TOOLS_NATIVE_PROJECT_NAME)*.csproj\n+\t-$(DELREC) ortools$Sdotnet$S$(OR_TOOLS_NATIVE_PROJECT_NAME)$Sbin\n+\t-$(DELREC) ortools$Sdotnet$S$(OR_TOOLS_NATIVE_PROJECT_NAME)$Sobj\n \t-$(DEL) ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)$S$(OR_TOOLS_ASSEMBLY_NAME)*.csproj\n-\t-$(DEL) ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)$Sruntime.json\n \t-$(DELREC) ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)$Sbin\n \t-$(DELREC) ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)$Sobj\n \t-$(DEL) ortools$Sdotnet$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)*.fsproj\n@@ -745,13 +755,13 @@ clean_dotnet:\n ######################\n .PHONY: nuget_archive # Build .Net \"Google.OrTools\" Nuget Package\n nuget_archive: dotnet | $(TEMP_DOTNET_DIR)\n-\t\"$(DOTNET_BIN)\" publish -c Release --no-dependencies --no-restore -f netstandard2.0 \\\n+\t\"$(DOTNET_BIN)\" publish $(DOTNET_BUILD_ARGS) --no-build --no-dependencies --no-restore -f netstandard2.0 \\\n  -o \"..$S..$S..$S$(TEMP_DOTNET_DIR)\" \\\n  ortools$Sdotnet$S$(OR_TOOLS_ASSEMBLY_NAME)$S$(OR_TOOLS_ASSEMBLY_NAME).csproj\n-\t\"$(DOTNET_BIN)\" publish -c Release --no-dependencies --no-restore -f netstandard2.0 \\\n+\t\"$(DOTNET_BIN)\" publish $(DOTNET_BUILD_ARGS) --no-build --no-dependencies --no-restore -f netstandard2.0 \\\n  -o \"..$S..$S..$S$(TEMP_DOTNET_DIR)\" \\\n  ortools$Sdotnet$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME)$S$(OR_TOOLS_FSHARP_ASSEMBLY_NAME).fsproj\n-\t\"$(DOTNET_BIN)\" pack -c Release \\\n+\t\"$(DOTNET_BIN)\" pack -c Release $(NUGET_PACK_ARGS) --no-build \\\n  -o \"..$S..$S..$S$(BIN_DIR)\" \\\n  ortools$Sdotnet\n \n@@ -775,6 +785,7 @@ detect_dotnet:\n \t@echo SWIG_INC = $(SWIG_INC)\n \t@echo SWIG_DOTNET_LIB_SUFFIX = $(SWIG_DOTNET_LIB_SUFFIX)\n \t@echo OR_TOOLS_NATIVE_ASSEMBLY_NAME = $(OR_TOOLS_NATIVE_ASSEMBLY_NAME)\n+\t@echo OR_TOOLS_NATIVE_PROJECT_NAME =$(OR_TOOLS_NATIVE_PROJECT_NAME)\n \t@echo DOTNET_ORTOOLS_NATIVE_NUPKG = $(DOTNET_ORTOOLS_NATIVE_NUPKG)\n \t@echo OR_TOOLS_ASSEMBLY_NAME = $(OR_TOOLS_ASSEMBLY_NAME)\n \t@echo DOTNET_ORTOOLS_NUPKG = $(DOTNET_ORTOOLS_NUPKG)\ndiff --git a/ortools/dotnet/Directory.Build.props b/ortools/dotnet/Directory.Build.props\nnew file mode 100644\nindex 00000000000..d5ed2e89a37\n--- /dev/null\n+++ b/ortools/dotnet/Directory.Build.props\n@@ -0,0 +1,32 @@\n+<?xml version=\"1.0\" encoding=\"utf-8\"?>\n+<Project>\n+  <!-- These settings are applied to all projects recursive from here (unless overridden).-->\n+  <PropertyGroup>\n+      <GenerateDocumentationFile>true</GenerateDocumentationFile>\n+\n+      <!-- Nuget Properties -->\n+      <MinClientVersion>4.1.0</MinClientVersion>\n+      <NeutralLanguage>en-US</NeutralLanguage>\n+      <Authors>Laurent Perron</Authors>\n+      <Company>Google LLC</Company>\n+      <Copyright>Copyright 2019 Google LLC</Copyright>\n+\n+       <!-- Pack Option -->\n+       <IncludeSymbols>true</IncludeSymbols>\n+       <PackageTags>native;math;LinearSolver;LinearProgramming;ConstraintSolver;ConstraintProgramming</PackageTags>\n+       <PackageIconUrl>https://developers.google.com/optimization/images/orLogo.png</PackageIconUrl>\n+       <PackageProjectUrl>https://developers.google.com/optimization</PackageProjectUrl>\n+       <PackageLicenseExpression>Apache-2.0</PackageLicenseExpression>\n+       <PackageRequireLicenseAcceptance>false</PackageRequireLicenseAcceptance>\n+       <PackageOutputPath>../../../packages</PackageOutputPath>\n+       <GeneratePackageOnBuild>false</GeneratePackageOnBuild>\n+       <RepositoryType>git</RepositoryType>\n+       <RepositoryUrl>https://github.com/google/or-tools</RepositoryUrl>\n+        <!--Disable CS1591 \"Missing XML comment for publicly visible type or member\" (Swig doesn't generate documentation)-->\n+        <NoWarn>1591</NoWarn>\n+  </PropertyGroup>\n+\n+  <PropertyGroup Label=\"BasePath\">\n+    <SolutionDir Condition=\"'$(SolutionDir)'==''\">$(MSBuildThisFileDirectory)</SolutionDir>\n+  </PropertyGroup>\n+</Project>\ndiff --git a/ortools/dotnet/Google.OrTools.FSharp/Google.OrTools.FSharp.fsproj.in b/ortools/dotnet/Google.OrTools.FSharp/Google.OrTools.FSharp.fsproj.in\nindex 24cdf6cc5f7..51da650fc13 100644\n--- a/ortools/dotnet/Google.OrTools.FSharp/Google.OrTools.FSharp.fsproj.in\n+++ b/ortools/dotnet/Google.OrTools.FSharp/Google.OrTools.FSharp.fsproj.in\n@@ -1,39 +1,28 @@\n-\ufeff<Project Sdk=\"Microsoft.NET.Sdk\">\n+<Project Sdk=\"Microsoft.NET.Sdk\">\n   <PropertyGroup>\n     <OutputType>Library</OutputType>\n-    <TargetFrameworks>netstandard2.0</TargetFrameworks>\n     <AssemblyName>Google.OrTools.FSharp</AssemblyName>\n     <Version>@PROJECT_VERSION@</Version>\n \n     <!-- Nuget Properties -->\n-    <MinClientVersion>4.1.0</MinClientVersion>\n     <Description>.NET F# wrapper for the Operations Research Tools project</Description>\n-    <NeutralLanguage>en-US</NeutralLanguage>\n-    <Authors>Laurent Perron</Authors>\n-    <Company>Google LLC</Company>\n-    <Copyright>Copyright 2018 Google LLC</Copyright>\n+\n     <!-- Pack Option -->\n     <Title>Google.OrTools.FSharp v@PROJECT_VERSION@</Title>\n     <PackageId>Google.OrTools.FSharp</PackageId>\n-    <PackageTags>native;math;LinearSolver;LinearProgramming;ConstraintSolver;ConstraintProgramming</PackageTags>\n-    <PackageIconUrl>https://developers.google.com/optimization/images/orLogo.png</PackageIconUrl>\n-    <PackageProjectUrl>https://developers.google.com/optimization</PackageProjectUrl>\n-    <PackageLicenseExpression>Apache-2.0</PackageLicenseExpression>\n-    <PackageRequireLicenseAcceptance>false</PackageRequireLicenseAcceptance>\n-    <PackageOutputPath>../../../packages</PackageOutputPath>\n-    <GeneratePackageOnBuild>false</GeneratePackageOnBuild>\n-    <RepositoryType>git</RepositoryType>\n-    <RepositoryUrl>https://github.com/google/or-tools</RepositoryUrl>\n \n+    <!-- Signing -->\n     <AssemblyKeyFileAttribute>../../../bin/or-tools.snk</AssemblyKeyFileAttribute>\n     <SignAssembly>true</SignAssembly>\n     <PublicSign Condition=\"'$(OS)' != 'Windows_NT'\">true</PublicSign>\n+  </PropertyGroup>\n \n-    <!-- Build Properties -->\n-    <IncludeBuildOutput>true</IncludeBuildOutput>\n-    <ProduceReferenceAssembly>false</ProduceReferenceAssembly>\n-    <UseSharedCompilation>false</UseSharedCompilation>\n-    <EnableDefaultItems>false</EnableDefaultItems>\n+  <!-- On windows we can build cross-platform netstandard and windows-only netframework.-->\n+  <PropertyGroup Condition=\" '$(OS)' != 'Windows_NT' And '$(OS)' != 'Windows' \">\n+    <TargetFramework>netstandard2.0</TargetFramework>\n+  </PropertyGroup>\n+  <PropertyGroup Condition=\" '$(OS)' == 'Windows_NT' Or '$(OS)' == 'Windows' \">\n+    <TargetFrameworks>netstandard2.0;net452</TargetFrameworks>\n   </PropertyGroup>\n \n   <PropertyGroup Condition=\" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' \">\ndiff --git a/ortools/dotnet/Google.OrTools.runtime.linux-x64/Google.OrTools.runtime.linux-x64.csproj.in b/ortools/dotnet/Google.OrTools.runtime.linux-x64/Google.OrTools.runtime.linux-x64.csproj.in\nindex 86c57bac08c..6538c0a7b10 100644\n--- a/ortools/dotnet/Google.OrTools.runtime.linux-x64/Google.OrTools.runtime.linux-x64.csproj.in\n+++ b/ortools/dotnet/Google.OrTools.runtime.linux-x64/Google.OrTools.runtime.linux-x64.csproj.in\n@@ -3,94 +3,34 @@\n     <OutputType>Library</OutputType>\n     <TargetFramework>netstandard2.0</TargetFramework>\n     <RuntimeIdentifier>linux-x64</RuntimeIdentifier>\n-    <AssemblyName>Google.OrTools</AssemblyName>\n+    <AssemblyName>google-ortools-native</AssemblyName>\n     <Version>@PROJECT_VERSION@</Version>\n \n     <!-- Nuget Properties -->\n-    <MinClientVersion>4.1.0</MinClientVersion>\n     <Description>.NET native wrapper for the Operations Research Tools project</Description>\n-    <NeutralLanguage>en-US</NeutralLanguage>\n-    <Authors>Laurent Perron</Authors>\n-    <Company>Google LLC</Company>\n-    <Copyright>Copyright 2018 Google LLC</Copyright>\n+    <IncludeBuildOutput>false</IncludeBuildOutput>\n+\n     <!-- Pack Option -->\n     <Title>Google.OrTools linux-x64 v@PROJECT_VERSION@</Title>\n     <PackageId>Google.OrTools.runtime.linux-x64</PackageId>\n-    <PackageTags>native;math;LinearSolver;LinearProgramming;ConstraintSolver;ConstraintProgramming</PackageTags>\n-    <PackageIconUrl>https://developers.google.com/optimization/images/orLogo.png</PackageIconUrl>\n-    <PackageProjectUrl>https://developers.google.com/optimization</PackageProjectUrl>\n-    <PackageLicenseExpression>Apache-2.0</PackageLicenseExpression>\n-    <PackageRequireLicenseAcceptance>false</PackageRequireLicenseAcceptance>\n-    <PackageOutputPath>../../../packages</PackageOutputPath>\n-    <GeneratePackageOnBuild>false</GeneratePackageOnBuild>\n-    <RepositoryType>git</RepositoryType>\n-    <RepositoryUrl>https://github.com/google/or-tools</RepositoryUrl>\n \n+    <!-- Signing -->\n     <AssemblyOriginatorKeyFile>../../../bin/or-tools.snk</AssemblyOriginatorKeyFile>\n     <SignAssembly>true</SignAssembly>\n     <PublicSign Condition=\"'$(OS)' != 'Windows_NT'\">true</PublicSign>\n-\n-    <!-- Build Properties -->\n-    <ProduceReferenceAssembly>true</ProduceReferenceAssembly>\n-    <UseSharedCompilation>false</UseSharedCompilation>\n-    <EnableDefaultItems>false</EnableDefaultItems>\n-    <BuildOutputTargetFolder>runtimes/$(RuntimeIdentifier)/lib</BuildOutputTargetFolder>\n   </PropertyGroup>\n \n   <ItemGroup>\n-    <Compile Include=\"../../gen/ortools/algorithms/*.cs\">\n-      <Link>algorithms/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/graph/*.cs\">\n-      <Link>graph/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../graph/csharp/*.cs\">\n-      <Link>graph/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/linear_solver/*.cs\">\n-      <Link>linear_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../linear_solver/csharp/*.cs\">\n-      <Link>linear_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/constraint_solver/*.cs\">\n-      <Link>constraint_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../constraint_solver/csharp/*.cs\">\n-      <Link>constraint_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/sat/*.cs\">\n-      <Link>sat/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../sat/csharp/*.cs\">\n-      <Link>sat/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/util/*.cs\">\n-      <Link>util/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../util/csharp/*.cs\">\n-      <Link>util/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n     <!-- Native library must be in native directory... -->\n     <Content Include=\"../../../dependencies/install/lib*/*.so*\">\n       <PackagePath>runtimes/linux-x64/native/%(Filename)%(Extension)</PackagePath>\n       <Pack>true</Pack>\n       <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n     </Content>\n-    <Content Include=\"../../../lib/Google.OrTools.runtime.linux-x64.so; ../../../lib/libortools.so\">\n+    <Content Include=\"../../../lib/$(AssemblyName).so; ../../../lib/libortools.so\">\n       <PackagePath>runtimes/linux-x64/native/%(Filename)%(Extension)</PackagePath>\n       <Pack>true</Pack>\n       <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n     </Content>\n   </ItemGroup>\n-\n-  <ItemGroup>\n-    <PackageReference Include=\"Google.Protobuf\" Version=\"3.9.0\" />\n-  </ItemGroup>\n </Project>\ndiff --git a/ortools/dotnet/Google.OrTools.runtime.osx-x64/Google.OrTools.runtime.osx-x64.csproj.in b/ortools/dotnet/Google.OrTools.runtime.osx-x64/Google.OrTools.runtime.osx-x64.csproj.in\nindex 04857f25745..f3ee00d1620 100644\n--- a/ortools/dotnet/Google.OrTools.runtime.osx-x64/Google.OrTools.runtime.osx-x64.csproj.in\n+++ b/ortools/dotnet/Google.OrTools.runtime.osx-x64/Google.OrTools.runtime.osx-x64.csproj.in\n@@ -3,94 +3,34 @@\n     <OutputType>Library</OutputType>\n     <TargetFramework>netstandard2.0</TargetFramework>\n     <RuntimeIdentifier>osx-x64</RuntimeIdentifier>\n-    <AssemblyName>Google.OrTools</AssemblyName>\n+    <AssemblyName>google-ortools-native</AssemblyName>\n     <Version>@PROJECT_VERSION@</Version>\n \n     <!-- Nuget Properties -->\n-    <MinClientVersion>4.1.0</MinClientVersion>\n     <Description>.NET native wrapper for the Operations Research Tools project</Description>\n-    <NeutralLanguage>en-US</NeutralLanguage>\n-    <Authors>Laurent Perron</Authors>\n-    <Company>Google LLC</Company>\n-    <Copyright>Copyright 2018 Google LLC</Copyright>\n+    <IncludeBuildOutput>false</IncludeBuildOutput>\n+\n     <!-- Pack Option -->\n     <Title>Google.OrTools osx-x64 v@PROJECT_VERSION@</Title>\n     <PackageId>Google.OrTools.runtime.osx-x64</PackageId>\n-    <PackageTags>native;math;LinearSolver;LinearProgramming;ConstraintSolver;ConstraintProgramming</PackageTags>\n-    <PackageIconUrl>https://developers.google.com/optimization/images/orLogo.png</PackageIconUrl>\n-    <PackageProjectUrl>https://developers.google.com/optimization</PackageProjectUrl>\n-    <PackageLicenseExpression>Apache-2.0</PackageLicenseExpression>\n-    <PackageRequireLicenseAcceptance>false</PackageRequireLicenseAcceptance>\n-    <PackageOutputPath>../../../packages</PackageOutputPath>\n-    <GeneratePackageOnBuild>false</GeneratePackageOnBuild>\n-    <RepositoryType>git</RepositoryType>\n-    <RepositoryUrl>https://github.com/google/or-tools</RepositoryUrl>\n \n+    <!-- Signing -->\n     <AssemblyOriginatorKeyFile>../../../bin/or-tools.snk</AssemblyOriginatorKeyFile>\n     <SignAssembly>true</SignAssembly>\n     <PublicSign Condition=\"'$(OS)' != 'Windows_NT'\">true</PublicSign>\n-\n-    <!-- Build Properties -->\n-    <ProduceReferenceAssembly>true</ProduceReferenceAssembly>\n-    <UseSharedCompilation>false</UseSharedCompilation>\n-    <EnableDefaultItems>false</EnableDefaultItems>\n-    <BuildOutputTargetFolder>runtimes/$(RuntimeIdentifier)/lib</BuildOutputTargetFolder>\n   </PropertyGroup>\n \n   <ItemGroup>\n-    <Compile Include=\"../../gen/ortools/algorithms/*.cs\">\n-      <Link>algorithms/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/graph/*.cs\">\n-      <Link>graph/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../graph/csharp/*.cs\">\n-      <Link>graph/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/linear_solver/*.cs\">\n-      <Link>linear_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../linear_solver/csharp/*.cs\">\n-      <Link>linear_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/constraint_solver/*.cs\">\n-      <Link>constraint_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../constraint_solver/csharp/*.cs\">\n-      <Link>constraint_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/sat/*.cs\">\n-      <Link>sat/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../sat/csharp/*.cs\">\n-      <Link>sat/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/util/*.cs\">\n-      <Link>util/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../util/csharp/*.cs\">\n-      <Link>util/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n     <!-- Native library must be in native directory... -->\n     <Content Include=\"../../../dependencies/install/lib/*.dylib*\">\n       <PackagePath>runtimes/osx-x64/native/%(Filename)%(Extension)</PackagePath>\n       <Pack>true</Pack>\n       <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n     </Content>\n-    <Content Include=\"../../../lib/Google.OrTools.runtime.osx-x64.dylib; ../../../lib/libortools.dylib\">\n+    <Content Include=\"../../../lib/$(AssemblyName).dylib; ../../../lib/libortools.dylib\">\n       <PackagePath>runtimes/osx-x64/native/%(Filename)%(Extension)</PackagePath>\n       <Pack>true</Pack>\n       <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n     </Content>\n   </ItemGroup>\n-\n-  <ItemGroup>\n-    <PackageReference Include=\"Google.Protobuf\" Version=\"3.9.0\" />\n-  </ItemGroup>\n </Project>\ndiff --git a/ortools/dotnet/Google.OrTools.runtime.win-x64/Google.OrTools.runtime.win-x64.csproj.in b/ortools/dotnet/Google.OrTools.runtime.win-x64/Google.OrTools.runtime.win-x64.csproj.in\nindex 4b688bb3dc6..c07e818a902 100644\n--- a/ortools/dotnet/Google.OrTools.runtime.win-x64/Google.OrTools.runtime.win-x64.csproj.in\n+++ b/ortools/dotnet/Google.OrTools.runtime.win-x64/Google.OrTools.runtime.win-x64.csproj.in\n@@ -1,92 +1,51 @@\n <Project Sdk=\"Microsoft.NET.Sdk\">\n   <PropertyGroup>\n     <OutputType>Library</OutputType>\n-    <TargetFramework>netstandard2.0</TargetFramework>\n     <RuntimeIdentifier>win-x64</RuntimeIdentifier>\n-    <AssemblyName>Google.OrTools</AssemblyName>\n+    <AssemblyName>google-ortools-native</AssemblyName>\n     <Version>@PROJECT_VERSION@</Version>\n \n     <!-- Nuget Properties -->\n-    <MinClientVersion>4.1.0</MinClientVersion>\n     <Description>.NET native wrapper for the Operations Research Tools project</Description>\n-    <NeutralLanguage>en-US</NeutralLanguage>\n-    <Authors>Laurent Perron</Authors>\n-    <Company>Google LLC</Company>\n-    <Copyright>Copyright 2018 Google LLC</Copyright>\n+    <IncludeBuildOutput>false</IncludeBuildOutput>\n+\n     <!-- Pack Option -->\n     <Title>Google.OrTools win-x64 v@PROJECT_VERSION@</Title>\n     <PackageId>Google.OrTools.runtime.win-x64</PackageId>\n-    <PackageTags>native;math;LinearSolver;LinearProgramming;ConstraintSolver;ConstraintProgramming</PackageTags>\n-    <PackageIconUrl>https://developers.google.com/optimization/images/orLogo.png</PackageIconUrl>\n-    <PackageProjectUrl>https://developers.google.com/optimization</PackageProjectUrl>\n-    <PackageLicenseExpression>Apache-2.0</PackageLicenseExpression>\n-    <PackageRequireLicenseAcceptance>false</PackageRequireLicenseAcceptance>\n-    <PackageOutputPath>../../../packages</PackageOutputPath>\n-    <GeneratePackageOnBuild>false</GeneratePackageOnBuild>\n-    <RepositoryType>git</RepositoryType>\n-    <RepositoryUrl>https://github.com/google/or-tools</RepositoryUrl>\n \n+    <!-- Signing -->\n     <AssemblyOriginatorKeyFile>../../../bin/or-tools.snk</AssemblyOriginatorKeyFile>\n     <SignAssembly>true</SignAssembly>\n     <PublicSign Condition=\"'$(OS)' != 'Windows_NT'\">true</PublicSign>\n+  </PropertyGroup>\n \n-    <!-- Build Properties -->\n-    <ProduceReferenceAssembly>true</ProduceReferenceAssembly>\n-    <UseSharedCompilation>false</UseSharedCompilation>\n-    <EnableDefaultItems>false</EnableDefaultItems>\n-    <BuildOutputTargetFolder>runtimes/$(RuntimeIdentifier)/lib</BuildOutputTargetFolder>\n+  <!-- On windows we can build cross-platform netstandard and windows-only netframework.-->\n+  <PropertyGroup Condition=\" '$(OS)' != 'Windows_NT' And '$(OS)' != 'Windows' \">\n+    <TargetFramework>netstandard2.0</TargetFramework>\n+  </PropertyGroup>\n+  <PropertyGroup Condition=\" '$(OS)' == 'Windows_NT' Or '$(OS)' == 'Windows' \">\n+    <TargetFrameworks>netstandard2.0;net452</TargetFrameworks>\n   </PropertyGroup>\n \n   <ItemGroup>\n-    <Compile Include=\"../../gen/ortools/algorithms/*.cs\">\n-      <Link>algorithms/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/graph/*.cs\">\n-      <Link>graph/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../graph/csharp/*.cs\">\n-      <Link>graph/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/linear_solver/*.cs\">\n-      <Link>linear_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../linear_solver/csharp/*.cs\">\n-      <Link>linear_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/constraint_solver/*.cs\">\n-      <Link>constraint_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../constraint_solver/csharp/*.cs\">\n-      <Link>constraint_solver/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/sat/*.cs\">\n-      <Link>sat/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../sat/csharp/*.cs\">\n-      <Link>sat/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n-    <Compile Include=\"../../gen/ortools/util/*.cs\">\n-      <Link>util/%(Filename)%(Extension)</Link>\n-    </Compile>\n-    <Compile Include=\"../../util/csharp/*.cs\">\n-      <Link>util/%(Filename)%(Extension)</Link>\n-    </Compile>\n-\n     <!-- Native library must be in native directory... -->\n     <!-- On windows libortools is built as static -->\n-    <Content Include=\"../../../lib/Google.OrTools.runtime.win-x64.dll\">\n+    <Content Include=\"../../../lib/$(AssemblyName).dll\">\n       <PackagePath>runtimes/win-x64/native/%(Filename)%(Extension)</PackagePath>\n       <Pack>true</Pack>\n       <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n     </Content>\n-  </ItemGroup>\n \n-  <ItemGroup>\n-    <PackageReference Include=\"Google.Protobuf\" Version=\"3.9.0\" />\n+    <!-- For netframework we need to copy the native binary manually during build on Nuget consumer side. That's why we need a separate target file doing this for us. -->\n+    <Content Include=\"$(MSBuildThisFileDirectory)\\Google.OrTools.runtime.win-x64.targets\">\n+      <PackagePath>build/net45/%(Filename)%(Extension)</PackagePath>\n+      <Pack>true</Pack>\n+      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n+    </Content>\n+    <Content Include=\"$(MSBuildThisFileDirectory)\\Google.OrTools.runtime.win-x64.targets\">\n+       <PackagePath>build/netstandard2.0/%(Filename)%(Extension)</PackagePath>\n+       <Pack>true</Pack>\n+       <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n+    </Content>\n   </ItemGroup>\n </Project>\ndiff --git a/ortools/dotnet/Google.OrTools.runtime.win-x64/Google.OrTools.runtime.win-x64.targets b/ortools/dotnet/Google.OrTools.runtime.win-x64/Google.OrTools.runtime.win-x64.targets\nnew file mode 100644\nindex 00000000000..be0ca568b0a\n--- /dev/null\n+++ b/ortools/dotnet/Google.OrTools.runtime.win-x64/Google.OrTools.runtime.win-x64.targets\n@@ -0,0 +1,17 @@\n+<?xml version=\"1.0\" encoding=\"utf-8\"?>\n+<Project ToolsVersion=\"4.0\" xmlns=\"http://schemas.microsoft.com/developer/msbuild/2003\">\n+\n+    <!-- Warn consumer if Platform != x64\n+   <Target Name=\"PlatformCheck\" BeforeTargets=\"ResolveAssemblyReferences\" Condition=\"'$(Platform)' != 'x64'\">\n+      <Error Text=\"You are using $(Platform). $(MSBuildThisFileName) contains unmanaged resoures for 64 bit platform only. Ensure that you set your application/test project platform to x64 (via solution configuration manager).\" />\n+   </Target>\n+-->\n+  <ItemGroup>\n+    <!-- A native dll must be copied manually to output directory. -->\n+    <NativeBinaries Include=\"$(MSBuildThisFileDirectory)..\\..\\runtimes\\**\\native\\**\\*.*\"/>\n+    <None Include=\"@(NativeBinaries)\">\n+      <Link>%(Filename)%(Extension)</Link>\n+      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n+    </None>\n+  </ItemGroup>\n+</Project>\ndiff --git a/ortools/dotnet/Google.OrTools/Google.OrTools.csproj.in b/ortools/dotnet/Google.OrTools/Google.OrTools.csproj.in\nindex b5438b8cfe9..d92a1392c44 100644\n--- a/ortools/dotnet/Google.OrTools/Google.OrTools.csproj.in\n+++ b/ortools/dotnet/Google.OrTools/Google.OrTools.csproj.in\n@@ -1,234 +1,105 @@\n <Project Sdk=\"Microsoft.NET.Sdk\">\n   <PropertyGroup>\n     <OutputType>Library</OutputType>\n-    <TargetFramework>netstandard2.0</TargetFramework>\n     <RuntimeIdentifiers>win-x64;osx-x64;linux-x64</RuntimeIdentifiers>\n     <AssemblyName>Google.OrTools</AssemblyName>\n     <Version>@PROJECT_VERSION@</Version>\n \n     <!-- Nuget Properties -->\n-    <MinClientVersion>4.1.0</MinClientVersion>\n     <Description>.NET wrapper for the Operations Research Tools project</Description>\n-    <NeutralLanguage>en-US</NeutralLanguage>\n-    <Authors>Laurent Perron</Authors>\n-    <Company>Google LLC</Company>\n-    <Copyright>Copyright 2018 Google LLC</Copyright>\n+\n     <!-- Pack Option -->\n     <Title>Google.OrTools v@PROJECT_VERSION@</Title>\n     <PackageId>Google.OrTools</PackageId>\n-    <PackageTags>native;math;LinearSolver;LinearProgramming;ConstraintSolver;ConstraintProgramming</PackageTags>\n-    <PackageIconUrl>https://developers.google.com/optimization/images/orLogo.png</PackageIconUrl>\n-    <PackageProjectUrl>https://developers.google.com/optimization</PackageProjectUrl>\n-    <PackageLicenseExpression>Apache-2.0</PackageLicenseExpression>\n-    <PackageRequireLicenseAcceptance>false</PackageRequireLicenseAcceptance>\n-    <PackageOutputPath>../../../packages</PackageOutputPath>\n-    <GeneratePackageOnBuild>false</GeneratePackageOnBuild>\n-    <RepositoryType>git</RepositoryType>\n-    <RepositoryUrl>https://github.com/google/or-tools</RepositoryUrl>\n-    <DevelopmentDependency>false</DevelopmentDependency>\n \n+    <!-- Signing -->\n     <AssemblyOriginatorKeyFile>../../../bin/or-tools.snk</AssemblyOriginatorKeyFile>\n     <SignAssembly>true</SignAssembly>\n     <PublicSign Condition=\"'$(OS)' != 'Windows_NT'\">true</PublicSign>\n-\n-    <!-- Build Properties -->\n-    <!-- we want to create a Meta-Project only referencing runtime Project(s) -->\n-    <IncludeBuildOutput>false</IncludeBuildOutput>\n-    <ProduceReferenceAssembly>false</ProduceReferenceAssembly>\n-    <UseSharedCompilation>false</UseSharedCompilation>\n-    <EnableDefaultItems>false</EnableDefaultItems>\n   </PropertyGroup>\n \n-  <!-- Check at least one reference assembly has been generated -->\n-  <Target Name=\"ValidateRuntimeRef\" BeforeTargets=\"Compile\">\n-    <ItemGroup>\n-      <RefLinux Include=\"../Google.OrTools.runtime.linux-x64/bin/$(Configuration)/$(TargetFramework)/linux-x64/ref/*.dll\" />\n-      <RefCentosLinux Include=\"../Google.OrTools.runtime.linux-x64/bin/LINUX/$(Configuration)/$(TargetFramework)/linux-x64/ref/*.dll\" />\n-      <RefOsx Include=\"../Google.OrTools.runtime.osx-x64/bin/$(Configuration)/$(TargetFramework)/osx-x64/ref/*.dll\" />\n-      <RefWin Include=\"../Google.OrTools.runtime.win-x64/bin/x64/$(Configuration)/$(TargetFramework)/win-x64/ref/*.dll\" />\n-    </ItemGroup>\n-    <Message\n-      Importance=\"high\"\n-      Text=\"RefAssembly from Google.OrTools.runtime.linux-x64: found\"\n-      Condition=\"Exists('@(RefLinux)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"RefAssembly from Google.OrTools.runtime.linux-x64: not found\"\n-      Condition=\"!Exists('@(RefLinux)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"RefAssembly from Google.OrTools.runtime.linux-x64 (CentOs): found\"\n-      Condition=\"Exists('@(RefCentosLinux)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"RefAssembly from Google.OrTools.runtime.linux-x64 (CentOs): not found\"\n-      Condition=\"!Exists('@(RefCentosLinux)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"RefAssembly from Google.OrTools.runtime.osx-x64: found\"\n-      Condition=\"Exists('@(RefOsx)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"RefAssembly from Google.OrTools.runtime.osx-x64: not found\"\n-      Condition=\"!Exists('@(RefOsx)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"RefAssembly from Google.OrTools.runtime.win-x64: found\"\n-      Condition=\"Exists('@(RefWin)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"RefAssembly from Google.OrTools.runtime.win-x64: not found\"\n-      Condition=\"!Exists('@(RefWin)')\" />\n-    <Error\n-      Text=\"You must locally 'dotnet build' at least one Google.OrTools.runtime.{rid} Project.\"\n-      Condition=\"!Exists('@(RefLinux)') AND !Exists('@(RefOsx)') AND !Exists('@(RefWin)') AND !Exists('@(RefCentosLinux)')\" />\n-  </Target>\n+  <!-- On windows we can build cross-platform netstandard and windows-only netframework.-->\n+  <PropertyGroup Condition=\" '$(OS)' != 'Windows_NT' And '$(OS)' != 'Windows' \">\n+    <TargetFramework>netstandard2.0</TargetFramework>\n+  </PropertyGroup>\n+  <PropertyGroup Condition=\" '$(OS)' == 'Windows_NT' Or '$(OS)' == 'Windows' \">\n+    <TargetFrameworks>netstandard2.0;net452</TargetFrameworks>\n+  </PropertyGroup>\n \n-  <!-- Need to copy one of the reference assembly generated -->\n   <ItemGroup>\n-    <RefLinux Include=\"../Google.OrTools.runtime.linux-x64/bin/$(Configuration)/$(TargetFramework)/linux-x64/ref/*.dll\" />\n-    <RefCentosLinux Include=\"../Google.OrTools.runtime.linux-x64/bin/LINUX/$(Configuration)/$(TargetFramework)/linux-x64/ref/*.dll\" />\n-    <RefOsx Include=\"../Google.OrTools.runtime.osx-x64/bin/$(Configuration)/$(TargetFramework)/osx-x64/ref/*.dll\" />\n-    <RefWin Include=\"../Google.OrTools.runtime.win-x64/bin/x64/$(Configuration)/$(TargetFramework)/win-x64/ref/*.dll\" />\n-    <Content\n-      Include=\"@(RefLinux)\"\n-      Condition=\"Exists('@(RefLinux)')\">\n-      <PackagePath>ref/$(TargetFramework)/%(Filename)%(Extension)</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content\n-      Include=\"@(RefCentosLinux)\"\n-      Condition=\"Exists('@(RefCentosLinux)')\">\n-      <PackagePath>ref/$(TargetFramework)/%(Filename)%(Extension)</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content\n-      Include=\"@(RefOsx)\"\n-      Condition=\"Exists('@(RefOsx)')\">\n-      <PackagePath>ref/$(TargetFramework)/%(Filename)%(Extension)</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content\n-      Include=\"@(RefWin)\"\n-      Condition=\"Exists('@(RefWin)')\">\n-      <PackagePath>ref/$(TargetFramework)/%(Filename)%(Extension)</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n+    <Compile Include=\"../../gen/ortools/algorithms/*.cs\">\n+      <Link>algorithms/%(Filename)%(Extension)</Link>\n+    </Compile>\n+\n+    <Compile Include=\"../../gen/ortools/graph/*.cs\">\n+      <Link>graph/%(Filename)%(Extension)</Link>\n+    </Compile>\n+    <Compile Include=\"../../graph/csharp/*.cs\">\n+      <Link>graph/%(Filename)%(Extension)</Link>\n+    </Compile>\n+\n+    <Compile Include=\"../../gen/ortools/linear_solver/*.cs\">\n+      <Link>linear_solver/%(Filename)%(Extension)</Link>\n+    </Compile>\n+    <Compile Include=\"../../linear_solver/csharp/*.cs\">\n+      <Link>linear_solver/%(Filename)%(Extension)</Link>\n+    </Compile>\n+\n+    <Compile Include=\"../../gen/ortools/constraint_solver/*.cs\">\n+      <Link>constraint_solver/%(Filename)%(Extension)</Link>\n+    </Compile>\n+    <Compile Include=\"../../constraint_solver/csharp/*.cs\">\n+      <Link>constraint_solver/%(Filename)%(Extension)</Link>\n+    </Compile>\n+\n+    <Compile Include=\"../../gen/ortools/sat/*.cs\">\n+      <Link>sat/%(Filename)%(Extension)</Link>\n+    </Compile>\n+    <Compile Include=\"../../sat/csharp/*.cs\">\n+      <Link>sat/%(Filename)%(Extension)</Link>\n+    </Compile>\n+\n+    <Compile Include=\"../../gen/ortools/util/*.cs\">\n+      <Link>util/%(Filename)%(Extension)</Link>\n+    </Compile>\n+    <Compile Include=\"../../util/csharp/*.cs\">\n+      <Link>util/%(Filename)%(Extension)</Link>\n+    </Compile>\n   </ItemGroup>\n \n-  <!-- Check at least one runtime package has been generated -->\n+  <!-- Validate at least one runtime package has been generated -->\n   <Target Name=\"ValidateRuntimePack\" BeforeTargets=\"GenerateNuspec\">\n     <ItemGroup>\n-      <RuntimeLinux Include=\"../../../packages/Google.OrTools.runtime.linux-x64.*.nupkg\" />\n-      <RuntimeOsx Include=\"../../../packages/Google.OrTools.runtime.osx-x64.*.nupkg\" />\n-      <RuntimeWin Include=\"../../../packages/Google.OrTools.runtime.win-x64.*.nupkg\" />\n+      <RuntimeLinux Include=\"../../../packages/Google.OrTools.runtime.linux-x64.*.nupkg\"/>\n+      <RuntimeOsx Include=\"../../../packages/Google.OrTools.runtime.osx-x64.*.nupkg\"/>\n+      <RuntimeWin Include=\"../../../packages/Google.OrTools.runtime.win-x64.*.nupkg\"/>\n     </ItemGroup>\n-    <Message\n-      Importance=\"high\"\n-      Text=\"Package Google.OrTools.runtime.linux-x64: found\"\n-      Condition=\"Exists('@(RuntimeLinux)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"Package Google.OrTools.runtime.linux-x64: not found\"\n-      Condition=\"!Exists('@(RuntimeLinux)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"Package Google.OrTools.runtime.osx-x64: found\"\n-      Condition=\"Exists('@(RuntimeOsx)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"Package Google.OrTools.runtime.osx-x64: not found\"\n-      Condition=\"!Exists('@(RuntimeOsx)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"Package Google.OrTools.runtime.win-x64: found\"\n-      Condition=\"Exists('@(RuntimeWin)')\" />\n-    <Message\n-      Importance=\"high\"\n-      Text=\"Package Google.OrTools.runtime.win-x64: not found\"\n-      Condition=\"!Exists('@(RuntimeWin)')\" />\n-    <Error\n-      Text=\"You must locally 'dotnet pack' at least one Google.OrTools.runtime.{rid} Project.\"\n-      Condition=\"!Exists('@(RuntimeLinux)') AND !Exists('@(RuntimeOsx)') AND !Exists('@(RuntimeWin)')\" />\n+    <Message Importance=\"high\" Text=\"Package Google.OrTools.runtime.linux-x64: found\" Condition=\"Exists('@(RuntimeLinux)')\"/>\n+    <Message Importance=\"high\" Text=\"-------  $(OS)  \"/>\n+    <Message Importance=\"high\" Text=\"Package Google.OrTools.runtime.linux-x64: not found\" Condition=\"!Exists('@(RuntimeLinux)')\"/>\n+    <Message Importance=\"high\" Text=\"Package Google.OrTools.runtime.osx-x64: found\" Condition=\"Exists('@(RuntimeOsx)')\"/>\n+    <Message Importance=\"high\" Text=\"Package Google.OrTools.runtime.osx-x64: not found\" Condition=\"!Exists('@(RuntimeOsx)')\"/>\n+    <Message Importance=\"high\" Text=\"Package Google.OrTools.runtime.win-x64: found\" Condition=\"Exists('@(RuntimeWin)')\"/>\n+    <Message Importance=\"high\" Text=\"Package Google.OrTools.runtime.win-x64: not found\" Condition=\"!Exists('@(RuntimeWin)')\"/>\n+    <Error Text=\"You must locally 'dotnet pack' at least one Google.OrTools.runtime.{rid} Project.\" Condition=\"!Exists('@(RuntimeLinux)') AND !Exists('@(RuntimeOsx)') AND !Exists('@(RuntimeWin)')\"/>\n   </Target>\n \n-  <!-- Copy all .proto file(s) -->\n+\n   <ItemGroup>\n-    <Content Include=\"../../algorithms/*.proto\">\n-      <PackagePath>content/algorithms</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content Include=\"../../graph/*.proto\">\n-      <PackagePath>content/graph</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content Include=\"../../linear_solver/*.proto\">\n-      <PackagePath>content/linear_solver</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content Include=\"../../bop/*.proto\">\n-      <PackagePath>content/bop</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content Include=\"../../glop/*.proto\">\n-      <PackagePath>content/glop</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content Include=\"../../constraint_solver/*.proto\">\n-      <PackagePath>content/constraint_solver</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content Include=\"../../sat/*.proto\">\n-      <PackagePath>content/sat</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content Include=\"../../util/*.proto\">\n-      <PackagePath>content/util</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n-    <Content Include=\"../../data/*.proto\">\n-      <PackagePath>content/data</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n+    <PackageReference Include=\"Google.Protobuf\" Version=\"3.9.0\"/>\n   </ItemGroup>\n \n-  <!-- Need to add some dependencies so Meta-Project will pull runtime Project(s) -->\n+  <!-- Need to add required runtime dependencies so Meta-Project will pull runtime Nuget(s) -->\n   <PropertyGroup>\n     <RestoreSources>../../../packages;$(RestoreSources);https://api.nuget.org/v3/index.json</RestoreSources>\n   </PropertyGroup>\n   <ItemGroup Condition=\"Exists('../../../packages/Google.OrTools.runtime.linux-x64.@PROJECT_VERSION@.nupkg')\">\n-    <PackageReference Include=\"Google.OrTools.runtime.linux-x64\" Version=\"@PROJECT_VERSION@\" />\n+    <PackageReference Include=\"Google.OrTools.runtime.linux-x64\" Version=\"@PROJECT_VERSION@\"/>\n   </ItemGroup>\n   <ItemGroup Condition=\"Exists('../../../packages/Google.OrTools.runtime.osx-x64.@PROJECT_VERSION@.nupkg')\">\n-    <PackageReference Include=\"Google.OrTools.runtime.osx-x64\" Version=\"@PROJECT_VERSION@\" />\n+    <PackageReference Include=\"Google.OrTools.runtime.osx-x64\" Version=\"@PROJECT_VERSION@\"/>\n   </ItemGroup>\n   <ItemGroup Condition=\"Exists('../../../packages/Google.OrTools.runtime.win-x64.@PROJECT_VERSION@.nupkg')\">\n-    <PackageReference Include=\"Google.OrTools.runtime.win-x64\" Version=\"@PROJECT_VERSION@\" />\n-  </ItemGroup>\n-\n-  <ItemGroup>\n-    <RuntimeLinux Include=\"../../../packages/Google.OrTools.runtime.linux-x64.*.nupkg\" />\n-    <RuntimeOsx Include=\"../../../packages/Google.OrTools.runtime.osx-x64.*.nupkg\" />\n-    <RuntimeWin Include=\"../../../packages/Google.OrTools.runtime.win-x64.*.nupkg\" />\n-    <Content\n-      Include=\"runtime.json\"\n-      Condition=\"Exists('@(RuntimeLinux)') AND Exists('@(RuntimeOsx)') AND Exists('@(RuntimeWin)')\">\n-      <PackagePath>runtime.json</PackagePath>\n-      <Pack>true</Pack>\n-      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n-    </Content>\n+    <PackageReference Include=\"Google.OrTools.runtime.win-x64\" Version=\"@PROJECT_VERSION@\"/>\n   </ItemGroup>\n </Project>\ndiff --git a/ortools/dotnet/Google.OrTools/runtime.json.in b/ortools/dotnet/Google.OrTools/runtime.json.in\ndeleted file mode 100644\nindex 266d7e65476..00000000000\n--- a/ortools/dotnet/Google.OrTools/runtime.json.in\n+++ /dev/null\n@@ -1,19 +0,0 @@\n-{\r\n-  \"runtimes\": {\r\n-    \"linux-x64\": {\r\n-      \"Google.OrTools\": {\r\n-        \"Google.OrTools.runtime.linux-x64\": \"@PROJECT_VERSION@\"\r\n-      }\r\n-    },\r\n-    \"osx-x64\": {\r\n-      \"Google.OrTools\": {\r\n-        \"Google.OrTools.runtime.osx-x64\": \"@PROJECT_VERSION@\"\r\n-      }\r\n-    },\r\n-    \"win-x64\": {\r\n-      \"Google.OrTools\": {\r\n-        \"Google.OrTools.runtime.win-x64\": \"@PROJECT_VERSION@\"\r\n-      }\r\n-    }\r\n-  }\r\n-}\r\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Build Errors on Windows**: The `make.exe` commands fail due to incorrect syntax and missing files. Address these issues to ensure compatibility on Windows.\n\n2. **NuGet Package Structure**: Consider creating a single NuGet package containing cross-platform binaries along with platform-dependent binaries, separating the build and packaging processes.\n\n3. **.NET Target Framework**: Change target frameworks for NuGet packages from `netstandard2.0` and `netframework4.5.2` to `netstandard1.1` and `netframework45`. This broadens accessibility.\n\n4. **Suppressed Warnings**: Silence CS1591 warnings due to missing XML comments for public members to reduce Travis CI build errors.\n\n5. **Testing on CentOS**: Test the workaround for inconsistent naming on CentOS and confirm whether assemblies are being created in the right directory."
      }
    ],
    "codediff_length": 51395
  },
  {
    "index": 120,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 7b3e78df0cb..37a511ae806 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -4,57 +4,79 @@ PROJECT(ortools LANGUAGES CXX)\n SET(CMAKE_CXX_STANDARD 11)\n \n INCLUDE(FindPkgConfig)\n+INCLUDE(ExternalProject)\n+\n+SET(CMAKE_INSTALL_LIBDIR lib)\n+SET(CMAKE_INSTALL_BINDIR bin)\n+SET(CMAKE_INSTALL_INCLUDEDIR include)\n \n IF(UNIX)\n     IF(NOT APPLE)\n         INCLUDE(GNUInstallDirs)\n     ENDIF()\n ENDIF()\n-SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fwrapv -DNDEBUG\")\n \n-IF(BUILD_PYTHON)\n-    SET(BUILD_CXX ON)\n-    FIND_PACKAGE(PythonInterp)\n-    FIND_PACKAGE(PythonLibs)\n-    INCLUDE_DIRECTORIES(${PYTHON_INCLUDE_PATH})\n+SET(BUILD_CXX ON)\n+SET(DOWNLOAD_LOCATION \"${CMAKE_CURRENT_BINARY_DIR}/downloads\" CACHE PATH \"Location where external projects will be downloaded.\")\n \n-    IF(PYTHON_VERSION_MAJOR GREATER_EQUAL 3)\n-        SET(CMAKE_SWIG_FLAGS \"${CMAKE_SWIG_FLAGS};-py3;-DPY3\")\n-    ENDIF()\n+MARK_AS_ADVANCED(BUILD_CXX)\n+MARK_AS_ADVANCED(DOWNLOAD_LOCATION)\n \n-    FIND_PACKAGE(SWIG REQUIRED)\n-    INCLUDE(cmake/UseSWIG.cmake)\n-ENDIF(BUILD_PYTHON)\n+SET(${PROJECT_NAME}externalTargets \"\")\n \n-IF(BUILD_CXX)\n-    SET(CMAKE_CXX_FLAGS  \"${CMAKE_CXX_FLAGS} -DUSE_GLOP -DUSE_BOP\")\n+FILE(READ ${CMAKE_CURRENT_SOURCE_DIR}/Dependencies.txt _Dependency_file)\n+FOREACH(DEPENDENCY Protobuf Gflags Glog cbc CoinUtils Osi Clp Cgl)\n+    STRING(REGEX REPLACE \".*${DEPENDENCY} = ([0-9.]+).*\" \"\\\\1\" ${DEPENDENCY}_VERSION ${_Dependency_file})\n+ENDFOREACH()\n \n-    FIND_PACKAGE(Protobuf REQUIRED)\n+IF(BUILD_CXX)\n+    FIND_PACKAGE(Threads REQUIRED)\n \n-    FILE(GLOB_RECURSE proto_files RELATIVE ${CMAKE_CURRENT_SOURCE_DIR}\n-        \"ortools/*.proto\")\n-    SET(PROTOBUF_GENERATE_CPP_APPEND_PATH OFF)\n-    FIND_PACKAGE(Gflags REQUIRED)\n+    FIND_PACKAGE(Protobuf ${Protobuf_VERSION} QUIET)\n+    IF(NOT Protobuf_FOUND)\n+        MESSAGE(STATUS \"Did not find system protobuff. Building as an external project\")\n+        INCLUDE(cmake/external/protobuf.cmake)\n+    ENDIF()\n+    INCLUDE_DIRECTORIES(${Protobuf_INCLUDE_DIRS})\n \n-    PKG_CHECK_MODULES(CBC cbc)\n-    IF(CBC_FOUND)\n-        SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${CBC_CFLAGS} -DUSE_CBC\")\n-    ENDIF(CBC_FOUND)\n+    FIND_PACKAGE(Gflags ${Gflags_VERSION} QUIET)\n+    IF(NOT Gflags_FOUND)\n+        MESSAGE(STATUS \"Did not find system gflags. Building as an external project\")\n+        INCLUDE(cmake/external/gflags.cmake)\n+    ENDIF()\n+    INCLUDE_DIRECTORIES(${Gflags_INCLUDE_DIRS})\n+\n+    SET(GLOG_VERSION ${Glog_VERSION})\n+    PKG_CHECK_MODULES(GLOG libglog>=${GLOG_VERSION})\n+    # Set again since pkg_check_module resets GLOG_VERSION\n+    SET(GLOG_VERSION ${Glog_VERSION})\n+    IF(NOT GLOG_FOUND)\n+        MESSAGE(STATUS \"Did not find system glog. Building as an external project.\")\n+        INCLUDE(cmake/external/glog.cmake)\n+    ENDIF()\n+    INCLUDE_DIRECTORIES(${GLOG_INCLUDE_DIRS})\n+\n+    SET(Cbc_VERSION ${cbc_VERSION})\n+    PKG_CHECK_MODULES(Cbc cbc)\n+    SET(Cbc_VERSION ${cbc_VERSION})\n+    IF(NOT Cbc_FOUND)\n+        MESSAGE(STATUS \"Did not find system coin-cbc. Building as an external Project.\")\n+        INCLUDE(cmake/external/cbc.cmake)\n+    ENDIF()\n+    INCLUDE_DIRECTORIES(${Cbc_INCLUDE_DIRS})\n \n-    PKG_CHECK_MODULES(CLP clp)\n-    IF(CLP_FOUND)\n-        SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${CLP_CFLAGS} -DUSE_CLP\")\n-    ENDIF(CLP_FOUND)\n+    SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fwrapv -DNDEBUG -DUSE_GLOP -DUSE_BOP -DUSE_CBC -DUSE_CLP\")\n \n-    PKG_CHECK_MODULES(GLOG libglog)\n+    FILE(GLOB_RECURSE proto_files RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} \"ortools/*.proto\")\n+    SET(PROTOBUF_GENERATE_CPP_APPEND_PATH OFF)\n \n     INCLUDE_DIRECTORIES(.)\n-    INCLUDE_DIRECTORIES(examples)\n     INCLUDE_DIRECTORIES(${CMAKE_CURRENT_BINARY_DIR})\n     INCLUDE_DIRECTORIES(${PROTOBUF_INCLUDE_DIRS})\n \n     PROTOBUF_GENERATE_CPP(PROTO_SRCS PROTO_HDRS ${proto_files})\n     ADD_LIBRARY(${PROJECT_NAME}Proto OBJECT ${PROTO_SRCS} ${PROTO_HDRS})\n+    ADD_DEPENDENCIES(${PROJECT_NAME}Proto ${${PROJECT_NAME}externalTargets})\n     SET_TARGET_PROPERTIES(${PROJECT_NAME}Proto PROPERTIES POSITION_INDEPENDENT_CODE ON)\n \n     SET(SUBTARGETS \"\")\n@@ -68,10 +90,11 @@ IF(BUILD_CXX)\n \n     ADD_LIBRARY(${PROJECT_NAME} SHARED ${SUBTARGETS})\n     TARGET_LINK_LIBRARIES(${PROJECT_NAME}\n-            ${GLOG_LIBRARIES}\n+            ${Cbc_LIBRARIES}\n+            ${Gflags_LIBRARIES}\n             ${Protobuf_LIBRARIES}\n-            ${gflags_LIBRARIES}\n-            ${CBC_LIBRARIES})\n+            ${GLOG_LIBRARIES}\n+            ${CMAKE_THREAD_LIBS_INIT})\n \n     ADD_DEPENDENCIES(${PROJECT_NAME} ${PROJECT_NAME}Proto)\n     INSTALL(TARGETS ${PROJECT_NAME}\n@@ -82,12 +105,6 @@ IF(BUILD_CXX)\n     ADD_SUBDIRECTORY(examples/cpp)\n ENDIF(BUILD_CXX)\n \n-IF(BUILD_PYTHON)\n-    FOREACH(SUBPROJECT constraint_solver algorithms graph linear_solver)\n-        ADD_SUBDIRECTORY(ortools/${SUBPROJECT}/python)\n-    ENDFOREACH(SUBPROJECT constraint_solver algorithms)\n-ENDIF(BUILD_PYTHON)\n-\n INSTALL(DIRECTORY ortools\n         DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}\n         FILES_MATCHING PATTERN \"*.h\")\ndiff --git a/Dependencies.txt b/Dependencies.txt\nnew file mode 100644\nindex 00000000000..bf0a0799560\n--- /dev/null\n+++ b/Dependencies.txt\n@@ -0,0 +1,8 @@\n+Protobuf = 3.3.0\n+Gflags = 2.2.0\n+Glog = 0.3.5\n+cbc = 2.9.8\n+CoinUtils = 2.10.13\n+Osi = 0.107.8\n+Clp = 1.16.10\n+Cgl = 0.59.9\n\\ No newline at end of file\ndiff --git a/cmake/external/cbc.cmake b/cmake/external/cbc.cmake\nnew file mode 100644\nindex 00000000000..bd92e555a2c\n--- /dev/null\n+++ b/cmake/external/cbc.cmake\n@@ -0,0 +1,47 @@\n+SET(ADD_CXXFLAGS \"-DCBC_THREAD_SAFE -DCBC_NO_INTERRUPT\")\n+\n+FOREACH(COIN_PROJECT CoinUtils Osi Clp Cgl Cbc)\n+    SET(${COIN_PROJECT}_URL https://github.com/coin-or/${COIN_PROJECT}.git)\n+    SET(${COIN_PROJECT}_INCLUDE_DIRS ${CMAKE_CURRENT_BINARY_DIR}/install/include)\n+\n+    ExternalProject_Add(${COIN_PROJECT}_project\n+            PREFIX ${COIN_PROJECT}\n+            GIT_REPOSITORY ${${COIN_PROJECT}_URL}\n+            GIT_TAG \"releases/${${COIN_PROJECT}_VERSION}\"\n+            DOWNLOAD_DIR \"${DOWNLOAD_LOCATION}\"\n+            UPDATE_COMMAND \"\"\n+            BUILD_IN_SOURCE 1\n+            CONFIGURE_COMMAND ${CMAKE_CURRENT_BINARY_DIR}/${COIN_PROJECT}/src/${COIN_PROJECT}_project/configure\n+            --disable-bzlib --without-lapack --with-pic --enable-static --prefix=${CMAKE_CURRENT_BINARY_DIR}/install\n+            ADD_CXXFLAGS=${ADD_CXXFLAGS})\n+\n+    ADD_LIBRARY(${COIN_PROJECT} STATIC IMPORTED)\n+    SET_PROPERTY(TARGET ${COIN_PROJECT} PROPERTY IMPORTED_LOCATION ${CMAKE_CURRENT_BINARY_DIR}/install/lib/lib${COIN_PROJECT}.a)\n+\n+    IF (${COIN_PROJECT} STREQUAL \"Cbc\" OR ${COIN_PROJECT} STREQUAL \"Clp\")\n+        ADD_LIBRARY(Osi${COIN_PROJECT} STATIC IMPORTED)\n+        SET_PROPERTY(TARGET Osi${COIN_PROJECT} PROPERTY IMPORTED_LOCATION ${CMAKE_CURRENT_BINARY_DIR}/install/lib/libOsi${COIN_PROJECT}.a)\n+        ADD_LIBRARY(${COIN_PROJECT}Solver STATIC IMPORTED)\n+        SET_PROPERTY(TARGET ${COIN_PROJECT}Solver PROPERTY IMPORTED_LOCATION ${CMAKE_CURRENT_BINARY_DIR}/install/lib/lib${COIN_PROJECT}Solver.a)\n+    ENDIF()\n+\n+    ADD_DEPENDENCIES(${COIN_PROJECT} ${COIN_PROJECT}_project)\n+ENDFOREACH()\n+\n+ADD_DEPENDENCIES(Osi_project CoinUtils_project)\n+ADD_DEPENDENCIES(Clp_project Osi_project)\n+ADD_DEPENDENCIES(Cgl_project Clp_project)\n+ADD_DEPENDENCIES(Cbc_project Cgl_project)\n+\n+SET_PROPERTY(TARGET Osi PROPERTY INTERFACE_LINK_LIBRARIES CoinUtils)\n+SET_PROPERTY(TARGET Clp PROPERTY INTERFACE_LINK_LIBRARIES Osi)\n+SET_PROPERTY(TARGET OsiClp PROPERTY INTERFACE_LINK_LIBRARIES Clp)\n+SET_PROPERTY(TARGET ClpSolver PROPERTY INTERFACE_LINK_LIBRARIES Clp)\n+SET_PROPERTY(TARGET Cgl PROPERTY INTERFACE_LINK_LIBRARIES Clp)\n+SET_PROPERTY(TARGET Cbc PROPERTY INTERFACE_LINK_LIBRARIES Cgl)\n+SET_PROPERTY(TARGET OsiCbc PROPERTY INTERFACE_LINK_LIBRARIES Cbc)\n+SET_PROPERTY(TARGET CbcSolver PROPERTY INTERFACE_LINK_LIBRARIES Cbc)\n+\n+LIST(APPEND ${PROJECT_NAME}externalTargets Cbc)\n+SET(Cbc_LIBRARIES \"\")\n+LIST(APPEND Cbc_LIBRARIES Cbc OsiCbc CbcSolver ClpSolver OsiClp)\ndiff --git a/cmake/external/gflags.cmake b/cmake/external/gflags.cmake\nnew file mode 100644\nindex 00000000000..625a374d5c6\n--- /dev/null\n+++ b/cmake/external/gflags.cmake\n@@ -0,0 +1,26 @@\n+SET(Gflags_INCLUDE_DIRS ${CMAKE_CURRENT_BINARY_DIR}/gflags_project/src/gflags/include/)\n+SET(Gflags_URL https://github.com/gflags/gflags)\n+\n+ExternalProject_Add(Gflags_project\n+        PREFIX Gflags\n+        GIT_REPOSITORY ${Gflags_URL}\n+        GIT_TAG \"v${Gflags_VERSION}\"\n+        DOWNLOAD_DIR \"${DOWNLOAD_LOCATION}\"\n+        UPDATE_COMMAND \"\"\n+        BUILD_IN_SOURCE 1\n+        SOURCE_DIR ${CMAKE_CURRENT_BINARY_DIR}/gflags_project/src/gflags\n+        CONFIGURE_COMMAND ${CMAKE_COMMAND}\n+        -DBUILD_STATIC_LIBS=ON\n+        -DBUILD_TESTING=OFF\n+        -DCMAKE_POSITION_INDEPENDENT_CODE=ON\n+        ${Gflags_ADDITIONAL_CMAKE_OPTIONS}\n+        INSTALL_COMMAND \"\"\n+        CMAKE_CACHE_ARGS\n+        -DCMAKE_BUILD_TYPE:STRING=Release\n+        -DCMAKE_VERBOSE_MAKEFILE:BOOL=OFF\n+        -DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=ON)\n+\n+ADD_LIBRARY(Gflags STATIC IMPORTED) \n+SET_PROPERTY(TARGET Gflags PROPERTY IMPORTED_LOCATION ${CMAKE_CURRENT_BINARY_DIR}/gflags_project/src/gflags/lib/libgflags.a)\n+SET(Gflags_LIBRARIES \"\")\n+LIST(APPEND Gflags_LIBRARIES Gflags)\ndiff --git a/cmake/external/glog.cmake b/cmake/external/glog.cmake\nnew file mode 100644\nindex 00000000000..ecfb2e3693c\n--- /dev/null\n+++ b/cmake/external/glog.cmake\n@@ -0,0 +1,26 @@\n+SET(GLOG_INCLUDE_DIRS ${CMAKE_CURRENT_BINARY_DIR}/glog_project/src/glog/)\n+LIST(APPEND GLOG_INCLUDE_DIRS ${CMAKE_CURRENT_BINARY_DIR}/glog_project/src/glog/src/)\n+SET(GLOG_URL https://github.com/google/glog)\n+\n+ExternalProject_Add(Glog_project\n+        PREFIX Glog\n+        GIT_REPOSITORY ${GLOG_URL}\n+        GIT_TAG \"v${GLOG_VERSION}\"\n+        DOWNLOAD_DIR \"${DOWNLOAD_LOCATION}\"\n+        UPDATE_COMMAND \"\"\n+        BUILD_IN_SOURCE 1\n+        SOURCE_DIR ${CMAKE_CURRENT_BINARY_DIR}/glog_project/src/glog\n+        CONFIGURE_COMMAND ${CMAKE_COMMAND}\n+        -DBUILD_TESTING=OFF\n+        -DCMAKE_POSITION_INDEPENDENT_CODE=ON\n+        ${Glogs_ADDITIONAL_CMAKE_OPTIONS}\n+        INSTALL_COMMAND \"\"\n+        CMAKE_CACHE_ARGS\n+        -DCMAKE_BUILD_TYPE:STRING=Release\n+        -DCMAKE_VERBOSE_MAKEFILE:BOOL=OFF\n+        -DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=ON)\n+\n+ADD_LIBRARY(GLOG STATIC IMPORTED) \n+SET_PROPERTY(TARGET GLOG PROPERTY IMPORTED_LOCATION ${CMAKE_CURRENT_BINARY_DIR}/glog_project/src/glog/libglog.a)\n+SET(GLOG_LIBRARIES \"\")\n+LIST(APPEND GLOG_LIBRARIES GLOG)\ndiff --git a/cmake/external/protobuf.cmake b/cmake/external/protobuf.cmake\nnew file mode 100644\nindex 00000000000..596659780d8\n--- /dev/null\n+++ b/cmake/external/protobuf.cmake\n@@ -0,0 +1,30 @@\n+FIND_PACKAGE(ZLIB REQUIRED)\n+\n+SET(Protobuf_INCLUDE_DIRS ${CMAKE_CURRENT_BINARY_DIR}/protobuf_project/src/protobuf/src)\n+SET(Protobuf_URL https://github.com/google/protobuf)\n+\n+ExternalProject_Add(Protobuf_project\n+        PREFIX Protobuf\n+        GIT_REPOSITORY ${Protobuf_URL}\n+        GIT_TAG \"v${Protobuf_VERSION}\"\n+        DOWNLOAD_DIR \"${DOWNLOAD_LOCATION}\"\n+        UPDATE_COMMAND \"\"\n+        BUILD_IN_SOURCE 1\n+        SOURCE_DIR ${CMAKE_CURRENT_BINARY_DIR}/protobuf_project/src/protobuf\n+        CONFIGURE_COMMAND ${CMAKE_COMMAND} cmake/\n+        -Dprotobuf_BUILD_TESTS=OFF\n+        -DBUILD_STATIC_LIBS=ON\n+        -DCMAKE_POSITION_INDEPENDENT_CODE=ON\n+        ${Protobuf_ADDITIONAL_CMAKE_OPTIONS}\n+        INSTALL_COMMAND \"\"\n+        CMAKE_CACHE_ARGS\n+        -DCMAKE_BUILD_TYPE:STRING=Release\n+        -DCMAKE_VERBOSE_MAKEFILE:BOOL=OFF\n+        -DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=ON)\n+\n+ADD_LIBRARY(Protobuf STATIC IMPORTED)\n+SET_PROPERTY(TARGET Protobuf PROPERTY IMPORTED_LOCATION ${CMAKE_CURRENT_BINARY_DIR}/protobuf_project/src/protobuf/libprotobuf.a)\n+SET(Protobuf_LIBRARIES \"\")\n+LIST(APPEND Protobuf_LIBRARIES Protobuf ${ZLIB_LIBRARIES})\n+\n+SET(Protobuf_PROTOC_EXECUTABLE ${CMAKE_CURRENT_BINARY_DIR}/protobuf_project/src/protobuf/protoc)\ndiff --git a/examples/cpp/CMakeLists.txt b/examples/cpp/CMakeLists.txt\nindex 9e8d182c1b8..5f8b23e669e 100644\n--- a/examples/cpp/CMakeLists.txt\n+++ b/examples/cpp/CMakeLists.txt\n@@ -1,10 +1,17 @@\n-ADD_LIBRARY(executable_libs STATIC\n+ADD_LIBRARY(${PROJECT_NAME}examples SHARED\n         cvrptw_lib.cc\n         parse_dimacs_assignment.cc\n         fap_model_printer.cc\n         fap_parser.cc\n         fap_utilities.cc)\n-ADD_DEPENDENCIES(executable_libs ${PROJECT_NAME}Proto)\n+\n+INSTALL(TARGETS ${PROJECT_NAME}examples\n+            EXPORT ${PROJECT_NAME}_Exports\n+            ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}\n+            LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n+            RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR})\n+\n+ADD_DEPENDENCIES(${PROJECT_NAME}examples ${PROJECT_NAME}Proto)\n \n FOREACH(EXECUTABLE\n         costas_array\n@@ -44,6 +51,6 @@ FOREACH(EXECUTABLE\n         tsp\n         weighted_tardiness_sat)\n     ADD_EXECUTABLE(${EXECUTABLE} ${EXECUTABLE}.cc)\n-    TARGET_LINK_LIBRARIES(${EXECUTABLE} executable_libs ${PROJECT_NAME})\n+    TARGET_LINK_LIBRARIES(${EXECUTABLE} ${PROJECT_NAME}examples ${PROJECT_NAME})\n     INSTALL(TARGETS ${EXECUTABLE} RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR})\n ENDFOREACH()\ndiff --git a/ortools/algorithms/python/CMakeLists.txt b/ortools/algorithms/python/CMakeLists.txt\nindex b6e30b15acf..d5233365dc8 100644\n--- a/ortools/algorithms/python/CMakeLists.txt\n+++ b/ortools/algorithms/python/CMakeLists.txt\n@@ -4,4 +4,6 @@ IF(BUILD_PYTHON)\n \n     SWIG_ADD_LIBRARY(pywrapknapsack_solver TYPE MODULE LANGUAGE python SOURCES knapsack_solver.i)\n     SWIG_LINK_LIBRARIES(pywrapknapsack_solver ${PROJECT_NAME})\n+\n+    INSTALL(TARGETS _pywrapknapsack_solver DESTINATION ${PYTHON_MODULE_PATH})\n ENDIF(BUILD_PYTHON)\n\\ No newline at end of file\ndiff --git a/ortools/constraint_solver/CMakeLists.txt b/ortools/constraint_solver/CMakeLists.txt\nindex 4392e1f0740..be65bf63f29 100644\n--- a/ortools/constraint_solver/CMakeLists.txt\n+++ b/ortools/constraint_solver/CMakeLists.txt\n@@ -4,15 +4,6 @@ PROJECT(${PROJECT_NAME}_constraint_solver)\n \n FILE(GLOB ${PROJECT_NAME}_SOURCES \"*.cc\")\n \n-IF(BUILD_PYTHON)\n-    PROTOBUF_GENERATE_PYTHON(PY_ASSIGN_PROTO_SRCS assignment.proto)\n-    PROTOBUF_GENERATE_PYTHON(PY_SEARCH_PROTO_SRCS search_limit.proto)\n-    PROTOBUF_GENERATE_PYTHON(PY_MODEL__PROTO_SRCS model.proto)\n-    PROTOBUF_GENERATE_PYTHON(PY_ROUTEN_PROTO_SRCS routing_enums.proto)\n-    PROTOBUF_GENERATE_PYTHON(PY_SOLVER_PROTO_SRCS solver_parameters.proto)\n-    PROTOBUF_GENERATE_PYTHON(PY_ROUTPA_PROTO_SRCS routing_parameters.proto)\n-ENDIF(BUILD_PYTHON)\n-\n ADD_LIBRARY(${PROJECT_NAME} OBJECT ${${PROJECT_NAME}_SOURCES})\n SET_TARGET_PROPERTIES(${PROJECT_NAME} PROPERTIES POSITION_INDEPENDENT_CODE ON)\n \ndiff --git a/ortools/constraint_solver/python/CMakeLists.txt b/ortools/constraint_solver/python/CMakeLists.txt\nindex 304bfa02a00..731ff9ce211 100644\n--- a/ortools/constraint_solver/python/CMakeLists.txt\n+++ b/ortools/constraint_solver/python/CMakeLists.txt\n@@ -4,4 +4,6 @@ IF(BUILD_PYTHON)\n \n     SWIG_ADD_LIBRARY(pywrapcp TYPE MODULE LANGUAGE python SOURCES routing.i)\n     SWIG_LINK_LIBRARIES(pywrapcp ${PROJECT_NAME})\n+\n+    INSTALL(TARGETS _pywrapcp DESTINATION ${PYTHON_MODULE_PATH})\n ENDIF(BUILD_PYTHON)\n\\ No newline at end of file\ndiff --git a/ortools/graph/python/CMakeLists.txt b/ortools/graph/python/CMakeLists.txt\nindex 09621069115..ca850aa0e60 100644\n--- a/ortools/graph/python/CMakeLists.txt\n+++ b/ortools/graph/python/CMakeLists.txt\n@@ -4,4 +4,6 @@ IF(BUILD_PYTHON)\n \n     SWIG_ADD_LIBRARY(pywrapgraph TYPE MODULE LANGUAGE python SOURCES graph.i)\n     SWIG_LINK_LIBRARIES(pywrapgraph ${PROJECT_NAME})\n+\n+    INSTALL(TARGETS _pywrapgraph DESTINATION ${PYTHON_MODULE_PATH})\n ENDIF(BUILD_PYTHON)\n\\ No newline at end of file\ndiff --git a/ortools/linear_solver/CMakeLists.txt b/ortools/linear_solver/CMakeLists.txt\nindex 9bc24531b86..d176a97c5e0 100644\n--- a/ortools/linear_solver/CMakeLists.txt\n+++ b/ortools/linear_solver/CMakeLists.txt\n@@ -4,11 +4,7 @@ PROJECT(${PROJECT_NAME}_linear_solver)\n \n FILE(GLOB ${PROJECT_NAME}_SOURCES \"*.cc\")\n \n-IF(BUILD_PYTHON)\n-    PROTOBUF_GENERATE_PYTHON(PY_PROTO_SRCS linear_solver.proto)\n-ENDIF(BUILD_PYTHON)\n-\n ADD_LIBRARY(${PROJECT_NAME} OBJECT ${${PROJECT_NAME}_SOURCES})\n SET_TARGET_PROPERTIES(${PROJECT_NAME} PROPERTIES POSITION_INDEPENDENT_CODE ON)\n \n-ADD_DEPENDENCIES(${PROJECT_NAME} ${ROOT_PROJECT}Proto)\n\\ No newline at end of file\n+ADD_DEPENDENCIES(${PROJECT_NAME} ${ROOT_PROJECT}Proto)\ndiff --git a/ortools/linear_solver/python/CMakeLists.txt b/ortools/linear_solver/python/CMakeLists.txt\nindex 3ceece33a4a..9a363c3c114 100644\n--- a/ortools/linear_solver/python/CMakeLists.txt\n+++ b/ortools/linear_solver/python/CMakeLists.txt\n@@ -4,4 +4,6 @@ IF(BUILD_PYTHON)\n \n     SWIG_ADD_LIBRARY(pywraplp TYPE MODULE LANGUAGE python SOURCES linear_solver.i)\n     SWIG_LINK_LIBRARIES(pywraplp ${PROJECT_NAME})\n+\n+    INSTALL(TARGETS _pywraplp DESTINATION ${PYTHON_MODULE_PATH})\n ENDIF()\n\\ No newline at end of file\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. Update dependency version in CMakeLists.txt: change Protobuf from 3.0.2 to 3.3.0.\n2. Implement a centralized configuration file for dependency management, usable across build systems.\n3. Fix the `add_dependencies` call in the CMakeLists.txt; currently has incorrect arguments.\n4. Address the issue where `PROJECT_NAME` appears to be undefined.\n5. Test the build on macOS and ensure it successfully compiles.\n6. Confirm the use of pkg-config, as missing it may hinder the build process.\n7. Check and correct syntax errors indicated on line 59 in the provided build log.\n8. Investigate the ability to force CMake to recompile local packages."
      }
    ],
    "codediff_length": 16955
  },
  {
    "index": 121,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/CONTRIBUTORS b/CONTRIBUTORS\nindex 47ac10ba80..726e5b59aa 100644\n--- a/CONTRIBUTORS\n+++ b/CONTRIBUTORS\n@@ -11,6 +11,7 @@ Bryan Borham <bjboreham@gmail.com>: Initial MSVC support\n Philip Quinn <p@partylemon.com>: cmake build and other assorted bits\n Brian Taylor <el.wubo@gmail.com>: emacs syntax highlighting\n Ben Laurie <ben@links.org>: discovered and responsibly disclosed security bugs\n+Marek Piku\u0142a <marek@pikula.co>: CMake improvements\n \n This file does not list people who maintain their own Cap'n Proto\n implementations as separate projects.  Those people are awesome too!  :)\ndiff --git a/RELEASE-PROCESS.md b/RELEASE-PROCESS.md\nindex 2b4a3af7e9..57a3c67fc7 100644\n--- a/RELEASE-PROCESS.md\n+++ b/RELEASE-PROCESS.md\n@@ -26,8 +26,8 @@ How to release\n \n * Install your release candidates on your local machine, as if you were a user.\n \n-* Go to `c++/samples` in the git repo and run `./test.sh`.  It will try to build against your\n-  installed copy.\n+* Go to `c++/samples` in the git repo and run `./test-cmake.sh`, or `./test.sh` if you don't like\n+  CMake.  It will try to build against your installed copy.\n \n * Post the release candidates somewhere public and then send links to the mailing list for people\n   to test.  Wait a bit for bug reports.\ndiff --git a/c++/.gitignore b/c++/.gitignore\nnew file mode 100644\nindex 0000000000..567609b123\n--- /dev/null\n+++ b/c++/.gitignore\n@@ -0,0 +1 @@\n+build/\ndiff --git a/c++/cmake/C++11.cmake b/c++/cmake/C++11.cmake\nnew file mode 100644\nindex 0000000000..105e320dc7\n--- /dev/null\n+++ b/c++/cmake/C++11.cmake\n@@ -0,0 +1,72 @@\n+#\n+# Macro that checks for C++11 support and sets compiler flags\n+# If C++11 is not present it throws message with MESSAGE_SEVERITY.\n+# Bear in mind, that for MSVC it's just passing \"-std=c++0x\" to compiler.\n+#\n+# Macro:\n+#   CheckCXX11(MESSAGE_SEVERITY)\n+#       MESSAGE_SEVERITY        it's not mandatory and has default value of \"STATUS\"\n+#                               this is severity of message if no C++11 was found\n+#\n+# Output variables:\n+#   COMPILER_SUPPORTS_CXX11     ON when compiler supports C++11\n+#\n+# Copyright (c) 2015, Marek Piku\u0142a <marek@pikula.co>\n+#\n+# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\n+# documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation\n+# the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,\n+# and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n+#\n+# The above copyright notice and this permission notice shall be included in all copies or substantial portions\n+# of the Software.\n+#\n+# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n+# TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n+# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n+# CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n+# DEALINGS IN THE SOFTWARE.\n+#\n+\n+macro (CheckCXX11)\n+    set (COMPILER_SUPPORTS_CXX11 OFF)\n+    \n+    if (MSVC)\n+        # MSVC has C++11 turned on by default\n+        set (COMPILER_SUPPORTS_CXX11 ON)\n+    else ()\n+        include (CheckCXXCompilerFlag)\n+        if (CMAKE_COMPILER_IS_GNUCXX)\n+            check_cxx_compiler_flag (\"-std=gnu++11\" GNUXX11)\n+        endif ()\n+        if (NOT GNUXX11)\n+            check_cxx_compiler_flag (\"-std=c++11\" CXX11)\n+            check_cxx_compiler_flag (\"-std=c++0x\" CXX0X)\n+        endif ()\n+        \n+        if (GNUXX11)\n+            set (CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=gnu++11\")\n+            set (COMPILER_SUPPORTS_CXX11 ON)\n+        elseif (CXX11)\n+            set (CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++11\")\n+            set (COMPILER_SUPPORTS_CXX11 ON)\n+        elseif (CXX0X)\n+            set (CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++0x\")\n+            set (COMPILER_SUPPORTS_CXX11 ON)\n+        endif ()\n+    endif ()\n+    \n+    if (NOT COMPILER_SUPPORTS_CXX11)\n+        if (${ARGC})\n+            set (MESSAGE_SEVERITY ${ARGV0})\n+        else ()\n+            set (MESSAGE_SEVERITY \"STATUS\")\n+        endif ()\n+        message (${MESSAGE_SEVERITY} \"C++11 support in ${CMAKE_CXX_COMPILER} compiler was not detected. Please use a different C++ compiler.\")\n+        unset (MESSAGE_SEVERITY)\n+    endif ()\n+    \n+    unset (GNUXX11)\n+    unset (CXX11)\n+    unset (CXX0X)\n+endmacro ()\ndiff --git a/c++/cmake/FindCapnProto.cmake b/c++/cmake/FindCapnp.cmake\nsimilarity index 81%\nrename from c++/cmake/FindCapnProto.cmake\nrename to c++/cmake/FindCapnp.cmake\nindex 55f79c24a7..370da9cecc 100644\n--- a/c++/cmake/FindCapnProto.cmake\n+++ b/c++/cmake/FindCapnp.cmake\n@@ -19,7 +19,7 @@\n #       Path to the `capnpc-c++` tool (can be set to override).\n #   CAPNP_INCLUDE_DIRS\n #       Include directories for the library's headers (can be set to override).\n-#   CANP_LIBRARIES\n+#   CAPNP_LIBRARIES\n #       The Cap'n Proto library paths.\n #   CAPNP_LIBRARIES_LITE\n #       Paths to only the 'lite' libraries.\n@@ -30,7 +30,7 @@\n #\n # Example usage:\n #\n-#   find_package(CapnProto REQUIRED)\n+#   find_package(Capnp REQUIRED)\n #   include_directories(${CAPNP_INCLUDE_DIRS})\n #   add_definitions(${CAPNP_DEFINITIONS})\n #\n@@ -72,12 +72,12 @@ function(CAPNP_GENERATE_CPP SOURCES HEADERS)\n     endforeach()\n   endif()\n \n-  if(DEFINED CAPNPC_OUTPUT_DIR)\n-    # Prepend a ':' to get the format for the '-o' flag right\n-    set(output_dir \":${CAPNPC_OUTPUT_DIR}\")\n-  else()\n-    set(output_dir \":.\")\n-  endif()\n+  if (NOT DEFINED CAPNPC_OUTPUT_DIR)\n+    set (CAPNPC_OUTPUT_DIR \"${CMAKE_CURRENT_BINARY_DIR}\")\n+  endif()  \n+  \n+  # Prepend a ':' to get the format for the '-o' flag right\n+  set(output_dir \":${CAPNPC_OUTPUT_DIR}\")\n \n   if(NOT DEFINED CAPNPC_SRC_PREFIX)\n     set(CAPNPC_SRC_PREFIX \"${CMAKE_CURRENT_SOURCE_DIR}\")\n@@ -91,21 +91,17 @@ function(CAPNP_GENERATE_CPP SOURCES HEADERS)\n     get_filename_component(file_dir \"${file_path}\" PATH)\n \n     # Figure out where the output files will go\n-    if (NOT DEFINED CAPNPC_OUTPUT_DIR)\n-      set(output_base \"${file_path}\")\n-    else()\n-      # Output files are placed in CAPNPC_OUTPUT_DIR, at a location as if they were\n-      # relative to CAPNPC_SRC_PREFIX.\n-      string(LENGTH \"${CAPNPC_SRC_PREFIX}\" prefix_len)\n-      string(SUBSTRING \"${file_path}\" 0 ${prefix_len} output_prefix)\n-      if(NOT \"${CAPNPC_SRC_PREFIX}\" STREQUAL \"${output_prefix}\")\n-        message(SEND_ERROR \"Could not determine output path for '${schema_file}' ('${file_path}') with source prefix '${CAPNPC_SRC_PREFIX}' into '${CAPNPC_OUTPUT_DIR}'.\")\n-      endif()\n-\n-      string(SUBSTRING \"${file_path}\" ${prefix_len} -1 output_path)\n-      set(output_base \"${CAPNPC_OUTPUT_DIR}${output_path}\")\n+    # Output files are placed in CAPNPC_OUTPUT_DIR, at a location as if they were\n+    # relative to CAPNPC_SRC_PREFIX.\n+    string(LENGTH \"${CAPNPC_SRC_PREFIX}\" prefix_len)\n+    string(SUBSTRING \"${file_path}\" 0 ${prefix_len} output_prefix)\n+    if(NOT \"${CAPNPC_SRC_PREFIX}\" STREQUAL \"${output_prefix}\")\n+      message(SEND_ERROR \"Could not determine output path for '${schema_file}' ('${file_path}') with source prefix '${CAPNPC_SRC_PREFIX}' into '${CAPNPC_OUTPUT_DIR}'.\")\n     endif()\n \n+    string(SUBSTRING \"${file_path}\" ${prefix_len} -1 output_path)\n+    set(output_base \"${CAPNPC_OUTPUT_DIR}${output_path}\")\n+\n     add_custom_command(\n       OUTPUT \"${output_base}.c++\" \"${output_base}.h\"\n       COMMAND \"${CAPNP_EXECUTABLE}\"\n@@ -181,6 +177,20 @@ find_program(CAPNPC_CXX_EXECUTABLE\n   HINTS \"${PKGCONFIG_CAPNP_PREFIX}/bin\"\n )\n \n+# Check for C++11 and add required compiler flags\n+include(C++11)\n+CheckCXX11(FATAL_ERROR)\n+\n+# Check if kj/common.h compiles (indicates all needed C++11 features are available)\n+check_cxx_source_compiles(\n+  \"#include <kj/common.h>\n+   int main() {return 0;}\"\n+  KJ_COMMON_COMPILES\n+)\n+if(NOT KJ_COMMON_COMPILES)\n+  message (FATAL_ERROR \"kj/common.h compile check failed! Your compiler probably doesn't support C++11 enough.\")\n+endif ()\n+\n # Only *require* the include directory, libkj, and libcapnp. If compiling with\n # CAPNP_LITE, nothing else will be found.\n include(FindPackageHandleStandardArgs)\ndiff --git a/c++/samples/.gitignore b/c++/samples/.gitignore\nnew file mode 100644\nindex 0000000000..567609b123\n--- /dev/null\n+++ b/c++/samples/.gitignore\n@@ -0,0 +1 @@\n+build/\ndiff --git a/c++/samples/CMakeLists.txt b/c++/samples/CMakeLists.txt\nnew file mode 100644\nindex 0000000000..6cc8f965a6\n--- /dev/null\n+++ b/c++/samples/CMakeLists.txt\n@@ -0,0 +1,62 @@\n+cmake_minimum_required (VERSION 2.8.12)\n+\n+project (\"Cap'n'proto sample\" CXX)\n+\n+# Needed to include generated Cap'n'proto headers\n+set (CMAKE_INCLUDE_CURRENT_DIR ON)\n+\n+# Include CMake scripts\n+set (CMAKE_MODULE_PATH \"${PROJECT_SOURCE_DIR}/../cmake\")\n+\n+# Enable tests\n+include(CTest)\n+\n+# Add \"-Wall\" to compiler flags\n+add_definitions (\"-Wall\")\n+\n+# Find Cap'n'proto\n+find_package (Capnp REQUIRED)\n+add_definitions(${CAPNP_DEFINITIONS})\n+\n+# Compile .capnp files\n+capnp_generate_cpp(CAPNPSRC_addressbook CAPNPHDR_addressbook \"${PROJECT_SOURCE_DIR}/addressbook.capnp\")\n+capnp_generate_cpp(CAPNPSRC_calculator CAPNPHDR_calculator \"${PROJECT_SOURCE_DIR}/calculator.capnp\")\n+\n+# Includes\n+include_directories (${CAPNP_INCLUDE_DIRS})\n+\n+# Targets\n+add_executable (addressbook\n+    addressbook.c++\n+    \"${CAPNPSRC_addressbook}\"\n+    \"${CAPNPHDR_addressbook}\"\n+)\n+target_link_libraries (addressbook ${CAPNP_LIBRARIES})\n+\n+add_executable (calculator-client\n+    calculator-client.c++\n+    \"${CAPNPSRC_calculator}\"\n+    \"${CAPNPHDR_calculator}\"\n+)\n+target_link_libraries (calculator-client ${CAPNP_LIBRARIES})\n+\n+add_executable (calculator-server\n+    calculator-server.c++\n+    \"${CAPNPSRC_calculator}\"\n+)\n+target_link_libraries (calculator-server ${CAPNP_LIBRARIES})\n+\n+# Tests\n+enable_testing()\n+\n+set (ADDRESSBOOK_EXEC \"${PROJECT_BINARY_DIR}/addressbook\")\n+configure_file (tests/addressbook1.sh.in tests/addressbook1.sh @ONLY)\n+configure_file (tests/addressbook2.sh.in tests/addressbook2.sh @ONLY)\n+\n+set (CALCULATOR_CLIENT_EXEC \"${PROJECT_BINARY_DIR}/calculator-client\")\n+set (CALCULATOR_SERVER_EXEC \"${PROJECT_BINARY_DIR}/calculator-server\")\n+configure_file (tests/calculator.sh.in tests/calculator.sh @ONLY)\n+\n+add_test (addressbook1 \"${PROJECT_BINARY_DIR}/tests/addressbook1.sh\")\n+add_test (addressbook2 \"${PROJECT_BINARY_DIR}/tests/addressbook2.sh\")\n+add_test (calculator \"${PROJECT_BINARY_DIR}/tests/calculator.sh\")\ndiff --git a/c++/samples/test-cmake.sh b/c++/samples/test-cmake.sh\nnew file mode 100755\nindex 0000000000..fbb504a816\n--- /dev/null\n+++ b/c++/samples/test-cmake.sh\n@@ -0,0 +1,12 @@\n+#! /usr/bin/env bash\n+#\n+# Quick script that compiles and runs the samples using CMake, then cleans up.\n+# Used for release testing.\n+\n+mkdir build\n+cd build\n+cmake ..\n+make\n+make test\n+cd ..\n+rm -fr build\ndiff --git a/c++/samples/test.sh b/c++/samples/test.sh\nindex 9d335aab54..18d5a83cd7 100755\n--- a/c++/samples/test.sh\n+++ b/c++/samples/test.sh\n@@ -1,6 +1,6 @@\n #! /usr/bin/env bash\n #\n-# Quick script that compiles and runs the samples, then cleans up.\n+# Quick script that compiles and runs the samples without CMake, then cleans up.\n # Used for release testing.\n \n set -exuo pipefail\n@@ -24,3 +24,4 @@ sleep 0.1\n kill %+\n wait %+ || true\n rm calculator-client calculator-server calculator.capnp.c++ calculator.capnp.h /tmp/capnp-calculator-example-$$\n+\ndiff --git a/c++/samples/tests/addressbook1.sh.in b/c++/samples/tests/addressbook1.sh.in\nnew file mode 100755\nindex 0000000000..29128d911b\n--- /dev/null\n+++ b/c++/samples/tests/addressbook1.sh.in\n@@ -0,0 +1,5 @@\n+#! /usr/bin/env bash\n+\n+set -exuo pipefail\n+\n+@ADDRESSBOOK_EXEC@ write | @ADDRESSBOOK_EXEC@ read\ndiff --git a/c++/samples/tests/addressbook2.sh.in b/c++/samples/tests/addressbook2.sh.in\nnew file mode 100755\nindex 0000000000..eee73d8647\n--- /dev/null\n+++ b/c++/samples/tests/addressbook2.sh.in\n@@ -0,0 +1,5 @@\n+#! /usr/bin/env bash\n+\n+set -exuo pipefail\n+\n+@ADDRESSBOOK_EXEC@ dwrite | @ADDRESSBOOK_EXEC@ dread\ndiff --git a/c++/samples/tests/calculator.sh.in b/c++/samples/tests/calculator.sh.in\nnew file mode 100755\nindex 0000000000..2df7489542\n--- /dev/null\n+++ b/c++/samples/tests/calculator.sh.in\n@@ -0,0 +1,9 @@\n+#! /usr/bin/env bash\n+\n+set -exuo pipefail\n+\n+@CALCULATOR_SERVER_EXEC@ unix:/tmp/capnp-calculator-example-$$ &\n+sleep 0.1\n+@CALCULATOR_CLIENT_EXEC@ unix:/tmp/capnp-calculator-example-$$\n+kill %+\n+wait %+ || true\ndiff --git a/c++/src/CMakeLists.txt b/c++/src/CMakeLists.txt\nindex 4c973c453b..920b0fd58a 100644\n--- a/c++/src/CMakeLists.txt\n+++ b/c++/src/CMakeLists.txt\n@@ -7,7 +7,7 @@ if(BUILD_TESTING)\n   include(CTest)\n \n   # Setup CAPNP_GENERATE_CPP for compiling test schemas\n-  find_package(CapnProto QUIET)\n+  find_package(Capnp QUIET)\n   set(CAPNP_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}\")\n \n   # Sadly, we can't use the 'test' target, as that's coopted by ctest\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Path Issue**: Change `.` to `CMAKE_CURRENT_LIST_DIR` to correctly reference the `.capnp` file location. \n\n2. **CMake Module Not Found**: Investigate why `FindCapnpProto.cmake` reports `capnp` not found when it is correctly installed. Ensure `feature_summary` recognizes installed packages.\n\n3. **License Concerns**: Remove the BSD 3-clause license from `samples/cmake`; instead, add your name to `CONTRIBUTORS` under the MIT license.\n\n4. **Testing Scripts**: Retain `test.sh` as is, and create a new `test-cmake.sh` to facilitate testing with CMake.\n\n5. **C++11 Checks**: Integrate C++11 checks directly into `FindCapnp.cmake` using `CHECK_CXX_SOURCE_COMPILES` to ensure robust and transparent compatibility checking before build errors occur. \n\n6. **Compiler Flags**: Avoid using `-Wall` for MSVC; ensure the usage of C++11 flags aligns with various compilers to prevent build issues."
      }
    ],
    "codediff_length": 13128
  },
  {
    "index": 122,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.github/workflows/quick-test.yml b/.github/workflows/quick-test.yml\nindex efb9a80c10..67f874b970 100644\n--- a/.github/workflows/quick-test.yml\n+++ b/.github/workflows/quick-test.yml\n@@ -10,6 +10,15 @@ on:\n     - 'release-*'\n \n jobs:\n+  Linux-musl:\n+    runs-on: ubuntu-latest\n+    container: alpine:latest\n+    steps:\n+      - uses: actions/checkout@v2\n+      - name: install dependencies\n+        run: apk add autoconf automake build-base cmake libtool libucontext-dev linux-headers openssl-dev\n+      - name: super-test\n+        run: ./super-test.sh quick\n   Linux:\n     runs-on: ubuntu-latest\n     strategy:\ndiff --git a/c++/CMakeLists.txt b/c++/CMakeLists.txt\nindex e7627b4c74..14b813fad8 100644\n--- a/c++/CMakeLists.txt\n+++ b/c++/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-cmake_minimum_required(VERSION 3.4)\n+cmake_minimum_required(VERSION 3.6)\n project(\"Cap'n Proto\" CXX)\n set(VERSION 0.10-dev)\n \n@@ -64,6 +64,50 @@ elseif (WITH_OPENSSL)\n   find_package(OpenSSL REQUIRED COMPONENTS Crypto SSL)\n endif()\n \n+set(WITH_FIBERS \"AUTO\" CACHE STRING\n+  \"Whether or not to build libkj-async with fibers\")\n+# define list of values GUI will offer for the variable\n+set_property(CACHE WITH_FIBERS PROPERTY STRINGS AUTO ON OFF)\n+\n+# CapnProtoConfig.cmake.in needs this variable.\n+set(_WITH_LIBUCONTEXT OFF)\n+\n+if (WITH_FIBERS OR WITH_FIBERS STREQUAL \"AUTO\")\n+  set(_capnp_fibers_found OFF)\n+  if (WIN32 OR CYGWIN)\n+    set(_capnp_fibers_found ON)\n+  else()\n+    # Fibers need makecontext, setcontext, getcontext, swapcontext that may be in libc,\n+    # or in libucontext (e.g. for musl).\n+    # We assume that makecontext implies that the others are present.\n+    include(CheckLibraryExists)\n+    check_library_exists(c makecontext \"\" HAVE_UCONTEXT_LIBC)\n+    if (HAVE_UCONTEXT_LIBC)\n+      set(_capnp_fibers_found ON)\n+    else()\n+      # Try with libucontext\n+      find_package(PkgConfig)\n+      if (PKG_CONFIG_FOUND)\n+        pkg_check_modules(libucontext IMPORTED_TARGET libucontext)\n+        if (libucontext_FOUND)\n+          set(_WITH_LIBUCONTEXT ON)\n+          set(_capnp_fibers_found ON)\n+        endif()\n+      else()\n+        set(_capnp_fibers_found OFF)\n+      endif()\n+    endif()\n+  endif()\n+\n+  if (_capnp_fibers_found)\n+    set(WITH_FIBERS ON)\n+  elseif(WITH_FIBERS STREQUAL \"AUTO\")\n+    set(WITH_FIBERS OFF)\n+  else()\n+    message(FATAL_ERROR \"Missing 'makecontext', 'getcontext', 'setcontext' or 'swapcontext' symbol in libc and no libucontext found: KJ won't be able to build with fibers. Disable fibers (-DWITH_FIBERS=OFF).\")\n+  endif()\n+endif()\n+\n if(MSVC)\n   # TODO(cleanup): Enable higher warning level in MSVC, but make sure to test\n   #   build with that warning level and clean out false positives.\ndiff --git a/c++/cmake/CapnProtoConfig.cmake.in b/c++/cmake/CapnProtoConfig.cmake.in\nindex 667f502fb5..0580b11a9f 100644\n--- a/c++/cmake/CapnProtoConfig.cmake.in\n+++ b/c++/cmake/CapnProtoConfig.cmake.in\n@@ -62,6 +62,38 @@ if (@WITH_OPENSSL@)  # WITH_OPENSSL\n   endif()\n endif()\n \n+if (@_WITH_LIBUCONTEXT@) # _WITH_LIBUCONTEXT\n+  set(forwarded_config_flags)\n+  if(CapnProto_FIND_QUIETLY)\n+    list(APPEND forwarded_config_flags QUIET)\n+  endif()\n+  if(CapnProto_FIND_REQUIRED)\n+    list(APPEND forwarded_config_flags REQUIRED)\n+  endif()\n+  # If the consuming project called find_package(CapnProto) with the QUIET or REQUIRED flags, forward\n+  # them to calls to find_package(PkgConfig) and pkg_check_modules(). Note that find_dependency()\n+  # would do this for us in the former case, but there is no such forwarding wrapper for\n+  # pkg_check_modules().\n+\n+  find_package(PkgConfig ${forwarded_config_flags})\n+  if(NOT ${PkgConfig_FOUND})\n+    # If we're here, the REQUIRED flag must not have been passed, else we would have had a fatal\n+    # error. Nevertheless, a diagnostic for this case is probably nice.\n+    if(NOT CapnProto_FIND_QUIETLY)\n+      message(WARNING \"pkg-config cannot be found\")\n+    endif()\n+    set(CapnProto_FOUND OFF)\n+    return()\n+  endif()\n+\n+  if (CMAKE_VERSION VERSION_LESS 3.6)\n+    # CMake >= 3.6 required due to the use of IMPORTED_TARGET\n+    message(SEND_ERROR \"libucontext support requires CMake >= 3.6.\")\n+  endif()\n+\n+  pkg_check_modules(libucontext IMPORTED_TARGET ${forwarded_config_flags} libucontext)\n+endif()\n+\n include(\"${CMAKE_CURRENT_LIST_DIR}/CapnProtoTargets.cmake\")\n include(\"${CMAKE_CURRENT_LIST_DIR}/CapnProtoMacros.cmake\")\n \ndiff --git a/c++/configure.ac b/c++/configure.ac\nindex 14b22263ac..731ce75c1b 100644\n--- a/c++/configure.ac\n+++ b/c++/configure.ac\n@@ -32,6 +32,11 @@ AC_ARG_WITH([openssl],\n     [build libkj-tls by linking against openssl @<:@default=check@:>@])],\n   [],[with_openssl=check])\n \n+AC_ARG_WITH([fibers],\n+  [AS_HELP_STRING([--with-fibers],\n+    [build libkj-async with fibers @<:@default=check@:>@])],\n+  [],[with_fibers=check])\n+\n AC_ARG_ENABLE([reflection], [\n   AS_HELP_STRING([--disable-reflection], [\n     compile Cap'n Proto in \"lite mode\", in which all reflection APIs (schema.h, dynamic.h, etc.)\n@@ -195,8 +200,46 @@ AS_IF([test \"$with_openssl\" != no], [\n ])\n AM_CONDITIONAL([BUILD_KJ_TLS], [test \"$with_openssl\" != no])\n \n-# CapnProtoConfig.cmake.in needs this variable.\n-AC_SUBST(WITH_OPENSSL, $with_openssl)\n+# Fibers need the symbols getcontext, setcontext, swapcontext and makecontext.\n+# We assume that makecontext implies the rest.\n+AS_IF([test \"$with_fibers\" != no], [\n+  libc_supports_fibers=yes\n+  AC_SEARCH_LIBS([makecontext], [], [], [\n+    libc_supports_fibers=no\n+  ])\n+\n+  AS_IF([test \"$libc_supports_fibers\" = yes], [\n+      with_fibers=yes\n+    ], [\n+    # If getcontext does not exist in libc, try with libucontext\n+    ucontext_supports_fibers=yes\n+    AC_CHECK_LIB(ucontext, [makecontext], [], [\n+      ucontext_supports_fibers=no\n+    ])\n+    AS_IF([test \"$ucontext_supports_fibers\" = yes], [\n+      ASYNC_LIBS=\"$ASYNC_LIBS -lucontext\"\n+      with_fibers=yes\n+    ], [\n+      AS_IF([test \"$with_fibers\" = yes], [\n+        AC_MSG_ERROR([Missing symbols required for fibers (makecontext, setcontext, ...). Disable fibers (--without-fibers) or install libucontext])\n+      ], [\n+        AC_MSG_WARN([could not find required symbols (makecontext, setcontext, ...) -- won't build with fibers])\n+        with_fibers=no\n+      ])\n+    ])\n+  ])\n+])\n+AS_IF([test \"$with_fibers\" = yes], [\n+  CXXFLAGS=\"$CXXFLAGS -DKJ_USE_FIBERS\"\n+], [\n+  CXXFLAGS=\"$CXXFLAGS -DKJ_USE_FIBERS=0\"\n+])\n+\n+# CapnProtoConfig.cmake.in needs these variables,\n+# we force them to NO because we don't need the CMake dependency for them,\n+# the dependencies are provided by the .pc files.\n+AC_SUBST(WITH_OPENSSL, NO)\n+AC_SUBST(_WITH_LIBUCONTEXT, NO)\n \n AM_CONDITIONAL([HAS_FUZZING_ENGINE], [test \"x$LIB_FUZZING_ENGINE\" != \"x\"])\n \ndiff --git a/c++/src/kj/CMakeLists.txt b/c++/src/kj/CMakeLists.txt\nindex 8788a20b22..24e1254941 100644\n--- a/c++/src/kj/CMakeLists.txt\n+++ b/c++/src/kj/CMakeLists.txt\n@@ -137,6 +137,15 @@ if(NOT CAPNP_LITE)\n   add_library(kj-async ${kj-async_sources})\n   add_library(CapnProto::kj-async ALIAS kj-async)\n   target_link_libraries(kj-async PUBLIC kj)\n+  if(WITH_FIBERS)\n+    target_compile_definitions(kj-async PUBLIC KJ_USE_FIBERS)\n+    if(_WITH_LIBUCONTEXT)\n+      target_link_libraries(kj-async PUBLIC PkgConfig::libucontext)\n+    endif()\n+  else()\n+    target_compile_definitions(kj-async PUBLIC KJ_USE_FIBERS=0)\n+  endif()\n+\n   if(UNIX)\n     # external clients of this library need to link to pthreads\n     target_compile_options(kj-async INTERFACE \"-pthread\")\n@@ -182,7 +191,7 @@ if(NOT CAPNP_LITE)\n   add_library(kj-tls ${kj-tls_sources})\n   add_library(CapnProto::kj-tls ALIAS kj-tls)\n   target_link_libraries(kj-tls PUBLIC kj-async)\n-  if (WITH_OPENSSL)\n+  if(WITH_OPENSSL)\n     target_compile_definitions(kj-tls PRIVATE KJ_HAS_OPENSSL)\n     target_link_libraries(kj-tls PRIVATE OpenSSL::SSL OpenSSL::Crypto)\n   endif()\n@@ -270,7 +279,7 @@ if(BUILD_TESTING)\n       compat/tls-test.c++\n     )\n     target_link_libraries(kj-heavy-tests kj-http kj-gzip kj-tls kj-async kj-test kj)\n-    if (WITH_OPENSSL)\n+    if(WITH_OPENSSL)\n       set_property(\n         SOURCE compat/tls-test.c++\n         APPEND PROPERTY COMPILE_DEFINITIONS KJ_HAS_OPENSSL\ndiff --git a/c++/src/kj/async-io-test.c++ b/c++/src/kj/async-io-test.c++\nindex 1b35fabe2f..cf353905fd 100644\n--- a/c++/src/kj/async-io-test.c++\n+++ b/c++/src/kj/async-io-test.c++\n@@ -373,9 +373,17 @@ bool systemSupportsAddress(StringPtr addr, StringPtr service = nullptr) {\n   // Can getaddrinfo() parse this addresses? This is only true if the address family (e.g., ipv6)\n   // is configured on at least one interface. (The loopback interface usually has both ipv4 and\n   // ipv6 configured, but not always.)\n+  struct addrinfo hints;\n+  hints.ai_family = AF_UNSPEC;\n+  hints.ai_socktype = 0;\n+  hints.ai_flags = AI_V4MAPPED | AI_ADDRCONFIG;\n+  hints.ai_protocol = 0;\n+  hints.ai_canonname = nullptr;\n+  hints.ai_addr = nullptr;\n+  hints.ai_next = nullptr;\n   struct addrinfo* list;\n   int status = getaddrinfo(\n-      addr.cStr(), service == nullptr ? nullptr : service.cStr(), nullptr, &list);\n+      addr.cStr(), service == nullptr ? nullptr : service.cStr(), &hints, &list);\n   if (status == 0) {\n     freeaddrinfo(list);\n     return true;\ndiff --git a/c++/src/kj/async-io-unix.c++ b/c++/src/kj/async-io-unix.c++\nindex aa845bcb6e..6b8b093e14 100644\n--- a/c++/src/kj/async-io-unix.c++\n+++ b/c++/src/kj/async-io-unix.c++\n@@ -1208,11 +1208,19 @@ Promise<Array<SocketAddress>> SocketAddress::lookupHost(\n   auto thread = heap<Thread>(kj::mvCapture(params, [outFd,portHint](LookupParams&& params) {\n     FdOutputStream output((AutoCloseFd(outFd)));\n \n+    struct addrinfo hints;\n+    hints.ai_family = AF_UNSPEC;\n+    hints.ai_socktype = 0;\n+    hints.ai_flags = AI_V4MAPPED | AI_ADDRCONFIG;\n+    hints.ai_protocol = 0;\n+    hints.ai_canonname = nullptr;\n+    hints.ai_addr = nullptr;\n+    hints.ai_next = nullptr;\n     struct addrinfo* list;\n     int status = getaddrinfo(\n         params.host == \"*\" ? nullptr : params.host.cStr(),\n         params.service == nullptr ? nullptr : params.service.cStr(),\n-        nullptr, &list);\n+        &hints, &list);\n     if (status == 0) {\n       KJ_DEFER(freeaddrinfo(list));\n \n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **Dependency Detection**: Implement checks to ascertain if `getcontext`, `makecontext` are missing in the base libc before attempting to link against `libucontext`. This ensures consistent behavior on glibc systems.\n\n2. **CMake Changes**: Modify CMake to replicate `find_dependency` behavior. Ensure it correctly forwards `QUIET` and `REQUIRED` flags for CapnProto. Investigate dependencies in `.pc` files (OpenSSL, `KJ_USE_FIBERS`).\n\n3. **CI Failures**: Address potential misconfiguration with IPv6 in CI. Consider disabling UI tests for musl if needed.\n\n4. **AI Flags**: Explicitly set the `hints.ai_flags` to `AI_V4MAPPED | AI_ADDRCONFIG` to ensure consistent DNS lookup behavior across platforms.\n\n5. **Commit Organization**: Separate commits for the `getaddrinfo` fix and fibers build changes for clarity in version history."
      }
    ],
    "codediff_length": 10180
  },
  {
    "index": 123,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/.github/workflows/quick-test.yml b/.github/workflows/quick-test.yml\nindex d4293f4f18..f0d300e984 100644\n--- a/.github/workflows/quick-test.yml\n+++ b/.github/workflows/quick-test.yml\n@@ -45,21 +45,28 @@ jobs:\n         os: ['windows-2016', 'windows-latest']\n         include:\n           - os: windows-2016\n-            target: 'Visual Studio 15 2017'\n           - os: windows-latest\n-            target: 'Visual Studio 16 2019'\n     steps:\n       - uses: actions/checkout@v2\n+      - name: Include $CONDA in $PATH\n+        run: |\n+          echo \"::add-path::$Env:CONDA\\condabin\"\n+      - name: Install dependencies via Conda\n+        run: |\n+          conda update -n base -c defaults -q conda\n+          conda install -n base -c defaults -q ninja openssl zlib\n       - name: Build and test\n         shell: cmd\n         run: |\n+            echo \"Activate conda base environment\"\n+            call activate base\n             echo \"Building Cap'n Proto with ${{ matrix.target }}\"\n-            cmake -Hc++ -Bbuild-output -G \"${{ matrix.target }}\" -DCMAKE_INSTALL_PREFIX=%CD%\\capnproto-c++-install\n-            cmake --build build-output --config debug --target install\n+            cmake -Hc++ -Bbuild-output -G Ninja -DCMAKE_BUILD_TYPE=debug -DCMAKE_PREFIX_PATH=\"%CONDA_PREFIX%\" -DCMAKE_INSTALL_PREFIX=%CD%\\capnproto-c++-install\n+            cmake --build build-output --target install\n \n             echo \"Building Cap'n Proto samples with ${{ matrix.target }}\"\n-            cmake -Hc++/samples -Bbuild-output-samples -G \"${{ matrix.target }}\" -DCMAKE_PREFIX_PATH=%CD%\\capnproto-c++-install\n-            cmake --build build-output-samples --config debug\n+            cmake -Hc++/samples -Bbuild-output-samples -G Ninja -DCMAKE_BUILD_TYPE=debug -DCMAKE_PREFIX_PATH=%CD%\\capnproto-c++-install\n+            cmake --build build-output-samples\n \n             cd build-output\\src\n             ctest -V -C debug\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 1a4b12fd0a..eb40764019 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -1,3 +1,3 @@\n-cmake_minimum_required(VERSION 3.1)\n+cmake_minimum_required(VERSION 3.4)\n project(\"Cap'n Proto Root\" CXX)\n add_subdirectory(c++)\ndiff --git a/c++/CMakeLists.txt b/c++/CMakeLists.txt\nindex d13eec1e93..8d518e4822 100644\n--- a/c++/CMakeLists.txt\n+++ b/c++/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-cmake_minimum_required(VERSION 3.1)\n+cmake_minimum_required(VERSION 3.4)\n project(\"Cap'n Proto\" CXX)\n set(VERSION 0.9-dev)\n \n@@ -41,6 +41,29 @@ else()\n   set(CAPNP_LITE_FLAG)\n endif()\n \n+set(WITH_OPENSSL \"AUTO\" CACHE STRING\n+  \"Whether or not to build libkj-tls by linking against openssl\")\n+# define list of values GUI will offer for the variable\n+set_property(CACHE WITH_OPENSSL PROPERTY STRINGS AUTO ON OFF)\n+\n+# shadow cache variable original value with ON/OFF,\n+# so from now on OpenSSL-specific code just has to check:\n+#     if (WITH_OPENSSL)\n+#         ...\n+#     endif()\n+if (CAPNP_LITE)\n+  set(WITH_OPENSSL OFF)\n+elseif (WITH_OPENSSL STREQUAL \"AUTO\")\n+  find_package(OpenSSL COMPONENTS Crypto SSL)\n+  if (OPENSSL_FOUND)\n+    set(WITH_OPENSSL ON)\n+  else()\n+    set(WITH_OPENSSL OFF)\n+  endif()\n+elseif (WITH_OPENSSL)\n+  find_package(OpenSSL REQUIRED COMPONENTS Crypto SSL)\n+endif()\n+\n if(MSVC)\n   # TODO(cleanup): Enable higher warning level in MSVC, but make sure to test\n   #   build with that warning level and clean out false positives.\n@@ -134,8 +157,10 @@ if(NOT MSVC)  # Don't install pkg-config files when building with MSVC\n   if(NOT CAPNP_LITE)\n     list(APPEND CAPNP_PKG_CONFIG_FILES\n       pkgconfig/kj-async.pc\n+      pkgconfig/kj-gzip.pc\n       pkgconfig/kj-http.pc\n       pkgconfig/kj-test.pc\n+      pkgconfig/kj-tls.pc\n       pkgconfig/capnp-rpc.pc\n       pkgconfig/capnp-json.pc\n     )\ndiff --git a/c++/cmake/CapnProtoConfig.cmake.in b/c++/cmake/CapnProtoConfig.cmake.in\nindex 0169e7cbe3..667f502fb5 100644\n--- a/c++/cmake/CapnProtoConfig.cmake.in\n+++ b/c++/cmake/CapnProtoConfig.cmake.in\n@@ -49,7 +49,18 @@ if(NOT _IMPORT_PREFIX)\n   set(_IMPORT_PREFIX ${PACKAGE_PREFIX_DIR})\n endif()\n \n-\n+if (@WITH_OPENSSL@)  # WITH_OPENSSL\n+  include(CMakeFindDependencyMacro)\n+  if (CMAKE_VERSION VERSION_LESS 3.9)\n+    # find_dependency() did not support COMPONENTS until CMake 3.9\n+    #\n+    # in practice, this call can be erroneous\n+    # if the user has only libcrypto installed, but not libssl\n+    find_dependency(OpenSSL)\n+  else()\n+    find_dependency(OpenSSL COMPONENTS Crypto SSL)\n+  endif()\n+endif()\n \n include(\"${CMAKE_CURRENT_LIST_DIR}/CapnProtoTargets.cmake\")\n include(\"${CMAKE_CURRENT_LIST_DIR}/CapnProtoMacros.cmake\")\ndiff --git a/c++/configure.ac b/c++/configure.ac\nindex 238c26dcbc..098b6f410a 100644\n--- a/c++/configure.ac\n+++ b/c++/configure.ac\n@@ -193,5 +193,8 @@ AS_IF([test \"$with_openssl\" != no], [\n ])\n AM_CONDITIONAL([BUILD_KJ_TLS], [test \"$with_openssl\" != no])\n \n+# CapnProtoConfig.cmake.in needs this variable.\n+AC_SUBST(WITH_OPENSSL, $with_openssl)\n+\n AC_CONFIG_FILES([Makefile] CAPNP_PKG_CONFIG_FILES CAPNP_CMAKE_CONFIG_FILES)\n AC_OUTPUT\ndiff --git a/c++/src/capnp/CMakeLists.txt b/c++/src/capnp/CMakeLists.txt\nindex deb4becf9e..2969c28f63 100644\n--- a/c++/src/capnp/CMakeLists.txt\n+++ b/c++/src/capnp/CMakeLists.txt\n@@ -29,7 +29,6 @@ endif()\n set(capnp_headers\n   c++.capnp.h\n   common.h\n-  compat/std-iterator.h\n   blob.h\n   endian.h\n   layout.h\n@@ -55,6 +54,9 @@ set(capnp_headers\n   generated-header-support.h\n   raw-schema.h\n )\n+set(capnp_compat_headers\n+  compat/std-iterator.h\n+)\n set(capnp_schemas\n   c++.capnp\n   schema.capnp\n@@ -72,6 +74,7 @@ target_include_directories(capnp INTERFACE\n set_target_properties(capnp PROPERTIES VERSION ${VERSION})\n install(TARGETS capnp ${INSTALL_TARGETS_DEFAULT_ARGS})\n install(FILES ${capnp_headers} ${capnp_schemas} DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/capnp\")\n+install(FILES ${capnp_compat_headers} DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/capnp/compat\")\n \n set(capnp-rpc_sources\n   serialize-async.c++\ndiff --git a/c++/src/kj/CMakeLists.txt b/c++/src/kj/CMakeLists.txt\nindex 110b0aa4a5..795ea11b10 100644\n--- a/c++/src/kj/CMakeLists.txt\n+++ b/c++/src/kj/CMakeLists.txt\n@@ -163,6 +163,29 @@ if(NOT CAPNP_LITE)\n   install(FILES ${kj-http_headers} DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/kj/compat\")\n endif()\n \n+# kj-tls ======================================================================\n+set(kj-tls_sources\n+  compat/readiness-io.c++\n+  compat/tls.c++\n+)\n+set(kj-tls_headers\n+  compat/readiness-io.h\n+  compat/tls.h\n+)\n+if(NOT CAPNP_LITE)\n+  add_library(kj-tls ${kj-tls_sources})\n+  add_library(CapnProto::kj-tls ALIAS kj-tls)\n+  target_link_libraries(kj-tls PUBLIC kj-async)\n+  if (WITH_OPENSSL)\n+    target_compile_definitions(kj-tls PRIVATE KJ_HAS_OPENSSL)\n+    target_link_libraries(kj-tls PRIVATE OpenSSL::SSL OpenSSL::Crypto)\n+  endif()\n+  # Ensure the library has a version set to match autotools build\n+  set_target_properties(kj-tls PROPERTIES VERSION ${VERSION})\n+  install(TARGETS kj-tls ${INSTALL_TARGETS_DEFAULT_ARGS})\n+  install(FILES ${kj-tls_headers} DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/kj/compat\")\n+endif()\n+\n # kj-gzip ======================================================================\n \n set(kj-gzip_sources\n@@ -236,8 +259,15 @@ if(BUILD_TESTING)\n       compat/url-test.c++\n       compat/http-test.c++\n       compat/gzip-test.c++\n+      compat/tls-test.c++\n     )\n-    target_link_libraries(kj-heavy-tests kj-http kj-gzip kj-async kj-test kj)\n+    target_link_libraries(kj-heavy-tests kj-http kj-gzip kj-tls kj-async kj-test kj)\n+    if (WITH_OPENSSL)\n+      set_source_files_properties(compat/tls-test.c++\n+        PROPERTIES\n+          COMPILE_DEFINITIONS KJ_HAS_OPENSSL\n+      )\n+    endif()\n     add_dependencies(check kj-heavy-tests)\n     add_test(NAME kj-heavy-tests-run COMMAND kj-heavy-tests)\n   endif()  # NOT CAPNP_LITE\ndiff --git a/c++/src/kj/compat/tls-test.c++ b/c++/src/kj/compat/tls-test.c++\nindex d9acd8a1ec..d247847223 100644\n--- a/c++/src/kj/compat/tls-test.c++\n+++ b/c++/src/kj/compat/tls-test.c++\n@@ -27,6 +27,14 @@\n #include <stdlib.h>\n #include <openssl/opensslv.h>\n \n+#if _WIN32\n+#define WIN32_LEAN_AND_MEAN\n+#include <winsock2.h>\n+#include <kj/windows-sanity.h>\n+#else\n+#include <sys/socket.h>\n+#endif\n+\n namespace kj {\n namespace {\n \n@@ -437,6 +445,16 @@ KJ_TEST(\"TLS full duplex\") {\n \n   auto pipe = test.io.provider->newTwoWayPipe();\n \n+#if _WIN32\n+  // On Windows we observe that `writeUp`, below, completes before the other end has started\n+  // reading, failing the `!writeUp.poll()` expectation. I guess Windows has big buffers. We can\n+  // fix this by requesting small buffers here. (Worth keeping in mind that Windows doesn't have\n+  // socketpairs, so `newTwoWayPipe()` is implemented in terms of loopback TCP, ugh.)\n+  uint small = 256;\n+  pipe.ends[0]->setsockopt(SOL_SOCKET, SO_SNDBUF, &small, sizeof(small));\n+  pipe.ends[0]->setsockopt(SOL_SOCKET, SO_RCVBUF, &small, sizeof(small));\n+#endif\n+\n   auto clientPromise = e.wrap(test.tlsClient.wrapClient(kj::mv(pipe.ends[0]), \"example.com\"));\n   auto serverPromise = e.wrap(test.tlsServer.wrapServer(kj::mv(pipe.ends[1])));\n \ndiff --git a/c++/src/kj/compat/tls.c++ b/c++/src/kj/compat/tls.c++\nindex 281f1a4e71..d4ead92085 100644\n--- a/c++/src/kj/compat/tls.c++\n+++ b/c++/src/kj/compat/tls.c++\n@@ -276,7 +276,7 @@ private:\n   kj::Promise<size_t> sslCall(Func&& func) {\n     if (disconnected) return size_t(0);\n \n-    ssize_t result = func();\n+    auto result = func();\n \n     if (result > 0) {\n       return result;\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "1. **MSVC Build Issues**: Resolve the build failure due to MSVC not finding OpenSSL and Zlib. Investigate using vcpkg or the SLProWeb build for OpenSSL as potential solutions.\n\n2. **Path Configuration**: Adjust system PATH to include directories where OpenSSL and Zlib are installed, as CMake searches these paths.\n\n3. **Build Recommendation**: Switch to Ninja for building; it resolved x86/x64 linking issues and improved log readability. \n\n4. **Data Type Fix**: Change `ssize_t` to `int` or `auto` for compatibility, as MSVC does not support `ssize_t`.\n\n5. **Configuration**: Use `cmake -A x64` to target the correct architecture, avoiding default Win32 build issues.\n\nConsider cherry-picking commit `629f691` to resolve the tls-test on Windows."
      }
    ],
    "codediff_length": 9471
  },
  {
    "index": 124,
    "prompt": [
      {
        "role": "user",
        "content": "diff --git a/c++/src/capnp/c++.capnp b/c++/src/capnp/c++.capnp\nindex 2bda547179..17db0eedc2 100644\n--- a/c++/src/capnp/c++.capnp\n+++ b/c++/src/capnp/c++.capnp\n@@ -24,3 +24,13 @@ $namespace(\"capnp::annotations\");\n \n annotation namespace(file): Text;\n annotation name(field, enumerant, struct, enum, interface, method, param, group, union): Text;\n+\n+annotation omitSchemas(file): Void;\n+# Requests that the generated code does not embed the types' schemas.\n+# This means you will not be able to use <capnp/schema.h> or <capnp/dynamic.h> APIs with this type.\n+# By extension, that means you will not be able to stringify messages nor use the JSON codec.\n+# However, the generated code will be somewhat smaller and will not include easily-extractable\n+# type information, which may be important in some use cases.\n+#\n+# All files that import your file will also be required to set this option if they are used to\n+# generate C++ code.\ndiff --git a/c++/src/capnp/c++.capnp.c++ b/c++/src/capnp/c++.capnp.c++\nindex 576d733b23..46d0577937 100644\n--- a/c++/src/capnp/c++.capnp.c++\n+++ b/c++/src/capnp/c++.capnp.c++\n@@ -64,5 +64,35 @@ const ::capnp::_::RawSchema s_f264a779fef191ce = {\n   0, 0, nullptr, nullptr, nullptr, { &s_f264a779fef191ce, nullptr, nullptr, 0, 0, nullptr }\n };\n #endif  // !CAPNP_LITE\n+static const ::capnp::_::AlignedData<21> b_e17e871ab8a5deab = {\n+  {   0,   0,   0,   0,   5,   0,   6,   0,\n+    171, 222, 165, 184,  26, 135, 126, 225,\n+     16,   0,   0,   0,   5,   0,   1,   0,\n+    129,  78,  48, 184, 123, 125, 248, 189,\n+      0,   0,   0,   0,   0,   0,   0,   0,\n+      0,   0,   0,   0,   0,   0,   0,   0,\n+     21,   0,   0,   0, 226,   0,   0,   0,\n+     33,   0,   0,   0,   7,   0,   0,   0,\n+      0,   0,   0,   0,   0,   0,   0,   0,\n+     28,   0,   0,   0,   3,   0,   1,   0,\n+      0,   0,   0,   0,   0,   0,   0,   0,\n+      0,   0,   0,   0,   0,   0,   0,   0,\n+     99,  97, 112, 110, 112,  47,  99,  43,\n+     43,  46,  99,  97, 112, 110, 112,  58,\n+    111, 109, 105, 116,  83,  99, 104, 101,\n+    109,  97, 115,   0,   0,   0,   0,   0,\n+      0,   0,   0,   0,   1,   0,   1,   0,\n+      0,   0,   0,   0,   0,   0,   0,   0,\n+      0,   0,   0,   0,   0,   0,   0,   0,\n+      0,   0,   0,   0,   0,   0,   0,   0,\n+      0,   0,   0,   0,   0,   0,   0,   0, }\n+};\n+::capnp::word const* const bp_e17e871ab8a5deab = b_e17e871ab8a5deab.words;\n+#if !CAPNP_LITE\n+const ::capnp::_::RawSchema s_e17e871ab8a5deab = {\n+  0xe17e871ab8a5deab, b_e17e871ab8a5deab.words, 21, nullptr, nullptr,\n+  0, 0, nullptr, nullptr, nullptr, { &s_e17e871ab8a5deab, nullptr, nullptr, 0, 0, nullptr }\n+};\n+#endif  // !CAPNP_LITE\n }  // namespace schemas\n }  // namespace capnp\ndiff --git a/c++/src/capnp/c++.capnp.h b/c++/src/capnp/c++.capnp.h\nindex 3cdd2a0f89..fa8ad02e7a 100644\n--- a/c++/src/capnp/c++.capnp.h\n+++ b/c++/src/capnp/c++.capnp.h\n@@ -18,6 +18,7 @@ namespace schemas {\n \n CAPNP_DECLARE_SCHEMA(b9c6f99ebf805f2c);\n CAPNP_DECLARE_SCHEMA(f264a779fef191ce);\n+CAPNP_DECLARE_SCHEMA(e17e871ab8a5deab);\n \n }  // namespace schemas\n }  // namespace capnp\ndiff --git a/c++/src/capnp/compiler/capnpc-c++.c++ b/c++/src/capnp/compiler/capnpc-c++.c++\nindex 305bf89273..09c13e0d8b 100644\n--- a/c++/src/capnp/compiler/capnpc-c++.c++\n+++ b/c++/src/capnp/compiler/capnpc-c++.c++\n@@ -64,6 +64,7 @@ namespace {\n \n static constexpr uint64_t NAMESPACE_ANNOTATION_ID = 0xb9c6f99ebf805f2cull;\n static constexpr uint64_t NAME_ANNOTATION_ID = 0xf264a779fef191ceull;\n+static constexpr uint64_t OMIT_SCHEMAS_ANNOTATION_ID = 0xe17e871ab8a5deabull;\n \n bool hasDiscriminantValue(const schema::Field::Reader& reader) {\n   return reader.getDiscriminantValue() != schema::Field::NO_DISCRIMINANT;\n@@ -2985,6 +2986,14 @@ private:\n \n     kj::Vector<kj::ArrayPtr<const char>> namespaceParts;\n     kj::String namespacePrefix;\n+    bool omitSchemas = false;\n+\n+    for (auto annotation : node.getAnnotations()) {\n+      if (annotation.getId() == OMIT_SCHEMAS_ANNOTATION_ID) {\n+        omitSchemas = true;\n+        break;\n+      }\n+    }\n \n     for (auto annotation: node.getAnnotations()) {\n       if (annotation.getId() == NAMESPACE_ANNOTATION_ID) {\n@@ -3085,7 +3094,8 @@ private:\n           \"\\n\"\n           \"namespace capnp {\\n\"\n           \"namespace schemas {\\n\",\n-          KJ_MAP(n, nodeTexts) { return kj::mv(n.capnpSchemaDefs); },\n+          omitSchemas ? kj::Array<kj::StringTree>() : KJ_MAP(n, nodeTexts) { return kj::mv(n.capnpSchemaDefs); },\n+          omitSchemas ? \"// Schemas omitted due to $Cxx.omitSchemas\\n\" : \"\",\n           \"}  // namespace schemas\\n\"\n           \"}  // namespace capnp\\n\",\n           sourceDefs.size() == 0 ? kj::strTree() : kj::strTree(\ndiff --git a/c++/src/capnp/test-import2.capnp b/c++/src/capnp/test-import2.capnp\nindex 23eb6003c5..eff6500373 100644\n--- a/c++/src/capnp/test-import2.capnp\n+++ b/c++/src/capnp/test-import2.capnp\n@@ -21,12 +21,36 @@\n \n @0xc64a3bf0338a124a;\n \n+using Cxx = import \"/capnp/c++.capnp\";\n using Import1 = import \"/capnp/schema.capnp\";\n using Import2 = import \"test-import.capnp\";\n using Import3 = import \"test.capnp\";\n \n+$Cxx.omitSchemas;\n+\n struct TestImport2 {\n   foo @0 :Import3.TestAllTypes;\n   bar @1 :Import1.Node;\n   baz @2 :Import2.TestImport;\n }\n+\n+interface TestImport2Interface {\n+  testInterfaceMethod @0 () -> (result :Bool);\n+}\n+\n+interface TestImport2ExtendingInterface extends(TestImport2Interface) {\n+  testInterfaceMethodTwo @0 () -> (result :Bool);\n+}\n+\n+enum TestImport2Enum {\n+  zero @0;\n+  one @1;\n+  two @2;\n+  three @3;\n+  four @4;\n+}\n+\n+struct TestImport2Structure {\n+  enumValue @0 :TestImport2Enum;\n+  anInterface @1 :TestImport2ExtendingInterface;\n+}\n"
      }
    ],
    "completion": [
      {
        "role": "assistant",
        "content": "The linker errors indicate missing schema references in `test-import2.capnp.c++o`, likely caused by `CAPNP_DECLARE_SCHEMA` declaring extern values. Suggested workaround: replace schema data with a zero-length array approach, which you've implemented successfully. Validate if this workaround is acceptable before submitting a PR. Consider splitting macros like `CAPNP_DECLARE_STRUCT_HEADER` to separate schema-related declarations, allowing omission when `omitSchemas` is enabled. Verify if removing `encodedSchema()` entirely is safe, as its sole use is in `schemaProto()`, which operates for schema usage only. Proceed with tests accordingly."
      }
    ],
    "codediff_length": 5637
  }
]