[
  {
    "index": 1,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "Note I have only added loading the profile key on the first post block, whilst I check im doing it the correct way.\r\n\r\nI need to add the frontend button next as well.",
    "label": null
  },
  {
    "index": 2,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "plz follow template with bot, once the ai reviewer is back online it'll deny the pr for this",
    "label": null
  },
  {
    "index": 3,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "Thank you for this thorough Ayrshare integration PR! The code looks well-structured with comprehensive implementation across both frontend and backend components.\n\nBefore this PR can be merged, there are a few items that need to be addressed:\n\n1. **Missing Checklist**: Please add the standard PR checklist from our template and check off the relevant items. Since this is a significant code change introducing new functionality, we need to ensure you've tested the implementation thoroughly.\n\n2. **Merge Conflicts**: The PR has the 'conflicts' label, indicating there are merge conflicts that need to be resolved before merging.\n\n3. **PR Title Scope**: Consider updating the PR title to use 'platform/blocks' as the scope instead of just 'block' to better align with our conventional commit format and labeled scopes.\n\n4. **Test Plan**: Please provide a test plan detailing how you've verified this integration works correctly. For example:\n   - Connecting to different social media platforms via Ayrshare\n   - Posting content to each supported platform\n   - Handling error cases (e.g., when profile key is missing)\n\nThe implementation itself looks solid, with proper security considerations and a clean architecture. Once the above items are addressed, this PR should be ready for final review.",
    "label": null
  },
  {
    "index": 4,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "‚ùå **Preview Environment Deployment Failed**\n\nüö® The preview environment deployment encountered critical errors and has been rolled back.\n\n**Cleanup Completed:**\n- ‚ò∏Ô∏è Kubernetes namespace deleted\n- üóÉÔ∏è Database schema dropped\n- üîå All services terminated\n\n*Please check the workflow logs for details and try again.*",
    "label": null
  },
  {
    "index": 5,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "Thanks for this comprehensive PR adding Ayrshare integration for social media posting! The implementation looks solid with good support across multiple platforms.\n\nI've reviewed your changes and have a couple of items that need addressing before this can be merged:\n\n1. **PR Title Format**: The scope in your title should be `blocks` instead of `block` to match our conventional commit format standards. Please update to: `feat(blocks): Added Ayrshare integration for social media posting`\n\n2. **Missing Checklist**: Your PR description is very detailed, which is great, but it's missing the required checklist section. Please add the standard PR checklist that includes items like:\n   - Confirming you've tested your changes\n   - Your test plan\n   - Any configuration changes\n\nThe code implementation itself looks well-structured with comprehensive support for various social media platforms. I particularly like how you've organized the different posting blocks with platform-specific options and validations.\n\nOnce you've addressed these two items, this PR should be ready for another review.",
    "label": null
  },
  {
    "index": 6,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "Thanks for the comprehensive Ayrshare integration PR! The implementation looks well-designed and thoroughly documented.\n\n### What Looks Good\n- Great PR description with detailed explanations of all components\n- Clean implementation of both backend and frontend components\n- Good separation of concerns with platform-specific posting blocks\n- Environment variables correctly added to `.env.example`\n- Proper handling of user_id in credential store operations\n- The new AYRSHARE block type is added in the correct alphabetical location\n\n### What Needs Addressing\n- **Missing checklist**: Please add the required checklist to the PR description. As this is a code change, we need a complete checklist including a test plan to verify the functionality works correctly.\n\n### Testing Considerations\nSince this is a complex integration, please ensure your test plan includes:\n- Creating and connecting to Ayrshare accounts\n- Posting to various social media platforms\n- Handling error cases (e.g., invalid credentials, failed posts)\n- Verifying the SSO flow works correctly\n\nOnce you've added the checklist with a proper test plan, this PR should be ready for final review.",
    "label": null
  },
  {
    "index": 7,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "Waiting on preview envs to be fixed before this can be comprehensively tested. \r\nAlso there is difficulty testing all platforms as I don't have all the different social account.",
    "label": null
  },
  {
    "index": 8,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "‚úÖ **Preview Environment Deployed Successfully**\n\nüìä **Deployment Summary**\n| Service | Status |\n|---------|--------|\n| Redis | ‚úÖ Success |\n| RabbitMQ | ‚úÖ Success |\n| Backend Server | ‚úÖ Success |\n| WebSocket Server | ‚úÖ Success |\n| Scheduler Server | ‚úÖ Success |\n| Frontend Builder | ‚úÖ Success |\n\nüîî Please check Discord for the preview environment URLs and details.\n\n*The deployment status and URLs will be posted in the AutoGPT Discord server.*",
    "label": null
  },
  {
    "index": 9,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "![Screenshot 2025-06-16 at 11 57 40](https://github.com/user-attachments/assets/3bba19c2-4983-47e8-88f5-9f5a6c6da32f)\r\n![Screenshot 2025-06-16 at 11 55 17](https://github.com/user-attachments/assets/55e3e80c-8106-4b36-8a15-11f86536ac2e)\r\n\r\nI've tested linkedin and twitter both work. The others need testing",
    "label": null
  },
  {
    "index": 10,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "‚úÖ **Preview Environment Deployed Successfully**\n\nüìä **Deployment Summary**\n| Service | Status |\n|---------|--------|\n| Redis | ‚úÖ Success |\n| RabbitMQ | ‚úÖ Success |\n| Backend Server | ‚úÖ Success |\n| WebSocket Server | ‚úÖ Success |\n| Scheduler Server | ‚úÖ Success |\n| Frontend Builder | ‚úÖ Success |\n\nüîî Please check Discord for the preview environment URLs and details.\n\n*The deployment status and URLs will be posted in the AutoGPT Discord server.*",
    "label": null
  },
  {
    "index": 11,
    "pr title": "feat(block): Add Ayrshare integration for social media posting",
    "comment": "‚úÖ **Preview Environment Deployed Successfully**\n\nüìä **Deployment Summary**\n| Service | Status |\n|---------|--------|\n| Redis | ‚úÖ Success |\n| RabbitMQ | ‚úÖ Success |\n| Backend Server | ‚úÖ Success |\n| WebSocket Server | ‚úÖ Success |\n| Scheduler Server | ‚úÖ Success |\n| Frontend Builder | ‚úÖ Success |\n\nüîî Please check Discord for the preview environment URLs and details.\n\n*The deployment status and URLs will be posted in the AutoGPT Discord server.*",
    "label": null
  },
  {
    "index": 12,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "The PR fails to meet some basic requirements but shows a good effort. Issues:\n1. The PR template is not properly filled out - missing test plan and checklist items\n2. While the scope is clear (frontend) and shown in the title correctly, documentation of changes could be clearer\n3. No clear explanation in PR body about 'why' these changes were needed\n4. No test plan or testing notes provided for such a large UI change\n\nHowever, the code itself looks well-structured with clear component organization and documentation. The TODO comments also show good forward planning.",
    "label": null
  },
  {
    "index": 13,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "## Feedback for PR Improvement\n\n### Missing PR Template & Checklist\nPlease fill out the complete PR template, including the checklist section. This is required for all PRs and helps reviewers understand what's being changed and how it's been tested.\n\n### Scope Mismatch\nYour PR title mentions only frontend changes (`feat(frontend)`), but the diff shows significant backend additions including:\n- New API routes in `/api/builder/`\n- New DB functions and models\n- Changes to store routes\n\nPlease update your title to reflect both frontend and backend changes, or better explain in the description why backend changes were needed for this frontend redesign.\n\n### User ID Validation\nSome of the new backend functions in `backend/server/v2/builder/db.py` don't appear to validate user permissions via user_id. Please review these functions to ensure proper authorization is in place or provide an explanation for why user_id checks aren't needed.\n\n### Merge Conflicts\nThis PR has merge conflicts that need to be resolved before it can be merged.\n\n### Testing\nPlease include information about how you've tested these changes, particularly since they span both frontend and backend components.\n\nOnce you've addressed these issues, the PR should be ready for re-review.",
    "label": null
  },
  {
    "index": 14,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your work on redesigning the block menu. This looks like a substantial change that will improve the builder page experience. \n\nHowever, there are a few things that need to be addressed before this PR can be merged:\n\n1. **Missing checklist**: Please complete the PR template checklist. For code changes like these, we need to know that you've tested your changes with a clear test plan.\n\n2. **Scope discrepancy**: Your PR title mentions only frontend changes, but the diff includes significant backend changes - new routes, endpoints, and database access functions. Please update your PR title to reflect that this is both a frontend and backend feature, perhaps something like `feat(frontend,backend): Redesign block menu on builder page`.\n\n3. **Implementation details**: Your PR description lists the components you've added but doesn't explain how they work together or what specific improvements they bring. Please enhance the description with more details about the implementation and how it improves upon the previous design.\n\n4. **Test plan**: Please add a test plan to your PR description explaining how you've tested these changes.\n\nThe code itself looks well-structured with proper authentication handling and user_id checks. I particularly like how you've organized the new components and the backend routes to support them. Once you address the above points, this PR should be ready for another review.",
    "label": null
  },
  {
    "index": 15,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your work on redesigning the block menu! I have a few comments before this can be merged:\n\n## Description and Checklist\n- Please update your PR description to include a more detailed explanation of the changes you've made\n- The required PR checklist is missing. Please add the checklist from the PR template and check off the appropriate items\n\n## Scope Mismatch\nYour PR title indicates this is a frontend feature (`feat(frontend)`), but the changes include substantial backend code, including:\n- New backend routes in `/api/builder`\n- New database functions in `backend/server/v2/builder/db.py`\n- New models in `backend/server/v2/builder/model.py`\n\nConsider updating your PR title to reflect that this involves both frontend and backend changes, perhaps something like `feat(platform): Redesign block menu on builder page with backend support`\n\n## Test Plan\nPlease include a test plan in your PR description to explain how you've tested these changes.\n\nOnce these items are addressed, we can proceed with reviewing the technical aspects of the implementation. The component list and structure looks well-organized!",
    "label": null
  },
  {
    "index": 16,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your work on redesigning the block menu! I have a few concerns about this PR that need to be addressed before it can be merged:\n\n1. **PR Description:** While you've listed the components you've added, the PR description should explain why these changes are needed and provide more context about the redesign goals.\n\n2. **Missing Checklist:** Your PR description is missing the required checklist section that outlines your test plan and confirms you've tested the changes appropriately. Please update your PR description to include the complete checklist.\n\n3. **Scope Mismatch:** The PR title indicates this is a frontend change, but the diff shows substantial backend changes including:\n   - New backend routes in `/api/builder`\n   - New database functions and models\n   - Changes to the store API\n\n   Please update either the PR title to reflect the full scope of changes (e.g., `feat(frontend,backend): Redesign block menu and add builder API endpoints`) or separate the backend changes into a different PR.\n\n4. **Dependencies:** You've added several new dependencies (`react-timeago`, `tailwind-scrollbar`, `tailwind-scrollbar-hide`). Please ensure these are necessary and document their purpose in the PR description.\n\n5. **Testing:** Please describe how you've tested these changes, especially the new backend routes and functionality.\n\nAdditionally, I see there's a conflicts label on this PR. Please resolve any merge conflicts before this can be approved.\n\nOnce you've addressed these issues, I'll be happy to review the PR again.",
    "label": null
  },
  {
    "index": 17,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your PR to redesign the block menu! The component list you provided is helpful for understanding what's been added. I have some feedback to help get this PR ready for merging:\n\n1. **Missing checklist**: This PR contains significant code changes but is missing the required checklist. Please add the checklist from the PR template and ensure you've tested all changes appropriately.\n\n2. **Scope mismatch**: While your title mentions frontend changes, a significant portion of this PR adds backend functionality (new routes, models, and database operations for the builder). Please update your PR title to reflect both frontend and backend changes, e.g., `feat(frontend,backend): Redesign block menu and add builder API endpoints`.\n\n3. **PR description improvements**: Consider expanding your description to mention the backend API endpoints you've added to support the block menu functionality.\n\nOnce you've addressed these items, we'll be able to review your PR again. The code changes themselves look good - I like the organized approach with the reusable components and the proper handling of user_id in the backend routes.",
    "label": null
  },
  {
    "index": 18,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thanks for the PR to redesign the block menu! The implementation looks comprehensive with both frontend components and backend support.\n\n### Feedback\n\n1. **PR Description Improvements**:\n   - The PR description is missing the required checklist from the template. Please add the checklist sections for code changes and make sure all items are checked off.\n   - While you've described the frontend components well, please also mention the significant backend changes (new API routes in `/api/builder`, pagination model extensions, etc.) that support this feature.\n\n2. **Implementation Notes**:\n   - The changes include backend routes and models to support the block menu functionality, which is good but should be mentioned in the PR description.\n   - I notice you've added several new npm packages (`react-timeago`, `tailwind-scrollbar`, etc.) - please include these in your description of changes.\n\n3. **Code Quality**:\n   - The backend implementation looks solid with well-structured endpoints and models.\n   - Good job on the TODO markers for future work.\n\nPlease update the PR description to include the missing checklist and mention the backend changes that support this feature. Once these items are addressed, the PR will be ready for another review.",
    "label": null
  },
  {
    "index": 19,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your PR to redesign the block menu! I've identified a few issues that need to be addressed before this can be merged:\n\n1. **Scope mismatch**: While your PR title indicates this is a frontend change, approximately half of the changes are backend-related (new API endpoints, models, database functions). The PR title and description should accurately reflect all major components being changed.\n\n2. **Missing checklist**: For substantial code changes like this, the PR template checklist needs to be completed to ensure proper testing and quality checks. Please add the checklist and check off the appropriate items.\n\n3. **Backend changes documentation**: The PR description doesn't mention any of the backend changes. Please update the description to include details about the new backend/server/v2/builder files and endpoints you're adding.\n\nAdditionally, I notice you've marked some items with \"BLOCK MENU TODO:\" for future work. If these are part of this redesign effort but will be addressed in separate PRs, that's fine, but please make that clear in the description.\n\nOnce you've updated the PR title to accurately reflect both frontend and backend changes, completed the required checklist, and expanded the description to cover all major components being changed, we can proceed with the review process.",
    "label": null
  },
  {
    "index": 20,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thanks for your PR on redesigning the block menu. I noticed a few things that need to be addressed before this can be merged:\n\n1. **Missing Checklist**: Please include the complete PR checklist in your description. Since your changes include significant code modifications, you'll need to add the checklist with appropriate test plans.\n\n2. **Scope Mismatch**: Your PR title only mentions frontend changes (`feat(frontend)`), but the diff shows substantial backend additions including:\n   - New API routes in `/api/builder`\n   - New database functionality\n   - New models and response types\n\n   Please update your PR title to reflect both the frontend and backend changes, perhaps something like `feat(frontend,backend): Redesign block menu on builder page`.\n\n3. **PR Description**: Consider enhancing your description to explain more about the purpose of the backend changes and how they relate to the frontend block menu redesign.\n\nThe changes themselves look promising, but we need to ensure the PR follows our submission guidelines before proceeding with the review of the actual implementation. Please make these updates so we can move forward with the review.",
    "label": null
  },
  {
    "index": 21,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your work on redesigning the block menu! I have a few concerns that need to be addressed before this PR can be merged:\n\n1. **Missing Checklist**: The PR description is missing the required checklist. Please update your description to include the standard checklist and fill it out completely.\n\n2. **Scope Mismatch**: The PR title mentions only frontend changes (`feat(frontend)`), but the diff shows significant backend changes as well. Please update the PR title to accurately reflect the scope of your changes. Something like `feat(platform): Redesign block menu on builder page` or `feat(platform/frontend,platform/backend): Redesign block menu on builder page` would be more appropriate.\n\n3. **Backend Changes**: The PR includes substantial backend additions:\n   - New builder routes and endpoints\n   - New database functions and models\n   - Changes to the store API\n\nPlease make sure to include these backend changes in your test plan when you add the checklist.\n\nOnce these items are addressed, we can proceed with the review of the code itself. The overall direction of the redesign looks promising!",
    "label": null
  },
  {
    "index": 22,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for working on redesigning the block menu. I see you've created several reusable components for this feature.\n\nI have two main concerns with this PR:\n\n1. **Missing Checklist**: Your PR description is missing the required checklist that should cover testing plan and other verification steps. Please update your description to include the standard checklist and fill it out appropriately.\n\n2. **Scope Mismatch**: Your PR title mentions only a frontend redesign, but the changes include significant backend work. I see new backend files for a builder API, including routes, models, and database functionality. The PR title should reflect both frontend and backend changes, something like: `feat(frontend,backend): Redesign block menu and add builder API`\n\nPlease update your PR to address these issues so we can proceed with the review. The code changes themselves look well-structured, but we need to ensure the PR follows our process requirements.\n\nAlso, I noticed you've marked some items with `BLOCK MENU TODO:` for future work. That's a good approach for tracking remaining tasks.",
    "label": null
  },
  {
    "index": 23,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Hi @Abhi1992002, thanks for your work on redesigning the block menu. I have some feedback to help get this PR ready for merging:\n\n## Required Changes\n\n1. **PR Description & Checklist**\n   - Please include the complete PR checklist from our template, including your test plan\n   - The description should explain both the frontend and backend changes\n\n2. **PR Scope**\n   - Your PR title mentions only frontend changes, but there are significant backend changes\n   - Please update the title to reflect both (e.g., `feat(frontend,backend): Redesign block menu on builder page`)\n\n3. **Backend Testing**\n   - The new API endpoints should have proper testing documentation\n   - Please describe how you've tested the new endpoints\n\n4. **User ID Security**\n   - For the new backend routes, please confirm that user_id checks are properly implemented\n\n## Questions\n\n1. What testing have you done for both the frontend components and backend endpoints?\n2. Are there any configuration changes needed for these new components?\n3. How do the new endpoints interact with the redesigned block menu?\n\nOnce these items are addressed, I'd be happy to re-review the PR. Thanks!",
    "label": null
  },
  {
    "index": 24,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thanks for working on redesigning the block menu for the builder page! This is an important improvement that will enhance the user experience. However, there are a couple of issues that need to be addressed before we can merge this PR:\n\n1. **Missing Checklist**: The PR template requires a filled-out checklist for all code changes. Please update your PR description to include the checklist from the template with all applicable items checked.\n\n2. **Scope Mismatch**: Your PR title indicates this is a frontend change, but the diff contains significant backend changes including:\n   - Adding new backend routes under `/api/builder`\n   - Creating new backend models and database functions\n   - Modifying the store API\n\n   Please either:\n   - Update the PR title to something like `feat(platform): Redesign block menu with backend support` to accurately reflect both frontend and backend changes, or\n   - Split this into separate PRs for frontend and backend changes\n\nAdditionally, while your PR description lists the components you've added, it would be helpful to include a brief explanation of the backend changes as well.\n\nOnce these items are addressed, we can proceed with the review of the implementation details. The component organization looks good, and I appreciate your marking future tasks with the `BLOCK MENU TODO:` tag for easy reference.",
    "label": null
  },
  {
    "index": 25,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thanks for working on the block menu redesign! This PR adds important components and functionality for the builder page.\n\n### Key Issues to Address\n\n1. **Missing Checklist:** Please add the required checklist to your PR description. This is mandatory for code changes and should include details about your test plan.\n\n2. **Scope Clarification:** Your PR title focuses on frontend changes, but includes significant backend changes (new endpoints, models, DB functions). While these backend changes appear necessary to support the frontend redesign, consider either:\n   - Updating the PR title to reflect both frontend and backend changes (e.g., `feat(platform): Redesign block menu on builder page with supporting API`)  \n   - OR splitting the PR into separate frontend and backend PRs if that makes sense\n\n3. **PR Conflicts:** There's a conflicts label on your PR - please resolve these merge conflicts.\n\n### Additional Notes\n\n- The TODO comments you've marked with `BLOCK MENU TODO:` are fine as placeholders for future work.\n- Good job properly implementing auth middleware on the new API routes.\n- Consider adding more details about what the redesigned block menu includes and what improvements it brings.\n\nOnce you've addressed these issues, particularly adding the required checklist, the PR should be ready for another review.",
    "label": null
  },
  {
    "index": 26,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your PR to redesign the block menu! The implementation looks thorough with many new components created for the builder page.\n\nHowever, I've noticed a couple of issues that need to be addressed before this can be merged:\n\n1. **Missing checklist**: The PR description is missing the required checklist from our PR template. Since this is a significant code change, please update your PR description to include a completed checklist with items like:\n   - Confirmation that you've tested your changes\n   - A test plan outlining how you verified your implementation works correctly\n\n2. **Scope mismatch**: Your PR title mentions only frontend changes, but the PR includes substantial backend implementations including:\n   - A new backend/server/v2/builder module with model, db, and routes files\n   - New API endpoints\n   - Modifications to existing store functionality\n\n   Please update your PR title to reflect both frontend and backend changes, perhaps something like: `feat(frontend,backend): Redesign block menu and add builder API endpoints`\n\nOnce these issues are addressed, we can proceed with the review of your implementation. The code itself looks well-structured with appropriate user_id handling in the backend functions.",
    "label": null
  },
  {
    "index": 27,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thanks for your PR on redesigning the block menu! There are a few items that need to be addressed before this can be merged:\n\n## Missing Required Information\n\n1. **Checklist**: Your PR is missing the required checklist section. Since this PR involves significant code changes, we need to ensure all necessary checks have been completed.\n\n2. **Test Plan**: Please include details on how you've tested these changes.\n\n## Scope Clarification\n\nYour PR title mentions frontend redesign, but includes significant backend changes (new API endpoints, models, etc.). While these backend changes appear to support the frontend redesign, it would be helpful to:\n\n- Update your PR title to reflect both frontend and backend changes, e.g., `feat(platform): Redesign block menu with supporting backend APIs`\n- OR clarify in your description how the backend changes are necessary for the frontend redesign\n\n## Documentation\n\nPlease add some brief documentation on the new backend endpoints you've created to help other developers understand their purpose and how they relate to the block menu redesign.\n\nThe code itself looks good - I see you've properly protected all routes with auth middleware and correctly handle user_id passing where needed. Once you've addressed these items, we can proceed with the review.",
    "label": null
  },
  {
    "index": 28,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for working on redesigning the block menu! This is an important improvement for the builder page UI. I've identified a couple of issues that need to be addressed before this PR can be merged:\n\n1. The PR description is missing the required checklist. Please update your description to include the checklist from our template, with all applicable items checked off.\n\n2. The PR title mentions only frontend changes (`feat(frontend)`), but the PR includes significant backend additions (new routes, models, and DB functions in `/backend/server/v2/builder/`). Either:\n   - Update the PR title to reflect both frontend and backend changes (e.g., `feat(platform): Redesign block menu with backend support`)\n   - Or split this into separate PRs for frontend and backend changes\n\nYour implementation looks good overall - I can see you've built reusable components and made sure the backend functions properly handle user_id for authentication. Please address the issues above so we can proceed with the review.\n\nNote: There's also a conflict label on this PR that will need to be resolved before merging.",
    "label": null
  },
  {
    "index": 29,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your PR to redesign the block menu on the builder page! This looks like a substantial piece of work that adds many components and backend support.  \n\nHowever, I've noticed a few issues that need to be addressed before this can be merged:\n\n1. **Missing Checklist**: Your PR is missing the required checklist. Please add the complete checklist from the PR template and check off the items you've completed. Given the scope of your changes, the checklist is necessary to ensure everything has been properly tested.\n\n2. **PR Title/Scope Mismatch**: Your PR title only mentions frontend changes, but there are significant backend changes as well (new API routes, database functions, models). Please update your PR title to reflect both aspects, perhaps something like: `feat(frontend,backend): Redesign block menu on builder page with API support`\n\n3. **Test Plan**: Please provide a test plan detailing how you've verified that both the frontend components and backend API routes work correctly.\n\n4. **PR Description**: Consider expanding your description to briefly explain the purpose of the backend changes and how they support the frontend redesign.\n\nYour component organization looks good, and I appreciate that you've marked future tasks with `BLOCK MENU TODO:`. Once you address these items, we'll be able to move forward with the review process.",
    "label": null
  },
  {
    "index": 30,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thanks for your contribution to redesign the block menu! This is a substantial PR with changes across both frontend and backend.\n\n### Missing Required Checklist\n\nPlease add the standard PR checklist to your description and complete it. This is required for all PRs with material code changes. The checklist helps ensure you've tested your changes appropriately and considered all necessary factors.\n\n### Scope Consideration\n\nYour PR title mentions frontend changes, but there are significant backend changes as well (new API endpoints, database functions, models). Consider either:\n1. Updating the PR title to reflect both frontend and backend changes, or\n2. Splitting this into two PRs if the changes are separable (one for backend support, one for frontend implementation)\n\n### TODOs in Code\n\nYou mentioned \"Some tasks are planned for the near future. I've marked them with `BLOCK MENU TODO:` so they can be found easily.\" Please ensure that these TODOs are addressed before the PR is merged, or create follow-up issues to track them.\n\n### Other Notes\n\n- The new backend endpoints look well-structured with appropriate auth middleware\n- The implementation seems comprehensive with search functionality, filtering, and pagination\n- Good job on adding new dependencies in package.json for the enhanced UI components\n\nPlease update your PR description with the required checklist and consider the scope recommendation.",
    "label": null
  },
  {
    "index": 31,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your PR! I noticed a few issues that need to be addressed before this can be merged:\n\n## Missing Checklist\nYour PR contains significant code changes but doesn't include the required checklist. Please add the standard checklist to your PR description and ensure all items are checked off.\n\n## Scope Mismatch\nYour PR title mentions only frontend changes (`feat(frontend): Redesign block menu on builder page`), but the actual changes include extensive backend work:\n- New backend routes in `/api/builder/`\n- New database functions and models for builder functionality\n- Changes to store and library endpoints\n\nPlease update your PR title to reflect both frontend and backend changes, for example: `feat(frontend,backend): Redesign block menu and add builder API endpoints`\n\n## PR Description Needs Expansion\nPlease provide more details in your PR description:\n- What problem does this redesign solve?\n- What are the key changes in both frontend and backend?\n- How should reviewers test these changes?\n\nThe current description lists small components but doesn't explain the overall architecture or the backend additions.\n\nOnce these issues are addressed, I'll be happy to review this PR again. Let me know if you need any clarification!",
    "label": null
  },
  {
    "index": 32,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thanks for your PR on redesigning the block menu! I have a couple of important issues that need to be addressed before this can be merged:\n\n## Required Changes\n\n1. **Missing Checklist**: The PR template requires a checklist to be completed for code changes. Please update your PR description to include the standard checklist and complete it.\n\n2. **PR Title/Scope Mismatch**: Your PR title indicates this is a frontend change (`feat(frontend)`), but the vast majority of changes are actually backend-related. The PR adds several new backend files (db.py, model.py, routes.py) and modifies existing backend code.\n\n   Please update your PR title to accurately reflect the scope of changes, such as `feat(platform): Redesign block menu with backend support` or similar that reflects both the frontend and backend work.\n\n3. **PR Description**: Consider expanding your PR description to explain why this redesign was needed and how it improves the current implementation. \n\n## Additional Notes\n\n- Your backend code changes look good from a security perspective - the functions properly use user_id for access control.\n- I noticed you've added a TODO comment \"BLOCK MENU TODO:\" for future work. Make sure these are tracked separately if they won't be addressed in this PR.\n- You've added some new dependencies in package.json (tailwind-scrollbar, react-timeago, etc.) - it would be helpful to mention these in the PR description.\n\nPlease update your PR with these changes so we can proceed with the review process. Let me know if you need any clarification!",
    "label": null
  },
  {
    "index": 33,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thanks for your work on redesigning the block menu! I noticed a few issues that need to be addressed before this PR can be merged:\n\n## Description and Scope\n\n- Your PR title indicates only frontend changes, but there are significant backend changes (new API routes, models, etc.). The scope in the title should reflect all areas being modified, such as `feat(platform)` or both frontend and backend.\n- The PR description focuses on frontend components but doesn't mention the backend API work. Please update your description to include details about all changes made.\n\n## Missing Required Checklist\n\n- The PR is missing the required checklist that should be filled out completely. Since this includes substantial code changes, please add the checklist and check off all applicable items.\n- Please include a test plan detailing how you've verified the changes work correctly.\n\n## Suggested Changes\n\n1. Update the PR title to correctly represent the scope of changes (e.g., `feat(platform): Redesign block menu on builder page`)\n2. Expand the PR description to include details about the backend API changes\n3. Add the required checklist template and fill it out completely\n4. Include a test plan that describes how you've tested these changes\n\nOnce these issues are addressed, we can proceed with reviewing the code changes in detail.",
    "label": null
  },
  {
    "index": 34,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your PR to redesign the block menu! I've reviewed your changes and have a few concerns that need to be addressed before this can be merged:\n\n## Missing Checklist\nThe PR description is missing the required checklist for code changes. Please update your description to include the standard checklist that confirms you've tested your changes properly.\n\n## Scope Mismatch\nYour PR title indicates this is a frontend change (`feat(frontend): Redesign block menu on builder page`), but the changes include significant backend additions:\n- New builder API endpoints\n- New database functions\n- New models and data structures\n\nThese backend changes appear to be more than 20% of the total changes, which exceeds our scope guidelines. You have two options:\n\n1. Split this into two PRs: one for frontend and one for backend changes\n2. Update the PR title to reflect both areas (e.g., `feat(frontend,backend): Redesign block menu with supporting API endpoints`)\n\nThe new backend code looks good in terms of security and user_id handling, but we need to ensure the PR accurately represents the work being done.\n\nPlease update your PR accordingly, and let me know if you need any help or clarification!",
    "label": null
  },
  {
    "index": 35,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thanks for the PR to redesign the block menu! The components structure you've listed looks well organized.\n\nI noticed a couple of issues that need to be addressed before this can be merged:\n\n1. **Missing checklist**: The PR template requires a checklist section to be completed for code changes. Please add the checklist from the template and fill it out appropriately, especially including your test plan.\n\n2. **Scope mismatch**: Your PR title indicates this is purely a frontend change (`feat(frontend)`), but the PR contains substantial backend changes including:\n   - New backend API routes in `/api/builder`\n   - New backend models and database methods\n   - Changes to existing backend services\n\nPlease update either:\n   - The PR title to reflect both frontend and backend changes (e.g., `feat(platform): Redesign block menu and add builder API endpoints`)\n   - OR split this into separate PRs for frontend and backend changes\n\nAlso, I notice you've marked some tasks with \"BLOCK MENU TODO\" for future work. It would be helpful to clarify in the PR description which parts are complete in this PR and which parts are planned for future PRs.\n\nLet me know if you need any help with these changes!",
    "label": null
  },
  {
    "index": 36,
    "pr title": "feat(frontend,backend): Redesign block menu on builder page with supporting API",
    "comment": "Thank you for your work on redesigning the block menu for the builder page. However, there are a couple of issues that need to be addressed before this PR can be merged:\n\n1. **Missing Checklist**: Your PR is missing the required checklist section. Please update your PR description to include the standard checklist and fill it out completely. This helps ensure all necessary steps have been completed before merging.\n\n2. **Scope Mismatch**: Your PR title mentions only frontend changes (`feat(frontend): Redesign block menu on builder page`), but the PR includes extensive backend changes as well. I see new backend routes, models, and database functions being added in:\n   - `backend/server/v2/builder/db.py`\n   - `backend/server/v2/builder/model.py`\n   - `backend/server/v2/builder/routes.py`\n   - And modifications to several other backend files\n\nYou have two options to address this:\n   - Update your PR title to reflect both frontend and backend changes, such as `feat(platform): Redesign block menu with supporting backend APIs`\n   - Or split this into separate PRs - one for frontend and one for backend changes\n\nPlease make these adjustments so we can proceed with the review. The changes themselves look valuable, but we need to ensure the PR follows our standards.",
    "label": null
  },
  {
    "index": 37,
    "pr title": "feat(platform): Add Block Development SDK with auto-registration system",
    "comment": "‚úÖ **Preview Environment Deployed Successfully**\n\nüìä **Deployment Summary**\n| Service | Status |\n|---------|--------|\n| Redis | ‚úÖ Success |\n| RabbitMQ | ‚úÖ Success |\n| Backend Server | ‚úÖ Success |\n| WebSocket Server | ‚úÖ Success |\n| Scheduler Server | ‚úÖ Success |\n| Frontend Builder | ‚úÖ Success |\n\nüîî Please check Discord for the preview environment URLs and details.\n\n*The deployment status and URLs will be posted in the AutoGPT Discord server.*",
    "label": null
  },
  {
    "index": 38,
    "pr title": "feat(platform): Add Block Development SDK with auto-registration system",
    "comment": "FYI I deleted all the comments with a script to clean up all the deployment testing",
    "label": null
  },
  {
    "index": 39,
    "pr title": "feat(platform): Add Block Development SDK with auto-registration system",
    "comment": "üßπ **Preview Environment Cleaned Up**\n\nAll resources for PR #10074 have been removed:\n- ‚ò∏Ô∏è Kubernetes namespace deleted\n- üóÉÔ∏è Database schema `pr10074` dropped\n\n*Cleanup completed successfully.*",
    "label": null
  },
  {
    "index": 40,
    "pr title": "feat(platform): Add Block Development SDK with auto-registration system",
    "comment": "‚úÖ **Preview Environment Deployed Successfully**\n\nüìä **Deployment Summary**\n| Service | Status |\n|---------|--------|\n| Redis | ‚úÖ Success |\n| RabbitMQ | ‚úÖ Success |\n| Backend Server | ‚úÖ Success |\n| WebSocket Server | ‚úÖ Success |\n| Scheduler Server | ‚úÖ Success |\n| Frontend Builder | ‚úÖ Success |\n\nüîî Please check Discord for the preview environment URLs and details.\n\n*The deployment status and URLs will be posted in the AutoGPT Discord server.*",
    "label": null
  },
  {
    "index": 41,
    "pr title": "feat(platform): Add Block Development SDK with auto-registration system",
    "comment": "‚ùå **Preview Environment Deployment Failed**\n\nüö® The preview environment deployment encountered critical errors and has been rolled back.\n\n**Cleanup Completed:**\n- ‚ò∏Ô∏è Kubernetes namespace deleted\n- üóÉÔ∏è Database schema dropped\n- üîå All services terminated\n\n*Please check the workflow logs for details and try again.*",
    "label": null
  },
  {
    "index": 42,
    "pr title": "feat(platform): Add Block Development SDK with auto-registration system",
    "comment": "Note: I've only reviewed the backend side of this\r\n\r\nFor tests, I'd like to see the full extent of the builder implications tested. \r\nEX: we can do with API key, with OAuth, with extra config, etc, all in one go. It shouldn't be too bad to keep up with due to Claude\r\n\r\nIt's also not clear to me if the builder is order-dependent or if it contains its own internal state machine for stepping through the order as it decides. Do the two examples below behave the same?\r\n```\r\nblah\r\n.withOAuth()\r\n.withApiKey()\r\n.build()\r\n\r\nvs \r\n\r\nblah\r\n.withApiKey()\r\n.withOAuth()\r\n.build()\r\n```\r\n\r\nAlso suggested a few things that I think can make it easier for people / AI to work with",
    "label": null
  },
  {
    "index": 43,
    "pr title": "feat(platform): Add Block Development SDK with auto-registration system",
    "comment": "> Note: I've only reviewed the backend side of this\r\n> \r\n> For tests, I'd like to see the full extent of the builder implications tested. EX: we can do with API key, with OAuth, with extra config, etc, all in one go. It shouldn't be too bad to keep up with due to Claude\r\n> \r\n> It's also not clear to me if the builder is order-dependent or if it contains its own internal state machine for stepping through the order as it decides. Do the two examples below behave the same?\r\n> \r\n> ```\r\n> blah\r\n> .withOAuth()\r\n> .withApiKey()\r\n> .build()\r\n> \r\n> vs \r\n> \r\n> blah\r\n> .withApiKey()\r\n> .withOAuth()\r\n> .build()\r\n> ```\r\n> \r\n> Also suggested a few things that I think can make it easier for people / AI to work with\r\n\r\nThe order of builder functions does not matter other than build going at the end",
    "label": null
  },
  {
    "index": 44,
    "pr title": "feat(platform): Add Block Development SDK with auto-registration system",
    "comment": "üßπ **Preview Environment Cleaned Up**\n\nAll resources for PR #10074 have been removed:\n- ‚ò∏Ô∏è Kubernetes namespace deleted\n- üóÉÔ∏è Database schema `pr_10074` dropped\n\n*Cleanup completed successfully.*",
    "label": null
  },
  {
    "index": 45,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "Thank you for your contribution to improve the scheduling UX in the platform library! I see that you've added several important features like API+backend data paths for scheduling, buttons for creating/deleting schedules, and updated the scheduling API.\n\nHowever, I cannot approve this PR yet because:\n\n1. **The checklist is incomplete** - Please check off all the items or remove sections that aren't applicable. At minimum, we need to see that you've:\n   - Clearly listed your changes (which you have)  \n   - Made and executed a test plan\n\n2. **Missing test plan** - Please add details about how you've tested these scheduling features. For example:\n   - Creating a schedule for an agent\n   - Verifying the schedule executes correctly\n   - Deleting a schedule\n   - Testing the UI components for scheduling\n\nOnce you've addressed these items, we can proceed with the review. The changes themselves look appropriate for the scope described in the PR title.",
    "label": null
  },
  {
    "index": 46,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "if you read this, it works! :rocket:",
    "label": null
  },
  {
    "index": 47,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "if you read this, it works! :rocket:",
    "label": null
  },
  {
    "index": 48,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "if you read this, it works! :rocket:",
    "label": null
  },
  {
    "index": 49,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "if you read this, it works! :rocket:",
    "label": null
  },
  {
    "index": 50,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "if you read this, it works! :rocket:",
    "label": null
  },
  {
    "index": 51,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "if you read this, it works! :rocket:",
    "label": null
  },
  {
    "index": 52,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "if you read this, it works! :rocket:",
    "label": null
  },
  {
    "index": 53,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "Thank you for working on the scheduling feature implementation! There are a few things that need to be addressed before this PR can be merged:\n\n### Missing Information\n\n1. **Checklist**: Please complete the checklist in the PR description. All items need to be checked off to indicate you've verified them.\n\n2. **Test Plan**: Please add a test plan explaining how you've tested these changes.\n\n3. **Backend Data Changes**: Since there are modifications to backend/data files, please explain how user_id checking is handled in the new/modified functions.\n\n### Scope Alignment\n\nThe PR title mentions \"platform/library\" but the changes span both frontend and backend components (which is also reflected in the PR labels). Consider updating the title to better reflect the scope of changes, perhaps something like: `feat(platform): Scheduling UX implementation`\n\n### Description Enhancements\n\nConsider expanding the description to better capture all the changes made. For example:\n- What specific API endpoints were updated/added?\n- How does the new scheduling flow work from a user perspective?\n- Are there any database changes or migrations needed?\n\nOnce these items are addressed, we'll be happy to review this PR again for merging. Thanks for your contribution to improving the scheduling feature!",
    "label": null
  },
  {
    "index": 54,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "Thank you for working on completing the scheduling feature implementation in the Library. There are a few items that need to be addressed before this PR can be merged:\n\n1. **Checklist Completion**: Please complete the checklist in the PR description. Each item needs to be checked off to confirm you've verified these aspects of your changes.\n\n2. **Test Plan**: Include a specific test plan that outlines how you've tested the scheduling functionality. This should cover creating schedules, deleting schedules, and verifying that scheduled runs execute as expected.\n\n3. **PR Scope**: The title mentions only 'platform/library' but your changes span across both frontend and backend components (as evidenced by the file changes and labels). Consider updating the title to better reflect the full scope of changes, such as 'feat(platform): Complete scheduling implementation in Library'.\n\n4. **More Detailed Description**: While your description lists the changes, it would be helpful to provide a bit more context about how these changes improve the scheduling UX and what the expected user experience will be after these changes.\n\nOnce these items are addressed, your PR will be ready for another review.",
    "label": null
  },
  {
    "index": 55,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "Thank you for your PR implementing scheduling features in the Library. I have a few points of feedback to help get this ready for merging:\n\n1. **Checklist not completed**: None of the checkboxes in the PR description are checked. Please complete the checklist by checking off all items or removing sections that are not applicable.\n\n2. **Scope in title doesn't match changes**: Your PR title indicates `feat(platform/library)`, but the changes span both frontend and backend components. Consider updating the title to better reflect the scope, perhaps something like `feat(platform): Scheduling UX` or `feat(platform/library,backend): Scheduling UX`.\n\n3. **Backend data modifications**: Since you're modifying files in `backend/data/`, please ensure that any added/changed functions pass the user_id and compare it correctly, or provide an explanation for why this isn't needed.\n\n4. **Test plan**: Please include a test plan that describes how you've tested these scheduling features.\n\nOnce you address these points, we can proceed with the review of the actual code changes.",
    "label": null
  },
  {
    "index": 56,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "Thank you for your detailed PR on enhancing the scheduling UX! The description and implementation plan look thorough and well-organized.\n\nHowever, I notice your checklist indicates you haven't completed testing according to your test plan yet. Before this PR can be merged, please:\n\n1. Complete the testing steps you've outlined in your checklist\n2. Check the box to confirm testing has been completed\n\nYour test plan looks comprehensive, covering schedule creation, execution, deletion, and UI state management. Once you've verified all these aspects work correctly, please update the PR.\n\nThe changes themselves look appropriate for the scope defined in your PR title (platform/library scheduling UX improvements), covering both frontend and backend components needed for this feature.",
    "label": null
  },
  {
    "index": 57,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "Thanks for this comprehensive PR improving the scheduling functionality! The changes look well-organized and clearly documented.\n\nHowever, I noticed that many of your test plan items are not checked off:\n- You've verified that newly created schedules appear in the list\n- But you haven't confirmed that scheduled runs execute successfully\n- You also haven't verified the deletion functionality works properly\n- And you haven't tested the UI behavior when the last schedule is deleted\n\nBefore we can merge this PR, please complete the testing according to your test plan and update the checklist to reflect the completed tests. This will ensure that all the functionality you've implemented works as expected.\n\nLet me know if you encounter any issues during testing that need to be addressed!",
    "label": null
  },
  {
    "index": 58,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 59,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 60,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 61,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 62,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 63,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 64,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 65,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 66,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 67,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 68,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 69,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 70,
    "pr title": "feat(platform/library): Scheduling UX",
    "comment": "If you read this, the demo works 8)",
    "label": null
  },
  {
    "index": 71,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "Ready for review while I iron out the last few details",
    "label": null
  },
  {
    "index": 72,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "Convert this to an issue plz?\r\n> Nice-to-have: make a button on webhook blocks to trigger a ping and check its result. The API endpoints for this is already implemented.",
    "label": null
  },
  {
    "index": 73,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "![image](https://github.com/user-attachments/assets/f1d2b2a2-7550-456e-af11-1754fe3d1a5a)\r\ncredentials seems non compatible with #8516 \r\n\r\nAlso hit this issue \r\n```\r\nINFO:     127.0.0.1:64414 - \"POST /api/graphs HTTP/1.1\" 400 Bad Request\r\n2024-11-12 19:01:02,046 ERROR  POST /api/graphs failed: Failed to create GitHub webhook: Validation Failed\r\n* url is missing a scheme\r\nTraceback (most recent call last):\r\n  File \"/Users/ntindle/Library/Caches/pypoetry/virtualenvs/autogpt-platform-backend-LOXRIHzA-py3.12/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\r\n    await app(scope, receive, sender)\r\n  File \"/Users/ntindle/Library/Caches/pypoetry/virtualenvs/autogpt-platform-backend-LOXRIHzA-py3.12/lib/python3.12/site-packages/starlette/routing.py\", line 73, in app\r\n    response = await f(request)\r\n               ^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/Library/Caches/pypoetry/virtualenvs/autogpt-platform-backend-LOXRIHzA-py3.12/lib/python3.12/site-packages/sentry_sdk/integrations/fastapi.py\", line 143, in _sentry_app\r\n    return await old_app(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/Library/Caches/pypoetry/virtualenvs/autogpt-platform-backend-LOXRIHzA-py3.12/lib/python3.12/site-packages/fastapi/routing.py\", line 301, in app\r\n    raw_response = await run_endpoint_function(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/Library/Caches/pypoetry/virtualenvs/autogpt-platform-backend-LOXRIHzA-py3.12/lib/python3.12/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\r\n    return await dependant.call(**values)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/server/routers/v1.py\", line 186, in create_new_graph\r\n    return await do_create_graph(create_graph, is_template=False, user_id=user_id)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/server/routers/v1.py\", line 221, in do_create_graph\r\n    graph = await on_graph_activate(\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/integrations/webhooks/graph_lifecycle_hooks.py\", line 43, in on_graph_activate\r\n    updated_node = await on_node_activate(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/integrations/webhooks/graph_lifecycle_hooks.py\", line 140, in on_node_activate\r\n    new_webhook = await webhooks_manager.get_suitable_webhook(\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/integrations/webhooks/base.py\", line 40, in get_suitable_webhook\r\n    return await self._create_webhook(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/integrations/webhooks/base.py\", line 138, in _create_webhook\r\n    provider_webhook_id, config = await self._register_webhook(\r\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/ntindle/code/agpt/AutoGPT/autogpt_platform/backend/backend/integrations/webhooks/github.py\", line 122, in _register_webhook\r\n    raise ValueError(f\"Failed to create GitHub webhook: {error_msg}\")\r\nValueError: Failed to create GitHub webhook: Validation Failed\r\n* url is missing a scheme\r\nINFO:     127.0.0.1:64466 - \"POST /api/graphs HTTP/1.1\" 400 Bad Request\r\n```\r\n\r\n![image](https://github.com/user-attachments/assets/ebd92341-5b65-4221-8c79-837e8eb934ef)\r\n\r\n\r\nWe should probably have a better error message than that for saying \"set your .env correctly\"",
    "label": null
  },
  {
    "index": 74,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "\r\nhttps://github.com/user-attachments/assets/d9a71e7f-f6ae-4483-a770-9e6cf87d045f\r\n\r\nrunning this agent gets me the following \r\n\r\nNote the weird credentials fields",
    "label": null
  },
  {
    "index": 75,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "Not sure if related but also can't delete creds",
    "label": null
  },
  {
    "index": 76,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "> running this agent gets me the following\r\n> \r\n> [video demonstrating error on run]\r\n\r\nGood catch. I'm not sure how to deal with this. The graph can't be run manually because it relies on a webhook to trigger it. Should we hide the \"Run\" button if a graph can't be run manually? Should it just do nothing?\r\n\r\n> Note the weird credentials fields\r\n\r\nDo you mean it still shows the field title **Credentials** while hiding the actual input? That is a bug, possibly improperly resolved merge conflict. I'll look into it.",
    "label": null
  },
  {
    "index": 77,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "Github PR review split the convos, im sorry <3",
    "label": null
  },
  {
    "index": 78,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "> Good catch. I'm not sure how to deal with this. The graph can't be run manually because it relies on a webhook to trigger it. Should we hide the \"Run\" button if a graph can't be run manually? Should it just do nothing?\r\n\r\nwhat's toran and john think",
    "label": null
  },
  {
    "index": 79,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "> The graph can't be run manually because it relies on a webhook to trigger it. Should we hide the \"Run\" button if a graph can't be run manually? Should it just do nothing?\r\n\r\nSo there needs to be a way of saying that you want your Agent to be \"Running\" - in this case listening for a webhook - or \"Stopped\" - i.e not listening on a webhook. I was thinking the run button would do that here.\r\n\r\nWhat's the current UX for this? Let's sync on this one @Pwuts as it's a lot for a comment.\r\n",
    "label": null
  },
  {
    "index": 80,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "Created follow-up ticket #8671",
    "label": null
  },
  {
    "index": 81,
    "pr title": "feat(platform, blocks): Webhook-triggered blocks",
    "comment": "> The advanced button here does nothing?\r\n\r\nThat's because the block has no \"advanced\" inputs, and the toggle doesn't hide when there is nothing to toggle.\r\n\r\n> We probably want these to be able to trivially link\r\n\r\nYes, there are a few ways to do that but most of those are out of scope for this PR and the rest not a sustainable fix imo. We should do a QOL improvement on all of the GitHub blocks to address stuff like this.\r\n\r\n> How do I pass a variable to this block [picture of GitHub webhook trigger block]\r\n\r\nYou don't. Due to the system's architecture, the webhook trigger block can't accept input links and must be the starting node.\r\n\r\n> Why is the output not number type for number\r\n\r\nBecause `NodeHandle` doesn't know what an `integer` is apparently:\r\nhttps://github.com/Significant-Gravitas/AutoGPT/blob/86535b5811f8d1cc0bdde2232693919c4b1115e3/autogpt_platform/frontend/src/components/NodeHandle.tsx#L22-L29\r\n\r\n- [ ] Add `integer` type to `NodeHandle` type list\r\n\r\n> we should probably allow the block to output the repo, URL, etc too for the trigger if its not taking in inputs\r\n\r\nMy idea for a sustainable and scalable fix for that is: allow directly connecting links to nested properties of object outputs. That's way out of scope for this PR.\r\n\r\nDue to the block layout, I don't want to add a large number of outputs because that just fills up the screen very quickly.\r\n\r\n> We need to clarify Payload, Sender and Pull request for normal people\r\n\r\nIf you don't know what a pull request is, why would you be using this block?\r\n\r\n- [x] Improve description of `payload` output\r\n\r\n> I'm not sure the diff in pull request and Payload\r\n\r\ncan't parse, come again?\r\n\r\n> I assume sender is creator?\r\n\r\nSender already has the description *\"Object representing the user who triggered the event\"*. Do you think that output also needs a better name, and if so what?\r\n\r\n> I have no idea (as a dev, not even user) how to debug this via UI. As a dev, I checked the raw output of the block in the logs. It just \"didn't work\" but succeeded from the UI perspective\r\n\r\nI also just debug by looking at the backend logs. Suggestions welcome.\r\n\r\nWe could store all incoming webhook payloads and add a view for that, but that's a significant feature addition. WDYT?\r\n\r\n> If a user does a bad design (ex: leaving out a value on a comparison) the webhook rejects but they should probably know that when saving because it will be an issue they won't be able to diagnose.\r\n\r\nYeah the node needs an indicator for whether a webhook is attached or not. Determining why can usually be done client-side, because it depends directly on whether the user filled out all the required inputs on the node.\r\n\r\n- [x] Create issue for webhook status indicator on webhook-triggered nodes\r\n\r\n> The Run button throws an error when you run (this is better than crashing tho)\r\n\r\nWould you rather hide the button? I'm not sure how to properly fix this.\r\n\r\n> We may want to do something to require platform base URL to be set if someone uses a trigger because currently it just doesn't do anything.\r\n\r\n- [x] Disable webhook-triggered blocks if `PLATFORM_BASE_URL` is not set\r\n- [x] Raise error in `BaseWebhooksManager` on attempt to create webhook if `PLATFORM_BASE_URL` is not set\r\n\r\n> we currently don't actually check platform base URL on inbound webhooks so we just execute from anything lol.\r\n> \r\n> > Replicate by running ngrok and disabling the line in your .env\r\n\r\nWhy would we need to check it on inbound webhook payloads? If it arrives, that's a job done. The `PLATFORM_BASE_URL` is only necessary to configure the webhook in the first place.",
    "label": null
  },
  {
    "index": 82,
    "pr title": "New rule: fix missing `git clone` when given a URL",
    "comment": "@djh82 would appreciate a re-review. I think I've fixed up all the issues",
    "label": null
  },
  {
    "index": 83,
    "pr title": "New rule: fix missing `git clone` when given a URL",
    "comment": "@scorphus thanks for your feedback! I believe that this rule would be worthwhile as I encountered it enough times to choose to spend my time on creating a rule for it. I tutor a computer science class where we teach git and have observed that I'm far from the only person to make this mistake. Since there's a rule for handling `git clone git clone`, which is useful when I type `git clone` then paste the URL, only for it to include its own `git clone` (Bitbucket does this), I'd say that this particular rule is reasonable enough, since it handles the opposite case.\r\n\r\nRE: your feedback on output matching, it does seem to be a little pointless. If you're interested in merging this PR at some point then I'll absolutely get rid of it.\r\n\r\nPerhaps it could search for `'git'` within the URL as an additional measure to avoid false positives? This would still work for all most of the popular git servers I'm aware of, at least using SSH. Would that change make the addition be worthwhile? Can you think of any other methods I could use to reduce the number of false positives?",
    "label": null
  },
  {
    "index": 84,
    "pr title": "New rule: fix missing `git clone` when given a URL",
    "comment": "Thanks for sharing your testimonial. Let's get this merged.\r\n\r\nRegarding matching the output, I thought about disregarding output altogether and caring only about `output.script` or `output.script_parts`.\r\n\r\nAsserting `git` in the URL would blacklist bitbucket repos.",
    "label": null
  },
  {
    "index": 85,
    "pr title": "New rule: fix missing `git clone` when given a URL",
    "comment": "Thanks again for the feedback! I fixed up things as per your suggestion, and also removed the code that checked the output.\r\n\r\nDouble checking, since I'm not entirely sure, should it check the URL for the presence of `git` somewhere? The only case I can think of that wouldn't work would be cloning using HTTPS on Bitbucket where `.git` has been manually removed from the end of their copied URL. Their SSH username is `git`, and their copy clone button copies the `git clone` part anyway. It would be helpful for preventing false positives such as [YouTube videos](https://www.youtube.com/watch?v=dQw4w9WgXcQ) (I apologise in advance).\r\n\r\n",
    "label": null
  },
  {
    "index": 86,
    "pr title": "New rule: fix missing `git clone` when given a URL",
    "comment": "Pretty sure I've got everything fixed up now! Let me know if there's anything else you'd like me to do!",
    "label": null
  },
  {
    "index": 87,
    "pr title": "New rule: fix missing `git clone` when given a URL",
    "comment": "Just bumping this one again @scorphus \r\nIs there anything else you want me to do on it?",
    "label": null
  },
  {
    "index": 88,
    "pr title": "New rule: fix missing `git clone` when given a URL",
    "comment": "@MiguelGuthridge, please let me know your thoughts about the last change I submitted.",
    "label": null
  },
  {
    "index": 89,
    "pr title": "New rule: fix missing `git clone` when given a URL",
    "comment": "@MiguelGuthridge, thanks for the complete patch! Much appreciated! üôå ",
    "label": null
  },
  {
    "index": 90,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8199300/badge)](https://coveralls.io/builds/8199300)\n\nCoverage decreased (-2.8%) to 90.289% when pulling **01c0e800cd2a236d2e00454937409278a8f26d82 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 91,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8199300/badge)](https://coveralls.io/builds/8199300)\n\nCoverage decreased (-2.8%) to 90.289% when pulling **01c0e800cd2a236d2e00454937409278a8f26d82 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 92,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8199300/badge)](https://coveralls.io/builds/8199300)\n\nCoverage decreased (-2.8%) to 90.289% when pulling **01c0e800cd2a236d2e00454937409278a8f26d82 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 93,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8199743/badge)](https://coveralls.io/builds/8199743)\n\nCoverage increased (+0.08%) to 93.2% when pulling **b97830f6f743f7d03839a8e771e2018726692961 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 94,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8199743/badge)](https://coveralls.io/builds/8199743)\n\nCoverage increased (+0.08%) to 93.2% when pulling **b97830f6f743f7d03839a8e771e2018726692961 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 95,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8199743/badge)](https://coveralls.io/builds/8199743)\n\nCoverage increased (+0.08%) to 93.2% when pulling **b97830f6f743f7d03839a8e771e2018726692961 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 96,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8199743/badge)](https://coveralls.io/builds/8199743)\n\nCoverage increased (+0.08%) to 93.2% when pulling **b97830f6f743f7d03839a8e771e2018726692961 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 97,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8199743/badge)](https://coveralls.io/builds/8199743)\n\nCoverage increased (+0.08%) to 93.2% when pulling **b97830f6f743f7d03839a8e771e2018726692961 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 98,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "Cheers @scorphus! It was your comments on #561 that inspired me to do this. I figured it might save some effort going forward.\n",
    "label": null
  },
  {
    "index": 99,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "Thanks again for the comments, @scorphus! I made some more changes addressing them :)\n",
    "label": null
  },
  {
    "index": 100,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8215085/badge)](https://coveralls.io/builds/8215085)\n\nCoverage increased (+0.08%) to 93.2% when pulling **31e127da1d47f290c81eac6aa82cddd0b8190ba4 on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 101,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "Awesome, @josephfrazier!\n\nWell, I feel I can push this even further üòÉ  As you're in the process of fixing these issues and changes haven't yet made into master, what would you say if I suggested you to remove a couple of commits and squash those which are logically similar/related?\n\nCommit 85a3e34 is a revert of 4d9f177, both could be removed. Also, all EXYZ-related commits could be joined together, leaving one single commit per violation ‚Äì¬†E123, E225, E231, E265, E302, E402, E711 and E731.\n\nWhat do you think about getting a cleaner history?\n",
    "label": null
  },
  {
    "index": 102,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "Good call @scorphus, I did a lot more error-fixing and cleaned up the history :D \n",
    "label": null
  },
  {
    "index": 103,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8221807/badge)](https://coveralls.io/builds/8221807)\n\nCoverage increased (+0.08%) to 93.2% when pulling **df8e5ecb40e3e2efa4d2004ad7d54ac6e54652ad on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 104,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8221807/badge)](https://coveralls.io/builds/8221807)\n\nCoverage increased (+0.08%) to 93.2% when pulling **df8e5ecb40e3e2efa4d2004ad7d54ac6e54652ad on josephfrazier:flake8** into **ce6b82c92d78ae283cb3db001766b76f6647bc47 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 105,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8243763/badge)](https://coveralls.io/builds/8243763)\n\nCoverage increased (+0.08%) to 93.232% when pulling **dda9d55989cd6c499624388ba55f900d0f42d892 on josephfrazier:flake8** into **4d714994a38d8b2f4342ab4f5e331b9db254076b on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 106,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8243763/badge)](https://coveralls.io/builds/8243763)\n\nCoverage decreased (-2.8%) to 90.335% when pulling **dda9d55989cd6c499624388ba55f900d0f42d892 on josephfrazier:flake8** into **4d714994a38d8b2f4342ab4f5e331b9db254076b on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 107,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "[![Coverage Status](https://coveralls.io/builds/8243763/badge)](https://coveralls.io/builds/8243763)\n\nCoverage decreased (-2.8%) to 90.335% when pulling **dda9d55989cd6c499624388ba55f900d0f42d892 on josephfrazier:flake8** into **4d714994a38d8b2f4342ab4f5e331b9db254076b on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 108,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "@nvbn, do you have any thoughts on this? Is there anything else that needs to be done to land it (other than fixing files that have been changed on the `master` branch)?",
    "label": null
  },
  {
    "index": 109,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "@josephfrazier, ooops, sorry, I just forgot about this pr.\r\n\r\nI'll check it in the nearest time and will merge it.\r\n\r\nThansk.",
    "label": null
  },
  {
    "index": 110,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "Great, thanks! I just pushed some changes that fix the files that had been updated on the master branch, but haven't rebased them yet. If everything looks good to you, let me know and I can `git rebase -i --autosquash master` to combine the `fixup!` commits with their referents and get rid of that `Merge branch 'master' into flake8` commit.",
    "label": null
  },
  {
    "index": 111,
    "pr title": "Run flake8 in Travis, fix some errors",
    "comment": "Cheers, hopefully this will make it easier to ensure future contributions adhere to the code style.",
    "label": null
  },
  {
    "index": 112,
    "pr title": "Adding devcontainer for easy Python development",
    "comment": "Also, the fix for Python 2.7 tests is already on current `master`, would you please rebase on top of that? üôÇ ",
    "label": null
  },
  {
    "index": 113,
    "pr title": "Adding devcontainer for easy Python development",
    "comment": "Howdy @storey247! Thanks for contributing. I'd really love to read your comments on my suggestions/questions above. I understand that you're probably busy with many stuff. But I thought I'd ping you üôÇ ",
    "label": null
  },
  {
    "index": 114,
    "pr title": "Adding devcontainer for easy Python development",
    "comment": "hi @scorphus thanks for all the feedback, yes I will action and get this PR split into two :smile: apologies for the delayed response, work is a bit crazy atm",
    "label": null
  },
  {
    "index": 115,
    "pr title": "Adding devcontainer for easy Python development",
    "comment": "Awesome! I already split the commit into three, so no need to create another PR, I can merge the changes regarding the new rule and we leave this PR for the devcontainer addition. What do you think?",
    "label": null
  },
  {
    "index": 116,
    "pr title": "Adding devcontainer for easy Python development",
    "comment": "Amazing! Nice work! üëèüëèüëè\r\n\r\nsounds like a plan, I‚Äôll rebase this on Monday when the work is merged and I‚Äôll tidy up the container so it‚Äôs nice and trim. \r\n\r\nThanks @scorphus ",
    "label": null
  },
  {
    "index": 117,
    "pr title": "Adding devcontainer for easy Python development",
    "comment": "There you go, @storey247. Sorry for the extra noise. To continue your work, I'd suggest you force-resetting to the `main_master` branch on your remote, that way you'll have exactly what this PR currently has. Please don't hesitate to ask me for help with that.",
    "label": null
  },
  {
    "index": 118,
    "pr title": "Adding devcontainer for easy Python development",
    "comment": "@scorphus I have now rebased my work from latest `master` and cleaned up the comments as discussed.\r\n\r\nI also added some notes into the `Contribute.md` to help people get up and running with the devcontainer setup if required.\r\n\r\nHopefully now this work can be merged in too. Let me know if there is anything else you need me to look at",
    "label": null
  },
  {
    "index": 119,
    "pr title": "Adding devcontainer for easy Python development",
    "comment": "> Thats super, @storey247! Thanks so much for hanging in! Please consider my suggestion below.\r\n\r\nFeedback actioned, just waiting on the builds and then should be good to merge üëç ",
    "label": null
  },
  {
    "index": 120,
    "pr title": "#1282 git misspelled",
    "comment": "I made test_not_match fucntion. I hope that now it is better!",
    "label": null
  },
  {
    "index": 121,
    "pr title": "#1282 git misspelled",
    "comment": "It feels like rather than solving this specifically for the git command, it might be prudent to try and solve the issue in the no_command rule?\r\n\r\nThe underlying issue is that https://github.com/nvbn/thefuck/blob/master/thefuck/shells/generic.py#L87 shlex removes the quotes when operating in posix mode (the default).\r\n\r\nWhat really needs to happen, is we need to use quote for each element of the new command, before calling join, i.e. we need to re-quote the split command.  So something like this:\r\n\r\n```python\r\n    return [' '.join(shell.quote(a) for a in [new_command] + command.script_parts[1:])\r\n            for new_command in new_cmds]\r\n```\r\n\r\nWhere quote is obtained from the current shell (`from thefuck.shells import shell`).  (Also, make my code less ugly, double list comprehension is unsightly!)",
    "label": null
  },
  {
    "index": 122,
    "pr title": "#1282 git misspelled",
    "comment": "Thank you a lot for the review! Is this commit satisfying for the project?",
    "label": null
  },
  {
    "index": 123,
    "pr title": "#1282 git misspelled",
    "comment": "You'll probably want to revert the readme change and add some further tests for no_command? ",
    "label": null
  },
  {
    "index": 124,
    "pr title": "#1282 git misspelled",
    "comment": "Sorry for the too many commits. Is it now okay?\r\nThank you a lot!",
    "label": null
  },
  {
    "index": 125,
    "pr title": "#1282 git misspelled",
    "comment": "@djh82 \r\nIs there any problem with the Ubuntu version 3.9 and what the reason why is not running properly?\r\nIs this PR okay for merging?",
    "label": null
  },
  {
    "index": 126,
    "pr title": "#1282 git misspelled",
    "comment": "Regarding the failure, please check #1310.",
    "label": null
  },
  {
    "index": 127,
    "pr title": "#1282 git misspelled",
    "comment": "@djh82 @scorphus\r\nAre there any other mistakes or missing cases?",
    "label": null
  },
  {
    "index": 128,
    "pr title": "#1282 git misspelled",
    "comment": "I believe that now it is correct!",
    "label": null
  },
  {
    "index": 129,
    "pr title": "#1282 git misspelled",
    "comment": "@NikosKakonas, could you please rebase this on top of current `master`? Thanks!",
    "label": null
  },
  {
    "index": 130,
    "pr title": "#1282 git misspelled",
    "comment": "@scorphus  Is it now okay? Thanks!",
    "label": null
  },
  {
    "index": 131,
    "pr title": "#1282 git misspelled",
    "comment": "@scorphus Is it okay for merging?",
    "label": null
  },
  {
    "index": 132,
    "pr title": "#1282 git misspelled",
    "comment": "@nkakonas does this justify a new release? This has been bugging me for a while.",
    "label": null
  },
  {
    "index": 133,
    "pr title": "#1282 git misspelled",
    "comment": "@scorphus could you cut a new release for this?",
    "label": null
  },
  {
    "index": 134,
    "pr title": "Globalize pyenv rule ",
    "comment": "@scorphus Is everything good with my pr, would you like me to enhance anything? :smile: ",
    "label": null
  },
  {
    "index": 135,
    "pr title": "Globalize pyenv rule ",
    "comment": "Yes I totally agree with all your points. My only thoughts lie on the matter of the global rule. Due to the almost identical commands of the env packages, my solution seemed really convenient. Though, if you think is better to make separate files for each command, I will work on it for sure. Probably the testing process will be more efficient in this way as well. ",
    "label": null
  },
  {
    "index": 136,
    "pr title": "Globalize pyenv rule ",
    "comment": "The identical parts of the rules could be kept in a single, separate ‚Äú`devenv`‚Äù submodule imported by all of the rules. Such submodule would reside under `thefuck/specific` along with other specific ones. This way there‚Äôs less repetition. What do you think?",
    "label": null
  },
  {
    "index": 137,
    "pr title": "Globalize pyenv rule ",
    "comment": "Yes, that' s a great idea! I will work on it, as well as the requested changes and come up with a new pr.",
    "label": null
  },
  {
    "index": 138,
    "pr title": "Globalize pyenv rule ",
    "comment": "Need to check why the tests fail, otherwise I think I managed to fullfill the requested changes and they seem really great!",
    "label": null
  },
  {
    "index": 139,
    "pr title": "Globalize pyenv rule ",
    "comment": "@scorphus Hello again, everything seems to work pretty great! Unfortunately, your idea of integrating some of the common code of the rules to specific/devenv.py was making the tests to fail, so I decided to simplify it. Hope I find some extra time and manage to integrade more of the common code of the rules in a couple of weeks.\r\n\r\nThank you for your help!",
    "label": null
  },
  {
    "index": 140,
    "pr title": "Globalize pyenv rule ",
    "comment": "You're on fire! üî• I hope I soon have time to review it more thoroughly. Thanks!",
    "label": null
  },
  {
    "index": 141,
    "pr title": "Globalize pyenv rule ",
    "comment": "Hello @scorphus I didn't have any time to enhance this commit, as I can understand you haven't found any time to review it in order to merge it as well. Let me know about your status :sunglasses: ",
    "label": null
  },
  {
    "index": 142,
    "pr title": "Globalize pyenv rule ",
    "comment": "Hey @scorphus,\r\n\r\nIt's okay don't worry! Let me know if you need any help, I will be glad to help üòÉ ",
    "label": null
  },
  {
    "index": 143,
    "pr title": "Globalize pyenv rule ",
    "comment": "I'd love if you could spare a review üôå",
    "label": null
  },
  {
    "index": 144,
    "pr title": "Globalize pyenv rule ",
    "comment": "Sorry guys I was pretty busy and saw the updates just now, cheers @divykj for the review! Glad to help @scorphus üôå",
    "label": null
  },
  {
    "index": 145,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "This solution works great, thanks.\n",
    "label": null
  },
  {
    "index": 146,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "Glad it works for you! It depends on `sed`, though. But I believe it's certain to be available.\n",
    "label": null
  },
  {
    "index": 147,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "Can it also include [solution for stdin](https://github.com/nvbn/thefuck/issues/76#issuecomment-96103809)?\n",
    "label": null
  },
  {
    "index": 148,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "@nvbn do you mean adopting the workaround as mentioned in https://github.com/nvbn/thefuck/issues/76#issuecomment-96103809?\n",
    "label": null
  },
  {
    "index": 149,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "@nvbn nice, 52f4852 does just that. Let's wait and see if anyone confirms it solves #76.\n",
    "label": null
  },
  {
    "index": 150,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "@scorphus, it solves both bugs for me. \n",
    "label": null
  },
  {
    "index": 151,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "@scorphus One thing on the `$TMPDIR` thing, a lot of Linux distributions don't appear to have it set by default. OS X does but not every Linux distro does so there should be a fallback there to `/tmp` if it's not set.\n",
    "label": null
  },
  {
    "index": 152,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "Yeah, absolutely. First I read http://en.wikipedia.org/wiki/TMPDIR and changed it. But then I thought it over and decided to `vagrant up` Ubuntu 14.04, CentOS 6.4 and Debian 7 to test it and, no surprise. Now I'm testing with `mktemp` and it's working just fine in all cases.\n",
    "label": null
  },
  {
    "index": 153,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "Ouch, no... too bad. `mktemp`'s implementations differ amongst Linux and OS X\n",
    "label": null
  },
  {
    "index": 154,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "So, how about this:\n\n``` fish\nfunction __thefuck_repl --description 'Replace operators into fish-compatible'\n    set -l tmp (echo $argv | sed 's/ && / ; and /g')\n    echo $tmp | sed 's/ || / ; or /g'\nend\n\nfunction fuck --description 'Correct your previous console command'\n    set -l eval_script (mktemp 2>/dev/null ; or mktemp -t 'thefuck')\n    thefuck $history[1] > $eval_script\n    eval (__thefuck_repl (cat $eval_script))\n    rm $eval_script\nend\n```\n",
    "label": null
  },
  {
    "index": 155,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "Can I merge it? Or it's not a final solution?\n",
    "label": null
  },
  {
    "index": 156,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "I moved aliases to [wiki](https://github.com/nvbn/thefuck/wiki/Shell-aliases), it will be faster to change them there.\n",
    "label": null
  },
  {
    "index": 157,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "I think it's good to go. Ping, @daenney, what do you think?\nEm 27/04/2015 02:58, \"Vladimir Iakovlev\" notifications@github.com\nescreveu:\n\n> I moved aliases to wiki\n> https://github.com/nvbn/thefuck/wiki/Shell-aliases, it will be faster\n> to change them there.\n> \n> ‚Äî\n> Reply to this email directly or view it on GitHub\n> https://github.com/nvbn/thefuck/pull/130#issuecomment-96514751.\n",
    "label": null
  },
  {
    "index": 158,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "Ya, I think this should work. Needs a rebase though since Github thinks it has a merge conflict.\n",
    "label": null
  },
  {
    "index": 159,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "Thanks for the input, @daenney!\n\nThe part of the README.md file regarding shell aliases and/or functions was move over to the wiki, that's why this is conflicting with master. I'll move the solution to the wiki too.\n",
    "label": null
  },
  {
    "index": 160,
    "pr title": "config.fish: improve documentation on creating Fish functions",
    "comment": "One thing to remind ourselves of, though, is that from now on, every single rule that involves logical operators (`&&` and `||` for instance) should enclose them in blank spaces, like the following: `cmd_x && cmd_y` or `cmd_x || cmd_z`.\n",
    "label": null
  },
  {
    "index": 161,
    "pr title": "Rule for branch dash 0",
    "comment": "Nice idea, maybe it will be a good thing to make that more generic? To just replace any argument that starts with `0` if it appears in `stderr`.",
    "label": null
  },
  {
    "index": 162,
    "pr title": "Rule for branch dash 0",
    "comment": "@nvbn When I quickly read your comment on my phone, I thought making this fix more generic sounded like a good idea, but upon reflection, I'm not so sure.\r\n\r\nIn the specific case I coded up, the argument needs to turn into a flag. Would making that assumption more generic (i.e. convert all arguments starting with `0` to `-`) make sense?\r\n\r\nFor that matter, what would the \"undo\" action look like, or would there even need to be an \"undo\" action? (In the specific example here, I need to delete a branch that was just accidentally created...what should the proper response be if `git branch 0v` wasn't the command?",
    "label": null
  },
  {
    "index": 163,
    "pr title": "Rule for branch dash 0",
    "comment": "@ProfessorTom you're right, initially I thought that `git branch 0v` prints something, but it just creates a branch.\r\n\r\nI guess the only way to generalize this rule is to also support cases like `git branch 0l`, `git branch 0a` and etc, so just check that the argument after `branch` starts with `0`.",
    "label": null
  },
  {
    "index": 164,
    "pr title": "Rule for branch dash 0",
    "comment": "Do you still want me to generalize this feature turning the `0` into a `-` and deleting the branch just created in all cases?\r\n\r\nIs there a case where this would cause more harm than good?",
    "label": null
  },
  {
    "index": 165,
    "pr title": "Rule for branch dash 0",
    "comment": "bumping to get a review and hopefully a merge.",
    "label": null
  },
  {
    "index": 166,
    "pr title": "Rule for branch dash 0",
    "comment": "@scorphus @nvbn Can I get a review on my latest changes?",
    "label": null
  },
  {
    "index": 167,
    "pr title": "Rule for branch dash 0",
    "comment": "What will it take to get this new approach reviewed and merged? cc @nvbn @scorphus @jamtur01 ",
    "label": null
  },
  {
    "index": 168,
    "pr title": "Rule for branch dash 0",
    "comment": "Thank you for contributing, @ProfessorTom üëç \r\n\r\nPlease check a new PR, which is probably going to be #1212.",
    "label": null
  },
  {
    "index": 169,
    "pr title": "Fix Issue #959: breaks after composer require with single package, revamp composer rules",
    "comment": "If only GitHub would show the comments in line-number order, other than chronological. Sorry if the review is confusing, please let me know if something is not clear.",
    "label": null
  },
  {
    "index": 170,
    "pr title": "Fix Issue #959: breaks after composer require with single package, revamp composer rules",
    "comment": "wow, thanks for the comprehensive code review! i'm currently occupied with midterm examinations at the moment so it'll take some time for me to follow up on your comments, i'll push my changes at the end of this week.",
    "label": null
  },
  {
    "index": 171,
    "pr title": "Fix Issue #959: breaks after composer require with single package, revamp composer rules",
    "comment": "Sorry for the delay. I've added in your requested changes, and also adopted Black as my code formatter.\r\n\r\nExcept for one problem: Black triggers `E203 whitespace before :` in line 31 of `composer_not_package.py`:\r\n\r\n\r\n```\r\nversion_constraint = offending_script_param[len(wrong_package_name) :]\r\n```\r\n\r\nAccording to [Black themselves](https://github.com/psf/black#slices), E203 should be ignored by flake. Perhaps we should check in a flake8 configuration file that follows their recommendation?",
    "label": null
  },
  {
    "index": 172,
    "pr title": "Fix Issue #959: breaks after composer require with single package, revamp composer rules",
    "comment": "Hey, thanks for keeping up! üëç \r\n\r\nI'm happy that you adopted Black. But maybe we're going too far with it. Like changing lines that are not part of the fix ‚Äì¬†which I've just noticed. Things such as formatting that should be part of a different PR ‚Äì¬†I know it was in the middle of one or two of my suggestions, I didn't notice it back then, sorry for that.\r\n\r\nAlso, I've just noticed that this PR fixes a rule and introduces another. These should be at least two separate commits.\r\n\r\nDo you think you can split the changes in separate commits, undo the lines that are not part of the fix/feature and update this PR? Otherwise, I could do that, if you don't mind. Authorship would be maintained, of course.",
    "label": null
  },
  {
    "index": 173,
    "pr title": "Fix Issue #959: breaks after composer require with single package, revamp composer rules",
    "comment": "This is my first code/feature related PR on a public repository so admittedly I'm not very familiar with best practices ‚Äì are you saying I should add more commits that reverses (removes) the `composer_not_package` rule, then open another PR (perhaps I refork `nvbn:master` and rebase), and then re-add `composer_not_package` and open a separate PR?\r\n\r\nI'm not very sure how to go about reversing selective lines of commits too; I don't use any Git GUI applications that can offer such a functionality.",
    "label": null
  },
  {
    "index": 174,
    "pr title": "Fix Issue #959: breaks after composer require with single package, revamp composer rules",
    "comment": "Sorry for the late reply, @chesnutcase.\r\n\r\nSplitting into two different PRs would be ideal, but as we've come this far, splitting changes into two different commits is more than enough.\r\n\r\nRegarding the changes introduced by the use of Black... On one hand, Black is great because it leaves no space for discussions about how to format code ‚Äì it does it for you. Out of a sudden, you stop wasting time with everything related to code formatting. On the other hand, when it comes to a codebase that's not previously formatted by it, that may generate undesirable noise, such as some parts of this pull request. So it's up to the developer to include only the relevant changes.\r\n\r\nPlease LMK if I can make myself any clearer. (I often fail at that)\r\n\r\nThanks again for contributing and for sticking to it!",
    "label": null
  },
  {
    "index": 175,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "Been loving this. Hope it gets reviewed and upstreamed for all. Thanks for making this!",
    "label": null
  },
  {
    "index": 176,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "I've just discovered `thefuck` and I can't imagine how I didn't stumble into it earlier.\r\n\r\nThis PR would fit like a glove for me that just switched to nixos and haven't yet grown the muscle memory of typing the `nix-shell` whenever my command fails.",
    "label": null
  },
  {
    "index": 177,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "i would love to see this merged as well",
    "label": null
  },
  {
    "index": 178,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "looks like you [can use this already](https://github.com/NixOS/nixpkgs/compare/master...KiaraGrouwstra:nixpkgs:thefuck-nix-shell) using e.g. an overlay, altho i had a bit of trouble getting it to work out of the box.\r\nspecifically, without adding `doCheck = false;`, i would run into this error:\r\n\r\n```\r\nerror: builder for '/nix/store/rl44gb6qd4x2myclj9i8cpkfrvw6ysqa-thefuck-3.32.drv' failed with exit code 2;\r\n       last 10 log lines:\r\n       > thefuck/system/unix.py:6\r\n       >   /build/source/thefuck/system/unix.py:6: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\r\n       >     from distutils.spawn import find_executable\r\n       >\r\n       > -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n       > =========================== short test summary info ============================\r\n       > ERROR  - ModuleNotFoundError: No module named 'pytest_docker_pexpect'\r\n       > !!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\r\n       > ========================= 1 warning, 1 error in 0.09s ==========================\r\n       > /nix/store/bknngadwym46j65qs14ic2w79rpav888-stdenv-linux/setup: line 1582: pop_var_context: head of shell_variables not a function context\r\n```\r\n\r\ni had tried removing the added test, altho that appeared not to resolve the issue.\r\n",
    "label": null
  },
  {
    "index": 179,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "it would seem cool to similarly get an approach using `nix run`, i.e. go from suggesting `nix-shell -p ponysay --run \"ponysay moo\"` to `nix run nixpkgs#ponysay -- moo` - this might eventually help extend beyond just `nixpkgs`.\r\n\r\nedit: https://github.com/KiaraGrouwstra/thefuck/commit/81d6786c80b86f2cc80b3ea90adc214df8266643\r\n",
    "label": null
  },
  {
    "index": 180,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "I've been using a custom rule that supports the new [unified CLI](https://zero-to-nix.com/concepts/nix#unified-cli) for a while, and was planning on opening a PR once this one has been merged (I hesitate to update this current PR as it's already tested and ready to be merged). I don't know if that will happen soon, so in the meantime I've pushed the changes to [this](https://github.com/thenbe/thefuck/tree/nix-shell-new) new branch instead, which [builds](https://github.com/thenbe/thefuck/compare/nix-shell...thenbe:thefuck:nix-shell-new) on this here PR. You can use the updated rule by adding it as a [custom rule](https://github.com/nvbn/thefuck?tab=readme-ov-file#creating-your-own-rules) to your config.\r\n\r\nIn the new rule, three variants are suggested. Assuming I run `cowsay hello world`, I am presented with the following:\r\n\r\n1. `nix run nixpkgs#cowsay -- hello world`: This runs my command in a non-interactive shell. Uses the nix unified CLI.\r\n1. `nix shell nixpkgs#cowsay`: This enters an interactive shell with `cowsay` available, but does not run any command. This is useful if you'd rather run the command yourself after entering the shell because your command requires delicate massaging (e.g. running it with `sudo`, prefixing it with environment variable, juggling quote variants, etc).\r\n1. `nix-shell -p cowsay --run \"cowsay hello world\"`. This runs my command in a non-interactive shell. Uses the nix original CLI.\r\n1. `nix shell nixpkgs#cowsay --command cowsay hello world`: Very similar to the first one so I've personally disabled this one.\r\n\r\n### Thoughts on future updates:\r\n\r\n\r\n\r\n- It'd be nice if there was a variant that runs my command and then _keeps me_ in the shell.\r\n  - For the original CLI, we [can](https://nix.dev/manual/nix/2.19/command-ref/nix-shell#options) add a `--command \"echo hello; return\"` to our `nix-shell` invocation.\r\n  - For the unified CLI: not sure yet, we might need to do something like this example from the [docs](https://nix.dev/manual/nix/2.19/command-ref/new-cli/nix3-shell): ` nix shell nixpkgs#gnumake --command sh -c \"cd src && make\"`\r\n- We should expose a couple of flags for users to configure this.\r\n  - `disable_unified_cli` (boolean)\r\n  - `disable_original_cli` (boolean)\r\n- As far as I can tell, the `command-not-found` db doesn't really play nice if you use flakes to configure your system and might return stale results (unless you update it manually?). [`nix-index`](https://github.com/nix-community/nix-index) seems to be the go-to alternative. It'd be great if we could optionally use that instead (perhaps behind a flag `enable_nix_index` for users who have installed `nix-index` (`programs.nix-index.enable = true;` in home manager).",
    "label": null
  },
  {
    "index": 181,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "@thenbe i agree integrating with `nix-index`'s `command-not-found` replacement seems cool, as a flake user.\r\ni kinda wish we could have `command-not-found` (and this `thefuck` integration) [extend to flake inputs beyond nixpkgs](https://github.com/nix-community/nix-index/issues/244) as well, such as to packages from NUR for example. preferably this should be dynamic based on your inputs rather than hardcoded to specific ones like nixpkgs, or NUR for that matter.\r\ni'll admit i haven't really figured out how that might work tho.",
    "label": null
  },
  {
    "index": 182,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "just tried these with a command like `program_i_have | program_i_dont_have`, seems that may complicate the suggestions a bit",
    "label": null
  },
  {
    "index": 183,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "I'm not sure if `thefuck` can handle piping.\r\n\r\nIf I make a typo `git statis` it will correct me to `git status`. But if I do `echo hello | git statis` it does not correct my typo. `thefuck` seems to work mostly on single commands AFAICT.\r\n",
    "label": null
  },
  {
    "index": 184,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "@thenbe hm, i'm not sure.\r\n\r\n```\r\nfortune | cowsay\r\nThe program 'cowsay' is not in your PATH. It is provided by several packages.\r\nYou can make it available in an ephemeral shell by typing one of the following:\r\n  nix-shell -p cowsay\r\n  nix-shell -p neo-cowsay\r\n$ fuck\r\nnix run nixpkgs#fortune | cowsay\r\n```\r\n\r\nfeels like it knows about the whole command given it's reproducing it?\r\n",
    "label": null
  },
  {
    "index": 185,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "another common nix thing we might be able to address from `thefuck` would be errors about packages being unfree\r\n\r\nedit: https://github.com/KiaraGrouwstra/thefuck/commit/16d838bf6f63117b161a2f1e6572e06108b007eb\r\n",
    "label": null
  },
  {
    "index": 186,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "@thenbe what was the argument to favor `nix run` over `nix shell` again? i guess the latter seems a bit more generic in case of handling non-standard binaries at least",
    "label": null
  },
  {
    "index": 187,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "If I'm only looking to execute a program (and don't need to be dropped into a shell) then I prefer `nix run` over `nix shell` as the [documentation](https://nix.dev/manual/nix/2.19/command-ref/new-cli/nix3-run) suggests `nix run` specifically for this use case.\r\n\r\nI also recall `nix run` being more performant (perhaps because we forego the overhead of launching a shell?). This last point is not derived from benchmarks, only anecdotal evidence.\r\n\r\n> i guess the latter seems a bit more generic in case of handling non-standard binaries at least\r\n\r\nI've added this variant (the 4th one in my [previous post](https://github.com/nvbn/thefuck/pull/1393#issuecomment-1961487094)), but disabled it after a while when I realized that I never reach for it. Do you find that you still need it over `nix run` (the 1st variant in my previous post)?",
    "label": null
  },
  {
    "index": 188,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "> another common nix thing we might be able to address from `thefuck` would be errors about packages being unfree\r\n> \r\n> edit: [KiaraGrouwstra@16d838b](https://github.com/KiaraGrouwstra/thefuck/commit/16d838bf6f63117b161a2f1e6572e06108b007eb)\r\n\r\nThis would be useful. Does it still complain about the `--impure` flag? Or do you use a workaround for that?",
    "label": null
  },
  {
    "index": 189,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "i've been using `thefuck` mostly thru its [`zsh` plugin](https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/thefuck), which just gets you the top suggestion. i found that failed for me for e.g. `poppler_utils`, which bundles multiple binaries.\r\nto be fair tho, i'm not sure that accounts for a large portion of its invocations, so maybe it could make sense to just actually type out `fuck` in those cases.\r\n\r\nwhat was the `--impure` error? i'm not sure i'd run into that.\r\n\r\nby the way, had you managed to also package your branch for nix? considering i seemed to need that `doCheck = false;` to get our branches to build thru nix.\r\n",
    "label": null
  },
  {
    "index": 190,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "I just have it aliased to `f` for extra convenience.\r\n\r\nI opted not to package it for nix separately since `fuck` already exposes a method for easily adding custom rules. Instead, I placed the rule in `~/mydotfiles/thefuck/rules/nix-shell.py` then told home-manager to symlink it to the appropriate place in `.config`:\r\n\r\n```nix\r\n# home.nix\r\nhome.file.\".config/thefuck/rules/nix-shell.py\".source = config.lib.file.mkOutOfStoreSymlink \"${config.home.homeDirectory}/mydotfiles/thefuck/rules/nix-shell.py\";\r\n```\r\n\r\nThis way I don't need to rebuild every time I tweak the rule.\r\n\r\n> what was the --impure error?\r\n\r\nThe unified CLI commands (`nix shell`, `nix run`, etc) will not acknowledge environment variables unless the `--impure` flag is used.\r\n\r\n<details>\r\n  <summary> output </summary>\r\n\r\n```\r\n$ NIXPKGS_ALLOW_UNFREE=1 nix shell nixpkgs#github-copilot-cli\r\n\r\nerror:\r\n       ‚Ä¶ in the condition of the assert statement\r\n\r\n         at /nix/store/xwc3zfc544jg6zhr0wi6k8253s7mwlhi-source/lib/customisation.nix:267:17:\r\n\r\n          266|     in commonAttrs // {\r\n          267|       drvPath = assert condition; drv.drvPath;\r\n             |                 ^\r\n          268|       outPath = assert condition; drv.outPath;\r\n\r\n       ‚Ä¶ while evaluating the attribute 'handled'\r\n\r\n         at /nix/store/xwc3zfc544jg6zhr0wi6k8253s7mwlhi-source/pkgs/stdenv/generic/check-meta.nix:490:7:\r\n\r\n          489|       # or, alternatively, just output a warning message.\r\n          490|       handled =\r\n             |       ^\r\n          491|         (\r\n\r\n       (stack trace truncated; use '--show-trace' to show the full trace)\r\n\r\n       error: Package ‚Äògithub-copilot-cli-0.1.36‚Äô in /nix/store/xwc3zfc544jg6zhr0wi6k8253s7mwlhi-source/pkgs/tools/misc/github-copilot-cli/default.nix:21 has\r\n an unfree license (‚Äòunfree‚Äô), refusing to evaluate.\r\n\r\n       a) To temporarily allow unfree packages, you can use an environment variable\r\n          for a single invocation of the nix tools.\r\n\r\n            $ export NIXPKGS_ALLOW_UNFREE=1\r\n\r\n          Note: When using `nix shell`, `nix build`, `nix develop`, etc with a flake,\r\n                then pass `--impure` in order to allow use of environment variables.\r\n\r\n       b) For `nixos-rebuild` you can set\r\n         { nixpkgs.config.allowUnfree = true; }\r\n       in configuration.nix to override this.\r\n\r\n       Alternatively you can configure a predicate to allow specific packages:\r\n         { nixpkgs.config.allowUnfreePredicate = pkg: builtins.elem (lib.getName pkg) [\r\n             \"github-copilot-cli-0.1.36\"\r\n           ];\r\n         }\r\n\r\n       c) For `nix-env`, `nix-build`, `nix-shell` or any other Nix command you can add\r\n         { allowUnfree = true; }\r\n       to ~/.config/nixpkgs/config.nix.\r\n\r\n\r\n```\r\n```bash\r\n# it wants this instead:\r\n$ NIXPKGS_ALLOW_UNFREE=1 nix shell nixpkgs#github-copilot-cli --impure\r\n```\r\n\r\n</details>\r\n",
    "label": null
  },
  {
    "index": 191,
    "pr title": "feat: new rule for `nix-shell`",
    "comment": "aah i see! i'd yet to take that into account. üôà\r\n\r\nspecifying the rules rather than doing overlays makes sense - thanks!\r\n",
    "label": null
  },
  {
    "index": 192,
    "pr title": "start work on -y",
    "comment": "To have it implemented the way we discussed earlier ‚Äì at shell alias/function level ‚Äì it would involve rewriting the shell alias ‚Äì i.e. [`Fish.app_alias()`](https://github.com/nvbn/thefuck/blob/51415a5cb1ca6955fb99908e7d0e7bf012a66312/thefuck/shells/fish.py#L21) ‚Äì¬†in order to make it conditionally set `THEFUCK_REQUIRE_CONFIRMATION` to `0` prior to calling `thefuck ...`.\n",
    "label": null
  },
  {
    "index": 193,
    "pr title": "start work on -y",
    "comment": "Aha, it's there, I interpreted your comment differently!\n",
    "label": null
  },
  {
    "index": 194,
    "pr title": "start work on -y",
    "comment": "Great!\n\nps.: I'm pondering how this could be done in the Bash alias, for instance.\n",
    "label": null
  },
  {
    "index": 195,
    "pr title": "start work on -y",
    "comment": "Okay, so @scorphus, I found how to add a fish argument, but where should this be documented, tested?\n\ncontains in `fish`: https://fishshell.com/docs/current/commands.html#contains-example\n",
    "label": null
  },
  {
    "index": 196,
    "pr title": "start work on -y",
    "comment": "[![Coverage Status](https://coveralls.io/builds/7153857/badge)](https://coveralls.io/builds/7153857)\n\nCoverage remained the same at 92.304% when pulling **ff5372e288c370efd17d8f968daa847e933f23fe on Haroenv:feat/option-y-override-verification** into **51415a5cb1ca6955fb99908e7d0e7bf012a66312 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 197,
    "pr title": "start work on -y",
    "comment": "[![Coverage Status](https://coveralls.io/builds/7153857/badge)](https://coveralls.io/builds/7153857)\n\nCoverage remained the same at 92.304% when pulling **ff5372e288c370efd17d8f968daa847e933f23fe on Haroenv:feat/option-y-override-verification** into **51415a5cb1ca6955fb99908e7d0e7bf012a66312 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 198,
    "pr title": "start work on -y",
    "comment": "For powershell, something like [switch](https://social.technet.microsoft.com/Forums/windowsserver/en-US/2961ae65-d7d9-4c1d-bdf2-505273925ccc/advanced-functions-flags?forum=winserverpowershell) could be used (but I don't know how it finds out what the name of the flag is\n",
    "label": null
  },
  {
    "index": 199,
    "pr title": "start work on -y",
    "comment": "In `bash` (probably the other shells as well, seeing they're aliases instead of functions too) it'll need to be replaced by a [function](http://apple.stackexchange.com/a/51010/98431)\n",
    "label": null
  },
  {
    "index": 200,
    "pr title": "start work on -y",
    "comment": "> [‚Ä¶] I found how to add a fish argument, but where should this be documented, tested? [‚Ä¶]\n\nThere are some [funcitonal tests ](https://github.com/nvbn/thefuck/tree/51415a5cb1ca6955fb99908e7d0e7bf012a66312/tests/functional) that could include tests for the new `-y` functionality.\n\n> For powershell, something like [switch](https://social.technet.microsoft.com/Forums/windowsserver/en-US/2961ae65-d7d9-4c1d-bdf2-505273925ccc/advanced-functions-flags?forum=winserverpowershell) could be used (but I don't know how it finds out what the name of the flag is\n\nLooks like it'll work. Maybe @MattKotsenas could chime in and shed some light on the matter?\n\n> In `bash` (probably the other shells as well, seeing they're aliases instead of functions too) it'll need to be replaced by a [function](http://apple.stackexchange.com/a/51010/98431)\n\nYeah, that's the critical change, I think. Not sure how much it impacts on the way TheFuck is set up by users and [tools](https://github.com/Bash-it/bash-it/blob/7415134878b8b01015c9a9fdbc66b784db02ff65/aliases/available/fuck.aliases.bash) alike.\n\nPerhaps there should be a `--function` argument that always creates a `function`. Then we can leave `--alias` functionality untouched. What do you think?\n",
    "label": null
  },
  {
    "index": 201,
    "pr title": "start work on -y",
    "comment": "I just realised that this would unset the confirmation for everything after once `-y`, will need `else` and setting it back to the default. (or setting it to the default at the end of the command maybe?)\n",
    "label": null
  },
  {
    "index": 202,
    "pr title": "start work on -y",
    "comment": "Here's [another example](https://github.com/robbyrussell/oh-my-zsh/blob/a7e30b26baa94bac99d9d05cf642bd1942ae1787/plugins/thefuck/thefuck.plugin.zsh#L7) of a tool that uses TheFuck.\n\nThinking it again, on most cases there won't be any problems creating a `function` instead of an `alias`. Let me recall how users used to set them.\n",
    "label": null
  },
  {
    "index": 203,
    "pr title": "start work on -y",
    "comment": "> [‚Ä¶] setting it back to the default [‚Ä¶]\n\nThat might be unnecessary. It should be an _in-command-variable_, something like:\n\n``` fish\n# middle of Fish alias\nif dash_y\n  env THEFUCK_REQUIRE_CONFIRMATION=0 TF_ALIAS=fuck PYTHONIOENCODING=utf-8 thefuck <cmd>\nelse\n  env TF_ALIAS=fuck PYTHONIOENCODING=utf-8 thefuck <cmd>\nend\n# ‚Ä¶\n```\n",
    "label": null
  },
  {
    "index": 204,
    "pr title": "start work on -y",
    "comment": "Since [aliases changed in 1.34](https://github.com/nvbn/thefuck#update) and are defined with `eval \"$(thefuck --alias)\"` I think we might be okay changing it to a `function`.\n\n/cc @nvbn any concerns?\n",
    "label": null
  },
  {
    "index": 205,
    "pr title": "start work on -y",
    "comment": "Oh-My-Fish [TheFuck plugin](https://github.com/oh-my-fish/plugin-thefuck/blob/86f7e1b720f8395964f348f601b4b8fd9a1cf671/functions/fuck.fish), for example, will need to be updated to support this feature, although it would continue to work nonetheless.\n",
    "label": null
  },
  {
    "index": 206,
    "pr title": "start work on -y",
    "comment": "[![Coverage Status](https://coveralls.io/builds/7156314/badge)](https://coveralls.io/builds/7156314)\n\nCoverage decreased (-0.5%) to 91.828% when pulling **a97416272c65f4fa7aa5a8b4e81e7d77756c1de3 on Haroenv:feat/option-y-override-verification** into **51415a5cb1ca6955fb99908e7d0e7bf012a66312 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 207,
    "pr title": "start work on -y",
    "comment": "[![Coverage Status](https://coveralls.io/builds/7161601/badge)](https://coveralls.io/builds/7161601)\n\nCoverage remained the same at 92.304% when pulling **c02357c58f3386dc272f19b55efcfedd57e25756 on Haroenv:feat/option-y-override-verification** into **51415a5cb1ca6955fb99908e7d0e7bf012a66312 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 208,
    "pr title": "start work on -y",
    "comment": "@Haroenv: the condition can be written like this:\n\n``` fish\ncontains -- \"-y\" $argv; and set -lx THEFUCK_REQUIRE_CONFIRMATION 0\n```\n- `l`: sets the variable locally ‚Äì it is bound to the funciton scope only\n- `x`: exports the variable to sibling processes ‚Äì¬†`thefuck` will be able to read it\n",
    "label": null
  },
  {
    "index": 209,
    "pr title": "start work on -y",
    "comment": "[![Coverage Status](https://coveralls.io/builds/7167243/badge)](https://coveralls.io/builds/7167243)\n\nCoverage remained the same at 92.304% when pulling **190db9407cb55a3a40c3a892ba7893cc94d10e37 on Haroenv:feat/option-y-override-verification** into **51415a5cb1ca6955fb99908e7d0e7bf012a66312 on nvbn:master**.\n",
    "label": null
  },
  {
    "index": 210,
    "pr title": "start work on -y",
    "comment": "Maybe it can be a bit simpler, just a different alias like:\n\n``` bash\nalias fuckit='THEFUCK_REQUIRE_CONFIRMATION=0 fuck'\n```\n\n?\n",
    "label": null
  },
  {
    "index": 211,
    "pr title": "start work on -y",
    "comment": "That seems like a great idea, should need to check if that saves the variable or if it uses it just once though. Using fuckit as a new alias makes sense\n",
    "label": null
  },
  {
    "index": 212,
    "pr title": "üåê Add Ukrainian translation for `docs/uk/docs/index.md`",
    "comment": "üåê Add Ukrainian translation for docs/uk/docs/index.md",
    "label": null
  },
  {
    "index": 213,
    "pr title": "üåê Add Ukrainian translation for `docs/uk/docs/index.md`",
    "comment": "> –î—É–∂–µ –∫—Ä—É—Ç–æ, —Ç—ñ–ª—å–∫–∏ —Ö–æ—Ç—ñ–≤ —Å—ñ—Å—Ç–∏ –∑–∞ –ø–µ—Ä–µ–∫–ª–∞–¥ —è–∫ –±–∞—á—É –≤–∏ –≤–∂–µ –ø–æ—á–∞–ª–∏. –î–æ–¥–∞–≤ –∫—ñ–ª—å–∫–∞ –∞–π—Ç–µ–º—ñ–≤ —Å—Ç–æ—Å–æ–≤–Ω–æ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É. –ù–∞–¥—ñ—é—Å—è –≤–æ–Ω–∏ –±—É–ª–∏ –∫–æ—Ä–∏—Å–Ω–∏–º–∏ —ñ –≤–∏ –ø–æ–≥–æ–¥–∂—É—î—Ç–µ—Å—è. –©–µ —Ä–∞–∑ –¥—è–∫—É—é –∑–∞ –ø—Ä–æ—Ä–æ–±–ª–µ–Ω—É —Ä–æ–±–æ—Ç—É\r\n\r\n–î—è–∫—É—é –∑–∞ –¥–æ–ø–æ–º–æ–≥—É! –ü–æ–≥–æ–¥–∂—É—é—Å—å –∑ –í–∞—à–∏–º–∏ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è–º–∏. –Ø–∫—â–æ –±–∞–∂–∞—î—Ç–µ –ø—Ä–∏—î–¥–Ω–∞—Ç–∏—Å—è –¥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É - —Ü–µ —Å—É–ø–µ—Ä, –º–æ–∂–µ–º–æ —Ä–æ–∑–¥—ñ–ª–∏—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—é –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏ —ñ —Ä–æ–±–∏—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥ —Ä–∞–∑–æ–º.",
    "label": null
  },
  {
    "index": 214,
    "pr title": "üåê Add Ukrainian translation for `docs/uk/docs/index.md`",
    "comment": "> > –î—É–∂–µ –∫—Ä—É—Ç–æ, —Ç—ñ–ª—å–∫–∏ —Ö–æ—Ç—ñ–≤ —Å—ñ—Å—Ç–∏ –∑–∞ –ø–µ—Ä–µ–∫–ª–∞–¥ —è–∫ –±–∞—á—É –≤–∏ –≤–∂–µ –ø–æ—á–∞–ª–∏. –î–æ–¥–∞–≤ –∫—ñ–ª—å–∫–∞ –∞–π—Ç–µ–º—ñ–≤ —Å—Ç–æ—Å–æ–≤–Ω–æ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É. –ù–∞–¥—ñ—é—Å—è –≤–æ–Ω–∏ –±—É–ª–∏ –∫–æ—Ä–∏—Å–Ω–∏–º–∏ —ñ –≤–∏ –ø–æ–≥–æ–¥–∂—É—î—Ç–µ—Å—è. –©–µ —Ä–∞–∑ –¥—è–∫—É—é –∑–∞ –ø—Ä–æ—Ä–æ–±–ª–µ–Ω—É —Ä–æ–±–æ—Ç—É\r\n> \r\n> –î—è–∫—É—é –∑–∞ –¥–æ–ø–æ–º–æ–≥—É! –ü–æ–≥–æ–¥–∂—É—é—Å—å –∑ –í–∞—à–∏–º–∏ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è–º–∏. –Ø–∫—â–æ –±–∞–∂–∞—î—Ç–µ –ø—Ä–∏—î–¥–Ω–∞—Ç–∏—Å—è –¥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É - —Ü–µ —Å—É–ø–µ—Ä, –º–æ–∂–µ–º–æ —Ä–æ–∑–¥—ñ–ª–∏—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—é –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏ —ñ —Ä–æ–±–∏—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥ —Ä–∞–∑–æ–º.\r\n\r\n–ó–≤—ñ—Å–Ω–æ —è —Ç—ñ–ª—å–∫–∏ –∑–∞. –î–∞–≤–∞–π—Ç–µ –∑–≤—è–∂–µ–º–æ—Å—è —ñ —Ä–æ–∑–¥—ñ–ª–∏–º–æ –ø–µ—Ä–µ–∫–ª–∞–¥. @python4eg –º—ñ–π –Ω—ñ–∫ –≤ —Ç–µ–ª–µ–≥—Ä–∞–º—ñ",
    "label": null
  },
  {
    "index": 215,
    "pr title": "üåê Add Ukrainian translation for `docs/uk/docs/index.md`",
    "comment": "@ilkuzmenko Hey, you made a huge work there, are you able to finish this? I could approve this after fixing the comments that were left by reviewers. Or if you are not able or don't want to work on it anymore can I do my own based on your?\r\nP.S. Hope you are okay now",
    "label": null
  },
  {
    "index": 216,
    "pr title": "üåê Add Ukrainian translation for `docs/uk/docs/index.md`",
    "comment": "@rostik1410 let me know if you need any help ",
    "label": null
  },
  {
    "index": 217,
    "pr title": "üåê Add Ukrainian translation for `docs/uk/docs/index.md`",
    "comment": "As this PR had requested changes to be applied but has been inactive for a while, it's now going to be closed. But if there's anyone interested, feel free to create a new PR.",
    "label": null
  },
  {
    "index": 218,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit 121e6d6a9ed2176615b308489cc8953790ab72ff at: https://88cd7bfd.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 219,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit 88c6d84911a4bc17f7fe3723ff57e9f692ddf492 at: https://8d96dfce.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 220,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit ced982a7a3f540bbad91a844e4b55bf9b220294f at: https://8e3e519d.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 221,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit 03e7b2dfda6779e5c4db649dd11bd52439ae0152 at: https://fd75c3b9.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 222,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit 49c0ceb5a3704f6c06b4df44385abc0d0fcda15b at: https://2cdb64e8.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 223,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit 7b9dfc3be6b7180d1ead298b4df5030869b7c8d7 at: https://b36663fa.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 224,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit add6aa7b5cf12e2d9ba722eb3e84363c13e07309 at: https://8d3d0eae.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 225,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit dca64ba1cd69184188f2898bc0aabeb43122cff1 at: https://04ac286b.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 226,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit ada79e684085b8f762522a9def6039de04510030 at: https://0140430d.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 227,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit 4c871702a100bfe668513ebd1c24762f53c8f910 at: https://01de0dd0.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 228,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "üìù Docs preview for commit 4b2019ee4a07accf2746394cb3f5b16fba011b3d at: https://eef7d8e2.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 229,
    "pr title": ":globe_with_meridians: Add Turkish translation for `docs/tr/docs/alternatives.md`",
    "comment": "Nice! Thanks @alperiox ü§ìüöÄ \r\n\r\nAnd thanks for your help @hasansezertasan ü•≥üíØ ",
    "label": null
  },
  {
    "index": 230,
    "pr title": "üåê Update Turkish translation for `docs/tr/docs/python-types.md`",
    "comment": "üìù Docs preview for commit 018703a41b7236195f10c1bdefa04b228f387071 at: https://149a3713.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 231,
    "pr title": "üåê Update Turkish translation for `docs/tr/docs/python-types.md`",
    "comment": "Geri d√∂n√º≈üler i√ßin te≈üekk√ºrler.",
    "label": null
  },
  {
    "index": 232,
    "pr title": "üåê Update Turkish translation for `docs/tr/docs/python-types.md`",
    "comment": "üìù Docs preview for commit 574596ceaae7cbb1447a4868e518111dab393a15 at: https://6b65633d.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 233,
    "pr title": "üåê Update Turkish translation for `docs/tr/docs/python-types.md`",
    "comment": "üìù Docs preview for commit aba7b4cb9f46728322e1d84f78563990f670ee9a at: https://461f92ef.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 234,
    "pr title": "üåê Update Turkish translation for `docs/tr/docs/python-types.md`",
    "comment": "üìù Docs preview for commit 1a6ae53e896e361c456c19dc8395861c130024f4 at: https://3aad993a.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 235,
    "pr title": "üåê Update Turkish translation for `docs/tr/docs/python-types.md`",
    "comment": "As this PR had requested changes to be applied but has been inactive for a while, it's now going to be closed. But if there's anyone interested, feel free to create a new PR.",
    "label": null
  },
  {
    "index": 236,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit 1ad46b67e6dc33ffb1178d18a86c922aae69b44a at: https://6489918cc356c5078c7143d3--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 237,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit cb8277b848f98da3dca93934efbf2e9afcee516a at: https://6489a1b7cb6e8811f92dc3e4--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 238,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit 40c1afec5cf87a49b12596d35a282d182d679c90 at: https://648c2ed97897085123307603--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 239,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit e8137f6f049b9b0580269782f05339ef99be56ad at: https://648c39c1546bc455bcbe061a--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 240,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit 481e4826b1222d63127d1a49cbee546163e6e22e at: https://648c3d3362aae25b60aaa027--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 241,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit 6aabbb641b1cf022cb863ccb90dbe29dd57edb0c at: https://648c41322c8d36602e0da830--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 242,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit 7e008fbad029c8948821cdae7cf08889c299d868 at: https://64905a8944734c66b54f1453--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 243,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit 3159e9fe77a6880746e306c69697e4bc6f6eb63d at: https://64905c2c44734c676c4f14dd--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 244,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit aa88cafcf0ce37179d67c54413b803e896ec7f03 at: https://64905d8e72e8806ce36e030c--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 245,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit 410e5a4eb9c1fbdabdebc01c6f010987975e0ac0 at: https://649472f6b121c94bf1ab2b91--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 246,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "üìù Docs preview for commit 55b6d628fb9b975c60311c61dc4311c28fd724f8 at: https://649a3167b8e96720081c1f8a--fastapi.netlify.app",
    "label": null
  },
  {
    "index": 247,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/response-model.md`",
    "comment": "Awesome, thanks @glsglsgls! üöÄ \r\n\r\nAnd thanks for the reviews @ivan-abc and @Alexandrhub üôá ‚òï ",
    "label": null
  },
  {
    "index": 248,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "üìù Docs preview for commit 3a0d3836b5a53cc11b6946e60eb9b5d7ef3d75f0 at: https://15e5624d.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 249,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Hello, @tiangolo \r\n\r\nWe want to create the language for zh-hant (Mandarin), but the language will be limited to 2 letters. What are your recommended approaches for handling languages that have more than two letters?",
    "label": null
  },
  {
    "index": 250,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Thanks @hsuanchi! Up to now, I've avoided language localizations as there aren't yet enough translations of the first language, for example, for `pt-PT`.\r\n\r\nThe first question would be, how different is it from `zh`? Would `zh` not be understandable by people who speak `zh-hant`?\r\n\r\nThe second question is, are there others (at least other two, in total with you at least three) that are willing to help with those translations to `zh-hant`? Because I need to get 2 approvals to merge, and if there are now two variants of `zh`, it's probably gonna be even more difficult to get approvals for both.\r\n\r\nThere are currently 63 PRs for `zh` awaiting for reviewers: https://github.com/tiangolo/fastapi/pulls?q=is%3Apr+is%3Aopen+sort%3Aupdated-desc+label%3Alang-zh\r\n\r\nLet me know what you think!",
    "label": null
  },
  {
    "index": 251,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Hello @tiangolo ,\r\n\r\nThank you for your swift reply. To address your first question, zh is generally considered to be Simplified Chinese (zh-hans), while zh-hant refers to Traditional Chinese. Although the two variants share similarities, they differ significantly in terms of characters and some terminology. People from regions such as Taiwan, Hong Kong, and Macau typically use zh-hant and may find zh less intuitive to read.\r\n\r\nAs for your second question, we have a robust team of over 10 developers who use FastAPI on a daily basis. Some of our members have also contributed to the Traditional Chinese translation of Python documentation ([python-docs-zh-tw](https://github.com/python/python-docs-zh-tw)). We're confident that we'll be able to efficiently review and contribute to the zh-hant localization for FastAPI.\r\n\r\nThank you once again, and looking forward to your reply.",
    "label": null
  },
  {
    "index": 252,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Hi @tiangolo ,\r\n\r\nI would like to kindly inform you that I am part of the same team as @hsuanchi , and we are wholeheartedly dedicated to supporting the translation of the content into `zh-hant`. Let's collaborate to make it even more exceptional!",
    "label": null
  },
  {
    "index": 253,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "I'm an avid user of FastAPI and would be thrilled to review @hsuanchi  's translation. Additionally, I'd be honored to contribute to the translation efforts for FastAPI, aiming to make it even more accessible and developer-friendly for the Chinese-speaking community.\"",
    "label": null
  },
  {
    "index": 254,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Fastapi basically consists of my day-to-day life and I'm confident that I can dedicate myself to contributing to the translations to zh-hant as zh-hant is my first language.\r\nIt'd be my pleasure to review @hsuanchi's translation and make the development of Fastapi more friendly to the Chinese-speaking community.",
    "label": null
  },
  {
    "index": 255,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Hello @tiangolo,\r\n\r\nI am in the same team as @hsuanchi. I am very eager to assist in the zh-hant localization to make FastAPI more accessible for the Traditional Chinese community. Looking forward to hearing from you!",
    "label": null
  },
  {
    "index": 256,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "I am a user of FastAPI from Taiwan, and I am very eager to promote FastAPI among Traditional Chinese-speaking users. This way, more users can read the documentation in their native language, which would lower the barrier to entry.",
    "label": null
  },
  {
    "index": 257,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Hi @tiangolo,\r\n\r\nIf I could contribute to the translation efforts of FastAPI, making community documents more clear and intuitive for developers using the zh-hant language, I find it highly meaningful.",
    "label": null
  },
  {
    "index": 258,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Dear @tiangolo,\r\n\r\nI am extremely excited and looking forward to seeing FastAPI in Traditional Chinese. The purpose of this initiative is to assist developers in Taiwan in using and understanding FastAPI more easily. We are committed to continuing to support and contribute to FastAPI.",
    "label": null
  },
  {
    "index": 259,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "As a software engineer from Hong Kong and Taiwan, I can tell that FastAPI is important for Traditional Chinese software community, we have a large community here working on Python with FastAPI in Taiwan.\r\n\r\nCan't wait to see more Traditional Chinese resources and contributions so FastAPI can be widely promoted.",
    "label": null
  },
  {
    "index": 260,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Traditional Chinese (`zh_hant`) and Simplified Chinese (`zh_hans`) are different *writing systems* of Chinese. Both are categorized under the `zh` code in ISO 639-1, and using this two-character code alone is insufficient to differentiate between the two. (Similarly, I'd say the term \"Mandarin\" in the PR title is not accurate enough.) They have different histories and cultures. Both are official in their regions and are widely used with rich literature and media. Their users generally have a strong preference for one writing system over the other based on their background. Though Mandarin is mostly spoken in both regions that use Traditional and Simplified Chinese characters, regional variations exist between both systems.\r\n\r\nIn the field of software technical document translation, many prominent resources offer both Traditional and Simplified Chinese versions simultaneously. Examples include [Python docs](https://docs.python.org/zh-tw/3/), [MDN docs](https://developer.mozilla.org/zh-TW/), [Microsoft docs](https://learn.microsoft.com/zh-tw/docs/), [AWS docs](https://docs.aws.amazon.com/zh_tw/), [React docs](https://zh-hant.legacy.reactjs.org/), [Angular docs](https://angular.tw/), and more. Although the momentum for zh_hant translation might not be as extensive as zh_hans, it's undeniable that Traditional Chinese is a legitimate and important language version for software documents.\r\n\r\nAs a Python backend engineer and a member of the Python document translation community, I'm more than willing to help with translating the FastAPI doc or reviewing for the translation PRs. (Actually, [I tried once before](https://github.com/tiangolo/fastapi/discussions/9758) lol).\r\n",
    "label": null
  },
  {
    "index": 261,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Hi @tiangolo , \r\n\r\nI am a software engineer who works with @hsuanchi. I understand your concern about the use of Traditional Chinese (`zh-Hant`) for translations. Here's a more detailed explanation of why it's essential to consider using `zh-Hant` for FastAPI translations:\r\n\r\n`zh-Hant`, which represents Traditional Chinese, is crucial for ensuring the accessibility and readability of FastAPI content for a specific audience. Traditional Chinese characters are primarily used in regions like Taiwan, Hong Kong, and among overseas Chinese communities. If your project has users in these areas or if your goal is to be inclusive of these regions, providing translations in `zh-Hant` is a necessity.\r\n\r\nHere's why `zh-Hant` matters:\r\n1. **Cultural Sensitivity**: Using Traditional Chinese characters is a matter of cultural sensitivity and respect. Some users in regions where Traditional Chinese is the norm may find it more comfortable and culturally appropriate when content is presented in `zh-Hant`.\r\n\r\n2. **Audience Reach**: Including `zh-Hant` extends your reach and ensures that FastAPI is accessible to a broader audience. It allows you to engage users who may prefer or are more familiar with Traditional Chinese characters.\r\n\r\n3. **User Experience**: Users tend to have a better user experience when content is in their preferred language variant. It enhances user satisfaction and encourages adoption.\r\n\r\nIn summary, providing translations in `zh-Hant` alongside `zh` is a strategic move to make FastAPI more inclusive, culturally sensitive, and user-friendly for a wider audience. It demonstrates your commitment to engaging with users from different regions and respecting their language and cultural preferences.\r\n\r\nWe hope you consider the importance of using `zh-Hant` as part of the translation efforts for FastAPI. Thank you for your understanding and support.",
    "label": null
  },
  {
    "index": 262,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Hi @tiangolo,  are there any updates? Are we ready to begin work on the Traditional Chinese version?\r\n\r\n\r\n\r\n\r\n\r\n",
    "label": null
  },
  {
    "index": 263,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "üìù Docs preview for commit 84b953ba9a18cb60f296ae9bdbdada60937e7562 at: https://3397a9ff.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 264,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "üìù Docs preview for commit 953ad1489ace9cae73f2fdcf3dfa1df4e94aec20 at: https://b5531961.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 265,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "> Here is the initial review of the translation part.\r\n\r\nThanks for helping with the review ü´°ü´°ü´°, all amendments are now complete.",
    "label": null
  },
  {
    "index": 266,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "üìù Docs preview for commit 73e95a72238dfc79c8d895ced60692e6fd8839a9 at: https://d5229374.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 267,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "üìù Docs preview for commit 66cba69728d587ee07cbb3b08168e0c252f9e50f at: https://c9489c35.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 268,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Amazing! If you all work together you could have all the FastAPI docs translated to Traditional Chinese in no time! üéâ \r\n\r\nI updated the script to handle docs to take this into account, and I added this discussion: https://github.com/tiangolo/fastapi/discussions/10949\r\n\r\nWhen there's a new PR for Traditional Chinese and I add the label, it will be automatically posted there. You could subscribe to that discussion to get notified when there's a new PR to review. ü§ì \r\n\r\nThank you all for your help!\r\n\r\nOnce this PR is ready and has two approving reviews I'll merge it. The same with the next future PRs. üöÄ ",
    "label": null
  },
  {
    "index": 269,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "üìù Docs preview for commit efc2197589ec94dda13015d4a17d80d9bc4b6334 at: https://be6f65a0.fastapitiangolo.pages.dev",
    "label": null
  },
  {
    "index": 270,
    "pr title": "üåê Initialize translations for Traditional Chinese",
    "comment": "Awesome, thank you @hsuanchi ! üç∞ \r\n\r\nAnd thanks for the reviews @SonnyYou, @mattwang44 ‚òï üç™ ",
    "label": null
  },
  {
    "index": 271,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/security/simple-oauth2.md`",
    "comment": "Do you happen to know three Russian developers you can ask a [PR review](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/requesting-a-pull-request-review) from? [This](https://github.com/tiangolo/fastapi/pulls?q=is%3Apr+is%3Aopen+Russian) might help.",
    "label": null
  },
  {
    "index": 272,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/security/simple-oauth2.md`",
    "comment": "@Xewus, @s111d –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å —Å —Ä–µ–≤—å—é. –ü–æ–¥–∫–ª—é—á–∞–π—Ç–µ—Å—å!\r\n:wave: :blush: ",
    "label": null
  },
  {
    "index": 273,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/security/simple-oauth2.md`",
    "comment": "Hi @AlertRED, I have updated the documentation with the latest syntax for `includes`.\r\nI will wait for you to review the changes suggested by @alv2017 before merging the PR. \r\nThanks to both of you for the help! :rocket: ",
    "label": null
  },
  {
    "index": 274,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/security/simple-oauth2.md`",
    "comment": "@alejsdev: Thank you for your help! \r\n\r\n@AlertRED: I think we are ready with PR, aren't we? \r\n\r\n:smiley: ",
    "label": null
  },
  {
    "index": 275,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/security/simple-oauth2.md`",
    "comment": "> @alejsdev: Thank you for your help! \n> \n> @AlertRED: I think we are ready with PR, aren't we? \n> \n> :smiley: \n\nYes, we are :)",
    "label": null
  },
  {
    "index": 276,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/security/simple-oauth2.md`",
    "comment": "–ü—Ä–æ–±–ª–µ–º–∞ —Ä–µ—à–µ–Ω–∞, —É –º–µ–Ω—è –Ω–∏–∫–∞–∫–∏—Ö –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π –±–æ–ª—å—à–µ –Ω–µ—Ç :smiley:",
    "label": null
  },
  {
    "index": 277,
    "pr title": "üåê Add Russian translation for `docs/ru/docs/tutorial/security/simple-oauth2.md`",
    "comment": "Great! Thanks for your work @AlertRED @Xewus @alv2017 :rocket: :sparkles: ",
    "label": null
  },
  {
    "index": 278,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "@dwarkeshsp have you measured any speedups compared to using the CPU?",
    "label": null
  },
  {
    "index": 279,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "Doesn't this also require switching FP16 off?",
    "label": null
  },
  {
    "index": 280,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "I'm getting this error when try to use MPS\r\n\r\n/Users/diego/.pyenv/versions/3.10.6/lib/python3.10/site-packages/whisper-1.0-py3.10.egg/whisper/decoding.py:629: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/diego/Projects/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/2d9b4df9-4b93-11ed-b0fc-2e32217d8374/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 23200 bytes\r\n'\r\nAbort trap: 6\r\n/Users/diego/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n\r\nany clues?",
    "label": null
  },
  {
    "index": 281,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "@DiegoGiovany Not an expert on this but It looks like PyTorch itself is missing some operators for MPS. See for example\r\nhttps://github.com/pytorch/pytorch/issues/77764#issuecomment-1254352628\r\n(which refers to repeat_interleave)\r\n\r\nand\r\nhttps://github.com/pytorch/pytorch/issues/87219\r\n",
    "label": null
  },
  {
    "index": 282,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "Thanks for your work. I just tried this. Unfortunately, it didn't work for me on my m1 max with 32GB.\r\nHere is what I did:\r\npip install git+https://github.com/openai/whisper.git@refs/pull/382/head\r\n\r\nNo errors on install and it works fine when run without mps: whisper audiofile_name --model medium \r\n\r\nWhen I run: whisper audiofile_name --model medium --device mps\r\n\r\nHere is the error I get:\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/810eba08-405a-11ed-86e9-6af958a02716/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1024x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s). \r\n\r\nWhen I run:  whisper audiofile_name --model medium --device mps --fp16 False\r\n\r\nHere is the error I get:\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nDetected language: English\r\n/anaconda3/lib/python3.9/site-packages/whisper/decoding.py:633: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/f0468ab4-4115-11ed-8edc-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 1007280 bytes\r\n\r\nBasically, same error as @DiegoGiovany.\r\n\r\nAny ideas on how to fix?",
    "label": null
  },
  {
    "index": 283,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "+1 for me!  I'm actually using an Intel Mac with Radeon Pro 560X 4 GB...",
    "label": null
  },
  {
    "index": 284,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "Related\r\nhttps://github.com/pytorch/pytorch/issues/87351",
    "label": null
  },
  {
    "index": 285,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "@dwarkeshsp \r\n\r\nnot workÔºåwith mbp2015 pytorch 1.3 stableÔºåegpu RX580, MacOS 12.3.\r\n\r\nchanged the code as the same as yours.\r\n\r\nchanged  to use --device mps but show error, maybe there is still somewhere to change or modify.\r\n\r\nuse --device cpu, it works.\r\n\r\nwith other pytorch-metal project, MPS works.",
    "label": null
  },
  {
    "index": 286,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "I also see the same errors as others mentioned above, on an M1 Mac running arm64 Python. ",
    "label": null
  },
  {
    "index": 287,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "On an M1 16\" MBP with 16GB running MacOS 13.0.1, I'm seeing the following with `openai-whisper-20230117`:\r\n\r\nUsing this command:\r\n```(venv) whisper_ai_playground % whisper './test_file.mp3' --model tiny.en --output_dir ./output --device mps```\r\n\r\nI'm encountering the following errors:\r\n\r\n```loc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/810eba08-405a-11ed-86e9-6af958a02716/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x384x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible```\r\n\r\n```LLVM ERROR: Failed to infer result type(s).```\r\n\r\n```zsh: abort      whisper  --model tiny.en --output_dir ./output --device mps```\r\n\r\n```/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '```",
    "label": null
  },
  {
    "index": 288,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "Is there any update on this, or did anyone figure out how to get it to work? ",
    "label": null
  },
  {
    "index": 289,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "Same problem with osx 13.2 in MacBook Pro M2 max:\r\n\r\n```\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1280x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\nzsh: abort      whisper audio.wav --language en --model large\r\nm2@Render ~ % /opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
    "label": null
  },
  {
    "index": 290,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "I'm getting the same error as @renderpci using the M1 Base Model\r\n```bash\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x512x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\n[1]    3746 abort      python3 test.py\r\n```\r\n**test.py:**\r\n```py\r\nimport whisper\r\n\r\nmodel = whisper.load_model(\"base\")\r\nresult = model.transcribe(\"audio.mp3\")\r\nprint(result[\"text\"])\r\n```",
    "label": null
  },
  {
    "index": 291,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "FWIW I switched to the C++ port https://github.com/ggerganov/whisper.cpp/ and got a ~15x speedup compared to CPU pytorch on my M1 Pro. (But note that it doesn't have all the features/flags from the official whisper repo.)",
    "label": null
  },
  {
    "index": 292,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "> FWIW I switched to the C++ port https://github.com/ggerganov/whisper.cpp/ \r\n\r\nFor us whisper.cpp is not an option:\r\n\r\n> **Should I use whisper.cpp in my project?**\r\n> \r\n> whisper.cpp is a hobby project. It does not strive to provide a production ready implementation. The main goals of the implementation is to be educational, minimalistic, portable, hackable and performant. There are no guarantees that the implementation is correct and bug-free and stuff can break at any point in the future. Support and updates will depend mostly on contributions, since with time I will move on and won't dedicate too much time on the project.\r\n> \r\n> If you plan to use whisper.cpp in your own project, keep in mind the above.\r\n> My advice is to not put all your eggs into the whisper.cpp basket.",
    "label": null
  },
  {
    "index": 293,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "The same error as @renderpci using the M2\r\n\r\n\r\nwhisper interview.mp4 --language en --model large --device mps\r\n\r\n```\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1280x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\nzsh: abort      whisper interview.mp4 --language en --model large --device mps\r\npac@dd ~ % /opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
    "label": null
  },
  {
    "index": 294,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "Hey @devpacdd  - this should be fixed in latest pytorch nightly (pip3 install --pre --force-reinstall torch --index-url https://download.pytorch.org/whl/nightly/cpu). Let me know if you still see any issues. Thanks",
    "label": null
  },
  {
    "index": 295,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "Still have the same error after updating\r\n\r\nEdit: After adding `--fp16 False` to the command, I now get a new error, as well as the old one:\r\n```\r\n/opt/homebrew/lib/python3.10/site-packages/whisper/decoding.py:633: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/5b8a32f9-5db2-11ed-8aeb-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 1007280 bytes\r\n'\r\nzsh: abort      whisper --model large --language de --task transcribe  --device mps --fp16\r\n/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
    "label": null
  },
  {
    "index": 296,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "i was able to get it to kinda work: https://github.com/davabase/whisper_real_time/issues/5#issue-1596258783",
    "label": null
  },
  {
    "index": 297,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "> The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n>   audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n\r\n@manuthebyte could you please make sure you are on a recent nightly? `repeat_interleave` should be natively supported. If you could try grabbing today's nightly and give a try that would be awesome! (You can get today's nightly with `pip3 install --pre --force-reinstall torch==2.0.0.dev20230224 --index-url https://download.pytorch.org/whl/nightly/cpu`)\r\n\r\n",
    "label": null
  },
  {
    "index": 298,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "Wow! \r\n\r\nwhen running:\r\n`Python3 transcribe_demo.py --model medium` (from https://github.com/davabase/whisper_real_time)\r\n\r\nwith the following packages in my pipenv's requirements.txt\r\n```\r\ncertifi==2022.12.7\r\ncharset-normalizer==3.0.1\r\nffmpeg-python==0.2.0\r\nfilelock==3.9.0\r\nfuture==0.18.3\r\nhuggingface-hub==0.12.1\r\nidna==3.4\r\nmore-itertools==9.0.0\r\nmpmath==1.2.1\r\nnetworkx==3.0rc1\r\nnumpy==1.24.2\r\nopenai-whisper @ git+https://github.com/openai/whisper.git@51c785f7c91b8c032a1fa79c0e8f862dea81b860\r\npackaging==23.0\r\nPillow==9.4.0\r\nPyAudio==0.2.13\r\nPyYAML==6.0\r\nregex==2022.10.31\r\nrequests==2.28.2\r\nSpeechRecognition==3.9.0\r\nsympy==1.11.1\r\ntokenizers==0.13.2\r\ntorch==2.0.0.dev20230224\r\ntorchaudio==0.13.1\r\ntorchvision==0.14.1\r\ntqdm==4.64.1\r\ntransformers==4.26.1\r\ntyping_extensions==4.4.0\r\nurllib3==1.26.14\r\n```\r\n\r\nit gets every word! while i was singing! in realtime, with maybe 50%~ gpu usage on the apple M2 Pro Max.",
    "label": null
  },
  {
    "index": 299,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "> > The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n> > audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n> \r\n> @manuthebyte could you please make sure you are on a recent nightly? `repeat_interleave` should be natively supported. If you could try grabbing today's nightly and give a try that would be awesome! (You can get today's nightly with `pip3 install --pre --force-reinstall torch==2.0.0.dev20230224 --index-url https://download.pytorch.org/whl/nightly/cpu`)\r\n\r\nWith my pip3 freeze being:\r\n```\r\nbeautifulsoup4==4.11.2\r\ncertifi==2022.12.7\r\ncharset-normalizer==3.0.1\r\ncolorama==0.4.6\r\ndnspython==2.3.0\r\nffmpeg-python==0.2.0\r\nfilelock==3.9.0\r\nfuture==0.18.3\r\nhuggingface-hub==0.12.1\r\nidna==3.4\r\nmore-itertools==9.0.0\r\nmpmath==1.2.1\r\nnetworkx==3.0rc1\r\nnumpy==1.24.2\r\nopenai-whisper @ git+https://github.com/openai/whisper.git@7858aa9c08d98f75575035ecd6481f462d66ca27\r\npackaging==23.0\r\nprotobuf==4.21.12\r\nPyYAML==6.0\r\nregex==2022.10.31\r\nrequests==2.28.2\r\nsix==1.16.0\r\nsoupsieve==2.4\r\nsympy==1.11.1\r\ntokenizers==0.13.2\r\ntorch==2.0.0.dev20230224\r\ntqdm==4.64.1\r\ntransformers==4.26.1\r\ntyping_extensions==4.4.0\r\nurllib3==1.26.14\r\n```\r\n\r\nIt now seems to use the GPU but I now get these errors:\r\n```\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:636: UserWarning: 0MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:443: UserWarning: 1MPS: no support for int64 reduction ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:143.)\r\n  timestamp_logprob = logprobs[k, self.tokenizer.timestamp_begin :].logsumexp(dim=-1)\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:444: UserWarning: 1MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:1269.)\r\n  max_text_token_logprob = logprobs[k, : self.tokenizer.timestamp_begin].max()\r\nTraceback (most recent call last):\r\n  File \"/opt/homebrew/bin/whisper\", line 8, in <module>\r\n    sys.exit(cli())\r\n             ^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 314, in cli\r\n    result = transcribe(model, audio_path, temperature=temperature, **args)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 183, in transcribe\r\n    result: DecodingResult = decode_with_fallback(segment)\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 118, in decode_with_fallback\r\n    decode_result = model.decode(segment, options)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 707, in decode\r\n    result = DecodingTask(model, options).run(mel)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 640, in run\r\n    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\r\n                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 609, in _main_loop\r\n    tokens, completed = self.decoder.update(tokens, logits, sum_logprobs)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 258, in update\r\n    next_tokens = Categorical(logits=logits / self.temperature).sample()\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/distributions/categorical.py\", line 66, in __init__\r\n    super().__init__(batch_shape, validate_args=validate_args)\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/distributions/distribution.py\", line 62, in __init__\r\n    raise ValueError(\r\nValueError: Expected parameter logits (Tensor of shape (5, 51865)) of distribution Categorical(logits: torch.Size([5, 51865])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\r\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan]], device='mps:0')\r\n```\r\n\r\nWhen running the command `whisper --model small --language en --task transcribe ***.wav --device mps`",
    "label": null
  },
  {
    "index": 300,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "> Hey @devpacdd - this should be fixed in latest pytorch nightly (pip3 install --pre --force-reinstall torch --index-url https://download.pytorch.org/whl/nightly/cpu). Let me know if you still see any issues. Thanks\r\n\r\nGeart! it works!\r\nBut.. In my test the GPU is slow than CPU... ??? \r\n\r\nAudio to transcribe: 1 minute with model large, language catalan\r\n\r\nCPU  : 2m : 33 s\r\nGPU (--device mps): 4m : 54 s\r\n\r\nI tried with different files and the result was the same; +/- double time with GPU enable.\r\n\r\nIt's normal? I expected less time for GPU than CPU.\r\n\r\nBest",
    "label": null
  },
  {
    "index": 301,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "I get this error while trying to use MPS\r\n\r\nHere is the command I am running: `whisper --model large --language en --task transcribe test.mp3 --device mps`\r\n\r\n```\r\n$ whisper --model large --language en --task transcribe test.mp3 --device mps\r\nTraceback (most recent call last):\r\n  File \"/Users/mukul/miniconda3/envs/ml/bin/whisper\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/whisper/transcribe.py\", line 433, in cli\r\n    model = load_model(model_name, device=device, download_root=model_dir)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/whisper/__init__.py\", line 159, in load_model\r\n    return model.to(device)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1170, in to\r\n    return self._apply(convert)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 869, in _apply\r\n    self._buffers[key] = fn(buf)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1168, in convert\r\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\r\nNotImplementedError: Could not run 'aten::empty.memory_format' with arguments from the 'SparseMPS' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty.memory_format' is only available for these backends: [CPU, MPS, Meta, QuantizedCPU, QuantizedMeta, MkldnnCPU, SparseCPU, SparseMeta, SparseCsrCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\r\n\r\nCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterCPU.cpp:31085 [kernel]\r\nMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMPS.cpp:24065 [kernel]\r\nMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26824 [kernel]\r\nQuantizedCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\r\nQuantizedMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterQuantizedMeta.cpp:105 [kernel]\r\nMkldnnCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMkldnnCPU.cpp:507 [kernel]\r\nSparseCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseCPU.cpp:1379 [kernel]\r\nSparseMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\r\nSparseCsrCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseCsrCPU.cpp:1128 [kernel]\r\nBackendSelect: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterBackendSelect.cpp:734 [kernel]\r\nPython: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\r\nFuncTorchDynamicLayerBackMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\r\nFunctionalize: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:290 [backend fallback]\r\nNamed: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\r\nConjugate: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\r\nNegative: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/NegateFallback.cpp:23 [kernel]\r\nZeroTensor: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:90 [kernel]\r\nADInplaceOrView: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\r\nAutogradOther: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradCUDA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradHIP: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradXLA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradIPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradXPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradHPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradVE: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradLazy: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMTIA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse1: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse2: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse3: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradNestedTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nTracer: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:16872 [kernel]\r\nAutocastCPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\r\nAutocastCUDA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\r\nFuncTorchBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:815 [backend fallback]\r\nFuncTorchVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\r\nBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1073 [backend fallback]\r\nVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\nFuncTorchGradWrapper: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\r\nPythonTLSSnapshot: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\r\nFuncTorchDynamicLayerFrontMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\r\nPythonDispatcher: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\r\n```",
    "label": null
  },
  {
    "index": 302,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "> pytorch/pytorch#87351\r\n\r\nI'd love to hear a clear update too. It looks like there will be a lot of demand for this. (Mac M2 myself) Thank you OpenAI people!",
    "label": null
  },
  {
    "index": 303,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "@mukulpatnaik \r\nMy device is M1 MacBook Pro, I got the same error with the latest version of whisper([v20230314](https://github.com/openai/whisper/releases/tag/v20230314)), then I switch to [v20230124](https://github.com/openai/whisper/releases/tag/v20230124), every thing works fine. (torch nightly version)\r\n\r\nBut, seems like mps is slower than cpu like @renderpci reported, for my task\r\n* cpu 3.26 s\r\n* mps 5.25 s\r\n* cpu+torch2 compile 3.31 s\r\n* mps+torch2 compile 4.94 s\r\n\r\nü´†",
    "label": null
  },
  {
    "index": 304,
    "pr title": "Uses MPS (Mac acceleration) by default when available",
    "comment": "@HFrost0, what's your macOS, PyTorch and Python version? Some versions support different operations, and PyTorch defaults to CPU on those. ",
    "label": null
  },
  {
    "index": 305,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "This DTW dependency introduces a licence incompatibility, but an alternative was suggested earlier in the discussions from memory.\r\n\r\nEdit: Alternative library recommended in https://github.com/openai/whisper/discussions/813#discussioncomment-4617447",
    "label": null
  },
  {
    "index": 306,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "Hi!\r\nI tried out this branch with ```kwargs['word_level_timestamps'] = True``` but the model performed very slowly. In addition (or rather because of) it started to hallucinate like mad. \r\nIm using chunks of short (couple of seconds) audio data in german produced by a VAD for live transcription.\r\n\r\nMaybe its a problem on my side, maybe anyone can try to reproduce?",
    "label": null
  },
  {
    "index": 307,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "Thanks for the comments, all -- this is work in progress and not quite ready for merging. I'm trying to address both hallucination and performance concerns.",
    "label": null
  },
  {
    "index": 308,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "Yet another DTW implementation, fyi. Can't vouch for it other than to say that it is Apache licensed, recently updated, has both pure Python and C implementations.\r\n\r\nhttps://github.com/wannesm/dtaidistance",
    "label": null
  },
  {
    "index": 309,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "Hi, thanks for the great work! \r\n\r\nI would like to ask if it is safe to swap to a smaller model (e.g. tiny) for world-level alignment to compute attention scores instead of using the same model (e.g. medium or large ) used to generate transcription. I suspect it could improve performance in terms of inference speed if this option would be supported. ",
    "label": null
  },
  {
    "index": 310,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "I found an interesting edge case with the `small` model where enabling the word-level timestamps option causes it to repeat the prompt at the end of the audio while also failing to infer the last word.\r\n\r\n```bash\r\n$ ffmpeg -t 29 -i https://audio2.redcircle.com/episodes/6b196013-8672-43d9-be52-4332b3207d93/stream.mp3 test.mp3\r\n\r\n$ whisper --model small test.mp3\r\n.../whisper/transcribe.py:98: UserWarning: FP16 is not supported on CPU; using FP32 instead\r\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nDetected language: English\r\n[00:00.000 --> 00:15.920]  Military veteran Eric Weinstein began 69 Whiskey as a college radio show on 107.7 The\r\n[00:15.920 --> 00:21.720]  Bronx, located on the campus of Ryder University in Lawrenceville, New Jersey.\r\n[00:21.720 --> 00:27.560]  A show once restrained by rules and boundaries now comes straight to you raw, uncensored and\r\n[00:27.560 --> 00:28.960]  unapologetic.\r\n\r\n$ whisper --model small --output_format json --word_timestamps True test.mp3\r\n.../whisper/transcribe.py:98: UserWarning: FP16 is not supported on CPU; using FP32 instead\r\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nDetected language: English\r\n[00:08.040 --> 00:15.940]  Military veteran Eric Weinstein began 69 Whiskey as a college radio show on 107.7 The\r\n[00:15.940 --> 00:21.320]  Bronx, located on the campus of Ryder University in Lawrenceville, New Jersey.\r\n[00:21.720 --> 00:28.980]  A show once restrained by rules and boundaries now comes straight to you raw, uncensored and\r\n[00:28.960 --> 00:28.960]  Military veteran Eric Weinstein began 69 Whiskey as a college radio show on 107.7 The\r\n[00:28.960 --> 00:28.960]  Bronx, located on the campus of Ryder University in Lawrenceville, New Jersey.\r\n[00:28.960 --> 00:28.960]  A show once restrained by rules and boundaries now comes straight to you raw, uncensored and\r\n[00:28.960 --> 00:28.960]  Military veteran Eric Weinstein began 69 Whiskey as a college radio show on 107.7 The\r\n[00:28.960 --> 00:28.960]  Bronx, located on the campus of Ryder University in Lawrenceville, New Jersey.\r\n```",
    "label": null
  },
  {
    "index": 311,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "Hi @jongwook ,\r\nSince you first release the notebook to obtain word-level timestamps I've been working on this to add to whisper process. And I've tried to test other alingment methods than DTW. Have you tried something else and found out that it works better?\r\n\r\nAlso, I've been struggling a lot with alucinations, specially for spanish content. I've create a cleaner function at segmet level, is there any smarter way?",
    "label": null
  },
  {
    "index": 312,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "is there any chance to have word level timestamps in Whisper API?",
    "label": null
  },
  {
    "index": 313,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "Hi @IgnacioSan22, the custom DTW implementation in this PR was for the license issue as noted by others and also for the speed. An alternative is to use the timestamp predictions from the model, but we found that it's less reliable than using the attention patterns like in this PR. If you have solutions using any other algorithms for alignment, please let me know!\r\n\r\nThe community had some success handling hallucinations by preprocessing the inputs with VAD, like:\r\n\r\n- #679\r\n- #397\r\n- https://github.com/m-bain/whisperX\r\n\r\n---\r\n\r\nHi @ioskevinshah, this feature is still experimental but we do plan to add it to the API as an option, once we're sure that it's reliable enough.",
    "label": null
  },
  {
    "index": 314,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "@jongwook is there a way to access it via a beta flag for instance? How can we know when something is/isn't added to the API?",
    "label": null
  },
  {
    "index": 315,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "For the API, the [speech-to-text guide](https://platform.openai.com/docs/guides/speech-to-text) and the [audio API reference](https://platform.openai.com/docs/api-reference/audio) provide the full documentation of the available features. These documents will be updated accordingly as we roll out new features.",
    "label": null
  },
  {
    "index": 316,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "> Hi @IgnacioSan22, the custom DTW implementation in this PR was for the license issue as noted by others and also for the speed. An alternative is to use the timestamp predictions from the model, but we found that it's less reliable than using the attention patterns like in this PR. If you have solutions using any other algorithms for alignment, please let me know!\r\n> \r\n> The community had some success handling hallucinations by preprocessing the inputs with VAD, like:\r\n> \r\n> * [A possible solution to Whisper hallucination¬†#679](https://github.com/openai/whisper/discussions/679)\r\n> * [Whisper WebUI with a VAD for more accurate non-English transcripts (Japanese)¬†#397](https://github.com/openai/whisper/discussions/397)\r\n> * https://github.com/m-bain/whisperX\r\n> \r\n> Hi @ioskevinshah, this feature is still experimental but we do plan to add it to the API as an option, once we're sure that it's reliable enough.\r\n\r\nHi @jongwook, I've tried the hungarian algorithm and in some cases the results are better, however due to the lack of resources I'm not capable to perform a proper study to find the best alingment algorithm. For hallucinations I've developed a postprocess functions that cleans the segments. It improves quite a lot, but I'll check those references. \r\n\r\nThanks",
    "label": null
  },
  {
    "index": 317,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "> For the API, the [speech-to-text guide](https://platform.openai.com/docs/guides/speech-to-text) and the [audio API reference](https://platform.openai.com/docs/api-reference/audio) provide the full documentation of the available features. These documents will be updated accordingly as we roll out new features.\r\n\r\nOne more question: when will this new feature be rolled out?",
    "label": null
  },
  {
    "index": 318,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "> Hi @IgnacioSan22, the custom DTW implementation in this PR was for the license issue as noted by others and also for the speed. An alternative is to use the timestamp predictions from the model, but we found that it's less reliable than using the attention patterns like in this PR. If you have solutions using any other algorithms for alignment, please let me know!\r\n> \r\n> The community had some success handling hallucinations by preprocessing the inputs with VAD, like:\r\n> \r\n> * [A possible solution to Whisper hallucination¬†#679](https://github.com/openai/whisper/discussions/679)\r\n> * [Whisper WebUI with a VAD for more accurate non-English transcripts (Japanese)¬†#397](https://github.com/openai/whisper/discussions/397)\r\n> * https://github.com/m-bain/whisperX\r\n> \r\n> Hi @ioskevinshah, this feature is still experimental but we do plan to add it to the API as an option, once we're sure that it's reliable enough.\r\n\r\nany workaround or logic after the API response?",
    "label": null
  },
  {
    "index": 319,
    "pr title": "word-level timestamps in `transcribe()`",
    "comment": "This is awesome! Is there a way to pass in pre-transcribed text that whisper can use for more accurate alignment?",
    "label": null
  },
  {
    "index": 320,
    "pr title": "Skip silence around hallucinations",
    "comment": "Testing on another example from https://github.com/openai/whisper/discussions/679#discussioncomment-7649183\r\n\r\n<details>\r\n<summary>Output</summary>\r\n\r\n```\r\nv2 runs:\r\n\r\n[00:00.000 --> 00:05.660]  spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo\r\nDETECTED HALLUCINATION:  non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho\r\nDETECTED HALLUCINATION:  no\r\nDETECTED HALLUCINATION:  no\r\n\r\n\r\n\r\n[00:00.000 --> 00:05.660]  spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo\r\nDETECTED HALLUCINATION:  non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho\r\nDETECTED HALLUCINATION:  .....\r\nDETECTED HALLUCINATION:  .....\r\n\r\n\r\n\r\n[00:00.000 --> 00:05.660]  spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo\r\nDETECTED HALLUCINATION:  non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho capito, non ho\r\nDETECTED HALLUCINATION:  uh\r\nDETECTED HALLUCINATION:  uh\r\n\r\n\r\n\r\nv3 run:\r\n\r\n[00:00.000 --> 00:04.240]  Spero che si ripigli un attimo, ho schiacciato qualche tasto che non dovevo.\r\nDETECTED HALLUCINATION:  Grazie a tutti.\r\nDETECTED HALLUCINATION:  E' un attimo che non dovevo.\r\n[00:54.440 --> 00:55.700]  Ehm, ehm.\r\n```",
    "label": null
  },
  {
    "index": 321,
    "pr title": "Skip silence around hallucinations",
    "comment": "When using `--clip_timestamps`, is there a need to pad before and after the clip? If so, what would be a recommended value for pad duration? ",
    "label": null
  },
  {
    "index": 322,
    "pr title": "Skip silence around hallucinations",
    "comment": "It should work without padding, but if the VAD is inaccurate then padding might help compensate for that.",
    "label": null
  },
  {
    "index": 323,
    "pr title": "Skip silence around hallucinations",
    "comment": "Will this PR included in the next release? If so, when it it planned?",
    "label": null
  },
  {
    "index": 324,
    "pr title": "Skip silence around hallucinations",
    "comment": "Related PR: #2005 (fixes a bug in `--clip_timestamps` if you pass an end timestamp that is after the audio end.)",
    "label": null
  },
  {
    "index": 325,
    "pr title": "Skip silence around hallucinations",
    "comment": "Just tested out hallucination_silence_threshold and it worked for me\r\nthanks!",
    "label": null
  },
  {
    "index": 326,
    "pr title": "Skip silence around hallucinations",
    "comment": "@ryanheise Can you show me your transcribe.py with debug stuff?",
    "label": null
  },
  {
    "index": 327,
    "pr title": "Skip silence around hallucinations",
    "comment": "I don't have the exact code anymore, but you could try temporarily inserting these two lines:\r\n\r\n```python\r\n                if score >= 3 or score + 0.01 >= len(words):\r\n                    print(f\"DETECTED HALLUCINATION: {segment['text']}\")\r\n```\r\n\r\nbefore the return in this function:\r\n\r\n```python\r\n            def is_segment_anomaly(segment: Optional[dict]) -> bool:\r\n                if segment is None or not segment[\"words\"]:\r\n                    return False\r\n                words = [w for w in segment[\"words\"] if w[\"word\"] not in punctuation]\r\n                words = words[:8]\r\n                score = sum(word_anomaly_score(w) for w in words)\r\n                return score >= 3 or score + 0.01 >= len(words)\r\n```",
    "label": null
  },
  {
    "index": 328,
    "pr title": "Skip silence around hallucinations",
    "comment": "@ryanheise\r\nSometimes `--hallucination_silence_threshold` makes whole non-hallucinating segments or part of segments disappear.\r\n\r\nBelow is example with disappeared `orange pigmentation.` segment.\r\n\r\nI'm using faster-whisper, but you should be able to reproduce it with whisper too as implementation is same.\r\nAudio file -> https://we.tl/t-U5a6Al5bRs\r\n\r\n\r\n`--language en --model=base --beam_size=5 --word_timestamps=True --hallucination_silence_threshold=None`:\r\n\r\n```\r\n[02:06.620 --> 02:11.120]  White tigers carry a mutated version of this gene, which prevents them from producing\r\n  Processing segment at 02:11.120\r\n[02:11.120 --> 02:12.460]  orange pigmentation.\r\n[02:15.360 --> 02:18.340]  Fewer than 4,000 tigers remain in the wild.\r\n```\r\n\r\n`--language en --model=base --beam_size=5 --word_timestamps=True --hallucination_silence_threshold=2`:\r\n\r\n```\r\n[02:06.620 --> 02:11.120]  White tigers carry a mutated version of this gene, which prevents them from producing\r\n  Processing segment at 02:12.380\r\n* HST_1: Skipping silence before possible hallucinations.\r\n* HST_3: DETECTED HALLUCINATION:  oxygen.\r\n  Processing segment at 02:13.380\r\n* HST_1: Skipping silence before possible hallucinations.\r\n[02:14.680 --> 02:18.360]  fewer than 4,000 tigers remain in the wild.\r\n```\r\n\r\nEDIT:\r\nfloat32 was in use",
    "label": null
  },
  {
    "index": 329,
    "pr title": "Skip silence around hallucinations",
    "comment": "I think, I've noticed a pattern, it happens when `if remaining_duration > threshold:` is not triggered, in there:\r\n`seek = previous_seek + segment_size`\r\n\r\nThen chunk go exactly by 30 secs cutting off the word.\r\n\r\nChunking when `--hallucination_silence_threshold=None`:\r\n\r\n```\r\n  Processing segment at 00:00.000\r\n  Processing segment at 00:26.040\r\n  Processing segment at 00:48.280\r\n  Processing segment at 01:14.400\r\n  Processing segment at 01:42.380\r\n  Processing segment at 02:11.120\r\n  Processing segment at 02:35.400\r\n  Processing segment at 03:05.400\r\n```\r\nChunking by setting high threshold `--hallucination_silence_threshold=40`:\r\n```\r\n  Processing segment at 00:00.000\r\n  Processing segment at 00:30.000\r\n  Processing segment at 01:00.000\r\n  Processing segment at 01:30.000\r\n  Processing segment at 02:00.000\r\n  Processing segment at 02:30.000\r\n  Processing segment at 03:00.000\r\n```",
    "label": null
  },
  {
    "index": 330,
    "pr title": "Skip silence around hallucinations",
    "comment": "Another thing, this PR affects transcription even if both new parameters are not enabled, I meant comparing vs without this PR.\r\n\r\nThis happens sometimes, but when it happens the discrepancy is always in the last chunk.\r\n\r\nAnd sometimes when discrepancy happens it tries to process additional micro chunk after it which produces some hallucination or fails because no-speech threshold is met, not sure if this is related to PR or to a discrepancy.\r\n\r\nExample of such discrepancy [audio is `05:05.877` long]:\r\n\r\nWithout this PR [perfect transcription]:\r\n```\r\nProcessing segment at 04:48.000\r\n[04:58.120 --> 05:05.260]  I just...\r\n[05:05.260 --> 05:05.760]  I...\r\n```\r\n\r\nWith this PR [all goes exactly same till the last chunk]:\r\n\r\n```\r\n  Processing segment at 04:48.000\r\n* Compression ratio threshold is not met with temperature 0.0 (3.523810 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.2 (3.523810 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.4 (8.038462 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.6 (3.523810 > 2.400000)\r\n* Compression ratio threshold is not met with temperature 0.8 (2.423077 > 2.400000)\r\n[05:01.940 --> 05:02.900]  Okay.\r\n[05:02.900 --> 05:04.000]  I just-\r\n[05:04.940 --> 05:05.740]  I-\r\n[05:05.740 --> 05:05.840]  I-\r\n* Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000\r\n  Processing segment at 05:05.840\r\n* Log probability threshold is not met with temperature 0.0 (-1.105777 < -1.000000)\r\n* No speech threshold is met (0.772002 > 0.600000)\r\n```",
    "label": null
  },
  {
    "index": 331,
    "pr title": "Skip silence around hallucinations",
    "comment": "> Sometimes `--hallucination_silence_threshold` makes whole non-hallucinating segments or part of segments disappear.\r\n\r\nThis logic is part of the original Whisper strategy of advancing by the full 30 seconds to the next window whenever the current segment is unfinished. So basically, if the segment finishes before the end of the 30 second window, then Whisper will crop the window to the exact end timestamp of the last word in that segment. But if the segment does not finish by the end of the 30 second window, the window is not cropped, the speech is assumed to run all the way to the end of the window.\r\n\r\nThis logic exists whether or not the `hallucination_silence_threshold` is enabled, and I have seen it cause problems in both cases, however the larger models tend to be better at picking up the words across the window boundary.\r\n\r\nIn your case, the sentence in question is:\r\n\r\n> White tigers carry a mutated version of this gene, which prevents them from producing orange pigmentation.\r\n\r\nThis sentence does not fit within the 30 second window, and the word \"orange\" is right on the boundary. In fact, the word \"orange\" is slightly before the boundary and the human ear can pick it up (as can the larger models) but the smaller models fail to pick it up.\r\n\r\nAnd given Whisper's logic in this case, it will assume the speech went right up to the end of the 30 second window and will resume the next window from there.\r\n\r\nSo although yes the large models would probably resolve this, I think it would still be better to change Whisper's strategy and crop the window to the end timestamp of the last word even in this case where we have an unfinished segment.",
    "label": null
  },
  {
    "index": 332,
    "pr title": "Skip silence around hallucinations",
    "comment": "> This logic is part of the original Whisper strategy of advancing by the full 30 seconds to the next window whenever the current segment is unfinished.\r\n\r\nI can't connect the dots...\r\nThen why it's \"unfinished\" when using `hallucination_silence_threshold` and it's \"finished\" without it?\r\n\r\nHow `remaining_duration <= hallucination_silence_threshold` means an \"unfinished\" segment? The option doesn't read as \"finished/unfinished segment threshold\"....\r\n",
    "label": null
  },
  {
    "index": 333,
    "pr title": "Skip silence around hallucinations",
    "comment": "Apologies, my explanation of that was around the wrong way. The original Whisper behaviour was that if the last segment in the window is \"complete\", THEN it skips to the end of the full 30 second window. If the last segment is incomplete, then it crops the window to end timestamp of the last word.\r\n\r\nBut when `hallucination_silence_threshold` is set, it still applies this logic in most cases except that it also includes a misfired heuristic that skips to the end of the full 30 second window if the end of the speech is close enough to the end of the window:\r\n\r\n```python\r\n                # skip silence before possible hallucinations\r\n                if hallucination_silence_threshold is not None:\r\n                    threshold = hallucination_silence_threshold\r\n                    if not single_timestamp_ending:\r\n                        last_word_end = get_end(current_segments)\r\n                        if last_word_end is not None and last_word_end > time_offset:\r\n                            remaining_duration = window_end_time - last_word_end\r\n                            if remaining_duration > threshold:  # <--- misfired heuristic\r\n                                seek = round(last_word_end * FRAMES_PER_SECOND)\r\n                            else:\r\n                                seek = previous_seek + segment_size\r\n````\r\n\r\nThe goal was to skip over as much silence as safely possible.\r\n\r\nHowever, in hindsight, this was a bit opportunistic, since after all `single_timestamp_ending` was `False` for good reason. You should find your example will work if you remove that heuristic. i.e. Delete this entire section:\r\n\r\n```python\r\n                    if not single_timestamp_ending:\r\n                        last_word_end = get_end(current_segments)\r\n                        if last_word_end is not None and last_word_end > time_offset:\r\n                            remaining_duration = window_end_time - last_word_end\r\n                            if remaining_duration > threshold:  # <--- misfired heuristic\r\n                                seek = round(last_word_end * FRAMES_PER_SECOND)\r\n                            else:\r\n                                seek = previous_seek + segment_size\r\n```\r\n\r\n(It's OK, the other parts of this code block are already handled elsewhere.)",
    "label": null
  },
  {
    "index": 334,
    "pr title": "Skip silence around hallucinations",
    "comment": "I've created a PR #2043 incorporating the above fix based on your counter example.",
    "label": null
  },
  {
    "index": 335,
    "pr title": "Skip silence around hallucinations",
    "comment": "Thanks for explanation, now this part of code makes sense.\r\nDo you have idea why seek in the last window can be affected by PR? -> https://github.com/openai/whisper/pull/1838#issuecomment-1960581637\r\n\r\n> The goal was to skip over as much silence as safely possible.\r\n\r\nImho, skipping to full 30s window is pretty unsafe.  üòÜ\r\nAnd it contradicted the description: \"skip silent periods longer than this threshold (in seconds) **when a possible hallucination is detected**\"",
    "label": null
  },
  {
    "index": 336,
    "pr title": "Skip silence around hallucinations",
    "comment": "> Do you have idea why seek in the last window can be affected by PR? -> https://github.com/openai/whisper/pull/1838#issuecomment-1960581637\r\n\r\nDo you have an audio file to reproduce?",
    "label": null
  },
  {
    "index": 337,
    "pr title": "Skip silence around hallucinations",
    "comment": "> Do you have an audio file to reproduce?\r\n\r\nThis file has discrepancy in the last window/chunk:\r\nt-001.mka -> https://we.tl/t-ecd6U1QaZp\r\n`--language en --model=base --beam_size 1 --word_timestamps=True`\r\n\r\nWhisper without this PR:\r\n```\r\n[01:53.920 --> 01:54.500]  I'll give you some advice.\r\n[01:59.500 --> 02:00.080]  I'll give you some advice.\r\n[02:00.080 --> 02:00.080]  I'll give you some advice.\r\n[02:00.080 --> 02:00.980]  Say the word, General.\r\n[02:02.300 --> 02:03.320]  Let him go.\r\n```\r\nWhisper with this PR:\r\n```\r\n[01:53.920 --> 01:55.200]  I'll give you some advice.\r\n[01:59.500 --> 02:00.980]  Say the word, General.\r\n[02:02.280 --> 02:03.320]  Let him go.\r\n```\r\n",
    "label": null
  },
  {
    "index": 338,
    "pr title": "Skip silence around hallucinations",
    "comment": "I'll test tomorrow, but does this also happen on PR https://github.com/openai/whisper/pull/2043 ?",
    "label": null
  },
  {
    "index": 339,
    "pr title": "Skip silence around hallucinations",
    "comment": "> I'll test tomorrow, but does this also happen on PR #2043 ?\r\n\r\nYes, because `hallucination_silence_threshold` option is not relevant for the issue.\r\n\r\nCulprit affecting only the last window is found. it happens because of this:\r\n```python\r\n            mel_segment = mel[:, seek : seek + segment_size]\r\n```\r\n\r\nThis is the fix [that's how it was before this PR]:\r\n```python\r\n            mel_segment = mel[:, seek : seek + N_FRAMES]\r\n```\r\n\r\nNot sure why you changed it, on my observation it makes more hallucinations [probably it's random].\r\nAnyway, the fix brings back the previous behavior.",
    "label": null
  },
  {
    "index": 340,
    "pr title": "Skip silence around hallucinations",
    "comment": "That is changed for `--cilp_timestamps` because parts of the audio that are clipped out should not be included in the mel spectrogram. I'll take a look at your test scenario to see what's going on.",
    "label": null
  },
  {
    "index": 341,
    "pr title": "Skip silence around hallucinations",
    "comment": "I've confirmed the discrepancy, which seems to be a consequence of slightly different mel spectrograms. Although in the two examples you gave (only the latter of which I have tested with the supplied audio file), the PR actually removed a hallucination on one example and introduced a hallucination on the other example. So on balance, it's hard to say whether this discrepancy it better or worse or about the same.\r\n\r\nSo if it's not clear whether it's better or worse, do you see anything incorrect in the clipping logic? I think the difference is that I am always clipping exactly to the stretch of audio being examined, and then padding it. But originally, there was padding on the end that was added immediately when the mel spectrogram was first generated, and then (in the original code), it is also possible that due to the dynamic shifting of the window starts, it could end up padding the last part of the audio twice, because there is no guarantee that that initial padding Whisper added at the start of the process was enough to reflect where this last window ended up actually starting.\r\n\r\nBut it's possible I've done something wrong which I can't see, so let me know if you do spot something incorrect in the logic.",
    "label": null
  },
  {
    "index": 342,
    "pr title": "Skip silence around hallucinations",
    "comment": "After plotting the mel spectrograms, I noticed the padding when the audio is first loaded (as a whole) contains all -1.0's, while the padding in the main loop for each 30 second window contains all 0.0's. Not sure why that is, but there are two different padding algorithms in the code, and weirdly they are producing different padding results.\r\n\r\nSo in your example, the PR ends up always using the padding algorithm that pads to 0.0's whereas originally the end of file padding had -1.0's. ",
    "label": null
  },
  {
    "index": 343,
    "pr title": "Skip silence around hallucinations",
    "comment": "There's still a chance that a hallucination will be produced.\r\nFor me it was:\r\n```\r\n[02:15:58.100 --> 02:16:05.380]  —è –≤–∞–º –≤—ã—à–ª—é. –í—Å–µ–≥–æ –¥–æ–±—Ä–æ–≥–æ, –¥–æ —Å–≤–∏–¥–∞–Ω–∏—è.\r\n[02:16:28.100 --> 02:16:30.100]  –†–µ–¥–∞–∫—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –ò.–ë–æ–π–∫–æ–≤–∞\r\n```\r\ni. e.\r\n```\r\n....\r\n[02:16:28.100 --> 02:16:30.100] Subtitle Editor I. Boykova\r\n```\r\nNotably, this timestamp belongs to the end of the audio.\r\n\r\nModel size: small. Also there are some results in google, if you search for this phrase. One of them:\r\n```\r\n[24:26.800 --> 24:30.160]  –°–º–æ—Ç—Ä–∏—Ç–µ —Ç–µ–ª–µ–±–∞—Ä–æ–º–µ—Ç—Ä –Ω–∞ –Ω–∞—à–µ–º —Ç–µ–ª–µ–∫–∞–Ω–∞–ª–µ.\r\n[24:30.160 --> 24:32.160]  –†–µ–¥–∞–∫—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –ò.–ë–æ–π–∫–æ–≤–∞\r\n[24:32.160 --> 24:39.160]  –ö–æ—Ä—Ä–µ–∫—Ç–æ—Ä –ê.–ö—É–ª–∞–∫–æ–≤–∞\r\n```\r\nfrom https://storage.googleapis.com/data.gdeltproject.org/blog/2022-tv-news-whisperasr/BELARUSTV_20221005_161500.small.transcribe.run1.txt",
    "label": null
  },
  {
    "index": 344,
    "pr title": "Skip silence around hallucinations",
    "comment": "That's certainly possible, and unfortunately there is no single choice of parameters that will be perfect in all scenarios. You can tweak the silence threshold, which is exposed on the command line. You can also try tweaking the other thresholds that were built into the code (like how long a word must be before it is flagged as an abnormality). If we can gather a large enough dataset of audio samples that produce hallucinations, we should be able to come up with better default settings that work well across a variety of scenarios and languages.",
    "label": null
  },
  {
    "index": 345,
    "pr title": "Skip silence around hallucinations",
    "comment": "@ryanheise \r\nI was using a bit tweaked segment anomaly heuristics to reduce false-positives, didn't noticed increase of false-negatives:\r\n\r\nchanged\r\n `if duration < 0.133:`\r\nto:\r\n`if duration < 0.133 and probability < 0.8:`\r\n\r\nchanged\r\n`return score >= 3 or score + 0.01 >= len(words)`\r\nto:\r\n`return score >= 3 or score + 0.001 >= len(words)`\r\n\r\nWhat you think about this tweak?",
    "label": null
  },
  {
    "index": 346,
    "pr title": "Skip silence around hallucinations",
    "comment": "Unfortunately I'm between computers right now (my old computer died 2 weeks ago, and I'm just in the process of installing everything on the recently arrived replacement...)\r\n\r\n>  return score >= 3 or score + 0.001 >= len(words)\r\n\r\nI don't see any problem with that change.\r\n\r\n>  `if duration < 0.133 and probability < 0.8:`\r\n\r\nDo you have an example audio for this one? I'd be interested to analyse this correlation between duration < 0.133 and probability < 0.8.\r\n\r\nThe alternative is to take into account more observations (like your audio example) and try to fit a new curve to the data. I initially fitted a simple linear curve, and maybe exponential could help because it could model a slower initial gradient.",
    "label": null
  },
  {
    "index": 347,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "For those who haven't heard of [TorchDynamo/TorchInductor](https://github.com/pytorch/torchdynamo), it is automatically fusing and mapping PyTorch to [Triton](https://github.com/openai/triton).",
    "label": null
  },
  {
    "index": 348,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "This sounds great! I was also wondering how fast it'd be if [Triton's flash attention](https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py) was integrated, but unfortunately it's A100 only.\r\n\r\nImplementation-wise, I think we could subclass the class `PyTorchInference(Inference):` and monkey-patch the attention layers only when TorchDynamo is available, so that the code is still usable in the older PyTorch versions.",
    "label": null
  },
  {
    "index": 349,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "> This sounds great! I was also wondering how fast it'd be if [Triton's flash attention](https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py) was integrated, but unfortunately it's A100 only.\r\n> \r\n> Implementation-wise, I think we could subclass the class `PyTorchInference(Inference):` and monkey-patch the attention layers only when TorchDynamo is available, so that the code is still usable in the older PyTorch versions.\r\n\r\nThat sounds awesome. I'd love to do that. I'm in the pytorch slack and the triton slack - would you like to chat there? I also have further questions on getting a little bit of realistic inference data so we can setup a benchmark on our end (As well as to better measure accuracy). The adhoc free audiobook approach isn't scaling super well, hah. ",
    "label": null
  },
  {
    "index": 350,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "do you have more benchmarks? for example, on cpu.",
    "label": null
  },
  {
    "index": 351,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "> do you have more benchmarks? for example, on cpu.\r\n\r\nNo, I am sorry, I do not. I plan on working with @jongwook to benchmark this properly :) ",
    "label": null
  },
  {
    "index": 352,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "This is the RFC - The implementation PR will be here: https://github.com/openai/whisper/pull/115",
    "label": null
  },
  {
    "index": 353,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "@voznesenskym I am curious why you guys started with \"torchdynamo\" instead of more widely-adopted \"torchscript\". We are in the process of making this torch.jit compatible, so I was wondering whether torchscript is slower in comparison.",
    "label": null
  },
  {
    "index": 354,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "> @voznesenskym I am curious why you guys started with \"torchdynamo\" instead of more widely-adopted \"torchscript\". We are in the process of making this torch.jit compatible, so I was wondering whether torchscript is slower in comparison.\r\n\r\nTorchDynamo and torchscript are fundamentally different projects, and we are investing in TorchDynamo as a next gen core component of our stack. While their surface levels goals (in this case, speed) align, they are rather different. I am happy to go into it more, but the ReadMe in the TorchDynamo project goes into great depths about what the project is. Have you had a chance to read that yet? ",
    "label": null
  },
  {
    "index": 355,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "@taylorchu I definitely recommend in going the torchdynamo route than `torch.jit`. it's more aligned with our future plans.",
    "label": null
  },
  {
    "index": 356,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "@soumith @voznesenskym  is the torch team plan for torchdynamo or torch.jit written some where? \r\n\r\nI am interested in whether one will choose one over the other in certain use cases. ",
    "label": null
  },
  {
    "index": 357,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "not written down anywhere concretely, we'll talk about it in a few months.\r\nBut about dynamo itself, we have quite a few posts here with various updates: https://dev-discuss.pytorch.org/",
    "label": null
  },
  {
    "index": 358,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "Just in case. I can provide a large set of data transcribed by whisper so that you guys can validate whether the change affects the text output. ",
    "label": null
  },
  {
    "index": 359,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "@voznesenskym I am trying to benchmark your approach with torchdynamo but got some error modules.  do you know which version torchinductor, torchdynamo and triton are used to make your modification work?  ",
    "label": null
  },
  {
    "index": 360,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "> @voznesenskym I am trying to benchmark your approach with torchdynamo but got some error modules. do you know which version torchinductor, torchdynamo and triton are used to make your modification work?\r\n\r\nHey, dynamo migrated to latest triton, so we maybe have some new errors here, but the torchdynamo Makefile https://github.com/pytorch/torchdynamo/blob/main/Makefile has the versions of all our deps (usually cutting edge nightlies).\r\n\r\nI plan to revisit this shortly, and will fix up any errors I find. ",
    "label": null
  },
  {
    "index": 361,
    "pr title": "[Do not land] [RFC] 1.375x speedup - Remove control flow from model, small hacks, enable TorchDynamo + TorchInductor",
    "comment": "Thanks, I'll close this for now, since it doesn't quite yet work \"out of the box\" and relying on nightly versions makes things difficult for me to maintain. I'm hoping to get an easier integration with the stable PyTorch 2 interface once it's out.",
    "label": null
  },
  {
    "index": 362,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "Hi @jongwook Not sure if you saw the comment below, but it includes a reproduction case which might be useful:\r\n\r\nhttps://github.com/openai/whisper/pull/869#issuecomment-1445024980\r\n\r\nThe repetition persists with this PR.",
    "label": null
  },
  {
    "index": 363,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "@ryanheise thanks! will look into it...",
    "label": null
  },
  {
    "index": 364,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "The problem triggered by the test data from @ryanheise is model sensitive. I see the problem with `small` but using either `small.en` or `medium.en` looks ok although the timing of the last few words is off. Below is the mp3 fragment converted to video to show the English subtitles.\r\n\r\nhttps://user-images.githubusercontent.com/3035114/223597998-74a8ec7f-da0b-4948-9f6a-75712820eb15.mp4\r\n\r\n\r\n",
    "label": null
  },
  {
    "index": 365,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "Thanks all! The incorrect zero-padding of Mel spectrograms as identified in #730 and #838 was contributing to this error. The fix in 477f0be appears to fix the repetition issue.",
    "label": null
  },
  {
    "index": 366,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "> The fix in https://github.com/openai/whisper/commit/477f0befc76456c37b2d2f484095f803592c90fa appears to fix the repetition issue.\r\n\r\nI can confirm this fixed my example, thanks! :+1:\r\n\r\n> Below is the mp3 fragment converted to video to show the English subtitles.\r\n\r\n@glangford FYI the subtitles didn't show in your video.",
    "label": null
  },
  {
    "index": 367,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "@ryanheise Inline, (on Mac at least) you may need to click on the >> on the right to turn on subtitles. Or download and view with VLC, Quicktime, or whatever and enable subtitles in the viewer.",
    "label": null
  },
  {
    "index": 368,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "Ah, I see, Firefox doesn't show any options, but downloading it and opening in VLC works. You can also do hard subs this way https://github.com/openai/whisper/discussions/435#discussioncomment-4238872\r\n\r\n> using either `small.en` or `medium.en` looks ok although the timing of the last few words is off.\r\n\r\nHere is the `base` model for comparison, which appears more accurate on the last few words:\r\n\r\nhttps://user-images.githubusercontent.com/19899190/223708621-c4b53230-171c-4e92-871f-4c5f390425a1.mp4",
    "label": null
  },
  {
    "index": 369,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "Btw have you guys tried with longer audio, e.g. 5 mins long? I am still getting a lot of repetition even with this fix.\r\nE.g. on the TEDLIUM test set \"AimeeMullins_2009P.wav\"\r\n>[02:10.440 --> 02:14.720]  and needless to say, thank God, I wasn't using a thesaurus back then.\r\n[02:14.720 --> 02:14.720]  and needless to say, thank God, I wasn't using a thesaurus back then.\r\n[02:15.460 --> 02:18.580]  I mean from this entry, it would seem that\r\n[02:18.580 --> 02:22.800]  I was born into a world that perceived someone like me\r\n[02:22.800 --> 02:23.340]  I was born into a world that perceived someone like me\r\n[02:23.340 --> 02:27.540]  to have nothing positive, whatsoever, going for them\r\n[02:27.540 --> 02:27.540]  to have nothing positive, whatsoever, going for them\r\n[02:27.540 --> 02:35.340]  When in fact today, I'm celebrated for the opportunities and adventures my life has procured\r\n[02:35.340 --> 02:35.960]  When in fact today, I'm celebrated for the opportunities and adventures my life has procured\r\n[02:35.960 --> 02:42.140]  So I immediately went to look up the 2009 online edition\r\n[02:42.140 --> 02:42.160]  So I immediately went to look up the 2009 online edition\r\n[02:42.160 --> 02:42.160]  So I immediately went to look up the 2009 online edition\r\n\r\nI was hoping to update word segmentation results for whisper-only word timestamps in our paper https://arxiv.org/abs/2303.00747\r\n\r\nBut currently i am getting better results with our implementation which is similar to https://github.com/linto-ai/whisper-timestamped\r\n",
    "label": null
  },
  {
    "index": 370,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "> Btw have you guys tried with longer audio, e.g. 5 mins long? I am still getting a lot of repetition even with this fix.\r\n\r\nI am testing a longer audio now (running on CPU, larger model, transcript+transcribe so it is taking a while). For clarity,\r\n* are you running the 20230307 release version? with, or without `--word_timestamps`?\r\n* the repetitions from \"AimeeMullins_2009P.wav\" above, are they from verbose print to the console? \r\n\r\nIt seems like there are different possible sources of error, in all the different discussions\r\n* model hallucination\r\n* new repetition introduced or magnified by `--word_timestamps True`\r\n* (hand waving) segmentation issues",
    "label": null
  },
  {
    "index": 371,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "> are you running the 20230307 release version? with, or without --word_timestamps?\r\n\r\nyes\r\n\r\n> the repetitions from \"AimeeMullins_2009P.wav\" above, are they from verbose print to the console?\r\n\r\nyes\r\n\r\n",
    "label": null
  },
  {
    "index": 372,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "@jongwook Note from @m-bain example above the repetition occurring with verbose print. The repetitions in this example are all \"instantaneous\" ; eg same start and end time\r\n> [02:14.720 --> 02:14.720] and needless to say, thank God, I wasn't using a thesaurus back then.\r\n\r\nthey are printed but then immediately cleared by this code, which looks like a bug unique to `--verbose True`\r\n\r\nhttps://github.com/openai/whisper/blob/aac47c98349b98cec5ca7b1be53960fb59f4436b/whisper/transcribe.py#L345",
    "label": null
  },
  {
    "index": 373,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "@m-bain Given this could you maybe rerun and see if the formal output formats are messed up or not, using `--verbose False`?",
    "label": null
  },
  {
    "index": 374,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "This is not a verbose error, and the start times and end times of repetition are not always instantaneous, see output for the .srt file without verbose:\r\n\r\n271\r\n00:02:14,440 --> 00:02:14,720\r\nand needless to say, thank God, I wasn't using a thesaurus back<u> then.</u>\r\n\r\n272\r\n00:02:14,720 --> 00:02:14,720\r\n\r\n\r\n273\r\n00:02:15,460 --> 00:02:16,180\r\n<u>I</u> mean from this entry, it would seem that\r\n\r\n274\r\n00:02:16,180 --> 00:02:16,360\r\nI<u> mean</u> from this entry, it would seem that\r\n\r\n275\r\n00:02:16,360 --> 00:02:16,960\r\nI mean<u> from</u> this entry, it would seem that\r\n\r\n276\r\n00:02:16,960 --> 00:02:17,220\r\nI mean from<u> this</u> entry, it would seem that\r\n\r\n277\r\n00:02:17,220 --> 00:02:17,620\r\nI mean from this<u> entry,</u> it would seem that\r\n\r\n278\r\n00:02:17,620 --> 00:02:17,800\r\nI mean from this entry, it would seem that\r\n>",
    "label": null
  },
  {
    "index": 375,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "So there are at least two problems then\r\n* verbose mode can print cleared segments\r\n* something else triggered by word_timestamps\r\n\r\nGiven how close the start/end times are it feels like something related to `seek_shift` is still off\r\nhttps://github.com/openai/whisper/blob/aac47c98349b98cec5ca7b1be53960fb59f4436b/whisper/transcribe.py#L337\r\n\r\n@m-bain Do the same repetitions happen with `word_timestamps False` or no? ",
    "label": null
  },
  {
    "index": 376,
    "pr title": "attempt to fix the repetition/hallucination issue identified in #1046",
    "comment": "Update, I realise there is some specific underline formatting in the word_timestamps, was able to get it working in the end. See here for comparison on word-level timestamp accuracy\r\n\r\n![image](https://user-images.githubusercontent.com/36994049/224011580-4782f2ad-a178-4b2d-80c3-4baa8ca54ab9.png)\r\n\r\n@jongwook could you share the evaluation for long-form transcription WER? I am unable to reproduce whisper results, right now I report in the vanilla setting -- greedy/beam5 decoding without the heuristic tricks\r\n",
    "label": null
  },
  {
    "index": 377,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "EDIT: Done\r\n\r\nTODO: correct propability display when supplying prompts (prompt tokens seem to get assigned prob of 0, if anyone can please help, I'd appreciate it)",
    "label": null
  },
  {
    "index": 378,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "Fixed probs offset (and prompt offset)\r\n\r\nNew (correct) output:\r\n![image](https://user-images.githubusercontent.com/43215895/227074244-58d15f24-2a25-4302-a1f9-068bd8d01d6f.png)\r\n",
    "label": null
  },
  {
    "index": 379,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "This can be really useful for proofing the output via something like Subtitle Edit.  \r\n\r\nWould really need an command line option to output an additional subtitle though, right?  \r\n\r\nI get the impression @jongwook doesn't want to stuff too many features in though, so how does such a useful feature get added without having a fork?",
    "label": null
  },
  {
    "index": 380,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "> I get the impression @jongwook doesn't want to stuff too many features in\r\n\r\nAlthough the colour terminal stuff might be questionable, I think adding per-token timestamps and confidence to the raw JSON results could itself be useful to a wider range of use cases. Exposing the raw data from Whisper would then make it possible to write your own external script on top of that to do the colour terminal staff.\r\n\r\nOne example of the wider potential uses of per-token data is that German is known to have very long compound words, and if you wanted to break them up (e.g. to compute a line break timestamp, or for sub-word highlighting, etc.), it would be helpful to have access to the raw data per token.",
    "label": null
  },
  {
    "index": 381,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "Hello!\r\n\r\n> Although the colour terminal stuff might be questionable\r\n\r\nI implemented the per-token confidence as is and implemented the colorful CLI output only in an example.\r\nThe main whisper code does not contain anything with color\r\n\r\n@jongwook is there anything I should modify or change for you to accept the PR? ",
    "label": null
  },
  {
    "index": 382,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "I'm hesitant to add this because the incremental utility of this compared to the probabilities returned by `word_timestamps=True` is quite niche, versus the added complexity & latency due to the additional GPU operations. The decoding logic is already taking as much as the forward pass, and I'm hoping to reduce this overhead. The subword token probabilities are not very useful anyway, because it's usually influenced more by language modeling than from speech recognition.\r\n\r\nFor the case you need per-token probs, you can add another forward pass without modifying decoding.py (similar to how it's done in [timing.py](https://github.com/openai/whisper/blob/76c901ab8d4558992c44138479c4d69eb52fadcb/whisper/timing.py#L197)) without incurring too much additional latency. It may even be faster than adding GPU operations for every autoregressive step.\r\n\r\nThe example script looks nifty, but i'd prefer it in the [show and tell](https://github.com/openai/whisper/discussions/categories/show-and-tell) section.",
    "label": null
  },
  {
    "index": 383,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "I see, thank you for the comprehensive response!",
    "label": null
  },
  {
    "index": 384,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "@SinanAkkoyun thanks for your contribution. Not sure, but seems it works incorrect, \r\nI made distorted speech example https://drive.google.com/file/d/12zGWllJg6edftcnwuHX_ZHMuwk7PlVjg/view?usp=sharing .\r\nIf I don't set the language of decoding i.e. `options = whisper.DecodingOptions() `,  the output is correct in terms of locating mispronounce (I can read this slavic) though it translates it to random language.\r\n![Screenshot from 2023-08-09 10-58-49](https://github.com/openai/whisper/assets/54935496/cf45eaab-1799-45d0-a386-2fc2e3076b1a)\r\n\r\nBut if I set 'en' for decoding  `options = whisper.DecodingOptions(language=\"en\")` the picture is wrong.\r\n![Screenshot from 2023-08-09 10-58-53](https://github.com/openai/whisper/assets/54935496/8c009a46-ec4d-4a47-abe3-786408580857)\r\n The rest of the code is the same as in your PR except I used \"small\" model.\r\n",
    "label": null
  },
  {
    "index": 385,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "@Rtut654 Hi, I don't quite understand the issue you are having, the \"I like to play badminton and football.\" seems to be correct, the football especially sounds vague in the audio you provided. Could you please tell me more about your issue?\r\n\r\nDespite that, the PR is not going to get merged, so I stopped working on it and use that modification in my own work which does not include translation\r\n\r\nIf the random translation is the problem you are referring to, I believe that my PR did not modify nor change the output prediction by any means, it just grabbed the logits and displays them as confidence",
    "label": null
  },
  {
    "index": 386,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "@SinanAkkoyun \r\nThe issue is in the accuracy of token_probs. The first version (with translation to Ukrainian) gives very accurate result since \"like\" was also mispronounced very much. Also the word \"football \" was mispronounced in the last part which is correctly shown in the first picture. \r\n\r\nI did the same test with other audio, setting language of decoding to English.  The picture was same. Somehow it is lowering the prob of the last word even when it is pronounced correctly. At the same time probs of mispronounciations were high which is strange. So something is wrong in the way it predicts probs when language is set to English.",
    "label": null
  },
  {
    "index": 387,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "Hello, @jongwook ! Could you please look at the issue?",
    "label": null
  },
  {
    "index": 388,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "@Rtut654 Ah I see, I am sorry but in my testing I was not able to reproduce that behaviour, for me it seemed very fine in regards to unclear spoken words and clearly spoken words, even in german transcriptions.\r\nTo me, the football sounded unclearer than the rest, my code does not do much except that it takes the unmodified logits. Maybe the model has a different sense of misspronunciation than you? It has been trained on many accents.\r\n\r\nI currently am working on other projects, you can take a look at the file changes yourself and work your way through, if you have a question feel free to ask and I will give my best to clarify",
    "label": null
  },
  {
    "index": 389,
    "pr title": "Per Token Confidence + Color terminal example",
    "comment": "In case it's of interest, I created a small web component to view the Whisper JSON file when `--word_timestamps` has been used. Ideas for improving it would be welcome!\r\n\r\nhttps://edsu.github.io/whisper-transcript/",
    "label": null
  },
  {
    "index": 390,
    "pr title": "add always_use_initial_prompt",
    "comment": "I think some variation on this idea might help it to remember your prompting in long audio, but when a window boundary occurs mid sentence, I think it's also important to have the previous text as the prompt.\r\n\r\nAs a compromise, have you thought about truncating the previous text at a sentence boundary and then prepending the initial prompt before that? It might be the best of both worlds.",
    "label": null
  },
  {
    "index": 391,
    "pr title": "add always_use_initial_prompt",
    "comment": "> I think some variation on this idea might help it to remember your prompting in long audio, but when a window boundary occurs mid sentence, I think it's also important to have the previous text as the prompt.\r\n> \r\n> As a compromise, have you thought about truncating the previous text at a sentence boundary and then prepending the initial prompt before that? It might be the best of both worlds.\r\n\r\nI agree, but I don't know how to do that.",
    "label": null
  },
  {
    "index": 392,
    "pr title": "add always_use_initial_prompt",
    "comment": "A really cheap modification might be to add a check here:\r\n\r\n```python\r\n            if not condition_on_previous_text or result.temperature > 0.5:\r\n                # do not feed the prompt tokens if a high temperature was used\r\n                prompt_reset_since = len(all_tokens)\r\n```\r\n\r\nso that you also check if your option is enabled and if the latest token ends with one of these characters `\".„ÄÇ!ÔºÅ?Ôºü\"`, effectively resetting the prompt after every sentence boundary. Then when feeding the prompt:\r\n\r\n```python\r\n            decode_options[\"prompt\"] = all_tokens[prompt_reset_since:]\r\n```\r\n\r\nIf your option is enabled you could prepend the initial prompt here.\r\n\r\nBUT, I think it might be more useful to parameterise how many previous sentences back to include in the prompt. For that the code would be a bit more complicated. But you could keep a FIFO buffer, e.g. to remember the last 3 sentences, you have a FIFO of size 3 containing the last 3 sentence boundary positions, which you put into the FIFO under the same condition as that first block of code above. The oldest sentence boundary gets popped out so you never have more than the last 3 in there.",
    "label": null
  },
  {
    "index": 393,
    "pr title": "add always_use_initial_prompt",
    "comment": "I use whisper ai for audio transcription and translation but since 25 February  it is not transcribing and Translating clearly !!!               I would be happy if anybody help me. plz ",
    "label": null
  },
  {
    "index": 394,
    "pr title": "add always_use_initial_prompt",
    "comment": "@ryanheise note that this code in `decoding.py:594` truncates the list of all prompt tokens (from the beginning), not the end. That means that simply prepending without checking for prompt window length will not always work. Truncation size depends on the model config.\r\n\r\n`tokens = ( [self.tokenizer.sot_prev] + prompt_tokens[-(self.n_ctx // 2 - 1) :] + tokens )`",
    "label": null
  },
  {
    "index": 395,
    "pr title": "add always_use_initial_prompt",
    "comment": "the output after this is just amazing\r\n\r\ni dont get why this is still not implemented ",
    "label": null
  },
  {
    "index": 396,
    "pr title": "add always_use_initial_prompt",
    "comment": "@mercury233 it is hallucinating significantly after this change. anyway to prevent it? other than that it works great. you found a solution for hallucination ? I can use very big beam size and best of but they didnt help. ",
    "label": null
  },
  {
    "index": 397,
    "pr title": "add always_use_initial_prompt",
    "comment": "> ```python\r\n>  not condition_on_previous_text or result.temperature > 0.5\r\n> ```\r\n\r\ncan you share modified file like this? i would like to test. currently it is having problems ",
    "label": null
  },
  {
    "index": 398,
    "pr title": "add always_use_initial_prompt",
    "comment": "yes with this way it is skipping 30 second blocks sometimes. we need optimization.  @mercury233 @ryanheise @radurevutchi ",
    "label": null
  },
  {
    "index": 399,
    "pr title": "add always_use_initial_prompt",
    "comment": "> @mercury233 it is hallucinating significantly after this change. anyway to prevent it? \r\n\r\nSorry, I didn't",
    "label": null
  },
  {
    "index": 400,
    "pr title": "add always_use_initial_prompt",
    "comment": "I have used the same basic idea of applying the initial prompt to every window to supply a dictionary of obscure words that might be in the transcript. It's very effective at boosting recognition of some words. However, I don't see it as in opposition to condition_on_previous text; the basic idea of using context from the end of the previous window to influence understanding of the beginning of the next window is still valuable.",
    "label": null
  },
  {
    "index": 401,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "From my understanding, this may be similar to Chinese which also has multiple written variants, although Chinese also has multiple spoken dialects. The way Whisper was trained, it was trained on all of these written and spoken variants under the umbrella of \"Chinese\", and so ultimately a single language code has to describe all of these. Since there is only one language code for Chinese, the way you get it to transcribe for a particular variant is therefore not by specifying a different language but by using the same language code and then using a prompt to get it off on the right foot with the variant. It may not be a strictly correct use of language codes, but the training is already done that way.\r\n\r\nI haven't tried transcribing Norwegian, but is it similar in that Whisper contains training data for both writing systems under a single umbrella of \"no\" which can be accessed by using a prompt to set it off in one of those two directions? If so, I'm not sure if changing it to \"nb\" would make sense.",
    "label": null
  },
  {
    "index": 402,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "[ryanheise]\n> From my understanding, this may be similar to Chinese which also has\n> multiple written variants, although Chinese also has multiple spoken\n> dialects.\n\nI believed China had several distinct languages with their own written\nlanguage as well as the written Mandarin standardized across the\ncountry, in addition to a lot of dialects of the different languages.\n\n> I haven't tried transcribing Norwegian, but is it similar in that\n> Whisper contains training data for both writing systems under a single\n> umbrella of \"no\" which can be accessed by using a prompt to set it off\n> in one of those two directions? If so, I'm not sure if changing it to\n> \"nb\" would make sense.\n\nThe transcribing I have tested so far gave me Norwegian Bokm√•l.  Not\nsure how to to prompt it to switch to Norwegian Nynorsk.\n\n-- \nHappy hacking\nPetter Reinholdtsen\n",
    "label": null
  },
  {
    "index": 403,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "You can try using `--initial_prompt \"Some introductory pre-sentence written in the Norwegian Nynorsk script.\"`\r\n\r\nSo you just write a made-up sentence in the script you want, and you might get better results if it is a sentence that you could plausibly imagine as having been spoken before the first actual sentence in the audio you're transcribing.",
    "label": null
  },
  {
    "index": 404,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "The rest of the world uses no and doing this change would result in numerous posts all over the world asking why -no doesn't work. Not to mention the hundreds of guides and copies of documentation the uses -no\r\n\r\nAs a minimum -no should be kept for legacy support and nn and nb should only be implemented if whisper actually knows the difference.",
    "label": null
  },
  {
    "index": 405,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "There are for sure quite a few using the Norwegian language codes incorrectly, or confuse the country and language code.  Because of this it is a good idea to keep the incorrect 'no' language code still working as an alias, probably for the W3C recommended 'nb' code.\r\n\r\nIn any case, if Whisper is unable to know the difference between Nynorsk and Bokm√•l, I guess the entire question is moot.",
    "label": null
  },
  {
    "index": 406,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "> You can try using `--initial_prompt \"Some introductory pre-sentence written in the Norwegian Nynorsk script.\"`\r\n\r\nBy the way, did you get around to trying this?",
    "label": null
  },
  {
    "index": 407,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "\n[ryanheise]\n> By the way, did you get around to trying this?\n\nI did, running this using a random nynorsk piece on youtube,\n<URL: https://yewtu.be/watch?v=s7olTWEIwAI >.\n\n  whisper --model medium Are\\ Kalv√∏\\ -\\ K√•seri\\ om\\ nynorsk\\ \\[s7olTWEIwAI\\].webm --language Nynorsk --initial_prompt \"eg heitar\"\n\nSadly the resulting transcription is of very low quality:\n\n  Den st√∏rste fordelen me √• bruke ny norsk er at det gj√¶r det lett √•\n  framst√• som langt meir intresang enn du faktisk er.  For oss som\n  koserer er det for eksempel helt opplagt enn fordel √• bruke ny norsk.\n\nThere are several typos and inaccuracies here at the start of the\nrecording. :)\n\n-- \nHappy hacking\nPetter Reinholdtsen\n",
    "label": null
  },
  {
    "index": 408,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "Normally I would say that \"eg heitar\" isn't actually a pre-sentence, it's only two words, no full stop at the end, etc. and probably not a great prompt to teach Whisper what style to continue in. Although that being said, I don't hold out any hopes that it will work well if you're getting typos. That feels like there's limited training data for that script.",
    "label": null
  },
  {
    "index": 409,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "We originally collected the language tags from the [VoxLingua107](https://bark.phon.ioc.ee/voxlingua107/) dataset, but 100% of the transcription data had `no`, and no `nn` label. We had some `nn` labels in the translation data, but I guess that's less relevant when the input is spoken Norwegian and output is English.\r\n\r\nSo the labeling was a bit haphazard, but I think it still makes sense to keep the macrolanguage label `no`, considering that that labels would've contained a mixture of Bokm√•l and Nynorsk. (It appears that most were in Bokm√•l though, as the Nynorsk prompting example above didn't work very well unfortunately.)",
    "label": null
  },
  {
    "index": 410,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "\n[Jong Wook Kim]\n> We originally collected the language tags from the\n> [VoxLingua107](https://bark.phon.ioc.ee/voxlingua107/) dataset, but\n> 100% of the transcription data had `no`, and no `nn` label. We had\n> some `nn` labels in the translation data, but I guess that's less\n> relevant when the input is spoken Norwegian and output is English.\n\nThis is not really surprising that Voxlingual07 used 'no', given that it\nstates \"VoxLingua107 is a speech dataset for training spoken language\nidentification models.\"  There is a difference between language codes\nfor spoken language and written language in Norway.  The Norwegian\nBokm√•l and Nynorsk are written languages, while the spoken language is a\ndialect of Norwegian.  So all written Norwegian should use either 'nb'\nor 'nn', and spoken language could use 'no'.  If you only found 'no' in\ntranscription data, the transcriptions are misclassified, and most\nlikely should have been classified as 'nb', the written variant used by\nmost people in Norway.\n\n> So the labeling was a bit haphazard, but I think it still makes sense\n> to keep the macrolanguage label `no`, considering that that labels\n> would've contained a mixture of Bokm√•l and Nynorsk. (It appears that\n> most were in Bokm√•l though, as the Nynorsk prompting example above\n> didn't work very well unfortunately.)\n\nYeah.  Hope someone can do a better job at training a system to write\nNorwegian Bokm√•l and Nynorsk with the correct classicication in the\nfuture.  At least the issue is better known in the Whisper community\nnow.\n\nNote, there are ways to fairly accurately detect if the written text is\nNynorsk or Bokm√•l by looking for marker words like 'jeg'(nb) vs 'eg'(nn)\nog 'en'(nb) vs 'ein'(nn).\n\n-- \nHappy hacking\nPetter Reinholdtsen\n",
    "label": null
  },
  {
    "index": 411,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "I was looking into this recently and one approach to work around Whisper's inclination toward Bokm√•l (based on its training data for `no`) would be to just use a separate tool to convert Whisper's Bokm√•l output into Nynorsk in post processing.\r\n\r\nFor example, [Apertium](https://www.apertium.org/) can be used, and can be installed locally (making it also helpful for automated pipelines).\r\n\r\nThe specific Bokm√•l/Nynorsk module for Apertium is [here](https://github.com/apertium/apertium-nno-nob), including some examples of its output.\r\n\r\nFor timestamps, the two scripts are at least textually similar enough to match them up (e.g. [Diff Match Patch](https://neil.fraser.name/software/diff_match_patch/demos/diff.html)). An easier way might be to just embed timestamps of the form 00:24:07 into the source text and see if Apertium preserves them in place without disrupting the translation process. It seems to work, but I haven't fully tested that.",
    "label": null
  },
  {
    "index": 412,
    "pr title": "Replaced 'no' langauge code with 'nb' and use full norwegian language names",
    "comment": "[ryanheise]\r\n> I was looking into this recently and one approach to work around\r\n> Whisper's inclination toward Bokm√•l (based on its training data for\r\n> `no`) would be to just use a separate tool to convert Whisper's Bokm√•l\r\n> output into Nynorsk in post processing.\r\n\r\nThis is a good point, and Apertium is doing a very good job as\r\nconverting Bokm√•l to Nynorsk.  But sadly it also require seriuos proof\r\nreading as it is far from perfect, according to the creator of the\r\nnb->nn Apertium transformer. :)\r\n\r\nIn any case, the main takeaway here is that the 'no' language code is\r\nfor a spoken language, while the 'nb' and 'nn' language codes are for\r\nwritten languages.\r\n\r\n-- \r\nHappy hacking\r\nPetter Reinholdtsen\r\n",
    "label": null
  },
  {
    "index": 413,
    "pr title": "Add support for AMD GPU (ROCm Platform)",
    "comment": "Instead of using environment variable, i suggest to use `extras_require` as could be see in [here](https://setuptools.pypa.io/en/latest/userguide/dependency_management.html#optional-dependencies). Another option is to automatically detect if it is using ROCm platform.",
    "label": null
  },
  {
    "index": 414,
    "pr title": "Add support for AMD GPU (ROCm Platform)",
    "comment": "Based on the suggestion, remove environmental variable and add function to detect ROCm Platform automatically.",
    "label": null
  },
  {
    "index": 415,
    "pr title": "Add support for AMD GPU (ROCm Platform)",
    "comment": "Will this work with generic AMD gpus, ie newer integrated gpus?",
    "label": null
  },
  {
    "index": 416,
    "pr title": "Add support for AMD GPU (ROCm Platform)",
    "comment": "> Will this work with generic AMD gpus, ie newer integrated gpus?\r\n\r\n@x86Gr This is the list of supported GPUs\r\n\r\nhttps://rocm.docs.amd.com/en/latest/release/gpu_os_support.html",
    "label": null
  },
  {
    "index": 417,
    "pr title": "Add support for AMD GPU (ROCm Platform)",
    "comment": "@x86Gr @glangford \r\nThis link should work: https://rocm.docs.amd.com/en/latest/release/gpu_os_support.html#linux-supported-gpus\r\n",
    "label": null
  },
  {
    "index": 418,
    "pr title": "Add support for AMD GPU (ROCm Platform)",
    "comment": "Any particular reason the PR only selected a subset of supported AMD GPUs? \r\n\r\ngfx1030 or gfx1100 appear to be missing",
    "label": null
  },
  {
    "index": 419,
    "pr title": "Add support for AMD GPU (ROCm Platform)",
    "comment": "@vadimkantorov  @Reviewer  of this PR. Is there any update about review to merge  this PR? Is there  anything I can help to speed up the process?  Thanks!",
    "label": null
  },
  {
    "index": 420,
    "pr title": "Add support for AMD GPU (ROCm Platform)",
    "comment": "running `pip install .` on that branch shows me \r\n```\r\n% pip install .            \r\nProcessing <snip>whisper/whisper\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nINFO: pip is looking at multiple versions of openai-whisper to determine which version is compatible with other requirements. This could take a while.\r\nERROR: Could not find a version that satisfies the requirement pytorch-triton-rocm>=2.0.1 (from openai-whisper) (from versions: 0.0.1)\r\nERROR: No matching distribution found for pytorch-triton-rocm>=2.0.1\r\n```\r\nwhat am i missing here?\r\n\r\n--\r\nEdit:\r\nNevermind, `pip install --upgrade --no-deps torch pytorch-triton-rocm --index-url https://download.pytorch.org/whl/rocm6.2` solved it. Maybe we should add that to the readme?",
    "label": null
  },
  {
    "index": 421,
    "pr title": "Add CSV formatted output in transcript, using integer start/end times in milliseconds.",
    "comment": "The CSV seems to just multiply the range by 1000 to get ms resolution.  Could we please have actual ms resolution for the speakers?  If doing text-to-speech of a natural conversation, and trying to combine it with speaker recognition (pytorch for example), two persons may speak in the same second.  We don't know who said what.  Therefore, if we had ms resolution out of whisper, we could easily know who said what sentence in a natural conversation.",
    "label": null
  },
  {
    "index": 422,
    "pr title": "Add CSV formatted output in transcript, using integer start/end times in milliseconds.",
    "comment": "To use Whisper for subtitles, Millisecond resolution would be a big plus. ",
    "label": null
  },
  {
    "index": 423,
    "pr title": "Add CSV formatted output in transcript, using integer start/end times in milliseconds.",
    "comment": "@ksn-systems that is precisely why I made this change. See #233 for details.",
    "label": null
  },
  {
    "index": 424,
    "pr title": "Add CSV formatted output in transcript, using integer start/end times in milliseconds.",
    "comment": "@jongwook  would it be possible to \"approve the workflow\" as I see this PR is stuck at \"1 workflow awaiting approval\".\r\n\r\nIs there anything I should change or clarify in order to get this PR merged or get the \"workflow awaiting approval\" to be satisfied?\r\n\r\nPlease note a similar PR was merged for whisper.cpp  ( https://github.com/ggerganov/whisper.cpp/pull/340 ). Having this functionality in place for whisper allows for easier comparison of results between implementations, via easier importing into spreadsheets and databases supporting the CSV format.",
    "label": null
  },
  {
    "index": 425,
    "pr title": "Add CSV formatted output in transcript, using integer start/end times in milliseconds.",
    "comment": "@NielsMayer Thanks for the PR! Would it work for you if I make this `write_tsv` instead? CSV format is not standardized and `csv.reader` and `pandas.read_csv` often create headache parsing quotes.\r\n\r\nI should probably merge #333 first with some modifications as the number of output files is becoming unwieldly.",
    "label": null
  },
  {
    "index": 426,
    "pr title": "Add CSV formatted output in transcript, using integer start/end times in milliseconds.",
    "comment": "> @NielsMayer Thanks for the PR! Would it work for you if I make this `write_tsv` instead? CSV format is not standardized and `csv.reader` and `pandas.read_csv` often create headache parsing quotes.\r\n> \r\n> I should probably merge #333 first with some modifications as the number of output files is becoming unwieldly.\r\n\r\nYes, merging #333 makes sense. If you do that first, I will update this PR to conform to the changes made, e.g. add additional csv (or tsv) output format keyword.\r\n\r\nW/r/t changing from CSV to TSV, that is fine by me as it would require a trivial change on my end. The reason why I chose CSV is that it seems more \"standard\";  although most of the programs automatically importing from CSV just as easily handle TSV. \r\n\r\nI'm not familiar with the comma issues you mention in csv.reader or pandas.read_csv, however, do note that I updated the code for compatibility with importing into, e.g. openoffice, where string type is automatically recognized if delimited by '\"' character.  To prevent issues, Internal `\"` in each CSV text line  is replaced by two consecutive single quotes `''` ... Note: ` print('\"' + segment['text'].strip().replace('\"', \"''\") + '\"'`\r\n\r\nChances are, such formatting and lack of special escape character means the existing solution would work with the readers you mention, @jongwook .\r\n\r\nPS: I updated my repo for this PR to the latest head of repository from whisper, so once again, there is a \"workflow awaiting approval\" message...",
    "label": null
  },
  {
    "index": 427,
    "pr title": "Add CSV formatted output in transcript, using integer start/end times in milliseconds.",
    "comment": "FYI here's a whisper CSV file read into libreoffice on a linux desktop. Note the \" replaced by '' \r\n(orig source: https://rumble.com/v2619vq-bills-proliferate-to-criminalize-speech-darren-beattie-on-lex-and-brazil-fa.html )\r\n```\r\n3171020 | 3172820 | and he is up right now.\r\n3172820 | 3176820 | [''System Updates,'' main theme music playing.]\r\n3182620 | 3183760 | Great to be here.\r\n```\r\n\r\n@jongwook how on earth did whisper figure out that ` [''System Updates,'' main theme music playing.]` -- I mean how did it figure out the name of the show (\"remembered\" the announcement of the show name at the beginning, sometimes an hour earlier?) \r\n\r\nSometimes however it gets the theme music wrong on the same show, but different episode: ( https://rumble.com/v24mywg-what-really-happened-in-brazil-yesterday-system-update-18.html )\r\n`\"[''The Daily Show Theme'']\"\r\n\r\nLikewise how is whisper figuring out where quotes start and end? It's kind of spooky actually! :-)",
    "label": null
  },
  {
    "index": 428,
    "pr title": "Add CSV formatted output in transcript, using integer start/end times in milliseconds.",
    "comment": "Thanks for accommodating the TSV suggestion! I merged a refactored version of #333 and edited this PR accordingly.\r\n\r\nThe issue about CSV is that, although CSV is more widely used and well known, even the simplest possible case like:\r\n\r\n```csv\r\nstart, end, text\r\n1234, 12345, \"hello, world!\"\r\n```\r\n\r\nresults in very inconsistent user experience according to the program because of the lack of standardization around the quotation marks:\r\n\r\n**Apple Quick Look:**\r\n<img width=\"176\" alt=\"image\" src=\"https://user-images.githubusercontent.com/266841/213907134-61c0790b-f92b-4a5b-bdfb-f714835aac50.png\">\r\n\r\n**Apple Numbers:**\r\n<img width=\"200\" alt=\"image\" src=\"https://user-images.githubusercontent.com/266841/213907251-577c1a5b-83b4-47dc-a3dd-25ccff3c69da.png\">\r\n\r\n**`csv.reader()`:**\r\n<img width=\"568\" alt=\"image\" src=\"https://user-images.githubusercontent.com/266841/213907278-ce67bbc7-0331-4ef2-bafd-e1b7860c58a6.png\">\r\n\r\n**pandas.read_csv()**\r\n<img width=\"229\" alt=\"image\" src=\"https://user-images.githubusercontent.com/266841/213907322-a997810e-3a72-4e34-9e0d-0371b83f988c.png\">\r\n\r\nThe latter two are the most common way to read CSV files in Python -- there are some combination of options to read the file as intended, but it's inconvenient and not practical to expect the users to use the \"correct\" configuration for all reader implementations.\r\n\r\n\r\nMeanwhile, TSV doesn't need to deal with quoting because the field values are not allowed to contain tab characters.\r\n\r\n---\r\n\r\nRe: the second comment, because of the way that Whisper was trained, the model must have encountered the exact music and the text `[\"System Updates\" main theme music playing.]` multiple times during training. It's usually an undesired behavior, and we tried to mitigate this (rather hackily) by suppressing the `[` character by default.\r\n",
    "label": null
  },
  {
    "index": 429,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Thanks for taking the time to do this!\n",
    "label": null
  },
  {
    "index": 430,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Are you serious ?\nThe meaning of a word is defined by its use, by the context.\nIn this case, _master_/_slave_ is used by every database server, in every documentation ([redis](http://redis.io/topics/replication), [mysql](http://dev.mysql.com/doc/refman/5.0/en/replication-howto.html) ‚Ä¶)\n\nNB: I don't say I'm against this change. Just that I don't see the point of changing two words with two others just because they have been used somewhere else.\nFor example, your avatar is red. Red, like communism. You should use a black and white color. Oh no, that's linked to racism too. Well. Let's remove colors, too, then ? ;)\n",
    "label": null
  },
  {
    "index": 431,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "As you can see from https://github.com/django/django/commit/beec05686ccc3bee8461f9a5a02c607a02352ae1 the terminology we have actually used is \"primary/replica\". So thank you for your interest, but there's nothing to see here and you can move along now.\n",
    "label": null
  },
  {
    "index": 432,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Before the flood of white male HN dwellers truly kicks off and obliterates all reasonable discussion, I'd like to thank the Django team for taking the time to do this.\n",
    "label": null
  },
  {
    "index": 433,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "i'm just here for the laughs. is IT becoming too stupid? has science gone too far?\n",
    "label": null
  },
  {
    "index": 434,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Discussion on the ticket: https://code.djangoproject.com/ticket/22667\n\"Primary\" and \"Replica\" aren't especially bad choices, but they're also wrong. The correct terms are `master` and `slave`. They've been used in databases, hardware setups, server setups and god knows what else for god knows how long.\n\nI cannot f_ing believe this PR made it through and was given actual man hours when there are massive outstanding PRs and patches on trac that need real attention. And don't be surprised that this does make it on HN and probably later on the usual slashdot/phoronix and what not. This is stupid *and_ controversial which is exactly what tech media loves.\n\nAnd to the HN/whatever crowd, don't post stupid memes here. This isn't the place.\n\nHelp yourselves and revert this, guys. Django docs, or docs in general are not the place to make up new terms for stuff that already exists.\n\nPS: Quick heads up: This made it to 4chan and various other troll places. Do not be surprised if there's suddenly an influx of .. weird comments.\n",
    "label": null
  },
  {
    "index": 435,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "This is silly.\nNext we will remove all mention og objects because some people might feel objectified.\nOr classes, because of the poor people that feels they are being discriminated against.\n\nSure, I understand that the use of words can hurt, but words themselves carry no meaning outside of it's use. Saying a car is yellow and calling a person yellow are two very different statements. We seem to have a new round of book burnings going on today...\n",
    "label": null
  },
  {
    "index": 436,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Guys, just ignore this. These are bots who do this automatically for projects, which have been circling around on Github lately. There are also ones about feminism etc. The Linux kernel also had a PR like this a few months ago with a massive amount of responses on it.\n\nDon't feed the trolls, and just continue to use `master` and `slave`.\n",
    "label": null
  },
  {
    "index": 437,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Faith in humanity restored. Thank you guys. I just want to add, that this will also be bad for django itself, since almost every developer who is no aware of this will be confused, and trust me - he will be expecting that this is some bizarre django thing, not the well known pattern. Peace.\n",
    "label": null
  },
  {
    "index": 438,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Thanks so much Django for doing this thing! <3\n",
    "label": null
  },
  {
    "index": 439,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Excellent stuff. Thanks for doing that.\n",
    "label": null
  },
  {
    "index": 440,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "I'm very glad for this change because as a PoC I felt very uncomfortable seeing and using this terminology in my code\n",
    "label": null
  },
  {
    "index": 441,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "glad to see big projects taking this seriously\n",
    "label": null
  },
  {
    "index": 442,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Thanks Django for making this important change to be more welcoming and inclusive to more members of the tech community. <3 \n",
    "label": null
  },
  {
    "index": 443,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "\"they've always been called that\" is a dumb reason to keep doing something, especially something that is hurtful or alienating. Kudos to Django for making this change! \n",
    "label": null
  },
  {
    "index": 444,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "The use of the terms `master` and `slave` in relation to databases (and hardware configurations) has always made me uncomfortable. I think the terms `leader` and `follower` are much more appropriate, and are actually more expressive. :heart: to the Django team for making this change!\n",
    "label": null
  },
  {
    "index": 445,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "These terms have been in use forever, but that doesn't make them good. Fixing them has to start somewhere; good for Django for taking the lead.\n",
    "label": null
  },
  {
    "index": 446,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": ":+1: \nGreat job @fcurella, thank you @alex & Django.\n",
    "label": null
  },
  {
    "index": 447,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Awesome change, thanks @fcurella! \"Primary/replica\" sounds much better.\n",
    "label": null
  },
  {
    "index": 448,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Good. The old terminology should be made obsolete.\n",
    "label": null
  },
  {
    "index": 449,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Thank you so much for making this change!\n",
    "label": null
  },
  {
    "index": 450,
    "pr title": "#22667 replaced occurrences of master/slave terminology with leader/follower",
    "comment": "Awesome change. Another reason to love the Django project :)\n",
    "label": null
  },
  {
    "index": 451,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "I was trying out this exciting branch and ran into this error when running a test:\r\n```\r\n<...>/lib/python3.12/site-packages/django/db/models/lookups.py:30: in __init__\r\n    self.rhs = self.get_prep_lookup()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = TupleIn(<django.db.models.fields.composite.Cols object at 0x107560980>, <django.db.models.sql.query.Query object at 0x1074e23f0>)\r\n\r\n    def get_prep_lookup(self):\r\n        if not isinstance(self.lhs, Cols):\r\n            raise ValueError(\r\n                \"The left-hand side of the 'in' lookup must be an instance of Cols\"\r\n            )\r\n        if not isinstance(self.rhs, Iterable):\r\n>           raise ValueError(\r\n                \"The right-hand side of the 'in' lookup must be an iterable\"\r\n            )\r\nE           ValueError: The right-hand side of the 'in' lookup must be an iterable\r\n```\r\n\r\nThe issue stems from the use of `isnull` like so:\r\n\r\n```\r\nMyModel.objects.filter(\r\n    type_override__severity__isnull=False\r\n).update(severity=\"high\")\r\n```\r\n\r\nCurious if anyone ran into this as well.\r\n\r\nEdited for traceback:\r\n\r\n```\r\n<...>\r\nlib/python3.12/site-packages/django/db/models/sql/compiler.py:2080: in pre_sql_setup\r\n    self.query.add_filter(\"pk__in\", query)\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1601: in add_filter\r\n    self.add_q(Q((filter_lhs, filter_rhs)))\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1617: in add_q\r\n    clause, _ = self._add_q(q_object, self.used_aliases)\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1649: in _add_q\r\n    child_clause, needed_inner = self.build_filter(\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1563: in build_filter\r\n    condition = self.build_lookup(lookups, col, value)\r\nlib/python3.12/site-packages/django/db/models/sql/query.py:1393: in build_lookup\r\n    lookup = lookup_class(lhs, rhs)\r\nlib/python3.12/site-packages/django/db/models/lookups.py:30: in __init__\r\n    self.rhs = self.get_prep_lookup()\r\n```\r\n\r\nSo, this is part of `SQLUpdateCompiler` and is coming from the `update` code path.",
    "label": null
  },
  {
    "index": 452,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Thanks for testing and reporting the issue @grjones! Indeed, I forgot to handle this use case. I'll look into it this week.",
    "label": null
  },
  {
    "index": 453,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "@grjones, FYI I pushed the fix",
    "label": null
  },
  {
    "index": 454,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "> @grjones, FYI I pushed the fix\r\n\r\nNice! I hope this gets merged in soon. Your branch has been working great for me.",
    "label": null
  },
  {
    "index": 455,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "I may have found one other small issue. When adding a regular `primary_key=True` on a single field, a unique constraint is added. But when using this branch, it becomes an `IntegrityError` instead. Adding a `UniqueConstraint` on the composite fields is a work-a-round but ideally would be captured in this PR. Imo, this PR is sooooo close. I'm excited for it to be merged in.",
    "label": null
  },
  {
    "index": 456,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "@grjones , thanks, I appreciate the feedback, I'll look into it. If a model defines `Meta.primary_key`, defining `primary_key=True` on a field should not be possible - could you give me a code example so I know how to reproduce the issue? I didn't know Django added unique constraints to primary keys, I'll check, but isn't that redundant?",
    "label": null
  },
  {
    "index": 457,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "> @grjones , thanks, I appreciate the feedback, I'll look into it. If a model defines `Meta.primary_key`, defining `primary_key=True` on a field should not be possible - could you give me a code example so I know how to reproduce the issue? I didn't know Django added unique constraints to primary keys, I'll check, but isn't that redundant?\r\n\r\nI'll see if I can give you a solid failing test. My \"unique constraint\" phrasing might not be exactly right. But ultimately, I believe Django queries the DB first to see if the new object's PK already exists and throws a validation error. The composite key logic doesn't seem to be doing that and so an unhandled IntegrityError is raised instead.",
    "label": null
  },
  {
    "index": 458,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "@grjones , sorry for the late reply, I've been busy last week. Could you give me more specifics? What's the error message you expect?",
    "label": null
  },
  {
    "index": 459,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "> @grjones , sorry for the late reply, I've been busy last week. Could you give me more specifics? What's the error message you expect?\r\n\r\nActually, I think it's mostly ok. I was using [Django Spanner](https://github.com/googleapis/python-spanner-django) and it's just not quite working with composite keys and will need to be fixed there. I wrote this and it passed. It probably shouldn't say `Id` though?\r\n\r\n```\r\nfrom django.core.exceptions import ValidationError\r\nfrom django.test import TestCase\r\n\r\nfrom .models import Tenant, User\r\n\r\n\r\nclass CompositePKCleanTests(TestCase):\r\n    \"\"\"\r\n    Test the .clean() method of composite_pk models.\r\n    \"\"\"\r\n\r\n    @classmethod\r\n    def setUpTestData(cls):\r\n        cls.tenant = Tenant.objects.create()\r\n\r\n    def test_validation_error_is_raised_when_pk_already_exists(self):\r\n        test_cases = [\r\n            {\"tenant\": self.tenant, \"id\": 2412, \"email\": \"user2412@example.com\"},\r\n            {\"tenant_id\": self.tenant.id, \"id\": 5316, \"email\": \"user5316@example.com\"},\r\n            {\"pk\": (self.tenant.id, 7424), \"email\": \"user7424@example.com\"},\r\n        ]\r\n        expected = \"{'id': ['User with this Id already exists.']}\"\r\n        for fields in test_cases:\r\n            User.objects.create(**fields)\r\n            with self.assertRaisesMessage(ValidationError, expected):\r\n                User(**fields).clean()\r\n```",
    "label": null
  },
  {
    "index": 460,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Thank you so much for taking the time to review my changes @LilyFoote !\r\nI have two questions:\r\n\r\n1. If `Meta.primary_key` is defined, this PR will automatically add a composite field called `primary_key` to the model. What do you think about this approach? I felt like it was easier to handle the composite primary keys this way as we can run checks against the meta class instead of traversing the model's fields for a composite field.\r\n2. I wrote a lot of tests testing the underlying queries made by the ORM. It makes a lot of sense to me, but I haven't seen this type of tests that much in the Django source code - do these tests look okay to you?",
    "label": null
  },
  {
    "index": 461,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": " \r\n> If `Meta.primary_key` is defined, this PR will automatically add a composite field called `primary_key` to the model. What do you think about this approach?\r\n\r\nI don't feel strongly that this is better or worse than another option here, so happy to go with what you think is best.\r\n\r\n> I wrote a lot of tests testing the underlying queries made by the ORM. It makes a lot of sense to me, but I haven't seen this type of tests that much in the Django source code - do these tests look okay to you?\r\n\r\nI like your tests quite a bit - they're pretty readable and comprehensive. The main issue I have with them is that they're written for specific databases instead of for generic database features. Where possible Django strongly prefers to test based on features because then the tests apply to as many databases as possible (including third party database libraries). I think the asserts of the actual SQL might be a bit tricky to adapt though, so we might need a different way to check what they're checking.\r\n\r\nAlso, after I reviewed yesterday, I thought of some more things:\r\n\r\n* We should add migrations tests to make sure that adding/removing `Meta.primary_key` works correctly and that removing a field that's part of a primary key also does something appropriate.\r\n* We might want tests for composite keys in forms and the admin. Maybe there's other areas too that we need to check the interactions.",
    "label": null
  },
  {
    "index": 462,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Thanks @charettes !\r\n\r\n> Something that came through my mind while reviewing is that we likely want a plan to eventually deprecate `Options.pk` in favor of `Options.primary_key`?\r\n\r\nI'm not sure what you mean by that, I don't think we can, because `Options.pk` refers to the field, while `Options.primary_key` is the list of field names.",
    "label": null
  },
  {
    "index": 463,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "So as far as I understand, at the moment `MultiColSource` is used by Django internally to represent `JOIN`s on multiple fields - that's why it has a `sources` field.\r\n\r\nI'm not sure it's the right decision to reuse this for composite fields, which on the other hand don't need `sources`, it just needs to represent a list of `Col`s as an expression.\r\n\r\nLet me know what you think!",
    "label": null
  },
  {
    "index": 464,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "> I'm not sure what you mean by that, I don't think we can, because Options.pk refers to the field, while Options.primary_key is the list of field names.\r\n\r\nYou're completely right. In this case is `pk` set to `CompositePrimaryKey` when `Meta.primary_key` is defined and is `primary_key` set when a non-composite primary is used as well?",
    "label": null
  },
  {
    "index": 465,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "> > I'm not sure what you mean by that, I don't think we can, because Options.pk refers to the field, while Options.primary_key is the list of field names.\r\n> \r\n> You're completely right. In this case is `pk` set to `CompositePrimaryKey` when `Meta.primary_key` is defined and is `primary_key` set when a non-composite primary is used as well?\r\n\r\nIt would not be set, if it's a regular primary key, `Meta.primary_key` is `None`.",
    "label": null
  },
  {
    "index": 466,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Hey @csirmazbendeguz, thank you for the amazing work out there! I was trying to test this branch on my local with SQLite and realised a few things:\r\n\r\n1. If you run `makemigrations` for a model with a `CompositePrimaryKey`, the resulting migration file has erroneous imports. To fix this, I believe we need to add `django.db.models.fields.composite` path to the `if...elif` block [here](https://github.com/django/django/blob/main/django/db/models/fields/__init__.py#L645).\r\n2. Assume that I have the following models:\r\n\r\n    ```py\r\n    class Author(models.Model):\r\n    name = models.CharField(max_length=100)\r\n\r\n    class Book(models.Model):\r\n        id = models.CompositePrimaryKey(\"author\", \"title\")\r\n        author = models.ForeignKey(Author, on_delete=models.CASCADE, related_name=\"books\")\r\n        title = models.CharField(max_length=255)\r\n    ```\r\n\r\n    With the current implementation, following test fails:\r\n    ```py\r\n    class TestCompositeFks(TestCase):\r\n        def test_composite_fks(self):\r\n            author = Author.objects.create(name=\"Author\")\r\n            book = Book.objects.create(author=author, title=\"Title\")\r\n            list(Author.objects.filter(books__in=[book])) == book\r\n    ```\r\n    with an `OperationalError`, caused by a syntax error. Executed SQL is as following:\r\n    ```SQL\r\n    SELECT\r\n        \"books_author\".\"id\",\r\n        \"books_author\".\"name\"\r\n    FROM\r\n        \"books_author\"\r\n        INNER JOIN \"books_book\" ON (\"books_author\".\"id\" = \"books_book\".\"author_id\")\r\n    WHERE\r\n        \"books_book\".\"author_id\", \"books_book\".\"title\" IN ((1, 'Title'))\r\n    ```\r\n    because LHS in WHERE clause should have been wrapped with parantheses like this:\r\n    ```SQL\r\n    ...\r\n    WHERE\r\n        (\"books_book\".\"author_id\", \"books_book\".\"title\") IN ((1, 'Title'))\r\n    ```\r\n    Unfortunately I didn't have a time to deep-dive to this.\r\n3. Not a big issue but my code editor (VSCode) does not recognize `models.CompositePrimaryKey`, although the import is working fine. This is probably related with Pylance or something that VSCode uses to recognize fields under `models` module.\r\n\r\nAgain thanks for this amazing initiative! üöÄ ",
    "label": null
  },
  {
    "index": 467,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Thanks a lot for the review @omerfarukabaci ! I'll take a look",
    "label": null
  },
  {
    "index": 468,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "> Author.objects.filter(books__in=[book])\r\n\r\n@omerfarukabaci , I pushed the changes to support this, but note that filtering on reverse relations is one of those \"gotchas\" in Django, it may not produce the results you expect.\r\n\r\n_EDIT: I mean it might return duplicates, you probably already know this, I'm just mentioning it just in case._",
    "label": null
  },
  {
    "index": 469,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "> If you run makemigrations for a model with a CompositePrimaryKey, the resulting migration file has erroneous imports\r\n\r\nYes, I recently changed the API to `CompositePrimaryKey`, the migrations are not 100% yet. I'm working on sorting them out.\r\nI pushed the fix for the issue you mentioned, thanks üëç ",
    "label": null
  },
  {
    "index": 470,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "@csirmazbendeguz Thanks for your answers, now the above issues seem like fixed, created migration is correct and reverse relation lookup is working as expected. Thank you! üöÄ\r\n\r\nWhile I was testing it further with the exact [same models](https://github.com/django/django/pull/18056#issuecomment-2158820017), I realized another issue:\r\n\r\n```py\r\nclass TestCompositeFks(TestCase):\r\n    def test_composite_fks(self):\r\n        author = Author.objects.create(name=\"Author\")\r\n        Book.objects.create(author=author, title=\"Title\")\r\n        author = Author.objects.annotate(book_count=Count(\"books\")).get()\r\n        assert author.book_count == 1\r\n```\r\n\r\nThis test fails with the following error:\r\n\r\n```\r\ndjango.db.utils.OperationalError: wrong number of arguments to function COUNT()\r\n```\r\n\r\nExecuted SQL is as following:\r\n\r\n```SQL\r\nSELECT\r\n    \"books_author\".\"id\",\r\n    \"books_author\".\"name\",\r\n    COUNT(\"books_book\".\"author_id\", \"books_book\".\"title\") AS \"book_count\"\r\nFROM\r\n    \"books_author\"\r\n    LEFT OUTER JOIN \"books_book\" ON (\"books_author\".\"id\" = \"books_book\".\"author_id\")\r\nGROUP BY\r\n    \"books_author\".\"id\",\r\n    \"books_author\".\"name\"\r\n```\r\n\r\nIf we could change the parameter we pass to the `COUNT` function to a concatenation as below:\r\n\r\n```SQL\r\nCOUNT(\"books_book\".\"author_id\" || '-' || \"books_book\".\"title\")\r\n```\r\n\r\nit should work fine (if I am not missing something), with the exception that for some databases we need to use `CONCAT` function instead of `||` operator, which might be resolved using the existing `db.models.functions.Concat` function.\r\n\r\nNote: I am not sure if concatenation works between every data type that is allowed to be a primary key, although this could be considered as an edge case.",
    "label": null
  },
  {
    "index": 471,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Thanks @omerfarukabaci , these bug reports are very helpful. Yes, I haven't considered annotations with multi-column pks. I'll look into this.",
    "label": null
  },
  {
    "index": 472,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Thanks @LilyFoote , @sarahboyce for the meeting.\r\nNotes:\r\n1. At the moment, `Count(\"books\")` is not too easy to fix. It could be written as `Count(\"books__author_id\")` and it would work. If we cannot fix it, we should document it. Maybe we could use `*` instead of `pk` for counting?\r\n2. The content types framework will not work with composite pks. This includes everything that depends on the content types framework, e.g. the `contrib.auth` module too.",
    "label": null
  },
  {
    "index": 473,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "I squsahed all commits and rebased to latest main branch.",
    "label": null
  },
  {
    "index": 474,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Idea: how about calling the field `PrimaryKey` instead of `CompositePrimaryKey`?",
    "label": null
  },
  {
    "index": 475,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "@omerfarukabaci , I thought about the issue of `Count(\"books\")`.\r\n\r\nMy conclusion is we can't support this.\r\n\r\nI don't think concatenating is a good solution. The only way we could support this is if we could get Django to count this with `*` instead of the primary key.\r\n\r\nThis is an edge case that is only needed for `Count` though, and it's not as simple to implement as it is to explain.\r\n\r\nI added a section to the docs about this. This is a case of using a database function with a composite primary key directly, which cannot be expected to work in general.\r\n\r\nIn your case, `Count(\"books__author_id\")` would do the trick instead.",
    "label": null
  },
  {
    "index": 476,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Regarding the issue raised by @sarahboyce last week...\r\n\r\nI think it is okay to merge this without support for generic relations. I added a section to the docs about this not being supported for now.\r\n\r\nThe only impact is some third-party packages using generic relations won't work with composite primary keys (e.g. `django-guardian`).\r\n\r\nLet's have a separate discussion on how to support this. I lean towards storing composite primary keys serialized as JSON in a single CharField.",
    "label": null
  },
  {
    "index": 477,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Btw, semantically it would be nice if it were possible to write:\r\n```python \r\nclass User(models.Model):\r\n    pk = models.CompositePrimaryKey(\"tenant_id\", \"id\")\r\n    tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE)\r\n    id = models.IntegerField()\r\n```\r\n\r\nie to let `CompositePrimaryKey` replace the automatically generated `pk`. Would that be possible?",
    "label": null
  },
  {
    "index": 478,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "> Btw, semantically it would be nice if it were possible to write:\r\n> \r\n> ```python\r\n> class User(models.Model):\r\n>     pk = models.CompositePrimaryKey(\"tenant_id\", \"id\")\r\n>     tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE)\r\n>     id = models.IntegerField()\r\n> ```\r\n> \r\n> ie to let `CompositePrimaryKey` replace the automatically generated `pk`. Would that be possible?\r\n\r\n@apollo13 , good point! It also came up when we were discussing this with @LilyFoote and @charettes . It seems like a natural thing to do, so it's worth a discussion. Here are a couple ideas that make sense to me:\r\n\r\n1. `pk` at the moment is reserved, users can't add a field named `pk`. We could remove this restriction.\r\n2. If `pk` is defined, it should always set `primary_key=True`.\r\n3. If `pk` is not defined, it should still refer to the `primary_key=True` field (e.g. `id` field). This is required for backwards-compatibility.\r\n4. If `pk` is defined, and it's an `IntegerField`, then a field called `pk` should be created in the database (same as any field, e.g. `id`).\r\n5. If `pk` is defined, and it's a `CompositePrimaryKey`, then a field called `pk` shouldn't be created in the database (same as any field, e.g. `primary_key`).\r\n\r\nMy only issue with this is, it adds extra complexity to how `pk` works. In this case, `pk` can be both a reference to the primary key field, or the primary key field itself.\r\n\r\nSo I'm not sure if it's worth doing this. It doesn't feel like an elegant or consistent solution to me.\r\n\r\n---\r\n\r\nThe other approach @charettes and @LilyFoote mentioned is to always have `pk` be a `CompositePrimaryKey` (could be renamed to `PrimaryKey`):\r\n\r\n1. `pk` cannot be defined explicitly.\r\n2. `CompositePrimaryKey` cannot be used explicitly.\r\n3. `pk` is _always_ added to the model in the background, and it's _always_ an instance of `CompositePrimaryKey`.\r\n4. Consequently, `pk` will cease to be a reference to another field, it will always be a field itself.\r\n5. If field `x` defines `primary_key=True`, `pk` is `CompositePrimaryKey(\"x\")`. `obj.pk` returns the value of `x` for backwards-compatibility (instead of a tuple).\r\n6. If `Meta.primary_key` option is `(\"a\", \"b\", \"c\")`, `pk` is `CompositePrimaryKey(\"a\", \"b\", \"c\")`. `obj.pk` returns a tuple.\r\n7. If `Meta.primary_key` is not set, it could be set to `(\"x\",)` automatically.\r\n\r\nThis is quite an invasive change. It would mean all existing models get a new field called `pk`.\r\n`meta.pk` would return a different field. Instead of `IntegerField`, it would return `CompositePrimaryKey`. Is breaking backwards-compatibility okay here?\r\n\r\nI don't have anything against it other than that. It does feel more intuitive. If the community wants this, I could fork this branch and open another PR.",
    "label": null
  },
  {
    "index": 479,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "Today's meeting with @LilyFoote and @charettes :\r\n* enable setting pk to CompositePrimaryKey explicitly. pk is a well-known Django keyword, so it makes sense to reuse it here, even if it somewhat complicates things.\r\n* pk can only be set to CompositePrimaryKey.\r\n* CompositePrimaryKey can't be set to anything else but pk.",
    "label": null
  },
  {
    "index": 480,
    "pr title": "Fixed #373 -- Added CompositePrimaryKey.",
    "comment": "@apollo13 , I discussed your suggestion with @LilyFoote and @charettes and they agreed. I pushed the changes. The only way to define a composite pk is with the `pk` field name now.",
    "label": null
  },
  {
    "index": 481,
    "pr title": "[Soc2014] Official meta API",
    "comment": "Here are some docs edits: http://dpaste.com/1X0TZB4\nLet me know if any changes look questionable.\n",
    "label": null
  },
  {
    "index": 482,
    "pr title": "[Soc2014] Official meta API",
    "comment": "Hi @timgraham thank you so much for the doc edits! I will have a look at them now.\n",
    "label": null
  },
  {
    "index": 483,
    "pr title": "[Soc2014] Official meta API",
    "comment": "Daniel, I'd recommend to finish the docs and then I'll do another review. After that, we can put out a call for anyone else who wants to do a final review. We still have time before 1.8 feature freeze to make changes as needed after merge, but this way you won't have to keep resolving conflicts due to changes in master.\n",
    "label": null
  },
  {
    "index": 484,
    "pr title": "[Soc2014] Official meta API",
    "comment": "Sounds great. I don't have access to a computer this week but will re-write\nall the docs as soon as I come back home.\n\nOn Wednesday, September 17, 2014, Tim Graham notifications@github.com\nwrote:\n\n> Daniel, I'd recommend to finish the docs and then I'll do another review.\n> After that, we can put out a call for anyone else who wants to do a final\n> review. We still have time before 1.8 feature freeze to make changes as\n> needed after merge, but this way you won't have to keep resolving conflicts\n> due to changes in master.\n> \n> ‚Äî\n> Reply to this email directly or view it on GitHub\n> https://github.com/django/django/pull/3114#issuecomment-55829765.\n\n## \n\n---\n\nPirosB3\n\nhttps://github.com/PirosB3\n",
    "label": null
  },
  {
    "index": 485,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@timgraham @freakboy3742 I have done pull from master, and now I am finishing up the docs. I expect this to be all complete in the next 2 days. Then we can do a final review \n",
    "label": null
  },
  {
    "index": 486,
    "pr title": "[Soc2014] Official meta API",
    "comment": "I ran into this issue using the code from the tutorial:\n\n```\n$ python manage.py shell\nTraceback (most recent call last):\n  File \"manage.py\", line 10, in <module>\n    execute_from_command_line(sys.argv)\n  File \"/home/tim/code/django/django/core/management/__init__.py\", line 336, in execute_from_command_line\n    utility.execute()\n  File \"/home/tim/code/django/django/core/management/__init__.py\", line 310, in execute\n    django.setup()\n  File \"/home/tim/code/django/django/__init__.py\", line 23, in setup\n    apps.populate(settings.INSTALLED_APPS)\n  File \"/home/tim/code/django/django/apps/registry.py\", line 115, in populate\n    app_config.ready()\n  File \"/home/tim/code/django/django/contrib/admin/apps.py\", line 22, in ready\n    self.module.autodiscover()\n  File \"/home/tim/code/django/django/contrib/admin/__init__.py\", line 24, in autodiscover\n    autodiscover_modules('admin', register_to=site)\n  File \"/home/tim/code/django/django/utils/module_loading.py\", line 73, in autodiscover_modules\n    import_module('%s.%s' % (app_config.name, module_to_search))\n  File \"/usr/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\n  File \"/home/tim/code/django/django/contrib/auth/admin.py\", line 182, in <module>\n    admin.site.register(Group, GroupAdmin)\n  File \"/home/tim/code/django/django/contrib/admin/sites.py\", line 101, in register\n    admin_class.check(model)\n  File \"/home/tim/code/django/django/contrib/admin/options.py\", line 149, in check\n    return cls.checks_class().check(cls, model, **kwargs)\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 492, in check\n    errors = super(ModelAdminChecks, self).check(cls, model=model, **kwargs)\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 32, in check\n    errors.extend(self._check_filter_horizontal(cls, model))\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 245, in _check_filter_horizontal\n    for index, field_name in enumerate(cls.filter_horizontal)\n  File \"/home/tim/code/django/django/contrib/admin/checks.py\", line 253, in _check_filter_item\n    field = model._meta.get_field(field_name)\n  File \"/home/tim/code/django/django/db/models/options.py\", line 434, in get_field\n    \"The Apps registry is still not ready, this means get_field() is not able \"\ndjango.core.exceptions.AppRegistryNotReady: The Apps registry is still not ready, this means get_field() is not able to find related objects that point to this model.\n```\n",
    "label": null
  },
  {
    "index": 487,
    "pr title": "[Soc2014] Official meta API",
    "comment": "There is still some usage of `get_field_by_name()` and other deprecated APIs in the tests. Run the tests with `python -Wall runtests.py` and ensure there are no errors.\n\nThere are also a fair number of flake8 errors -- some appear not related to your changes, but rather like you haven't merged in some commits from master. I think you could probably rebase and squash most of the commits now.\n",
    "label": null
  },
  {
    "index": 488,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@timgraham \nRE \"I ran into this issue using the code from the tutorial: ....\"\nTotally right, I added a fix for it, currently running unit tests. It looks like some admin checks are happening prior to the apps registry being ready. This should never happen actually, so I added a fix for it.\nI'll let you know once all tests pass with -Wall\n",
    "label": null
  },
  {
    "index": 489,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@timgraham I have just pushed the last changes with your comments fixed.\n",
    "label": null
  },
  {
    "index": 490,
    "pr title": "[Soc2014] Official meta API",
    "comment": "There are still many flake8 errors on your branch aren't there? This is what I see:\n\n```\n./django/db/models/manager.py:6:1: F401 'FieldDoesNotExist' imported but unused\n./django/db/models/options.py:13:1: F401 'Field' imported but unused\n./django/db/models/options.py:500:17: E126 continuation line over-indented for hanging indent\n./django/db/models/base.py:1420:9: F401 'FieldDoesNotExist' imported but unused\n./django/db/models/fields/__init__.py:45:1: E302 expected 2 blank lines, found 1\n./django/contrib/contenttypes/fields.py:41:15: W291 trailing whitespace\n./django/contrib/admin/utils.py:462:1: E302 expected 2 blank lines, found 1\n./django/contrib/admin/utils.py:481:1: E302 expected 2 blank lines, found 1\n./tests/prefetch_related/tests.py:723:45: E127 continuation line over-indented for visual indent\n./tests/apps/tests.py:18:1: F401 'AbstractPerson' imported but unused\n./tests/apps/tests.py:18:1: F401 'BasePerson' imported but unused\n./tests/apps/tests.py:18:1: F401 'Relation' imported but unused\n./tests/apps/tests.py:18:1: F401 'new_apps_2' imported but unused\n./tests/test_client_regress/tests.py:997:31: E127 continuation line over-indented for visual indent\n./tests/introspection/tests.py:133:18: E127 continuation line over-indented for visual indent\n```\n",
    "label": null
  },
  {
    "index": 491,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@aaugustin - do you know if admin checks happening prior to the app registry being ready is expected? see https://github.com/django/django/pull/3114#issuecomment-57612835. Seems suspicious to me and the workaround adds more code which isn't ideal: 3a6a7131e020b49ae3c030adddf320b32d43f3a8.\n",
    "label": null
  },
  {
    "index": 492,
    "pr title": "[Soc2014] Official meta API",
    "comment": "buildbot, retest this please.\n",
    "label": null
  },
  {
    "index": 493,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@freakboy3742 @timgraham Latest fixes (documentation + style + implementation) have been pushed. I'm ready for a further review\n",
    "label": null
  },
  {
    "index": 494,
    "pr title": "[Soc2014] Official meta API",
    "comment": "buildbot, retest this please.\n",
    "label": null
  },
  {
    "index": 495,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@collinanderson did the last fixes we spoke about, can you give me another rev?\n",
    "label": null
  },
  {
    "index": 496,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@PirosB3 It looks like most of comments on the PR have now been addressed.\n",
    "label": null
  },
  {
    "index": 497,
    "pr title": "[Soc2014] Official meta API",
    "comment": "Thanks @collinanderson \nLooking forward to hear comments from @timgraham @freakboy3742\n",
    "label": null
  },
  {
    "index": 498,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@timgraham To me it looks like the admin checks should be triggered from `AdminAppConfig.ready()`.\n",
    "label": null
  },
  {
    "index": 499,
    "pr title": "[Soc2014] Official meta API",
    "comment": "# Further API change\n\n### Properties changes\n- many_to_many becomes _many_to_many and is only used internally, as there should be no more external distinction between m2m and forward fields\n- fields, concrete_fields, local_concrete_fields become all internal, (with a _ before and not documented) , as there should be no more external distinction between m2m and forward fields\n- related_objects become reverse_fields, in order to keep the same name convention\n- we add another property called \"forward_fields\"\n- make get_fields() internal, but we don't change the endpoint name for legacy reasons (there was already a get_fields())\n\n### Final _meta API\n- field_names => [\"name\", \"surname\", ...]\n- get_field(field_name) => FieldInstance\n- forward_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- reverse_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n\n### Final internal _meta API\n- _fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- _concrete_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- _local_concrete_fields => [FieldInstance, FieldInstance, FieldInstance, .. ]\n- _many_to_many => [FieldInstance, FieldInstance, FieldInstance, .. ]\n",
    "label": null
  },
  {
    "index": 500,
    "pr title": "[Soc2014] Official meta API",
    "comment": "Assuming we document the `FieldDoesNotExist` exception as part of this (which will be necessary) this PR should also resolve https://code.djangoproject.com/ticket/9104 one way or the other.\n",
    "label": null
  },
  {
    "index": 501,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@tomchristie super correct! I have not documented FieldDoesNotExist yet. Waiting till we sort out the last field flags issues and the _meta API. Once I get the final blessing on these, I will finish the documentation part.\nSaid this, isn't django.db.models.fields the correct place for this Exception?\n",
    "label": null
  },
  {
    "index": 502,
    "pr title": "[Soc2014] Official meta API",
    "comment": "If we make it a public API, I am in favor of moving it to `core.exceptions` (and keeping backwards compatibility where it is now)\n",
    "label": null
  },
  {
    "index": 503,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@timgraham sounds good to me. We can move it there and then alias it back on db.models.fields\n",
    "label": null
  },
  {
    "index": 504,
    "pr title": "[Soc2014] Official meta API",
    "comment": "\"We can move it there and then alias it back on db.models.fields\"\n\nYes, that sounds like the right thing to do.\n\nOptionally we _could_ have the `db.models.fields` version be pushed into the pending deprecation state, but I don't much mind either way on that.\n",
    "label": null
  },
  {
    "index": 505,
    "pr title": "[Soc2014] Official meta API",
    "comment": "A quick question on API correctness:\n`opts.field_names` API can also return more than 1 name for each field, this usually happens with ForeignKeys, where fields can be fetched by property or property_id.\n\nThis is an example where `manager` is a ForeignKey: `{u'id', 'item', 'manager', u'manager_id', 'name'}`\n\nDo you think this is the correct way to go? or shall we exclude duplicates from `field_names`?\n",
    "label": null
  },
  {
    "index": 506,
    "pr title": "[Soc2014] Official meta API",
    "comment": "Gut reaction: I'd certainly expect it to only return the canonical attribute names, and not the `_id` variants.\n\nSo long as the API gives enough information for users to be able to derive the \"_id\" style ones if needed then that would seem sufficient.\n",
    "label": null
  },
  {
    "index": 507,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@tomchristie interestingly Django also uses the *_id stuff internally. I suggest we keep the possibility of Django fetching fields by *_id using get_field(), but we remove duplicates in field_names\n",
    "label": null
  },
  {
    "index": 508,
    "pr title": "[Soc2014] Official meta API",
    "comment": "@PirosB3 What's the hold-up in using `_meta.fields` as the main (and only) entry point? Is that backward compatibility because `fields` doesn't have \"fake\" fields like reverse relations?\n\nIf that's the case I think we have here a unique opportunity to get it right and it's easy enough to provide an upgrade path.\n",
    "label": null
  }
]