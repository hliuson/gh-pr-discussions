[
    {
    "index": 3,
    "filtered_comments": [
      "I'm getting this error when try to use MPS\r\n\r\n/Users/diego/.pyenv/versions/3.10.6/lib/python3.10/site-packages/whisper-1.0-py3.10.egg/whisper/decoding.py:629: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/diego/Projects/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/2d9b4df9-4b93-11ed-b0fc-2e32217d8374/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 23200 bytes\r\n'\r\nAbort trap: 6\r\n/Users/diego/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n\r\nany clues?",
      "@DiegoGiovany Not an expert on this but It looks like PyTorch itself is missing some operators for MPS. See for example\r\nhttps://github.com/pytorch/pytorch/issues/77764#issuecomment-1254352628\r\n(which refers to repeat_interleave)\r\n\r\nand\r\nhttps://github.com/pytorch/pytorch/issues/87219\r\n",
      "Thanks for your work. I just tried this. Unfortunately, it didn't work for me on my m1 max with 32GB.\r\nHere is what I did:\r\npip install git+https://github.com/openai/whisper.git@refs/pull/382/head\r\n\r\nNo errors on install and it works fine when run without mps: whisper audiofile_name --model medium \r\n\r\nWhen I run: whisper audiofile_name --model medium --device mps\r\n\r\nHere is the error I get:\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/810eba08-405a-11ed-86e9-6af958a02716/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1024x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s). \r\n\r\nWhen I run:  whisper audiofile_name --model medium --device mps --fp16 False\r\n\r\nHere is the error I get:\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\nDetected language: English\r\n/anaconda3/lib/python3.9/site-packages/whisper/decoding.py:633: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/f0468ab4-4115-11ed-8edc-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 1007280 bytes\r\n\r\nBasically, same error as @DiegoGiovany.\r\n\r\nAny ideas on how to fix?",
      "@dwarkeshsp \r\n\r\nnot work，with mbp2015 pytorch 1.3 stable，egpu RX580, MacOS 12.3.\r\n\r\nchanged the code as the same as yours.\r\n\r\nchanged  to use --device mps but show error, maybe there is still somewhere to change or modify.\r\n\r\nuse --device cpu, it works.\r\n\r\nwith other pytorch-metal project, MPS works.",
      "I also see the same errors as others mentioned above, on an M1 Mac running arm64 Python. ",
      "On an M1 16\" MBP with 16GB running MacOS 13.0.1, I'm seeing the following with `openai-whisper-20230117`:\r\n\r\nUsing this command:\r\n```(venv) whisper_ai_playground % whisper './test_file.mp3' --model tiny.en --output_dir ./output --device mps```\r\n\r\nI'm encountering the following errors:\r\n\r\n```loc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/810eba08-405a-11ed-86e9-6af958a02716/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x384x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible```\r\n\r\n```LLVM ERROR: Failed to infer result type(s).```\r\n\r\n```zsh: abort      whisper  --model tiny.en --output_dir ./output --device mps```\r\n\r\n```/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '```",
      "Same problem with osx 13.2 in MacBook Pro M2 max:\r\n\r\n```\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1280x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\nzsh: abort      whisper audio.wav --language en --model large\r\nm2@Render ~ % /opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
      "I'm getting the same error as @renderpci using the M1 Base Model\r\n```bash\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x512x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\n[1]    3746 abort      python3 test.py\r\n```\r\n**test.py:**\r\n```py\r\nimport whisper\r\n\r\nmodel = whisper.load_model(\"base\")\r\nresult = model.transcribe(\"audio.mp3\")\r\nprint(result[\"text\"])\r\n```",
      "FWIW I switched to the C++ port https://github.com/ggerganov/whisper.cpp/ and got a ~15x speedup compared to CPU pytorch on my M1 Pro. (But note that it doesn't have all the features/flags from the official whisper repo.)",
      "> FWIW I switched to the C++ port https://github.com/ggerganov/whisper.cpp/ \r\n\r\nFor us whisper.cpp is not an option:\r\n\r\n> **Should I use whisper.cpp in my project?**\r\n> \r\n> whisper.cpp is a hobby project. It does not strive to provide a production ready implementation. The main goals of the implementation is to be educational, minimalistic, portable, hackable and performant. There are no guarantees that the implementation is correct and bug-free and stuff can break at any point in the future. Support and updates will depend mostly on contributions, since with time I will move on and won't dedicate too much time on the project.\r\n> \r\n> If you plan to use whisper.cpp in your own project, keep in mind the above.\r\n> My advice is to not put all your eggs into the whisper.cpp basket.",
      "The same error as @renderpci using the M2\r\n\r\n\r\nwhisper interview.mp4 --language en --model large --device mps\r\n\r\n```\r\nloc(\"mps_multiply\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":228:0)): error: input types 'tensor<1x1280x3000xf16>' and 'tensor<1xf32>' are not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s).\r\nzsh: abort      whisper interview.mp4 --language en --model large --device mps\r\npac@dd ~ % /opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
      "Hey @devpacdd  - this should be fixed in latest pytorch nightly (pip3 install --pre --force-reinstall torch --index-url https://download.pytorch.org/whl/nightly/cpu). Let me know if you still see any issues. Thanks",
      "Still have the same error after updating\r\n\r\nEdit: After adding `--fp16 False` to the command, I now get a new error, as well as the old one:\r\n```\r\n/opt/homebrew/lib/python3.10/site-packages/whisper/decoding.py:633: UserWarning: The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/AppleInternal/Library/BuildRoots/5b8a32f9-5db2-11ed-8aeb-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:794: failed assertion `[MPSNDArray, initWithBuffer:descriptor:] Error: buffer is not large enough. Must be 1007280 bytes\r\n'\r\nzsh: abort      whisper --model large --language de --task transcribe  --device mps --fp16\r\n/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n```",
      "i was able to get it to kinda work: https://github.com/davabase/whisper_real_time/issues/5#issue-1596258783",
      "> The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n>   audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n\r\n@manuthebyte could you please make sure you are on a recent nightly? `repeat_interleave` should be natively supported. If you could try grabbing today's nightly and give a try that would be awesome! (You can get today's nightly with `pip3 install --pre --force-reinstall torch==2.0.0.dev20230224 --index-url https://download.pytorch.org/whl/nightly/cpu`)\r\n\r\n",
      "Wow! \r\n\r\nwhen running:\r\n`Python3 transcribe_demo.py --model medium` (from https://github.com/davabase/whisper_real_time)\r\n\r\nwith the following packages in my pipenv's requirements.txt\r\n```\r\ncertifi==2022.12.7\r\ncharset-normalizer==3.0.1\r\nffmpeg-python==0.2.0\r\nfilelock==3.9.0\r\nfuture==0.18.3\r\nhuggingface-hub==0.12.1\r\nidna==3.4\r\nmore-itertools==9.0.0\r\nmpmath==1.2.1\r\nnetworkx==3.0rc1\r\nnumpy==1.24.2\r\nopenai-whisper @ git+https://github.com/openai/whisper.git@51c785f7c91b8c032a1fa79c0e8f862dea81b860\r\npackaging==23.0\r\nPillow==9.4.0\r\nPyAudio==0.2.13\r\nPyYAML==6.0\r\nregex==2022.10.31\r\nrequests==2.28.2\r\nSpeechRecognition==3.9.0\r\nsympy==1.11.1\r\ntokenizers==0.13.2\r\ntorch==2.0.0.dev20230224\r\ntorchaudio==0.13.1\r\ntorchvision==0.14.1\r\ntqdm==4.64.1\r\ntransformers==4.26.1\r\ntyping_extensions==4.4.0\r\nurllib3==1.26.14\r\n```\r\n\r\nit gets every word! while i was singing! in realtime, with maybe 50%~ gpu usage on the apple M2 Pro Max.",
      "> > The operator 'aten::repeat_interleave.self_int' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n> > audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n> \r\n> @manuthebyte could you please make sure you are on a recent nightly? `repeat_interleave` should be natively supported. If you could try grabbing today's nightly and give a try that would be awesome! (You can get today's nightly with `pip3 install --pre --force-reinstall torch==2.0.0.dev20230224 --index-url https://download.pytorch.org/whl/nightly/cpu`)\r\n\r\nWith my pip3 freeze being:\r\n```\r\nbeautifulsoup4==4.11.2\r\ncertifi==2022.12.7\r\ncharset-normalizer==3.0.1\r\ncolorama==0.4.6\r\ndnspython==2.3.0\r\nffmpeg-python==0.2.0\r\nfilelock==3.9.0\r\nfuture==0.18.3\r\nhuggingface-hub==0.12.1\r\nidna==3.4\r\nmore-itertools==9.0.0\r\nmpmath==1.2.1\r\nnetworkx==3.0rc1\r\nnumpy==1.24.2\r\nopenai-whisper @ git+https://github.com/openai/whisper.git@7858aa9c08d98f75575035ecd6481f462d66ca27\r\npackaging==23.0\r\nprotobuf==4.21.12\r\nPyYAML==6.0\r\nregex==2022.10.31\r\nrequests==2.28.2\r\nsix==1.16.0\r\nsoupsieve==2.4\r\nsympy==1.11.1\r\ntokenizers==0.13.2\r\ntorch==2.0.0.dev20230224\r\ntqdm==4.64.1\r\ntransformers==4.26.1\r\ntyping_extensions==4.4.0\r\nurllib3==1.26.14\r\n```\r\n\r\nIt now seems to use the GPU but I now get these errors:\r\n```\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:636: UserWarning: 0MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\r\n  audio_features = audio_features.repeat_interleave(self.n_group, dim=0)\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:443: UserWarning: 1MPS: no support for int64 reduction ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:143.)\r\n  timestamp_logprob = logprobs[k, self.tokenizer.timestamp_begin :].logsumexp(dim=-1)\r\n/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py:444: UserWarning: 1MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:1269.)\r\n  max_text_token_logprob = logprobs[k, : self.tokenizer.timestamp_begin].max()\r\nTraceback (most recent call last):\r\n  File \"/opt/homebrew/bin/whisper\", line 8, in <module>\r\n    sys.exit(cli())\r\n             ^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 314, in cli\r\n    result = transcribe(model, audio_path, temperature=temperature, **args)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 183, in transcribe\r\n    result: DecodingResult = decode_with_fallback(segment)\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/transcribe.py\", line 118, in decode_with_fallback\r\n    decode_result = model.decode(segment, options)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 707, in decode\r\n    result = DecodingTask(model, options).run(mel)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 640, in run\r\n    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\r\n                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 609, in _main_loop\r\n    tokens, completed = self.decoder.update(tokens, logits, sum_logprobs)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/whisper/decoding.py\", line 258, in update\r\n    next_tokens = Categorical(logits=logits / self.temperature).sample()\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/distributions/categorical.py\", line 66, in __init__\r\n    super().__init__(batch_shape, validate_args=validate_args)\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/torch/distributions/distribution.py\", line 62, in __init__\r\n    raise ValueError(\r\nValueError: Expected parameter logits (Tensor of shape (5, 51865)) of distribution Categorical(logits: torch.Size([5, 51865])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\r\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan],\r\n        [nan, nan, nan,  ..., nan, nan, nan]], device='mps:0')\r\n```\r\n\r\nWhen running the command `whisper --model small --language en --task transcribe ***.wav --device mps`",
      "> Hey @devpacdd - this should be fixed in latest pytorch nightly (pip3 install --pre --force-reinstall torch --index-url https://download.pytorch.org/whl/nightly/cpu). Let me know if you still see any issues. Thanks\r\n\r\nGeart! it works!\r\nBut.. In my test the GPU is slow than CPU... ??? \r\n\r\nAudio to transcribe: 1 minute with model large, language catalan\r\n\r\nCPU  : 2m : 33 s\r\nGPU (--device mps): 4m : 54 s\r\n\r\nI tried with different files and the result was the same; +/- double time with GPU enable.\r\n\r\nIt's normal? I expected less time for GPU than CPU.\r\n\r\nBest",
      "I get this error while trying to use MPS\r\n\r\nHere is the command I am running: `whisper --model large --language en --task transcribe test.mp3 --device mps`\r\n\r\n```\r\n$ whisper --model large --language en --task transcribe test.mp3 --device mps\r\nTraceback (most recent call last):\r\n  File \"/Users/mukul/miniconda3/envs/ml/bin/whisper\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/whisper/transcribe.py\", line 433, in cli\r\n    model = load_model(model_name, device=device, download_root=model_dir)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/whisper/__init__.py\", line 159, in load_model\r\n    return model.to(device)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1170, in to\r\n    return self._apply(convert)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 869, in _apply\r\n    self._buffers[key] = fn(buf)\r\n  File \"/Users/mukul/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1168, in convert\r\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\r\nNotImplementedError: Could not run 'aten::empty.memory_format' with arguments from the 'SparseMPS' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty.memory_format' is only available for these backends: [CPU, MPS, Meta, QuantizedCPU, QuantizedMeta, MkldnnCPU, SparseCPU, SparseMeta, SparseCsrCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\r\n\r\nCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterCPU.cpp:31085 [kernel]\r\nMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMPS.cpp:24065 [kernel]\r\nMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26824 [kernel]\r\nQuantizedCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\r\nQuantizedMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterQuantizedMeta.cpp:105 [kernel]\r\nMkldnnCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterMkldnnCPU.cpp:507 [kernel]\r\nSparseCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseCPU.cpp:1379 [kernel]\r\nSparseMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\r\nSparseCsrCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseCsrCPU.cpp:1128 [kernel]\r\nBackendSelect: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterBackendSelect.cpp:734 [kernel]\r\nPython: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\r\nFuncTorchDynamicLayerBackMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\r\nFunctionalize: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:290 [backend fallback]\r\nNamed: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\r\nConjugate: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\r\nNegative: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/NegateFallback.cpp:23 [kernel]\r\nZeroTensor: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:90 [kernel]\r\nADInplaceOrView: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\r\nAutogradOther: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradCUDA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradHIP: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradXLA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradIPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradXPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradHPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradVE: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradLazy: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradMTIA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse1: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse2: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradPrivateUse3: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nAutogradNestedTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:17927 [autograd kernel]\r\nTracer: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:16872 [kernel]\r\nAutocastCPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\r\nAutocastCUDA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\r\nFuncTorchBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:815 [backend fallback]\r\nFuncTorchVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\r\nBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1073 [backend fallback]\r\nVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\r\nFuncTorchGradWrapper: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\r\nPythonTLSSnapshot: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\r\nFuncTorchDynamicLayerFrontMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\r\nPythonDispatcher: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\r\n```",
      "@mukulpatnaik \r\nMy device is M1 MacBook Pro, I got the same error with the latest version of whisper([v20230314](https://github.com/openai/whisper/releases/tag/v20230314)), then I switch to [v20230124](https://github.com/openai/whisper/releases/tag/v20230124), every thing works fine. (torch nightly version)\r\n\r\nBut, seems like mps is slower than cpu like @renderpci reported, for my task\r\n* cpu 3.26 s\r\n* mps 5.25 s\r\n* cpu+torch2 compile 3.31 s\r\n* mps+torch2 compile 4.94 s\r\n\r\n🫠"
    ],
    "code_diff": "diff --git a/whisper/__init__.py b/whisper/__init__.py\nindex 2a1fb4ec6..4f45f9969 100644\n--- a/whisper/__init__.py\n+++ b/whisper/__init__.py\n@@ -92,7 +92,12 @@ def load_model(name: str, device: Optional[Union[str, torch.device]] = None, dow\n     \"\"\"\n \n     if device is None:\n-        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n+        if torch.cuda.is_available():\n+            device = \"cuda\"\n+        elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n+            device = \"mps\"\n+        else:\n+            device = \"cpu\"\n     if download_root is None:\n         download_root = os.getenv(\n             \"XDG_CACHE_HOME\", \ndiff --git a/whisper/transcribe.py b/whisper/transcribe.py\nindex d95d3336d..0d89a5d77 100644\n--- a/whisper/transcribe.py\n+++ b/whisper/transcribe.py\n@@ -75,6 +75,8 @@ def transcribe(\n     if model.device == torch.device(\"cpu\"):\n         if torch.cuda.is_available():\n             warnings.warn(\"Performing inference on CPU when CUDA is available\")\n+        if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n+            warnings.warn(\"Performing inference on CPU when MPS is available\")\n         if dtype == torch.float16:\n             warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n             dtype = torch.float32\n",
    "diff_length": 1323
  }
]